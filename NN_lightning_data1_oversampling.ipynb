{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6a7c158",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7c823d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d840881",
   "metadata": {},
   "source": [
    "## Display function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c24af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for displaying ROC curves of multiple classifiers\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def plot_roc_connected_points(results_list, results_original_roc, name=\"All Classifiers\"):\n",
    "    \"\"\"\n",
    "    Creates a plot showing the performance of all classifiers as points,\n",
    "    and connects them with a line, sorted by FPR.\n",
    "\n",
    "    Args:\n",
    "        results_list: A list of dictionaries, where each dict contains 'fpr', 'tpr'.\n",
    "    \"\"\"\n",
    "    if not results_list:\n",
    "        print(\"No results to plot.\")\n",
    "        return\n",
    "\n",
    "    # Convert results to a pandas DataFrame for easy sorting\n",
    "    df = pd.DataFrame(results_list)\n",
    "    \n",
    "    # Sort the models by their False Positive Rate to create a left-to-right line\n",
    "    df_sorted = df.sort_values(by='fpr').reset_index(drop=True)\n",
    "    \n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    # Plot all the individual model points as a scatter plot\n",
    "    # This helps see the actual performance of each model\n",
    "    plt.scatter(df_sorted['fpr'], df_sorted['tpr'], c='black', marker='o', \n",
    "                alpha=0.6, s=100, zorder=3) # zorder=3 puts dots on top\n",
    "\n",
    "    # Plot the line connecting the points\n",
    "    plt.plot(df_sorted['fpr'], df_sorted['tpr'], color='red', lw=1.5,\n",
    "             alpha=0.8, label=f'{name} (AUC = {auc(df_sorted[\"fpr\"], df_sorted[\"tpr\"]):.2f})')\n",
    "    \n",
    "    #plot the original ROC curve\n",
    "    plt.plot(results_original_roc[\"fpr\"], results_original_roc[\"tpr\"], color='blue', \n",
    "             label=f'{results_original_roc[\"name\"]} (AUC = {results_original_roc[\"auc\"]:.2f})')\n",
    "\n",
    "    # Plot the \"no-skill\" line for reference\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.title('Performance Path of All Trained Classifiers')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23b1ea",
   "metadata": {},
   "source": [
    "## Best ROC envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e350c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def get_best_roc_envelope(results_list, results_original_roc=None):\n",
    "    \"\"\"\n",
    "    Constructs the upper envelope of multiple ROC curves to find the best\n",
    "    possible operating points from a collection of classifiers.\n",
    "\n",
    "    This function is guaranteed to produce a list of points that starts at\n",
    "    (FPR=0, TPR=0) and ends at (FPR=1, TPR=1), making it suitable for direct\n",
    "    plotting and AUC calculation.\n",
    "\n",
    "    Args:\n",
    "        results_list (list): A list of dictionaries. Each dictionary must\n",
    "                             contain a 'model' name and the full ROC results\n",
    "                             under the 'full_roc' key.\n",
    "        results_original_roc (dict, optional): A dictionary containing the\n",
    "                                               ROC results of a baseline model,\n",
    "                                               which will also be included in\n",
    "                                               the comparison. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        list: A sorted list of dictionaries representing the optimal ROC\n",
    "              envelope. Each dictionary includes 'model', 'fpr', 'tpr',\n",
    "              and 'threshold'.\n",
    "    \"\"\"\n",
    "    all_points = []\n",
    "\n",
    "    # Step 1: Gather all ROC points from all provided models\n",
    "    all_results = results_list[:]\n",
    "    if results_original_roc:\n",
    "        all_results.append({\n",
    "            'model': 'original_baseline',\n",
    "            'full_roc': results_original_roc\n",
    "        })\n",
    "\n",
    "    for result in all_results:\n",
    "        model_name = result.get('model', 'Unknown Model')\n",
    "        roc = result.get('full_roc')\n",
    "        if not roc: continue\n",
    "\n",
    "        fprs = roc.get('fpr', [])\n",
    "        tprs = roc.get('tpr', [])\n",
    "        thresholds = roc.get('thresholds', [])\n",
    "\n",
    "        for i in range(len(fprs)):\n",
    "            threshold = thresholds[i] if i < len(thresholds) else thresholds[-1]\n",
    "            all_points.append({\n",
    "                'model': model_name, 'fpr': fprs[i],\n",
    "                'tpr': tprs[i], 'threshold': threshold\n",
    "            })\n",
    "\n",
    "    # Handle case with no data by returning a default diagonal line\n",
    "    if not all_points:\n",
    "        return [\n",
    "            {'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf},\n",
    "            {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}\n",
    "        ]\n",
    "\n",
    "    # Step 2: Sort all points by FPR (asc), then by TPR (desc)\n",
    "    all_points.sort(key=lambda p: (p['fpr'], -p['tpr']))\n",
    "\n",
    "    # Step 3: Build the core ROC envelope\n",
    "    best_roc_envelope = []\n",
    "    max_tpr_so_far = -1.0\n",
    "    for point in all_points:\n",
    "        # Add a point only if it has a strictly higher TPR\n",
    "        if point['tpr'] > max_tpr_so_far:\n",
    "            # To prevent adding multiple points at the same FPR, check if the last point\n",
    "            # has the same FPR and replace it if so (since this one has a higher TPR)\n",
    "            if best_roc_envelope and best_roc_envelope[-1]['fpr'] == point['fpr']:\n",
    "                best_roc_envelope[-1] = point\n",
    "            else:\n",
    "                best_roc_envelope.append(point)\n",
    "            max_tpr_so_far = point['tpr']\n",
    "    \n",
    "    # Step 4: Manually add extremities if they are missing\n",
    "    \n",
    "    # Ensure the curve starts at (0, 0)\n",
    "    if not best_roc_envelope or best_roc_envelope[0]['fpr'] > 0.0:\n",
    "        best_roc_envelope.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if best_roc_envelope[-1]['fpr'] < 1.0 or best_roc_envelope[-1]['tpr'] < 1.0:\n",
    "        best_roc_envelope.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    return best_roc_envelope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b781e9",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c3deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def generate_data(dataset):\n",
    "    if dataset == \"data1\":\n",
    "        no_predictors = 2\n",
    "        no_samples = 1600\n",
    "        no_classes = 2\n",
    "        #kerneltype = 'linear'  #comment out for polynomial kernel\n",
    "        #kerneltype = 'poly'  #comment out for linear kernel\n",
    "\n",
    "\n",
    "\n",
    "        n_samples_per_cluster = 400\n",
    "        n_clusters = 4\n",
    "\n",
    "        # Create the clusters deterministically\n",
    "        np.random.seed(0) # for reproducibility\n",
    "\n",
    "        X = np.zeros((n_samples_per_cluster * n_clusters, 2))\n",
    "        y = np.zeros(n_samples_per_cluster * n_clusters)\n",
    "\n",
    "        # Cluster centers in corners of a square\n",
    "        centers = [[0, 0], [2, 0], [0, 2], [2, 2]]\n",
    "\n",
    "        # Assign points to clusters deterministically\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = slice(i * n_samples_per_cluster, (i + 1) * n_samples_per_cluster)\n",
    "            X[cluster_indices] = centers[i] + np.random.normal(scale=0.5, size=(n_samples_per_cluster, 2))\n",
    "            if i == 0 or i == 3:\n",
    "                y[cluster_indices] = 0\n",
    "            else:\n",
    "                y[cluster_indices] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #Visualize\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap='viridis', s=50)\n",
    "        plt.title('Four Clusters of Equal Size')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "\n",
    "        #add intercept to X\n",
    "        #X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # # shuffle data\n",
    "        # permutation = np.random.permutation(no_samples)\n",
    "        # X = X[permutation]\n",
    "        # y = y[permutation]\n",
    "\n",
    "\n",
    "        #Split data into training and testing sets\n",
    "        # Step 1: Split off the 1000 training samples. The rest (600) go into a temporary pool.\n",
    "        # We can use absolute numbers for the size.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=1000,  # Specify exactly 1000 samples for training\n",
    "            random_state=42,\n",
    "            stratify=y        # Crucial for classification: keeps class proportions the same\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "        train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        val_data = test_data\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "    elif dataset == \"data2\":\n",
    "        no_predictors = 2\n",
    "        no_samples = 1600\n",
    "        no_classes = 2\n",
    "        #kerneltype = 'linear'  #comment out for polynomial kernel\n",
    "        #kerneltype = 'poly'  #comment out for linear kernel\n",
    "\n",
    "\n",
    "\n",
    "        n_samples_per_cluster = 400\n",
    "        n_clusters = 4\n",
    "\n",
    "        # Create the clusters deterministically\n",
    "        np.random.seed(0) # for reproducibility\n",
    "\n",
    "        X = np.zeros((n_samples_per_cluster * n_clusters, 2))\n",
    "        y = np.zeros(n_samples_per_cluster * n_clusters)\n",
    "\n",
    "        # Cluster centers in corners of a square\n",
    "        centers = [[0, 0], [2, 0], [1, 2], [1, 2]]\n",
    "\n",
    "        # Assign points to clusters deterministically\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = slice(i * n_samples_per_cluster, (i + 1) * n_samples_per_cluster)\n",
    "            X[cluster_indices] = centers[i] + np.random.normal(scale=0.5, size=(n_samples_per_cluster, 2))\n",
    "            if i == 0 or i == 3:\n",
    "                y[cluster_indices] = 0\n",
    "            else:\n",
    "                y[cluster_indices] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #Visualize\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap='viridis', s=50)\n",
    "        plt.title('Four Clusters of Equal Size')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "\n",
    "        #add intercept to X\n",
    "        #X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # # shuffle data\n",
    "        # permutation = np.random.permutation(no_samples)\n",
    "        # X = X[permutation]\n",
    "        # y = y[permutation]\n",
    "\n",
    "\n",
    "        #Split data into training and testing sets\n",
    "        # Step 1: Split off the 1000 training samples. The rest (600) go into a temporary pool.\n",
    "        # We can use absolute numbers for the size.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=1000,  # Specify exactly 1000 samples for training\n",
    "            random_state=42,\n",
    "            stratify=y        # Crucial for classification: keeps class proportions the same\n",
    "        )\n",
    "\n",
    "\n",
    "        train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        val_data = test_data\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "    elif dataset == \"pneumoniaMNIST\":\n",
    "        import medmnist\n",
    "        print(medmnist.__version__)\n",
    "        # read in the PneumoniaMNIST dataset\n",
    "        from medmnist import PneumoniaMNIST\n",
    "        train_data = PneumoniaMNIST(split='train', download=True, size=224)\n",
    "        test_data = PneumoniaMNIST(split='test', download=True, size=224)\n",
    "        val_data = PneumoniaMNIST(split='val', download=True, size=224)\n",
    "        # print the dataset info\n",
    "        print(f\"Number of training samples: {len(train_data)}\")\n",
    "        print(f\"Number of test samples: {len(test_data)}\")\n",
    "        print(f\"Number of validation samples: {len(val_data)}\")\n",
    "\n",
    "    return train_data, test_data, val_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c59034e",
   "metadata": {},
   "source": [
    "## Data1: NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74133e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a060ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "IMAGE_SIZE = 224\n",
    "NUM_CLASSES = 1\n",
    "NUM_CHANNELS = 1\n",
    "NUM_EPOCHS = 1\n",
    "NUM_WORKERS = 4\n",
    "K_FOLDS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a702675",
   "metadata": {},
   "source": [
    "### Lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3760e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "\n",
    "# A simple classifier head\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_features=2, hidden_units=32, num_classes=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_features (int): Number of input features (2 for your data)\n",
    "            hidden_units (int): Number of neurons in the hidden layer\n",
    "            num_classes (int): Number of output classes (1 for binary)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            # --- Hidden Layer 1 ---\n",
    "            # Takes 2 features in, outputs a hidden representation of size 32\n",
    "            nn.Linear(in_features=input_features, out_features=hidden_units),\n",
    "            nn.ReLU(),  # <-- The crucial non-linear activation function\n",
    "\n",
    "            # --- Output Layer ---\n",
    "            # Takes the 16-unit hidden representation, outputs 1 logit\n",
    "            nn.Linear(in_features=hidden_units, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)\n",
    "\n",
    "# A new LightningModule just for training the classifier\n",
    "class LitClassifier(pl.LightningModule):\n",
    "    def __init__(self, input_features=512, hidden_units=32, num_classes=1, learning_rate=1e-4, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = SimpleClassifier(\n",
    "            input_features=self.hparams.input_features,\n",
    "            hidden_units=self.hparams.hidden_units,\n",
    "            num_classes=self.hparams.num_classes\n",
    "        )\n",
    "\n",
    "        self.current_test_threshold = 0.5  # Default threshold for binary classification\n",
    "\n",
    "        # This ensures the model's structure is correct upon initialization\n",
    "        if self.hparams.pos_weight is not None:\n",
    "            self.criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(self.hparams.pos_weight))\n",
    "        else:\n",
    "            self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        \n",
    "        \n",
    "        # --- METRICS ---\n",
    "        self.train_accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.test_accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.test_auc = torchmetrics.AUROC(task=\"binary\")\n",
    "        \n",
    "        # This list will store outputs from each test step\n",
    "        self.test_step_outputs = []\n",
    "        # This dictionary will hold the final results\n",
    "        self.last_test_results = {}\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        features, labels = batch\n",
    "        outputs = self(features)\n",
    "        \n",
    "        # For the loss function, labels need to be reshaped to match outputs\n",
    "        loss = self.criterion(outputs, labels.float().view(-1, 1))\n",
    "        \n",
    "        # For metrics, squeeze predictions to match labels' shape\n",
    "        self.train_accuracy(outputs.squeeze(), labels.int())\n",
    "        \n",
    "        self.log('classifier_train_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('classifier_train_acc', self.train_accuracy, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        features, labels = batch\n",
    "        outputs = self.model(features)\n",
    "        loss = self.criterion(outputs, labels.float().view(-1, 1))\n",
    "\n",
    "        # Append predictions and labels to our list for aggregation\n",
    "        self.test_step_outputs.append({\"preds\": outputs.detach(), \"labels\": labels.detach()})\n",
    "        \n",
    "        self.log('test_loss', loss)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        if not self.test_step_outputs:\n",
    "            return # Avoid errors if test loop was empty\n",
    "\n",
    "        # Concatenate all predictions and labels\n",
    "        all_preds = torch.cat([x['preds'] for x in self.test_step_outputs])\n",
    "        all_labels = torch.cat([x['labels'] for x in self.test_step_outputs])\n",
    "\n",
    "        # --- FIX: Squeeze BOTH predictions and labels to ensure they match ---\n",
    "        squeezed_preds = all_preds.squeeze()\n",
    "        all_probs = torch.sigmoid(squeezed_preds)\n",
    "        # The labels tensor might also be [N, 1], so we squeeze it as well.\n",
    "        int_labels = all_labels.squeeze().int()\n",
    "\n",
    "        # Calculate final scalar metrics\n",
    "        test_acc = self.test_accuracy(squeezed_preds, int_labels)\n",
    "        test_auc_val = self.test_auc(squeezed_preds, int_labels)\n",
    "\n",
    "\n",
    "        # Get the confusion matrix stats at the default 0.0 logit threshold\n",
    "        tp, fp, tn, fn, _ = torchmetrics.functional.stat_scores(\n",
    "            all_probs, int_labels, task=\"binary\", threshold=self.current_test_threshold\n",
    "        ) \n",
    "        \n",
    "        # Calculate TPR and FPR from these raw scores\n",
    "        epsilon = 1e-6\n",
    "        tpr_at_0 = tp / (tp + fn + epsilon)\n",
    "        fpr_at_0 = fp / (fp + tn + epsilon)\n",
    "\n",
    "        # Calculate data for the full ROC Curve\n",
    "        fpr_full, tpr_full, thresholds_full = torchmetrics.functional.roc(\n",
    "            torch.sigmoid(squeezed_preds),\n",
    "            int_labels,\n",
    "            task=\"binary\"\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"\\n--- Final Classifier Test Metrics ---\")\n",
    "        print(f\"Accuracy: {test_acc:.4f}\")\n",
    "        print(f\"AUC: {test_auc_val:.4f}\")\n",
    "        print(\"-------------------------------------\\n\")\n",
    "        \n",
    "        self.last_test_results = {\n",
    "            \"w\": self.hparams.get('w'),\n",
    "            \"fpr\": fpr_at_0.cpu().numpy(),\n",
    "            \"tpr\": tpr_at_0.cpu().numpy(),\n",
    "            \"threshold\": self.current_test_threshold,\n",
    "            \"auc\": test_auc_val.cpu().numpy(),\n",
    "            \"accuracy\": test_acc.cpu().numpy(),\n",
    "            \"full_roc\": {\n",
    "                \"fpr\": fpr_full.cpu().numpy(),\n",
    "                \"tpr\": tpr_full.cpu().numpy(),\n",
    "                \"thresholds\": thresholds_full.cpu().numpy()\n",
    "            }\n",
    "        }\n",
    "        self.test_step_outputs.clear()\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ea652",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4f28dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1000, 2), (1000,)\n",
      "Test data shape: (600, 2), (600,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "train_data, test_data, val_data = generate_data(\"data1\")\n",
    "\n",
    "\n",
    "train_data_tensor = data.TensorDataset(torch.tensor(train_data[:, :-1], dtype=torch.float32),\n",
    "                                        torch.tensor(train_data[:, -1], dtype=torch.float32))\n",
    "train_loader = data.DataLoader(train_data_tensor, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS) #over-write later for k-fold cross-validation\n",
    "test_data_tensor = data.TensorDataset(torch.tensor(test_data[:, :-1], dtype=torch.float32),\n",
    "                                       torch.tensor(test_data[:, -1], dtype=torch.float32))\n",
    "test_loader = data.DataLoader(test_data_tensor, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "# initialize fold\n",
    "kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8065beae",
   "metadata": {},
   "source": [
    "### Regular training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "261a6f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Training for 1 epochs on train_loader ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (16) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d509b66b3345939b1e18eb984fd865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model from Phase 1 saved to: /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v13.ckpt\n",
      "\n",
      "--- Testing model from Phase 1 checkpoint: /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v13.ckpt ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a84e9d55144cccac53d2af5b2395e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4683\n",
      "AUC: 0.4458\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7087163925170898\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Manually Calculating Metrics on Test Set ---\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[190 110]\n",
      " [210  90]]\n",
      "\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.47      0.63      0.54       300\n",
      "     Class 1       0.45      0.30      0.36       300\n",
      "\n",
      "    accuracy                           0.47       600\n",
      "   macro avg       0.46      0.47      0.45       600\n",
      "weighted avg       0.46      0.47      0.45       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# --- Place any constants or unchanging objects outside the loop ---\n",
    "pl.seed_everything(42, workers=True)\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. Instantiate the LightningModule\n",
    "model = LitClassifier(input_features=2, hidden_units=32, learning_rate=LEARNING_RATE)\n",
    "\n",
    "checkpoint_callback_full_model = ModelCheckpoint(\n",
    "    monitor='classifier_train_acc',  # Monitor training accuracy\n",
    "    every_n_epochs=1,                # Save model every epoch\n",
    "    dirpath='checkpoints/',\n",
    "    filename='simple-clf-{epoch:02d}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "train_trainer_1 = pl.Trainer(\n",
    "    accelerator='gpu',                 # Use GPUs\n",
    "    devices=1,                         # Number of GPUs to use\n",
    "    #strategy='ddp_notebook',                    # DistributedDataParallel strategy (best for multi-GPU)\n",
    "    max_epochs=NUM_EPOCHS,              # Total number of epochs\n",
    "    callbacks=[checkpoint_callback_full_model, progress_bar],\n",
    "    logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=\"simple-clf-train\"),\n",
    ")\n",
    "\n",
    "test_trainer_1 = pl.Trainer(\n",
    "    accelerator='gpu',\n",
    "    devices=1,  # Use only one GPU\n",
    "    logger = pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=\"simple-clf-test\"),\n",
    "    # Add the callback here so the Trainer can find the 'best' path\n",
    "    callbacks=[checkpoint_callback_full_model],\n",
    "    precision='16-mixed'  # Use mixed precision for testing\n",
    ")\n",
    "\n",
    "# --- Phase 1 Training ---\n",
    "print(f\"--- Starting Training for {NUM_EPOCHS} epochs on train_loader ---\")\n",
    "train_trainer_1.fit(model, train_dataloaders=train_loader)\n",
    "\n",
    "# CRITICAL: Save the path to the best model from this phase\n",
    "path_after_phase1 = checkpoint_callback_full_model.best_model_path\n",
    "print(f\"Best model from Phase 1 saved to: {path_after_phase1}\")\n",
    "\n",
    "# --- Test 1: Evaluate the model from after Phase 1 ---\n",
    "print(f\"\\n--- Testing model from Phase 1 checkpoint: {path_after_phase1} ---\")\n",
    "model.current_test_title = \"ROC Curve after training on DataLoader 1\"\n",
    "model = LitClassifier.load_from_checkpoint(path_after_phase1)  # Load the model from Phase 1\n",
    "model.eval().to('cuda:0')  # Ensure the model is in evaluation mode and on GPU\n",
    "test_trainer_1.test(model, dataloaders=test_loader, ckpt_path=path_after_phase1)\n",
    "results_phase1 = model.last_test_results.copy()\n",
    "results_original_roc = {\"fpr\": results_phase1[\"full_roc\"][\"fpr\"], \"tpr\": results_phase1[\"full_roc\"][\"tpr\"], \"thresholds\": results_phase1[\"full_roc\"][\"thresholds\"], \"name\": \"Original NN data1\", \"auc\": results_phase1[\"auc\"], \"model\": model}\n",
    "\n",
    "# Metrics\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "model.eval() # Set to evaluation mode\n",
    "\n",
    "final_predictions = [] # This will store binary predictions (0s or 1s)\n",
    "true_labels = []\n",
    "\n",
    "print(\"\\n--- Manually Calculating Metrics on Test Set ---\")\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        # Move input data to the same device as the model\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # 1. Get the raw model output (logits) and convert to probabilities\n",
    "        outputs = torch.sigmoid(model(inputs))\n",
    "\n",
    "        # 2. Convert probabilities to binary class predictions (0 or 1) using a 0.5 threshold\n",
    "        preds = (outputs > 0.5).int()\n",
    "\n",
    "        final_predictions.extend(preds.cpu().numpy().flatten())\n",
    "        true_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "# Ensure they are numpy arrays for sklearn\n",
    "true_labels = np.array(true_labels)\n",
    "final_predictions = np.array(final_predictions)\n",
    "\n",
    "# Now, calculate metrics using the correct binary predictions\n",
    "print(\"\\n--- Confusion Matrix ---\")\n",
    "cm = confusion_matrix(true_labels, final_predictions)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "report = classification_report(true_labels, final_predictions, target_names=['Class 0', 'Class 1'], zero_division=0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6c2d0a",
   "metadata": {},
   "source": [
    "### Oversampling ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "226e70dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "# --- Configuration ---\n",
    "EPSILON = 1e-9\n",
    "# EXPECTED_MODES_PER_CLASS, etc. removed\n",
    "# FIXED_TARGET_STD_SYNTHETIC removed\n",
    "\n",
    "# --- Parameter for KDE-like generator ---\n",
    "SIGMA_KDE_PERTURBATION = 0.1 # Adjust as needed\n",
    "\n",
    "# --- This block generates the list of ratios for your experiment ---\n",
    "def generate_ratios(train_data):\n",
    "    # 1. Get original class counts from your train_dataset\n",
    "\n",
    "    # --- Initial Data Analysis ---\n",
    "    counter = Counter(train_data[:, -1])  # Assuming the last column is the class label\n",
    "    Class0_initial = counter.get(0, 0)\n",
    "    Class1_initial = counter.get(1, 0)\n",
    "\n",
    "\n",
    "    class_ratio_low = 0.1   \n",
    "    class_ratio_high = 100.0 \n",
    "    num_points_below = 25 \n",
    "    num_points_above = 25 \n",
    "\n",
    "    if Class1_initial == 0 and Class0_initial == 0:\n",
    "        print(\"ERROR: Both classes have zero samples initially. Cannot proceed.\")\n",
    "        alpha_target_actual_values = [] \n",
    "        current_class_ratio = 1.0\n",
    "    elif Class1_initial == 0:\n",
    "        current_class_ratio = np.inf \n",
    "    else:\n",
    "        current_class_ratio = Class0_initial / Class1_initial\n",
    "\n",
    "    # ... (alpha_target_actual_values generation - same robust version) ...\n",
    "    alpha_target_list = []\n",
    "    if Class0_initial > 0 or Class1_initial > 0: \n",
    "        if current_class_ratio > 0 and not np.isinf(current_class_ratio): \n",
    "            alpha_target_list.append(current_class_ratio)\n",
    "        _safe_class_ratio_low = max(class_ratio_low, EPSILON)\n",
    "        if current_class_ratio > _safe_class_ratio_low and not np.isinf(current_class_ratio): \n",
    "            try:\n",
    "                alpha_b = np.geomspace(_safe_class_ratio_low, current_class_ratio, num_points_below, endpoint=False)\n",
    "                alpha_target_list.extend(alpha_b)\n",
    "            except ValueError: pass\n",
    "        if current_class_ratio < class_ratio_high and current_class_ratio >= 0 and not np.isinf(current_class_ratio): \n",
    "            try:\n",
    "                _start_geom_above = max(current_class_ratio, _safe_class_ratio_low) \n",
    "                if class_ratio_high > _start_geom_above:\n",
    "                    alpha_a = np.geomspace(_start_geom_above, class_ratio_high, num_points_above, endpoint=True)\n",
    "                    if not np.isclose(_start_geom_above, current_class_ratio) and current_class_ratio >=_safe_class_ratio_low and current_class_ratio <= class_ratio_high :\n",
    "                        alpha_target_list.append(current_class_ratio)\n",
    "                    alpha_target_list.extend(alpha_a)\n",
    "                elif np.isclose(class_ratio_high, _start_geom_above):\n",
    "                    alpha_target_list.append(class_ratio_high)\n",
    "            except ValueError: pass\n",
    "        if not alpha_target_list and (Class0_initial > 0 or Class1_initial > 0): \n",
    "            if not np.isinf(current_class_ratio) and current_class_ratio > 0:\n",
    "                alpha_target_list.append(current_class_ratio)\n",
    "            else: \n",
    "                alpha_target_list.extend(np.geomspace(_safe_class_ratio_low, class_ratio_high, num_points_below + num_points_above))\n",
    "        alpha_target_actual_values = np.unique(alpha_target_list)\n",
    "        alpha_target_actual_values = np.sort(alpha_target_actual_values[alpha_target_actual_values >= 0]) \n",
    "        alpha_target_actual_values = alpha_target_actual_values[alpha_target_actual_values >= _safe_class_ratio_low] \n",
    "        alpha_target_actual_values = alpha_target_actual_values[alpha_target_actual_values <= class_ratio_high]\n",
    "        if not alpha_target_actual_values.size and (Class0_initial > 0 or Class1_initial > 0) : \n",
    "            if not np.isinf(current_class_ratio) and current_class_ratio > _safe_class_ratio_low and current_class_ratio < class_ratio_high:\n",
    "                alpha_target_actual_values = np.array([current_class_ratio])\n",
    "            else: \n",
    "                alpha_target_actual_values = np.array([(_safe_class_ratio_low + class_ratio_high)/2.0])\n",
    "\n",
    "\n",
    "    print(f\"INFO: Initial C0={Class0_initial}, C1={Class1_initial}, Ratio(0/1): {current_class_ratio if Class1_initial > 0 else 'N/A'}\")\n",
    "    print(f\"INFO: Target ratios (w values): {alpha_target_actual_values}\")\n",
    "    print(f\"INFO: KDE-like perturbation sigma: {SIGMA_KDE_PERTURBATION}\")\n",
    "    print(f\"INFO: Standard deviation of synthetic samples will NOT be modified after generation.\")\n",
    "\n",
    "    return alpha_target_actual_values, Class0_initial, Class1_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db29e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def oversample_dataset_KDE(Class0_initial, Class1_initial, alpha_target, train_data):\n",
    "    \"\"\"\n",
    "    Oversamples a dataset to a target ratio using a KDE-like method.\n",
    "    This version contains fixes for shape errors when no samples are generated.\n",
    "    \"\"\"\n",
    "    # --- Determine Oversampling Strategy ---\n",
    "    oversampled_class_label_by_strategy = -1\n",
    "    initial_count_of_oversampled_class = -1\n",
    "    final_count_of_oversampled_class = -1\n",
    "\n",
    "    if Class1_initial == 0 and Class0_initial > 0:\n",
    "        current_class_ratio = np.inf\n",
    "    elif Class1_initial == 0 and Class0_initial == 0:\n",
    "        current_class_ratio = 1.0 # Or some other neutral value\n",
    "    else:\n",
    "        current_class_ratio = Class0_initial / Class1_initial\n",
    "\n",
    "    # Decide which class to oversample or if we should do nothing\n",
    "    if abs(alpha_target - current_class_ratio) < EPSILON:\n",
    "        # Ratios are the same, do nothing\n",
    "        initial_count_of_oversampled_class = Class1_initial # Placeholder\n",
    "        final_count_of_oversampled_class = Class1_initial   # Placeholder\n",
    "    elif alpha_target > current_class_ratio:\n",
    "        # Target has more C0 relative to C1 -> Oversample C0\n",
    "        oversampled_class_label_by_strategy = 0\n",
    "        initial_count_of_oversampled_class = Class0_initial\n",
    "        final_count_of_oversampled_class = int(round(Class1_initial * alpha_target))\n",
    "    else: # alpha_target < current_class_ratio\n",
    "        # Target has more C1 relative to C0 -> Oversample C1\n",
    "        oversampled_class_label_by_strategy = 1\n",
    "        initial_count_of_oversampled_class = Class1_initial\n",
    "        final_count_of_oversampled_class = int(round(Class0_initial / alpha_target))\n",
    "\n",
    "    num_synthetic_to_generate = max(0, final_count_of_oversampled_class - initial_count_of_oversampled_class)\n",
    "    print(f\"  INFO: Strategy: Oversample class {oversampled_class_label_by_strategy} from {initial_count_of_oversampled_class} to {final_count_of_oversampled_class} (generating {num_synthetic_to_generate} samples).\")\n",
    "\n",
    "\n",
    "    # --- KDE-like Synthetic Sample Generation ---\n",
    "    if num_synthetic_to_generate > 0:\n",
    "        print(f\"  INFO: Using KDE-like generator. Perturbation sigma: {SIGMA_KDE_PERTURBATION}\")\n",
    "        X_new_synthetic = []\n",
    "        y_new_synthetic = []\n",
    "\n",
    "        indices_class = np.where(train_data[:, -1] == oversampled_class_label_by_strategy)[0]\n",
    "        \n",
    "        if len(indices_class) > 0:\n",
    "            for _ in range(num_synthetic_to_generate):\n",
    "                idx_star = np.random.choice(indices_class)\n",
    "                X_star = train_data[idx_star, :-1]\n",
    "                epsilon_noise = np.random.randn(*X_star.shape)\n",
    "                X_prime = X_star + SIGMA_KDE_PERTURBATION * epsilon_noise\n",
    "                X_new_synthetic.append(X_prime)\n",
    "                y_new_synthetic.append(oversampled_class_label_by_strategy)\n",
    "\n",
    "            X_new_synthetic_arr = np.array(X_new_synthetic)\n",
    "            y_new_synthetic_arr = np.array(y_new_synthetic)\n",
    "            X_resampled = np.vstack((train_data[:, :-1], X_new_synthetic_arr))\n",
    "            y_resampled = np.concatenate((train_data[:, -1], y_new_synthetic_arr))\n",
    "            resampled_counts = Counter(y_resampled)\n",
    "            print(f\"  INFO: KDE-like generation complete. New C0={resampled_counts.get(0,0)}, C1={resampled_counts.get(1,0)}\")\n",
    "        else:\n",
    "             # This can happen if the class to oversample has 0 members\n",
    "            print(\"  WARNING: Cannot generate samples for a class with 0 members. Returning original data.\")\n",
    "            X_resampled = train_data[:, :-1]\n",
    "            y_resampled = train_data[:, -1]\n",
    "\n",
    "    else: # num_synthetic_to_generate is 0\n",
    "        print(\"  INFO: No synthetic samples were required or generated.\")\n",
    "        # --- THIS IS THE CRITICAL FIX ---\n",
    "        # Correctly slice the original data instead of copying the whole array\n",
    "        X_resampled = train_data[:, :-1]\n",
    "        y_resampled = train_data[:, -1]\n",
    "        # ----------------------------\n",
    "\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19d1bd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 1/4 ---\n",
      "INFO: Initial C0=372, C1=378, Ratio(0/1): 0.9841269841269841\n",
      "INFO: Target ratios (w values): [  0.1          0.10957767   0.12007265   0.13157281   0.14417441\n",
      "   0.15798295   0.17311403   0.18969432   0.2078626    0.22777099\n",
      "   0.24958614   0.27349066   0.29968468   0.32838748   0.35983934\n",
      "   0.39430355   0.43206862   0.47345071   0.51879624   0.56848481\n",
      "   0.62293239   0.68259477   0.74797142   0.81960962   0.8981091\n",
      "   0.98412698   1.19309221   1.44642819   1.75355644   2.12589895\n",
      "   2.57730304   3.1245563    3.78801094   4.59234063   5.56745817\n",
      "   6.74962791   8.1828144    9.92031746  12.02675431  14.58046277\n",
      "  17.67641452  21.42974714  25.98004601  31.49653545  38.18437216\n",
      "  46.29227489  56.12177425  68.03842656  82.48540875 100.        ]\n",
      "INFO: KDE-like perturbation sigma: 0.1\n",
      "INFO: Standard deviation of synthetic samples will NOT be modified after generation.\n",
      "\n",
      "--- Processing target ratio w (1/50): 0.1000 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 3720 (generating 3342 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=372, C1=3720\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e58cf1b5f54e44bff2a4d14ad528f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac02b220ee154d898f7281c577b22226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4880\n",
      "AUC: 0.5607\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7624002695083618\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (2/50): 0.1096 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 3395 (generating 3017 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=372, C1=3395\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fcc09a57d7a4fe0a20a334ee8f1dfa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a7492c10a24be9962574062ff67f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4880\n",
      "AUC: 0.6003\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9550947546958923\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (3/50): 0.1201 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 3098 (generating 2720 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=372, C1=3098\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e3ab9ebbc949688e0e9e65e6f8ba3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb76ac719c04310885f2c59da1042c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4880\n",
      "AUC: 0.6314\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0474355220794678\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (4/50): 0.1316 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 2827 (generating 2449 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=372, C1=2827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (49) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fee57cacc94445db63bf00cd5dd559f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15eef1787d974165a8225ef0ef600999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4880\n",
      "AUC: 0.7143\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9868143200874329\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (5/50): 0.1442 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 2580 (generating 2202 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=372, C1=2580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (46) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb7c23239f54b75b4a83aaf5298cec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8415704c05b643179bcc7dd10049b07f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4880\n",
      "AUC: 0.8447\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8949532508850098\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (6/50): 0.1580 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 2355 (generating 1977 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=372, C1=2355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (42) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea38659b38c149dd975f0746a0e1401d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7cab6a13db44372be58f3dd90648ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4960\n",
      "AUC: 0.9381\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7903444766998291\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (7/50): 0.1731 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 2149 (generating 1771 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=372, C1=2149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (39) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eeccfb581674611a6ba84cf772c20a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8e267e5c3e4ea1a3b7d6a0ffabdfa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5000\n",
      "AUC: 0.9626\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7185837030410767\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (8/50): 0.1897 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 1961 (generating 1583 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=372, C1=1961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (36) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a356f2cb4a74c74a859944abcf8801b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08aa11a06384f3ab30af4df65ee44d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5080\n",
      "AUC: 0.9688\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6478472948074341\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (9/50): 0.2079 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 1790 (generating 1412 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=372, C1=1790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (33) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6f5709242340a8a2edcdde45495a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0805acf86ffd4b46a44f4e76dbb25bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5480\n",
      "AUC: 0.9704\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5824982523918152\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (10/50): 0.2278 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 1633 (generating 1255 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=372, C1=1633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (31) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ecce27b0464be1903db217f75abfa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec2f685112d4e7db01aabfd230ebcb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6520\n",
      "AUC: 0.9694\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5358381867408752\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (11/50): 0.2496 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 1490 (generating 1112 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=372, C1=1490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (29) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a1fa3070c64b5ca50a89f110715a10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837c8c1ca3df4629a21e65af851a6e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7080\n",
      "AUC: 0.9694\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.497673362493515\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (12/50): 0.2735 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 1360 (generating 982 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=372, C1=1360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (27) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5431501e69ba4481904b25197634d92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1cf81e126147c0aaedb6b31cfb60e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.9699\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4637703597545624\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (13/50): 0.2997 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 1241 (generating 863 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=372, C1=1241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (25) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60a1770e79445b8868fffc003785f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225ce1542fad4a6fb8701732a84b7c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7840\n",
      "AUC: 0.9688\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.426698237657547\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (14/50): 0.3284 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 1133 (generating 755 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=372, C1=1133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (23) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa505d7364b4b46a078cc2445787403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a212e6375b0f461e92b0b36d2c5f00fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8080\n",
      "AUC: 0.9700\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.402442991733551\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (15/50): 0.3598 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 1034 (generating 656 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=372, C1=1034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f89132b474f424fb25dad30d7d2fe59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a87f5552c04bdd9e62235df562e43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8200\n",
      "AUC: 0.9700\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3808201551437378\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (16/50): 0.3943 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 943 (generating 565 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=372, C1=943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (20) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2475520edf3349cfbf962bef4a5d4072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1beabc63965f4859b00540eeb28ed956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8360\n",
      "AUC: 0.9704\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.36241376399993896\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (17/50): 0.4321 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 861 (generating 483 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=372, C1=861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (19) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d846e015b322432eb91615f1404227b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229e77d1ed714ada90c0a0d392aecec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8680\n",
      "AUC: 0.9704\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3455115854740143\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (18/50): 0.4735 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 786 (generating 408 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=372, C1=786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (18) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d991b0d3c274059ab91d8dd0d036f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063264c5e1944b2d88ccd5d69be35d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8720\n",
      "AUC: 0.9711\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.32946300506591797\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (19/50): 0.5188 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 717 (generating 339 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=372, C1=717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (17) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62865cabb22d48029a621610c8cccdd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049171d2bc0642d5b0387b503d26e667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8760\n",
      "AUC: 0.9718\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3158637583255768\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (20/50): 0.5685 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 654 (generating 276 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=372, C1=654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (16) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6c8a4da85a4bb69a7d60f52601c350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361ec51077f04821a57faccacfc59390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8920\n",
      "AUC: 0.9720\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3003257215023041\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (21/50): 0.6229 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 597 (generating 219 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=372, C1=597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "311b34629c154b8193714993e231df09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dfcaaf113ba4edfbfb2ffb5f4e4a33b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8920\n",
      "AUC: 0.9734\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2913019359111786\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (22/50): 0.6826 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 545 (generating 167 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=372, C1=545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54add981276e45a180133a81578f124d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c54408cff74852b011569c4dd82ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9040\n",
      "AUC: 0.9733\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.28025519847869873\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (23/50): 0.7480 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 497 (generating 119 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=372, C1=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95886d2924740d3ae7054914f707475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6919f83564446898b4634307076f584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9080\n",
      "AUC: 0.9737\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.270548939704895\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (24/50): 0.8196 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 454 (generating 76 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=372, C1=454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e25838e100847e3b10aa9dbbc595c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d35d79f24094197be35af8e555f052c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9080\n",
      "AUC: 0.9742\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.26392027735710144\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (25/50): 0.8981 ---\n",
      "  INFO: Strategy: Oversample class 1 from 378 to 414 (generating 36 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=372, C1=414\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e8f8e1032f44eaae9f140d39aef7cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bdc3dbbce1e4877a6d3950b88fb4b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9040\n",
      "AUC: 0.9747\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2574273347854614\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (26/50): 0.9841 ---\n",
      "  INFO: Strategy: Oversample class -1 from 378 to 378 (generating 0 samples).\n",
      "  INFO: No synthetic samples were required or generated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cac08750fa40cf8ed944c2fb2b169d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbbcc5bbcc6a420fac5fdabfb073d536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9080\n",
      "AUC: 0.9754\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2519330680370331\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (27/50): 1.1931 ---\n",
      "  INFO: Strategy: Oversample class 0 from 372 to 451 (generating 79 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=451, C1=378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2807fc13419f43a8ae6bb064ccae2bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a97c5824a84a7db0293fede5f9ea76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9160\n",
      "AUC: 0.9761\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.24604958295822144\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (28/50): 1.4464 ---\n",
      "  INFO: Strategy: Oversample class 0 from 372 to 547 (generating 175 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=547, C1=378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8cce7e8b6754e42b763ba2777fac850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84fe0947be5842099058beb66eb98990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9160\n",
      "AUC: 0.9768\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2401999533176422\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (29/50): 1.7536 ---\n",
      "  INFO: Strategy: Oversample class 0 from 372 to 663 (generating 291 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=663, C1=378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a6ccb5c9ca4bd7b13629c6defcd423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d676925fce44ce9765efc78b576ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9200\n",
      "AUC: 0.9772\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.23537470400333405\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (30/50): 2.1259 ---\n",
      "  INFO: Strategy: Oversample class 0 from 372 to 804 (generating 432 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=804, C1=378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04997df008ef462a88bf60e11242d188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b228889b304598ac89aba209958c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9200\n",
      "AUC: 0.9783\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.23309023678302765\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (31/50): 2.5773 ---\n",
      "  INFO: Strategy: Oversample class 0 from 372 to 974 (generating 602 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=974, C1=378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4279d98fad59439bb2314903fd187f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1095b00f8e44c1b9dfe20a0ce1c37a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9160\n",
      "AUC: 0.9792\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.23262135684490204\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (32/50): 3.1246 ---\n",
      "  INFO: Strategy: Oversample class 0 from 372 to 1181 (generating 809 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=1181, C1=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75172295822c4017ac8e888f94ef3a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe5c7897bec4357a4a80b64a63ccace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9040\n",
      "AUC: 0.9806\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.23105758428573608\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (33/50): 3.7880 ---\n",
      "  INFO: Strategy: Oversample class 0 from 372 to 1432 (generating 1060 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=1432, C1=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (28) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f739e04c4674aabbe35dfa747b257f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7efd0ec67314e7f931b5f2e0d1ec0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9160\n",
      "AUC: 0.9810\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2377723753452301\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (34/50): 4.5923 ---\n",
      "  INFO: Strategy: Oversample class 0 from 372 to 1736 (generating 1364 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=1736, C1=378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e4f7ecfa5b4314831a23f6b5eaf676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2884c9c306fa4efab38ea24033083551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9040\n",
      "AUC: 0.9821\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.24667666852474213\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (35/50): 5.5675 ---\n",
      "  INFO: Strategy: Oversample class 0 from 372 to 2104 (generating 1732 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=2104, C1=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (38) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ccc39f71384ef9a3fef362f74df0b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b299c0d49b38446fb05537da75b7632b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9040\n",
      "AUC: 0.9843\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2416703850030899\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (36/50): 6.7496 ---\n",
      "  INFO: Strategy: Oversample class 0 from 372 to 2551 (generating 2179 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=2551, C1=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (45) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc17f13f2a104079b6d8bf47758c55ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625c06fec8ee44d4ae44f8fee6eaac52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9000\n",
      "AUC: 0.9851\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.24910351634025574\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (37/50): 8.1828 ---\n",
      "  INFO: Strategy: Oversample class 0 from 372 to 3093 (generating 2721 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=3093, C1=378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b54217d370b48e7974f7847b294db03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300dd736d44740629e1cc808862a02ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9120\n",
      "AUC: 0.9871\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.24009710550308228\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (38/50): 9.9203 ---\n",
      "  INFO: Strategy: Oversample class 0 from 372 to 3750 (generating 3378 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=3750, C1=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b99df2751542a69a5c780babe4a94c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe6e843cd2d47d8b4c425d4721707ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8920\n",
      "AUC: 0.9879\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2529444396495819\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (39/50): 12.0268 ---\n",
      "  INFO: Strategy: Oversample class 0 from 372 to 4546 (generating 4174 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=4546, C1=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e1b5e8d45040fab04339703b9c39ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884e490bec564500bd5fb892b81af043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8840\n",
      "AUC: 0.9889\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.26145148277282715\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (40/50): 14.5805 ---\n",
      "  INFO: Strategy: Oversample class 0 from 372 to 5511 (generating 5139 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=5511, C1=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3533f3061564428d8d541a2050ffe89b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d30ef875ec4894a966e7f8d676c617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8800\n",
      "AUC: 0.9898\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.26153942942619324\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (41/50): 17.6764 ---\n",
      "  INFO: Strategy: Oversample class 0 from 372 to 6682 (generating 6310 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=6682, C1=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a22b0b83ee44f5929a96fa5c7337ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28abdb242449497dbf86e8161a732e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8800\n",
      "AUC: 0.9905\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2600703239440918\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (42/50): 21.4297 ---\n",
      "  INFO: Strategy: Oversample class 0 from 372 to 8100 (generating 7728 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=8100, C1=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc256011cb246a0aca27cad32fc399b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8d199108e4482bac22c090dbe90c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8800\n",
      "AUC: 0.9910\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.26476579904556274\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (43/50): 25.9800 ---\n",
      "  INFO: Strategy: Oversample class 0 from 372 to 9820 (generating 9448 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=9820, C1=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa9aa64e973440c9dca96f7dfeadc51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be0f819bc0148879a844461bfbfc132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8640\n",
      "AUC: 0.9914\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2866976857185364\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (44/50): 31.4965 ---\n",
      "  INFO: Strategy: Oversample class 0 from 372 to 11906 (generating 11534 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=11906, C1=378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865ac79812ca400fa1017db585e10c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00bcd5bab51048939ab7057b7a8c3d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8520\n",
      "AUC: 0.9917\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.30151495337486267\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (45/50): 38.1844 ---\n",
      "  INFO: Strategy: Oversample class 0 from 372 to 14434 (generating 14062 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=14434, C1=378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb48e2479aa4011b433750017000ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf8d845e1714621b8c294ebe5a383b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8680\n",
      "AUC: 0.9924\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.28516387939453125\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (46/50): 46.2923 ---\n",
      "  INFO: Strategy: Oversample class 0 from 372 to 17498 (generating 17126 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=17498, C1=378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "197821b9306c4d309855fe6a765cc784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ab5c9dc5f64b889f232e69f517232d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8560\n",
      "AUC: 0.9924\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.30698031187057495\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (47/50): 56.1218 ---\n",
      "  INFO: Strategy: Oversample class 0 from 372 to 21214 (generating 20842 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=21214, C1=378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00324a8486e24ad4a54ea4fd12df3cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6f187d3cc441fcbd7a22a0791a0b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8680\n",
      "AUC: 0.9931\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.29416871070861816\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (48/50): 68.0384 ---\n",
      "  INFO: Strategy: Oversample class 0 from 372 to 25719 (generating 25347 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=25719, C1=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a166530544234ae09ff4190d7b8160d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bda0cdcca4647008342b7e0cbf083bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8560\n",
      "AUC: 0.9932\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.30849674344062805\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (49/50): 82.4854 ---\n",
      "  INFO: Strategy: Oversample class 0 from 372 to 31179 (generating 30807 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=31179, C1=378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9732142c4640b29a0e56dd4aaa5b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa156c8f964b4136b9a5de772a1c6fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8640\n",
      "AUC: 0.9935\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.30730700492858887\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (50/50): 100.0000 ---\n",
      "  INFO: Strategy: Oversample class 0 from 372 to 37800 (generating 37428 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=37800, C1=378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73da53ad61d84f5ebc369016a07aa0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0165b3dddc864ad39b027f12301634e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8640\n",
      "AUC: 0.9932\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3251645565032959\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 2/4 ---\n",
      "INFO: Initial C0=382, C1=368, Ratio(0/1): 1.0380434782608696\n",
      "INFO: Target ratios (w values): [  0.1          0.1098117    0.1205861    0.13241765   0.14541007\n",
      "   0.15967727   0.17534433   0.19254859   0.21144089   0.23218684\n",
      "   0.25496832   0.27998505   0.30745635   0.33762305   0.37074961\n",
      "   0.40712646   0.44707249   0.49093791   0.53910727   0.59200287\n",
      "   0.65008843   0.71387317   0.78391627   0.8608318    0.94529405\n",
      "   1.03804348   1.25566338   1.51890606   1.83733607   2.22252312\n",
      "   2.68846243   3.25208328   3.93386402   4.75857621   5.75618463\n",
      "   6.96293596   8.42267584  10.18844187  12.32439071  14.90812905\n",
      "  18.03353342  21.81416103  26.38737569  31.91933877  38.61104641\n",
      "  46.70563246  56.49720238  68.34151919  82.66892959 100.        ]\n",
      "INFO: KDE-like perturbation sigma: 0.1\n",
      "INFO: Standard deviation of synthetic samples will NOT be modified after generation.\n",
      "\n",
      "--- Processing target ratio w (1/50): 0.1000 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 3820 (generating 3452 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=382, C1=3820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb209e7099c4630af184edd51532a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee7c105ce66343a9a78ba9ac47412fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5280\n",
      "AUC: 0.4978\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8184681534767151\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (2/50): 0.1098 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 3479 (generating 3111 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=382, C1=3479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6fc581ffff240b3969062f406549119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3288b27be949b7ab51b4f701eb0f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5280\n",
      "AUC: 0.5092\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0466934442520142\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (3/50): 0.1206 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 3168 (generating 2800 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=382, C1=3168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7181e98f714fdd97b79e6ace26255c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2370f83b75a0405ca245e577f18572fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5280\n",
      "AUC: 0.5316\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0682384967803955\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (4/50): 0.1324 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 2885 (generating 2517 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=382, C1=2885\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127d3cdbd313460f95eb5c17c7c38a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933d19b45b224c229ba997cf9943d26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5280\n",
      "AUC: 0.6148\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9708600044250488\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (5/50): 0.1454 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 2627 (generating 2259 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=382, C1=2627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (47) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95484262ea39419394a977f1cf2e4d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5c4e75d43444a2bd1243a4297d12c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.7885\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8540332317352295\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (6/50): 0.1597 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 2392 (generating 2024 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=382, C1=2392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (43) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27a19ef22ab4434acbf7accb820d2ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c5b5d505964c0eb7a653dd1b809647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.9255\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.748319685459137\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (7/50): 0.1753 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 2179 (generating 1811 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=382, C1=2179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (40) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8a992954c240b384a62f0f5fdc3147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab1170ed4ad4299b00347e17f24a04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5400\n",
      "AUC: 0.9689\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6662014126777649\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (8/50): 0.1925 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 1984 (generating 1616 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=382, C1=1984\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c10d56228bd4c5091de18f35b78d098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d06bd4615b804c4a8c57dcb066646689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5480\n",
      "AUC: 0.9846\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5943437814712524\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (9/50): 0.2114 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 1807 (generating 1439 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=382, C1=1807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (34) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3874ec3175934668b8fa06a6b519a7c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5b3d11c9cb4f07a3f8ea0bc8bf37c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5840\n",
      "AUC: 0.9882\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.522169828414917\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (10/50): 0.2322 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 1645 (generating 1277 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=382, C1=1645\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb7a45b158cf4b05bb96a4c75348daba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd9e01187681415597585f583449a7be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5920\n",
      "AUC: 0.9882\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.48543375730514526\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (11/50): 0.2550 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 1498 (generating 1130 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=382, C1=1498\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433c352cd6064167a287868585483bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e5bd1510964adaa8cc38ac223dae18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7440\n",
      "AUC: 0.9879\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.42993712425231934\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (12/50): 0.2800 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 1364 (generating 996 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=382, C1=1364\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372a5922644c4036a2b955115d6fc047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57c059249fa5460caba133a8e10ca231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8040\n",
      "AUC: 0.9882\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3942520022392273\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (13/50): 0.3075 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 1242 (generating 874 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=382, C1=1242\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc06f696b5d4a1e8236e0e3c55ada09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791c3d532a26423cac3c8b0c5296bf3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8440\n",
      "AUC: 0.9881\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3680793046951294\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (14/50): 0.3376 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 1131 (generating 763 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=382, C1=1131\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07fc06687dd94088857b37daa191a971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4203105cf540a9a89ce1c60f9c6dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8760\n",
      "AUC: 0.9879\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3402573764324188\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (15/50): 0.3707 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 1030 (generating 662 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=382, C1=1030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (22) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c58b0f6b58d64c279a3f1babf6ba79d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775279a80db044b8af25fd6a0f076deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8960\n",
      "AUC: 0.9880\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3181328773498535\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (16/50): 0.4071 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 938 (generating 570 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=382, C1=938\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1450fcab39fe4a6b91937f46fb86ecf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950b4ac0b28e4375b0e4651cd7712822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9040\n",
      "AUC: 0.9880\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.30095022916793823\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (17/50): 0.4471 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 854 (generating 486 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=382, C1=854\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcbb928cd17e4a72883b12b7028c78d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef19e57ec2af411b8156a1ab0877baa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9120\n",
      "AUC: 0.9883\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.28917109966278076\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (18/50): 0.4909 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 778 (generating 410 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=382, C1=778\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb79867360364da8be92b93586d62225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92dbdebeb1ec4b08b1878b3db020b767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9320\n",
      "AUC: 0.9884\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.27217844128608704\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (19/50): 0.5391 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 709 (generating 341 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=382, C1=709\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a8a2c5b7fd4ab7a6c3d48a5a724847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5045d863119f4c1897c38027a9b0aa29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9360\n",
      "AUC: 0.9881\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2583162486553192\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (20/50): 0.5920 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 645 (generating 277 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=382, C1=645\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940b5d81f351453fb2a1e01a8ebf7d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54767dc551c0461092425384d2adde94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9440\n",
      "AUC: 0.9884\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.24853749573230743\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (21/50): 0.6501 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 588 (generating 220 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=382, C1=588\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d604cd284d45ecbdb24c9648416d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0655ee69f8c04c3889cc1120c6adcbfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9440\n",
      "AUC: 0.9884\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.24088063836097717\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (22/50): 0.7139 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 535 (generating 167 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=382, C1=535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb618cda37f54832a37cbf55279757f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed24d8b19eb044f5aa4889910d3f76dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9320\n",
      "AUC: 0.9887\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.23273038864135742\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (23/50): 0.7839 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 487 (generating 119 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=382, C1=487\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e561a47cf8c40e9a80a33a79d711c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175193deeed2421fa70d82442a71f99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9440\n",
      "AUC: 0.9893\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.22731854021549225\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (24/50): 0.8608 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 444 (generating 76 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=382, C1=444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f219e0de9e5149a69dc501ef5201613b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce79297cbd3341269d38601b631e7913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9400\n",
      "AUC: 0.9890\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.22213509678840637\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (25/50): 0.9453 ---\n",
      "  INFO: Strategy: Oversample class 1 from 368 to 404 (generating 36 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=382, C1=404\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23408dba97044ff5bfaef07c0c842ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e58e9d8055574e06974e5923c4f15476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9520\n",
      "AUC: 0.9891\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.21852454543113708\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (26/50): 1.0380 ---\n",
      "  INFO: Strategy: Oversample class -1 from 368 to 368 (generating 0 samples).\n",
      "  INFO: No synthetic samples were required or generated.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15f17f600614825a114d0346bf76183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1713aab6f53a48f0a2e9bf038390b592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9480\n",
      "AUC: 0.9890\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.21648962795734406\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (27/50): 1.2557 ---\n",
      "  INFO: Strategy: Oversample class 0 from 382 to 462 (generating 80 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=462, C1=368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a2000af37d40ceba62b09c86a59a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9b7b53b568428e8df1a1ee1c54505a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9440\n",
      "AUC: 0.9891\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2170329988002777\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (28/50): 1.5189 ---\n",
      "  INFO: Strategy: Oversample class 0 from 382 to 559 (generating 177 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=559, C1=368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5c38f4b69941a69c94a478e10a4684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b57467ed8bf340c7851e4f0e47a8a13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9400\n",
      "AUC: 0.9895\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2145720273256302\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (29/50): 1.8373 ---\n",
      "  INFO: Strategy: Oversample class 0 from 382 to 676 (generating 294 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=676, C1=368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b03fd78a93a40da878569dcad5c6d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b247e74154ea4bcd84f9b21b7638c9a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9440\n",
      "AUC: 0.9897\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.21780060231685638\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (30/50): 2.2225 ---\n",
      "  INFO: Strategy: Oversample class 0 from 382 to 818 (generating 436 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=818, C1=368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82695275364c4658aa32784498cb8d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ff7dc5eb0e4481839d5f37188190f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9240\n",
      "AUC: 0.9899\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.22466032207012177\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (31/50): 2.6885 ---\n",
      "  INFO: Strategy: Oversample class 0 from 382 to 989 (generating 607 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=989, C1=368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ccdc067ca04dc9aeb4fa06415672a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f071ef09ad4e8ca9f2694b7177ec1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9200\n",
      "AUC: 0.9904\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.22926126420497894\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (32/50): 3.2521 ---\n",
      "  INFO: Strategy: Oversample class 0 from 382 to 1197 (generating 815 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=1197, C1=368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa0ce953ca8a411d9f2cfb10d1153327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e952671f2b34a2abf9867e1c1c08994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9120\n",
      "AUC: 0.9911\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.23591375350952148\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (33/50): 3.9339 ---\n",
      "  INFO: Strategy: Oversample class 0 from 382 to 1448 (generating 1066 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=1448, C1=368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a79986c82942d485548697e09c29a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c1247e024d4ab4bf21aaecb63e803c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9000\n",
      "AUC: 0.9906\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2562273144721985\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (34/50): 4.7586 ---\n",
      "  INFO: Strategy: Oversample class 0 from 382 to 1751 (generating 1369 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=1751, C1=368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1665c27f55134e509d77c51edd47556f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c9d55479b9491aa67754098a1a132f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8960\n",
      "AUC: 0.9917\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2624960243701935\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (35/50): 5.7562 ---\n",
      "  INFO: Strategy: Oversample class 0 from 382 to 2118 (generating 1736 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=2118, C1=368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e913ee9689624dfaacab6a2e7cf938ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f33d581cbca42368560639ee0ddc519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8920\n",
      "AUC: 0.9925\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2635040581226349\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (36/50): 6.9629 ---\n",
      "  INFO: Strategy: Oversample class 0 from 382 to 2562 (generating 2180 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=2562, C1=368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d17c79ff4aa423685dc7b0f22c42d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19228c0a05a47ddae1c96262bfd4738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8760\n",
      "AUC: 0.9927\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.27975964546203613\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (37/50): 8.4227 ---\n",
      "  INFO: Strategy: Oversample class 0 from 382 to 3100 (generating 2718 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=3100, C1=368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b22e55a36b4d92b09f649dd8ab9ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d7ace225a144b89656591dbe6c025b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8680\n",
      "AUC: 0.9936\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.28184008598327637\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (38/50): 10.1884 ---\n",
      "  INFO: Strategy: Oversample class 0 from 382 to 3749 (generating 3367 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=3749, C1=368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09bbe822992d4f188d91b58787c912f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8453ba48aea343f29f7ad793865f50c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8560\n",
      "AUC: 0.9940\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.29287487268447876\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (39/50): 12.3244 ---\n",
      "  INFO: Strategy: Oversample class 0 from 382 to 4535 (generating 4153 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=4535, C1=368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a063a8248aa442296936c5b061fd268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f620325c4bc4831b0f7175d38cf01dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8440\n",
      "AUC: 0.9943\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3112942576408386\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (40/50): 14.9081 ---\n",
      "  INFO: Strategy: Oversample class 0 from 382 to 5486 (generating 5104 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=5486, C1=368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6121dc0fda4c5cb32d70a13f75ce58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b62c9b6911b45a1a7a22cd5acdc46b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8600\n",
      "AUC: 0.9945\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.29250505566596985\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (41/50): 18.0335 ---\n",
      "  INFO: Strategy: Oversample class 0 from 382 to 6636 (generating 6254 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=6636, C1=368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64fa14d4734a4809aae2d89fa66b42bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1944dd23e41e4043b9ac99cbbd7b391a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8640\n",
      "AUC: 0.9946\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3126000761985779\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (42/50): 21.8142 ---\n",
      "  INFO: Strategy: Oversample class 0 from 382 to 8028 (generating 7646 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=8028, C1=368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb27c4412b641d19f1d6712979c0833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a7565df9064d9896fa3c55849833e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8600\n",
      "AUC: 0.9947\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.321266233921051\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (43/50): 26.3874 ---\n",
      "  INFO: Strategy: Oversample class 0 from 382 to 9711 (generating 9329 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=9711, C1=368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d3d1a277fd447f811bee72117bb5a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a506bc01384f5085fd416e75d267bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8360\n",
      "AUC: 0.9949\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3660370707511902\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (44/50): 31.9193 ---\n",
      "  INFO: Strategy: Oversample class 0 from 382 to 11746 (generating 11364 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=11746, C1=368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d850f4508a69492a94ccf10055582e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7587bc1c42f543fcbdcb186ea9049989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8600\n",
      "AUC: 0.9944\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.34533143043518066\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (45/50): 38.6110 ---\n",
      "  INFO: Strategy: Oversample class 0 from 382 to 14209 (generating 13827 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=14209, C1=368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beeac5309a7746e79e3c365284338e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3580ef27e041f281326895b74281e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8520\n",
      "AUC: 0.9946\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3669152855873108\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (46/50): 46.7056 ---\n",
      "  INFO: Strategy: Oversample class 0 from 382 to 17188 (generating 16806 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=17188, C1=368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f073f213a56448b78123b14c6f22dfad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95355d366ba4e52aac5cd076c6c13c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8560\n",
      "AUC: 0.9947\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.37192440032958984\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (47/50): 56.4972 ---\n",
      "  INFO: Strategy: Oversample class 0 from 382 to 20791 (generating 20409 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=20791, C1=368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a24e5eed1c84f778942dfb40eedacfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c318a3c65ed44849041efe999ebe7f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8480\n",
      "AUC: 0.9950\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4011308550834656\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (48/50): 68.3415 ---\n",
      "  INFO: Strategy: Oversample class 0 from 382 to 25150 (generating 24768 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=25150, C1=368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba3f263d9914426b92a9850ea0a4a48a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff7a95e66db4b68a834031298eaa1c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8520\n",
      "AUC: 0.9949\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.41934534907341003\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (49/50): 82.6689 ---\n",
      "  INFO: Strategy: Oversample class 0 from 382 to 30422 (generating 30040 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=30422, C1=368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "334deaa524d44fa2bc9dca3a377c1678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ca2de838cf46da8dec8d86903e4b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8480\n",
      "AUC: 0.9951\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4312947392463684\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (50/50): 100.0000 ---\n",
      "  INFO: Strategy: Oversample class 0 from 382 to 36800 (generating 36418 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=36800, C1=368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4e3a79a8e243c5b79ada8d03f2d691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1747647b744b0fab0f27d779d91aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8600\n",
      "AUC: 0.9948\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4154323637485504\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 3/4 ---\n",
      "INFO: Initial C0=380, C1=370, Ratio(0/1): 1.027027027027027\n",
      "INFO: Target ratios (w values): [  0.1          0.10976485   0.12048322   0.13224822   0.14516205\n",
      "   0.1593369    0.17489591   0.19197423   0.21072021   0.23129672\n",
      "   0.25388249   0.27867373   0.30588579   0.33575507   0.36854103\n",
      "   0.4045285    0.44403009   0.48738894   0.53498173   0.58722187\n",
      "   0.64456319   0.70750379   0.77659045   0.85242332   0.93566115\n",
      "   1.02702703   1.24288981   1.50412311   1.82026299   2.20284984\n",
      "   2.66584963   3.22616373   3.90424587   4.7248488    5.71792784\n",
      "   6.91973441   8.3741393   10.13423419  12.26426968  14.84200067\n",
      "  17.9615248   21.73671732  26.30538805  31.83431198  38.52531722\n",
      "  46.62265256  56.42190353  68.28078248  82.63218651 100.        ]\n",
      "INFO: KDE-like perturbation sigma: 0.1\n",
      "INFO: Standard deviation of synthetic samples will NOT be modified after generation.\n",
      "\n",
      "--- Processing target ratio w (1/50): 0.1000 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 3800 (generating 3430 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=380, C1=3800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c1b2f8201da4ad2a5050b9496c340de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c00cacc745f47d592978f64d2454ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5200\n",
      "AUC: 0.6190\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7108163833618164\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (2/50): 0.1098 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 3462 (generating 3092 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=380, C1=3462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "760fbb737a64415d9841973adb96793e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8812b4cbc2e34c7cb5f4eb5f0092afa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5200\n",
      "AUC: 0.6385\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8747847676277161\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (3/50): 0.1205 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 3154 (generating 2784 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=380, C1=3154\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e4deaed4264387b0cf6465842c1563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8da492c78804752be6ddc9d4c96b067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5200\n",
      "AUC: 0.7381\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9249715805053711\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (4/50): 0.1322 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 2873 (generating 2503 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=380, C1=2873\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "632d149fcb6e440b86642a49141e9c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709c7bb79f0041f5a2ed461cdfe7760d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5200\n",
      "AUC: 0.8881\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8332862257957458\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (5/50): 0.1452 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 2618 (generating 2248 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=380, C1=2618\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb7c8349f7184574bdf3a3ed6673ba07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a09bb48642641edb141a3007ec772a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5200\n",
      "AUC: 0.9528\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7402395009994507\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (6/50): 0.1593 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 2385 (generating 2015 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=380, C1=2385\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f8e211e0ed04c8cba876ddc54042b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784fb184f4f94b60badcafc78711b692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5200\n",
      "AUC: 0.9640\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6521097421646118\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (7/50): 0.1749 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 2173 (generating 1803 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=380, C1=2173\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7d7b88922d0454987f8026ff8293ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3767b64cf44fcb92bee7970d6e9a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5200\n",
      "AUC: 0.9653\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5820795893669128\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (8/50): 0.1920 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 1979 (generating 1609 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=380, C1=1979\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f9975d8ae947cdbe9416d72e4427e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb4cdf25cd9469190f892b481423046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6040\n",
      "AUC: 0.9649\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5331018567085266\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (9/50): 0.2107 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 1803 (generating 1433 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=380, C1=1803\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961f32853eb64904b5de7107164c38d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6bade625f6a4916a731f916975b0290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6640\n",
      "AUC: 0.9654\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.498065710067749\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (10/50): 0.2313 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 1643 (generating 1273 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=380, C1=1643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c77ddb17e74a0e970d59cc74bc8886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa9002a4ae64a4d81b53e350183c21f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7080\n",
      "AUC: 0.9653\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46399232745170593\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (11/50): 0.2539 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 1497 (generating 1127 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=380, C1=1497\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab204db78a864d5381fc8d86ea8b0475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3eec86ad43847b8a99a01ddbb8c4cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7760\n",
      "AUC: 0.9655\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4339248538017273\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (12/50): 0.2787 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 1364 (generating 994 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=380, C1=1364\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b643963fc94469daf7f7cd9d5890484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4196778f4142403ca936154cc3962451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8280\n",
      "AUC: 0.9654\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.40726739168167114\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (13/50): 0.3059 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 1242 (generating 872 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=380, C1=1242\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01eb08e9c93f4c72ae2c7923b6ace31c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe142a867624d559608e3118d3bbdec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8440\n",
      "AUC: 0.9666\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3883538842201233\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (14/50): 0.3358 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 1132 (generating 762 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=380, C1=1132\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d4e4f416134ebaa234517473868131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf84b3271ae54133b0c2a2dcdcfa2f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8480\n",
      "AUC: 0.9674\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.36783191561698914\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (15/50): 0.3685 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 1031 (generating 661 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=380, C1=1031\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a601eb7e85c847cf9a02c20a8d64da2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9693842bad4ae6bb4be8d9fe142cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8600\n",
      "AUC: 0.9675\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.34677621722221375\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (16/50): 0.4045 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 939 (generating 569 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=380, C1=939\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea9201552e048ceafd7a2fad8b6afce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8297f6b412640cf986b5ccd6ca915e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8720\n",
      "AUC: 0.9682\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.32865288853645325\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (17/50): 0.4440 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 856 (generating 486 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=380, C1=856\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e509d1a5e96497bacb309100f0b5a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8a44ecf8314371ae2ca9c7b729522e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8760\n",
      "AUC: 0.9692\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3203476369380951\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (18/50): 0.4874 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 780 (generating 410 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=380, C1=780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb151a051464ee58b89efede0508ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b00e5712d8314c0794a9f50e87c53f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8800\n",
      "AUC: 0.9698\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3037194013595581\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (19/50): 0.5350 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 710 (generating 340 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=380, C1=710\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06bfde62a73f40f195eab4159bae606c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112f0a3be79f46b58f02789831dff2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8960\n",
      "AUC: 0.9698\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2896781861782074\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (20/50): 0.5872 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 647 (generating 277 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=380, C1=647\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836dae05036f4d2a874b730af0d3c627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a7989858734922b3eaa4be2e2a04f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9000\n",
      "AUC: 0.9707\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2789728045463562\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (21/50): 0.6446 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 590 (generating 220 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=380, C1=590\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42d5afa256c42c1988056ce1f0f6083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0117fcd8f4415c84ed9c1c52fa9d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9080\n",
      "AUC: 0.9715\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2702409625053406\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (22/50): 0.7075 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 537 (generating 167 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=380, C1=537\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a540b047aab042bea309cd0b2058e32b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce7def2a6f0a43e2ac69e154c6124494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9240\n",
      "AUC: 0.9719\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2610713541507721\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (23/50): 0.7766 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 489 (generating 119 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=380, C1=489\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73620d87ff244dc8901cc7c0b2f1c085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e85cdb94cf483f9ca3b6dbc44c1598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9280\n",
      "AUC: 0.9727\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2539919912815094\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (24/50): 0.8524 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 446 (generating 76 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=380, C1=446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd94a459e114b168e052f8fbacae0ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333d533e841b4e00ac5f048b9bfdd8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9360\n",
      "AUC: 0.9730\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2476142793893814\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (25/50): 0.9357 ---\n",
      "  INFO: Strategy: Oversample class 1 from 370 to 406 (generating 36 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=380, C1=406\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43a365908b44ed79034caf4b8f455fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b1a3f722fb484c9a5325ff9a956185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9360\n",
      "AUC: 0.9734\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2425379753112793\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (26/50): 1.0270 ---\n",
      "  INFO: Strategy: Oversample class -1 from 370 to 370 (generating 0 samples).\n",
      "  INFO: No synthetic samples were required or generated.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac1dd58a85945d4b69b5705e4ac838c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a459821b4749969b78fd1f456a8b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9400\n",
      "AUC: 0.9739\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.23775994777679443\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (27/50): 1.2429 ---\n",
      "  INFO: Strategy: Oversample class 0 from 380 to 460 (generating 80 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=460, C1=370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d365c6ffb3412b823ba95beb4ddf35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9660dfc431dd440fa6bab31d8b094e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9360\n",
      "AUC: 0.9738\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.23509053885936737\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (28/50): 1.5041 ---\n",
      "  INFO: Strategy: Oversample class 0 from 380 to 557 (generating 177 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=557, C1=370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec4cca88eda471a84062de0983188bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b325dd2688435183adfc48a508cec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9400\n",
      "AUC: 0.9743\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2295948565006256\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (29/50): 1.8203 ---\n",
      "  INFO: Strategy: Oversample class 0 from 380 to 673 (generating 293 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=673, C1=370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac7b6c320144fdabccd0bb9ec493843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b00c7b836943e3ac514e802bf6bfd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9480\n",
      "AUC: 0.9748\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2285914272069931\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (30/50): 2.2028 ---\n",
      "  INFO: Strategy: Oversample class 0 from 380 to 815 (generating 435 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=815, C1=370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf95c53743541b0994e554c56cad089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad69e3f9de6400a99fe7a2c7edd2e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9440\n",
      "AUC: 0.9754\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.22909051179885864\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (31/50): 2.6658 ---\n",
      "  INFO: Strategy: Oversample class 0 from 380 to 986 (generating 606 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=986, C1=370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0798b13320410a92e3be78e411e963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60267aa7e99c4f18a30ee9941b7620eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9360\n",
      "AUC: 0.9758\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.23292623460292816\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (32/50): 3.2262 ---\n",
      "  INFO: Strategy: Oversample class 0 from 380 to 1194 (generating 814 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=1194, C1=370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218b6bec280e4d55ae9f5dcf2e70c288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95bb40ee73d047a6bc476a0d61a7963c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9120\n",
      "AUC: 0.9767\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.23937875032424927\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (33/50): 3.9042 ---\n",
      "  INFO: Strategy: Oversample class 0 from 380 to 1445 (generating 1065 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=1445, C1=370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a7523108f14e9f9925d5fc3a64a0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91717239df97466e98438651561ee168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9080\n",
      "AUC: 0.9779\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.24641071259975433\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (34/50): 4.7248 ---\n",
      "  INFO: Strategy: Oversample class 0 from 380 to 1748 (generating 1368 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=1748, C1=370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029f8b01dfed4e80985359a01597a45a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484d6cac4f00484790bb3f80891f0d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8960\n",
      "AUC: 0.9788\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.26082149147987366\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (35/50): 5.7179 ---\n",
      "  INFO: Strategy: Oversample class 0 from 380 to 2116 (generating 1736 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=2116, C1=370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "772417e44eb544f6b1e9f63b3ee357e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4294fc55a946e19521ecd05bfd595a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8960\n",
      "AUC: 0.9806\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.26289862394332886\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (36/50): 6.9197 ---\n",
      "  INFO: Strategy: Oversample class 0 from 380 to 2560 (generating 2180 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=2560, C1=370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ae1b0833254552947a7f7e01ac6098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a401cb513c40b487d137520b2f259c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8960\n",
      "AUC: 0.9818\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.26778027415275574\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (37/50): 8.3741 ---\n",
      "  INFO: Strategy: Oversample class 0 from 380 to 3098 (generating 2718 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=3098, C1=370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63d179d3b04422fb09888a9d4be97a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e547129a5e24613937d4cd10662aec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8800\n",
      "AUC: 0.9829\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2847744822502136\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (38/50): 10.1342 ---\n",
      "  INFO: Strategy: Oversample class 0 from 380 to 3750 (generating 3370 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=3750, C1=370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ce640868914c2c85894a7fcd63c694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f609b4f488a4fb68280c91ec9043e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8880\n",
      "AUC: 0.9852\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2719954252243042\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (39/50): 12.2643 ---\n",
      "  INFO: Strategy: Oversample class 0 from 380 to 4538 (generating 4158 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=4538, C1=370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80daf3db4e80490b9a7f8de262482ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b42f0ded1442faa284a7c7caed2983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8640\n",
      "AUC: 0.9866\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.29493409395217896\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (40/50): 14.8420 ---\n",
      "  INFO: Strategy: Oversample class 0 from 380 to 5492 (generating 5112 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=5492, C1=370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3ceb6478ef4efab5c567eec789c51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed75751e6aa459ba2ab7eb1603fbae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8640\n",
      "AUC: 0.9883\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.297874391078949\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (41/50): 17.9615 ---\n",
      "  INFO: Strategy: Oversample class 0 from 380 to 6646 (generating 6266 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=6646, C1=370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f40e01e4c4a46dbabf51b15e9239929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ccb9366ea394a73b65695d1d8ed4f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8600\n",
      "AUC: 0.9891\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.29931890964508057\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (42/50): 21.7367 ---\n",
      "  INFO: Strategy: Oversample class 0 from 380 to 8043 (generating 7663 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=8043, C1=370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b82d9a95da74b2e929ce3899e8be14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4130f1e586f4c7e8101e3874d3ea465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8600\n",
      "AUC: 0.9900\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.31074926257133484\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (43/50): 26.3054 ---\n",
      "  INFO: Strategy: Oversample class 0 from 380 to 9733 (generating 9353 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=9733, C1=370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d9c2af1f194e83b93b940a920ab0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28c1e9dfd564f7b983dc796c9b095a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8600\n",
      "AUC: 0.9906\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.313467800617218\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (44/50): 31.8343 ---\n",
      "  INFO: Strategy: Oversample class 0 from 380 to 11779 (generating 11399 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=11779, C1=370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9b1a2e00914810bab0f015965adb30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b2b9fca02a42cfbb71f8060e066708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8440\n",
      "AUC: 0.9921\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.34876343607902527\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (45/50): 38.5253 ---\n",
      "  INFO: Strategy: Oversample class 0 from 380 to 14254 (generating 13874 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=14254, C1=370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac3ef8f51034ae880b42cbaa684029b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560e99142fd64ad8aba13ec76d384e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8560\n",
      "AUC: 0.9924\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3231951594352722\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (46/50): 46.6227 ---\n",
      "  INFO: Strategy: Oversample class 0 from 380 to 17250 (generating 16870 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=17250, C1=370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4985f4e8f804ddfbea1dad9f4ed7ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0ebd0a5a0d443cb8cfb1e7da77304d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8320\n",
      "AUC: 0.9930\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3646348714828491\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (47/50): 56.4219 ---\n",
      "  INFO: Strategy: Oversample class 0 from 380 to 20876 (generating 20496 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=20876, C1=370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6de9bac140a49799726337a738c6e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1b581a72824da8b26df7f471862a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8320\n",
      "AUC: 0.9935\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.41798582673072815\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (48/50): 68.2808 ---\n",
      "  INFO: Strategy: Oversample class 0 from 380 to 25264 (generating 24884 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=25264, C1=370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64a648470094c8a9c89392e343b56c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7499494196e41b4a474fc1e2c5a6375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8400\n",
      "AUC: 0.9935\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.38103818893432617\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (49/50): 82.6322 ---\n",
      "  INFO: Strategy: Oversample class 0 from 380 to 30574 (generating 30194 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=30574, C1=370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28902602ba5c4283b8fbaea5b2f12c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6ca987f41e4d5fa9cd3b018959863f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8360\n",
      "AUC: 0.9937\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3990187644958496\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (50/50): 100.0000 ---\n",
      "  INFO: Strategy: Oversample class 0 from 380 to 37000 (generating 36620 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=37000, C1=370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b980a65209824c75b356acbaad3ea95c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead7b8da88524af08b1daa04f3e2cb15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8200\n",
      "AUC: 0.9937\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4583030343055725\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "--- Starting Fold 4/4 ---\n",
      "INFO: Initial C0=366, C1=384, Ratio(0/1): 0.953125\n",
      "INFO: Target ratios (w values): [  0.1          0.10943746   0.11976557   0.1310684    0.14343792\n",
      "   0.15697481   0.17178924   0.18800178   0.20574437   0.2251614\n",
      "   0.24641092   0.26966584   0.29511544   0.32296684   0.35344669\n",
      "   0.38680307   0.42330745   0.46325691   0.50697658   0.55482228\n",
      "   0.6071834    0.66448607   0.72719666   0.79582554   0.87093124\n",
      "   0.953125     1.15704953   1.40460445   1.70512463   2.06994219\n",
      "   2.51281379   3.05043936   3.70309186   4.49538171   5.45718483\n",
      "   6.6247692    8.04216245   9.76281209  11.85160094  14.38729368\n",
      "  17.46550703  21.20231522  25.738627    31.24549903  37.93058618\n",
      "  46.04597183  55.8976735   67.85718225  82.37547102 100.        ]\n",
      "INFO: KDE-like perturbation sigma: 0.1\n",
      "INFO: Standard deviation of synthetic samples will NOT be modified after generation.\n",
      "\n",
      "--- Processing target ratio w (1/50): 0.1000 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 3660 (generating 3276 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=366, C1=3660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30fddee9d9df43f193881516bc9d743e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f959a3a6fec4d79888345fa5322fd63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4640\n",
      "AUC: 0.5514\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8724315762519836\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (2/50): 0.1094 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 3344 (generating 2960 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=366, C1=3344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d076567fc4479db734c778b3002554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b925466cc2f54eb18efd27951707f0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4680\n",
      "AUC: 0.5616\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1235783100128174\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (3/50): 0.1198 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 3056 (generating 2672 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=366, C1=3056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3508321b73aa4ef8918302a9af0dfd0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5fccd826cc4c7ba8ecf92fc3c26184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4840\n",
      "AUC: 0.5878\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1265523433685303\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (4/50): 0.1311 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 2792 (generating 2408 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=366, C1=2792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a16f5319c034d73869bcbd9ef1e484f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7c7651a2c440feb523f613d252fd87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4960\n",
      "AUC: 0.6430\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.035796880722046\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (5/50): 0.1434 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 2552 (generating 2168 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=366, C1=2552\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d853b03a223e4446b1eb4f813d006af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f694fb1301c04e42b8f97e27b48b8e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5240\n",
      "AUC: 0.7431\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9314102530479431\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (6/50): 0.1570 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 2332 (generating 1948 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=366, C1=2332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cba5b6cd077491fa158d52381c1dde1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10210936454849338e0f7e39967de0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5320\n",
      "AUC: 0.8488\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8394737839698792\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (7/50): 0.1718 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 2131 (generating 1747 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=366, C1=2131\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d744c3e8559d413087f7b9ea8f960508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042694ce230e4cc5a99bb253bedcdddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5480\n",
      "AUC: 0.9262\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7416750192642212\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (8/50): 0.1880 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 1947 (generating 1563 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=366, C1=1947\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f7c1f82d3a49378414e8f03c2c77cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4129b7b7011c48b49bafff76c3293cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5640\n",
      "AUC: 0.9540\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6653791666030884\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (9/50): 0.2057 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 1779 (generating 1395 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=366, C1=1779\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db03eb130c67482b8e2acd1c38ad304e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229832e2e3674b798531e540df519633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5680\n",
      "AUC: 0.9698\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5973303318023682\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (10/50): 0.2252 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 1626 (generating 1242 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=366, C1=1626\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded031750a574e1cb4a257026f26a0ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857c9f663160495c81d788737a1d4add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5840\n",
      "AUC: 0.9751\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5529171228408813\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (11/50): 0.2464 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 1485 (generating 1101 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=366, C1=1485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6d4361e5c045e49dd49132f7729cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295837194c8a42f4b0c336f8bc24dc2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6080\n",
      "AUC: 0.9777\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5072837471961975\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (12/50): 0.2697 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 1357 (generating 973 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=366, C1=1357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdab890885ed476ca26900786ad1407e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2bcbd37176f498eaab6b7d68afa2d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7120\n",
      "AUC: 0.9789\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4683661162853241\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (13/50): 0.2951 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 1240 (generating 856 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=366, C1=1240\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b1835dda78429ab0d06a9cba1b2ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b685d35a53a547e9af2d0971f1f18cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8000\n",
      "AUC: 0.9793\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.42820557951927185\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (14/50): 0.3230 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 1133 (generating 749 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=366, C1=1133\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b738f22b2c843aba44b9e3b73792c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff0337fba40a432e84ed9437b66f6cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8240\n",
      "AUC: 0.9795\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.40136632323265076\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (15/50): 0.3534 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 1036 (generating 652 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=366, C1=1036\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92710ef720dd4df98cd461138819fe68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d2b48f2c184bd3b6e4c2297a3494a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8440\n",
      "AUC: 0.9796\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.37458646297454834\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (16/50): 0.3868 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 946 (generating 562 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=366, C1=946\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb261a2e4724acb8a59f87900a23970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5024696ed354ca9995ca811d69abf43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8680\n",
      "AUC: 0.9800\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.34839892387390137\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (17/50): 0.4233 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 865 (generating 481 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=366, C1=865\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14182c68137f4fbf8dfbeb3f5f5f5cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100c54cacf8f4df6bbc1fdf66bf11af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8880\n",
      "AUC: 0.9800\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.32458654046058655\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (18/50): 0.4633 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 790 (generating 406 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=366, C1=790\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1137680f94124f46ae6c1cac343143f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe18037645b64a8eb12c710edc3f48ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9040\n",
      "AUC: 0.9808\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.31147900223731995\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (19/50): 0.5070 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 722 (generating 338 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=366, C1=722\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9517effd3e924a0c90b712e7222afedb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764b54ffde3a4826ae4acc16af95bd45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8960\n",
      "AUC: 0.9812\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.29785361886024475\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (20/50): 0.5548 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 660 (generating 276 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=366, C1=660\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85e7168db07448e8649258f2d479324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a924330c092c4f3ea9553c8f00e73fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9080\n",
      "AUC: 0.9816\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.28499865531921387\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (21/50): 0.6072 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 603 (generating 219 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=366, C1=603\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d145ed92d23471f8d5c4e97626d1a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7ad38d8eb045d4bb5a659c59406c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9080\n",
      "AUC: 0.9819\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.27561014890670776\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (22/50): 0.6645 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 551 (generating 167 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=366, C1=551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cafd25cd141499ea178e32325bc5822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda41a6e3d584b6dbb265926c56aacd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9200\n",
      "AUC: 0.9820\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2652970552444458\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (23/50): 0.7272 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 503 (generating 119 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=366, C1=503\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64dab665beca46af9e74fd306dac90a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5484c7068e3c4970a9904ed778cce03c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9200\n",
      "AUC: 0.9821\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2549632489681244\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (24/50): 0.7958 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 460 (generating 76 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=366, C1=460\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11da0f3d2e14ccc997cedc1940c7d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d907495d1d40a0a1d4cfdaca12de43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9160\n",
      "AUC: 0.9821\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.24846874177455902\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (25/50): 0.8709 ---\n",
      "  INFO: Strategy: Oversample class 1 from 384 to 420 (generating 36 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=366, C1=420\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4b0b11ea4a4bb384a7573a3394bed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4797847ee87f4c18a8db53ebb0422add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9120\n",
      "AUC: 0.9828\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.24171455204486847\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (26/50): 0.9531 ---\n",
      "  INFO: Strategy: Oversample class -1 from 384 to 384 (generating 0 samples).\n",
      "  INFO: No synthetic samples were required or generated.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b66be9ad8e4728beb509e434fecd2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb695c7ffeef435fb5fe4bdefda50389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9240\n",
      "AUC: 0.9828\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.23504745960235596\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (27/50): 1.1570 ---\n",
      "  INFO: Strategy: Oversample class 0 from 366 to 444 (generating 78 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=444, C1=384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a744364efa44900886a1f54a9b5610e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe11cee8cb1b496b84e2d9dcd58193ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9280\n",
      "AUC: 0.9829\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.23026281595230103\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (28/50): 1.4046 ---\n",
      "  INFO: Strategy: Oversample class 0 from 366 to 539 (generating 173 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=539, C1=384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e6c59e369f45019ca6658d77d0e828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68cc62a9cfba4b13a357afc373026513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9280\n",
      "AUC: 0.9831\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.22611987590789795\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (29/50): 1.7051 ---\n",
      "  INFO: Strategy: Oversample class 0 from 366 to 655 (generating 289 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=655, C1=384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d545ab75854ef69ede1eaaf26607f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a28e8e3b3b4938b37fc70078240e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9240\n",
      "AUC: 0.9837\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.22329527139663696\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (30/50): 2.0699 ---\n",
      "  INFO: Strategy: Oversample class 0 from 366 to 795 (generating 429 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=795, C1=384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcfc086378ab487fa000354c888009e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43828053da024b1d8bc113872e34476e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9160\n",
      "AUC: 0.9842\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2241695374250412\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (31/50): 2.5128 ---\n",
      "  INFO: Strategy: Oversample class 0 from 366 to 965 (generating 599 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=965, C1=384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e2258881f2408c8807048765f63156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965f1e44166447f2b2a2a1d5dddd5007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9200\n",
      "AUC: 0.9848\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2260391265153885\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (32/50): 3.0504 ---\n",
      "  INFO: Strategy: Oversample class 0 from 366 to 1171 (generating 805 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=1171, C1=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b2619290cb4293a863a8a1ed80a883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8aa6580698489ba87826c3e75237ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9040\n",
      "AUC: 0.9857\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.22805581986904144\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (33/50): 3.7031 ---\n",
      "  INFO: Strategy: Oversample class 0 from 366 to 1422 (generating 1056 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=1422, C1=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b8ce417d3947c980545995c4eff867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9402c2e7d04ba0903b4a49617d8f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8960\n",
      "AUC: 0.9860\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.23736505210399628\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (34/50): 4.4954 ---\n",
      "  INFO: Strategy: Oversample class 0 from 366 to 1726 (generating 1360 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=1726, C1=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (32) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aac4ee846914959b4eb9f396437fd57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782b946fa86545e1a6b479665c23c8ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8920\n",
      "AUC: 0.9871\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2466861605644226\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (35/50): 5.4572 ---\n",
      "  INFO: Strategy: Oversample class 0 from 366 to 2096 (generating 1730 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=2096, C1=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041fd0456393426589e1dcbb0d5ee981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c08876bb18841139910ffa68cafd518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8880\n",
      "AUC: 0.9891\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.24721042811870575\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (36/50): 6.6248 ---\n",
      "  INFO: Strategy: Oversample class 0 from 366 to 2544 (generating 2178 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=2544, C1=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5252376328794d1cb0a74c50b9d20812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800292b743c64388aa8ea354e942f305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8920\n",
      "AUC: 0.9909\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.23987211287021637\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (37/50): 8.0422 ---\n",
      "  INFO: Strategy: Oversample class 0 from 366 to 3088 (generating 2722 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=3088, C1=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38baaaa1daee4a8daeef102032c2655d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13255987b97455281f9fc19f30d0cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8840\n",
      "AUC: 0.9922\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.25031140446662903\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (38/50): 9.7628 ---\n",
      "  INFO: Strategy: Oversample class 0 from 366 to 3749 (generating 3383 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=3749, C1=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ac40ebab974672884eed0cd8a17bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da61293d7e5414393edbc00df6ee54e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8760\n",
      "AUC: 0.9927\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2822609841823578\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (39/50): 11.8516 ---\n",
      "  INFO: Strategy: Oversample class 0 from 366 to 4551 (generating 4185 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=4551, C1=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51697bbf77664fdcbf48d43b5da3f5c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556e02b1c7b444578c72e70bcb4c2db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8800\n",
      "AUC: 0.9938\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.27413955330848694\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing target ratio w (40/50): 14.3873 ---\n",
      "  INFO: Strategy: Oversample class 0 from 366 to 5525 (generating 5159 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=5525, C1=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cbeff7f234844d6821892839d07cb0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a30322903114318a168305bc2b7614d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8800\n",
      "AUC: 0.9949\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.27237778902053833\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (41/50): 17.4655 ---\n",
      "  INFO: Strategy: Oversample class 0 from 366 to 6707 (generating 6341 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=6707, C1=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d6e909ff6c4ff489059cc5fb73dbaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4034c6c7c7401d9dba08040e6016e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8720\n",
      "AUC: 0.9954\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2897533178329468\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (42/50): 21.2023 ---\n",
      "  INFO: Strategy: Oversample class 0 from 366 to 8142 (generating 7776 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=8142, C1=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a1e1770a6b24b47b446c611ce38c7f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1753aedb44842dfb5c3cbfbb8213b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8760\n",
      "AUC: 0.9958\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2872764468193054\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (43/50): 25.7386 ---\n",
      "  INFO: Strategy: Oversample class 0 from 366 to 9884 (generating 9518 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n",
      "  INFO: KDE-like generation complete. New C0=9884, C1=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d7b990453a4fb9911f1fbd217ec114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "624e152a6e9f4f88816f794424684c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8760\n",
      "AUC: 0.9959\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.29558074474334717\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (44/50): 31.2455 ---\n",
      "  INFO: Strategy: Oversample class 0 from 366 to 11998 (generating 11632 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=11998, C1=384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e8b86d780e45b5bd4f56d837185098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dce57dcb043460ab059df22cd47af20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8640\n",
      "AUC: 0.9966\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.32235366106033325\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (45/50): 37.9306 ---\n",
      "  INFO: Strategy: Oversample class 0 from 366 to 14565 (generating 14199 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=14565, C1=384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5c2d7ebcb040c0b971221cc637be80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0acdb4cda7c43d3aa981cc465afb0c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8800\n",
      "AUC: 0.9968\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.29123783111572266\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (46/50): 46.0460 ---\n",
      "  INFO: Strategy: Oversample class 0 from 366 to 17682 (generating 17316 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=17682, C1=384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee27eddc6b2a4890a2b5eca3e3a5d30c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01b63176c5c49078ea48a5a49a792a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8640\n",
      "AUC: 0.9971\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3244567811489105\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (47/50): 55.8977 ---\n",
      "  INFO: Strategy: Oversample class 0 from 366 to 21465 (generating 21099 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=21465, C1=384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57e2023fb634324acd7cf51a6148b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d45d3ea8e944c5db090e1fa8bdcbf6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8720\n",
      "AUC: 0.9970\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.336512953042984\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (48/50): 67.8572 ---\n",
      "  INFO: Strategy: Oversample class 0 from 366 to 26057 (generating 25691 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=26057, C1=384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9efafe40e3f24dd5bc26d2ae8b99f9bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680cf660423c467e84d2560ac697005b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8560\n",
      "AUC: 0.9974\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3824178874492645\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (49/50): 82.3755 ---\n",
      "  INFO: Strategy: Oversample class 0 from 366 to 31632 (generating 31266 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=31632, C1=384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b4316fa53c444008f21ae61bc5af044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3d9ca925724dc4a2482881c5ecd305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8720\n",
      "AUC: 0.9974\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.34504473209381104\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Processing target ratio w (50/50): 100.0000 ---\n",
      "  INFO: Strategy: Oversample class 0 from 366 to 38400 (generating 38034 samples).\n",
      "  INFO: Using KDE-like generator. Perturbation sigma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INFO: KDE-like generation complete. New C0=38400, C1=384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7fbf8ead234de8a99c33bd6a1c9cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v11.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v11.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v11.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v11.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61701f2be1e495db97768227045df2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8640\n",
      "AUC: 0.9974\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3690871000289917\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "import numpy as np\n",
    "\n",
    "# --- Place any constants or unchanging objects outside the loop ---\n",
    "pl.seed_everything(42, workers=True)\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "#store the weighted classifiers of all the folds\n",
    "list_folds_weighted_clfs = []  # List to store classifiers from all folds\n",
    "#store the best classfiers of all the folds\n",
    "list_folds_best_models = []  # List to store best models from all folds\n",
    "\n",
    "# Dictionary to store the history of each fold\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "\n",
    "# 3. K-fold cross-validation loop\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(train_data_tensor)):\n",
    "    list_weighted_clfs = [] # List to store the models trained at each stage\n",
    "    best_clfs = [] # List to store the best models from each stage\n",
    "    best_model_paths = [] # List to store the path of the best model from each stage\n",
    "    print(f\"--- Starting Fold {fold + 1}/{K_FOLDS} ---\")\n",
    "    # 1. Instantiate the LightningModule\n",
    "    model = LitClassifier(input_features=2, hidden_units=32, learning_rate=LEARNING_RATE)\n",
    "\n",
    "    # --- Create datasets and dataloaders for the current fold ---\n",
    "    # FIX 2: Get the fold-specific data by indexing the underlying tensors of the TensorDataset\n",
    "    fold_train_features, fold_train_labels = train_data_tensor.tensors[0][train_ids], train_data_tensor.tensors[1][train_ids]\n",
    "    fold_val_features, fold_val_labels = train_data_tensor.tensors[0][val_ids], train_data_tensor.tensors[1][val_ids]\n",
    "\n",
    "    # Create the validation loader for this fold\n",
    "    fold_val_dataset = data.TensorDataset(fold_val_features, fold_val_labels)\n",
    "    fold_loader = data.DataLoader(fold_val_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "\n",
    "    # Create a temporary dataset for the generate_ratios function\n",
    "    temp_train_dataset_for_ratios = np.c_[fold_train_features, fold_train_labels]\n",
    "    alpha_target_actual_values, Class0_initial, Class1_initial = generate_ratios(train_data=temp_train_dataset_for_ratios)\n",
    "\n",
    "    for w_idx, w in enumerate(alpha_target_actual_values):\n",
    "        print(f\"\\n--- Processing target ratio w ({w_idx+1}/{len(alpha_target_actual_values)}): {w:.4f} ---\")\n",
    "        X_train, y_train = oversample_dataset_KDE(Class0_initial, Class1_initial, w, train_data=temp_train_dataset_for_ratios)\n",
    "        # Create a new DataLoader for the current stage with the oversampled data\n",
    "        oversampled_train_dataset = data.TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                                                       torch.tensor(y_train, dtype=torch.float32))\n",
    "        fold_train_loader = data.DataLoader(oversampled_train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)  # Ensure drop_last=True for consistent batch sizes\n",
    "        \n",
    "        \n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            every_n_epochs=1,                # Save model every epoch\n",
    "            dirpath=f'checkpoints/stage_{w_idx+1}/fold_{fold+1}/',\n",
    "            filename=f'best-model-fold{fold+1}-{{epoch:02d}}',\n",
    "            save_top_k=1,\n",
    "            mode='max',\n",
    "        )\n",
    "        \n",
    "        # 3. Instantiate a NEW Trainer for this specific stage\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator='gpu',\n",
    "            devices=1,\n",
    "            #strategy='ddp_notebook',\n",
    "            max_epochs=NUM_EPOCHS, # Number of epochs for THIS stage\n",
    "            callbacks=[checkpoint_callback, progress_bar],\n",
    "            #logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=f\"stage_{w_idx+1}_fold_{fold+1}_ratio_{alpha_target_actual_values}\"),\n",
    "            precision='16-mixed'\n",
    "            )\n",
    "        \n",
    "        # 4. Train the model. It will start with weights from the previous stage.\n",
    "        trainer.fit(model, train_dataloaders=fold_train_loader)\n",
    "        \n",
    "        # 5. Get the path to the best model from THIS stage and store it\n",
    "        if checkpoint_callback.best_model_path:\n",
    "            best_path_this_stage = checkpoint_callback.best_model_path\n",
    "            print(f\"--- Fold {fold+1} Stage {w_idx+1} complete. Best model path: {best_path_this_stage} ---\")\n",
    "            best_model_paths.append(best_path_this_stage)\n",
    "            \n",
    "            # 6. CRITICAL: Load the best weights back into the model object\n",
    "            # This ensures we carry forward the BEST model to the next stage, not the last.\n",
    "            print(f\"Loading best weights from {best_path_this_stage} to continue...\")\n",
    "            model = LitClassifier.load_from_checkpoint(best_path_this_stage, strict=False)  # Use strict=False to ignore missing keys if any\n",
    "        else:\n",
    "            print(f\"--- Fold {fold+1} Stage {w_idx+1} complete. No checkpoint was saved. ---\")\n",
    "            # If no checkpoint was saved, the model object will just have the weights from the last epoch.\n",
    "\n",
    "        # 7. Test the model after each stage\n",
    "        print(f\"\\n--- Testing model after Fold {fold+1} Stage {w_idx+1} ---\")\n",
    "        trainer.test(model, dataloaders=fold_loader, ckpt_path=best_path_this_stage)\n",
    "        results_classifier = model.last_test_results.copy()\n",
    "        current_model = {\n",
    "            \"model\": model,\n",
    "            \"fpr\": results_classifier[\"fpr\"],\n",
    "            \"tpr\": results_classifier[\"tpr\"],\n",
    "            \"threshold\": results_classifier[\"threshold\"],\n",
    "            \"full_roc\": results_classifier[\"full_roc\"]\n",
    "        }\n",
    "        list_weighted_clfs.append(current_model)\n",
    "        best_clfs = get_best_roc_envelope(list_weighted_clfs, results_original_roc)\n",
    "    list_folds_weighted_clfs.append(list_weighted_clfs)\n",
    "    list_folds_best_models.append(best_clfs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34745efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to pickle/NN_data1_oversampling.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_models': [[{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.8360656),\n",
       "    'threshold': np.float16(0.4316)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0078125),\n",
       "    'tpr': np.float32(0.92622954),\n",
       "    'threshold': np.float16(0.09467)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.015625),\n",
       "    'tpr': np.float32(0.93442625),\n",
       "    'threshold': np.float16(0.1103)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.03125),\n",
       "    'tpr': np.float32(0.94262296),\n",
       "    'threshold': np.float16(0.06177)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0390625),\n",
       "    'tpr': np.float32(0.9590164),\n",
       "    'threshold': np.float16(0.03824)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0546875),\n",
       "    'tpr': np.float32(0.9672131),\n",
       "    'threshold': np.float16(0.024)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0703125),\n",
       "    'tpr': np.float32(0.97540987),\n",
       "    'threshold': np.float16(0.02971)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.109375),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.00704)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.8333333),\n",
       "    'threshold': np.float16(0.843)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.008474576),\n",
       "    'tpr': np.float32(0.9469697),\n",
       "    'threshold': np.float16(0.06165)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.016949153),\n",
       "    'tpr': np.float32(0.9848485),\n",
       "    'threshold': np.float16(0.01201)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.025423728),\n",
       "    'tpr': np.float32(0.99242425),\n",
       "    'threshold': np.float16(0.00909)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.13559322),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.0761)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.8923077),\n",
       "    'threshold': np.float16(0.0874)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.008333334),\n",
       "    'tpr': np.float32(0.9076923),\n",
       "    'threshold': np.float16(0.11816)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.016666668),\n",
       "    'tpr': np.float32(0.9307692),\n",
       "    'threshold': np.float16(0.09186)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.025),\n",
       "    'tpr': np.float32(0.95384616),\n",
       "    'threshold': np.float16(0.03964)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.033333335),\n",
       "    'tpr': np.float32(0.96153843),\n",
       "    'threshold': np.float16(0.2352)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.041666668),\n",
       "    'tpr': np.float32(0.9692308),\n",
       "    'threshold': np.float16(0.09174)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.06666667),\n",
       "    'tpr': np.float32(0.97692305),\n",
       "    'threshold': np.float16(0.0591)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.13333334),\n",
       "    'tpr': np.float32(0.99230766),\n",
       "    'threshold': np.float16(0.0009475)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.15),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.001623)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.92241377),\n",
       "    'threshold': np.float16(0.05792)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0074626864),\n",
       "    'tpr': np.float32(0.9310345),\n",
       "    'threshold': np.float16(0.04596)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.014925373),\n",
       "    'tpr': np.float32(0.9396552),\n",
       "    'threshold': np.float16(0.06915)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.02238806),\n",
       "    'tpr': np.float32(0.98275864),\n",
       "    'threshold': np.float16(0.02866)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.05970149),\n",
       "    'tpr': np.float32(0.9913793),\n",
       "    'threshold': np.float16(0.01883)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.06716418),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.00885)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}]],\n",
       " 'weighted_clfs': [[{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(1., dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.0625   , 0.0625   , 0.0703125,\n",
       "            0.0859375, 0.0859375, 0.0859375, 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.1484375, 0.1484375,\n",
       "            0.1484375, 0.15625  , 0.15625  , 0.1640625, 0.171875 , 0.171875 ,\n",
       "            0.1796875, 0.1796875, 0.1796875, 0.1796875, 0.1875   , 0.203125 ,\n",
       "            0.2109375, 0.2109375, 0.2109375, 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.2421875, 0.2421875, 0.25     , 0.2578125, 0.2734375, 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3046875, 0.3046875, 0.3203125,\n",
       "            0.328125 , 0.328125 , 0.3359375, 0.3359375, 0.3359375, 0.3359375,\n",
       "            0.34375  , 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.3671875,\n",
       "            0.3828125, 0.3984375, 0.40625  , 0.4140625, 0.4140625, 0.4140625,\n",
       "            0.421875 , 0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.4453125, 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.640625 ,\n",
       "            0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.671875 , 0.671875 , 0.6796875, 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.71875  , 0.7265625, 0.734375 , 0.734375 ,\n",
       "            0.734375 , 0.75     , 0.7578125, 0.7734375, 0.7734375, 0.7734375,\n",
       "            0.7734375, 0.78125  , 0.796875 , 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01639344, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.05737705, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.07377049, 0.07377049, 0.08196721, 0.08196721,\n",
       "            0.08196721, 0.09016393, 0.09016393, 0.09016393, 0.10655738,\n",
       "            0.1147541 , 0.1147541 , 0.1147541 , 0.1147541 , 0.1147541 ,\n",
       "            0.12295082, 0.12295082, 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.14754099, 0.1557377 , 0.1557377 , 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.25409836, 0.26229507, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.28688523, 0.28688523, 0.28688523, 0.28688523,\n",
       "            0.28688523, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.3114754 , 0.31967214, 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.36065573, 0.36885247, 0.37704918, 0.37704918,\n",
       "            0.37704918, 0.3852459 , 0.3852459 , 0.3852459 , 0.3852459 ,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40163934, 0.40983605,\n",
       "            0.4262295 , 0.4262295 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.45901638, 0.46721312, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.56557375, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6147541 , 0.63114756, 0.63114756, 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.71311474, 0.72131145, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.78688526, 0.78688526,\n",
       "            0.795082  , 0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8047, 0.8   , 0.792 , 0.7905, 0.7847, 0.7837, 0.7817,\n",
       "            0.778 , 0.771 , 0.77  , 0.7686, 0.7666, 0.766 , 0.7656, 0.7637,\n",
       "            0.762 , 0.7617, 0.76  , 0.758 , 0.7573, 0.757 , 0.756 , 0.7544,\n",
       "            0.754 , 0.7534, 0.7524, 0.752 , 0.751 , 0.75  , 0.7495, 0.749 ,\n",
       "            0.7485, 0.748 , 0.7476, 0.747 , 0.7466, 0.746 , 0.745 , 0.744 ,\n",
       "            0.7437, 0.7427, 0.742 , 0.7417, 0.7397, 0.739 , 0.7383, 0.738 ,\n",
       "            0.736 , 0.735 , 0.7344, 0.734 , 0.7324, 0.732 , 0.7314, 0.731 ,\n",
       "            0.7305, 0.7295, 0.7285, 0.727 , 0.7266, 0.726 , 0.7256, 0.7246,\n",
       "            0.7236, 0.723 , 0.722 , 0.721 , 0.72  , 0.718 , 0.717 , 0.7163,\n",
       "            0.716 , 0.7153, 0.7144, 0.714 , 0.7124, 0.711 , 0.7075, 0.7056,\n",
       "            0.705 , 0.7046, 0.703 , 0.701 , 0.7007, 0.6987, 0.698 , 0.6973,\n",
       "            0.6963, 0.6953, 0.6934, 0.6895, 0.6826, 0.6787, 0.678 , 0.6763,\n",
       "            0.6743, 0.6694, 0.669 , 0.6665, 0.6636, 0.658 , 0.657 , 0.6553,\n",
       "            0.654 , 0.6523, 0.6514, 0.6504, 0.649 , 0.6484, 0.6436, 0.64  ,\n",
       "            0.6396, 0.6367, 0.6357, 0.635 , 0.6343, 0.633 , 0.6323, 0.632 ,\n",
       "            0.6313, 0.631 , 0.6284, 0.628 , 0.6265, 0.6226, 0.622 , 0.6216,\n",
       "            0.621 , 0.6206, 0.62  , 0.6187, 0.618 , 0.6177, 0.6143, 0.6123,\n",
       "            0.6113, 0.6104, 0.61  , 0.6074, 0.607 , 0.6064, 0.606 , 0.6045,\n",
       "            0.603 , 0.6006, 0.5996, 0.599 , 0.5986, 0.5977, 0.596 , 0.595 ,\n",
       "            0.5947, 0.594 , 0.5933, 0.5923, 0.5913, 0.59  , 0.5894, 0.588 ,\n",
       "            0.586 , 0.585 , 0.5845, 0.5835, 0.583 , 0.5825, 0.5815, 0.58  ,\n",
       "            0.5796, 0.578 , 0.577 , 0.5767, 0.5757, 0.5747, 0.5728, 0.5723,\n",
       "            0.5713, 0.571 , 0.5693, 0.5664, 0.566 , 0.565 , 0.5625, 0.5615,\n",
       "            0.5557, 0.5547, 0.554 , 0.541 , 0.539 , 0.5386, 0.5356, 0.5347,\n",
       "            0.53  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(1., dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.0390625, 0.046875 , 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.1484375, 0.1484375, 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1875   , 0.1875   , 0.1953125,\n",
       "            0.1953125, 0.2109375, 0.2109375, 0.2109375, 0.2109375, 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.2421875, 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.2734375, 0.28125  , 0.28125  , 0.296875 , 0.3046875,\n",
       "            0.3046875, 0.3046875, 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.3515625, 0.3515625, 0.3515625, 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.390625 , 0.3984375, 0.3984375, 0.40625  ,\n",
       "            0.40625  , 0.4140625, 0.4140625, 0.421875 , 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4375   , 0.4375   , 0.453125 , 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   , 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.578125 , 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.6171875, 0.625    ,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.7734375, 0.78125  , 0.7890625, 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.03278688, 0.04098361, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.07377049, 0.07377049,\n",
       "            0.07377049, 0.07377049, 0.07377049, 0.08196721, 0.08196721,\n",
       "            0.09016393, 0.09016393, 0.09836066, 0.10655738, 0.10655738,\n",
       "            0.10655738, 0.10655738, 0.10655738, 0.12295082, 0.13114753,\n",
       "            0.13114753, 0.13114753, 0.13114753, 0.14754099, 0.1557377 ,\n",
       "            0.17213115, 0.18852459, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22950819, 0.22950819, 0.22950819, 0.22950819,\n",
       "            0.22950819, 0.22950819, 0.23770492, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.26229507, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.28688523, 0.28688523, 0.29508197,\n",
       "            0.29508197, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.33606556, 0.3442623 , 0.3442623 , 0.3442623 , 0.3442623 ,\n",
       "            0.352459  , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.3852459 , 0.3852459 , 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4180328 , 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5409836 , 0.5491803 ,\n",
       "            0.5491803 , 0.5491803 , 0.55737704, 0.55737704, 0.56557375,\n",
       "            0.58196723, 0.59016395, 0.59016395, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.77868855, 0.795082  , 0.8032787 , 0.8196721 ,\n",
       "            0.8278689 , 0.8442623 , 0.852459  , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90163934, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.952 , 0.9497, 0.9487, 0.9434, 0.9385, 0.938 , 0.936 ,\n",
       "            0.9355, 0.9346, 0.933 , 0.927 , 0.9253, 0.924 , 0.923 , 0.9214,\n",
       "            0.921 , 0.9194, 0.918 , 0.9175, 0.9165, 0.916 , 0.9155, 0.915 ,\n",
       "            0.9146, 0.914 , 0.913 , 0.9116, 0.911 , 0.91  , 0.9077, 0.907 ,\n",
       "            0.9062, 0.906 , 0.9023, 0.902 , 0.901 , 0.9004, 0.9   , 0.8994,\n",
       "            0.899 , 0.8984, 0.898 , 0.8975, 0.897 , 0.8965, 0.896 , 0.895 ,\n",
       "            0.8945, 0.894 , 0.8926, 0.8916, 0.891 , 0.8906, 0.89  , 0.8896,\n",
       "            0.889 , 0.8887, 0.884 , 0.8833, 0.883 , 0.8813, 0.8804, 0.8794,\n",
       "            0.879 , 0.877 , 0.876 , 0.8755, 0.875 , 0.8745, 0.874 , 0.8716,\n",
       "            0.871 , 0.8706, 0.869 , 0.8647, 0.8623, 0.86  , 0.8594, 0.858 ,\n",
       "            0.855 , 0.852 , 0.851 , 0.8506, 0.8486, 0.845 , 0.8447, 0.8423,\n",
       "            0.8413, 0.837 , 0.833 , 0.8276, 0.827 , 0.826 , 0.8223, 0.8174,\n",
       "            0.816 , 0.8135, 0.8125, 0.811 , 0.8105, 0.8066, 0.806 , 0.8057,\n",
       "            0.805 , 0.8003, 0.7993, 0.7983, 0.797 , 0.795 , 0.794 , 0.7935,\n",
       "            0.7925, 0.792 , 0.7896, 0.7847, 0.7837, 0.783 , 0.782 , 0.7817,\n",
       "            0.7783, 0.7773, 0.777 , 0.7764, 0.7754, 0.775 , 0.7744, 0.769 ,\n",
       "            0.768 , 0.7666, 0.761 , 0.753 , 0.7524, 0.7505, 0.7476, 0.7466,\n",
       "            0.746 , 0.7446, 0.7437, 0.7427, 0.7417, 0.7397, 0.7393, 0.7354,\n",
       "            0.735 , 0.7324, 0.7314, 0.731 , 0.7295, 0.7207, 0.7197, 0.7183,\n",
       "            0.716 , 0.712 , 0.711 , 0.709 , 0.7056, 0.705 , 0.703 , 0.7017,\n",
       "            0.698 , 0.694 , 0.693 , 0.682 , 0.6807, 0.6797, 0.679 , 0.6772,\n",
       "            0.6753, 0.6733, 0.6675, 0.6655, 0.664 , 0.6562, 0.655 , 0.654 ,\n",
       "            0.6533, 0.6514, 0.65  , 0.648 , 0.6465, 0.644 , 0.6436, 0.6426,\n",
       "            0.6377, 0.637 , 0.6333, 0.631 , 0.6304, 0.63  , 0.6294, 0.6255,\n",
       "            0.6226, 0.6177, 0.616 , 0.6094, 0.592 , 0.576 , 0.5645, 0.56  ,\n",
       "            0.556 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(1., dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.0859375, 0.09375  ,\n",
       "            0.09375  , 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.1953125, 0.1953125, 0.203125 , 0.21875  ,\n",
       "            0.2265625, 0.2265625, 0.234375 , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.328125 , 0.328125 , 0.328125 , 0.328125 , 0.328125 , 0.328125 ,\n",
       "            0.3515625, 0.3671875, 0.3671875, 0.375    , 0.3828125, 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.4140625, 0.4140625, 0.421875 , 0.421875 ,\n",
       "            0.421875 , 0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5      , 0.5      , 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.59375  , 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.05737705, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.07377049, 0.08196721, 0.09016393,\n",
       "            0.09016393, 0.09836066, 0.09836066, 0.09836066, 0.10655738,\n",
       "            0.10655738, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13114753, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.16393442, 0.18032786, 0.18852459, 0.18852459,\n",
       "            0.21311475, 0.22131148, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.25409836, 0.25409836, 0.25409836, 0.26229507, 0.26229507,\n",
       "            0.2704918 , 0.2704918 , 0.2704918 , 0.27868852, 0.29508197,\n",
       "            0.29508197, 0.29508197, 0.29508197, 0.30327868, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.37704918, 0.37704918,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.4262295 , 0.44262296, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6557377 , 0.6557377 , 0.6721311 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.74590164, 0.75409836,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.89344263, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9736, 0.9727, 0.971 , 0.9673, 0.9653, 0.9624, 0.962 ,\n",
       "            0.9575, 0.956 , 0.955 , 0.954 , 0.9536, 0.9517, 0.95  , 0.949 ,\n",
       "            0.948 , 0.9473, 0.947 , 0.9463, 0.9453, 0.9443, 0.944 , 0.943 ,\n",
       "            0.942 , 0.9414, 0.94  , 0.9395, 0.939 , 0.9385, 0.938 , 0.937 ,\n",
       "            0.9365, 0.936 , 0.9355, 0.935 , 0.9346, 0.9336, 0.932 , 0.931 ,\n",
       "            0.9307, 0.93  , 0.929 , 0.9287, 0.928 , 0.9277, 0.9272, 0.927 ,\n",
       "            0.9263, 0.925 , 0.924 , 0.9233, 0.9224, 0.9204, 0.9185, 0.918 ,\n",
       "            0.9175, 0.917 , 0.9165, 0.916 , 0.9146, 0.914 , 0.9136, 0.9126,\n",
       "            0.912 , 0.9087, 0.908 , 0.9077, 0.9067, 0.9062, 0.904 , 0.9023,\n",
       "            0.902 , 0.9004, 0.9   , 0.898 , 0.8975, 0.8945, 0.893 , 0.8926,\n",
       "            0.8916, 0.8896, 0.889 , 0.8877, 0.887 , 0.8867, 0.8857, 0.8853,\n",
       "            0.8804, 0.88  , 0.879 , 0.8774, 0.875 , 0.8745, 0.8726, 0.8716,\n",
       "            0.871 , 0.8706, 0.8687, 0.865 , 0.8647, 0.8643, 0.8623, 0.8613,\n",
       "            0.861 , 0.86  , 0.8594, 0.857 , 0.8564, 0.856 , 0.8555, 0.8545,\n",
       "            0.854 , 0.8516, 0.85  , 0.8496, 0.8486, 0.848 , 0.8467, 0.8447,\n",
       "            0.8438, 0.842 , 0.841 , 0.8394, 0.8345, 0.833 , 0.832 , 0.831 ,\n",
       "            0.83  , 0.8296, 0.8247, 0.824 , 0.822 , 0.8213, 0.8164, 0.814 ,\n",
       "            0.811 , 0.8066, 0.803 , 0.8003, 0.7983, 0.795 , 0.7915, 0.788 ,\n",
       "            0.7847, 0.7837, 0.783 , 0.7773, 0.7764, 0.765 , 0.763 , 0.7617,\n",
       "            0.758 , 0.7563, 0.754 , 0.7524, 0.7505, 0.745 , 0.7437, 0.742 ,\n",
       "            0.7344, 0.73  , 0.7275, 0.7266, 0.7227, 0.72  , 0.7144, 0.7114,\n",
       "            0.71  , 0.7056, 0.705 , 0.704 , 0.698 , 0.693 , 0.6904, 0.685 ,\n",
       "            0.681 , 0.6797, 0.676 , 0.675 , 0.6743, 0.6714, 0.6665, 0.6597,\n",
       "            0.659 , 0.6587, 0.658 , 0.655 , 0.654 , 0.653 , 0.646 , 0.645 ,\n",
       "            0.6416, 0.6064, 0.6035, 0.585 , 0.574 , 0.5654, 0.5615],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(1., dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.046875 , 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.1015625, 0.109375 , 0.1328125, 0.1328125,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.1640625, 0.1640625, 0.171875 ,\n",
       "            0.1796875, 0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.2109375, 0.2109375, 0.21875  , 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.2421875, 0.2421875, 0.2421875, 0.25     , 0.265625 ,\n",
       "            0.28125  , 0.28125  , 0.28125  , 0.2890625, 0.3046875, 0.3125   ,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.3671875, 0.3671875, 0.3671875, 0.375    , 0.3828125,\n",
       "            0.3828125, 0.390625 , 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.4140625, 0.4140625, 0.421875 , 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.4765625, 0.4765625,\n",
       "            0.4765625, 0.4765625, 0.4765625, 0.4765625, 0.4765625, 0.4765625,\n",
       "            0.4765625, 0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5      , 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.19672132, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.25409836, 0.26229507, 0.26229507, 0.2704918 , 0.2704918 ,\n",
       "            0.27868852, 0.27868852, 0.28688523, 0.29508197, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.32786885,\n",
       "            0.32786885, 0.33606556, 0.33606556, 0.33606556, 0.3442623 ,\n",
       "            0.3442623 , 0.3442623 , 0.3442623 , 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36065573, 0.37704918, 0.37704918, 0.37704918,\n",
       "            0.37704918, 0.3852459 , 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.4918033 , 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.52459013, 0.5327869 , 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.55737704, 0.55737704, 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.58196723, 0.59016395, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.63114756, 0.6393443 , 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.704918  , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.77868855, 0.78688526, 0.8032787 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.974 , 0.9727, 0.97  , 0.9683, 0.966 , 0.9634, 0.963 ,\n",
       "            0.959 , 0.952 , 0.9517, 0.951 , 0.9473, 0.946 , 0.945 , 0.9424,\n",
       "            0.942 , 0.9395, 0.939 , 0.938 , 0.9375, 0.936 , 0.9355, 0.9346,\n",
       "            0.9336, 0.9326, 0.932 , 0.9316, 0.93  , 0.9297, 0.9287, 0.928 ,\n",
       "            0.9272, 0.9263, 0.926 , 0.925 , 0.9233, 0.923 , 0.9224, 0.922 ,\n",
       "            0.9214, 0.921 , 0.92  , 0.9194, 0.9185, 0.918 , 0.9175, 0.917 ,\n",
       "            0.9165, 0.916 , 0.9155, 0.915 , 0.9146, 0.9136, 0.913 , 0.9126,\n",
       "            0.912 , 0.9116, 0.911 , 0.9106, 0.91  , 0.9097, 0.908 , 0.9077,\n",
       "            0.907 , 0.906 , 0.9053, 0.905 , 0.9023, 0.902 , 0.9014, 0.901 ,\n",
       "            0.9004, 0.9   , 0.8994, 0.899 , 0.8984, 0.8975, 0.8965, 0.896 ,\n",
       "            0.894 , 0.893 , 0.892 , 0.8916, 0.891 , 0.8906, 0.8887, 0.888 ,\n",
       "            0.887 , 0.886 , 0.8857, 0.8853, 0.8843, 0.884 , 0.883 , 0.8813,\n",
       "            0.881 , 0.88  , 0.8794, 0.8784, 0.878 , 0.8755, 0.8745, 0.874 ,\n",
       "            0.8735, 0.873 , 0.8726, 0.8716, 0.8687, 0.867 , 0.866 , 0.8657,\n",
       "            0.865 , 0.8643, 0.863 , 0.8623, 0.861 , 0.8594, 0.8584, 0.856 ,\n",
       "            0.8535, 0.852 , 0.851 , 0.849 , 0.848 , 0.847 , 0.8433, 0.8403,\n",
       "            0.837 , 0.8354, 0.8345, 0.831 , 0.8296, 0.8247, 0.824 , 0.818 ,\n",
       "            0.8174, 0.8057, 0.8047, 0.803 , 0.8003, 0.8   , 0.7964, 0.7954,\n",
       "            0.794 , 0.7886, 0.785 , 0.784 , 0.7695, 0.766 , 0.765 , 0.764 ,\n",
       "            0.763 , 0.7617, 0.7515, 0.751 , 0.7495, 0.745 , 0.7446, 0.7427,\n",
       "            0.7354, 0.7324, 0.7305, 0.73  , 0.72  , 0.717 , 0.716 , 0.7095,\n",
       "            0.706 , 0.701 , 0.6924, 0.686 , 0.685 , 0.684 , 0.678 , 0.673 ,\n",
       "            0.67  , 0.6665, 0.665 , 0.662 , 0.6567, 0.656 , 0.6543, 0.6533,\n",
       "            0.651 , 0.6504, 0.639 , 0.6333, 0.6304, 0.6265, 0.608 , 0.592 ,\n",
       "            0.5796, 0.568 , 0.5464, 0.543 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(1., dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.0859375, 0.09375  ,\n",
       "            0.09375  , 0.1015625, 0.1015625, 0.125    , 0.125    , 0.1328125,\n",
       "            0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.1640625, 0.171875 ,\n",
       "            0.1796875, 0.1796875, 0.1875   , 0.203125 , 0.203125 , 0.2109375,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.2421875, 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.359375 , 0.375    , 0.375    , 0.375    , 0.390625 ,\n",
       "            0.3984375, 0.3984375, 0.40625  , 0.4140625, 0.4140625, 0.421875 ,\n",
       "            0.421875 , 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.16393442, 0.18032786,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22950819, 0.23770492,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.28688523, 0.29508197,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45081967, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.4918033 , 0.5       , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.59016395, 0.59016395, 0.59836066, 0.59836066,\n",
       "            0.60655737, 0.60655737, 0.63114756, 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6639344 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6885246 , 0.72131145,\n",
       "            0.72131145, 0.72131145, 0.72131145, 0.7295082 , 0.7295082 ,\n",
       "            0.7295082 , 0.7295082 , 0.73770493, 0.74590164, 0.74590164,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.74590164, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.8442623 , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9756, 0.971 , 0.9707, 0.9688, 0.9653, 0.9644, 0.964 ,\n",
       "            0.9634, 0.9526, 0.952 , 0.9478, 0.947 , 0.9463, 0.945 , 0.941 ,\n",
       "            0.9365, 0.9346, 0.934 , 0.933 , 0.9326, 0.9297, 0.9277, 0.927 ,\n",
       "            0.9243, 0.924 , 0.9224, 0.9214, 0.9204, 0.92  , 0.9194, 0.919 ,\n",
       "            0.918 , 0.9175, 0.917 , 0.916 , 0.9155, 0.915 , 0.9146, 0.9136,\n",
       "            0.9126, 0.911 , 0.9106, 0.9097, 0.909 , 0.9087, 0.907 , 0.906 ,\n",
       "            0.905 , 0.904 , 0.903 , 0.9023, 0.902 , 0.901 , 0.9004, 0.9   ,\n",
       "            0.899 , 0.8975, 0.897 , 0.896 , 0.8955, 0.895 , 0.893 , 0.8926,\n",
       "            0.8916, 0.891 , 0.8906, 0.888 , 0.8877, 0.887 , 0.886 , 0.8853,\n",
       "            0.8843, 0.883 , 0.882 , 0.8813, 0.88  , 0.8794, 0.879 , 0.8784,\n",
       "            0.878 , 0.8774, 0.877 , 0.8765, 0.876 , 0.8755, 0.8745, 0.874 ,\n",
       "            0.873 , 0.8726, 0.871 , 0.869 , 0.8687, 0.868 , 0.8667, 0.8657,\n",
       "            0.8647, 0.863 , 0.8623, 0.8613, 0.861 , 0.8604, 0.8594, 0.859 ,\n",
       "            0.858 , 0.8574, 0.857 , 0.8564, 0.856 , 0.855 , 0.8545, 0.852 ,\n",
       "            0.8516, 0.851 , 0.8506, 0.8496, 0.848 , 0.847 , 0.8467, 0.844 ,\n",
       "            0.8438, 0.8423, 0.8403, 0.84  , 0.8335, 0.8325, 0.832 , 0.8296,\n",
       "            0.8286, 0.8276, 0.826 , 0.825 , 0.823 , 0.8228, 0.814 , 0.813 ,\n",
       "            0.811 , 0.8086, 0.808 , 0.8066, 0.8003, 0.7993, 0.791 , 0.788 ,\n",
       "            0.7803, 0.7705, 0.7695, 0.7676, 0.7666, 0.765 , 0.7637, 0.7607,\n",
       "            0.7495, 0.747 , 0.741 , 0.7383, 0.735 , 0.734 , 0.7334, 0.723 ,\n",
       "            0.7217, 0.717 , 0.7163, 0.7124, 0.708 , 0.7036, 0.701 , 0.69  ,\n",
       "            0.687 , 0.6816, 0.6772, 0.6733, 0.6675, 0.666 , 0.659 , 0.6577,\n",
       "            0.6523, 0.6494, 0.645 , 0.641 , 0.6396, 0.635 , 0.634 , 0.6333,\n",
       "            0.6313, 0.626 , 0.6255, 0.6113, 0.606 , 0.6035, 0.603 , 0.5986,\n",
       "            0.5947, 0.5605, 0.558 , 0.5454, 0.5107, 0.5083], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.984375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.046875 , 0.0546875,\n",
       "            0.0546875, 0.0625   , 0.0625   , 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.0859375, 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.1171875, 0.1171875, 0.125    , 0.1328125,\n",
       "            0.1328125, 0.140625 , 0.140625 , 0.1484375, 0.15625  , 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1875   , 0.1953125,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.28125  , 0.2890625, 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.484375 , 0.5      , 0.5078125, 0.515625 , 0.5390625, 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.578125 , 0.578125 , 0.5859375,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6875   , 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.18032786, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22950819, 0.23770492, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.3442623 , 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.45081967,\n",
       "            0.45901638, 0.47540984, 0.48360655, 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.977 , 0.9736, 0.9717, 0.9697, 0.9673, 0.965 , 0.964 ,\n",
       "            0.962 , 0.9585, 0.9536, 0.95  , 0.945 , 0.944 , 0.943 , 0.942 ,\n",
       "            0.941 , 0.9395, 0.938 , 0.9336, 0.9326, 0.9316, 0.9297, 0.928 ,\n",
       "            0.9272, 0.9253, 0.925 , 0.9243, 0.924 , 0.9233, 0.923 , 0.9224,\n",
       "            0.922 , 0.921 , 0.92  , 0.9175, 0.917 , 0.9165, 0.914 , 0.913 ,\n",
       "            0.9087, 0.908 , 0.9077, 0.906 , 0.9043, 0.904 , 0.902 , 0.901 ,\n",
       "            0.9004, 0.8984, 0.897 , 0.8955, 0.895 , 0.8945, 0.894 , 0.892 ,\n",
       "            0.889 , 0.8887, 0.887 , 0.886 , 0.8843, 0.884 , 0.883 , 0.8823,\n",
       "            0.882 , 0.8804, 0.88  , 0.8794, 0.879 , 0.878 , 0.877 , 0.876 ,\n",
       "            0.8755, 0.875 , 0.8745, 0.874 , 0.8735, 0.871 , 0.8706, 0.8687,\n",
       "            0.8677, 0.8657, 0.8623, 0.861 , 0.8594, 0.858 , 0.8555, 0.854 ,\n",
       "            0.853 , 0.8525, 0.852 , 0.8516, 0.848 , 0.8467, 0.8457, 0.8438,\n",
       "            0.843 , 0.841 , 0.8403, 0.8394, 0.839 , 0.8374, 0.837 , 0.8364,\n",
       "            0.836 , 0.8354, 0.8345, 0.831 , 0.83  , 0.829 , 0.827 , 0.8267,\n",
       "            0.825 , 0.8237, 0.8223, 0.8213, 0.8203, 0.82  , 0.8193, 0.8184,\n",
       "            0.817 , 0.816 , 0.815 , 0.8145, 0.813 , 0.8105, 0.809 , 0.806 ,\n",
       "            0.8057, 0.804 , 0.8037, 0.8027, 0.802 , 0.8013, 0.801 , 0.8003,\n",
       "            0.799 , 0.7983, 0.7974, 0.797 , 0.7954, 0.794 , 0.793 , 0.792 ,\n",
       "            0.7915, 0.791 , 0.7905, 0.7896, 0.7886, 0.7876, 0.787 , 0.7847,\n",
       "            0.7812, 0.781 , 0.7803, 0.777 , 0.776 , 0.774 , 0.7734, 0.77  ,\n",
       "            0.7656, 0.7646, 0.764 , 0.7563, 0.7524, 0.7437, 0.7417, 0.7407,\n",
       "            0.736 , 0.7324, 0.73  , 0.728 , 0.7246, 0.715 , 0.711 , 0.7104,\n",
       "            0.7046, 0.6963, 0.695 , 0.69  , 0.687 , 0.6772, 0.6665, 0.6636,\n",
       "            0.6577, 0.6567, 0.648 , 0.6475, 0.647 , 0.641 , 0.6396, 0.632 ,\n",
       "            0.629 , 0.6274, 0.6245, 0.6143, 0.6113, 0.6104, 0.606 , 0.602 ,\n",
       "            0.596 , 0.5957, 0.58  , 0.579 , 0.574 , 0.5713, 0.569 , 0.537 ,\n",
       "            0.525 , 0.5234, 0.4712], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9765625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.046875 , 0.0546875, 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.1015625,\n",
       "            0.1015625, 0.1015625, 0.1015625, 0.109375 , 0.109375 , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.1328125, 0.140625 , 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1796875, 0.1953125, 0.203125 ,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.21875  , 0.2265625, 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.2890625, 0.296875 ,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.359375 , 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.3828125, 0.3984375, 0.4140625, 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.515625 , 0.53125  , 0.5390625, 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.59375  , 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.28688523, 0.29508197, 0.30327868, 0.31967214,\n",
       "            0.32786885, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.47540984, 0.48360655, 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.74590164, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.852459  , 0.852459  , 0.852459  , 0.852459  , 0.852459  ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9805, 0.978 , 0.971 , 0.9688, 0.9683, 0.968 , 0.966 ,\n",
       "            0.9634, 0.958 , 0.9565, 0.9497, 0.949 , 0.946 , 0.9453, 0.944 ,\n",
       "            0.9434, 0.9424, 0.942 , 0.94  , 0.939 , 0.938 , 0.9375, 0.9365,\n",
       "            0.936 , 0.9326, 0.932 , 0.9307, 0.93  , 0.929 , 0.9287, 0.928 ,\n",
       "            0.9253, 0.9243, 0.924 , 0.922 , 0.9214, 0.921 , 0.9204, 0.9194,\n",
       "            0.918 , 0.917 , 0.9165, 0.9155, 0.9146, 0.912 , 0.9116, 0.911 ,\n",
       "            0.91  , 0.908 , 0.9077, 0.906 , 0.9053, 0.902 , 0.9   , 0.8984,\n",
       "            0.8975, 0.8965, 0.895 , 0.893 , 0.8916, 0.8887, 0.888 , 0.887 ,\n",
       "            0.8867, 0.886 , 0.885 , 0.8833, 0.8813, 0.8804, 0.88  , 0.8784,\n",
       "            0.877 , 0.8765, 0.8677, 0.866 , 0.8657, 0.863 , 0.8623, 0.8613,\n",
       "            0.86  , 0.858 , 0.8574, 0.855 , 0.8516, 0.851 , 0.849 , 0.848 ,\n",
       "            0.8477, 0.8447, 0.844 , 0.8438, 0.8403, 0.839 , 0.8374, 0.8345,\n",
       "            0.8335, 0.833 , 0.829 , 0.8286, 0.8276, 0.8237, 0.823 , 0.822 ,\n",
       "            0.82  , 0.8174, 0.815 , 0.8145, 0.8135, 0.8105, 0.8027, 0.7993,\n",
       "            0.798 , 0.795 , 0.794 , 0.793 , 0.792 , 0.7915, 0.79  , 0.7896,\n",
       "            0.786 , 0.7856, 0.782 , 0.7817, 0.779 , 0.7783, 0.777 , 0.776 ,\n",
       "            0.7744, 0.7734, 0.769 , 0.7666, 0.7646, 0.762 , 0.7583, 0.758 ,\n",
       "            0.7573, 0.755 , 0.754 , 0.752 , 0.7476, 0.743 , 0.742 , 0.7393,\n",
       "            0.739 , 0.7363, 0.7354, 0.734 , 0.7334, 0.733 , 0.7314, 0.731 ,\n",
       "            0.7256, 0.724 , 0.7236, 0.7227, 0.722 , 0.7217, 0.7207, 0.72  ,\n",
       "            0.7197, 0.719 , 0.718 , 0.717 , 0.7163, 0.716 , 0.7153, 0.7144,\n",
       "            0.714 , 0.7134, 0.7085, 0.7056, 0.704 , 0.7007, 0.695 , 0.693 ,\n",
       "            0.691 , 0.686 , 0.682 , 0.6807, 0.6685, 0.658 , 0.648 , 0.645 ,\n",
       "            0.6416, 0.638 , 0.636 , 0.634 , 0.625 , 0.621 , 0.6187, 0.615 ,\n",
       "            0.6104, 0.604 , 0.6006, 0.5913, 0.5894, 0.587 , 0.582 , 0.5796,\n",
       "            0.576 , 0.57  , 0.5674, 0.5522, 0.5454, 0.543 , 0.542 , 0.5195,\n",
       "            0.506 , 0.492 , 0.4375, 0.4348], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9609375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.0859375,\n",
       "            0.0859375, 0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.1328125, 0.1328125, 0.140625 , 0.1484375, 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2265625, 0.234375 , 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5625   , 0.578125 ,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04918033, 0.06557377, 0.07377049, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.19672132,\n",
       "            0.20491803, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.32786885, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.6147541 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.8606557 , 0.8606557 , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.982 , 0.9814, 0.98  , 0.971 , 0.9697, 0.9688, 0.9624,\n",
       "            0.96  , 0.9575, 0.955 , 0.952 , 0.9517, 0.951 , 0.95  , 0.9487,\n",
       "            0.9463, 0.9434, 0.943 , 0.941 , 0.9395, 0.939 , 0.938 , 0.9375,\n",
       "            0.9365, 0.934 , 0.9316, 0.931 , 0.9307, 0.93  , 0.9287, 0.928 ,\n",
       "            0.9272, 0.9263, 0.9253, 0.923 , 0.922 , 0.9214, 0.921 , 0.9204,\n",
       "            0.919 , 0.918 , 0.9165, 0.916 , 0.9146, 0.914 , 0.9136, 0.9116,\n",
       "            0.9097, 0.909 , 0.905 , 0.904 , 0.902 , 0.9   , 0.8994, 0.8975,\n",
       "            0.8955, 0.89  , 0.888 , 0.8857, 0.8853, 0.885 , 0.8843, 0.8833,\n",
       "            0.8823, 0.882 , 0.8804, 0.879 , 0.8784, 0.875 , 0.874 , 0.8687,\n",
       "            0.8647, 0.863 , 0.8613, 0.861 , 0.859 , 0.8564, 0.855 , 0.8516,\n",
       "            0.85  , 0.8496, 0.848 , 0.846 , 0.8433, 0.843 , 0.8423, 0.839 ,\n",
       "            0.8374, 0.837 , 0.8335, 0.832 , 0.83  , 0.8267, 0.823 , 0.8223,\n",
       "            0.8164, 0.807 , 0.805 , 0.8047, 0.8037, 0.803 , 0.8027, 0.8022,\n",
       "            0.8013, 0.7944, 0.7915, 0.7886, 0.778 , 0.772 , 0.7705, 0.77  ,\n",
       "            0.768 , 0.7637, 0.7627, 0.758 , 0.7563, 0.754 , 0.7485, 0.7476,\n",
       "            0.747 , 0.745 , 0.7437, 0.7427, 0.7417, 0.741 , 0.74  , 0.7354,\n",
       "            0.734 , 0.7334, 0.733 , 0.73  , 0.729 , 0.7246, 0.722 , 0.721 ,\n",
       "            0.7197, 0.7163, 0.7134, 0.7046, 0.7036, 0.7026, 0.6997, 0.699 ,\n",
       "            0.6973, 0.695 , 0.69  , 0.6875, 0.6807, 0.679 , 0.6777, 0.6763,\n",
       "            0.6753, 0.6743, 0.674 , 0.672 , 0.6714, 0.671 , 0.67  , 0.668 ,\n",
       "            0.6675, 0.6655, 0.664 , 0.661 , 0.659 , 0.6567, 0.655 , 0.654 ,\n",
       "            0.65  , 0.647 , 0.6455, 0.6445, 0.6436, 0.641 , 0.64  , 0.6396,\n",
       "            0.6377, 0.632 , 0.631 , 0.629 , 0.627 , 0.6265, 0.6255, 0.624 ,\n",
       "            0.6216, 0.621 , 0.6206, 0.62  , 0.6187, 0.618 , 0.6157, 0.6147,\n",
       "            0.613 , 0.6123, 0.6094, 0.5977, 0.5938, 0.5913, 0.5825, 0.5728,\n",
       "            0.569 , 0.563 , 0.5566, 0.555 , 0.5527, 0.552 , 0.547 , 0.543 ,\n",
       "            0.5366, 0.536 , 0.517 , 0.5103, 0.5083, 0.5073, 0.507 , 0.5   ,\n",
       "            0.4866, 0.454 , 0.4014, 0.3977], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8828125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.078125 , 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.1171875,\n",
       "            0.125    , 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.1640625,\n",
       "            0.1640625, 0.171875 , 0.171875 , 0.1796875, 0.1875   , 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.234375 , 0.234375 ,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3203125, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.484375 , 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.703125 , 0.7109375, 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.1557377 , 0.16393442, 0.18032786,\n",
       "            0.18852459, 0.20491803, 0.21311475, 0.22131148, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.27868852, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.33606556, 0.3442623 , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.4918033 , 0.5081967 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6229508 , 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90983605, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.985 , 0.9844, 0.983 , 0.9746, 0.972 , 0.971 , 0.9697,\n",
       "            0.967 , 0.965 , 0.9644, 0.9634, 0.963 , 0.962 , 0.9595, 0.956 ,\n",
       "            0.954 , 0.953 , 0.9526, 0.9478, 0.9463, 0.9443, 0.943 , 0.9424,\n",
       "            0.9404, 0.937 , 0.936 , 0.9355, 0.9346, 0.9336, 0.933 , 0.932 ,\n",
       "            0.9316, 0.9307, 0.928 , 0.9277, 0.9272, 0.926 , 0.925 , 0.9243,\n",
       "            0.923 , 0.921 , 0.92  , 0.917 , 0.9165, 0.9155, 0.914 , 0.913 ,\n",
       "            0.912 , 0.9116, 0.9097, 0.907 , 0.9062, 0.9043, 0.9004, 0.9   ,\n",
       "            0.89  , 0.888 , 0.887 , 0.8853, 0.8833, 0.882 , 0.8794, 0.8774,\n",
       "            0.874 , 0.873 , 0.872 , 0.8716, 0.868 , 0.8677, 0.8667, 0.8657,\n",
       "            0.8647, 0.863 , 0.862 , 0.8604, 0.86  , 0.8516, 0.8506, 0.847 ,\n",
       "            0.8438, 0.8423, 0.842 , 0.84  , 0.8384, 0.8335, 0.833 , 0.832 ,\n",
       "            0.8276, 0.8247, 0.8223, 0.8213, 0.821 , 0.817 , 0.8164, 0.8105,\n",
       "            0.8096, 0.807 , 0.8047, 0.79  , 0.789 , 0.787 , 0.782 , 0.7725,\n",
       "            0.7646, 0.761 , 0.7583, 0.752 , 0.7515, 0.7505, 0.7476, 0.744 ,\n",
       "            0.7437, 0.737 , 0.7324, 0.726 , 0.7227, 0.721 , 0.7153, 0.712 ,\n",
       "            0.7114, 0.709 , 0.7075, 0.706 , 0.7056, 0.703 , 0.702 , 0.698 ,\n",
       "            0.695 , 0.6885, 0.686 , 0.6855, 0.6846, 0.684 , 0.682 , 0.6777,\n",
       "            0.6763, 0.676 , 0.6753, 0.673 , 0.6724, 0.671 , 0.6704, 0.6646,\n",
       "            0.6626, 0.662 , 0.661 , 0.656 , 0.6553, 0.651 , 0.65  , 0.6494,\n",
       "            0.6484, 0.64  , 0.639 , 0.6265, 0.6177, 0.6147, 0.6143, 0.6104,\n",
       "            0.602 , 0.5977, 0.596 , 0.5957, 0.5938, 0.5933, 0.593 , 0.591 ,\n",
       "            0.5894, 0.5845, 0.5825, 0.578 , 0.5767, 0.5723, 0.57  , 0.5674,\n",
       "            0.565 , 0.5645, 0.563 , 0.5625, 0.561 , 0.556 , 0.5527, 0.55  ,\n",
       "            0.547 , 0.546 , 0.543 , 0.54  , 0.5376, 0.537 , 0.536 , 0.535 ,\n",
       "            0.5327, 0.532 , 0.5317, 0.52  , 0.5195, 0.519 , 0.5156, 0.514 ,\n",
       "            0.5107, 0.5103, 0.5083, 0.505 , 0.4983, 0.4978, 0.4976, 0.4932,\n",
       "            0.4915, 0.4788, 0.4773, 0.47  , 0.4685, 0.468 , 0.4666, 0.465 ,\n",
       "            0.4106, 0.361 , 0.3564], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6796875, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.046875 , 0.0546875,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0546875, 0.0546875, 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.1171875, 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.171875 , 0.1796875, 0.1875   , 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.21875  , 0.2265625, 0.234375 , 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.05737705, 0.07377049, 0.08196721, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.27868852, 0.28688523, 0.30327868, 0.3114754 ,\n",
       "            0.33606556, 0.3442623 , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.5081967 , 0.5163934 , 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.989 , 0.988 , 0.987 , 0.9795, 0.9766, 0.976 , 0.9736,\n",
       "            0.972 , 0.97  , 0.969 , 0.9683, 0.968 , 0.9653, 0.9624, 0.9604,\n",
       "            0.96  , 0.9595, 0.959 , 0.955 , 0.954 , 0.9526, 0.9517, 0.9497,\n",
       "            0.9487, 0.9478, 0.9463, 0.945 , 0.9443, 0.944 , 0.943 , 0.9424,\n",
       "            0.9414, 0.941 , 0.9404, 0.9395, 0.9385, 0.938 , 0.9365, 0.9346,\n",
       "            0.934 , 0.932 , 0.9307, 0.9297, 0.929 , 0.9272, 0.9253, 0.9243,\n",
       "            0.922 , 0.9214, 0.9194, 0.917 , 0.9165, 0.915 , 0.914 , 0.912 ,\n",
       "            0.91  , 0.9087, 0.9023, 0.8965, 0.895 , 0.8926, 0.891 , 0.887 ,\n",
       "            0.886 , 0.8853, 0.885 , 0.8823, 0.8813, 0.88  , 0.877 , 0.875 ,\n",
       "            0.8726, 0.872 , 0.8716, 0.8706, 0.869 , 0.866 , 0.865 , 0.8643,\n",
       "            0.8633, 0.8604, 0.8555, 0.8525, 0.846 , 0.845 , 0.8438, 0.8423,\n",
       "            0.8384, 0.836 , 0.834 , 0.832 , 0.83  , 0.8296, 0.8223, 0.822 ,\n",
       "            0.8213, 0.817 , 0.816 , 0.812 , 0.806 , 0.8013, 0.793 , 0.784 ,\n",
       "            0.78  , 0.7793, 0.779 , 0.778 , 0.7603, 0.759 , 0.7583, 0.753 ,\n",
       "            0.7363, 0.7354, 0.7275, 0.723 , 0.721 , 0.7207, 0.712 , 0.707 ,\n",
       "            0.7007, 0.7   , 0.6997, 0.6973, 0.696 , 0.691 , 0.689 , 0.6816,\n",
       "            0.68  , 0.6787, 0.6753, 0.673 , 0.6685, 0.6655, 0.6606, 0.6577,\n",
       "            0.6553, 0.651 , 0.6494, 0.6484, 0.648 , 0.647 , 0.6455, 0.645 ,\n",
       "            0.6367, 0.6343, 0.6294, 0.629 , 0.6265, 0.625 , 0.6235, 0.623 ,\n",
       "            0.6187, 0.618 , 0.616 , 0.6157, 0.6133, 0.6074, 0.6016, 0.5947,\n",
       "            0.592 , 0.586 , 0.5757, 0.5737, 0.5713, 0.568 , 0.566 , 0.5615,\n",
       "            0.558 , 0.5513, 0.5474, 0.5435, 0.542 , 0.539 , 0.537 , 0.5356,\n",
       "            0.5347, 0.532 , 0.531 , 0.5303, 0.5215, 0.5166, 0.5137, 0.5103,\n",
       "            0.508 , 0.505 , 0.504 , 0.498 , 0.4963, 0.494 , 0.4905, 0.4895,\n",
       "            0.489 , 0.488 , 0.4866, 0.482 , 0.4773, 0.4734, 0.4731, 0.4702,\n",
       "            0.467 , 0.4668, 0.462 , 0.461 , 0.4607, 0.4602, 0.4578, 0.4563,\n",
       "            0.453 , 0.4426, 0.4392, 0.4377, 0.4348, 0.4338, 0.4321, 0.4307,\n",
       "            0.4277, 0.4265, 0.4258, 0.4226, 0.4219, 0.4038, 0.3994, 0.3987,\n",
       "            0.3699, 0.3237, 0.3162], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5703125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0546875,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.078125 ,\n",
       "            0.078125 , 0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.1171875, 0.1171875, 0.125    , 0.1328125,\n",
       "            0.1328125, 0.140625 , 0.15625  , 0.1640625, 0.171875 , 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.21875  , 0.2265625, 0.2421875, 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.3671875, 0.375    , 0.375    , 0.3828125, 0.3984375,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5703125, 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.28688523, 0.31967214, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.37704918, 0.39344263,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.78688526, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.991 , 0.9897, 0.989 , 0.983 , 0.98  , 0.9795, 0.979 ,\n",
       "            0.9785, 0.9766, 0.9756, 0.974 , 0.972 , 0.9717, 0.9707, 0.9673,\n",
       "            0.967 , 0.9644, 0.964 , 0.9634, 0.9604, 0.9595, 0.959 , 0.956 ,\n",
       "            0.954 , 0.953 , 0.9526, 0.951 , 0.9507, 0.95  , 0.9497, 0.9487,\n",
       "            0.9478, 0.9473, 0.9463, 0.9434, 0.9424, 0.942 , 0.941 , 0.939 ,\n",
       "            0.937 , 0.9355, 0.9326, 0.9316, 0.9287, 0.9277, 0.9253, 0.925 ,\n",
       "            0.923 , 0.921 , 0.92  , 0.919 , 0.918 , 0.914 , 0.913 , 0.9126,\n",
       "            0.907 , 0.903 , 0.9   , 0.899 , 0.8975, 0.8916, 0.89  , 0.8896,\n",
       "            0.889 , 0.888 , 0.886 , 0.8813, 0.88  , 0.878 , 0.877 , 0.874 ,\n",
       "            0.871 , 0.8706, 0.87  , 0.8633, 0.862 , 0.861 , 0.86  , 0.859 ,\n",
       "            0.858 , 0.8535, 0.849 , 0.843 , 0.8413, 0.841 , 0.8384, 0.838 ,\n",
       "            0.8345, 0.8315, 0.8296, 0.8257, 0.8223, 0.819 , 0.8145, 0.811 ,\n",
       "            0.8086, 0.808 , 0.806 , 0.797 , 0.7896, 0.7773, 0.7744, 0.772 ,\n",
       "            0.77  , 0.7603, 0.757 , 0.751 , 0.75  , 0.733 , 0.7275, 0.7246,\n",
       "            0.722 , 0.7207, 0.6973, 0.6963, 0.6943, 0.689 , 0.6797, 0.6777,\n",
       "            0.6753, 0.672 , 0.6694, 0.6646, 0.659 , 0.6587, 0.6562, 0.656 ,\n",
       "            0.6504, 0.646 , 0.643 , 0.6406, 0.6387, 0.636 , 0.63  , 0.626 ,\n",
       "            0.6255, 0.624 , 0.623 , 0.6216, 0.615 , 0.613 , 0.6113, 0.6074,\n",
       "            0.6064, 0.6045, 0.6   , 0.5967, 0.596 , 0.587 , 0.582 , 0.58  ,\n",
       "            0.5776, 0.575 , 0.5684, 0.566 , 0.5625, 0.5586, 0.545 , 0.544 ,\n",
       "            0.543 , 0.5415, 0.5396, 0.532 , 0.5273, 0.5176, 0.512 , 0.511 ,\n",
       "            0.5107, 0.5093, 0.501 , 0.4998, 0.4958, 0.4944, 0.4883, 0.4863,\n",
       "            0.4834, 0.4822, 0.4783, 0.4758, 0.4714, 0.4712, 0.4692, 0.4617,\n",
       "            0.4612, 0.4573, 0.4531, 0.4448, 0.4438, 0.4385, 0.437 , 0.4348,\n",
       "            0.4343, 0.4326, 0.4302, 0.4292, 0.4287, 0.423 , 0.4229, 0.4224,\n",
       "            0.4143, 0.408 , 0.4075, 0.4006, 0.4001, 0.3992, 0.395 , 0.3936,\n",
       "            0.3916, 0.391 , 0.39  , 0.3887, 0.3875, 0.3848, 0.3672, 0.3625,\n",
       "            0.3618, 0.3538, 0.3481, 0.3472, 0.3328, 0.3289, 0.3218, 0.321 ,\n",
       "            0.2927, 0.2795], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.0546875,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.078125 , 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.1328125, 0.140625 , 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.2421875, 0.2421875, 0.2421875, 0.25     , 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5      , 0.515625 , 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.23770492, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.29508197, 0.3114754 , 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.8770492 ,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9927, 0.991 , 0.9907, 0.985 , 0.9834, 0.9824, 0.982 ,\n",
       "            0.9814, 0.9805, 0.9785, 0.9766, 0.9756, 0.9746, 0.9727, 0.972 ,\n",
       "            0.97  , 0.9673, 0.967 , 0.9663, 0.9653, 0.9644, 0.962 , 0.959 ,\n",
       "            0.9585, 0.957 , 0.9565, 0.956 , 0.9546, 0.954 , 0.952 , 0.9517,\n",
       "            0.95  , 0.948 , 0.9463, 0.946 , 0.945 , 0.9443, 0.944 , 0.9434,\n",
       "            0.943 , 0.9414, 0.939 , 0.9355, 0.935 , 0.9346, 0.931 , 0.93  ,\n",
       "            0.929 , 0.928 , 0.9272, 0.9253, 0.9224, 0.9214, 0.92  , 0.917 ,\n",
       "            0.914 , 0.91  , 0.9077, 0.904 , 0.902 , 0.901 , 0.8965, 0.895 ,\n",
       "            0.893 , 0.8906, 0.89  , 0.8896, 0.8853, 0.883 , 0.882 , 0.8804,\n",
       "            0.877 , 0.8745, 0.8735, 0.869 , 0.868 , 0.8657, 0.8643, 0.861 ,\n",
       "            0.8584, 0.858 , 0.8574, 0.8564, 0.85  , 0.8496, 0.84  , 0.839 ,\n",
       "            0.8384, 0.835 , 0.8315, 0.831 , 0.8267, 0.823 , 0.817 , 0.813 ,\n",
       "            0.8125, 0.8086, 0.8022, 0.801 , 0.792 , 0.79  , 0.7666, 0.765 ,\n",
       "            0.764 , 0.7637, 0.762 , 0.7563, 0.7383, 0.733 , 0.7314, 0.7173,\n",
       "            0.717 , 0.716 , 0.715 , 0.7114, 0.6846, 0.68  , 0.6753, 0.6724,\n",
       "            0.671 , 0.6616, 0.659 , 0.656 , 0.647 , 0.6406, 0.639 , 0.6357,\n",
       "            0.6343, 0.629 , 0.6265, 0.626 , 0.6216, 0.618 , 0.615 , 0.6147,\n",
       "            0.6143, 0.6123, 0.603 , 0.601 , 0.5996, 0.5986, 0.597 , 0.5947,\n",
       "            0.589 , 0.585 , 0.584 , 0.582 , 0.5806, 0.574 , 0.572 , 0.568 ,\n",
       "            0.5674, 0.5664, 0.566 , 0.5566, 0.5527, 0.5425, 0.5396, 0.538 ,\n",
       "            0.5347, 0.533 , 0.53  , 0.5156, 0.514 , 0.5127, 0.5107, 0.51  ,\n",
       "            0.509 , 0.4924, 0.4841, 0.484 , 0.4832, 0.4792, 0.4778, 0.4712,\n",
       "            0.4707, 0.4583, 0.4553, 0.4504, 0.4478, 0.4468, 0.4443, 0.4436,\n",
       "            0.4414, 0.439 , 0.4329, 0.4314, 0.4307, 0.4224, 0.422 , 0.4172,\n",
       "            0.4148, 0.414 , 0.4055, 0.403 , 0.3984, 0.3962, 0.3923, 0.3894,\n",
       "            0.384 , 0.3835, 0.3826, 0.382 , 0.3774, 0.3728, 0.3604, 0.3591,\n",
       "            0.358 , 0.352 , 0.3516, 0.3513, 0.35  , 0.3477, 0.3442, 0.3423,\n",
       "            0.337 , 0.3328, 0.3271, 0.3157, 0.3071, 0.3037, 0.2998, 0.2969,\n",
       "            0.287 , 0.2866, 0.2676, 0.2654, 0.2627, 0.2622, 0.2483],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.4140625, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.0703125, 0.0703125, 0.0703125, 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.1171875, 0.125    , 0.125    , 0.1328125,\n",
       "            0.140625 , 0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.2265625, 0.234375 , 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.28125  , 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.625    , 0.6328125, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.40163934, 0.40983605,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5163934 , 0.52459013, 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6885246 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.993 , 0.9917, 0.987 , 0.9863, 0.9844, 0.9824, 0.982 ,\n",
       "            0.98  , 0.9785, 0.978 , 0.976 , 0.9756, 0.972 , 0.971 , 0.9697,\n",
       "            0.969 , 0.9683, 0.968 , 0.9663, 0.9644, 0.963 , 0.9624, 0.962 ,\n",
       "            0.9604, 0.96  , 0.9595, 0.957 , 0.955 , 0.954 , 0.9536, 0.953 ,\n",
       "            0.952 , 0.95  , 0.9487, 0.948 , 0.9463, 0.946 , 0.944 , 0.942 ,\n",
       "            0.94  , 0.9385, 0.9375, 0.9355, 0.934 , 0.9326, 0.932 , 0.929 ,\n",
       "            0.9272, 0.924 , 0.9194, 0.919 , 0.9146, 0.9136, 0.913 , 0.9126,\n",
       "            0.9087, 0.9077, 0.9067, 0.903 , 0.898 , 0.8965, 0.893 , 0.891 ,\n",
       "            0.8906, 0.888 , 0.886 , 0.8857, 0.8784, 0.877 , 0.8765, 0.8716,\n",
       "            0.87  , 0.8647, 0.8643, 0.863 , 0.858 , 0.857 , 0.855 , 0.851 ,\n",
       "            0.8467, 0.8457, 0.845 , 0.84  , 0.8384, 0.8354, 0.8306, 0.828 ,\n",
       "            0.827 , 0.8247, 0.816 , 0.813 , 0.809 , 0.8013, 0.7935, 0.7886,\n",
       "            0.783 , 0.7827, 0.7812, 0.778 , 0.758 , 0.755 , 0.7515, 0.7456,\n",
       "            0.741 , 0.7324, 0.72  , 0.7153, 0.713 , 0.706 , 0.704 , 0.7007,\n",
       "            0.6963, 0.6797, 0.677 , 0.661 , 0.651 , 0.633 , 0.624 , 0.622 ,\n",
       "            0.6216, 0.6187, 0.617 , 0.6123, 0.6104, 0.6045, 0.603 , 0.6006,\n",
       "            0.599 , 0.5938, 0.5913, 0.5884, 0.5825, 0.5815, 0.581 , 0.578 ,\n",
       "            0.5713, 0.5693, 0.569 , 0.564 , 0.5576, 0.556 , 0.5557, 0.552 ,\n",
       "            0.5513, 0.542 , 0.536 , 0.5327, 0.52  , 0.519 , 0.516 , 0.515 ,\n",
       "            0.5127, 0.509 , 0.494 , 0.488 , 0.4846, 0.4797, 0.4795, 0.4756,\n",
       "            0.4753, 0.4736, 0.4734, 0.4675, 0.4646, 0.4568, 0.4534, 0.4485,\n",
       "            0.446 , 0.4436, 0.4338, 0.4187, 0.4182, 0.4167, 0.403 , 0.4023,\n",
       "            0.4016, 0.3967, 0.3962, 0.3918, 0.3916, 0.3845, 0.3828, 0.381 ,\n",
       "            0.3809, 0.3748, 0.3684, 0.3672, 0.3652, 0.3638, 0.3606, 0.348 ,\n",
       "            0.3477, 0.3413, 0.3408, 0.3345, 0.329 , 0.3215, 0.3186, 0.3171,\n",
       "            0.3142, 0.312 , 0.311 , 0.3108, 0.3088, 0.3   , 0.2834, 0.2825,\n",
       "            0.2817, 0.2798, 0.2773, 0.2756, 0.27  , 0.2651, 0.2615, 0.2483,\n",
       "            0.2415, 0.2395, 0.2394, 0.2328, 0.2242, 0.2235, 0.2208, 0.2048,\n",
       "            0.1973, 0.1956], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3671875, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.0703125,\n",
       "            0.0703125, 0.0703125, 0.078125 , 0.078125 , 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.109375 , 0.1171875,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.203125 , 0.2109375, 0.21875  , 0.21875  ,\n",
       "            0.2265625, 0.2265625, 0.234375 , 0.2421875, 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.28125  , 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.08196721, 0.09016393,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.72131145,\n",
       "            0.7295082 , 0.7295082 , 0.74590164, 0.75409836, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.994 , 0.9927, 0.9897, 0.9893, 0.9873, 0.9844, 0.9834,\n",
       "            0.983 , 0.982 , 0.98  , 0.9795, 0.9775, 0.974 , 0.9736, 0.973 ,\n",
       "            0.97  , 0.9697, 0.9688, 0.9683, 0.968 , 0.9673, 0.967 , 0.9663,\n",
       "            0.966 , 0.9644, 0.962 , 0.9614, 0.961 , 0.96  , 0.9595, 0.959 ,\n",
       "            0.958 , 0.9575, 0.9565, 0.954 , 0.9536, 0.953 , 0.9526, 0.952 ,\n",
       "            0.95  , 0.9478, 0.9463, 0.946 , 0.944 , 0.943 , 0.9424, 0.9414,\n",
       "            0.937 , 0.9365, 0.9346, 0.934 , 0.9287, 0.926 , 0.9214, 0.921 ,\n",
       "            0.9204, 0.9194, 0.9185, 0.917 , 0.9155, 0.9146, 0.9126, 0.912 ,\n",
       "            0.91  , 0.908 , 0.903 , 0.9014, 0.8984, 0.898 , 0.8975, 0.8945,\n",
       "            0.8877, 0.886 , 0.8843, 0.8794, 0.8765, 0.876 , 0.8696, 0.869 ,\n",
       "            0.8687, 0.8667, 0.8555, 0.8525, 0.844 , 0.843 , 0.842 , 0.839 ,\n",
       "            0.8364, 0.8335, 0.8325, 0.8267, 0.8257, 0.8174, 0.8135, 0.802 ,\n",
       "            0.799 , 0.796 , 0.782 , 0.781 , 0.7773, 0.7744, 0.77  , 0.755 ,\n",
       "            0.752 , 0.7515, 0.7383, 0.734 , 0.719 , 0.7134, 0.7056, 0.703 ,\n",
       "            0.6987, 0.692 , 0.6885, 0.679 , 0.6787, 0.6597, 0.65  , 0.626 ,\n",
       "            0.615 , 0.606 , 0.6055, 0.6035, 0.602 , 0.5986, 0.595 , 0.5938,\n",
       "            0.585 , 0.5845, 0.579 , 0.574 , 0.5728, 0.5723, 0.571 , 0.5703,\n",
       "            0.5635, 0.557 , 0.5527, 0.5513, 0.549 , 0.545 , 0.5425, 0.542 ,\n",
       "            0.5405, 0.5376, 0.5303, 0.53  , 0.5195, 0.5103, 0.509 , 0.5063,\n",
       "            0.5005, 0.499 , 0.495 , 0.4934, 0.4849, 0.4832, 0.4783, 0.4622,\n",
       "            0.4565, 0.4543, 0.448 , 0.4463, 0.4456, 0.4434, 0.443 , 0.4397,\n",
       "            0.437 , 0.429 , 0.4275, 0.4248, 0.4155, 0.415 , 0.389 , 0.3813,\n",
       "            0.3801, 0.3792, 0.376 , 0.3708, 0.3694, 0.3684, 0.3667, 0.3596,\n",
       "            0.3586, 0.3557, 0.3535, 0.3503, 0.3496, 0.3477, 0.3442, 0.339 ,\n",
       "            0.3381, 0.3364, 0.3318, 0.3293, 0.3286, 0.3252, 0.314 , 0.3118,\n",
       "            0.305 , 0.3044, 0.3027, 0.2969, 0.2815, 0.28  , 0.2795, 0.2788,\n",
       "            0.2778, 0.2756, 0.2747, 0.2717, 0.2683, 0.2642, 0.2477, 0.2456,\n",
       "            0.2449, 0.2438, 0.2426, 0.2367, 0.2322, 0.2318, 0.2261, 0.2161,\n",
       "            0.2133, 0.2074, 0.2004, 0.1982, 0.1962, 0.1855, 0.1838, 0.1666,\n",
       "            0.1624, 0.1616], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3359375, dtype=float32),\n",
       "    'tpr': array(0.9836066, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.0703125, 0.0703125, 0.0703125,\n",
       "            0.0703125, 0.0703125, 0.078125 , 0.078125 , 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.1015625, 0.1015625, 0.109375 , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.2109375, 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.2265625, 0.234375 , 0.2421875, 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.20491803, 0.21311475, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.30327868, 0.3114754 , 0.31967214, 0.33606556,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.58196723,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9946, 0.993 , 0.9927, 0.991 , 0.9907, 0.9893, 0.988 ,\n",
       "            0.9854, 0.9844, 0.984 , 0.9824, 0.982 , 0.98  , 0.978 , 0.9766,\n",
       "            0.976 , 0.974 , 0.9736, 0.9727, 0.971 , 0.9707, 0.97  , 0.9697,\n",
       "            0.969 , 0.9688, 0.9653, 0.965 , 0.9644, 0.964 , 0.9624, 0.961 ,\n",
       "            0.96  , 0.9575, 0.957 , 0.9565, 0.9526, 0.9517, 0.949 , 0.9478,\n",
       "            0.947 , 0.9463, 0.946 , 0.9453, 0.9414, 0.94  , 0.9395, 0.937 ,\n",
       "            0.936 , 0.9336, 0.9272, 0.9243, 0.923 , 0.921 , 0.9194, 0.9185,\n",
       "            0.918 , 0.916 , 0.9155, 0.913 , 0.909 , 0.9053, 0.905 , 0.9033,\n",
       "            0.9014, 0.901 , 0.9004, 0.898 , 0.895 , 0.887 , 0.8853, 0.8823,\n",
       "            0.88  , 0.8784, 0.8726, 0.872 , 0.8706, 0.869 , 0.8633, 0.863 ,\n",
       "            0.856 , 0.8486, 0.845 , 0.842 , 0.8394, 0.838 , 0.836 , 0.8354,\n",
       "            0.833 , 0.8325, 0.827 , 0.819 , 0.816 , 0.8086, 0.8003, 0.798 ,\n",
       "            0.7915, 0.786 , 0.776 , 0.771 , 0.767 , 0.7627, 0.7573, 0.749 ,\n",
       "            0.746 , 0.745 , 0.7275, 0.7217, 0.707 , 0.7   , 0.694 , 0.6895,\n",
       "            0.6875, 0.6772, 0.672 , 0.6685, 0.657 , 0.6367, 0.6357, 0.601 ,\n",
       "            0.5938, 0.593 , 0.5874, 0.582 , 0.5767, 0.575 , 0.5747, 0.5664,\n",
       "            0.565 , 0.5645, 0.554 , 0.553 , 0.5527, 0.552 , 0.547 , 0.5444,\n",
       "            0.5435, 0.5312, 0.5293, 0.527 , 0.526 , 0.5254, 0.5225, 0.52  ,\n",
       "            0.518 , 0.5176, 0.516 , 0.5137, 0.506 , 0.504 , 0.4895, 0.487 ,\n",
       "            0.4824, 0.4785, 0.4731, 0.4724, 0.4663, 0.462 , 0.4521, 0.4504,\n",
       "            0.4448, 0.4377, 0.4316, 0.4229, 0.4185, 0.416 , 0.4136, 0.4124,\n",
       "            0.4092, 0.4048, 0.4045, 0.4033, 0.3982, 0.3928, 0.389 , 0.3875,\n",
       "            0.3772, 0.3628, 0.3555, 0.3513, 0.3499, 0.349 , 0.3398, 0.338 ,\n",
       "            0.3345, 0.3298, 0.3281, 0.3252, 0.3245, 0.324 , 0.319 , 0.3152,\n",
       "            0.3147, 0.3123, 0.307 , 0.306 , 0.3013, 0.301 , 0.299 , 0.2976,\n",
       "            0.29  , 0.2822, 0.281 , 0.2742, 0.2737, 0.2734, 0.267 , 0.252 ,\n",
       "            0.251 , 0.2482, 0.248 , 0.2451, 0.2413, 0.2397, 0.2352, 0.233 ,\n",
       "            0.2148, 0.2144, 0.2137, 0.2133, 0.2129, 0.2085, 0.207 , 0.2039,\n",
       "            0.1967, 0.1962, 0.1843, 0.1792, 0.1768, 0.1721, 0.17  , 0.1573,\n",
       "            0.1552, 0.1394, 0.1364, 0.1349], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.296875, dtype=float32),\n",
       "    'tpr': array(0.97540987, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.0390625, 0.046875 , 0.0546875, 0.0625   ,\n",
       "            0.0703125, 0.0703125, 0.0703125, 0.0703125, 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.1015625, 0.109375 , 0.109375 , 0.1171875, 0.125    , 0.1328125,\n",
       "            0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.2109375, 0.21875  , 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.19672132, 0.20491803, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.795082  , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.90983605, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.995 , 0.994 , 0.9937, 0.9927, 0.992 , 0.9907, 0.989 ,\n",
       "            0.987 , 0.986 , 0.985 , 0.9844, 0.983 , 0.9814, 0.9795, 0.979 ,\n",
       "            0.9785, 0.9756, 0.974 , 0.9736, 0.9727, 0.972 , 0.9717, 0.9707,\n",
       "            0.9683, 0.968 , 0.967 , 0.9663, 0.966 , 0.9653, 0.9634, 0.9624,\n",
       "            0.962 , 0.9604, 0.96  , 0.9595, 0.9585, 0.9536, 0.9526, 0.952 ,\n",
       "            0.951 , 0.9507, 0.949 , 0.948 , 0.9473, 0.9434, 0.9424, 0.9414,\n",
       "            0.94  , 0.938 , 0.935 , 0.929 , 0.9263, 0.926 , 0.924 , 0.9214,\n",
       "            0.921 , 0.9204, 0.92  , 0.919 , 0.9175, 0.9155, 0.914 , 0.909 ,\n",
       "            0.9077, 0.906 , 0.9053, 0.905 , 0.9033, 0.9014, 0.8945, 0.89  ,\n",
       "            0.886 , 0.883 , 0.881 , 0.8745, 0.872 , 0.871 , 0.8706, 0.862 ,\n",
       "            0.861 , 0.8574, 0.8467, 0.843 , 0.8403, 0.836 , 0.8335, 0.833 ,\n",
       "            0.8237, 0.817 , 0.8145, 0.8057, 0.796 , 0.7915, 0.7856, 0.78  ,\n",
       "            0.7725, 0.765 , 0.7617, 0.7563, 0.75  , 0.744 , 0.74  , 0.721 ,\n",
       "            0.715 , 0.7   , 0.688 , 0.684 , 0.682 , 0.6743, 0.6685, 0.663 ,\n",
       "            0.6494, 0.639 , 0.6235, 0.6216, 0.5796, 0.579 , 0.576 , 0.572 ,\n",
       "            0.566 , 0.56  , 0.559 , 0.5547, 0.549 , 0.546 , 0.545 , 0.5376,\n",
       "            0.534 , 0.5337, 0.5317, 0.5283, 0.526 , 0.52  , 0.509 , 0.5083,\n",
       "            0.507 , 0.505 , 0.5034, 0.5024, 0.5005, 0.4966, 0.4944, 0.4912,\n",
       "            0.4893, 0.4841, 0.4797, 0.4663, 0.463 , 0.4573, 0.4556, 0.4504,\n",
       "            0.4465, 0.4412, 0.4307, 0.4253, 0.425 , 0.4187, 0.417 , 0.4058,\n",
       "            0.3962, 0.3901, 0.3882, 0.3853, 0.3833, 0.381 , 0.3782, 0.3755,\n",
       "            0.3735, 0.3716, 0.3652, 0.3643, 0.3594, 0.3462, 0.3416, 0.3296,\n",
       "            0.3281, 0.3186, 0.3184, 0.3108, 0.3071, 0.3022, 0.2988, 0.297 ,\n",
       "            0.2969, 0.2952, 0.293 , 0.2886, 0.2842, 0.282 , 0.2803, 0.278 ,\n",
       "            0.2742, 0.2705, 0.27  , 0.2617, 0.256 , 0.252 , 0.2489, 0.2451,\n",
       "            0.2445, 0.2421, 0.2247, 0.2234, 0.2224, 0.2212, 0.2175, 0.2128,\n",
       "            0.211 , 0.2106, 0.205 , 0.1896, 0.1891, 0.1886, 0.187 , 0.1848,\n",
       "            0.1824, 0.1799, 0.1752, 0.1721, 0.161 , 0.1564, 0.1562, 0.1495,\n",
       "            0.1472, 0.1346, 0.1326, 0.1178, 0.1158, 0.115 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.234375, dtype=float32),\n",
       "    'tpr': array(0.97540987, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.0703125, 0.0703125, 0.0703125,\n",
       "            0.0703125, 0.0703125, 0.078125 , 0.078125 , 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.1015625, 0.109375 , 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.2109375, 0.21875  , 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.3359375, 0.34375  ,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.21311475, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.28688523, 0.29508197, 0.3114754 , 0.31967214, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.5327869 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.704918  , 0.72131145, 0.7295082 , 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9956 , 0.9946 , 0.994  , 0.993  , 0.9917 , 0.9897 ,\n",
       "            0.988  , 0.987  , 0.986  , 0.9854 , 0.984  , 0.9824 , 0.982  ,\n",
       "            0.9805 , 0.98   , 0.9795 , 0.9766 , 0.976  , 0.9756 , 0.975  ,\n",
       "            0.974  , 0.9736 , 0.973  , 0.9727 , 0.972  , 0.969  , 0.9688 ,\n",
       "            0.9683 , 0.9673 , 0.967  , 0.964  , 0.9634 , 0.962  , 0.961  ,\n",
       "            0.96   , 0.9595 , 0.954  , 0.9536 , 0.9526 , 0.9517 , 0.9507 ,\n",
       "            0.949  , 0.948  , 0.9443 , 0.943  , 0.942  , 0.941  , 0.939  ,\n",
       "            0.9355 , 0.929  , 0.9272 , 0.9263 , 0.924  , 0.922  , 0.9204 ,\n",
       "            0.9194 , 0.918  , 0.916  , 0.9136 , 0.9087 , 0.9077 , 0.906  ,\n",
       "            0.9053 , 0.9043 , 0.904  , 0.9033 , 0.902  , 0.893  , 0.89   ,\n",
       "            0.8853 , 0.881  , 0.8784 , 0.8745 , 0.8706 , 0.87   , 0.869  ,\n",
       "            0.8594 , 0.858  , 0.856  , 0.843  , 0.8403 , 0.839  , 0.838  ,\n",
       "            0.8325 , 0.831  , 0.8306 , 0.829  , 0.8286 , 0.818  , 0.8125 ,\n",
       "            0.8105 , 0.8086 , 0.798  , 0.791  , 0.7827 , 0.779  , 0.7725 ,\n",
       "            0.7646 , 0.757  , 0.7544 , 0.7476 , 0.7407 , 0.736  , 0.7314 ,\n",
       "            0.712  , 0.7046 , 0.69   , 0.6733 , 0.672  , 0.6714 , 0.66   ,\n",
       "            0.656  , 0.652  , 0.631  , 0.6143 , 0.6084 , 0.603  , 0.563  ,\n",
       "            0.558  , 0.555  , 0.553  , 0.5464 , 0.5405 , 0.54   , 0.5317 ,\n",
       "            0.53   , 0.526  , 0.5215 , 0.52   , 0.515  , 0.513  , 0.5063 ,\n",
       "            0.506  , 0.495  , 0.4888 , 0.4878 , 0.4844 , 0.4834 , 0.4824 ,\n",
       "            0.4797 , 0.479  , 0.4734 , 0.4727 , 0.4648 , 0.4631 , 0.4604 ,\n",
       "            0.4548 , 0.4456 , 0.4358 , 0.4336 , 0.429  , 0.4187 , 0.4158 ,\n",
       "            0.3975 , 0.3962 , 0.3953 , 0.395  , 0.3909 , 0.3787 , 0.3682 ,\n",
       "            0.3625 , 0.3616 , 0.3557 , 0.3552 , 0.3545 , 0.351  , 0.348  ,\n",
       "            0.3474 , 0.3418 , 0.3345 , 0.3315 , 0.321  , 0.314  , 0.308  ,\n",
       "            0.3066 , 0.2903 , 0.2898 , 0.2844 , 0.2795 , 0.2761 , 0.2756 ,\n",
       "            0.273  , 0.27   , 0.269  , 0.2666 , 0.2637 , 0.262  , 0.2563 ,\n",
       "            0.2546 , 0.2542 , 0.252  , 0.2507 , 0.2448 , 0.2429 , 0.2406 ,\n",
       "            0.2346 , 0.2302 , 0.2266 , 0.224  , 0.2194 , 0.2189 , 0.2173 ,\n",
       "            0.2024 , 0.2015 , 0.1982 , 0.1976 , 0.1973 , 0.1937 , 0.1885 ,\n",
       "            0.1864 , 0.1858 , 0.1794 , 0.1686 , 0.1665 , 0.1653 , 0.1649 ,\n",
       "            0.1627 , 0.161  , 0.1592 , 0.158  , 0.1511 , 0.1396 , 0.1357 ,\n",
       "            0.1304 , 0.1271 , 0.11676, 0.1134 , 0.0998 , 0.0981 , 0.0979 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.2109375, dtype=float32),\n",
       "    'tpr': array(0.9590164, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.0703125, 0.0703125, 0.0703125, 0.0703125, 0.0703125, 0.078125 ,\n",
       "            0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.109375 , 0.1171875, 0.125    , 0.125    , 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.2109375, 0.2109375, 0.21875  , 0.2265625, 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.2890625, 0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.4921875, 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.16393442, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.21311475, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.30327868, 0.3114754 , 0.31967214, 0.33606556,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.78688526, 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.8442623 , 0.8442623 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.996  , 0.995  , 0.994  , 0.9937 , 0.9927 , 0.99   ,\n",
       "            0.9893 , 0.988  , 0.9873 , 0.987  , 0.9854 , 0.984  , 0.9834 ,\n",
       "            0.982  , 0.9814 , 0.981  , 0.9785 , 0.978  , 0.977  , 0.976  ,\n",
       "            0.975  , 0.9746 , 0.974  , 0.9736 , 0.971  , 0.9707 , 0.9697 ,\n",
       "            0.969  , 0.9688 , 0.968  , 0.9653 , 0.9644 , 0.964  , 0.963  ,\n",
       "            0.962  , 0.9556 , 0.955  , 0.9546 , 0.9536 , 0.953  , 0.9517 ,\n",
       "            0.9507 , 0.95   , 0.9463 , 0.944  , 0.9434 , 0.9424 , 0.9414 ,\n",
       "            0.938  , 0.9316 , 0.929  , 0.928  , 0.9243 , 0.924  , 0.9233 ,\n",
       "            0.9224 , 0.9214 , 0.9204 , 0.917  , 0.9155 , 0.908  , 0.9077 ,\n",
       "            0.907  , 0.9067 , 0.9062 , 0.9053 , 0.9043 , 0.9033 , 0.8926 ,\n",
       "            0.891  , 0.8867 , 0.8813 , 0.8794 , 0.8774 , 0.875  , 0.8706 ,\n",
       "            0.8687 , 0.868  , 0.8677 , 0.86   , 0.855  , 0.8545 , 0.843  ,\n",
       "            0.839  , 0.8384 , 0.837  , 0.832  , 0.8296 , 0.8286 , 0.828  ,\n",
       "            0.817  , 0.8115 , 0.8066 , 0.8037 , 0.7915 , 0.786  , 0.771  ,\n",
       "            0.7705 , 0.765  , 0.7583 , 0.753  , 0.75   , 0.743  , 0.736  ,\n",
       "            0.728  , 0.7236 , 0.7227 , 0.706  , 0.698  , 0.679  , 0.665  ,\n",
       "            0.661  , 0.6587 , 0.6445 , 0.6436 , 0.6396 , 0.608  , 0.5938 ,\n",
       "            0.5913 , 0.591  , 0.5464 , 0.5356 , 0.5347 , 0.533  , 0.5327 ,\n",
       "            0.526  , 0.5215 , 0.517  , 0.515  , 0.506  , 0.5044 , 0.502  ,\n",
       "            0.4976 , 0.4944 , 0.4907 , 0.4873 , 0.4805 , 0.4678 , 0.467  ,\n",
       "            0.4666 , 0.461  , 0.4604 , 0.4595 , 0.4573 , 0.4556 , 0.4548 ,\n",
       "            0.45   , 0.441  , 0.4404 , 0.4307 , 0.4285 , 0.4243 , 0.4094 ,\n",
       "            0.4087 , 0.4067 , 0.4053 , 0.3997 , 0.3892 , 0.378  , 0.3752 ,\n",
       "            0.3713 , 0.3665 , 0.361  , 0.3518 , 0.3481 , 0.334  , 0.3333 ,\n",
       "            0.3289 , 0.327  , 0.326  , 0.322  , 0.3206 , 0.3176 , 0.3113 ,\n",
       "            0.3057 , 0.303  , 0.2998 , 0.288  , 0.2832 , 0.2822 , 0.261  ,\n",
       "            0.2595 , 0.2578 , 0.257  , 0.2556 , 0.2534 , 0.2467 , 0.2441 ,\n",
       "            0.2421 , 0.2418 , 0.2346 , 0.2328 , 0.2269 , 0.2266 , 0.2261 ,\n",
       "            0.2255 , 0.2233 , 0.2186 , 0.2125 , 0.2109 , 0.2091 , 0.2051 ,\n",
       "            0.2006 , 0.1985 , 0.1935 , 0.1934 , 0.1812 , 0.1791 , 0.179  ,\n",
       "            0.1747 , 0.1725 , 0.1698 , 0.1686 , 0.1614 , 0.1559 , 0.1493 ,\n",
       "            0.1483 , 0.148  , 0.1478 , 0.1465 , 0.1459 , 0.1407 , 0.1404 ,\n",
       "            0.1399 , 0.1306 , 0.124  , 0.1229 , 0.1194 , 0.11316, 0.111  ,\n",
       "            0.0995 , 0.09534, 0.08417, 0.0836 , 0.08344], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1875, dtype=float32),\n",
       "    'tpr': array(0.94262296, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.0703125, 0.0703125, 0.0703125, 0.0703125, 0.0703125, 0.078125 ,\n",
       "            0.078125 , 0.078125 , 0.0859375, 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.1640625, 0.171875 , 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.2265625, 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.13934426, 0.14754099,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.33606556, 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6967213 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.73770493, 0.73770493, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.8442623 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.996  , 0.9956 , 0.995  , 0.9946 , 0.9937 , 0.9907 ,\n",
       "            0.99   , 0.989  , 0.988  , 0.986  , 0.9844 , 0.984  , 0.983  ,\n",
       "            0.9805 , 0.979  , 0.9785 , 0.978  , 0.9766 , 0.976  , 0.975  ,\n",
       "            0.9746 , 0.974  , 0.973  , 0.972  , 0.9717 , 0.971  , 0.9707 ,\n",
       "            0.9683 , 0.9673 , 0.9663 , 0.966  , 0.965  , 0.9624 , 0.958  ,\n",
       "            0.9575 , 0.9556 , 0.9546 , 0.954  , 0.952  , 0.951  , 0.95   ,\n",
       "            0.9463 , 0.946  , 0.9443 , 0.944  , 0.9424 , 0.942  , 0.938  ,\n",
       "            0.9316 , 0.928  , 0.9263 , 0.926  , 0.924  , 0.9224 , 0.9204 ,\n",
       "            0.92   , 0.919  , 0.9146 , 0.91   , 0.9087 , 0.908  , 0.9062 ,\n",
       "            0.906  , 0.905  , 0.893  , 0.8906 , 0.886  , 0.884  , 0.8774 ,\n",
       "            0.877  , 0.8716 , 0.869  , 0.8687 , 0.8657 , 0.856  , 0.8477 ,\n",
       "            0.839  , 0.8374 , 0.8335 , 0.83   , 0.8286 , 0.8276 , 0.823  ,\n",
       "            0.8228 , 0.81   , 0.807  , 0.8057 , 0.7974 , 0.7876 , 0.7847 ,\n",
       "            0.7607 , 0.757  , 0.756  , 0.7544 , 0.744  , 0.742  , 0.734  ,\n",
       "            0.725  , 0.7236 , 0.7188 , 0.718  , 0.697  , 0.6885 , 0.673  ,\n",
       "            0.654  , 0.65   , 0.6494 , 0.635  , 0.632  , 0.6284 , 0.5825 ,\n",
       "            0.5723 , 0.5713 , 0.534  , 0.5205 , 0.516  , 0.514  , 0.5093 ,\n",
       "            0.5073 , 0.4976 , 0.4944 , 0.488  , 0.4878 , 0.482  , 0.4788 ,\n",
       "            0.4783 , 0.4705 , 0.469  , 0.46   , 0.4512 , 0.4492 , 0.4438 ,\n",
       "            0.4434 , 0.4417 , 0.4402 , 0.4365 , 0.435  , 0.433  , 0.4314 ,\n",
       "            0.4204 , 0.4202 , 0.4065 , 0.4062 , 0.4048 , 0.3901 , 0.388  ,\n",
       "            0.386  , 0.38   , 0.3735 , 0.3655 , 0.358  , 0.3528 , 0.3455 ,\n",
       "            0.3428 , 0.3333 , 0.3303 , 0.3225 , 0.309  , 0.3079 , 0.3076 ,\n",
       "            0.3025 , 0.3013 , 0.301  , 0.2996 , 0.2988 , 0.291  , 0.2864 ,\n",
       "            0.2827 , 0.2825 , 0.2788 , 0.2715 , 0.2622 , 0.2588 , 0.236  ,\n",
       "            0.2356 , 0.2355 , 0.233  , 0.2318 , 0.2289 , 0.2244 , 0.2234 ,\n",
       "            0.2229 , 0.2194 , 0.2184 , 0.213  , 0.2081 , 0.2059 , 0.2029 ,\n",
       "            0.2021 , 0.2015 , 0.2002 , 0.197  , 0.1906 , 0.1896 , 0.1886 ,\n",
       "            0.1852 , 0.1797 , 0.1787 , 0.1725 , 0.1721 , 0.1624 , 0.1608 ,\n",
       "            0.1588 , 0.1555 , 0.1517 , 0.1506 , 0.1501 , 0.1422 , 0.1404 ,\n",
       "            0.1373 , 0.1315 , 0.1311 , 0.131  , 0.1293 , 0.1288 , 0.1268 ,\n",
       "            0.1265 , 0.1232 , 0.1229 , 0.1138 , 0.1093 , 0.1078 , 0.1034 ,\n",
       "            0.09827, 0.0957 , 0.08527, 0.08093, 0.07104, 0.0707 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1484375, dtype=float32),\n",
       "    'tpr': array(0.93442625, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0390625, 0.0390625, 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.0703125, 0.0703125, 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.078125 , 0.078125 , 0.078125 , 0.0859375, 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.171875 , 0.1875   , 0.1875   , 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.2109375, 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3125   ,\n",
       "            0.3203125, 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.515625 , 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.996  , 0.995  , 0.994  , 0.9907 , 0.9897 , 0.989  ,\n",
       "            0.9873 , 0.9863 , 0.984  , 0.9834 , 0.983  , 0.982  , 0.9814 ,\n",
       "            0.981  , 0.98   , 0.9785 , 0.9775 , 0.977  , 0.9766 , 0.9756 ,\n",
       "            0.9736 , 0.973  , 0.9727 , 0.972  , 0.9717 , 0.971  , 0.9673 ,\n",
       "            0.967  , 0.966  , 0.9653 , 0.9634 , 0.9614 , 0.959  , 0.9585 ,\n",
       "            0.958  , 0.9565 , 0.95   , 0.9497 , 0.948  , 0.9478 , 0.9463 ,\n",
       "            0.9453 , 0.944  , 0.941  , 0.9365 , 0.936  , 0.932  , 0.931  ,\n",
       "            0.9253 , 0.924  , 0.9233 , 0.9204 , 0.9185 , 0.916  , 0.914  ,\n",
       "            0.913  , 0.911  , 0.9097 , 0.9087 , 0.9077 , 0.907  , 0.906  ,\n",
       "            0.905  , 0.9043 , 0.895  , 0.8926 , 0.892  , 0.8823 , 0.88   ,\n",
       "            0.876  , 0.8755 , 0.873  , 0.8706 , 0.866  , 0.8657 , 0.8643 ,\n",
       "            0.852  , 0.8394 , 0.835  , 0.833  , 0.8296 , 0.826  , 0.824  ,\n",
       "            0.82   , 0.8135 , 0.81   , 0.803  , 0.8022 , 0.8003 , 0.79   ,\n",
       "            0.7866 , 0.779  , 0.7764 , 0.7437 , 0.737  , 0.733  , 0.726  ,\n",
       "            0.7188 , 0.718  , 0.7124 , 0.7075 , 0.707  , 0.6963 , 0.674  ,\n",
       "            0.6636 , 0.661  , 0.64   , 0.6357 , 0.6187 , 0.6167 , 0.6113 ,\n",
       "            0.5986 , 0.564  , 0.54   , 0.5396 , 0.532  , 0.517  , 0.4983 ,\n",
       "            0.4856 , 0.4854 , 0.4807 , 0.473  , 0.4678 , 0.4673 , 0.4666 ,\n",
       "            0.4583 , 0.4512 , 0.4446 , 0.441  , 0.4358 , 0.4348 , 0.4314 ,\n",
       "            0.4304 , 0.4265 , 0.4226 , 0.4204 , 0.4163 , 0.409  , 0.4067 ,\n",
       "            0.4053 , 0.4045 , 0.395  , 0.3945 , 0.3938 , 0.3833 , 0.374  ,\n",
       "            0.3723 , 0.3677 , 0.3635 , 0.3633 , 0.345  , 0.3384 , 0.3376 ,\n",
       "            0.3289 , 0.3123 , 0.3113 , 0.3037 , 0.3025 , 0.2969 , 0.2847 ,\n",
       "            0.2822 , 0.282  , 0.279  , 0.278  , 0.2742 , 0.2727 , 0.2722 ,\n",
       "            0.2693 , 0.264  , 0.259  , 0.2556 , 0.2534 , 0.2532 , 0.2413 ,\n",
       "            0.2283 , 0.2139 , 0.2103 , 0.2031 , 0.2023 , 0.2021 , 0.1982 ,\n",
       "            0.1954 , 0.1952 , 0.1946 , 0.194  , 0.1885 , 0.1864 , 0.1848 ,\n",
       "            0.1792 , 0.1781 , 0.1758 , 0.1733 , 0.1688 , 0.1652 , 0.165  ,\n",
       "            0.1617 , 0.1603 , 0.1597 , 0.1534 , 0.152  , 0.1519 , 0.1436 ,\n",
       "            0.1421 , 0.1385 , 0.1332 , 0.1326 , 0.1321 , 0.1288 , 0.1213 ,\n",
       "            0.1193 , 0.1172 , 0.1166 , 0.1128 , 0.1124 , 0.1103 , 0.1063 ,\n",
       "            0.1054 , 0.1047 , 0.10394, 0.10266, 0.09686, 0.09656, 0.0887 ,\n",
       "            0.0854 , 0.082  , 0.07806, 0.0707 , 0.06647, 0.0578 , 0.05737,\n",
       "            0.05676], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1484375, dtype=float32),\n",
       "    'tpr': array(0.93442625, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.078125 , 0.078125 , 0.0859375,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.1640625, 0.171875 , 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.10655738,\n",
       "            0.1147541 , 0.13114753, 0.13934426, 0.14754099, 0.16393442,\n",
       "            0.17213115, 0.18852459, 0.19672132, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.25409836, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.352459  , 0.36885247, 0.37704918, 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.7704918 , 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.996  , 0.9956 , 0.9946 , 0.991  , 0.99   , 0.9893 ,\n",
       "            0.9883 , 0.9873 , 0.985  , 0.9844 , 0.9834 , 0.9824 , 0.982  ,\n",
       "            0.981  , 0.98   , 0.9785 , 0.9775 , 0.977  , 0.975  , 0.974  ,\n",
       "            0.9736 , 0.9727 , 0.9717 , 0.9688 , 0.9683 , 0.967  , 0.9663 ,\n",
       "            0.9653 , 0.965  , 0.962  , 0.9604 , 0.96   , 0.9575 , 0.95   ,\n",
       "            0.9497 , 0.9487 , 0.948  , 0.9478 , 0.946  , 0.945  , 0.9424 ,\n",
       "            0.9395 , 0.9385 , 0.935  , 0.934  , 0.9336 , 0.9277 , 0.927  ,\n",
       "            0.9253 , 0.923  , 0.9185 , 0.918  , 0.9165 , 0.915  , 0.9106 ,\n",
       "            0.909  , 0.9087 , 0.907  , 0.9067 , 0.8955 , 0.894  , 0.8916 ,\n",
       "            0.883  , 0.878  , 0.8774 , 0.876  , 0.8677 , 0.8667 , 0.864  ,\n",
       "            0.862  , 0.8545 , 0.849  , 0.8423 , 0.8364 , 0.835  , 0.8257 ,\n",
       "            0.8228 , 0.8193 , 0.8164 , 0.812  , 0.8057 , 0.8047 , 0.7954 ,\n",
       "            0.7905 , 0.7896 , 0.7783 , 0.773  , 0.7725 , 0.744  , 0.723  ,\n",
       "            0.7227 , 0.7188 , 0.712  , 0.708  , 0.7065 , 0.706  , 0.7    ,\n",
       "            0.6973 , 0.672  , 0.662  , 0.6504 , 0.638  , 0.6245 , 0.6167 ,\n",
       "            0.612  , 0.602  , 0.581  , 0.5605 , 0.5386 , 0.531  , 0.5103 ,\n",
       "            0.5015 , 0.494  , 0.4805 , 0.4758 , 0.4702 , 0.468  , 0.4617 ,\n",
       "            0.4614 , 0.4502 , 0.4485 , 0.448  , 0.4414 , 0.4387 , 0.4338 ,\n",
       "            0.4294 , 0.4292 , 0.4258 , 0.412  , 0.4111 , 0.4104 , 0.406  ,\n",
       "            0.4053 , 0.4014 , 0.3916 , 0.3896 , 0.3833 , 0.3796 , 0.3787 ,\n",
       "            0.3777 , 0.3757 , 0.3677 , 0.3525 , 0.3477 , 0.346  , 0.3455 ,\n",
       "            0.3254 , 0.32   , 0.3176 , 0.3171 , 0.307  , 0.306  , 0.2993 ,\n",
       "            0.296  , 0.2917 , 0.2776 , 0.2664 , 0.2656 , 0.263  , 0.2622 ,\n",
       "            0.2593 , 0.2573 , 0.2505 , 0.2494 , 0.2471 , 0.2441 , 0.2355 ,\n",
       "            0.2335 , 0.2334 , 0.2229 , 0.2224 , 0.1968 , 0.1965 , 0.1964 ,\n",
       "            0.196  , 0.1913 , 0.1903 , 0.1893 , 0.1885 , 0.183  , 0.1787 ,\n",
       "            0.1749 , 0.1737 , 0.1707 , 0.1703 , 0.1643 , 0.1605 , 0.1598 ,\n",
       "            0.1592 , 0.1588 , 0.1586 , 0.1562 , 0.1542 , 0.1525 , 0.1477 ,\n",
       "            0.1433 , 0.1359 , 0.1357 , 0.1355 , 0.129  , 0.1284 , 0.12445,\n",
       "            0.12286, 0.118  , 0.11633, 0.11597, 0.1118 , 0.1067 , 0.1058 ,\n",
       "            0.1041 , 0.1034 , 0.1023 , 0.1011 , 0.10016, 0.0998 , 0.0993 ,\n",
       "            0.0986 , 0.0914 , 0.0856 , 0.08466, 0.08105, 0.0775 , 0.0745 ,\n",
       "            0.06635, 0.06223, 0.0539 , 0.0538 , 0.0536 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.125, dtype=float32),\n",
       "    'tpr': array(0.93442625, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0703125,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.078125 , 0.078125 , 0.0859375,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.1640625, 0.171875 , 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.2109375, 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.24590164, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.996  , 0.9956 , 0.9946 , 0.9917 , 0.99   , 0.9893 ,\n",
       "            0.9883 , 0.988  , 0.985  , 0.9844 , 0.9834 , 0.983  , 0.9824 ,\n",
       "            0.9814 , 0.981  , 0.98   , 0.979  , 0.978  , 0.9775 , 0.977  ,\n",
       "            0.9746 , 0.9736 , 0.9727 , 0.9717 , 0.968  , 0.9673 , 0.9663 ,\n",
       "            0.966  , 0.9653 , 0.965  , 0.9614 , 0.9604 , 0.9595 , 0.9575 ,\n",
       "            0.9497 , 0.949  , 0.9478 , 0.9473 , 0.945  , 0.944  , 0.9434 ,\n",
       "            0.941  , 0.938  , 0.937  , 0.933  , 0.932  , 0.9316 , 0.9253 ,\n",
       "            0.9243 , 0.924  , 0.923  , 0.9204 , 0.916  , 0.914  , 0.9136 ,\n",
       "            0.9097 , 0.908  , 0.9067 , 0.9053 , 0.9043 , 0.9033 , 0.903  ,\n",
       "            0.891  , 0.8906 , 0.8877 , 0.88   , 0.874  , 0.873  , 0.8726 ,\n",
       "            0.8677 , 0.8633 , 0.861  , 0.8594 , 0.857  , 0.8477 , 0.8433 ,\n",
       "            0.8345 , 0.829  , 0.8276 , 0.8203 , 0.8174 , 0.8135 , 0.8105 ,\n",
       "            0.806  , 0.8037 , 0.7954 , 0.794  , 0.787  , 0.7827 , 0.777  ,\n",
       "            0.7646 , 0.763  , 0.761  , 0.729  , 0.7114 , 0.709  , 0.706  ,\n",
       "            0.704  , 0.697  , 0.6924 , 0.6914 , 0.6904 , 0.688  , 0.68   ,\n",
       "            0.6587 , 0.6475 , 0.6377 , 0.6216 , 0.609  , 0.597  , 0.5874 ,\n",
       "            0.586  , 0.563  , 0.539  , 0.504  , 0.4988 , 0.4873 , 0.4849 ,\n",
       "            0.4692 , 0.4563 , 0.4524 , 0.449  , 0.444  , 0.4407 , 0.4402 ,\n",
       "            0.43   , 0.426  , 0.4224 , 0.4185 , 0.415  , 0.4102 , 0.4045 ,\n",
       "            0.4023 , 0.3936 , 0.3923 , 0.3918 , 0.3875 , 0.3862 , 0.385  ,\n",
       "            0.3718 , 0.3704 , 0.362  , 0.3613 , 0.3596 , 0.3572 , 0.357  ,\n",
       "            0.355  , 0.3313 , 0.3298 , 0.328  , 0.3274 , 0.3254 , 0.2996 ,\n",
       "            0.2979 , 0.297  , 0.294  , 0.2776 , 0.274  , 0.2698 , 0.268  ,\n",
       "            0.2527 , 0.249  , 0.248  , 0.2473 , 0.243  , 0.241  , 0.2372 ,\n",
       "            0.236  , 0.2334 , 0.2307 , 0.2283 , 0.2185 , 0.2184 , 0.218  ,\n",
       "            0.2158 , 0.2142 , 0.2063 , 0.1924 , 0.1798 , 0.1752 , 0.1738 ,\n",
       "            0.173  , 0.1725 , 0.1696 , 0.1665 , 0.1627 , 0.1608 , 0.1587 ,\n",
       "            0.1577 , 0.1558 , 0.1532 , 0.1461 , 0.1448 , 0.1443 , 0.1434 ,\n",
       "            0.1422 , 0.1383 , 0.1362 , 0.1359 , 0.1356 , 0.1354 , 0.1292 ,\n",
       "            0.129  , 0.12177, 0.1216 , 0.12085, 0.11676, 0.1122 , 0.1101 ,\n",
       "            0.1074 , 0.1056 , 0.1034 , 0.0977 , 0.09503, 0.0939 , 0.0933 ,\n",
       "            0.09125, 0.0906 , 0.0901 , 0.0869 , 0.086  , 0.0851 , 0.08435,\n",
       "            0.0827 , 0.07904, 0.07666, 0.0709 , 0.0683 , 0.06573, 0.0619 ,\n",
       "            0.05624, 0.05194, 0.0452 , 0.0446 , 0.04376], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1171875, dtype=float32),\n",
       "    'tpr': array(0.93442625, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0390625, 0.0390625, 0.046875 , 0.0546875,\n",
       "            0.0546875, 0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.078125 ,\n",
       "            0.078125 , 0.078125 , 0.078125 , 0.0859375, 0.0859375, 0.09375  ,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1796875, 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.203125 , 0.2109375, 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.12295082, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.2704918 , 0.27868852, 0.28688523, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5327869 ,\n",
       "            0.5409836 , 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.996  , 0.9956 , 0.9946 , 0.991  , 0.99   , 0.9893 ,\n",
       "            0.9883 , 0.988  , 0.9844 , 0.984  , 0.9834 , 0.9824 , 0.982  ,\n",
       "            0.981  , 0.9805 , 0.979  , 0.978  , 0.977  , 0.9766 , 0.976  ,\n",
       "            0.9736 , 0.973  , 0.9727 , 0.972  , 0.9717 , 0.971  , 0.9707 ,\n",
       "            0.9663 , 0.965  , 0.9644 , 0.964  , 0.9634 , 0.96   , 0.9595 ,\n",
       "            0.9585 , 0.9575 , 0.957  , 0.9556 , 0.948  , 0.9473 , 0.946  ,\n",
       "            0.9453 , 0.942  , 0.941  , 0.9395 , 0.939  , 0.9365 , 0.9346 ,\n",
       "            0.9297 , 0.929  , 0.9287 , 0.922  , 0.9204 , 0.918  , 0.9136 ,\n",
       "            0.911  , 0.9106 , 0.9053 , 0.904  , 0.9023 , 0.9    , 0.8994 ,\n",
       "            0.8984 , 0.8965 , 0.886  , 0.8843 , 0.882  , 0.8735 , 0.8696 ,\n",
       "            0.8657 , 0.865  , 0.856  , 0.8555 , 0.851  , 0.8506 , 0.8496 ,\n",
       "            0.8374 , 0.836  , 0.8267 , 0.818  , 0.817  , 0.8105 , 0.8057 ,\n",
       "            0.8047 , 0.7983 , 0.7964 , 0.7954 , 0.7856 , 0.7837 , 0.774  ,\n",
       "            0.7646 , 0.752  , 0.74   , 0.71   , 0.6953 , 0.6934 , 0.693  ,\n",
       "            0.6904 , 0.678  , 0.677  , 0.671  , 0.6646 , 0.646  , 0.634  ,\n",
       "            0.619  , 0.601  , 0.588  , 0.574  , 0.567  , 0.5645 , 0.543  ,\n",
       "            0.514  , 0.4817 , 0.4634 , 0.4602 , 0.4568 , 0.4421 , 0.4329 ,\n",
       "            0.4297 , 0.4287 , 0.4243 , 0.4224 , 0.4175 , 0.4062 , 0.4016 ,\n",
       "            0.4    , 0.3955 , 0.3948 , 0.3914 , 0.384  , 0.3777 , 0.372  ,\n",
       "            0.3696 , 0.3674 , 0.364  , 0.3582 , 0.3574 , 0.35   , 0.3406 ,\n",
       "            0.3403 , 0.3396 , 0.3389 , 0.335  , 0.3335 , 0.3105 , 0.3071 ,\n",
       "            0.306  , 0.3047 , 0.2932 , 0.2795 , 0.2776 , 0.2761 , 0.2708 ,\n",
       "            0.256  , 0.248  , 0.2434 , 0.241  , 0.231  , 0.2285 , 0.2281 ,\n",
       "            0.2251 , 0.2227 , 0.2184 , 0.2167 , 0.2123 , 0.211  , 0.208  ,\n",
       "            0.2058 , 0.2012 , 0.1968 , 0.1962 , 0.1921 , 0.1898 , 0.1892 ,\n",
       "            0.1656 , 0.1644 , 0.1598 , 0.1581 , 0.1564 , 0.1562 , 0.151  ,\n",
       "            0.1501 , 0.1451 , 0.144  , 0.143  , 0.142  , 0.1396 , 0.136  ,\n",
       "            0.1304 , 0.1302 , 0.1271 , 0.12244, 0.1222 , 0.122  , 0.1214 ,\n",
       "            0.12085, 0.1166 , 0.11597, 0.11536, 0.1095 , 0.1078 , 0.1056 ,\n",
       "            0.10144, 0.0977 , 0.09515, 0.0945 , 0.0922 , 0.0845 , 0.0825 ,\n",
       "            0.082  , 0.0818 , 0.08136, 0.0805 , 0.07965, 0.076  , 0.07544,\n",
       "            0.0745 , 0.07355, 0.07196, 0.0688 , 0.06866, 0.06198, 0.05942,\n",
       "            0.05698, 0.0538 , 0.04794, 0.04385, 0.03812, 0.0378 , 0.0372 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1171875, dtype=float32),\n",
       "    'tpr': array(0.93442625, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.0390625, 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.078125 , 0.0859375, 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.1640625, 0.171875 , 0.171875 , 0.1796875, 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.1953125, 0.203125 , 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.296875 , 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.02459016, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.14754099, 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.32786885, 0.33606556, 0.36065573, 0.37704918,\n",
       "            0.3852459 , 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.996  , 0.9956 , 0.995  , 0.992  , 0.99   , 0.9897 ,\n",
       "            0.9883 , 0.988  , 0.985  , 0.9844 , 0.9834 , 0.983  , 0.9824 ,\n",
       "            0.982  , 0.9805 , 0.9795 , 0.978  , 0.9775 , 0.977  , 0.976  ,\n",
       "            0.975  , 0.974  , 0.973  , 0.9727 , 0.972  , 0.9707 , 0.9683 ,\n",
       "            0.967  , 0.9663 , 0.966  , 0.9634 , 0.96   , 0.9595 , 0.958  ,\n",
       "            0.9478 , 0.9463 , 0.9453 , 0.944  , 0.9434 , 0.9424 , 0.941  ,\n",
       "            0.938  , 0.9355 , 0.933  , 0.9316 , 0.928  , 0.9277 , 0.9243 ,\n",
       "            0.922  , 0.9214 , 0.9204 , 0.9165 , 0.9126 , 0.912  , 0.9097 ,\n",
       "            0.909  , 0.908  , 0.906  , 0.904  , 0.903  , 0.902  , 0.901  ,\n",
       "            0.9004 , 0.897  , 0.888  , 0.883  , 0.877  , 0.8696 , 0.8667 ,\n",
       "            0.861  , 0.86   , 0.8545 , 0.8516 , 0.845  , 0.8413 , 0.8306 ,\n",
       "            0.822  , 0.8213 , 0.821  , 0.8135 , 0.809  , 0.799  , 0.79   ,\n",
       "            0.7896 , 0.7876 , 0.7793 , 0.777  , 0.7725 , 0.7686 , 0.7563 ,\n",
       "            0.7495 , 0.743  , 0.712  , 0.685  , 0.682  , 0.6816 , 0.6807 ,\n",
       "            0.6787 , 0.6724 , 0.6685 , 0.668  , 0.6533 , 0.6514 , 0.6367 ,\n",
       "            0.624  , 0.6133 , 0.601  , 0.581  , 0.573  , 0.555  , 0.5513 ,\n",
       "            0.5264 , 0.5117 , 0.4653 , 0.4536 , 0.4531 , 0.4382 , 0.4346 ,\n",
       "            0.4258 , 0.419  , 0.4133 , 0.4126 , 0.4102 , 0.4094 , 0.3948 ,\n",
       "            0.3882 , 0.381  , 0.3796 , 0.3777 , 0.3772 , 0.3691 , 0.3594 ,\n",
       "            0.3557 , 0.3555 , 0.353  , 0.3523 , 0.3518 , 0.3372 , 0.3333 ,\n",
       "            0.3267 , 0.3252 , 0.3247 , 0.322  , 0.321  , 0.3132 , 0.2937 ,\n",
       "            0.2932 , 0.2915 , 0.2905 , 0.2869 , 0.2651 , 0.2617 , 0.2568 ,\n",
       "            0.2537 , 0.2399 , 0.2368 , 0.2344 , 0.2319 , 0.2205 , 0.2147 ,\n",
       "            0.2128 , 0.2108 , 0.2103 , 0.2089 , 0.2023 , 0.2013 , 0.1991 ,\n",
       "            0.1976 , 0.1962 , 0.1879 , 0.1855 , 0.1833 , 0.1816 , 0.18   ,\n",
       "            0.1766 , 0.1593 , 0.1516 , 0.1486 , 0.1464 , 0.1439 , 0.1431 ,\n",
       "            0.1426 , 0.1396 , 0.1337 , 0.1334 , 0.1321 , 0.131  , 0.1307 ,\n",
       "            0.12054, 0.1192 , 0.11816, 0.118  , 0.11676, 0.11597, 0.11395,\n",
       "            0.1126 , 0.1118 , 0.1097 , 0.108  , 0.1067 , 0.1056 , 0.1    ,\n",
       "            0.0991 , 0.09894, 0.0957 , 0.09186, 0.0887 , 0.0876 , 0.0851 ,\n",
       "            0.0824 , 0.07764, 0.0763 , 0.07574, 0.0753 , 0.0733 , 0.07227,\n",
       "            0.0708 , 0.06964, 0.06793, 0.0678 , 0.06586, 0.0643 , 0.0628 ,\n",
       "            0.06165, 0.0555 , 0.0534 , 0.05145, 0.04803, 0.04327, 0.0395 ,\n",
       "            0.0341 , 0.03366, 0.03284], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1171875, dtype=float32),\n",
       "    'tpr': array(0.92622954, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0703125,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.078125 , 0.0859375, 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.1796875, 0.1796875, 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.203125 , 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.28125  , 0.2890625, 0.296875 , 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.02459016, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.1147541 , 0.12295082, 0.14754099, 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5081967 , 0.5163934 , 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.795082  , 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.996  , 0.9956 , 0.995  , 0.991  , 0.9897 , 0.9893 ,\n",
       "            0.9883 , 0.988  , 0.9844 , 0.984  , 0.983  , 0.9824 , 0.981  ,\n",
       "            0.9795 , 0.9785 , 0.977  , 0.9766 , 0.9756 , 0.9736 , 0.973  ,\n",
       "            0.972  , 0.971  , 0.9707 , 0.97   , 0.9697 , 0.9663 , 0.9644 ,\n",
       "            0.964  , 0.9634 , 0.963  , 0.959  , 0.9585 , 0.9575 , 0.957  ,\n",
       "            0.9556 , 0.9473 , 0.946  , 0.9453 , 0.945  , 0.942  , 0.9395 ,\n",
       "            0.939  , 0.938  , 0.9365 , 0.9346 , 0.932  , 0.9277 , 0.9272 ,\n",
       "            0.9253 , 0.9194 , 0.9165 , 0.9155 , 0.9106 , 0.908  , 0.9077 ,\n",
       "            0.906  , 0.903  , 0.9004 , 0.8984 , 0.8975 , 0.897  , 0.895  ,\n",
       "            0.8936 , 0.8813 , 0.881  , 0.8716 , 0.87   , 0.8643 , 0.863  ,\n",
       "            0.8564 , 0.849  , 0.8447 , 0.841  , 0.8403 , 0.8315 , 0.8257 ,\n",
       "            0.818  , 0.811  , 0.8105 , 0.8037 , 0.7983 , 0.795  , 0.7856 ,\n",
       "            0.776  , 0.775  , 0.7725 , 0.7646 , 0.758  , 0.752  , 0.7354 ,\n",
       "            0.7334 , 0.7246 , 0.6953 , 0.679  , 0.675  , 0.671  , 0.668  ,\n",
       "            0.6626 , 0.662  , 0.656  , 0.652  , 0.647  , 0.631  , 0.63   ,\n",
       "            0.6177 , 0.593  , 0.5845 , 0.5605 , 0.555  , 0.5435 , 0.5312 ,\n",
       "            0.5107 , 0.4934 , 0.4565 , 0.4321 , 0.4219 , 0.4187 , 0.4104 ,\n",
       "            0.409  , 0.407  , 0.4016 , 0.4014 , 0.3965 , 0.3757 , 0.3728 ,\n",
       "            0.3687 , 0.3682 , 0.3662 , 0.3606 , 0.3594 , 0.35   , 0.343  ,\n",
       "            0.3416 , 0.335  , 0.3335 , 0.3325 , 0.3284 , 0.32   , 0.3162 ,\n",
       "            0.314  , 0.312  , 0.3115 , 0.3071 , 0.306  , 0.2952 , 0.2786 ,\n",
       "            0.278  , 0.2761 , 0.2722 , 0.2625 , 0.248  , 0.2456 , 0.2444 ,\n",
       "            0.2397 , 0.2319 , 0.224  , 0.2173 , 0.2108 , 0.2053 , 0.1996 ,\n",
       "            0.1984 , 0.1946 , 0.1885 , 0.1874 , 0.1841 , 0.1827 , 0.182  ,\n",
       "            0.1805 , 0.171  , 0.1694 , 0.1692 , 0.1659 , 0.1653 , 0.1625 ,\n",
       "            0.1433 , 0.1428 , 0.1406 , 0.1404 , 0.138  , 0.134  , 0.1317 ,\n",
       "            0.1316 , 0.1282 , 0.1267 , 0.1204 , 0.12024, 0.1198 , 0.11084,\n",
       "            0.1095 , 0.1084 , 0.1078 , 0.10706, 0.1069 , 0.1045 , 0.103  ,\n",
       "            0.1019 , 0.09827, 0.0967 , 0.09656, 0.09283, 0.0903 , 0.0874 ,\n",
       "            0.0845 , 0.08386, 0.0824 , 0.0771 , 0.0745 , 0.0694 , 0.0693 ,\n",
       "            0.06915, 0.06903, 0.06866, 0.06586, 0.0643 , 0.06384, 0.0631 ,\n",
       "            0.0629 , 0.06244, 0.06097, 0.05728, 0.0552 , 0.0526 , 0.04996,\n",
       "            0.0476 , 0.04535, 0.03906, 0.0355 , 0.03079, 0.03056, 0.0305 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.109375, dtype=float32),\n",
       "    'tpr': array(0.92622954, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.046875 , 0.046875 , 0.046875 , 0.046875 ,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.0703125, 0.0703125,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.0859375, 0.0859375, 0.09375  ,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.15625  , 0.15625  ,\n",
       "            0.1640625, 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.2890625, 0.296875 , 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5703125, 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.10655738,\n",
       "            0.1147541 , 0.13934426, 0.14754099, 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.21311475, 0.22950819,\n",
       "            0.24590164, 0.26229507, 0.2704918 , 0.28688523, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.40163934, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.8442623 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9966 , 0.996  , 0.9956 , 0.992  , 0.99   , 0.989  ,\n",
       "            0.9873 , 0.987  , 0.985  , 0.9834 , 0.9824 , 0.9814 , 0.981  ,\n",
       "            0.9805 , 0.98   , 0.9775 , 0.977  , 0.975  , 0.9736 , 0.9727 ,\n",
       "            0.971  , 0.9697 , 0.968  , 0.966  , 0.9653 , 0.9604 , 0.96   ,\n",
       "            0.9595 , 0.959  , 0.9575 , 0.956  , 0.9556 , 0.954  , 0.944  ,\n",
       "            0.9414 , 0.941  , 0.9404 , 0.9365 , 0.9346 , 0.932  , 0.93   ,\n",
       "            0.9297 , 0.926  , 0.922  , 0.9214 , 0.9194 , 0.919  , 0.918  ,\n",
       "            0.913  , 0.9087 , 0.9077 , 0.905  , 0.9043 , 0.903  , 0.9014 ,\n",
       "            0.8994 , 0.899  , 0.8975 , 0.8955 , 0.8916 , 0.886  , 0.884  ,\n",
       "            0.8726 , 0.8706 , 0.8647 , 0.861  , 0.855  , 0.8516 , 0.8467 ,\n",
       "            0.845  , 0.8413 , 0.841  , 0.8335 , 0.83   , 0.814  , 0.8125 ,\n",
       "            0.812  , 0.805  , 0.8037 , 0.7993 , 0.7793 , 0.7715 , 0.769  ,\n",
       "            0.7583 , 0.7563 , 0.755  , 0.75   , 0.732  , 0.7314 , 0.725  ,\n",
       "            0.718  , 0.6943 , 0.6606 , 0.66   , 0.654  , 0.6533 , 0.6514 ,\n",
       "            0.6484 , 0.6455 , 0.641  , 0.624  , 0.612  , 0.6006 , 0.5986 ,\n",
       "            0.5864 , 0.58   , 0.553  , 0.5503 , 0.5215 , 0.515  , 0.4875 ,\n",
       "            0.487  , 0.429  , 0.4216 , 0.4167 , 0.4111 , 0.3992 , 0.388  ,\n",
       "            0.3877 , 0.3818 , 0.381  , 0.3787 , 0.3765 , 0.3635 , 0.3567 ,\n",
       "            0.3508 , 0.349  , 0.3408 , 0.3376 , 0.3337 , 0.3293 , 0.3284 ,\n",
       "            0.3262 , 0.322  , 0.321  , 0.3206 , 0.3198 , 0.307  , 0.3037 ,\n",
       "            0.2996 , 0.2993 , 0.2927 , 0.292  , 0.287  , 0.273  , 0.2651 ,\n",
       "            0.2617 , 0.2603 , 0.2588 , 0.255  , 0.2319 , 0.2216 , 0.2198 ,\n",
       "            0.21   , 0.2094 , 0.2089 , 0.2023 , 0.1982 , 0.187  , 0.1848 ,\n",
       "            0.1846 , 0.182  , 0.1805 , 0.1761 , 0.1743 , 0.1731 , 0.1694 ,\n",
       "            0.1676 , 0.1617 , 0.1604 , 0.1584 , 0.1567 , 0.1512 , 0.149  ,\n",
       "            0.1362 , 0.1293 , 0.1262 , 0.1232 , 0.1229 , 0.12024, 0.12   ,\n",
       "            0.1144 , 0.1138 , 0.1134 , 0.11066, 0.10895, 0.10016, 0.09827,\n",
       "            0.0977 , 0.0974 , 0.0972 , 0.0967 , 0.09503, 0.0932 , 0.09235,\n",
       "            0.09106, 0.0874 , 0.0851 , 0.08496, 0.08154, 0.07965, 0.0761 ,\n",
       "            0.07434, 0.07385, 0.0694 , 0.0666 , 0.0645 , 0.06305, 0.0627 ,\n",
       "            0.06256, 0.06042, 0.05954, 0.0577 , 0.05646, 0.05594, 0.0551 ,\n",
       "            0.0538 , 0.05243, 0.05154, 0.04968, 0.04578, 0.04376, 0.04218,\n",
       "            0.03928, 0.0347 , 0.03137, 0.02692, 0.02686, 0.02615],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.09375, dtype=float32),\n",
       "    'tpr': array(0.92622954, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.046875 , 0.046875 , 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.0703125, 0.0703125, 0.0703125,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.0859375, 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.109375 , 0.1171875, 0.125    , 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.15625  , 0.15625  , 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1875   , 0.1953125,\n",
       "            0.1953125, 0.2109375, 0.21875  , 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01639344, 0.02459016, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.25409836,\n",
       "            0.26229507, 0.27868852, 0.28688523, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.8442623 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.996  , 0.9956 , 0.995  , 0.991  , 0.9893 , 0.9883 ,\n",
       "            0.987  , 0.986  , 0.9834 , 0.982  , 0.9814 , 0.981  , 0.9805 ,\n",
       "            0.98   , 0.9795 , 0.979  , 0.978  , 0.9756 , 0.974  , 0.9727 ,\n",
       "            0.9717 , 0.971  , 0.9707 , 0.9697 , 0.9683 , 0.9663 , 0.9653 ,\n",
       "            0.9624 , 0.962  , 0.9585 , 0.958  , 0.956  , 0.955  , 0.954  ,\n",
       "            0.9536 , 0.9526 , 0.9517 , 0.941  , 0.938  , 0.9375 , 0.937  ,\n",
       "            0.9355 , 0.9346 , 0.932  , 0.931  , 0.928  , 0.927  , 0.9243 ,\n",
       "            0.921  , 0.917  , 0.915  , 0.914  , 0.9126 , 0.91   , 0.908  ,\n",
       "            0.904  , 0.8994 , 0.8975 , 0.8965 , 0.896  , 0.895  , 0.892  ,\n",
       "            0.8906 , 0.889  , 0.887  , 0.8853 , 0.8794 , 0.875  , 0.8633 ,\n",
       "            0.8623 , 0.855  , 0.852  , 0.8477 , 0.838  , 0.836  , 0.8345 ,\n",
       "            0.8257 , 0.8213 , 0.821  , 0.8037 , 0.7993 , 0.7925 , 0.792  ,\n",
       "            0.7856 , 0.7666 , 0.7593 , 0.7554 , 0.745  , 0.7407 , 0.74   ,\n",
       "            0.739  , 0.7354 , 0.716  , 0.708  , 0.7036 , 0.702  , 0.675  ,\n",
       "            0.6455 , 0.641  , 0.6367 , 0.634  , 0.633  , 0.6265 , 0.626  ,\n",
       "            0.6235 , 0.6055 , 0.5967 , 0.583  , 0.576  , 0.561  , 0.5586 ,\n",
       "            0.53   , 0.5264 , 0.4927 , 0.4895 , 0.4663 , 0.466  , 0.407  ,\n",
       "            0.392  , 0.3904 , 0.3855 , 0.3792 , 0.37   , 0.3696 , 0.3647 ,\n",
       "            0.363  , 0.3604 , 0.3503 , 0.3406 , 0.3333 , 0.333  , 0.332  ,\n",
       "            0.3193 , 0.3115 , 0.3098 , 0.3076 , 0.3    , 0.2988 , 0.2974 ,\n",
       "            0.291  , 0.2869 , 0.2847 , 0.2844 , 0.2825 , 0.2747 , 0.2683 ,\n",
       "            0.2534 , 0.247  , 0.2448 , 0.243  , 0.236  , 0.2319 , 0.2158 ,\n",
       "            0.207  , 0.2032 , 0.2021 , 0.1934 , 0.193  , 0.1913 , 0.1869 ,\n",
       "            0.1855 , 0.1714 , 0.1707 , 0.169  , 0.1664 , 0.1609 , 0.1605 ,\n",
       "            0.1588 , 0.1537 , 0.1494 , 0.1473 , 0.1436 , 0.1432 , 0.1409 ,\n",
       "            0.136  , 0.1349 , 0.1225 , 0.1188 , 0.11755, 0.11536, 0.113  ,\n",
       "            0.11145, 0.1097 , 0.10913, 0.10394, 0.1019 , 0.10016, 0.0986 ,\n",
       "            0.0906 , 0.0891 , 0.0885 , 0.0882 , 0.088  , 0.0876 , 0.0862 ,\n",
       "            0.086  , 0.0828 , 0.0824 , 0.0788 , 0.0775 , 0.07544, 0.0733 ,\n",
       "            0.0732 , 0.0717 , 0.0683 , 0.06696, 0.0667 , 0.06223, 0.05942,\n",
       "            0.0577 , 0.05664, 0.0556 , 0.0543 , 0.05185, 0.05176, 0.0509 ,\n",
       "            0.04968, 0.04858, 0.0476 , 0.0463 , 0.0462 , 0.04337, 0.04068,\n",
       "            0.03897, 0.0377 , 0.03476, 0.03073, 0.0277 , 0.02365, 0.0236 ,\n",
       "            0.02289], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.09375, dtype=float32),\n",
       "    'tpr': array(0.92622954, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.046875 , 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.0625   ,\n",
       "            0.0703125, 0.0703125, 0.0703125, 0.0703125, 0.0703125, 0.078125 ,\n",
       "            0.0859375, 0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.15625  , 0.15625  , 0.15625  , 0.1640625, 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01639344, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.13114753, 0.13934426, 0.1557377 , 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.21311475, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.28688523, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.996  , 0.995  , 0.991  , 0.9893 , 0.9873 , 0.9863 ,\n",
       "            0.9854 , 0.9834 , 0.983  , 0.982  , 0.9805 , 0.98   , 0.9795 ,\n",
       "            0.9785 , 0.9775 , 0.975  , 0.9727 , 0.972  , 0.9707 , 0.9697 ,\n",
       "            0.9688 , 0.9683 , 0.9663 , 0.9644 , 0.964  , 0.961  , 0.9604 ,\n",
       "            0.956  , 0.955  , 0.9546 , 0.954  , 0.952  , 0.9517 , 0.949  ,\n",
       "            0.9487 , 0.938  , 0.9346 , 0.934  , 0.9336 , 0.933  , 0.9326 ,\n",
       "            0.9263 , 0.9233 , 0.9224 , 0.9214 , 0.917  , 0.913  , 0.912  ,\n",
       "            0.909  , 0.907  , 0.9067 , 0.904  , 0.899  , 0.8945 , 0.891  ,\n",
       "            0.8906 , 0.89   , 0.8877 , 0.886  , 0.885  , 0.883  , 0.8774 ,\n",
       "            0.873  , 0.87   , 0.8574 , 0.855  , 0.849  , 0.839  , 0.8315 ,\n",
       "            0.8276 , 0.8237 , 0.814  , 0.813  , 0.809  , 0.8047 , 0.7915 ,\n",
       "            0.791  , 0.7905 , 0.783  , 0.7817 , 0.777  , 0.755  , 0.748  ,\n",
       "            0.743  , 0.733  , 0.728  , 0.727  , 0.718  , 0.716  , 0.702  ,\n",
       "            0.692  , 0.6885 , 0.6826 , 0.662  , 0.6304 , 0.6265 , 0.621  ,\n",
       "            0.619  , 0.611  , 0.608  , 0.6064 , 0.5977 , 0.589  , 0.5806 ,\n",
       "            0.567  , 0.545  , 0.54   , 0.533  , 0.513  , 0.501  , 0.474  ,\n",
       "            0.46   , 0.4487 , 0.4397 , 0.3887 , 0.3728 , 0.3691 , 0.3633 ,\n",
       "            0.3616 , 0.3528 , 0.3525 , 0.3484 , 0.3435 , 0.343  , 0.317  ,\n",
       "            0.3147 , 0.3132 , 0.309  , 0.3032 , 0.302  , 0.291  , 0.2898 ,\n",
       "            0.2896 , 0.2832 , 0.283  , 0.2815 , 0.276  , 0.2703 , 0.2683 ,\n",
       "            0.2668 , 0.266  , 0.2637 , 0.2588 , 0.256  , 0.247  , 0.2299 ,\n",
       "            0.2274 , 0.2268 , 0.2235 , 0.218  , 0.213  , 0.1982 , 0.1896 ,\n",
       "            0.1838 , 0.1813 , 0.1803 , 0.1799 , 0.1787 , 0.1759 , 0.1727 ,\n",
       "            0.157  , 0.1552 , 0.1533 , 0.1499 , 0.1495 , 0.1492 , 0.1476 ,\n",
       "            0.1423 , 0.1375 , 0.1366 , 0.1327 , 0.1305 , 0.1289 , 0.12244,\n",
       "            0.1201 , 0.11816, 0.11316, 0.1101 , 0.1067 , 0.1047 , 0.1043 ,\n",
       "            0.10266, 0.10144, 0.09686, 0.096  , 0.0959 , 0.0939 , 0.0888 ,\n",
       "            0.0868 , 0.08136, 0.08124, 0.0808 , 0.0799 , 0.07904, 0.0785 ,\n",
       "            0.07654, 0.0763 , 0.07587, 0.0715 , 0.0693 , 0.06915, 0.0642 ,\n",
       "            0.06384, 0.0629 , 0.06143, 0.06097, 0.05966, 0.0541 , 0.05252,\n",
       "            0.05176, 0.05154, 0.05127, 0.0496 , 0.04794, 0.04733, 0.04648,\n",
       "            0.0452 , 0.0437 , 0.0432 , 0.04202, 0.04108, 0.0369 , 0.03677,\n",
       "            0.0354 , 0.03418, 0.03156, 0.0277 , 0.02489, 0.02124, 0.02116,\n",
       "            0.0206 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.078125, dtype=float32),\n",
       "    'tpr': array(0.91803277, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.03125  ,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.046875 , 0.046875 , 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.0703125, 0.0703125,\n",
       "            0.0703125, 0.0703125, 0.078125 , 0.0859375, 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.109375 , 0.1171875, 0.125    , 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.1484375, 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.171875 , 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.08196721, 0.09016393,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.30327868, 0.3114754 , 0.31967214, 0.33606556,\n",
       "            0.3442623 , 0.36065573, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.996  , 0.9956 , 0.995  , 0.9946 , 0.99   , 0.9883 ,\n",
       "            0.9863 , 0.985  , 0.9844 , 0.9814 , 0.9805 , 0.979  , 0.9785 ,\n",
       "            0.978  , 0.9775 , 0.9766 , 0.976  , 0.9756 , 0.972  , 0.97   ,\n",
       "            0.9697 , 0.969  , 0.968  , 0.9673 , 0.967  , 0.9663 , 0.966  ,\n",
       "            0.964  , 0.961  , 0.959  , 0.9565 , 0.955  , 0.9526 , 0.951  ,\n",
       "            0.9497 , 0.948  , 0.945  , 0.9336 , 0.929  , 0.9287 , 0.9272 ,\n",
       "            0.9253 , 0.925  , 0.9204 , 0.9175 , 0.916  , 0.914  , 0.908  ,\n",
       "            0.905  , 0.904  , 0.9004 , 0.899  , 0.8965 , 0.895  , 0.89   ,\n",
       "            0.8857 , 0.882  , 0.8813 , 0.88   , 0.878  , 0.8774 , 0.874  ,\n",
       "            0.8726 , 0.871  , 0.8677 , 0.861  , 0.8584 , 0.845  , 0.841  ,\n",
       "            0.836  , 0.8267 , 0.825  , 0.812  , 0.81   , 0.8096 , 0.7964 ,\n",
       "            0.7944 , 0.7925 , 0.7793 , 0.7754 , 0.7725 , 0.772  , 0.7656 ,\n",
       "            0.7617 , 0.757  , 0.7334 , 0.7275 , 0.719  , 0.71   , 0.7075 ,\n",
       "            0.7036 , 0.692  , 0.69   , 0.675  , 0.6597 , 0.659  , 0.6323 ,\n",
       "            0.605  , 0.5977 , 0.5933 , 0.59   , 0.5845 , 0.579  , 0.5737 ,\n",
       "            0.569  , 0.558  , 0.556  , 0.5415 , 0.516  , 0.506  , 0.4993 ,\n",
       "            0.482  , 0.4668 , 0.438  , 0.4224 , 0.4172 , 0.4119 , 0.3545 ,\n",
       "            0.3416 , 0.3313 , 0.329  , 0.3267 , 0.3247 , 0.3232 , 0.3174 ,\n",
       "            0.3154 , 0.29   , 0.2896 , 0.288  , 0.2825 , 0.2805 , 0.2756 ,\n",
       "            0.27   , 0.2659 , 0.2654 , 0.263  , 0.2556 , 0.2502 , 0.2493 ,\n",
       "            0.2487 , 0.2482 , 0.2471 , 0.2418 , 0.2358 , 0.234  , 0.2332 ,\n",
       "            0.2318 , 0.2242 , 0.2065 , 0.2059 , 0.2058 , 0.2028 , 0.188  ,\n",
       "            0.1857 , 0.1794 , 0.1636 , 0.1603 , 0.16   , 0.1594 , 0.1565 ,\n",
       "            0.1564 , 0.1528 , 0.1492 , 0.1384 , 0.1351 , 0.132  , 0.1267 ,\n",
       "            0.1259 , 0.1255 , 0.12286, 0.1213 , 0.11597, 0.11395, 0.11163,\n",
       "            0.111  , 0.1043 , 0.1041 , 0.1023 , 0.0955 , 0.0939 , 0.09204,\n",
       "            0.09174, 0.0896 , 0.0871 , 0.0869 , 0.08466, 0.0824 , 0.08154,\n",
       "            0.0775 , 0.0774 , 0.0753 , 0.0698 , 0.0695 , 0.0688 , 0.0683 ,\n",
       "            0.06757, 0.06696, 0.066  , 0.065  , 0.06384, 0.06244, 0.06177,\n",
       "            0.0601 , 0.05792, 0.0549 , 0.0544 , 0.0541 , 0.05252, 0.05136,\n",
       "            0.0509 , 0.04663, 0.044  , 0.04385, 0.04327, 0.04288, 0.04138,\n",
       "            0.04077, 0.04   , 0.03928, 0.03705, 0.03656, 0.03534, 0.03506,\n",
       "            0.03436, 0.03403, 0.03073, 0.03038, 0.0292 , 0.02838, 0.02576,\n",
       "            0.02284, 0.02042, 0.01724, 0.01653], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.0703125, dtype=float32),\n",
       "    'tpr': array(0.90983605, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.046875 , 0.046875 , 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.15625  , 0.1640625, 0.171875 , 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.22131148, 0.23770492,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9956  , 0.995   , 0.994   , 0.993   , 0.9927  ,\n",
       "            0.9897  , 0.9873  , 0.982   , 0.981   , 0.98    , 0.9785  ,\n",
       "            0.977   , 0.9756  , 0.9746  , 0.9736  , 0.9727  , 0.972   ,\n",
       "            0.971   , 0.9697  , 0.969   , 0.967   , 0.965   , 0.9644  ,\n",
       "            0.9624  , 0.9585  , 0.9575  , 0.954   , 0.9526  , 0.952   ,\n",
       "            0.9517  , 0.95    , 0.949   , 0.947   , 0.945   , 0.9434  ,\n",
       "            0.941   , 0.9375  , 0.937   , 0.932   , 0.9297  , 0.92    ,\n",
       "            0.918   , 0.9175  , 0.914   , 0.912   , 0.91    , 0.9067  ,\n",
       "            0.901   , 0.899   , 0.8984  , 0.898   , 0.895   , 0.8916  ,\n",
       "            0.8867  , 0.886   , 0.8853  , 0.874   , 0.8735  , 0.8706  ,\n",
       "            0.868   , 0.866   , 0.8643  , 0.8623  , 0.8613  , 0.861   ,\n",
       "            0.8594  , 0.8584  , 0.8574  , 0.846   , 0.841   , 0.833   ,\n",
       "            0.831   , 0.8223  , 0.8086  , 0.795   , 0.794   , 0.793   ,\n",
       "            0.786   , 0.7793  , 0.772   , 0.7676  , 0.7583  , 0.7534  ,\n",
       "            0.753   , 0.747   , 0.743   , 0.738   , 0.737   , 0.7217  ,\n",
       "            0.6914  , 0.6885  , 0.6743  , 0.6704  , 0.6665  , 0.658   ,\n",
       "            0.6567  , 0.634   , 0.631   , 0.6245  , 0.6235  , 0.6104  ,\n",
       "            0.6055  , 0.5703  , 0.5625  , 0.562   , 0.546   , 0.5356  ,\n",
       "            0.5327  , 0.532   , 0.516   , 0.509   , 0.501   , 0.4878  ,\n",
       "            0.4592  , 0.453   , 0.435   , 0.4272  , 0.3887  , 0.3855  ,\n",
       "            0.379   , 0.3625  , 0.3142  , 0.3086  , 0.3044  , 0.3015  ,\n",
       "            0.2908  , 0.2903  , 0.2883  , 0.2812  , 0.2793  , 0.2578  ,\n",
       "            0.2566  , 0.2563  , 0.2485  , 0.2417  , 0.2391  , 0.2374  ,\n",
       "            0.237   , 0.2295  , 0.2278  , 0.2266  , 0.2222  , 0.2213  ,\n",
       "            0.2197  , 0.2145  , 0.213   , 0.2115  , 0.2104  , 0.208   ,\n",
       "            0.1998  , 0.1993  , 0.1935  , 0.1829  , 0.1813  , 0.1754  ,\n",
       "            0.1714  , 0.1632  , 0.1609  , 0.1561  , 0.1437  , 0.1385  ,\n",
       "            0.1346  , 0.1342  , 0.1334  , 0.132   , 0.13    , 0.12335 ,\n",
       "            0.119   , 0.1158  , 0.11316 , 0.11163 , 0.11066 , 0.1097  ,\n",
       "            0.10596 , 0.1056  , 0.1019  , 0.10126 , 0.09753 , 0.0962  ,\n",
       "            0.09186 , 0.0876  , 0.0854  , 0.0825  , 0.08124 , 0.0808  ,\n",
       "            0.0785  , 0.07794 , 0.07684 , 0.0729  , 0.0717  , 0.0715  ,\n",
       "            0.0693  , 0.0677  , 0.0666  , 0.0656  , 0.06232 , 0.05933 ,\n",
       "            0.059   , 0.05856 , 0.05698 , 0.05542 , 0.055   , 0.0546  ,\n",
       "            0.0542  , 0.0539  , 0.0534  , 0.0532  , 0.0504  , 0.04578 ,\n",
       "            0.04553 , 0.04468 , 0.04385 , 0.04312 , 0.04208 , 0.04163 ,\n",
       "            0.03876 , 0.03732 , 0.03662 , 0.03644 , 0.03616 , 0.03424 ,\n",
       "            0.03384 , 0.0336  , 0.03308 , 0.02992 , 0.02975 , 0.02931 ,\n",
       "            0.02791 , 0.02718 , 0.02696 , 0.02484 , 0.0247  , 0.024   ,\n",
       "            0.0236  , 0.02089 , 0.01888 , 0.01678 , 0.014114, 0.01406 ,\n",
       "            0.01322 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.046875, dtype=float32),\n",
       "    'tpr': array(0.8770492, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.0390625, 0.046875 , 0.046875 , 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.1328125, 0.140625 , 0.140625 , 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.171875 , 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.09016393,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.995   , 0.9946  , 0.9937  , 0.992   , 0.9917  ,\n",
       "            0.9883  , 0.9854  , 0.979   , 0.978   , 0.977   , 0.9756  ,\n",
       "            0.9736  , 0.972   , 0.971   , 0.97    , 0.9697  , 0.9683  ,\n",
       "            0.966   , 0.9644  , 0.962   , 0.9595  , 0.959   , 0.956   ,\n",
       "            0.9556  , 0.954   , 0.953   , 0.951   , 0.946   , 0.945   ,\n",
       "            0.9434  , 0.9424  , 0.941   , 0.9395  , 0.9365  , 0.936   ,\n",
       "            0.932   , 0.9307  , 0.9243  , 0.915   , 0.909   , 0.9053  ,\n",
       "            0.904   , 0.9033  , 0.899   , 0.8975  , 0.8936  , 0.883   ,\n",
       "            0.882   , 0.8813  , 0.88    , 0.8784  , 0.8755  , 0.8726  ,\n",
       "            0.867   , 0.8604  , 0.854   , 0.852   , 0.8506  , 0.849   ,\n",
       "            0.8486  , 0.8467  , 0.8433  , 0.841   , 0.8394  , 0.8384  ,\n",
       "            0.837   , 0.826   , 0.8164  , 0.8135  , 0.8086  , 0.8003  ,\n",
       "            0.786   , 0.7656  , 0.7637  , 0.7603  , 0.751   , 0.7485  ,\n",
       "            0.735   , 0.734   , 0.7246  , 0.724   , 0.722   , 0.7104  ,\n",
       "            0.709   , 0.705   , 0.702   , 0.6924  , 0.6597  , 0.659   ,\n",
       "            0.6416  , 0.641   , 0.634   , 0.6245  , 0.6133  , 0.588   ,\n",
       "            0.581   , 0.5786  , 0.5615  , 0.5605  , 0.5283  , 0.528   ,\n",
       "            0.5195  , 0.509   , 0.495   , 0.4863  , 0.4817  , 0.4756  ,\n",
       "            0.4697  , 0.4673  , 0.4521  , 0.4482  , 0.4138  , 0.411   ,\n",
       "            0.3801  , 0.3733  , 0.348   , 0.345   , 0.3313  , 0.3157  ,\n",
       "            0.2756  , 0.2722  , 0.2695  , 0.2673  , 0.2617  , 0.2573  ,\n",
       "            0.2485  , 0.2483  , 0.2449  , 0.2367  , 0.2274  , 0.2249  ,\n",
       "            0.2211  , 0.2139  , 0.2125  , 0.2065  , 0.2053  , 0.2051  ,\n",
       "            0.2009  , 0.1981  , 0.1921  , 0.1885  , 0.1844  , 0.1835  ,\n",
       "            0.183   , 0.1796  , 0.179   , 0.1766  , 0.1753  , 0.1721  ,\n",
       "            0.1671  , 0.1631  , 0.1569  , 0.1552  , 0.1482  , 0.1399  ,\n",
       "            0.1339  , 0.1322  , 0.1293  , 0.1263  , 0.11395 , 0.112   ,\n",
       "            0.1097  , 0.10876 , 0.1076  , 0.1063  , 0.10284 , 0.0993  ,\n",
       "            0.096   , 0.0945  , 0.0925  , 0.088   , 0.0876  , 0.0868  ,\n",
       "            0.08344 , 0.0808  , 0.0805  , 0.07965 , 0.0752  , 0.0745  ,\n",
       "            0.0716  , 0.06915 , 0.06805 , 0.065   , 0.06396 , 0.0637  ,\n",
       "            0.06244 , 0.0603  , 0.05878 , 0.05856 , 0.0575  , 0.0556  ,\n",
       "            0.054   , 0.05136 , 0.05014 , 0.04886 , 0.04788 , 0.0477  ,\n",
       "            0.0464  , 0.04526 , 0.04492 , 0.04443 , 0.044   , 0.04282 ,\n",
       "            0.04108 , 0.041   , 0.04047 , 0.03738 , 0.03705 , 0.0369  ,\n",
       "            0.03662 , 0.03522 , 0.03354 , 0.03284 , 0.03198 , 0.03137 ,\n",
       "            0.03021 , 0.0292  , 0.02887 , 0.02791 , 0.02759 , 0.02722 ,\n",
       "            0.02707 , 0.02676 , 0.02373 , 0.0237  , 0.02333 , 0.02191 ,\n",
       "            0.02112 , 0.02101 , 0.01984 , 0.0196  , 0.01901 , 0.01872 ,\n",
       "            0.01646 , 0.014786, 0.01297 , 0.01086 , 0.01021 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.046875, dtype=float32),\n",
       "    'tpr': array(0.852459, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.03125  , 0.0390625, 0.046875 , 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.046875 , 0.046875 , 0.046875 , 0.046875 ,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.1328125, 0.1328125, 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.1640625, 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.22950819,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.30327868, 0.3114754 , 0.31967214, 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.995  , 0.9946 , 0.993  , 0.9927 , 0.991  , 0.9873 ,\n",
       "            0.9844 , 0.98   , 0.9785 , 0.977  , 0.975  , 0.9736 , 0.9717 ,\n",
       "            0.9707 , 0.97   , 0.9697 , 0.969  , 0.9683 , 0.967  , 0.9653 ,\n",
       "            0.961  , 0.9585 , 0.9556 , 0.955  , 0.9546 , 0.9517 , 0.9473 ,\n",
       "            0.9443 , 0.9395 , 0.939  , 0.936  , 0.935  , 0.934  , 0.931  ,\n",
       "            0.925  , 0.919  , 0.909  , 0.9077 , 0.9053 , 0.8994 , 0.8936 ,\n",
       "            0.8926 , 0.8916 , 0.8843 , 0.8794 , 0.878  , 0.8726 , 0.872  ,\n",
       "            0.8716 , 0.8687 , 0.868  , 0.8643 , 0.859  , 0.853  , 0.8525 ,\n",
       "            0.8486 , 0.8413 , 0.837  , 0.8364 , 0.8354 , 0.831  , 0.8306 ,\n",
       "            0.8247 , 0.823  , 0.8228 , 0.8203 , 0.811  , 0.8105 , 0.808  ,\n",
       "            0.7896 , 0.783  , 0.7827 , 0.755  , 0.74   , 0.7344 , 0.7275 ,\n",
       "            0.7256 , 0.716  , 0.711  , 0.704  , 0.6997 , 0.6973 , 0.687  ,\n",
       "            0.685  , 0.683  , 0.679  , 0.672  , 0.651  , 0.6494 , 0.6313 ,\n",
       "            0.631  , 0.624  , 0.614  , 0.5767 , 0.5747 , 0.5425 , 0.542  ,\n",
       "            0.5376 , 0.5317 , 0.5264 , 0.5137 , 0.4944 , 0.4934 , 0.4846 ,\n",
       "            0.4802 , 0.4543 , 0.4536 , 0.451  , 0.4502 , 0.4434 , 0.4148 ,\n",
       "            0.41   , 0.3762 , 0.3716 , 0.3394 , 0.3289 , 0.3262 , 0.3147 ,\n",
       "            0.2888 , 0.2834 , 0.256  , 0.2445 , 0.2441 , 0.2424 , 0.2405 ,\n",
       "            0.2374 , 0.2318 , 0.2222 , 0.2123 , 0.2113 , 0.2028 , 0.2001 ,\n",
       "            0.197  , 0.1913 , 0.1842 , 0.1836 , 0.1805 , 0.1804 , 0.1796 ,\n",
       "            0.1794 , 0.1687 , 0.166  , 0.162  , 0.1592 , 0.1584 , 0.1558 ,\n",
       "            0.155  , 0.1506 , 0.1505 , 0.1467 , 0.1407 , 0.1387 , 0.1356 ,\n",
       "            0.133  , 0.1273 , 0.11597, 0.11316, 0.113  , 0.1105 , 0.10614,\n",
       "            0.10175, 0.09845, 0.0955 , 0.09283, 0.089  , 0.0888 , 0.0868 ,\n",
       "            0.0833 , 0.0828 , 0.07904, 0.07837, 0.0721 , 0.0717 , 0.07135,\n",
       "            0.0683 , 0.0666 , 0.06573, 0.0629 , 0.06052, 0.0602 , 0.05933,\n",
       "            0.05792, 0.05646, 0.0548 , 0.054  , 0.0533 , 0.0531 , 0.05194,\n",
       "            0.05154, 0.0506 , 0.04987, 0.04904, 0.0476 , 0.04385, 0.04272,\n",
       "            0.04083, 0.0401 , 0.0398 , 0.03964, 0.03928, 0.03897, 0.03854,\n",
       "            0.03748, 0.03726, 0.0336 , 0.03284, 0.0324 , 0.03143, 0.03125,\n",
       "            0.02982, 0.02954, 0.02948, 0.02914, 0.02806, 0.02533, 0.0248 ,\n",
       "            0.02448, 0.02428, 0.02405, 0.02377, 0.02272, 0.02267, 0.02258,\n",
       "            0.02191, 0.02124, 0.02042, 0.01968, 0.01888, 0.01816, 0.01791,\n",
       "            0.01672, 0.0161 , 0.01584, 0.01572, 0.01525, 0.01401, 0.01219,\n",
       "            0.01049, 0.00895, 0.00885, 0.00861], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.015625, dtype=float32),\n",
       "    'tpr': array(0.8442623, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.03125  ,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.046875 , 0.046875 , 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.0625   ,\n",
       "            0.0625   , 0.0703125, 0.0703125, 0.078125 , 0.0859375, 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.1640625, 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9375   ,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.29508197, 0.30327868, 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.995   , 0.9946  , 0.993   , 0.991   , 0.9907  ,\n",
       "            0.9893  , 0.988   , 0.9844  , 0.9756  , 0.975   , 0.9746  ,\n",
       "            0.974   , 0.9727  , 0.9717  , 0.9707  , 0.969   , 0.9683  ,\n",
       "            0.9673  , 0.965   , 0.962   , 0.9595  , 0.9585  , 0.958   ,\n",
       "            0.9575  , 0.9546  , 0.9536  , 0.951   , 0.9497  , 0.947   ,\n",
       "            0.946   , 0.9453  , 0.9434  , 0.937   , 0.933   , 0.9326  ,\n",
       "            0.9287  , 0.9272  , 0.927   , 0.9243  , 0.9194  , 0.918   ,\n",
       "            0.91    , 0.9004  , 0.8906  , 0.888   , 0.8867  , 0.8853  ,\n",
       "            0.8784  , 0.878   , 0.8677  , 0.8613  , 0.8574  , 0.8564  ,\n",
       "            0.8555  , 0.847   , 0.844   , 0.842   , 0.84    , 0.8325  ,\n",
       "            0.8257  , 0.8247  , 0.823   , 0.8228  , 0.815   , 0.813   ,\n",
       "            0.812   , 0.8105  , 0.8013  , 0.8003  , 0.799   , 0.7983  ,\n",
       "            0.776   , 0.774   , 0.771   , 0.769   , 0.7393  , 0.72    ,\n",
       "            0.7144  , 0.7114  , 0.708   , 0.6787  , 0.677   , 0.6753  ,\n",
       "            0.67    , 0.667   , 0.6553  , 0.654   , 0.6406  , 0.632   ,\n",
       "            0.6294  , 0.5996  , 0.595   , 0.585   , 0.572   , 0.5674  ,\n",
       "            0.554   , 0.5303  , 0.511   , 0.5044  , 0.4985  , 0.4915  ,\n",
       "            0.4758  , 0.4714  , 0.46    , 0.459   , 0.45    , 0.435   ,\n",
       "            0.4211  , 0.4011  , 0.3982  , 0.395   , 0.3926  , 0.3909  ,\n",
       "            0.3809  , 0.3503  , 0.3408  , 0.321   , 0.295   , 0.2803  ,\n",
       "            0.269   , 0.2673  , 0.2434  , 0.2366  , 0.2129  , 0.2125  ,\n",
       "            0.2063  , 0.206   , 0.2045  , 0.1987  , 0.1904  , 0.1827  ,\n",
       "            0.1744  , 0.1731  , 0.1692  , 0.164   , 0.1592  , 0.1588  ,\n",
       "            0.1555  , 0.1533  , 0.1531  , 0.149   , 0.141   , 0.1393  ,\n",
       "            0.134   , 0.1317  , 0.1285  , 0.1272  , 0.1249  , 0.1243  ,\n",
       "            0.1236  , 0.11633 , 0.115   , 0.1134  , 0.11163 , 0.11084 ,\n",
       "            0.1093  , 0.10284 , 0.0942  , 0.09186 , 0.0899  , 0.0874  ,\n",
       "            0.0836  , 0.07666 , 0.07355 , 0.07227 , 0.07007 , 0.06964 ,\n",
       "            0.06757 , 0.06635 , 0.066   , 0.06223 , 0.06198 , 0.0603  ,\n",
       "            0.05612 , 0.05594 , 0.05542 , 0.05292 , 0.05225 , 0.0511  ,\n",
       "            0.04724 , 0.0464  , 0.0456  , 0.0451  , 0.04492 , 0.04218 ,\n",
       "            0.04193 , 0.04153 , 0.04138 , 0.03897 , 0.0386  , 0.0376  ,\n",
       "            0.0372  , 0.037   , 0.0369  , 0.03522 , 0.03403 , 0.03143 ,\n",
       "            0.03062 , 0.03038 , 0.03033 , 0.02982 , 0.02881 , 0.02866 ,\n",
       "            0.0286  , 0.02827 , 0.02718 , 0.02518 , 0.02513 , 0.02405 ,\n",
       "            0.02338 , 0.02293 , 0.02289 , 0.02254 , 0.0225  , 0.02148 ,\n",
       "            0.0203  , 0.01894 , 0.01883 , 0.01785 , 0.01758 , 0.01692 ,\n",
       "            0.01685 , 0.01666 , 0.01646 , 0.0161  , 0.01596 , 0.01445 ,\n",
       "            0.01374 , 0.01333 , 0.01248 , 0.01192 , 0.011505, 0.011375,\n",
       "            0.011116, 0.009415, 0.008545, 0.007374, 0.006073, 0.00605 ,\n",
       "            0.0056  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.015625, dtype=float32),\n",
       "    'tpr': array(0.8196721, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.0390625, 0.046875 , 0.046875 , 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.0546875, 0.0625   ,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.109375 , 0.1171875, 0.125    , 0.1328125,\n",
       "            0.1328125, 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.15625  ,\n",
       "            0.1640625, 0.1640625, 0.171875 , 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.1147541 , 0.12295082,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.2704918 ,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.5327869 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9956  , 0.9946  , 0.9937  , 0.9897  , 0.989   ,\n",
       "            0.9883  , 0.986   , 0.985   , 0.9756  , 0.975   , 0.972   ,\n",
       "            0.9707  , 0.9697  , 0.9688  , 0.9663  , 0.963   , 0.9595  ,\n",
       "            0.9585  , 0.9575  , 0.9546  , 0.954   , 0.9536  , 0.95    ,\n",
       "            0.9497  , 0.948   , 0.946   , 0.938   , 0.936   , 0.932   ,\n",
       "            0.931   , 0.9272  , 0.9233  , 0.9214  , 0.917   , 0.916   ,\n",
       "            0.904   , 0.903   , 0.899   , 0.895   , 0.883   , 0.8813  ,\n",
       "            0.8745  , 0.872   , 0.8706  , 0.869   , 0.857   , 0.8564  ,\n",
       "            0.8555  , 0.851   , 0.835   , 0.832   , 0.828   , 0.8267  ,\n",
       "            0.8228  , 0.8154  , 0.8125  , 0.8096  , 0.806   , 0.8037  ,\n",
       "            0.802   , 0.7983  , 0.7974  , 0.797   , 0.7954  , 0.79    ,\n",
       "            0.785   , 0.7773  , 0.7627  , 0.756   , 0.7524  , 0.752   ,\n",
       "            0.7373  , 0.731   , 0.705   , 0.6973  , 0.695   , 0.693   ,\n",
       "            0.6665  , 0.662   , 0.658   , 0.637   , 0.6357  , 0.6245  ,\n",
       "            0.612   , 0.6094  , 0.6025  , 0.5864  , 0.5825  , 0.5786  ,\n",
       "            0.5527  , 0.5444  , 0.539   , 0.518   , 0.5156  , 0.5005  ,\n",
       "            0.4868  , 0.4775  , 0.4656  , 0.4539  , 0.4446  , 0.4329  ,\n",
       "            0.4233  , 0.413   , 0.4038  , 0.4     , 0.3843  , 0.3708  ,\n",
       "            0.358   , 0.3542  , 0.3496  , 0.3433  , 0.3408  , 0.3271  ,\n",
       "            0.314   , 0.2847  , 0.2703  , 0.2544  , 0.2537  , 0.2207  ,\n",
       "            0.207   , 0.1993  , 0.1897  , 0.1892  , 0.1876  , 0.1833  ,\n",
       "            0.1759  , 0.1664  , 0.1663  , 0.1588  , 0.1449  , 0.144   ,\n",
       "            0.1416  , 0.1394  , 0.1392  , 0.1364  , 0.134   , 0.1307  ,\n",
       "            0.1305  , 0.1252  , 0.1216  , 0.12146 , 0.1126  , 0.111   ,\n",
       "            0.10913 , 0.10895 , 0.10706 , 0.1069  , 0.1041  , 0.0986  ,\n",
       "            0.0967  , 0.0898  , 0.0887  , 0.088   , 0.0856  , 0.0851  ,\n",
       "            0.0836  , 0.0802  , 0.0799  , 0.0725  , 0.0698  , 0.06683 ,\n",
       "            0.0662  , 0.0643  , 0.05823 , 0.0553  , 0.055   , 0.05225 ,\n",
       "            0.051   , 0.05072 , 0.04803 , 0.04715 , 0.0462  , 0.0461  ,\n",
       "            0.04544 , 0.04193 , 0.04147 , 0.03943 , 0.03824 , 0.03775 ,\n",
       "            0.03494 , 0.0343  , 0.03354 , 0.0334  , 0.0315  , 0.03108 ,\n",
       "            0.03056 , 0.03033 , 0.02959 , 0.02834 , 0.02759 , 0.02753 ,\n",
       "            0.02733 , 0.02646 , 0.02527 , 0.02452 , 0.02434 , 0.0241  ,\n",
       "            0.02284 , 0.02211 , 0.02191 , 0.02162 , 0.02109 , 0.02104 ,\n",
       "            0.01979 , 0.01909 , 0.0184  , 0.01826 , 0.01805 , 0.01785 ,\n",
       "            0.01672 , 0.0164  , 0.01634 , 0.01567 , 0.014786, 0.01467 ,\n",
       "            0.013794, 0.01359 , 0.01297 , 0.01257 , 0.01248 , 0.01224 ,\n",
       "            0.012054, 0.01196 , 0.01169 , 0.0116  , 0.01103 , 0.00978 ,\n",
       "            0.00934 , 0.00874 , 0.008316, 0.008255, 0.008156, 0.008064,\n",
       "            0.007904, 0.00784 , 0.00669 , 0.006313, 0.00543 , 0.0044  ,\n",
       "            0.00435 , 0.00387 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.015625, dtype=float32),\n",
       "    'tpr': array(0.8196721, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.046875 , 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.0625   , 0.0703125, 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.1015625, 0.1015625, 0.109375 , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.1640625, 0.171875 , 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5409836 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.996   , 0.995   , 0.9937  , 0.9917  , 0.991   ,\n",
       "            0.9893  , 0.9863  , 0.9775  , 0.977   , 0.9756  , 0.974   ,\n",
       "            0.973   , 0.9717  , 0.9707  , 0.968   , 0.9663  , 0.9644  ,\n",
       "            0.963   , 0.9624  , 0.9604  , 0.959   , 0.9575  , 0.9565  ,\n",
       "            0.9526  , 0.95    , 0.948   , 0.947   , 0.945   , 0.9434  ,\n",
       "            0.9395  , 0.936   , 0.9346  , 0.9336  , 0.9307  , 0.9243  ,\n",
       "            0.92    , 0.9185  , 0.911   , 0.907   , 0.906   , 0.9033  ,\n",
       "            0.901   , 0.8867  , 0.8853  , 0.884   , 0.8774  , 0.876   ,\n",
       "            0.872   , 0.868   , 0.8594  , 0.8535  , 0.852   , 0.8384  ,\n",
       "            0.835   , 0.8335  , 0.8306  , 0.8267  , 0.8228  , 0.8145  ,\n",
       "            0.8115  , 0.8105  , 0.806   , 0.8047  , 0.804   , 0.801   ,\n",
       "            0.7954  , 0.791   , 0.785   , 0.783   , 0.766   , 0.762   ,\n",
       "            0.7573  , 0.7534  , 0.745   , 0.737   , 0.7227  , 0.719   ,\n",
       "            0.705   , 0.696   , 0.6914  , 0.6665  , 0.659   , 0.656   ,\n",
       "            0.6343  , 0.6104  , 0.61    , 0.601   , 0.5967  , 0.5806  ,\n",
       "            0.5796  , 0.57    , 0.566   , 0.5615  , 0.543   , 0.5366  ,\n",
       "            0.5317  , 0.5303  , 0.5176  , 0.472   , 0.4578  , 0.4546  ,\n",
       "            0.4233  , 0.419   , 0.4138  , 0.3987  , 0.393   , 0.3792  ,\n",
       "            0.3777  , 0.3564  , 0.3523  , 0.35    , 0.3423  , 0.3315  ,\n",
       "            0.3171  , 0.3025  , 0.2996  , 0.2428  , 0.2426  , 0.2301  ,\n",
       "            0.2277  , 0.2227  , 0.1783  , 0.1763  , 0.1724  , 0.1709  ,\n",
       "            0.1693  , 0.1653  , 0.1643  , 0.164   , 0.1589  , 0.1566  ,\n",
       "            0.1409  , 0.1349  , 0.1283  , 0.1263  , 0.1262  , 0.1256  ,\n",
       "            0.1243  , 0.1128  , 0.112   , 0.1099  , 0.1041  , 0.1032  ,\n",
       "            0.10175 , 0.0991  , 0.0986  , 0.09753 , 0.096   , 0.0899  ,\n",
       "            0.0887  , 0.0879  , 0.07434 , 0.07385 , 0.0724  , 0.0721  ,\n",
       "            0.0656  , 0.06525 , 0.065   , 0.0645  , 0.0613  , 0.0589  ,\n",
       "            0.05844 , 0.05582 , 0.0547  , 0.0531  , 0.0511  , 0.0509  ,\n",
       "            0.05032 , 0.0451  , 0.04184 , 0.0417  , 0.03934 , 0.03845 ,\n",
       "            0.0378  , 0.03595 , 0.03568 , 0.0356  , 0.03494 , 0.0341  ,\n",
       "            0.03302 , 0.0313  , 0.0305  , 0.0301  , 0.02992 , 0.02965 ,\n",
       "            0.02821 , 0.02722 , 0.02692 , 0.0267  , 0.02542 , 0.0247  ,\n",
       "            0.02386 , 0.0232  , 0.0225  , 0.02182 , 0.0217  , 0.02148 ,\n",
       "            0.02057 , 0.02034 , 0.02007 , 0.01942 , 0.0192  , 0.01851 ,\n",
       "            0.01685 , 0.01634 , 0.01622 , 0.01602 , 0.01567 , 0.01525 ,\n",
       "            0.014114, 0.01322 , 0.01287 , 0.01248 , 0.012054, 0.01196 ,\n",
       "            0.011734, 0.01147 , 0.011375, 0.01129 , 0.0112  , 0.01086 ,\n",
       "            0.009636, 0.00948 , 0.00934 , 0.008415, 0.00838 , 0.00803 ,\n",
       "            0.007904, 0.007637, 0.00749 , 0.007404, 0.00629 , 0.006264,\n",
       "            0.005535, 0.00526 , 0.00514 , 0.004665, 0.00387 , 0.00384 ,\n",
       "            0.003607], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.0078125, dtype=float32),\n",
       "    'tpr': array(0.8032787, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.109375 ,\n",
       "            0.109375 , 0.1171875, 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.15625  , 0.15625  , 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9966  , 0.9956  , 0.994   , 0.991   , 0.9907  ,\n",
       "            0.9883  , 0.9844  , 0.9805  , 0.98    , 0.9746  , 0.973   ,\n",
       "            0.9727  , 0.9707  , 0.969   , 0.9663  , 0.9644  , 0.962   ,\n",
       "            0.9614  , 0.961   , 0.9604  , 0.957   , 0.9565  , 0.953   ,\n",
       "            0.9453  , 0.9443  , 0.942   , 0.9404  , 0.9395  , 0.937   ,\n",
       "            0.9355  , 0.928   , 0.9253  , 0.915   , 0.9062  , 0.9023  ,\n",
       "            0.9014  , 0.8945  , 0.8926  , 0.8916  , 0.8833  , 0.883   ,\n",
       "            0.876   , 0.8647  , 0.863   , 0.862   , 0.859   , 0.844   ,\n",
       "            0.8267  , 0.825   , 0.821   , 0.8154  , 0.8105  , 0.809   ,\n",
       "            0.8086  , 0.807   , 0.8066  , 0.8003  , 0.7983  , 0.796   ,\n",
       "            0.7944  , 0.786   , 0.766   , 0.7593  , 0.749   , 0.7456  ,\n",
       "            0.743   , 0.7407  , 0.7373  , 0.7324  , 0.706   , 0.6973  ,\n",
       "            0.695   , 0.691   , 0.68    , 0.6567  , 0.6533  , 0.632   ,\n",
       "            0.6304  , 0.584   , 0.576   , 0.5703  , 0.544   , 0.5356  ,\n",
       "            0.529   , 0.5225  , 0.517   , 0.5156  , 0.506   , 0.5015  ,\n",
       "            0.498   , 0.4824  , 0.4753  , 0.4626  , 0.4463  , 0.434   ,\n",
       "            0.413   , 0.41    , 0.4     , 0.3865  , 0.3582  , 0.3445  ,\n",
       "            0.3442  , 0.3257  , 0.322   , 0.3198  , 0.3147  , 0.2908  ,\n",
       "            0.286   , 0.2854  , 0.2766  , 0.2487  , 0.2255  , 0.1962  ,\n",
       "            0.1892  , 0.187   , 0.186   , 0.1624  , 0.1565  , 0.1543  ,\n",
       "            0.1487  , 0.1433  , 0.1409  , 0.134   , 0.1283  , 0.1226  ,\n",
       "            0.12244 , 0.12146 , 0.1201  , 0.111   , 0.1105  , 0.1084  ,\n",
       "            0.10034 , 0.0986  , 0.0927  , 0.0901  , 0.0874  , 0.0866  ,\n",
       "            0.0851  , 0.0818  , 0.08167 , 0.08154 , 0.0805  , 0.0801  ,\n",
       "            0.07587 , 0.06915 , 0.0689  , 0.06854 , 0.0631  , 0.0576  ,\n",
       "            0.05603 , 0.0543  , 0.0537  , 0.04996 , 0.0485  , 0.0477  ,\n",
       "            0.04587 , 0.04544 , 0.04468 , 0.04385 , 0.04337 , 0.0417  ,\n",
       "            0.04    , 0.0367  , 0.03534 , 0.03528 , 0.03506 , 0.035   ,\n",
       "            0.03168 , 0.02954 , 0.02849 , 0.02834 , 0.02701 , 0.02606 ,\n",
       "            0.02556 , 0.02522 , 0.02475 , 0.02438 , 0.02351 , 0.02254 ,\n",
       "            0.02199 , 0.02191 , 0.02129 , 0.02097 , 0.02069 , 0.02052 ,\n",
       "            0.0196  , 0.01785 , 0.01752 , 0.01718 , 0.0171  , 0.01628 ,\n",
       "            0.01622 , 0.01616 , 0.01567 , 0.015366, 0.01473 , 0.0145  ,\n",
       "            0.014336, 0.01359 , 0.01297 , 0.012825, 0.01277 , 0.012726,\n",
       "            0.011116, 0.01057 , 0.01041 , 0.01037 , 0.01001 , 0.00934 ,\n",
       "            0.00899 , 0.00874 , 0.008675, 0.008575, 0.008545, 0.00819 ,\n",
       "            0.008064, 0.00784 , 0.00752 , 0.007347, 0.00685 , 0.00624 ,\n",
       "            0.006096, 0.0058  , 0.005577, 0.005554, 0.00549 , 0.00524 ,\n",
       "            0.004944, 0.004593, 0.00454 , 0.0041  , 0.003975, 0.00343 ,\n",
       "            0.003311, 0.003185, 0.0028  , 0.00279 , 0.00255 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.8196721, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.09375  , 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.125    , 0.125    , 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.       , 0.997    , 0.996    , 0.995    , 0.994    , 0.9937   ,\n",
       "            0.992    , 0.99     , 0.986    , 0.983    , 0.982    , 0.981    ,\n",
       "            0.9775   , 0.9746   , 0.973    , 0.972    , 0.9707   , 0.97     ,\n",
       "            0.9697   , 0.9683   , 0.9673   , 0.9653   , 0.962    , 0.9595   ,\n",
       "            0.9575   , 0.957    , 0.951    , 0.9497   , 0.9463   , 0.9414   ,\n",
       "            0.941    , 0.9404   , 0.9336   , 0.9263   , 0.9243   , 0.916    ,\n",
       "            0.914    , 0.9116   , 0.904    , 0.901    , 0.9      , 0.899    ,\n",
       "            0.8936   , 0.889    , 0.887    , 0.8794   , 0.8765   , 0.871    ,\n",
       "            0.865    , 0.86     , 0.852    , 0.8457   , 0.844    , 0.836    ,\n",
       "            0.831    , 0.829    , 0.8257   , 0.8223   , 0.8174   , 0.8154   ,\n",
       "            0.815    , 0.8125   , 0.803    , 0.799    , 0.7974   , 0.7827   ,\n",
       "            0.782    , 0.757    , 0.752    , 0.7456   , 0.745    , 0.738    ,\n",
       "            0.727    , 0.7153   , 0.7095   , 0.702    , 0.6934   , 0.68     ,\n",
       "            0.6787   , 0.657    , 0.654    , 0.6426   , 0.63     , 0.621    ,\n",
       "            0.5786   , 0.578    , 0.5557   , 0.5537   , 0.546    , 0.5454   ,\n",
       "            0.538    , 0.5327   , 0.5215   , 0.509    , 0.5063   , 0.489    ,\n",
       "            0.4868   , 0.4587   , 0.439    , 0.4177   , 0.4146   , 0.4004   ,\n",
       "            0.3948   , 0.3901   , 0.3794   , 0.3755   , 0.3508   , 0.327    ,\n",
       "            0.3098   , 0.3032   , 0.2898   , 0.2886   , 0.2722   , 0.2451   ,\n",
       "            0.2401   , 0.2283   , 0.2249   , 0.212    , 0.1621   , 0.1569   ,\n",
       "            0.1562   , 0.1537   , 0.1509   , 0.15     , 0.1458   , 0.1442   ,\n",
       "            0.1439   , 0.1364   , 0.1279   , 0.1166   , 0.1144   , 0.1054   ,\n",
       "            0.1032   , 0.10144  , 0.0998   , 0.09686  , 0.09283  , 0.0925   ,\n",
       "            0.088    , 0.0873   , 0.0863   , 0.0818   , 0.0788   , 0.06903  ,\n",
       "            0.06635  , 0.0662   , 0.0627   , 0.06244  , 0.06085  , 0.05966  ,\n",
       "            0.05624  , 0.0541   , 0.0504   , 0.05023  , 0.04996  , 0.0485   ,\n",
       "            0.04587  , 0.0451   , 0.0437   , 0.04303  , 0.0398   , 0.03955  ,\n",
       "            0.03943  , 0.03812  , 0.03488  , 0.03354  , 0.03333  , 0.03056  ,\n",
       "            0.03038  , 0.02893  , 0.02727  , 0.02701  , 0.02576  , 0.02547  ,\n",
       "            0.02527  , 0.02489  , 0.02457  , 0.02324  , 0.02242  , 0.02191  ,\n",
       "            0.02182  , 0.02097  , 0.02045  , 0.01924  , 0.01816  , 0.01799  ,\n",
       "            0.01778  , 0.01738  , 0.0171   , 0.01628  , 0.01622  , 0.0159   ,\n",
       "            0.01554  , 0.01519  , 0.015076 , 0.015015 , 0.01467  , 0.0145   ,\n",
       "            0.01229  , 0.01147  , 0.01129  , 0.01103  , 0.01086  , 0.01065  ,\n",
       "            0.00986  , 0.00952  , 0.00899  , 0.00892  , 0.008545 , 0.00848  ,\n",
       "            0.008286 , 0.00822  , 0.00784  , 0.007404 , 0.007374 , 0.007065 ,\n",
       "            0.006905 , 0.006878 , 0.00669  , 0.006565 , 0.006413 , 0.00589  ,\n",
       "            0.0056   , 0.005302 , 0.00528  , 0.00524  , 0.0051   , 0.00483  ,\n",
       "            0.004772 , 0.003975 , 0.00387  , 0.003496 , 0.003248 , 0.003016 ,\n",
       "            0.003004 , 0.002705 , 0.002684 , 0.00262  , 0.002378 , 0.001965 ,\n",
       "            0.0019045], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.77868855, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.0390625, 0.046875 , 0.0546875, 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.09375  ,\n",
       "            0.1015625, 0.1015625, 0.109375 , 0.1171875, 0.125    , 0.125    ,\n",
       "            0.1328125, 0.140625 , 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1796875, 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04918033, 0.05737705, 0.07377049, 0.08196721, 0.09016393,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5081967 , 0.52459013, 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.       , 0.9976   , 0.997    , 0.996    , 0.994    , 0.9937   ,\n",
       "            0.9917   , 0.9854   , 0.9844   , 0.982    , 0.9805   , 0.977    ,\n",
       "            0.9746   , 0.9736   , 0.973    , 0.9717   , 0.97     , 0.969    ,\n",
       "            0.9688   , 0.9683   , 0.9653   , 0.9614   , 0.954    , 0.9536   ,\n",
       "            0.9497   , 0.9487   , 0.946    , 0.9443   , 0.9395   , 0.937    ,\n",
       "            0.928    , 0.9253   , 0.92     , 0.916    , 0.91     , 0.904    ,\n",
       "            0.902    , 0.899    , 0.896    , 0.894    , 0.8906   , 0.885    ,\n",
       "            0.8755   , 0.87     , 0.8696   , 0.867    , 0.8667   , 0.8535   ,\n",
       "            0.8496   , 0.8457   , 0.832    , 0.823    , 0.8213   , 0.8184   ,\n",
       "            0.817    , 0.816    , 0.8086   , 0.802    , 0.799    , 0.7983   ,\n",
       "            0.7856   , 0.7754   , 0.7666   , 0.7607   , 0.743    , 0.742    ,\n",
       "            0.7246   , 0.72     , 0.718    , 0.716    , 0.7036   , 0.7026   ,\n",
       "            0.6953   , 0.693    , 0.688    , 0.6504   , 0.646    , 0.6343   ,\n",
       "            0.632    , 0.6206   , 0.598    , 0.5835   , 0.5425   , 0.5386   ,\n",
       "            0.53     , 0.521    , 0.5103   , 0.504    , 0.4885   , 0.486    ,\n",
       "            0.4836   , 0.4556   , 0.4487   , 0.4377   , 0.4316   , 0.4265   ,\n",
       "            0.416    , 0.3784   , 0.3772   , 0.3667   , 0.3599   , 0.3508   ,\n",
       "            0.3423   , 0.3357   , 0.3052   , 0.2878   , 0.2861   , 0.2534   ,\n",
       "            0.2478   , 0.2455   , 0.2397   , 0.208    , 0.189    , 0.1885   ,\n",
       "            0.185    , 0.1826   , 0.1301   , 0.1289   , 0.1283   , 0.1279   ,\n",
       "            0.1236   , 0.12317  , 0.11676  , 0.11554  , 0.1124   , 0.103    ,\n",
       "            0.09235  , 0.09125  , 0.0863   , 0.083    , 0.07965  , 0.0753   ,\n",
       "            0.0721   , 0.0683   , 0.0672   , 0.0666   , 0.06525  , 0.065    ,\n",
       "            0.0636   , 0.06305  , 0.0531   , 0.051    , 0.0506   , 0.04803  ,\n",
       "            0.0478   , 0.045    , 0.0436   , 0.04263  , 0.04077  , 0.0376   ,\n",
       "            0.0354   , 0.03528  , 0.0345   , 0.03424  , 0.03354  , 0.03174  ,\n",
       "            0.03096  , 0.02992  , 0.02763  , 0.02727  , 0.02722  , 0.02538  ,\n",
       "            0.02298  , 0.02254  , 0.02246  , 0.02191  , 0.01999  , 0.01927  ,\n",
       "            0.01816  , 0.01772  , 0.01738  , 0.01718  , 0.01634  , 0.01616  ,\n",
       "            0.01602  , 0.01525  , 0.01519  , 0.014336 , 0.01359  , 0.01243  ,\n",
       "            0.01201  , 0.01169  , 0.01133  , 0.011116 , 0.01099  , 0.01082  ,\n",
       "            0.01078  , 0.01049  , 0.01045  , 0.009895 , 0.00986  , 0.00919  ,\n",
       "            0.008514 , 0.007755 , 0.007347 , 0.007317 , 0.00729  , 0.007065 ,\n",
       "            0.006798 , 0.006218 , 0.00617  , 0.00605  , 0.0058   , 0.0056   ,\n",
       "            0.005577 , 0.00532  , 0.00516  , 0.004738 , 0.004627 , 0.00461  ,\n",
       "            0.0044   , 0.004215 , 0.00415  , 0.004116 , 0.0039   , 0.00368  ,\n",
       "            0.00358  , 0.003525 , 0.00343  , 0.003147 , 0.003136 , 0.003063 ,\n",
       "            0.002935 , 0.002878 , 0.002453 , 0.00235  , 0.002043 , 0.001897 ,\n",
       "            0.001883 , 0.001694 , 0.001642 , 0.0016165, 0.001579 , 0.001484 ,\n",
       "            0.001351 , 0.001099 , 0.001044 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.76229507, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.0390625, 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.09375  ,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.109375 , 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.203125 , 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.578125 ,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04918033, 0.05737705, 0.07377049, 0.08196721, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.43442622, 0.44262296, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9854e-01, 9.9805e-01, 9.9707e-01, 9.9561e-01,\n",
       "            9.9414e-01, 9.9316e-01, 9.8926e-01, 9.8535e-01, 9.8145e-01,\n",
       "            9.8096e-01, 9.8047e-01, 9.7949e-01, 9.7900e-01, 9.7852e-01,\n",
       "            9.7803e-01, 9.7607e-01, 9.7559e-01, 9.7363e-01, 9.6973e-01,\n",
       "            9.6924e-01, 9.6631e-01, 9.6484e-01, 9.6387e-01, 9.6094e-01,\n",
       "            9.5654e-01, 9.5410e-01, 9.5166e-01, 9.4287e-01, 9.3994e-01,\n",
       "            9.3896e-01, 9.3750e-01, 9.2578e-01, 9.2383e-01, 9.1992e-01,\n",
       "            9.1895e-01, 9.1602e-01, 9.1016e-01, 9.0723e-01, 8.9844e-01,\n",
       "            8.9307e-01, 8.8818e-01, 8.7842e-01, 8.7451e-01, 8.7402e-01,\n",
       "            8.6719e-01, 8.6572e-01, 8.4229e-01, 8.3984e-01, 8.3740e-01,\n",
       "            8.3643e-01, 8.3594e-01, 8.2422e-01, 8.2031e-01, 8.1494e-01,\n",
       "            8.0859e-01, 8.0078e-01, 7.9980e-01, 7.8418e-01, 7.7441e-01,\n",
       "            7.7295e-01, 7.5830e-01, 7.4902e-01, 7.4707e-01, 7.4609e-01,\n",
       "            7.4365e-01, 7.2559e-01, 7.1680e-01, 7.1436e-01, 7.0850e-01,\n",
       "            7.0703e-01, 7.0117e-01, 6.8262e-01, 6.6895e-01, 6.6504e-01,\n",
       "            6.5820e-01, 6.3867e-01, 6.1914e-01, 5.7373e-01, 5.6201e-01,\n",
       "            5.5176e-01, 5.4688e-01, 5.2295e-01, 5.2246e-01, 5.1562e-01,\n",
       "            5.0342e-01, 4.8511e-01, 4.8047e-01, 4.6362e-01, 4.4849e-01,\n",
       "            4.4336e-01, 4.2725e-01, 4.2285e-01, 4.1064e-01, 3.9795e-01,\n",
       "            3.8013e-01, 3.7549e-01, 3.6890e-01, 3.5742e-01, 3.3594e-01,\n",
       "            3.2788e-01, 3.2129e-01, 3.1885e-01, 3.1299e-01, 2.8198e-01,\n",
       "            2.7539e-01, 2.5757e-01, 2.4207e-01, 2.0789e-01, 2.0447e-01,\n",
       "            2.0215e-01, 1.8506e-01, 1.8042e-01, 1.6260e-01, 1.4490e-01,\n",
       "            1.2170e-01, 1.2024e-01, 1.1456e-01, 1.1298e-01, 1.1279e-01,\n",
       "            1.1047e-01, 1.1029e-01, 1.0431e-01, 1.0193e-01, 9.2041e-02,\n",
       "            8.7280e-02, 8.6182e-02, 8.1665e-02, 7.7820e-02, 7.4768e-02,\n",
       "            7.3669e-02, 6.8542e-02, 5.8777e-02, 5.8228e-02, 5.8136e-02,\n",
       "            5.6458e-02, 5.3589e-02, 5.2704e-02, 5.1758e-02, 5.0812e-02,\n",
       "            4.1687e-02, 4.1138e-02, 3.9703e-02, 3.9337e-02, 3.7384e-02,\n",
       "            3.4821e-02, 3.3142e-02, 3.2654e-02, 3.2104e-02, 3.0914e-02,\n",
       "            3.0792e-02, 2.9312e-02, 2.8870e-02, 2.8656e-02, 2.6413e-02,\n",
       "            2.5620e-02, 2.4612e-02, 2.2934e-02, 2.1744e-02, 1.8936e-02,\n",
       "            1.8799e-02, 1.8509e-02, 1.8295e-02, 1.8234e-02, 1.6663e-02,\n",
       "            1.6220e-02, 1.5488e-02, 1.4732e-02, 1.4450e-02, 1.3374e-02,\n",
       "            1.3275e-02, 1.2672e-02, 1.2627e-02, 1.2428e-02, 1.1780e-02,\n",
       "            1.1292e-02, 1.1116e-02, 1.0330e-02, 9.4833e-03, 9.1629e-03,\n",
       "            9.1248e-03, 8.9493e-03, 8.7814e-03, 8.7128e-03, 8.4457e-03,\n",
       "            8.4152e-03, 7.6942e-03, 7.4043e-03, 7.1754e-03, 6.9046e-03,\n",
       "            6.2180e-03, 6.1226e-03, 6.0959e-03, 5.9586e-03, 5.9128e-03,\n",
       "            5.7983e-03, 5.4893e-03, 4.8485e-03, 4.6654e-03, 4.4327e-03,\n",
       "            4.3640e-03, 4.3144e-03, 4.1809e-03, 4.1504e-03, 3.6926e-03,\n",
       "            3.6793e-03, 3.6354e-03, 3.5934e-03, 3.3894e-03, 3.1967e-03,\n",
       "            3.1719e-03, 3.0270e-03, 2.8896e-03, 2.7905e-03, 2.7790e-03,\n",
       "            2.7046e-03, 2.6722e-03, 2.4147e-03, 2.3327e-03, 2.2964e-03,\n",
       "            2.0351e-03, 1.8892e-03, 1.7681e-03, 1.7271e-03, 1.7204e-03,\n",
       "            1.7004e-03, 1.6041e-03, 1.3990e-03, 1.2894e-03, 1.2445e-03,\n",
       "            1.2159e-03, 1.2016e-03, 1.1072e-03, 1.0080e-03, 8.1062e-04,\n",
       "            7.0953e-04, 6.5136e-04, 5.6362e-04, 5.0354e-04], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.75409836, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.046875 , 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.109375 , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.15625  , 0.1640625, 0.1640625, 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04918033, 0.05737705, 0.07377049, 0.08196721, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9902e-01, 9.9854e-01, 9.9805e-01, 9.9707e-01,\n",
       "            9.9561e-01, 9.9463e-01, 9.9170e-01, 9.8877e-01, 9.8633e-01,\n",
       "            9.8486e-01, 9.8438e-01, 9.8389e-01, 9.8340e-01, 9.8242e-01,\n",
       "            9.8193e-01, 9.8145e-01, 9.8047e-01, 9.7754e-01, 9.7510e-01,\n",
       "            9.7461e-01, 9.7168e-01, 9.6924e-01, 9.6533e-01, 9.6338e-01,\n",
       "            9.6289e-01, 9.5898e-01, 9.5215e-01, 9.4775e-01, 9.4434e-01,\n",
       "            9.3115e-01, 9.3066e-01, 9.2725e-01, 9.2529e-01, 9.2041e-01,\n",
       "            9.1602e-01, 9.1016e-01, 9.0381e-01, 9.0283e-01, 8.9844e-01,\n",
       "            8.9014e-01, 8.8379e-01, 8.8135e-01, 8.7793e-01, 8.7012e-01,\n",
       "            8.5645e-01, 8.5449e-01, 8.4814e-01, 8.4766e-01, 8.4668e-01,\n",
       "            8.4619e-01, 8.4375e-01, 8.3887e-01, 8.3398e-01, 8.3008e-01,\n",
       "            8.2471e-01, 8.1836e-01, 8.1543e-01, 8.0029e-01, 7.8516e-01,\n",
       "            7.7979e-01, 7.7539e-01, 7.6514e-01, 7.5977e-01, 7.5342e-01,\n",
       "            7.5098e-01, 7.2998e-01, 7.2119e-01, 7.1924e-01, 7.1484e-01,\n",
       "            7.1436e-01, 7.1143e-01, 7.0947e-01, 6.9238e-01, 6.7578e-01,\n",
       "            6.6943e-01, 6.5918e-01, 6.4160e-01, 6.1279e-01, 5.7471e-01,\n",
       "            5.6738e-01, 5.5176e-01, 5.4297e-01, 5.2930e-01, 5.2637e-01,\n",
       "            5.1855e-01, 4.8511e-01, 4.8267e-01, 4.8047e-01, 4.6289e-01,\n",
       "            4.5630e-01, 4.2285e-01, 4.1895e-01, 4.0698e-01, 4.0479e-01,\n",
       "            3.9233e-01, 3.6572e-01, 3.6304e-01, 3.5645e-01, 3.5352e-01,\n",
       "            3.2202e-01, 3.1348e-01, 3.1323e-01, 3.0664e-01, 2.9175e-01,\n",
       "            2.7271e-01, 2.6587e-01, 2.5586e-01, 2.2400e-01, 1.9934e-01,\n",
       "            1.9104e-01, 1.7529e-01, 1.7200e-01, 1.6235e-01, 1.4905e-01,\n",
       "            1.3147e-01, 1.0651e-01, 1.0339e-01, 1.0144e-01, 1.0107e-01,\n",
       "            9.8938e-02, 9.6008e-02, 9.5886e-02, 9.5154e-02, 9.2224e-02,\n",
       "            8.3435e-02, 7.2876e-02, 7.0068e-02, 6.7932e-02, 6.4392e-02,\n",
       "            6.1981e-02, 5.8655e-02, 5.6549e-02, 5.0140e-02, 4.8676e-02,\n",
       "            4.5776e-02, 4.4861e-02, 4.4189e-02, 4.3762e-02, 4.2084e-02,\n",
       "            4.1534e-02, 3.5400e-02, 3.3600e-02, 3.2715e-02, 3.2349e-02,\n",
       "            3.1204e-02, 2.6611e-02, 2.4139e-02, 2.3911e-02, 2.3331e-02,\n",
       "            2.3239e-02, 2.2888e-02, 2.2766e-02, 2.1210e-02, 2.1042e-02,\n",
       "            2.0340e-02, 1.8188e-02, 1.8127e-02, 1.7715e-02, 1.6724e-02,\n",
       "            1.3168e-02, 1.3123e-02, 1.3069e-02, 1.3023e-02, 1.2924e-02,\n",
       "            1.1467e-02, 1.1292e-02, 1.1032e-02, 1.0406e-02, 9.9716e-03,\n",
       "            9.8572e-03, 9.8190e-03, 9.4833e-03, 8.9874e-03, 8.5144e-03,\n",
       "            7.9651e-03, 7.7553e-03, 7.2327e-03, 6.9580e-03, 6.7177e-03,\n",
       "            6.4125e-03, 6.3629e-03, 6.2637e-03, 6.1913e-03, 5.8670e-03,\n",
       "            5.7297e-03, 5.3864e-03, 5.2605e-03, 5.1613e-03, 4.8676e-03,\n",
       "            4.7188e-03, 4.2801e-03, 4.0703e-03, 3.9597e-03, 3.8700e-03,\n",
       "            3.8395e-03, 3.5381e-03, 3.4828e-03, 3.4294e-03, 3.3627e-03,\n",
       "            3.1967e-03, 3.0403e-03, 2.9011e-03, 2.8114e-03, 2.7466e-03,\n",
       "            2.7256e-03, 2.5311e-03, 2.4052e-03, 2.3422e-03, 2.3327e-03,\n",
       "            2.2964e-03, 2.1820e-03, 2.0504e-03, 2.0027e-03, 1.9493e-03,\n",
       "            1.9264e-03, 1.8463e-03, 1.6937e-03, 1.6422e-03, 1.5545e-03,\n",
       "            1.4553e-03, 1.3943e-03, 1.2598e-03, 1.2064e-03, 1.0281e-03,\n",
       "            1.0118e-03, 9.9277e-04, 9.3269e-04, 8.9693e-04, 8.0729e-04,\n",
       "            7.8249e-04, 7.7629e-04, 7.3814e-04, 6.2370e-04, 5.6171e-04,\n",
       "            4.4584e-04, 3.9506e-04, 3.4070e-04, 3.0303e-04, 2.6536e-04],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.75409836, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.0390625, 0.046875 , 0.0546875, 0.0625   ,\n",
       "            0.0625   , 0.0703125, 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.09375  , 0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.08196721, 0.09016393,\n",
       "            0.09836066, 0.12295082, 0.13934426, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.52459013, 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9951e-01, 9.9854e-01, 9.9805e-01, 9.9707e-01,\n",
       "            9.9609e-01, 9.9414e-01, 9.9365e-01, 9.9170e-01, 9.8926e-01,\n",
       "            9.8877e-01, 9.8779e-01, 9.8682e-01, 9.8486e-01, 9.8438e-01,\n",
       "            9.8389e-01, 9.8291e-01, 9.8047e-01, 9.7803e-01, 9.7705e-01,\n",
       "            9.7559e-01, 9.7217e-01, 9.7070e-01, 9.6973e-01, 9.6680e-01,\n",
       "            9.5996e-01, 9.5508e-01, 9.4873e-01, 9.4434e-01, 9.3994e-01,\n",
       "            9.3945e-01, 9.3750e-01, 9.3701e-01, 9.3311e-01, 9.3018e-01,\n",
       "            9.2285e-01, 9.1943e-01, 9.1797e-01, 9.1602e-01, 9.1357e-01,\n",
       "            9.0576e-01, 8.9697e-01, 8.9062e-01, 8.8721e-01, 8.7500e-01,\n",
       "            8.6670e-01, 8.6621e-01, 8.6523e-01, 8.6475e-01, 8.6426e-01,\n",
       "            8.5986e-01, 8.5840e-01, 8.5156e-01, 8.4961e-01, 8.4863e-01,\n",
       "            8.3643e-01, 8.3594e-01, 8.1055e-01, 7.9395e-01, 7.8857e-01,\n",
       "            7.8174e-01, 7.8076e-01, 7.7344e-01, 7.5928e-01, 7.5049e-01,\n",
       "            7.3584e-01, 7.3389e-01, 7.3242e-01, 7.2949e-01, 7.1973e-01,\n",
       "            6.9824e-01, 6.9580e-01, 6.8994e-01, 6.8652e-01, 6.6113e-01,\n",
       "            6.5430e-01, 5.9863e-01, 5.8398e-01, 5.6982e-01, 5.4980e-01,\n",
       "            5.4541e-01, 5.3271e-01, 5.2539e-01, 5.2344e-01, 4.9707e-01,\n",
       "            4.9487e-01, 4.7363e-01, 4.5288e-01, 4.3896e-01, 4.2529e-01,\n",
       "            4.1406e-01, 4.1138e-01, 4.1113e-01, 3.7939e-01, 3.7036e-01,\n",
       "            3.6206e-01, 3.5742e-01, 3.4229e-01, 3.2471e-01, 3.0835e-01,\n",
       "            2.9297e-01, 2.8247e-01, 2.7197e-01, 2.6294e-01, 2.4744e-01,\n",
       "            2.4365e-01, 2.2083e-01, 1.8530e-01, 1.7212e-01, 1.5686e-01,\n",
       "            1.5430e-01, 1.4233e-01, 1.4038e-01, 1.1456e-01, 9.9670e-02,\n",
       "            9.6863e-02, 9.5337e-02, 9.4360e-02, 9.2346e-02, 8.9111e-02,\n",
       "            8.2520e-02, 7.7393e-02, 7.3425e-02, 7.1045e-02, 6.6956e-02,\n",
       "            6.2927e-02, 5.7800e-02, 5.6122e-02, 5.2704e-02, 5.1666e-02,\n",
       "            4.4861e-02, 4.3121e-02, 4.0375e-02, 3.9551e-02, 3.8696e-02,\n",
       "            3.8239e-02, 3.6438e-02, 3.1799e-02, 3.0502e-02, 2.9205e-02,\n",
       "            2.6306e-02, 2.6154e-02, 2.5711e-02, 2.5223e-02, 2.0844e-02,\n",
       "            1.9684e-02, 1.9638e-02, 1.9608e-02, 1.7914e-02, 1.7639e-02,\n",
       "            1.6281e-02, 1.5778e-02, 1.5671e-02, 1.5541e-02, 1.5427e-02,\n",
       "            1.5129e-02, 1.5076e-02, 1.1917e-02, 1.1330e-02, 1.0735e-02,\n",
       "            1.0696e-02, 1.0612e-02, 9.3002e-03, 9.1629e-03, 8.8120e-03,\n",
       "            8.7128e-03, 8.5754e-03, 8.4152e-03, 8.2169e-03, 7.9346e-03,\n",
       "            7.8735e-03, 7.8125e-03, 7.5760e-03, 7.2060e-03, 7.0114e-03,\n",
       "            6.3629e-03, 5.6877e-03, 5.5122e-03, 5.3215e-03, 5.2795e-03,\n",
       "            5.1384e-03, 5.0621e-03, 4.8485e-03, 4.8294e-03, 4.1656e-03,\n",
       "            4.0855e-03, 3.9291e-03, 3.6793e-03, 3.3512e-03, 3.2730e-03,\n",
       "            3.1471e-03, 2.9697e-03, 2.9125e-03, 2.8553e-03, 2.6836e-03,\n",
       "            2.6112e-03, 2.5406e-03, 2.4815e-03, 2.4529e-03, 2.3689e-03,\n",
       "            2.3422e-03, 2.3232e-03, 2.2430e-03, 2.1000e-03, 1.8673e-03,\n",
       "            1.7824e-03, 1.7748e-03, 1.6289e-03, 1.6041e-03, 1.5917e-03,\n",
       "            1.5669e-03, 1.4896e-03, 1.4553e-03, 1.4048e-03, 1.3666e-03,\n",
       "            1.3561e-03, 1.3247e-03, 1.1158e-03, 1.1120e-03, 9.5463e-04,\n",
       "            9.1839e-04, 9.1457e-04, 8.0729e-04, 7.7343e-04, 6.6137e-04,\n",
       "            6.4611e-04, 5.6601e-04, 5.5504e-04, 5.5075e-04, 5.4646e-04,\n",
       "            5.3358e-04, 5.3167e-04, 4.9353e-04, 3.8743e-04, 3.2496e-04,\n",
       "            2.8467e-04, 2.2519e-04, 1.9264e-04, 1.6475e-04, 1.4424e-04,\n",
       "            1.2827e-04], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.75409836, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0625   , 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.09375  ,\n",
       "            0.1015625, 0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.1484375, 0.15625  , 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.890625 ,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.03278688, 0.04098361,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.08196721, 0.09836066,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.1557377 , 0.16393442,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9951e-01, 9.9902e-01, 9.9854e-01, 9.9805e-01,\n",
       "            9.9707e-01, 9.9609e-01, 9.9561e-01, 9.9414e-01, 9.9121e-01,\n",
       "            9.9023e-01, 9.8975e-01, 9.8926e-01, 9.8877e-01, 9.8730e-01,\n",
       "            9.8584e-01, 9.8193e-01, 9.8096e-01, 9.7998e-01, 9.7852e-01,\n",
       "            9.7754e-01, 9.7656e-01, 9.6729e-01, 9.6436e-01, 9.5117e-01,\n",
       "            9.5068e-01, 9.4873e-01, 9.4775e-01, 9.4629e-01, 9.4238e-01,\n",
       "            9.4141e-01, 9.3359e-01, 9.3311e-01, 9.2920e-01, 9.2773e-01,\n",
       "            9.2529e-01, 9.2285e-01, 9.1309e-01, 9.0479e-01, 8.9551e-01,\n",
       "            8.9258e-01, 8.8525e-01, 8.8379e-01, 8.7646e-01, 8.7354e-01,\n",
       "            8.7109e-01, 8.6182e-01, 8.6084e-01, 8.5986e-01, 8.5547e-01,\n",
       "            8.5156e-01, 8.5107e-01, 8.4375e-01, 8.3789e-01, 8.3008e-01,\n",
       "            8.1006e-01, 7.9883e-01, 7.9248e-01, 7.7979e-01, 7.7393e-01,\n",
       "            7.7344e-01, 7.6221e-01, 7.6172e-01, 7.5342e-01, 7.4951e-01,\n",
       "            7.4707e-01, 7.2266e-01, 7.1875e-01, 7.1680e-01, 7.1533e-01,\n",
       "            6.9971e-01, 6.8652e-01, 6.7383e-01, 6.4648e-01, 5.8252e-01,\n",
       "            5.6348e-01, 5.6201e-01, 5.4395e-01, 5.3613e-01, 5.3271e-01,\n",
       "            5.1025e-01, 5.0635e-01, 4.7241e-01, 4.6802e-01, 4.4556e-01,\n",
       "            4.4507e-01, 4.2725e-01, 4.2212e-01, 4.0991e-01, 3.9697e-01,\n",
       "            3.7842e-01, 3.7573e-01, 3.6450e-01, 3.6426e-01, 3.4546e-01,\n",
       "            3.2153e-01, 2.9932e-01, 2.8369e-01, 2.6587e-01, 2.6123e-01,\n",
       "            2.5415e-01, 2.4329e-01, 2.3438e-01, 2.1912e-01, 2.1338e-01,\n",
       "            1.7139e-01, 1.5479e-01, 1.5186e-01, 1.4502e-01, 1.1633e-01,\n",
       "            1.1554e-01, 9.9792e-02, 9.0271e-02, 8.9905e-02, 8.5876e-02,\n",
       "            8.1787e-02, 7.5989e-02, 7.5745e-02, 7.5195e-02, 6.5613e-02,\n",
       "            5.7709e-02, 5.7373e-02, 5.5206e-02, 5.0507e-02, 5.0140e-02,\n",
       "            4.7333e-02, 3.9551e-02, 3.9490e-02, 3.4760e-02, 3.2837e-02,\n",
       "            3.2593e-02, 3.2532e-02, 3.1082e-02, 3.0273e-02, 2.8015e-02,\n",
       "            2.7588e-02, 2.1484e-02, 2.1454e-02, 2.1210e-02, 2.1088e-02,\n",
       "            2.0920e-02, 1.9089e-02, 1.6785e-02, 1.5015e-02, 1.4336e-02,\n",
       "            1.3687e-02, 1.3329e-02, 1.2100e-02, 1.1780e-02, 1.1688e-02,\n",
       "            1.1467e-02, 1.0902e-02, 1.0857e-02, 1.0246e-02, 9.8953e-03,\n",
       "            8.0948e-03, 7.6675e-03, 7.5493e-03, 6.9580e-03, 6.3629e-03,\n",
       "            6.3400e-03, 5.8441e-03, 5.7983e-03, 5.7068e-03, 5.6419e-03,\n",
       "            5.5351e-03, 5.4283e-03, 4.9820e-03, 4.8103e-03, 4.7188e-03,\n",
       "            4.4670e-03, 3.9902e-03, 3.8242e-03, 3.7804e-03, 3.7365e-03,\n",
       "            3.4695e-03, 3.2864e-03, 3.1357e-03, 3.0403e-03, 2.9011e-03,\n",
       "            2.8896e-03, 2.4052e-03, 2.2964e-03, 2.0351e-03, 2.0103e-03,\n",
       "            1.9722e-03, 1.9493e-03, 1.8969e-03, 1.8177e-03, 1.7614e-03,\n",
       "            1.7071e-03, 1.6613e-03, 1.6356e-03, 1.5917e-03, 1.5669e-03,\n",
       "            1.5125e-03, 1.4162e-03, 1.3885e-03, 1.2445e-03, 1.2159e-03,\n",
       "            1.1921e-03, 1.0900e-03, 9.6607e-04, 9.5844e-04, 9.4748e-04,\n",
       "            8.9359e-04, 8.7976e-04, 8.6260e-04, 8.5592e-04, 8.2970e-04,\n",
       "            8.2016e-04, 7.6437e-04, 6.4135e-04, 6.3848e-04, 5.7268e-04,\n",
       "            5.3978e-04, 5.1546e-04, 4.4942e-04, 4.2725e-04, 4.0936e-04,\n",
       "            3.6407e-04, 3.3021e-04, 2.9826e-04, 2.9588e-04, 2.8682e-04,\n",
       "            2.8467e-04, 2.6536e-04, 2.0504e-04, 1.6868e-04, 1.4651e-04,\n",
       "            1.1593e-04, 9.9957e-05, 8.2195e-05, 7.1406e-05, 6.3002e-05],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.72131145, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.0234375, 0.0234375, 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.046875 , 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.09375  , 0.09375  , 0.109375 , 0.1171875, 0.125    , 0.1328125,\n",
       "            0.140625 , 0.140625 , 0.1484375, 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.171875 , 0.1796875, 0.1875   , 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.2421875, 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.01639344, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.1147541 , 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9951e-01, 9.9902e-01, 9.9854e-01, 9.9707e-01,\n",
       "            9.9658e-01, 9.9561e-01, 9.9268e-01, 9.9219e-01, 9.9121e-01,\n",
       "            9.9072e-01, 9.8926e-01, 9.8877e-01, 9.8828e-01, 9.8779e-01,\n",
       "            9.8730e-01, 9.8438e-01, 9.8242e-01, 9.8096e-01, 9.8047e-01,\n",
       "            9.7998e-01, 9.7803e-01, 9.7607e-01, 9.7412e-01, 9.7266e-01,\n",
       "            9.6094e-01, 9.5996e-01, 9.5410e-01, 9.5264e-01, 9.5117e-01,\n",
       "            9.4922e-01, 9.3945e-01, 9.3555e-01, 9.3457e-01, 9.3408e-01,\n",
       "            9.2822e-01, 9.1553e-01, 9.1504e-01, 9.1455e-01, 9.1357e-01,\n",
       "            8.9014e-01, 8.8818e-01, 8.8721e-01, 8.8379e-01, 8.7500e-01,\n",
       "            8.7402e-01, 8.6084e-01, 8.5938e-01, 8.5303e-01, 8.4961e-01,\n",
       "            8.4326e-01, 8.3496e-01, 8.3447e-01, 8.3057e-01, 8.2910e-01,\n",
       "            8.2031e-01, 8.1641e-01, 8.1250e-01, 7.7100e-01, 7.7051e-01,\n",
       "            7.6953e-01, 7.6318e-01, 7.3926e-01, 7.3828e-01, 7.2949e-01,\n",
       "            7.2607e-01, 7.2510e-01, 7.1436e-01, 6.9141e-01, 6.8408e-01,\n",
       "            6.7139e-01, 6.6650e-01, 6.6406e-01, 6.4990e-01, 5.8301e-01,\n",
       "            5.4639e-01, 5.0928e-01, 5.0732e-01, 5.0391e-01, 4.9780e-01,\n",
       "            4.9048e-01, 4.5483e-01, 4.2480e-01, 4.1772e-01, 4.1260e-01,\n",
       "            4.0576e-01, 3.9355e-01, 3.8501e-01, 3.8257e-01, 3.6768e-01,\n",
       "            3.5376e-01, 3.5010e-01, 3.3862e-01, 3.1982e-01, 3.1030e-01,\n",
       "            3.0835e-01, 2.6294e-01, 2.5342e-01, 2.4866e-01, 2.3938e-01,\n",
       "            2.2021e-01, 2.1008e-01, 1.9763e-01, 1.9482e-01, 1.8567e-01,\n",
       "            1.7957e-01, 1.4880e-01, 1.3318e-01, 1.3000e-01, 1.2451e-01,\n",
       "            9.0881e-02, 8.3130e-02, 7.7942e-02, 7.6538e-02, 7.2510e-02,\n",
       "            6.9397e-02, 6.7078e-02, 6.5125e-02, 5.9540e-02, 5.3497e-02,\n",
       "            5.1758e-02, 4.7424e-02, 4.1931e-02, 3.8605e-02, 2.9587e-02,\n",
       "            2.8168e-02, 2.7695e-02, 2.6657e-02, 2.6306e-02, 2.4521e-02,\n",
       "            2.4094e-02, 2.2461e-02, 2.1912e-02, 2.1576e-02, 1.9714e-02,\n",
       "            1.6922e-02, 1.6525e-02, 1.5541e-02, 1.4671e-02, 1.2924e-02,\n",
       "            1.2573e-02, 9.4147e-03, 8.8501e-03, 8.5144e-03, 7.9651e-03,\n",
       "            7.5760e-03, 7.4883e-03, 7.3738e-03, 7.1220e-03, 6.9847e-03,\n",
       "            6.9046e-03, 6.2180e-03, 5.1613e-03, 5.0812e-03, 4.8294e-03,\n",
       "            4.8103e-03, 4.6463e-03, 4.5547e-03, 4.2496e-03, 4.1351e-03,\n",
       "            4.0550e-03, 3.6793e-03, 3.5515e-03, 3.4294e-03, 3.4027e-03,\n",
       "            3.1853e-03, 2.9583e-03, 2.9354e-03, 2.9125e-03, 2.7580e-03,\n",
       "            2.4338e-03, 2.4242e-03, 2.3689e-03, 2.1496e-03, 2.0828e-03,\n",
       "            1.8749e-03, 1.8177e-03, 1.7138e-03, 1.6747e-03, 1.5364e-03,\n",
       "            1.3094e-03, 1.2445e-03, 1.1921e-03, 1.1559e-03, 1.1339e-03,\n",
       "            1.0242e-03, 9.9277e-04, 9.8515e-04, 9.5844e-04, 9.2554e-04,\n",
       "            9.1839e-04, 8.4257e-04, 8.3923e-04, 8.2016e-04, 7.3814e-04,\n",
       "            7.0953e-04, 6.9857e-04, 6.5660e-04, 5.7459e-04, 5.4407e-04,\n",
       "            5.2977e-04, 5.0926e-04, 4.8971e-04, 4.7278e-04, 4.6182e-04,\n",
       "            4.6015e-04, 4.4775e-04, 4.1080e-04, 3.9363e-04, 3.3808e-04,\n",
       "            3.2759e-04, 3.0541e-04, 2.5916e-04, 2.5511e-04, 2.2173e-04,\n",
       "            2.0993e-04, 2.0826e-04, 1.7810e-04, 1.6737e-04, 1.6606e-04,\n",
       "            1.4424e-04, 1.4317e-04, 1.3769e-04, 1.3447e-04, 1.2732e-04,\n",
       "            9.6858e-05, 7.7248e-05, 6.7115e-05, 4.7565e-05, 4.6849e-05,\n",
       "            3.2187e-05, 3.0220e-05, 2.5451e-05], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.6967213, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0625   , 0.0703125, 0.078125 , 0.078125 ,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.140625 , 0.1484375, 0.1484375, 0.15625  , 0.1640625, 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.609375 , 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.02459016, 0.04098361, 0.06557377, 0.08196721,\n",
       "            0.09836066, 0.10655738, 0.12295082, 0.13114753, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18852459, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.52459013, 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9951e-01, 9.9902e-01, 9.9756e-01, 9.9707e-01,\n",
       "            9.9414e-01, 9.9365e-01, 9.9316e-01, 9.9268e-01, 9.9170e-01,\n",
       "            9.9121e-01, 9.8975e-01, 9.8877e-01, 9.8779e-01, 9.8535e-01,\n",
       "            9.8389e-01, 9.7949e-01, 9.7852e-01, 9.7705e-01, 9.7510e-01,\n",
       "            9.7412e-01, 9.6191e-01, 9.6143e-01, 9.5996e-01, 9.5898e-01,\n",
       "            9.4971e-01, 9.4873e-01, 9.4580e-01, 9.3750e-01, 9.3115e-01,\n",
       "            9.3018e-01, 9.2627e-01, 9.2432e-01, 9.1650e-01, 9.1309e-01,\n",
       "            9.0918e-01, 9.0430e-01, 9.0186e-01, 9.0137e-01, 8.9697e-01,\n",
       "            8.8770e-01, 8.8232e-01, 8.6865e-01, 8.6523e-01, 8.6279e-01,\n",
       "            8.5742e-01, 8.5352e-01, 8.4570e-01, 8.4473e-01, 8.3838e-01,\n",
       "            8.3594e-01, 8.2959e-01, 8.2178e-01, 7.9980e-01, 7.9248e-01,\n",
       "            7.8809e-01, 7.8223e-01, 7.7588e-01, 7.5586e-01, 7.5293e-01,\n",
       "            7.4512e-01, 7.3389e-01, 7.2949e-01, 7.0557e-01, 7.0312e-01,\n",
       "            7.0215e-01, 6.6064e-01, 6.5527e-01, 6.4355e-01, 6.3379e-01,\n",
       "            6.1377e-01, 5.4443e-01, 5.4053e-01, 4.8633e-01, 4.7437e-01,\n",
       "            4.7192e-01, 4.7046e-01, 4.4946e-01, 4.3018e-01, 3.9575e-01,\n",
       "            3.9331e-01, 3.8013e-01, 3.7842e-01, 3.7720e-01, 3.7646e-01,\n",
       "            3.5645e-01, 3.5596e-01, 3.3960e-01, 3.1812e-01, 3.1372e-01,\n",
       "            2.8979e-01, 2.8418e-01, 2.7734e-01, 2.4060e-01, 2.2949e-01,\n",
       "            2.2424e-01, 2.1606e-01, 1.8970e-01, 1.8225e-01, 1.7737e-01,\n",
       "            1.7297e-01, 1.4819e-01, 1.4783e-01, 1.2512e-01, 1.2347e-01,\n",
       "            1.0229e-01, 1.0126e-01, 6.8787e-02, 6.5979e-02, 6.5857e-02,\n",
       "            6.4758e-02, 6.3110e-02, 6.0974e-02, 5.6854e-02, 5.4504e-02,\n",
       "            4.9316e-02, 4.2816e-02, 4.2084e-02, 4.1534e-02, 3.3783e-02,\n",
       "            3.3600e-02, 2.9419e-02, 2.3560e-02, 2.0645e-02, 1.9608e-02,\n",
       "            1.9196e-02, 1.8539e-02, 1.8433e-02, 1.8265e-02, 1.8097e-02,\n",
       "            1.7715e-02, 1.6724e-02, 1.3901e-02, 1.2772e-02, 1.2573e-02,\n",
       "            1.2428e-02, 9.8953e-03, 9.5215e-03, 9.3002e-03, 8.0338e-03,\n",
       "            7.5493e-03, 7.3738e-03, 6.5880e-03, 5.7983e-03, 5.3635e-03,\n",
       "            5.2605e-03, 4.9438e-03, 4.8294e-03, 4.6654e-03, 4.3831e-03,\n",
       "            4.2801e-03, 4.1161e-03, 3.6068e-03, 3.5648e-03, 3.5381e-03,\n",
       "            3.1853e-03, 3.1242e-03, 3.0270e-03, 2.7256e-03, 2.6836e-03,\n",
       "            2.5311e-03, 2.4624e-03, 2.3880e-03, 2.2526e-03, 2.1000e-03,\n",
       "            2.0504e-03, 2.0103e-03, 1.9722e-03, 1.9045e-03, 1.8892e-03,\n",
       "            1.8749e-03, 1.8311e-03, 1.7548e-03, 1.7481e-03, 1.5612e-03,\n",
       "            1.4782e-03, 1.3304e-03, 1.2493e-03, 1.1244e-03, 1.0481e-03,\n",
       "            1.0443e-03, 9.0742e-04, 7.7629e-04, 7.4100e-04, 7.1812e-04,\n",
       "            6.9857e-04, 6.8235e-04, 6.7186e-04, 6.4611e-04, 6.1893e-04,\n",
       "            5.7936e-04, 5.7030e-04, 5.6171e-04, 5.2547e-04, 4.7112e-04,\n",
       "            4.6182e-04, 4.3058e-04, 4.2558e-04, 3.9673e-04, 3.7408e-04,\n",
       "            3.5000e-04, 3.2759e-04, 3.1495e-04, 3.0303e-04, 2.9588e-04,\n",
       "            2.8253e-04, 2.7585e-04, 2.6727e-04, 2.6321e-04, 2.4533e-04,\n",
       "            2.2173e-04, 2.0659e-04, 1.8811e-04, 1.8382e-04, 1.7405e-04,\n",
       "            1.3447e-04, 1.2827e-04, 1.2732e-04, 1.1325e-04, 1.0473e-04,\n",
       "            9.6083e-05, 9.4593e-05, 9.1016e-05, 7.2539e-05, 7.2002e-05,\n",
       "            6.6042e-05, 6.4015e-05, 4.7207e-05, 3.7372e-05, 3.2723e-05,\n",
       "            2.3007e-05, 2.2113e-05, 1.5438e-05, 1.3411e-05, 1.1504e-05],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.7295082, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.046875 , 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.0859375, 0.09375  , 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.125    , 0.125    , 0.1328125, 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.04098361, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.10655738, 0.1147541 , 0.13114753,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.21311475, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 1.0000e+00, 9.9951e-01, 9.9854e-01, 9.9805e-01,\n",
       "            9.9756e-01, 9.9609e-01, 9.9561e-01, 9.9512e-01, 9.9414e-01,\n",
       "            9.9365e-01, 9.9316e-01, 9.9219e-01, 9.9072e-01, 9.8926e-01,\n",
       "            9.8877e-01, 9.8730e-01, 9.8633e-01, 9.8535e-01, 9.8486e-01,\n",
       "            9.7656e-01, 9.7412e-01, 9.7021e-01, 9.6924e-01, 9.6631e-01,\n",
       "            9.5996e-01, 9.5654e-01, 9.4824e-01, 9.4629e-01, 9.4482e-01,\n",
       "            9.4385e-01, 9.3945e-01, 9.3799e-01, 9.3311e-01, 9.2822e-01,\n",
       "            9.2383e-01, 9.1943e-01, 9.1699e-01, 9.1650e-01, 9.1455e-01,\n",
       "            9.0430e-01, 9.0137e-01, 8.9600e-01, 8.9209e-01, 8.9062e-01,\n",
       "            8.8428e-01, 8.8330e-01, 8.7842e-01, 8.7646e-01, 8.7207e-01,\n",
       "            8.5645e-01, 8.5010e-01, 8.4717e-01, 8.3447e-01, 8.0908e-01,\n",
       "            8.0664e-01, 8.0518e-01, 7.9443e-01, 7.7441e-01, 7.7246e-01,\n",
       "            7.6807e-01, 7.6025e-01, 7.5586e-01, 7.3975e-01, 7.2949e-01,\n",
       "            7.2705e-01, 6.9922e-01, 6.9824e-01, 6.7773e-01, 5.8252e-01,\n",
       "            5.7227e-01, 5.5908e-01, 5.4590e-01, 5.4395e-01, 5.2539e-01,\n",
       "            5.1416e-01, 4.9902e-01, 4.6777e-01, 4.5850e-01, 4.4043e-01,\n",
       "            4.3188e-01, 4.1772e-01, 4.0283e-01, 3.9282e-01, 3.7280e-01,\n",
       "            3.6475e-01, 3.4741e-01, 3.4595e-01, 3.4058e-01, 3.2715e-01,\n",
       "            3.1323e-01, 2.7002e-01, 2.6807e-01, 2.5415e-01, 2.4414e-01,\n",
       "            2.3547e-01, 2.0605e-01, 2.0264e-01, 1.8909e-01, 1.4001e-01,\n",
       "            1.3794e-01, 1.3708e-01, 1.2067e-01, 1.1969e-01, 1.0248e-01,\n",
       "            7.4341e-02, 7.4219e-02, 7.3303e-02, 6.0638e-02, 6.0516e-02,\n",
       "            5.8990e-02, 5.8441e-02, 5.4504e-02, 5.2246e-02, 5.0507e-02,\n",
       "            4.6814e-02, 4.5532e-02, 4.0833e-02, 3.6285e-02, 2.9877e-02,\n",
       "            2.0172e-02, 1.9760e-02, 1.9348e-02, 1.9012e-02, 1.7441e-02,\n",
       "            1.7242e-02, 1.6983e-02, 1.4900e-02, 1.4282e-02, 1.3901e-02,\n",
       "            1.3168e-02, 1.0735e-02, 1.0452e-02, 9.5215e-03, 8.5144e-03,\n",
       "            6.4392e-03, 6.1455e-03, 5.8670e-03, 5.6648e-03, 5.6419e-03,\n",
       "            5.1003e-03, 4.9057e-03, 4.8294e-03, 4.7569e-03, 4.6272e-03,\n",
       "            3.9291e-03, 3.8548e-03, 3.3894e-03, 2.9812e-03, 2.8114e-03,\n",
       "            2.6321e-03, 2.5902e-03, 2.5311e-03, 2.5215e-03, 2.4815e-03,\n",
       "            2.2602e-03, 2.1915e-03, 2.1152e-03, 1.8387e-03, 1.7748e-03,\n",
       "            1.7271e-03, 1.7138e-03, 1.6108e-03, 1.5011e-03, 1.4162e-03,\n",
       "            1.3885e-03, 1.3723e-03, 1.2255e-03, 1.1787e-03, 1.1740e-03,\n",
       "            1.1559e-03, 1.1511e-03, 1.1034e-03, 1.0281e-03, 9.5081e-04,\n",
       "            9.1124e-04, 6.6662e-04, 6.4611e-04, 5.9557e-04, 5.8174e-04,\n",
       "            5.0926e-04, 5.0545e-04, 4.7278e-04, 4.5466e-04, 4.2558e-04,\n",
       "            4.1890e-04, 4.0770e-04, 3.6979e-04, 3.3021e-04, 3.1257e-04,\n",
       "            3.0303e-04, 2.6536e-04, 2.5129e-04, 2.2697e-04, 2.1827e-04,\n",
       "            2.1482e-04, 2.0993e-04, 2.0027e-04, 1.9562e-04, 1.8239e-04,\n",
       "            1.7810e-04, 1.7679e-04, 1.5724e-04, 1.4889e-04, 1.4770e-04,\n",
       "            1.4091e-04, 1.3232e-04, 1.0389e-04, 8.6844e-05, 8.3506e-05,\n",
       "            6.6578e-05, 6.6042e-05, 6.4015e-05, 5.4777e-05, 5.2691e-05,\n",
       "            5.0664e-05, 4.3631e-05, 3.4511e-05, 3.4273e-05, 3.3975e-05,\n",
       "            3.1173e-05, 2.9981e-05, 2.1935e-05, 1.6987e-05, 1.4961e-05,\n",
       "            1.0967e-05, 9.7156e-06, 7.0333e-06, 5.5432e-06, 4.8876e-06],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.704918, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.078125 , 0.078125 , 0.0859375,\n",
       "            0.0859375, 0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.1171875, 0.125    , 0.125    , 0.1328125, 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.02459016, 0.04098361, 0.05737705, 0.07377049,\n",
       "            0.08196721, 0.10655738, 0.1147541 , 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.18032786, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 1.0000e+00, 9.9951e-01, 9.9902e-01, 9.9854e-01,\n",
       "            9.9805e-01, 9.9707e-01, 9.9658e-01, 9.9561e-01, 9.9512e-01,\n",
       "            9.9365e-01, 9.9316e-01, 9.9219e-01, 9.9072e-01, 9.8975e-01,\n",
       "            9.8730e-01, 9.8584e-01, 9.8242e-01, 9.8096e-01, 9.8047e-01,\n",
       "            9.7754e-01, 9.7510e-01, 9.7217e-01, 9.6924e-01, 9.6875e-01,\n",
       "            9.6582e-01, 9.6338e-01, 9.5361e-01, 9.4678e-01, 9.4531e-01,\n",
       "            9.4385e-01, 9.4092e-01, 9.3994e-01, 9.3311e-01, 9.3262e-01,\n",
       "            9.3164e-01, 9.2871e-01, 9.0576e-01, 9.0332e-01, 9.0088e-01,\n",
       "            8.9453e-01, 8.9258e-01, 8.8721e-01, 8.8477e-01, 8.8281e-01,\n",
       "            8.7109e-01, 8.6865e-01, 8.6377e-01, 8.6328e-01, 8.5156e-01,\n",
       "            8.4131e-01, 8.2861e-01, 8.2764e-01, 8.2568e-01, 7.9980e-01,\n",
       "            7.9590e-01, 7.9004e-01, 7.8857e-01, 7.8174e-01, 7.7588e-01,\n",
       "            7.5146e-01, 7.4707e-01, 7.4414e-01, 7.2754e-01, 6.8799e-01,\n",
       "            6.8311e-01, 6.6260e-01, 6.5576e-01, 6.0059e-01, 5.6201e-01,\n",
       "            5.4541e-01, 5.0342e-01, 4.9292e-01, 4.8389e-01, 4.7607e-01,\n",
       "            4.4043e-01, 4.1528e-01, 4.0649e-01, 3.9966e-01, 3.7720e-01,\n",
       "            3.6499e-01, 3.6475e-01, 3.5278e-01, 3.4814e-01, 3.4570e-01,\n",
       "            3.2910e-01, 3.2080e-01, 2.8833e-01, 2.8564e-01, 2.7075e-01,\n",
       "            2.4658e-01, 2.3682e-01, 2.1191e-01, 2.0630e-01, 1.9299e-01,\n",
       "            1.8359e-01, 1.8079e-01, 1.4392e-01, 1.3013e-01, 1.2903e-01,\n",
       "            1.1932e-01, 1.1029e-01, 9.2224e-02, 8.8501e-02, 6.3965e-02,\n",
       "            5.7068e-02, 5.2246e-02, 5.0598e-02, 4.9591e-02, 4.9316e-02,\n",
       "            4.6631e-02, 4.3121e-02, 4.1840e-02, 3.6987e-02, 3.4302e-02,\n",
       "            3.1921e-02, 2.6154e-02, 2.4429e-02, 2.3285e-02, 1.5900e-02,\n",
       "            1.5839e-02, 1.3428e-02, 1.3168e-02, 1.1330e-02, 1.1032e-02,\n",
       "            1.0902e-02, 1.0780e-02, 1.0406e-02, 9.6741e-03, 8.0643e-03,\n",
       "            6.8245e-03, 6.3629e-03, 5.7983e-03, 5.6877e-03, 5.1994e-03,\n",
       "            3.9597e-03, 3.8700e-03, 3.3760e-03, 3.2101e-03, 2.7905e-03,\n",
       "            2.7466e-03, 2.6207e-03, 2.4242e-03, 2.2259e-03, 2.2163e-03,\n",
       "            2.1324e-03, 1.8606e-03, 1.7824e-03, 1.7614e-03, 1.7481e-03,\n",
       "            1.6680e-03, 1.6356e-03, 1.5488e-03, 1.5125e-03, 1.2894e-03,\n",
       "            1.2493e-03, 1.2159e-03, 1.0815e-03, 1.0729e-03, 9.5844e-04,\n",
       "            9.1457e-04, 8.5592e-04, 8.2302e-04, 8.2016e-04, 8.1062e-04,\n",
       "            7.7629e-04, 7.4387e-04, 7.3528e-04, 7.2098e-04, 7.0429e-04,\n",
       "            6.8235e-04, 6.5374e-04, 5.8842e-04, 5.4836e-04, 5.1737e-04,\n",
       "            5.1546e-04, 4.4084e-04, 3.5977e-04, 3.5691e-04, 3.1495e-04,\n",
       "            3.0780e-04, 2.6727e-04, 2.5129e-04, 2.4152e-04, 2.3782e-04,\n",
       "            2.3234e-04, 2.2173e-04, 2.0659e-04, 1.9717e-04, 1.8668e-04,\n",
       "            1.8525e-04, 1.7130e-04, 1.5473e-04, 1.4544e-04, 1.4317e-04,\n",
       "            1.2529e-04, 1.1235e-04, 1.0473e-04, 1.0389e-04, 1.0312e-04,\n",
       "            1.0228e-04, 9.7632e-05, 9.3877e-05, 9.1016e-05, 7.9691e-05,\n",
       "            7.7248e-05, 6.4015e-05, 5.6505e-05, 5.6088e-05, 5.5611e-05,\n",
       "            5.3048e-05, 4.8697e-05, 3.7372e-05, 3.5942e-05, 3.2723e-05,\n",
       "            2.8610e-05, 2.6047e-05, 2.5868e-05, 2.5451e-05, 2.3007e-05,\n",
       "            1.8477e-05, 1.7643e-05, 1.7524e-05, 1.7107e-05, 1.5914e-05,\n",
       "            1.5438e-05, 1.1325e-05, 8.4043e-06, 7.9870e-06, 6.3181e-06,\n",
       "            4.5896e-06, 3.8743e-06, 2.5034e-06, 2.2054e-06], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.7295082, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.0390625, 0.046875 , 0.0546875, 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.0859375,\n",
       "            0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.109375 , 0.109375 ,\n",
       "            0.1171875, 0.1171875, 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.02459016, 0.04918033, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.10655738, 0.1147541 , 0.13934426, 0.1557377 ,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 1.0000e+00, 9.9951e-01, 9.9902e-01, 9.9854e-01,\n",
       "            9.9805e-01, 9.9756e-01, 9.9707e-01, 9.9658e-01, 9.9609e-01,\n",
       "            9.9561e-01, 9.9463e-01, 9.9365e-01, 9.9316e-01, 9.9170e-01,\n",
       "            9.9121e-01, 9.8926e-01, 9.8877e-01, 9.8828e-01, 9.8242e-01,\n",
       "            9.8145e-01, 9.8047e-01, 9.7852e-01, 9.7559e-01, 9.7363e-01,\n",
       "            9.7119e-01, 9.6973e-01, 9.6533e-01, 9.5996e-01, 9.5557e-01,\n",
       "            9.5508e-01, 9.5459e-01, 9.5264e-01, 9.4727e-01, 9.4678e-01,\n",
       "            9.4092e-01, 9.3701e-01, 9.3506e-01, 9.2188e-01, 9.2139e-01,\n",
       "            9.1357e-01, 9.0967e-01, 9.0771e-01, 9.0332e-01, 9.0234e-01,\n",
       "            8.9600e-01, 8.9404e-01, 8.8818e-01, 8.8086e-01, 8.5693e-01,\n",
       "            8.5107e-01, 8.4229e-01, 8.3838e-01, 8.3301e-01, 8.1299e-01,\n",
       "            8.0664e-01, 7.9834e-01, 7.8369e-01, 7.8174e-01, 7.7539e-01,\n",
       "            7.7490e-01, 7.6855e-01, 7.5195e-01, 7.2900e-01, 7.2754e-01,\n",
       "            7.0801e-01, 6.9189e-01, 5.8643e-01, 5.7471e-01, 5.5420e-01,\n",
       "            5.4980e-01, 5.4639e-01, 5.2344e-01, 5.0732e-01, 4.8511e-01,\n",
       "            4.4727e-01, 4.4653e-01, 4.4263e-01, 4.1235e-01, 4.0332e-01,\n",
       "            3.8989e-01, 3.7061e-01, 3.7012e-01, 3.5010e-01, 3.4448e-01,\n",
       "            3.4204e-01, 3.3496e-01, 3.1055e-01, 2.8491e-01, 2.4487e-01,\n",
       "            2.4304e-01, 2.3706e-01, 2.2888e-01, 2.1619e-01, 1.9983e-01,\n",
       "            1.7993e-01, 1.7078e-01, 1.2610e-01, 1.1163e-01, 1.0742e-01,\n",
       "            1.0449e-01, 8.7280e-02, 6.1890e-02, 6.1768e-02, 4.9774e-02,\n",
       "            4.8767e-02, 4.8492e-02, 4.7424e-02, 4.6722e-02, 4.4434e-02,\n",
       "            4.1077e-02, 3.9276e-02, 3.5889e-02, 3.5156e-02, 3.3661e-02,\n",
       "            2.9312e-02, 2.5375e-02, 2.2156e-02, 1.4114e-02, 1.2627e-02,\n",
       "            1.2337e-02, 1.1688e-02, 1.1200e-02, 8.9874e-03, 8.6746e-03,\n",
       "            7.8430e-03, 7.7248e-03, 7.2594e-03, 5.3444e-03, 4.2000e-03,\n",
       "            3.7212e-03, 3.5515e-03, 3.1605e-03, 3.1109e-03, 2.6321e-03,\n",
       "            2.5406e-03, 2.2335e-03, 2.1744e-03, 2.1324e-03, 2.0580e-03,\n",
       "            1.8463e-03, 1.7891e-03, 1.7271e-03, 1.7071e-03, 1.6422e-03,\n",
       "            1.4439e-03, 1.3885e-03, 1.1787e-03, 1.1606e-03, 1.1559e-03,\n",
       "            1.1292e-03, 1.0815e-03, 1.0319e-03, 1.0242e-03, 1.0080e-03,\n",
       "            9.5844e-04, 8.5258e-04, 7.7343e-04, 7.2670e-04, 6.9332e-04,\n",
       "            6.8521e-04, 6.6662e-04, 6.1178e-04, 6.0701e-04, 5.3787e-04,\n",
       "            5.1928e-04, 4.7278e-04, 4.7112e-04, 4.4250e-04, 4.1890e-04,\n",
       "            3.8910e-04, 3.7408e-04, 3.5691e-04, 3.3283e-04, 3.2759e-04,\n",
       "            2.6536e-04, 2.5129e-04, 2.4533e-04, 2.0993e-04, 2.0826e-04,\n",
       "            1.9562e-04, 1.8811e-04, 1.7405e-04, 1.4997e-04, 1.3661e-04,\n",
       "            1.3137e-04, 1.2732e-04, 1.1772e-04, 1.0473e-04, 1.0389e-04,\n",
       "            1.0312e-04, 9.2447e-05, 8.1539e-05, 8.0287e-05, 7.6592e-05,\n",
       "            7.3671e-05, 6.4552e-05, 6.0141e-05, 5.8293e-05, 5.4777e-05,\n",
       "            5.4359e-05, 5.3048e-05, 5.0247e-05, 4.7207e-05, 4.4703e-05,\n",
       "            4.3333e-05, 4.2677e-05, 4.1664e-05, 2.7776e-05, 2.6703e-05,\n",
       "            2.4855e-05, 1.9372e-05, 1.9073e-05, 1.7762e-05, 1.5438e-05,\n",
       "            1.3649e-05, 1.2994e-05, 1.2338e-05, 1.1146e-05, 8.9407e-06,\n",
       "            8.3447e-06, 8.2850e-06, 7.5698e-06, 7.0930e-06, 5.2452e-06,\n",
       "            3.8147e-06, 3.1590e-06, 1.9073e-06, 1.7881e-06, 8.9407e-07],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.704918, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.109375 ,\n",
       "            0.109375 , 0.125    , 0.1328125, 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.984375 , 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.04098361, 0.06557377, 0.09836066, 0.1147541 ,\n",
       "            0.13114753, 0.1557377 , 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 1.0000e+00, 9.9951e-01, 9.9902e-01, 9.9854e-01,\n",
       "            9.9805e-01, 9.9707e-01, 9.9658e-01, 9.9561e-01, 9.9463e-01,\n",
       "            9.9316e-01, 9.9072e-01, 9.8926e-01, 9.8828e-01, 9.8779e-01,\n",
       "            9.8682e-01, 9.8633e-01, 9.8486e-01, 9.8389e-01, 9.8340e-01,\n",
       "            9.8145e-01, 9.7998e-01, 9.7217e-01, 9.7119e-01, 9.6924e-01,\n",
       "            9.6436e-01, 9.6191e-01, 9.5703e-01, 9.5117e-01, 9.4922e-01,\n",
       "            9.4775e-01, 9.3945e-01, 9.3652e-01, 9.2725e-01, 9.1504e-01,\n",
       "            9.0967e-01, 9.0820e-01, 9.0527e-01, 9.0283e-01, 9.0088e-01,\n",
       "            8.9941e-01, 8.9453e-01, 8.9160e-01, 8.9014e-01, 8.8721e-01,\n",
       "            8.8281e-01, 8.6670e-01, 8.5986e-01, 8.5840e-01, 8.5156e-01,\n",
       "            8.3594e-01, 8.2666e-01, 8.0566e-01, 8.0176e-01, 7.7148e-01,\n",
       "            7.7051e-01, 7.4268e-01, 7.1875e-01, 7.1191e-01, 6.7969e-01,\n",
       "            6.6162e-01, 6.4453e-01, 5.5859e-01, 5.5225e-01, 5.3467e-01,\n",
       "            5.2930e-01, 4.8999e-01, 4.8828e-01, 4.8193e-01, 4.6729e-01,\n",
       "            4.6021e-01, 4.4995e-01, 4.2725e-01, 4.2700e-01, 4.2505e-01,\n",
       "            3.8623e-01, 3.8428e-01, 3.6523e-01, 3.4229e-01, 3.2812e-01,\n",
       "            2.8174e-01, 2.7417e-01, 2.5610e-01, 2.5464e-01, 2.5342e-01,\n",
       "            2.2632e-01, 2.2302e-01, 2.1094e-01, 2.0935e-01, 1.6138e-01,\n",
       "            1.5466e-01, 1.5063e-01, 1.3208e-01, 9.4666e-02, 9.4177e-02,\n",
       "            8.5388e-02, 5.8228e-02, 5.6458e-02, 5.5603e-02, 4.5685e-02,\n",
       "            4.0100e-02, 3.8239e-02, 3.8025e-02, 3.7109e-02, 3.6438e-02,\n",
       "            3.4698e-02, 3.1494e-02, 2.9709e-02, 2.7374e-02, 2.5421e-02,\n",
       "            2.2675e-02, 2.2034e-02, 2.0493e-02, 1.2428e-02, 1.0246e-02,\n",
       "            1.0010e-02, 8.7433e-03, 8.6441e-03, 7.8125e-03, 7.7553e-03,\n",
       "            7.4043e-03, 5.3024e-03, 4.7379e-03, 3.2482e-03, 3.1967e-03,\n",
       "            2.5024e-03, 2.3422e-03, 2.2163e-03, 2.1744e-03, 1.8969e-03,\n",
       "            1.6613e-03, 1.6232e-03, 1.4668e-03, 1.3456e-03, 1.3247e-03,\n",
       "            1.3094e-03, 1.1969e-03, 1.1787e-03, 1.1606e-03, 1.1339e-03,\n",
       "            1.0529e-03, 9.5081e-04, 9.1124e-04, 8.9693e-04, 8.4257e-04,\n",
       "            7.3528e-04, 7.1526e-04, 6.4611e-04, 6.4373e-04, 6.3610e-04,\n",
       "            6.0225e-04, 5.9319e-04, 5.8842e-04, 5.6791e-04, 5.5075e-04,\n",
       "            4.5300e-04, 4.3726e-04, 4.2391e-04, 4.0460e-04, 3.8004e-04,\n",
       "            3.5000e-04, 3.3927e-04, 3.0541e-04, 2.7800e-04, 2.6727e-04,\n",
       "            2.4152e-04, 2.2697e-04, 2.1827e-04, 1.9562e-04, 1.8525e-04,\n",
       "            1.7953e-04, 1.5724e-04, 1.4997e-04, 1.4889e-04, 1.4544e-04,\n",
       "            1.4424e-04, 1.3340e-04, 1.1414e-04, 1.1063e-04, 1.0473e-04,\n",
       "            9.8407e-05, 8.7500e-05, 8.2195e-05, 6.4552e-05, 6.2048e-05,\n",
       "            5.3465e-05, 5.2273e-05, 5.1856e-05, 4.8339e-05, 4.4703e-05,\n",
       "            3.9756e-05, 3.8505e-05, 3.6776e-05, 3.5107e-05, 3.0935e-05,\n",
       "            2.7776e-05, 2.7537e-05, 2.6882e-05, 2.5094e-05, 2.4498e-05,\n",
       "            2.3365e-05, 2.3007e-05, 2.1756e-05, 1.9848e-05, 1.9372e-05,\n",
       "            1.8179e-05, 1.2517e-05, 1.1683e-05, 1.1384e-05, 1.0788e-05,\n",
       "            7.9274e-06, 6.8545e-06, 6.5565e-06, 5.9605e-06, 5.3048e-06,\n",
       "            4.8280e-06, 3.8743e-06, 3.5763e-06, 3.5167e-06, 3.2783e-06,\n",
       "            2.9802e-06, 2.2054e-06, 1.6093e-06, 1.5497e-06, 1.3113e-06,\n",
       "            7.7486e-07, 3.5763e-07], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.72131145, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.109375 , 0.109375 , 0.109375 , 0.1171875, 0.125    , 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5703125, 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.9609375, 0.96875  , 0.984375 , 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.04098361, 0.07377049, 0.09836066, 0.12295082,\n",
       "            0.13934426, 0.16393442, 0.18032786, 0.18852459, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.33606556, 0.3442623 , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 1.0000e+00, 9.9951e-01, 9.9902e-01, 9.9854e-01,\n",
       "            9.9805e-01, 9.9756e-01, 9.9707e-01, 9.9658e-01, 9.9512e-01,\n",
       "            9.9414e-01, 9.9365e-01, 9.9268e-01, 9.9170e-01, 9.8779e-01,\n",
       "            9.8682e-01, 9.8633e-01, 9.8535e-01, 9.8486e-01, 9.8389e-01,\n",
       "            9.8340e-01, 9.7949e-01, 9.7021e-01, 9.6924e-01, 9.6484e-01,\n",
       "            9.6387e-01, 9.6289e-01, 9.6045e-01, 9.5996e-01, 9.5752e-01,\n",
       "            9.5166e-01, 9.4971e-01, 9.4531e-01, 9.4336e-01, 9.3604e-01,\n",
       "            9.3311e-01, 9.3115e-01, 9.2627e-01, 9.2432e-01, 9.1895e-01,\n",
       "            9.1797e-01, 9.0869e-01, 9.0137e-01, 8.9893e-01, 8.9209e-01,\n",
       "            8.8428e-01, 8.7354e-01, 8.6670e-01, 8.5791e-01, 8.5645e-01,\n",
       "            8.4766e-01, 8.4229e-01, 8.3691e-01, 8.3154e-01, 8.2764e-01,\n",
       "            7.9004e-01, 7.6465e-01, 7.5342e-01, 7.5244e-01, 7.5098e-01,\n",
       "            7.2900e-01, 7.1826e-01, 6.9922e-01, 5.9131e-01, 5.8594e-01,\n",
       "            5.6689e-01, 5.4102e-01, 5.2783e-01, 5.1025e-01, 4.9634e-01,\n",
       "            4.5142e-01, 4.4873e-01, 4.4312e-01, 4.2310e-01, 4.2065e-01,\n",
       "            4.0552e-01, 3.9648e-01, 3.8379e-01, 3.5913e-01, 3.5400e-01,\n",
       "            3.5303e-01, 3.1201e-01, 2.8247e-01, 2.8052e-01, 2.5854e-01,\n",
       "            2.3547e-01, 2.3425e-01, 2.1899e-01, 1.9897e-01, 1.8152e-01,\n",
       "            1.6528e-01, 1.6064e-01, 1.5125e-01, 1.1340e-01, 9.9487e-02,\n",
       "            8.0078e-02, 6.9519e-02, 5.1086e-02, 4.6539e-02, 4.5868e-02,\n",
       "            4.5105e-02, 3.7689e-02, 3.3844e-02, 3.3661e-02, 3.2776e-02,\n",
       "            3.2227e-02, 2.8870e-02, 2.8488e-02, 2.7374e-02, 2.1576e-02,\n",
       "            1.9913e-02, 1.9608e-02, 1.8906e-02, 1.8127e-02, 1.1246e-02,\n",
       "            9.4528e-03, 7.0381e-03, 6.5117e-03, 6.0730e-03, 5.9814e-03,\n",
       "            5.7526e-03, 5.3024e-03, 5.1804e-03, 3.9139e-03, 3.5381e-03,\n",
       "            2.4624e-03, 2.0504e-03, 1.8463e-03, 1.6870e-03, 1.6289e-03,\n",
       "            1.3151e-03, 1.1606e-03, 1.1072e-03, 1.0815e-03, 1.0567e-03,\n",
       "            9.2173e-04, 9.0742e-04, 8.9359e-04, 8.6260e-04, 7.0953e-04,\n",
       "            7.0667e-04, 6.4373e-04, 6.4135e-04, 6.2132e-04, 6.1655e-04,\n",
       "            5.2118e-04, 4.9734e-04, 4.8780e-04, 4.5300e-04, 4.3559e-04,\n",
       "            4.3225e-04, 4.2558e-04, 4.0770e-04, 4.0293e-04, 3.8743e-04,\n",
       "            3.0303e-04, 2.9588e-04, 2.9135e-04, 2.8253e-04, 2.5511e-04,\n",
       "            2.4533e-04, 2.0826e-04, 1.8811e-04, 1.7262e-04, 1.6224e-04,\n",
       "            1.5962e-04, 1.4997e-04, 1.3030e-04, 1.2636e-04, 1.1593e-04,\n",
       "            1.0890e-04, 1.0556e-04, 9.6858e-05, 9.3877e-05, 6.9201e-05,\n",
       "            6.8128e-05, 6.6042e-05, 6.3539e-05, 6.2048e-05, 5.3465e-05,\n",
       "            4.3988e-05, 3.9160e-05, 3.3736e-05, 3.3200e-05, 3.2723e-05,\n",
       "            3.2425e-05, 3.0935e-05, 2.5690e-05, 2.4498e-05, 2.2650e-05,\n",
       "            2.0921e-05, 1.9670e-05, 1.9372e-05, 1.7107e-05, 1.6689e-05,\n",
       "            1.5914e-05, 1.4305e-05, 1.3232e-05, 1.2636e-05, 1.1563e-05,\n",
       "            1.0610e-05, 1.0133e-05, 7.3910e-06, 6.6161e-06, 6.3181e-06,\n",
       "            5.5432e-06, 4.5896e-06, 4.2319e-06, 3.3975e-06, 3.1590e-06,\n",
       "            3.0398e-06, 2.7418e-06, 2.1458e-06, 1.9670e-06, 1.7881e-06,\n",
       "            1.7285e-06, 1.1921e-06, 8.3447e-07, 7.7486e-07, 4.1723e-07,\n",
       "            1.7881e-07], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.72131145, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.0546875,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.109375 , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.671875 , 0.6796875, 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.9140625, 0.9296875, 0.9375   , 0.9453125, 0.9609375, 0.96875  ,\n",
       "            0.984375 , 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.05737705, 0.09016393, 0.1147541 , 0.1557377 ,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 1.0000e+00, 9.9951e-01, 9.9902e-01, 9.9854e-01,\n",
       "            9.9805e-01, 9.9756e-01, 9.9658e-01, 9.9609e-01, 9.9561e-01,\n",
       "            9.9268e-01, 9.9219e-01, 9.9072e-01, 9.8975e-01, 9.8926e-01,\n",
       "            9.8877e-01, 9.8730e-01, 9.8682e-01, 9.8633e-01, 9.8096e-01,\n",
       "            9.7949e-01, 9.7754e-01, 9.7607e-01, 9.7559e-01, 9.7363e-01,\n",
       "            9.7119e-01, 9.6973e-01, 9.6924e-01, 9.6582e-01, 9.6533e-01,\n",
       "            9.6387e-01, 9.5068e-01, 9.5020e-01, 9.4727e-01, 9.4629e-01,\n",
       "            9.4531e-01, 9.3701e-01, 9.3359e-01, 9.3262e-01, 9.3066e-01,\n",
       "            9.2627e-01, 9.1553e-01, 9.0381e-01, 8.9893e-01, 8.9844e-01,\n",
       "            8.9258e-01, 8.9062e-01, 8.7012e-01, 8.6426e-01, 8.6377e-01,\n",
       "            8.4570e-01, 8.2568e-01, 8.1982e-01, 8.1787e-01, 8.0713e-01,\n",
       "            7.8271e-01, 7.7539e-01, 7.5293e-01, 7.5195e-01, 7.4414e-01,\n",
       "            7.1484e-01, 6.0693e-01, 5.6787e-01, 5.5811e-01, 5.5615e-01,\n",
       "            5.3711e-01, 5.0977e-01, 4.5532e-01, 4.3604e-01, 4.3457e-01,\n",
       "            4.2065e-01, 4.1431e-01, 3.9038e-01, 3.8867e-01, 3.4033e-01,\n",
       "            3.3325e-01, 3.2104e-01, 3.1885e-01, 3.1372e-01, 3.1006e-01,\n",
       "            2.8564e-01, 2.6245e-01, 2.3340e-01, 1.9055e-01, 1.8933e-01,\n",
       "            1.8689e-01, 1.8372e-01, 1.6943e-01, 1.5051e-01, 1.3586e-01,\n",
       "            1.0706e-01, 1.0193e-01, 9.0759e-02, 8.9111e-02, 6.7566e-02,\n",
       "            3.8696e-02, 3.8330e-02, 3.8239e-02, 3.5828e-02, 3.0624e-02,\n",
       "            2.9251e-02, 2.5711e-02, 2.4612e-02, 2.4002e-02, 2.0721e-02,\n",
       "            2.0493e-02, 1.8265e-02, 1.7380e-02, 1.5305e-02, 1.4503e-02,\n",
       "            1.0651e-02, 9.9335e-03, 8.7128e-03, 7.0953e-03, 4.8103e-03,\n",
       "            4.2496e-03, 3.8853e-03, 3.5381e-03, 3.3894e-03, 3.2482e-03,\n",
       "            2.7580e-03, 1.7204e-03, 1.4553e-03, 1.4210e-03, 1.2846e-03,\n",
       "            1.2646e-03, 1.1292e-03, 1.0605e-03, 7.3528e-04, 6.6948e-04,\n",
       "            5.7459e-04, 5.5695e-04, 5.3978e-04, 5.3596e-04, 4.8208e-04,\n",
       "            4.5300e-04, 4.4417e-04, 4.4250e-04, 3.5977e-04, 3.4070e-04,\n",
       "            3.2759e-04, 3.2496e-04, 3.2258e-04, 2.7800e-04, 2.7370e-04,\n",
       "            2.5511e-04, 2.4915e-04, 2.3234e-04, 2.1827e-04, 2.1482e-04,\n",
       "            1.9717e-04, 1.9109e-04, 1.6606e-04, 1.6093e-04, 1.4091e-04,\n",
       "            1.3983e-04, 1.3447e-04, 1.1593e-04, 1.0473e-04, 9.7632e-05,\n",
       "            9.2447e-05, 9.1016e-05, 8.4817e-05, 7.6592e-05, 7.3135e-05,\n",
       "            6.9201e-05, 6.7115e-05, 6.4015e-05, 5.9187e-05, 5.2691e-05,\n",
       "            4.9114e-05, 4.7922e-05, 4.7207e-05, 4.6849e-05, 3.1173e-05,\n",
       "            2.9802e-05, 2.9564e-05, 2.8193e-05, 2.7537e-05, 2.5272e-05,\n",
       "            2.2829e-05, 2.0921e-05, 2.0802e-05, 1.9968e-05, 1.7524e-05,\n",
       "            1.4067e-05, 1.2994e-05, 1.2815e-05, 1.1027e-05, 1.0073e-05,\n",
       "            9.6560e-06, 9.5963e-06, 9.5367e-06, 8.1658e-06, 6.7949e-06,\n",
       "            6.6757e-06, 6.5565e-06, 5.3644e-06, 4.1723e-06, 4.0531e-06,\n",
       "            3.7551e-06, 2.8014e-06, 2.5630e-06, 2.5034e-06, 2.3246e-06,\n",
       "            2.0266e-06, 1.7881e-06, 1.6689e-06, 1.4305e-06, 1.1921e-06,\n",
       "            1.0133e-06, 9.5367e-07, 8.9407e-07, 5.9605e-07, 4.7684e-07,\n",
       "            4.1723e-07, 2.3842e-07, 1.1921e-07], dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(1., dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.04237288,\n",
       "            0.05084746, 0.05932203, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.33898306, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.45762712, 0.45762712, 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 , 0.58474576,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.88135594, 0.8898305 , 0.90677965, 0.91525424, 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00757576, 0.00757576, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03787879, 0.03787879, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.09090909, 0.09090909, 0.09848485, 0.09848485,\n",
       "            0.10606061, 0.11363637, 0.12121212, 0.12878788, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.23484848,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.33333334,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.40151516, 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.67424244, 0.6818182 , 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.912 , 0.9116, 0.8965, 0.8906, 0.8853, 0.8823, 0.882 ,\n",
       "            0.8774, 0.8765, 0.8735, 0.873 , 0.872 , 0.871 , 0.87  , 0.8696,\n",
       "            0.8657, 0.8647, 0.8643, 0.8633, 0.862 , 0.8594, 0.859 , 0.856 ,\n",
       "            0.8506, 0.8496, 0.849 , 0.8486, 0.848 , 0.847 , 0.8467, 0.8438,\n",
       "            0.842 , 0.841 , 0.84  , 0.8384, 0.8374, 0.8364, 0.8345, 0.832 ,\n",
       "            0.8247, 0.8237, 0.8228, 0.821 , 0.8193, 0.8184, 0.818 , 0.8154,\n",
       "            0.8145, 0.813 , 0.8125, 0.8105, 0.8086, 0.8057, 0.805 , 0.8047,\n",
       "            0.804 , 0.8037, 0.803 , 0.7993, 0.799 , 0.7974, 0.796 , 0.793 ,\n",
       "            0.7925, 0.791 , 0.7905, 0.788 , 0.787 , 0.786 , 0.7856, 0.781 ,\n",
       "            0.7803, 0.7793, 0.7783, 0.777 , 0.7754, 0.772 , 0.767 , 0.7666,\n",
       "            0.766 , 0.7656, 0.7637, 0.762 , 0.7617, 0.7603, 0.759 , 0.757 ,\n",
       "            0.756 , 0.7544, 0.7515, 0.751 , 0.7495, 0.7485, 0.747 , 0.745 ,\n",
       "            0.743 , 0.7407, 0.74  , 0.7397, 0.7363, 0.7354, 0.7344, 0.733 ,\n",
       "            0.731 , 0.7285, 0.728 , 0.726 , 0.724 , 0.7227, 0.7188, 0.7183,\n",
       "            0.713 , 0.7114, 0.7104, 0.709 , 0.708 , 0.706 , 0.7046, 0.704 ,\n",
       "            0.7036, 0.701 , 0.699 , 0.6987, 0.6978, 0.696 , 0.6934, 0.6914,\n",
       "            0.691 , 0.69  , 0.6885, 0.6865, 0.6855, 0.6846, 0.683 , 0.6826,\n",
       "            0.6816, 0.6797, 0.6777, 0.6772, 0.6753, 0.675 , 0.674 , 0.673 ,\n",
       "            0.67  , 0.6675, 0.6665, 0.661 , 0.659 , 0.658 , 0.656 , 0.654 ,\n",
       "            0.6504, 0.6494, 0.648 , 0.6445, 0.6406, 0.635 , 0.6323, 0.6313,\n",
       "            0.631 , 0.627 , 0.6216, 0.6206, 0.62  , 0.6113, 0.609 , 0.605 ,\n",
       "            0.602 , 0.5977, 0.5967, 0.595 , 0.594 , 0.593 , 0.5894, 0.5825,\n",
       "            0.5815, 0.578 , 0.577 , 0.5747, 0.5728, 0.571 , 0.5703, 0.5625,\n",
       "            0.5557, 0.555 , 0.553 , 0.5522, 0.552 , 0.5513, 0.55  , 0.547 ,\n",
       "            0.5464, 0.5444, 0.544 , 0.5405, 0.5396, 0.5386, 0.5366, 0.5337,\n",
       "            0.5293, 0.529 , 0.5264, 0.525 , 0.5244, 0.522 , 0.5215, 0.5205,\n",
       "            0.52  , 0.5195, 0.5176, 0.517 , 0.5166, 0.516 , 0.5156, 0.5117,\n",
       "            0.5063], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(1., dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.01694915, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11864407, 0.12711865, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.2457627 , 0.2542373 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.3644068 , 0.37288135,\n",
       "            0.37288135, 0.37288135, 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.40677965, 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.6101695 ,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00757576,\n",
       "            0.00757576, 0.01515152, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.02272727, 0.02272727, 0.02272727, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03787879, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06060606, 0.06060606,\n",
       "            0.06060606, 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.08333334, 0.08333334, 0.09090909, 0.09848485, 0.09848485,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.15151516, 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.22727273, 0.24242425, 0.25      , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.3030303 , 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.4318182 , 0.43939394, 0.4469697 , 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.49242425, 0.50757575, 0.5151515 ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.6818182 , 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9814, 0.9756, 0.9727, 0.9717, 0.971 , 0.9707, 0.97  ,\n",
       "            0.969 , 0.968 , 0.9663, 0.9653, 0.965 , 0.963 , 0.9624, 0.962 ,\n",
       "            0.9614, 0.96  , 0.9585, 0.958 , 0.957 , 0.9565, 0.955 , 0.954 ,\n",
       "            0.9536, 0.953 , 0.9526, 0.952 , 0.9517, 0.9507, 0.95  , 0.947 ,\n",
       "            0.9463, 0.946 , 0.945 , 0.9443, 0.9414, 0.941 , 0.9404, 0.94  ,\n",
       "            0.939 , 0.937 , 0.9365, 0.936 , 0.935 , 0.9346, 0.934 , 0.9336,\n",
       "            0.9326, 0.932 , 0.931 , 0.9307, 0.928 , 0.9277, 0.9272, 0.927 ,\n",
       "            0.9263, 0.924 , 0.923 , 0.922 , 0.92  , 0.9194, 0.919 , 0.917 ,\n",
       "            0.916 , 0.9146, 0.913 , 0.9126, 0.911 , 0.91  , 0.9097, 0.9087,\n",
       "            0.908 , 0.906 , 0.9053, 0.902 , 0.9014, 0.901 , 0.9004, 0.899 ,\n",
       "            0.8984, 0.897 , 0.8965, 0.896 , 0.8945, 0.8926, 0.892 , 0.8906,\n",
       "            0.889 , 0.8887, 0.887 , 0.886 , 0.885 , 0.883 , 0.8823, 0.8813,\n",
       "            0.881 , 0.88  , 0.878 , 0.8774, 0.877 , 0.873 , 0.872 , 0.8696,\n",
       "            0.868 , 0.8677, 0.865 , 0.8643, 0.864 , 0.8633, 0.863 , 0.8623,\n",
       "            0.861 , 0.859 , 0.8584, 0.8564, 0.856 , 0.8535, 0.8525, 0.8516,\n",
       "            0.85  , 0.8486, 0.844 , 0.843 , 0.8413, 0.8403, 0.8384, 0.8315,\n",
       "            0.827 , 0.8257, 0.825 , 0.824 , 0.823 , 0.8203, 0.8193, 0.8174,\n",
       "            0.8164, 0.812 , 0.8105, 0.8057, 0.8013, 0.8003, 0.8   , 0.798 ,\n",
       "            0.7964, 0.796 , 0.7944, 0.791 , 0.7886, 0.785 , 0.773 , 0.77  ,\n",
       "            0.7695, 0.758 , 0.747 , 0.7373, 0.736 , 0.7266, 0.7085, 0.7056,\n",
       "            0.705 , 0.6978, 0.6875, 0.683 , 0.6787, 0.678 , 0.675 , 0.6724,\n",
       "            0.661 , 0.6606, 0.657 , 0.6553, 0.6475, 0.6465, 0.6426, 0.6416,\n",
       "            0.6396, 0.638 , 0.637 , 0.634 , 0.6333, 0.632 , 0.629 , 0.624 ,\n",
       "            0.6216, 0.619 , 0.6187, 0.6177, 0.614 , 0.61  , 0.6094, 0.6045,\n",
       "            0.5977, 0.592 , 0.584 , 0.5835, 0.5767, 0.576 , 0.575 , 0.5747,\n",
       "            0.5728, 0.5723, 0.5713, 0.57  , 0.568 , 0.566 , 0.555 , 0.5425,\n",
       "            0.535 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(1., dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.01694915, 0.02542373, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.11016949,\n",
       "            0.12711865, 0.13559322, 0.15254237, 0.16949153, 0.16949153,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.23728813, 0.26271185, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.34745762, 0.34745762, 0.3644068 , 0.3644068 ,\n",
       "            0.3644068 , 0.37288135, 0.37288135, 0.37288135, 0.3898305 ,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.42372882, 0.42372882, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.42372882, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00757576, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03787879, 0.03787879, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.06818182, 0.07575758, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.13636364, 0.13636364, 0.13636364, 0.14393939,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.20454545, 0.21212122, 0.22727273, 0.23484848, 0.25      ,\n",
       "            0.25757575, 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28030303, 0.28787878, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.36363637,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.4090909 , 0.42424244,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.4848485 , 0.49242425,\n",
       "            0.50757575, 0.5151515 , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9814, 0.976 , 0.9746, 0.9736, 0.973 , 0.9717, 0.971 ,\n",
       "            0.9707, 0.968 , 0.9673, 0.9644, 0.964 , 0.9634, 0.963 , 0.9624,\n",
       "            0.962 , 0.961 , 0.96  , 0.9595, 0.959 , 0.9575, 0.9556, 0.9546,\n",
       "            0.954 , 0.9536, 0.9526, 0.952 , 0.9517, 0.951 , 0.9507, 0.949 ,\n",
       "            0.947 , 0.9463, 0.946 , 0.9443, 0.944 , 0.9434, 0.943 , 0.942 ,\n",
       "            0.9414, 0.941 , 0.9404, 0.9395, 0.939 , 0.938 , 0.9375, 0.936 ,\n",
       "            0.935 , 0.9346, 0.934 , 0.9336, 0.9326, 0.932 , 0.9316, 0.93  ,\n",
       "            0.929 , 0.9272, 0.927 , 0.9263, 0.926 , 0.9243, 0.924 , 0.9233,\n",
       "            0.923 , 0.9224, 0.922 , 0.921 , 0.9204, 0.92  , 0.9194, 0.9185,\n",
       "            0.918 , 0.917 , 0.916 , 0.9155, 0.915 , 0.914 , 0.9136, 0.913 ,\n",
       "            0.9126, 0.912 , 0.911 , 0.9106, 0.91  , 0.9097, 0.9087, 0.908 ,\n",
       "            0.907 , 0.906 , 0.905 , 0.9043, 0.9033, 0.902 , 0.901 , 0.8984,\n",
       "            0.8975, 0.8965, 0.896 , 0.8955, 0.895 , 0.8945, 0.893 , 0.8926,\n",
       "            0.8916, 0.8906, 0.889 , 0.8877, 0.885 , 0.8823, 0.882 , 0.8784,\n",
       "            0.8774, 0.8755, 0.875 , 0.8745, 0.8726, 0.872 , 0.871 , 0.8687,\n",
       "            0.868 , 0.8667, 0.8657, 0.865 , 0.864 , 0.862 , 0.8604, 0.86  ,\n",
       "            0.8594, 0.8584, 0.8545, 0.8525, 0.852 , 0.8477, 0.847 , 0.8403,\n",
       "            0.831 , 0.8193, 0.8184, 0.8154, 0.8076, 0.8037, 0.7993, 0.7925,\n",
       "            0.788 , 0.773 , 0.769 , 0.7583, 0.75  , 0.7397, 0.7393, 0.7324,\n",
       "            0.721 , 0.7173, 0.7095, 0.709 , 0.7075, 0.703 , 0.6963, 0.6943,\n",
       "            0.692 , 0.6904, 0.69  , 0.689 , 0.6836, 0.6772, 0.677 , 0.676 ,\n",
       "            0.6743, 0.674 , 0.6665, 0.666 , 0.6587, 0.658 , 0.652 , 0.651 ,\n",
       "            0.649 , 0.6484, 0.645 , 0.644 , 0.6387, 0.62  , 0.6177, 0.6084,\n",
       "            0.605 , 0.6035, 0.6016, 0.601 , 0.5996, 0.597 , 0.596 , 0.589 ,\n",
       "            0.588 , 0.581 , 0.5674, 0.5454, 0.538 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(1., dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.08474576, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.1779661 , 0.20338982, 0.20338982,\n",
       "            0.21186441, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27966103, 0.2881356 , 0.2881356 , 0.2881356 , 0.2881356 ,\n",
       "            0.29661018, 0.29661018, 0.29661018, 0.31355932, 0.33050847,\n",
       "            0.33898306, 0.33898306, 0.33898306, 0.33898306, 0.33898306,\n",
       "            0.34745762, 0.34745762, 0.34745762, 0.34745762, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.38135594, 0.3898305 , 0.3898305 , 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.40677965, 0.41525424, 0.41525424, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.00757576, 0.01515152,\n",
       "            0.01515152, 0.02272727, 0.02272727, 0.02272727, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.04545455,\n",
       "            0.0530303 , 0.06060606, 0.06818182, 0.08333334, 0.09090909,\n",
       "            0.09090909, 0.10606061, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.12878788, 0.13636364, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.15151516, 0.1590909 , 0.1590909 , 0.1590909 , 0.1590909 ,\n",
       "            0.16666667, 0.18181819, 0.18939394, 0.21212122, 0.21969697,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.23484848, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37121212, 0.37878788, 0.3939394 , 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.4469697 , 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.5       , 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.56060606, 0.5833333 , 0.59090906,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.6818182 , 0.68939394, 0.70454544, 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.74242425, 0.74242425,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.965 , 0.9644, 0.9624, 0.961 , 0.9595, 0.959 , 0.9585,\n",
       "            0.9575, 0.955 , 0.953 , 0.9517, 0.9507, 0.95  , 0.9497, 0.949 ,\n",
       "            0.9473, 0.947 , 0.9463, 0.9453, 0.945 , 0.9443, 0.9434, 0.9424,\n",
       "            0.942 , 0.9414, 0.941 , 0.94  , 0.9395, 0.9385, 0.937 , 0.9365,\n",
       "            0.936 , 0.9355, 0.935 , 0.9346, 0.934 , 0.9336, 0.933 , 0.9326,\n",
       "            0.9316, 0.931 , 0.93  , 0.9297, 0.929 , 0.9287, 0.928 , 0.9277,\n",
       "            0.927 , 0.9263, 0.926 , 0.9243, 0.924 , 0.9233, 0.923 , 0.9224,\n",
       "            0.9214, 0.921 , 0.9204, 0.92  , 0.9194, 0.919 , 0.9185, 0.9175,\n",
       "            0.917 , 0.916 , 0.9155, 0.9146, 0.914 , 0.913 , 0.9126, 0.9116,\n",
       "            0.911 , 0.9097, 0.909 , 0.9087, 0.9077, 0.907 , 0.9062, 0.906 ,\n",
       "            0.9053, 0.905 , 0.9043, 0.9033, 0.903 , 0.9023, 0.901 , 0.9004,\n",
       "            0.8994, 0.899 , 0.8984, 0.8975, 0.897 , 0.896 , 0.8955, 0.895 ,\n",
       "            0.894 , 0.893 , 0.892 , 0.8906, 0.89  , 0.8867, 0.8857, 0.8853,\n",
       "            0.8843, 0.8833, 0.8823, 0.882 , 0.8813, 0.88  , 0.8794, 0.8784,\n",
       "            0.876 , 0.875 , 0.8726, 0.869 , 0.8677, 0.8657, 0.865 , 0.863 ,\n",
       "            0.862 , 0.8604, 0.8584, 0.857 , 0.849 , 0.8467, 0.8447, 0.8433,\n",
       "            0.84  , 0.8394, 0.8335, 0.8325, 0.83  , 0.827 , 0.8125, 0.8115,\n",
       "            0.807 , 0.8013, 0.785 , 0.7817, 0.776 , 0.76  , 0.757 , 0.7554,\n",
       "            0.7466, 0.7334, 0.7324, 0.729 , 0.7275, 0.724 , 0.719 , 0.7188,\n",
       "            0.718 , 0.712 , 0.7075, 0.699 , 0.6978, 0.694 , 0.6934, 0.692 ,\n",
       "            0.6885, 0.6865, 0.6836, 0.682 , 0.6816, 0.681 , 0.6807, 0.6733,\n",
       "            0.671 , 0.669 , 0.664 , 0.6597, 0.659 , 0.655 , 0.6514, 0.6484,\n",
       "            0.648 , 0.6265, 0.623 , 0.6133, 0.61  , 0.6084, 0.6064, 0.6045,\n",
       "            0.604 , 0.603 , 0.5996, 0.597 , 0.5903, 0.589 , 0.5786, 0.5605,\n",
       "            0.5293, 0.527 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9830508, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.01694915, 0.02542373, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.09322034, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.11016949, 0.11016949, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.1440678 , 0.15254237, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.21186441, 0.22033899, 0.22033899, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.34745762, 0.3559322 , 0.3644068 , 0.3644068 ,\n",
       "            0.37288135, 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.3983051 , 0.3983051 , 0.40677965, 0.41525424, 0.41525424,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44067797, 0.44067797, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44067797, 0.44067797, 0.44067797, 0.44067797, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.60169494, 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.11363637, 0.12878788, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.22727273, 0.22727273,\n",
       "            0.23484848, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.36363637, 0.37121212,\n",
       "            0.38636363, 0.38636363, 0.41666666, 0.4318182 , 0.4469697 ,\n",
       "            0.45454547, 0.45454547, 0.46212122, 0.46969697, 0.4848485 ,\n",
       "            0.5       , 0.530303  , 0.5378788 , 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.57575756, 0.59090906, 0.59090906,\n",
       "            0.59090906, 0.6060606 , 0.6136364 , 0.6287879 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.6818182 , 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.70454544, 0.70454544, 0.719697  ,\n",
       "            0.719697  , 0.7348485 , 0.7348485 , 0.74242425, 0.74242425,\n",
       "            0.75      , 0.75757575, 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.7878788 , 0.79545456, 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8636364 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 , 0.8863636 ,\n",
       "            0.9015151 , 0.9015151 , 0.9015151 , 0.90909094, 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.973 , 0.96  , 0.9585, 0.956 , 0.955 , 0.951 , 0.9487,\n",
       "            0.947 , 0.945 , 0.9414, 0.9395, 0.939 , 0.938 , 0.9365, 0.936 ,\n",
       "            0.9336, 0.933 , 0.932 , 0.9316, 0.931 , 0.9307, 0.93  , 0.9297,\n",
       "            0.929 , 0.9287, 0.928 , 0.9277, 0.9272, 0.926 , 0.9253, 0.924 ,\n",
       "            0.923 , 0.9224, 0.921 , 0.92  , 0.917 , 0.916 , 0.9146, 0.914 ,\n",
       "            0.9136, 0.913 , 0.9126, 0.912 , 0.9116, 0.911 , 0.9106, 0.91  ,\n",
       "            0.9097, 0.9087, 0.9067, 0.9062, 0.906 , 0.9053, 0.905 , 0.9033,\n",
       "            0.903 , 0.9023, 0.9014, 0.901 , 0.9004, 0.8994, 0.899 , 0.898 ,\n",
       "            0.8975, 0.897 , 0.8965, 0.8955, 0.894 , 0.893 , 0.8926, 0.892 ,\n",
       "            0.8916, 0.89  , 0.8896, 0.889 , 0.8877, 0.8867, 0.886 , 0.8857,\n",
       "            0.8853, 0.8833, 0.883 , 0.8823, 0.8813, 0.8804, 0.88  , 0.8794,\n",
       "            0.879 , 0.878 , 0.877 , 0.876 , 0.8755, 0.8735, 0.8716, 0.871 ,\n",
       "            0.87  , 0.8687, 0.8677, 0.8667, 0.8647, 0.861 , 0.8604, 0.858 ,\n",
       "            0.857 , 0.8564, 0.856 , 0.8555, 0.855 , 0.854 , 0.853 , 0.8516,\n",
       "            0.8506, 0.848 , 0.847 , 0.8467, 0.8433, 0.84  , 0.8384, 0.836 ,\n",
       "            0.828 , 0.8276, 0.825 , 0.8247, 0.8228, 0.8223, 0.813 , 0.8115,\n",
       "            0.8076, 0.805 , 0.7983, 0.795 , 0.788 , 0.779 , 0.751 , 0.746 ,\n",
       "            0.7456, 0.744 , 0.7437, 0.7407, 0.74  , 0.7285, 0.717 , 0.715 ,\n",
       "            0.7124, 0.7085, 0.7017, 0.7   , 0.697 , 0.6943, 0.6914, 0.6875,\n",
       "            0.683 , 0.682 , 0.6807, 0.678 , 0.677 , 0.6733, 0.6704, 0.6694,\n",
       "            0.6646, 0.66  , 0.6567, 0.653 , 0.6514, 0.6436, 0.639 , 0.6387,\n",
       "            0.6367, 0.6133, 0.6104, 0.6016, 0.596 , 0.5947, 0.593 , 0.59  ,\n",
       "            0.5894, 0.5845, 0.5825, 0.574 , 0.572 , 0.559 , 0.532 , 0.4993,\n",
       "            0.4915], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9830508, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.13559322, 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.1779661 , 0.21186441, 0.21186441,\n",
       "            0.22033899, 0.2457627 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.2881356 , 0.29661018, 0.29661018, 0.29661018, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.37288135, 0.38135594, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.40677965, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03787879,\n",
       "            0.0530303 , 0.06818182, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.09848485, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.37121212,\n",
       "            0.37878788, 0.3939394 , 0.40151516, 0.41666666, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.46212122, 0.46969697, 0.4848485 ,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.5378788 ,\n",
       "            0.5530303 , 0.5681818 , 0.5833333 , 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6287879 , 0.6363636 , 0.6515151 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.70454544, 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.7348485 , 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.780303  , 0.780303  , 0.7878788 , 0.7878788 , 0.79545456,\n",
       "            0.79545456, 0.8030303 , 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.8333333 , 0.8333333 , 0.8484849 , 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8636364 , 0.8636364 , 0.8636364 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9814, 0.9688, 0.963 , 0.957 , 0.955 , 0.953 , 0.9526,\n",
       "            0.9497, 0.9473, 0.9463, 0.946 , 0.9453, 0.9443, 0.9385, 0.9375,\n",
       "            0.937 , 0.936 , 0.935 , 0.9346, 0.934 , 0.9336, 0.933 , 0.9326,\n",
       "            0.932 , 0.9307, 0.9287, 0.9272, 0.926 , 0.925 , 0.924 , 0.9233,\n",
       "            0.923 , 0.9204, 0.919 , 0.917 , 0.9165, 0.914 , 0.912 , 0.911 ,\n",
       "            0.91  , 0.9097, 0.9087, 0.908 , 0.9062, 0.9053, 0.905 , 0.9043,\n",
       "            0.9033, 0.903 , 0.902 , 0.901 , 0.9   , 0.8994, 0.899 , 0.8936,\n",
       "            0.8926, 0.8916, 0.891 , 0.8906, 0.89  , 0.8896, 0.887 , 0.886 ,\n",
       "            0.885 , 0.8823, 0.882 , 0.8794, 0.879 , 0.8765, 0.876 , 0.875 ,\n",
       "            0.8745, 0.874 , 0.8726, 0.8716, 0.8706, 0.87  , 0.8696, 0.869 ,\n",
       "            0.8687, 0.8677, 0.8647, 0.864 , 0.862 , 0.8613, 0.86  , 0.8594,\n",
       "            0.8584, 0.858 , 0.857 , 0.8564, 0.856 , 0.8525, 0.8506, 0.85  ,\n",
       "            0.8496, 0.8486, 0.8477, 0.847 , 0.8467, 0.846 , 0.845 , 0.8447,\n",
       "            0.8438, 0.8433, 0.842 , 0.8374, 0.837 , 0.836 , 0.8354, 0.835 ,\n",
       "            0.8345, 0.8335, 0.833 , 0.8325, 0.832 , 0.8315, 0.8296, 0.8286,\n",
       "            0.828 , 0.8267, 0.826 , 0.823 , 0.8223, 0.8213, 0.8184, 0.8174,\n",
       "            0.8154, 0.8135, 0.8125, 0.8086, 0.805 , 0.8037, 0.803 , 0.8027,\n",
       "            0.8022, 0.8003, 0.799 , 0.7974, 0.797 , 0.7915, 0.7905, 0.79  ,\n",
       "            0.7886, 0.785 , 0.778 , 0.7754, 0.7695, 0.7603, 0.76  , 0.758 ,\n",
       "            0.757 , 0.7446, 0.735 , 0.733 , 0.727 , 0.7256, 0.722 , 0.718 ,\n",
       "            0.7065, 0.7046, 0.703 , 0.698 , 0.6978, 0.6953, 0.6914, 0.6875,\n",
       "            0.6846, 0.6807, 0.6743, 0.674 , 0.6733, 0.6694, 0.668 , 0.6655,\n",
       "            0.663 , 0.659 , 0.6567, 0.656 , 0.654 , 0.6465, 0.643 , 0.6416,\n",
       "            0.6387, 0.6313, 0.63  , 0.6265, 0.6255, 0.6226, 0.5996, 0.5938,\n",
       "            0.587 , 0.5806, 0.578 , 0.576 , 0.574 , 0.5728, 0.5723, 0.569 ,\n",
       "            0.5674, 0.555 , 0.554 , 0.538 , 0.5024, 0.4758, 0.4539],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9745763, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11016949, 0.11016949,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.41525424, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.5508475 , 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06060606, 0.06818182, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.28030303, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.3560606 ,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.46212122, 0.47727272, 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.52272725, 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.6060606 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.70454544, 0.7121212 , 0.719697  , 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.79545456, 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8636364 , 0.8636364 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.9318182 , 0.9318182 , 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.987 , 0.9756, 0.968 , 0.9653, 0.9624, 0.9595, 0.9585,\n",
       "            0.957 , 0.9565, 0.9546, 0.954 , 0.9536, 0.953 , 0.9517, 0.95  ,\n",
       "            0.946 , 0.9443, 0.942 , 0.9414, 0.94  , 0.9395, 0.9385, 0.9365,\n",
       "            0.9355, 0.935 , 0.934 , 0.933 , 0.9326, 0.932 , 0.931 , 0.9307,\n",
       "            0.9297, 0.924 , 0.9233, 0.9224, 0.9214, 0.9204, 0.9194, 0.918 ,\n",
       "            0.917 , 0.915 , 0.914 , 0.9136, 0.9126, 0.9116, 0.911 , 0.9097,\n",
       "            0.908 , 0.9062, 0.9053, 0.904 , 0.902 , 0.9004, 0.8984, 0.898 ,\n",
       "            0.8975, 0.897 , 0.8945, 0.893 , 0.8926, 0.891 , 0.8906, 0.89  ,\n",
       "            0.8877, 0.8853, 0.884 , 0.8833, 0.8813, 0.8804, 0.88  , 0.8784,\n",
       "            0.8745, 0.8735, 0.8726, 0.871 , 0.869 , 0.8677, 0.8667, 0.865 ,\n",
       "            0.8613, 0.8604, 0.86  , 0.859 , 0.858 , 0.857 , 0.8555, 0.854 ,\n",
       "            0.85  , 0.8486, 0.8477, 0.846 , 0.844 , 0.843 , 0.8423, 0.841 ,\n",
       "            0.8403, 0.8384, 0.8364, 0.836 , 0.8354, 0.8325, 0.832 , 0.8286,\n",
       "            0.8247, 0.8223, 0.822 , 0.8213, 0.821 , 0.8193, 0.8174, 0.8164,\n",
       "            0.8076, 0.807 , 0.8057, 0.805 , 0.8   , 0.7974, 0.797 , 0.796 ,\n",
       "            0.7935, 0.793 , 0.79  , 0.788 , 0.7866, 0.7856, 0.785 , 0.7827,\n",
       "            0.782 , 0.781 , 0.78  , 0.779 , 0.7783, 0.778 , 0.7773, 0.777 ,\n",
       "            0.7764, 0.775 , 0.774 , 0.7705, 0.7695, 0.7686, 0.7666, 0.7646,\n",
       "            0.7637, 0.7617, 0.7607, 0.7603, 0.7593, 0.758 , 0.7563, 0.756 ,\n",
       "            0.755 , 0.7544, 0.7505, 0.75  , 0.7495, 0.7485, 0.7456, 0.745 ,\n",
       "            0.742 , 0.739 , 0.7383, 0.7344, 0.732 , 0.7295, 0.728 , 0.7246,\n",
       "            0.7236, 0.7217, 0.7207, 0.714 , 0.711 , 0.7007, 0.7   , 0.699 ,\n",
       "            0.6978, 0.693 , 0.6865, 0.681 , 0.6772, 0.677 , 0.667 , 0.6646,\n",
       "            0.6606, 0.6577, 0.655 , 0.6484, 0.642 , 0.6416, 0.636 , 0.6353,\n",
       "            0.633 , 0.626 , 0.625 , 0.619 , 0.6167, 0.611 , 0.6084, 0.607 ,\n",
       "            0.6   , 0.5767, 0.5674, 0.561 , 0.554 , 0.5503, 0.549 , 0.5483,\n",
       "            0.5454, 0.5435, 0.543 , 0.5425, 0.5283, 0.5273, 0.509 , 0.4583,\n",
       "            0.4434, 0.4045], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9576271, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06818182, 0.07575758, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.12121212, 0.12878788, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21969697, 0.25      ,\n",
       "            0.2651515 , 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.3560606 , 0.37121212, 0.37878788, 0.38636363, 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46969697, 0.47727272, 0.49242425,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.8333333 , 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.92424244, 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9897, 0.98  , 0.9717, 0.971 , 0.967 , 0.9644, 0.9634,\n",
       "            0.9624, 0.96  , 0.9595, 0.959 , 0.9575, 0.957 , 0.955 , 0.9536,\n",
       "            0.951 , 0.947 , 0.9453, 0.945 , 0.942 , 0.9414, 0.9395, 0.939 ,\n",
       "            0.938 , 0.9375, 0.937 , 0.9355, 0.934 , 0.9316, 0.9287, 0.9277,\n",
       "            0.927 , 0.926 , 0.9243, 0.9214, 0.92  , 0.9194, 0.918 , 0.916 ,\n",
       "            0.9155, 0.915 , 0.9126, 0.9106, 0.9097, 0.9067, 0.906 , 0.9043,\n",
       "            0.904 , 0.9033, 0.902 , 0.9014, 0.899 , 0.8984, 0.8975, 0.8965,\n",
       "            0.8955, 0.8926, 0.891 , 0.89  , 0.889 , 0.8867, 0.886 , 0.8853,\n",
       "            0.8843, 0.876 , 0.875 , 0.8745, 0.874 , 0.872 , 0.865 , 0.864 ,\n",
       "            0.8633, 0.8613, 0.8574, 0.8564, 0.8555, 0.85  , 0.849 , 0.8486,\n",
       "            0.848 , 0.8477, 0.8467, 0.8457, 0.8438, 0.843 , 0.842 , 0.8413,\n",
       "            0.8374, 0.837 , 0.832 , 0.8276, 0.827 , 0.8247, 0.824 , 0.8135,\n",
       "            0.8115, 0.81  , 0.8057, 0.8037, 0.803 , 0.7983, 0.7905, 0.787 ,\n",
       "            0.786 , 0.785 , 0.7817, 0.781 , 0.7793, 0.777 , 0.7705, 0.768 ,\n",
       "            0.7676, 0.7617, 0.7593, 0.759 , 0.7583, 0.7476, 0.747 , 0.7437,\n",
       "            0.7373, 0.736 , 0.7324, 0.7314, 0.7305, 0.729 , 0.728 , 0.7256,\n",
       "            0.7246, 0.724 , 0.722 , 0.7183, 0.7163, 0.713 , 0.71  , 0.705 ,\n",
       "            0.7046, 0.7036, 0.702 , 0.6978, 0.6973, 0.697 , 0.695 , 0.6943,\n",
       "            0.694 , 0.6924, 0.692 , 0.6914, 0.691 , 0.6895, 0.688 , 0.687 ,\n",
       "            0.6855, 0.6846, 0.6826, 0.682 , 0.6816, 0.6807, 0.68  , 0.6797,\n",
       "            0.678 , 0.677 , 0.6763, 0.676 , 0.6753, 0.675 , 0.674 , 0.6733,\n",
       "            0.668 , 0.6665, 0.666 , 0.6646, 0.663 , 0.6626, 0.66  , 0.6587,\n",
       "            0.6562, 0.656 , 0.65  , 0.647 , 0.641 , 0.64  , 0.6387, 0.6245,\n",
       "            0.6206, 0.619 , 0.614 , 0.6123, 0.61  , 0.6084, 0.607 , 0.6064,\n",
       "            0.602 , 0.5977, 0.5923, 0.588 , 0.5845, 0.5767, 0.552 , 0.538 ,\n",
       "            0.532 , 0.5264, 0.521 , 0.5205, 0.519 , 0.5176, 0.5166, 0.5146,\n",
       "            0.5107, 0.501 , 0.5   , 0.4792, 0.4124, 0.4116, 0.356 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.88135594, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.08474576, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.16101696, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.21186441, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.7881356 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.07575758,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.22727273, 0.24242425, 0.25      ,\n",
       "            0.2651515 , 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.4318182 , 0.43939394, 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.92424244, 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.992 , 0.984 , 0.976 , 0.974 , 0.9707, 0.97  , 0.968 ,\n",
       "            0.9673, 0.9653, 0.965 , 0.9644, 0.964 , 0.9614, 0.9604, 0.9595,\n",
       "            0.9585, 0.9575, 0.9565, 0.95  , 0.9497, 0.948 , 0.9478, 0.9463,\n",
       "            0.9443, 0.9434, 0.943 , 0.9424, 0.9404, 0.94  , 0.9395, 0.939 ,\n",
       "            0.9385, 0.938 , 0.9365, 0.9355, 0.9346, 0.9307, 0.929 , 0.926 ,\n",
       "            0.9253, 0.925 , 0.924 , 0.922 , 0.921 , 0.92  , 0.9194, 0.919 ,\n",
       "            0.918 , 0.9126, 0.9116, 0.9097, 0.9077, 0.907 , 0.906 , 0.9053,\n",
       "            0.9043, 0.9033, 0.903 , 0.9   , 0.8994, 0.898 , 0.897 , 0.895 ,\n",
       "            0.892 , 0.8916, 0.891 , 0.8896, 0.889 , 0.8887, 0.888 , 0.886 ,\n",
       "            0.8857, 0.8833, 0.8823, 0.882 , 0.8745, 0.8696, 0.869 , 0.867 ,\n",
       "            0.8647, 0.8633, 0.8604, 0.8584, 0.855 , 0.8486, 0.8467, 0.846 ,\n",
       "            0.8438, 0.8433, 0.841 , 0.84  , 0.8394, 0.839 , 0.8384, 0.836 ,\n",
       "            0.8335, 0.8325, 0.8286, 0.828 , 0.826 , 0.821 , 0.819 , 0.818 ,\n",
       "            0.8115, 0.8086, 0.7974, 0.797 , 0.794 , 0.7847, 0.782 , 0.77  ,\n",
       "            0.7646, 0.7617, 0.761 , 0.7593, 0.758 , 0.75  , 0.749 , 0.7397,\n",
       "            0.737 , 0.7324, 0.731 , 0.7305, 0.7295, 0.7275, 0.7173, 0.7163,\n",
       "            0.712 , 0.71  , 0.7065, 0.703 , 0.695 , 0.6895, 0.6846, 0.684 ,\n",
       "            0.6807, 0.6797, 0.675 , 0.669 , 0.6626, 0.66  , 0.6562, 0.655 ,\n",
       "            0.653 , 0.6523, 0.651 , 0.6475, 0.647 , 0.6445, 0.6416, 0.638 ,\n",
       "            0.637 , 0.636 , 0.6353, 0.634 , 0.6304, 0.63  , 0.6284, 0.627 ,\n",
       "            0.6255, 0.624 , 0.6226, 0.621 , 0.62  , 0.6177, 0.6167, 0.6113,\n",
       "            0.606 , 0.601 , 0.598 , 0.5977, 0.5967, 0.595 , 0.5947, 0.5894,\n",
       "            0.589 , 0.588 , 0.5874, 0.5864, 0.5845, 0.584 , 0.5835, 0.582 ,\n",
       "            0.581 , 0.58  , 0.5796, 0.579 , 0.5786, 0.578 , 0.5776, 0.577 ,\n",
       "            0.576 , 0.5757, 0.575 , 0.5747, 0.573 , 0.5723, 0.572 , 0.5713,\n",
       "            0.571 , 0.5703, 0.5684, 0.5664, 0.5596, 0.5522, 0.5293, 0.509 ,\n",
       "            0.5063, 0.4988, 0.494 , 0.4912, 0.491 , 0.4897, 0.4878, 0.4844,\n",
       "            0.4795, 0.4712, 0.4695, 0.4492, 0.3774, 0.368 , 0.3093],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.86440676, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.11016949, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.13559322, 0.1440678 , 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7457627 , 0.7711864 ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.12121212, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.16666667, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.2651515 , 0.27272728, 0.28787878,\n",
       "            0.29545453, 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.47727272, 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.7348485 , 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.9166667 , 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.92424244, 0.92424244, 0.92424244,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.994 , 0.9873, 0.981 , 0.9785, 0.9756, 0.975 , 0.9736,\n",
       "            0.9727, 0.9707, 0.97  , 0.9697, 0.9673, 0.9663, 0.9653, 0.964 ,\n",
       "            0.962 , 0.9575, 0.957 , 0.9556, 0.9536, 0.952 , 0.951 , 0.9507,\n",
       "            0.949 , 0.9487, 0.948 , 0.9473, 0.947 , 0.9463, 0.9453, 0.944 ,\n",
       "            0.9424, 0.9385, 0.938 , 0.935 , 0.9346, 0.933 , 0.9326, 0.9307,\n",
       "            0.93  , 0.928 , 0.9272, 0.927 , 0.926 , 0.9224, 0.9214, 0.9194,\n",
       "            0.9175, 0.917 , 0.9165, 0.915 , 0.9146, 0.9136, 0.912 , 0.9116,\n",
       "            0.9106, 0.9097, 0.9077, 0.9062, 0.904 , 0.903 , 0.9014, 0.8994,\n",
       "            0.899 , 0.8984, 0.8975, 0.897 , 0.895 , 0.8945, 0.894 , 0.8936,\n",
       "            0.8896, 0.889 , 0.8867, 0.882 , 0.8794, 0.8765, 0.875 , 0.872 ,\n",
       "            0.869 , 0.8687, 0.8657, 0.8643, 0.853 , 0.852 , 0.851 , 0.8477,\n",
       "            0.845 , 0.8447, 0.844 , 0.842 , 0.841 , 0.8384, 0.8374, 0.834 ,\n",
       "            0.8306, 0.83  , 0.828 , 0.8237, 0.823 , 0.821 , 0.8154, 0.8105,\n",
       "            0.8022, 0.796 , 0.791 , 0.7856, 0.7817, 0.767 , 0.7656, 0.7583,\n",
       "            0.756 , 0.751 , 0.7495, 0.7466, 0.7324, 0.7295, 0.726 , 0.7246,\n",
       "            0.7217, 0.7144, 0.709 , 0.702 , 0.6973, 0.6904, 0.689 , 0.6875,\n",
       "            0.677 , 0.672 , 0.671 , 0.669 , 0.665 , 0.662 , 0.661 , 0.6597,\n",
       "            0.6567, 0.6475, 0.6465, 0.641 , 0.6406, 0.6377, 0.6367, 0.6357,\n",
       "            0.634 , 0.6274, 0.627 , 0.6265, 0.622 , 0.62  , 0.6177, 0.6143,\n",
       "            0.612 , 0.6113, 0.61  , 0.609 , 0.6074, 0.607 , 0.6055, 0.5933,\n",
       "            0.5894, 0.5796, 0.577 , 0.576 , 0.5757, 0.574 , 0.573 , 0.5713,\n",
       "            0.571 , 0.57  , 0.5693, 0.5674, 0.566 , 0.5645, 0.5596, 0.556 ,\n",
       "            0.5557, 0.554 , 0.5537, 0.5474, 0.5435, 0.542 , 0.5396, 0.5376,\n",
       "            0.536 , 0.533 , 0.5327, 0.531 , 0.527 , 0.526 , 0.525 , 0.5234,\n",
       "            0.523 , 0.5195, 0.519 , 0.5186, 0.518 , 0.5166, 0.5156, 0.5127,\n",
       "            0.512 , 0.5117, 0.5107, 0.508 , 0.504 , 0.4778, 0.476 , 0.4663,\n",
       "            0.4607, 0.4575, 0.4568, 0.4556, 0.454 , 0.452 , 0.444 , 0.4355,\n",
       "            0.4338, 0.4143, 0.338 , 0.3198, 0.261 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5423729, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05932203, 0.05932203,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11016949, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.48305085, 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.08333334, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.21212122, 0.21969697,\n",
       "            0.24242425, 0.25      , 0.27272728, 0.28787878, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.9166667 , 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.995 , 0.989 , 0.983 , 0.9795, 0.977 , 0.9756, 0.974 ,\n",
       "            0.9727, 0.9717, 0.971 , 0.9707, 0.969 , 0.9688, 0.967 , 0.9663,\n",
       "            0.966 , 0.961 , 0.959 , 0.9575, 0.9565, 0.9556, 0.9546, 0.953 ,\n",
       "            0.951 , 0.9507, 0.949 , 0.9478, 0.946 , 0.945 , 0.9443, 0.944 ,\n",
       "            0.9414, 0.939 , 0.938 , 0.935 , 0.9336, 0.933 , 0.9326, 0.931 ,\n",
       "            0.9287, 0.9277, 0.9243, 0.924 , 0.9233, 0.92  , 0.9194, 0.918 ,\n",
       "            0.914 , 0.9136, 0.913 , 0.9106, 0.91  , 0.908 , 0.9077, 0.9053,\n",
       "            0.9014, 0.8994, 0.899 , 0.898 , 0.8975, 0.897 , 0.8965, 0.894 ,\n",
       "            0.893 , 0.8926, 0.8916, 0.8896, 0.889 , 0.8867, 0.881 , 0.8804,\n",
       "            0.879 , 0.8765, 0.869 , 0.8677, 0.867 , 0.8667, 0.8647, 0.857 ,\n",
       "            0.8564, 0.8545, 0.8506, 0.849 , 0.848 , 0.845 , 0.8447, 0.842 ,\n",
       "            0.838 , 0.8345, 0.832 , 0.8296, 0.827 , 0.8267, 0.823 , 0.8223,\n",
       "            0.821 , 0.814 , 0.8125, 0.8086, 0.8013, 0.8   , 0.792 , 0.7915,\n",
       "            0.7886, 0.776 , 0.7734, 0.7544, 0.749 , 0.747 , 0.746 , 0.7456,\n",
       "            0.7407, 0.7344, 0.7285, 0.7217, 0.7104, 0.7056, 0.704 , 0.6978,\n",
       "            0.691 , 0.6885, 0.6855, 0.677 , 0.6714, 0.671 , 0.668 , 0.6606,\n",
       "            0.658 , 0.6543, 0.649 , 0.648 , 0.632 , 0.6255, 0.625 , 0.619 ,\n",
       "            0.6167, 0.615 , 0.609 , 0.6064, 0.5933, 0.592 , 0.591 , 0.59  ,\n",
       "            0.5894, 0.584 , 0.5815, 0.581 , 0.5806, 0.5776, 0.575 , 0.571 ,\n",
       "            0.564 , 0.562 , 0.5527, 0.5513, 0.547 , 0.545 , 0.5425, 0.539 ,\n",
       "            0.5386, 0.537 , 0.536 , 0.5347, 0.5312, 0.5303, 0.5293, 0.5225,\n",
       "            0.522 , 0.518 , 0.5117, 0.5034, 0.5024, 0.502 , 0.5015, 0.4963,\n",
       "            0.4905, 0.4902, 0.49  , 0.4895, 0.4858, 0.4824, 0.4795, 0.4688,\n",
       "            0.468 , 0.4673, 0.4614, 0.4592, 0.4583, 0.4463, 0.445 , 0.4404,\n",
       "            0.435 , 0.4292, 0.429 , 0.4285, 0.428 , 0.427 , 0.425 , 0.4233,\n",
       "            0.421 , 0.4202, 0.418 , 0.416 , 0.4155, 0.4153, 0.4138, 0.4133,\n",
       "            0.413 , 0.4111, 0.4102, 0.4065, 0.4048, 0.4019, 0.401 , 0.4   ,\n",
       "            0.3972, 0.3955, 0.3918, 0.3909, 0.378 , 0.3025, 0.2708, 0.2153],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.41525424, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.29661018, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.14393939, 0.15151516, 0.16666667,\n",
       "            0.18181819, 0.20454545, 0.21212122, 0.21969697, 0.23484848,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.31060606, 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.5       ,\n",
       "            0.50757575, 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.996 , 0.99  , 0.9844, 0.981 , 0.9785, 0.978 , 0.9775,\n",
       "            0.976 , 0.975 , 0.9746, 0.974 , 0.973 , 0.9727, 0.971 , 0.9707,\n",
       "            0.969 , 0.9688, 0.962 , 0.9614, 0.9604, 0.9575, 0.956 , 0.9556,\n",
       "            0.9546, 0.953 , 0.9517, 0.951 , 0.95  , 0.949 , 0.9487, 0.9478,\n",
       "            0.9463, 0.946 , 0.9434, 0.942 , 0.9395, 0.9375, 0.937 , 0.936 ,\n",
       "            0.9336, 0.932 , 0.9316, 0.9297, 0.9277, 0.9263, 0.926 , 0.9243,\n",
       "            0.9194, 0.918 , 0.9165, 0.916 , 0.915 , 0.914 , 0.912 , 0.9106,\n",
       "            0.909 , 0.908 , 0.9043, 0.9033, 0.903 , 0.902 , 0.9   , 0.8994,\n",
       "            0.899 , 0.8975, 0.8955, 0.895 , 0.894 , 0.8906, 0.889 , 0.8853,\n",
       "            0.8843, 0.881 , 0.879 , 0.8735, 0.8706, 0.869 , 0.868 , 0.8667,\n",
       "            0.8545, 0.8535, 0.8525, 0.852 , 0.8467, 0.846 , 0.843 , 0.8374,\n",
       "            0.836 , 0.8325, 0.8296, 0.8286, 0.8237, 0.82  , 0.8193, 0.8154,\n",
       "            0.815 , 0.8115, 0.8047, 0.799 , 0.7944, 0.7915, 0.7886, 0.78  ,\n",
       "            0.7783, 0.7676, 0.7646, 0.7417, 0.7373, 0.7324, 0.7305, 0.7236,\n",
       "            0.721 , 0.718 , 0.707 , 0.6934, 0.6855, 0.6826, 0.6816, 0.676 ,\n",
       "            0.6724, 0.65  , 0.649 , 0.6475, 0.642 , 0.6406, 0.6387, 0.6377,\n",
       "            0.6367, 0.63  , 0.62  , 0.61  , 0.606 , 0.602 , 0.588 , 0.5874,\n",
       "            0.585 , 0.5825, 0.58  , 0.5654, 0.5625, 0.562 , 0.561 , 0.555 ,\n",
       "            0.5547, 0.5527, 0.5522, 0.5513, 0.551 , 0.5503, 0.545 , 0.538 ,\n",
       "            0.53  , 0.528 , 0.525 , 0.5205, 0.52  , 0.5127, 0.51  , 0.5083,\n",
       "            0.508 , 0.507 , 0.501 , 0.499 , 0.497 , 0.4946, 0.4895, 0.4858,\n",
       "            0.4846, 0.4844, 0.4832, 0.478 , 0.4734, 0.4639, 0.4604, 0.4602,\n",
       "            0.4583, 0.458 , 0.4553, 0.4548, 0.4473, 0.435 , 0.4316, 0.4304,\n",
       "            0.4287, 0.4238, 0.4219, 0.4177, 0.414 , 0.4124, 0.406 , 0.4014,\n",
       "            0.4   , 0.3943, 0.3936, 0.3896, 0.3892, 0.3855, 0.383 , 0.3826,\n",
       "            0.3772, 0.3752, 0.3716, 0.3682, 0.367 , 0.3667, 0.3662, 0.3657,\n",
       "            0.3633, 0.3596, 0.359 , 0.3577, 0.356 , 0.3533, 0.35  , 0.3477,\n",
       "            0.3457, 0.345 , 0.343 , 0.3425, 0.3418, 0.3394, 0.3325, 0.33  ,\n",
       "            0.3232, 0.32  , 0.271 , 0.2257, 0.1753], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.33050847, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7966102 ,\n",
       "            0.80508476, 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25757575, 0.2651515 , 0.28030303, 0.28787878, 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.5530303 , 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9966, 0.9917, 0.9863, 0.9834, 0.9814, 0.9805, 0.98  ,\n",
       "            0.979 , 0.978 , 0.9775, 0.977 , 0.976 , 0.9756, 0.9746, 0.973 ,\n",
       "            0.9727, 0.972 , 0.97  , 0.966 , 0.9653, 0.9644, 0.9624, 0.9604,\n",
       "            0.96  , 0.9595, 0.958 , 0.9575, 0.9565, 0.956 , 0.9546, 0.953 ,\n",
       "            0.9526, 0.9517, 0.95  , 0.9497, 0.948 , 0.9463, 0.9453, 0.942 ,\n",
       "            0.9404, 0.9395, 0.9385, 0.938 , 0.9365, 0.9336, 0.932 , 0.929 ,\n",
       "            0.9287, 0.928 , 0.9263, 0.924 , 0.922 , 0.921 , 0.9204, 0.919 ,\n",
       "            0.9155, 0.914 , 0.9126, 0.9106, 0.9097, 0.9077, 0.906 , 0.9043,\n",
       "            0.902 , 0.9014, 0.9004, 0.8975, 0.8945, 0.894 , 0.8926, 0.892 ,\n",
       "            0.8896, 0.8853, 0.8833, 0.8784, 0.878 , 0.874 , 0.8706, 0.8657,\n",
       "            0.8643, 0.8574, 0.8555, 0.853 , 0.8516, 0.85  , 0.8496, 0.8467,\n",
       "            0.844 , 0.841 , 0.839 , 0.8296, 0.8276, 0.824 , 0.8213, 0.818 ,\n",
       "            0.816 , 0.8145, 0.808 , 0.807 , 0.8057, 0.7993, 0.792 , 0.787 ,\n",
       "            0.7837, 0.778 , 0.769 , 0.7617, 0.758 , 0.7324, 0.728 , 0.7275,\n",
       "            0.727 , 0.7246, 0.709 , 0.7065, 0.703 , 0.7007, 0.682 , 0.6807,\n",
       "            0.6777, 0.6763, 0.6626, 0.6577, 0.6543, 0.642 , 0.6416, 0.6323,\n",
       "            0.622 , 0.6216, 0.6206, 0.6196, 0.6123, 0.6113, 0.5977, 0.5923,\n",
       "            0.586 , 0.585 , 0.567 , 0.5664, 0.5654, 0.564 , 0.561 , 0.5405,\n",
       "            0.5396, 0.5386, 0.537 , 0.5356, 0.533 , 0.5317, 0.5254, 0.5215,\n",
       "            0.5195, 0.5186, 0.514 , 0.505 , 0.498 , 0.4932, 0.493 , 0.4883,\n",
       "            0.4856, 0.483 , 0.482 , 0.48  , 0.479 , 0.4746, 0.4685, 0.467 ,\n",
       "            0.4646, 0.4626, 0.4614, 0.4583, 0.4546, 0.4524, 0.4487, 0.4321,\n",
       "            0.4316, 0.4285, 0.4275, 0.4263, 0.4238, 0.4226, 0.4216, 0.4143,\n",
       "            0.4019, 0.3975, 0.3962, 0.3933, 0.3894, 0.3867, 0.3794, 0.3784,\n",
       "            0.3743, 0.3708, 0.3696, 0.3652, 0.3594, 0.3538, 0.353 , 0.3523,\n",
       "            0.3486, 0.348 , 0.346 , 0.3438, 0.34  , 0.3396, 0.3374, 0.3337,\n",
       "            0.3245, 0.3228, 0.3223, 0.3218, 0.3215, 0.32  , 0.3179, 0.3113,\n",
       "            0.307 , 0.3066, 0.3044, 0.3027, 0.3015, 0.2976, 0.2969, 0.2957,\n",
       "            0.295 , 0.2913, 0.2844, 0.2778, 0.2737, 0.2678, 0.2351, 0.1885,\n",
       "            0.1417], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.2542373, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.1969697 , 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.997  , 0.992  , 0.9873 , 0.984  , 0.982  , 0.981  ,\n",
       "            0.9805 , 0.9795 , 0.979  , 0.9785 , 0.9775 , 0.9766 , 0.976  ,\n",
       "            0.975  , 0.974  , 0.973  , 0.9727 , 0.971  , 0.966  , 0.9653 ,\n",
       "            0.965  , 0.9634 , 0.961  , 0.9604 , 0.96   , 0.958  , 0.9575 ,\n",
       "            0.957  , 0.9556 , 0.9546 , 0.9536 , 0.9526 , 0.952  , 0.9507 ,\n",
       "            0.95   , 0.9497 , 0.949  , 0.9473 , 0.9463 , 0.9434 , 0.9414 ,\n",
       "            0.9404 , 0.938  , 0.936  , 0.9346 , 0.9336 , 0.9307 , 0.93   ,\n",
       "            0.9277 , 0.927  , 0.925  , 0.9224 , 0.921  , 0.9204 , 0.919  ,\n",
       "            0.916  , 0.912  , 0.9097 , 0.907  , 0.9067 , 0.9053 , 0.9043 ,\n",
       "            0.903  , 0.901  , 0.9004 , 0.8984 , 0.8975 , 0.8945 , 0.8926 ,\n",
       "            0.892  , 0.8916 , 0.8896 , 0.889  , 0.8867 , 0.8853 , 0.884  ,\n",
       "            0.88   , 0.8735 , 0.8706 , 0.8696 , 0.863  , 0.8613 , 0.8584 ,\n",
       "            0.8516 , 0.85   , 0.8496 , 0.8486 , 0.8447 , 0.842  , 0.8403 ,\n",
       "            0.8325 , 0.832  , 0.8257 , 0.82   , 0.8154 , 0.8086 , 0.8066 ,\n",
       "            0.8027 , 0.8    , 0.7964 , 0.7925 , 0.783  , 0.7773 , 0.776  ,\n",
       "            0.7754 , 0.7544 , 0.753  , 0.7485 , 0.743  , 0.7217 , 0.7124 ,\n",
       "            0.7085 , 0.708  , 0.699  , 0.693  , 0.6875 , 0.682  , 0.677  ,\n",
       "            0.663  , 0.657  , 0.6514 , 0.6455 , 0.645  , 0.6406 , 0.629  ,\n",
       "            0.6187 , 0.612  , 0.61   , 0.605  , 0.5996 , 0.5986 , 0.589  ,\n",
       "            0.581  , 0.5728 , 0.569  , 0.5615 , 0.561  , 0.558  , 0.544  ,\n",
       "            0.541  , 0.5312 , 0.525  , 0.5215 , 0.514  , 0.5093 , 0.509  ,\n",
       "            0.502  , 0.4963 , 0.4954 , 0.4902 , 0.4875 , 0.4778 , 0.4683 ,\n",
       "            0.467  , 0.4658 , 0.4626 , 0.4573 , 0.4563 , 0.452  , 0.4512 ,\n",
       "            0.4492 , 0.4336 , 0.433  , 0.4329 , 0.4321 , 0.432  , 0.4304 ,\n",
       "            0.4248 , 0.4197 , 0.4185 , 0.4116 , 0.4072 , 0.4026 , 0.396  ,\n",
       "            0.3938 , 0.3906 , 0.384  , 0.3806 , 0.3784 , 0.377  , 0.3765 ,\n",
       "            0.368  , 0.3442 , 0.343  , 0.3425 , 0.3367 , 0.3364 , 0.335  ,\n",
       "            0.332  , 0.3318 , 0.3252 , 0.3245 , 0.3213 , 0.3198 , 0.316  ,\n",
       "            0.313  , 0.311  , 0.3086 , 0.3044 , 0.303  , 0.3025 , 0.3018 ,\n",
       "            0.3005 , 0.2976 , 0.2944 , 0.2878 , 0.2869 , 0.2854 , 0.2751 ,\n",
       "            0.2742 , 0.274  , 0.2732 , 0.2727 , 0.2725 , 0.2695 , 0.2632 ,\n",
       "            0.2573 , 0.2542 , 0.2512 , 0.2498 , 0.2452 , 0.2451 , 0.2448 ,\n",
       "            0.2445 , 0.2406 , 0.233  , 0.2247 , 0.2229 , 0.2152 , 0.2054 ,\n",
       "            0.157  , 0.11615], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.20338982, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06818182, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.14393939, 0.1590909 , 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28787878, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.33333334, 0.34848484, 0.3560606 ,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9976, 0.993 , 0.9883, 0.985 , 0.983 , 0.9824, 0.982 ,\n",
       "            0.9805, 0.98  , 0.979 , 0.978 , 0.977 , 0.9766, 0.9756, 0.9746,\n",
       "            0.9673, 0.967 , 0.9663, 0.9653, 0.9644, 0.9624, 0.961 , 0.96  ,\n",
       "            0.959 , 0.9585, 0.9575, 0.9565, 0.9546, 0.954 , 0.952 , 0.951 ,\n",
       "            0.9507, 0.9478, 0.9463, 0.9424, 0.94  , 0.9395, 0.9385, 0.938 ,\n",
       "            0.9355, 0.935 , 0.9326, 0.9287, 0.928 , 0.924 , 0.9233, 0.923 ,\n",
       "            0.922 , 0.921 , 0.92  , 0.914 , 0.9136, 0.913 , 0.9116, 0.9106,\n",
       "            0.909 , 0.9077, 0.9053, 0.905 , 0.9043, 0.902 , 0.8984, 0.897 ,\n",
       "            0.896 , 0.895 , 0.8926, 0.8906, 0.89  , 0.8823, 0.8804, 0.876 ,\n",
       "            0.872 , 0.871 , 0.868 , 0.866 , 0.864 , 0.8604, 0.855 , 0.8516,\n",
       "            0.8477, 0.8457, 0.844 , 0.8423, 0.842 , 0.8384, 0.83  , 0.8286,\n",
       "            0.8257, 0.8164, 0.815 , 0.807 , 0.806 , 0.8027, 0.7993, 0.796 ,\n",
       "            0.794 , 0.786 , 0.775 , 0.7734, 0.7725, 0.7695, 0.747 , 0.742 ,\n",
       "            0.741 , 0.7373, 0.7153, 0.705 , 0.6987, 0.6978, 0.682 , 0.68  ,\n",
       "            0.675 , 0.6694, 0.663 , 0.6494, 0.644 , 0.633 , 0.632 , 0.6265,\n",
       "            0.6235, 0.613 , 0.602 , 0.5933, 0.5923, 0.591 , 0.582 , 0.5806,\n",
       "            0.5693, 0.5566, 0.5474, 0.546 , 0.5435, 0.5396, 0.534 , 0.524 ,\n",
       "            0.518 , 0.509 , 0.4956, 0.4922, 0.4915, 0.4836, 0.4834, 0.4812,\n",
       "            0.4744, 0.4717, 0.4697, 0.469 , 0.4688, 0.4612, 0.4583, 0.4465,\n",
       "            0.4426, 0.4385, 0.4358, 0.434 , 0.4326, 0.4324, 0.4321, 0.4224,\n",
       "            0.4219, 0.421 , 0.4053, 0.403 , 0.4016, 0.4001, 0.3984, 0.3982,\n",
       "            0.3896, 0.3877, 0.3865, 0.3806, 0.371 , 0.369 , 0.3647, 0.3616,\n",
       "            0.361 , 0.3508, 0.3445, 0.344 , 0.3435, 0.343 , 0.3394, 0.339 ,\n",
       "            0.3086, 0.3064, 0.306 , 0.3052, 0.3   , 0.2983, 0.2957, 0.2935,\n",
       "            0.2922, 0.2869, 0.2832, 0.283 , 0.282 , 0.2815, 0.2812, 0.2732,\n",
       "            0.271 , 0.27  , 0.2676, 0.2651, 0.264 , 0.2622, 0.2578, 0.2568,\n",
       "            0.2556, 0.2542, 0.2467, 0.2358, 0.2351, 0.233 , 0.2325, 0.2322,\n",
       "            0.2299, 0.2238, 0.2175, 0.214 , 0.211 , 0.2065, 0.2059, 0.205 ,\n",
       "            0.2039, 0.2002, 0.1925, 0.1835, 0.1829, 0.1823, 0.1744, 0.1312,\n",
       "            0.0962], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.18644068, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.04545455, 0.0530303 , 0.06818182, 0.08333334, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.12121212, 0.12878788, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.16666667, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.6666667 , 0.67424244, 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9976, 0.993 , 0.989 , 0.985 , 0.983 , 0.9814, 0.9805,\n",
       "            0.98  , 0.979 , 0.978 , 0.977 , 0.9766, 0.975 , 0.9746, 0.974 ,\n",
       "            0.9697, 0.968 , 0.9673, 0.967 , 0.966 , 0.965 , 0.964 , 0.9624,\n",
       "            0.962 , 0.9614, 0.961 , 0.9604, 0.9585, 0.9575, 0.956 , 0.9546,\n",
       "            0.953 , 0.9526, 0.9507, 0.95  , 0.9497, 0.9487, 0.9473, 0.9453,\n",
       "            0.942 , 0.9414, 0.939 , 0.938 , 0.9375, 0.937 , 0.935 , 0.931 ,\n",
       "            0.9263, 0.9233, 0.9214, 0.921 , 0.9204, 0.918 , 0.9165, 0.916 ,\n",
       "            0.914 , 0.913 , 0.9106, 0.9097, 0.9087, 0.908 , 0.9077, 0.907 ,\n",
       "            0.904 , 0.902 , 0.9004, 0.899 , 0.8975, 0.897 , 0.894 , 0.893 ,\n",
       "            0.892 , 0.8853, 0.8774, 0.877 , 0.8726, 0.867 , 0.8647, 0.863 ,\n",
       "            0.861 , 0.856 , 0.851 , 0.843 , 0.842 , 0.8413, 0.8394, 0.839 ,\n",
       "            0.832 , 0.8237, 0.8228, 0.821 , 0.8135, 0.8057, 0.805 , 0.804 ,\n",
       "            0.7974, 0.793 , 0.7915, 0.786 , 0.7754, 0.7705, 0.769 , 0.763 ,\n",
       "            0.758 , 0.7417, 0.732 , 0.728 , 0.706 , 0.6978, 0.6895, 0.6787,\n",
       "            0.6665, 0.6626, 0.6533, 0.653 , 0.6484, 0.628 , 0.627 , 0.621 ,\n",
       "            0.613 , 0.6123, 0.6025, 0.5996, 0.5835, 0.576 , 0.574 , 0.569 ,\n",
       "            0.5635, 0.554 , 0.551 , 0.5396, 0.53  , 0.52  , 0.518 , 0.5117,\n",
       "            0.5103, 0.503 , 0.496 , 0.4749, 0.469 , 0.4685, 0.4653, 0.4644,\n",
       "            0.4597, 0.456 , 0.4492, 0.4436, 0.4429, 0.4426, 0.4385, 0.4343,\n",
       "            0.4316, 0.4248, 0.4146, 0.4138, 0.4116, 0.4072, 0.4038, 0.4036,\n",
       "            0.403 , 0.399 , 0.3958, 0.3933, 0.3787, 0.3772, 0.3745, 0.3708,\n",
       "            0.3677, 0.3608, 0.3591, 0.3557, 0.3542, 0.345 , 0.3406, 0.3357,\n",
       "            0.3325, 0.3306, 0.3274, 0.3208, 0.3193, 0.3171, 0.3105, 0.3079,\n",
       "            0.2808, 0.2805, 0.278 , 0.2756, 0.2747, 0.271 , 0.2703, 0.2688,\n",
       "            0.2622, 0.258 , 0.2568, 0.2522, 0.2507, 0.246 , 0.2433, 0.2391,\n",
       "            0.2378, 0.237 , 0.2367, 0.2338, 0.229 , 0.2274, 0.2273, 0.2269,\n",
       "            0.219 , 0.2106, 0.21  , 0.2076, 0.207 , 0.2051, 0.2045, 0.1985,\n",
       "            0.1924, 0.1885, 0.1853, 0.1844, 0.18  , 0.1799, 0.1794, 0.1788,\n",
       "            0.1754, 0.1674, 0.1589, 0.158 , 0.1501, 0.1086, 0.0786],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.16949153, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.04545455, 0.06060606, 0.08333334, 0.09090909, 0.09848485,\n",
       "            0.10606061, 0.11363637, 0.12121212, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.18939394,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.32575756, 0.33333334, 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.719697  , 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.998  , 0.994  , 0.9897 , 0.9863 , 0.9844 , 0.9824 ,\n",
       "            0.982  , 0.981  , 0.9805 , 0.98   , 0.9795 , 0.9785 , 0.9766 ,\n",
       "            0.976  , 0.974  , 0.972  , 0.971  , 0.9697 , 0.969  , 0.9688 ,\n",
       "            0.9673 , 0.9663 , 0.9653 , 0.9644 , 0.9634 , 0.963  , 0.9624 ,\n",
       "            0.9614 , 0.96   , 0.959  , 0.9565 , 0.9546 , 0.9536 , 0.953  ,\n",
       "            0.9517 , 0.9507 , 0.948  , 0.9473 , 0.945  , 0.9443 , 0.9434 ,\n",
       "            0.9424 , 0.9414 , 0.9404 , 0.9385 , 0.9336 , 0.9307 , 0.93   ,\n",
       "            0.9253 , 0.9243 , 0.924  , 0.922  , 0.9214 , 0.921  , 0.918  ,\n",
       "            0.917  , 0.9155 , 0.9146 , 0.9126 , 0.912  , 0.9087 , 0.907  ,\n",
       "            0.9067 , 0.906  , 0.9053 , 0.905  , 0.903  , 0.9004 , 0.8994 ,\n",
       "            0.8984 , 0.886  , 0.8857 , 0.882  , 0.881  , 0.8784 , 0.8755 ,\n",
       "            0.8735 , 0.8706 , 0.87   , 0.8677 , 0.8633 , 0.857  , 0.851  ,\n",
       "            0.845  , 0.8433 , 0.842  , 0.836  , 0.827  , 0.826  , 0.8247 ,\n",
       "            0.8223 , 0.814  , 0.8125 , 0.8047 , 0.8    , 0.798  , 0.791  ,\n",
       "            0.78   , 0.777  , 0.7686 , 0.762  , 0.749  , 0.7383 , 0.735  ,\n",
       "            0.724  , 0.7056 , 0.7017 , 0.695  , 0.669  , 0.665  , 0.661  ,\n",
       "            0.657  , 0.654  , 0.6265 , 0.626  , 0.6196 , 0.615  , 0.612  ,\n",
       "            0.6074 , 0.6064 , 0.6    , 0.5806 , 0.57   , 0.569  , 0.568  ,\n",
       "            0.5547 , 0.5415 , 0.54   , 0.5337 , 0.53   , 0.508  , 0.5054 ,\n",
       "            0.4905 , 0.4822 , 0.482  , 0.4683 , 0.4646 , 0.4575 , 0.4539 ,\n",
       "            0.4438 , 0.4436 , 0.4397 , 0.4324 , 0.4321 , 0.426  , 0.4238 ,\n",
       "            0.4192 , 0.4143 , 0.411  , 0.4062 , 0.406  , 0.403  , 0.3967 ,\n",
       "            0.3909 , 0.3875 , 0.3823 , 0.38   , 0.3767 , 0.3713 , 0.3687 ,\n",
       "            0.368  , 0.3594 , 0.358  , 0.3523 , 0.3496 , 0.3486 , 0.3447 ,\n",
       "            0.34   , 0.3389 , 0.3386 , 0.3325 , 0.3164 , 0.3137 , 0.3123 ,\n",
       "            0.311  , 0.3105 , 0.31   , 0.3071 , 0.2983 , 0.2837 , 0.2761 ,\n",
       "            0.2732 , 0.2708 , 0.2646 , 0.2607 , 0.2595 , 0.2559 , 0.2527 ,\n",
       "            0.2483 , 0.2455 , 0.2418 , 0.2391 , 0.2307 , 0.2302 , 0.229  ,\n",
       "            0.2266 , 0.2244 , 0.2222 , 0.2197 , 0.2144 , 0.2125 , 0.2124 ,\n",
       "            0.208  , 0.2058 , 0.2051 , 0.199  , 0.1948 , 0.1942 , 0.1923 ,\n",
       "            0.1917 , 0.191  , 0.189  , 0.1829 , 0.1768 , 0.1743 , 0.1736 ,\n",
       "            0.1707 , 0.169  , 0.1686 , 0.1647 , 0.1637 , 0.16   , 0.1531 ,\n",
       "            0.1444 , 0.1432 , 0.143  , 0.1355 , 0.09076, 0.0656 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.12711865, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.11363637, 0.12121212, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.1969697 , 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.25      , 0.25757575, 0.2651515 , 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.50757575, 0.5151515 , 0.52272725, 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.70454544, 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.998 , 0.994 , 0.9897, 0.986 , 0.9844, 0.984 , 0.9824,\n",
       "            0.982 , 0.9814, 0.981 , 0.979 , 0.9785, 0.9775, 0.9766, 0.9756,\n",
       "            0.972 , 0.9707, 0.97  , 0.9688, 0.9683, 0.968 , 0.9663, 0.965 ,\n",
       "            0.9644, 0.964 , 0.963 , 0.9624, 0.961 , 0.9595, 0.9585, 0.9575,\n",
       "            0.954 , 0.9536, 0.953 , 0.952 , 0.951 , 0.95  , 0.9497, 0.9487,\n",
       "            0.9473, 0.9453, 0.945 , 0.9424, 0.941 , 0.9404, 0.9385, 0.938 ,\n",
       "            0.932 , 0.9287, 0.9263, 0.926 , 0.922 , 0.9214, 0.9185, 0.9175,\n",
       "            0.917 , 0.9126, 0.9116, 0.909 , 0.908 , 0.907 , 0.905 , 0.903 ,\n",
       "            0.9014, 0.8994, 0.8975, 0.896 , 0.8945, 0.893 , 0.8916, 0.8906,\n",
       "            0.8813, 0.875 , 0.8735, 0.8726, 0.872 , 0.8667, 0.8647, 0.862 ,\n",
       "            0.857 , 0.8564, 0.8545, 0.8496, 0.8403, 0.8345, 0.834 , 0.8325,\n",
       "            0.8267, 0.818 , 0.814 , 0.811 , 0.805 , 0.7964, 0.796 , 0.791 ,\n",
       "            0.7905, 0.779 , 0.778 , 0.769 , 0.762 , 0.759 , 0.757 , 0.743 ,\n",
       "            0.7393, 0.723 , 0.715 , 0.709 , 0.6997, 0.688 , 0.68  , 0.6646,\n",
       "            0.6504, 0.636 , 0.628 , 0.6265, 0.622 , 0.612 , 0.6025, 0.5977,\n",
       "            0.594 , 0.587 , 0.5767, 0.567 , 0.564 , 0.555 , 0.5454, 0.541 ,\n",
       "            0.532 , 0.5312, 0.5166, 0.5137, 0.4902, 0.4795, 0.479 , 0.4773,\n",
       "            0.4668, 0.4653, 0.4624, 0.456 , 0.4282, 0.4233, 0.4224, 0.4177,\n",
       "            0.416 , 0.4124, 0.412 , 0.407 , 0.399 , 0.3967, 0.3923, 0.3901,\n",
       "            0.389 , 0.3813, 0.3708, 0.3704, 0.3677, 0.3594, 0.3582, 0.3577,\n",
       "            0.3547, 0.3508, 0.3486, 0.3467, 0.3438, 0.3345, 0.328 , 0.3262,\n",
       "            0.3225, 0.3176, 0.317 , 0.3147, 0.3064, 0.3035, 0.2998, 0.295 ,\n",
       "            0.2908, 0.2866, 0.282 , 0.2815, 0.2783, 0.2756, 0.2703, 0.2678,\n",
       "            0.2644, 0.2632, 0.2622, 0.2303, 0.2292, 0.2272, 0.2269, 0.2264,\n",
       "            0.223 , 0.2216, 0.2185, 0.2123, 0.2075, 0.2065, 0.206 , 0.2054,\n",
       "            0.2028, 0.1976, 0.1959, 0.1924, 0.1904, 0.1897, 0.1853, 0.1846,\n",
       "            0.183 , 0.1821, 0.1779, 0.1765, 0.1627, 0.1619, 0.16  , 0.1582,\n",
       "            0.1567, 0.1564, 0.1505, 0.1448, 0.1412, 0.1383, 0.1368, 0.1333,\n",
       "            0.1329, 0.1326, 0.1315, 0.1288, 0.1229, 0.1216, 0.1128, 0.1122,\n",
       "            0.1054, 0.0772, 0.055 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.11016949, dtype=float32),\n",
       "    'tpr': array(0.97727275, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.1969697 , 0.21212122, 0.21969697,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.36363637, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.47727272, 0.4848485 ,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6969697 , 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.998  , 0.994  , 0.9897 , 0.985  , 0.9834 , 0.983  ,\n",
       "            0.982  , 0.9814 , 0.981  , 0.9805 , 0.98   , 0.979  , 0.9775 ,\n",
       "            0.9766 , 0.976  , 0.9756 , 0.974  , 0.973  , 0.9717 , 0.9683 ,\n",
       "            0.9673 , 0.967  , 0.966  , 0.9644 , 0.963  , 0.9624 , 0.962  ,\n",
       "            0.961  , 0.9604 , 0.96   , 0.9595 , 0.957  , 0.955  , 0.9546 ,\n",
       "            0.9536 , 0.951  , 0.9478 , 0.9473 , 0.947  , 0.946  , 0.9453 ,\n",
       "            0.942  , 0.9414 , 0.9395 , 0.939  , 0.937  , 0.9346 , 0.9307 ,\n",
       "            0.9287 , 0.927  , 0.92   , 0.9185 , 0.9175 , 0.917  , 0.9155 ,\n",
       "            0.912  , 0.9116 , 0.9087 , 0.908  , 0.9043 , 0.9004 , 0.9    ,\n",
       "            0.899  , 0.8984 , 0.8965 , 0.8955 , 0.895  , 0.893  , 0.8896 ,\n",
       "            0.8887 , 0.881  , 0.8755 , 0.871  , 0.8687 , 0.867  , 0.8643 ,\n",
       "            0.86   , 0.8574 , 0.8545 , 0.8516 , 0.8477 , 0.84   , 0.837  ,\n",
       "            0.8257 , 0.8247 , 0.8213 , 0.8193 , 0.816  , 0.807  , 0.8066 ,\n",
       "            0.7964 , 0.796  , 0.788  , 0.786  , 0.783  , 0.7793 , 0.766  ,\n",
       "            0.755  , 0.754  , 0.745  , 0.743  , 0.7354 , 0.7144 , 0.714  ,\n",
       "            0.706  , 0.6997 , 0.692  , 0.677  , 0.6655 , 0.659  , 0.6436 ,\n",
       "            0.6323 , 0.6187 , 0.601  , 0.596  , 0.592  , 0.581  , 0.58   ,\n",
       "            0.578  , 0.574  , 0.57   , 0.5415 , 0.5366 , 0.53   , 0.522  ,\n",
       "            0.5195 , 0.5186 , 0.512  , 0.4954 , 0.4944 , 0.4912 , 0.4573 ,\n",
       "            0.4546 , 0.452  , 0.445  , 0.44   , 0.4385 , 0.4336 , 0.4272 ,\n",
       "            0.4065 , 0.3982 , 0.395  , 0.394  , 0.3867 , 0.383  , 0.3757 ,\n",
       "            0.3718 , 0.367  , 0.3667 , 0.366  , 0.3625 , 0.3503 , 0.3435 ,\n",
       "            0.3386 , 0.3367 , 0.336  , 0.335  , 0.3333 , 0.3328 , 0.3281 ,\n",
       "            0.3235 , 0.3145 , 0.3132 , 0.3047 , 0.298  , 0.2925 , 0.292  ,\n",
       "            0.2917 , 0.2827 , 0.2776 , 0.2686 , 0.2642 , 0.2625 , 0.258  ,\n",
       "            0.255  , 0.249  , 0.247  , 0.2462 , 0.2429 , 0.2378 , 0.2347 ,\n",
       "            0.2327 , 0.2294 , 0.2244 , 0.2069 , 0.1991 , 0.1967 , 0.1934 ,\n",
       "            0.1924 , 0.1919 , 0.1858 , 0.1853 , 0.1838 , 0.1814 , 0.177  ,\n",
       "            0.1765 , 0.1752 , 0.1741 , 0.1729 , 0.1721 , 0.1698 , 0.1682 ,\n",
       "            0.1666 , 0.165  , 0.1636 , 0.1627 , 0.1611 , 0.1578 , 0.153  ,\n",
       "            0.1483 , 0.1346 , 0.1344 , 0.1323 , 0.1293 , 0.1283 , 0.128  ,\n",
       "            0.12335, 0.1174 , 0.1144 , 0.11163, 0.1076 , 0.1074 , 0.10614,\n",
       "            0.10486, 0.1047 , 0.1045 , 0.1025 , 0.0959 , 0.0873 , 0.0869 ,\n",
       "            0.08093, 0.0655 , 0.04602], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.09322034, dtype=float32),\n",
       "    'tpr': array(0.97727275, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.11016949, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.07575758, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.12121212, 0.12878788, 0.14393939,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.3030303 ,\n",
       "            0.31060606, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37878788, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.998  , 0.994  , 0.9897 , 0.985  , 0.9834 , 0.983  ,\n",
       "            0.9814 , 0.981  , 0.9805 , 0.9795 , 0.977  , 0.976  , 0.9756 ,\n",
       "            0.975  , 0.9736 , 0.9707 , 0.9688 , 0.968  , 0.9673 , 0.967  ,\n",
       "            0.966  , 0.9653 , 0.9644 , 0.9624 , 0.962  , 0.96   , 0.9595 ,\n",
       "            0.9575 , 0.956  , 0.9536 , 0.9497 , 0.949  , 0.948  , 0.947  ,\n",
       "            0.945  , 0.9443 , 0.944  , 0.942  , 0.9385 , 0.936  , 0.9336 ,\n",
       "            0.933  , 0.931  , 0.929  , 0.921  , 0.92   , 0.918  , 0.916  ,\n",
       "            0.9155 , 0.9136 , 0.913  , 0.911  , 0.91   , 0.9097 , 0.9062 ,\n",
       "            0.9014 , 0.9004 , 0.8984 , 0.8975 , 0.897  , 0.895  , 0.8945 ,\n",
       "            0.894  , 0.8916 , 0.8906 , 0.878  , 0.8716 , 0.87   , 0.8696 ,\n",
       "            0.866  , 0.8643 , 0.859  , 0.8564 , 0.8545 , 0.854  , 0.8525 ,\n",
       "            0.847  , 0.838  , 0.8354 , 0.8257 , 0.82   , 0.8164 , 0.8145 ,\n",
       "            0.811  , 0.803  , 0.802  , 0.7954 , 0.7905 , 0.787  , 0.7847 ,\n",
       "            0.782  , 0.7666 , 0.764  , 0.7524 , 0.7456 , 0.742  , 0.7344 ,\n",
       "            0.7266 , 0.704  , 0.7007 , 0.6943 , 0.6797 , 0.6675 , 0.659  ,\n",
       "            0.6465 , 0.6353 , 0.6123 , 0.604  , 0.5894 , 0.5854 , 0.57   ,\n",
       "            0.566  , 0.565  , 0.5625 , 0.556  , 0.553  , 0.529  , 0.522  ,\n",
       "            0.5166 , 0.5083 , 0.5044 , 0.4998 , 0.4958 , 0.4797 , 0.4785 ,\n",
       "            0.4675 , 0.4382 , 0.435  , 0.427  , 0.4224 , 0.414  , 0.412  ,\n",
       "            0.4072 , 0.3872 , 0.3777 , 0.374  , 0.3687 , 0.3684 , 0.3665 ,\n",
       "            0.3557 , 0.3506 , 0.35   , 0.3477 , 0.3464 , 0.34   , 0.3352 ,\n",
       "            0.3245 , 0.3223 , 0.3206 , 0.316  , 0.3135 , 0.3132 , 0.3108 ,\n",
       "            0.3074 , 0.3044 , 0.2954 , 0.295  , 0.292  , 0.2847 , 0.2761 ,\n",
       "            0.273  , 0.2717 , 0.2712 , 0.2612 , 0.258  , 0.249  , 0.2485 ,\n",
       "            0.2437 , 0.241  , 0.237  , 0.2344 , 0.2301 , 0.2285 , 0.2229 ,\n",
       "            0.2195 , 0.2185 , 0.2152 , 0.2059 , 0.1865 , 0.1813 , 0.1807 ,\n",
       "            0.1794 , 0.1787 , 0.1772 , 0.1744 , 0.1726 , 0.1671 , 0.1643 ,\n",
       "            0.1619 , 0.1614 , 0.1593 , 0.1575 , 0.1561 , 0.1531 , 0.1527 ,\n",
       "            0.1501 , 0.1495 , 0.1466 , 0.1464 , 0.1462 , 0.1455 , 0.141  ,\n",
       "            0.137  , 0.1346 , 0.12054, 0.12036, 0.11816, 0.1152 , 0.11456,\n",
       "            0.11395, 0.1097 , 0.10376, 0.10126, 0.0986 , 0.0962 , 0.09467,\n",
       "            0.0935 , 0.093  , 0.0927 , 0.09174, 0.0898 , 0.08374, 0.07574,\n",
       "            0.07544, 0.0698 , 0.0549 , 0.0384 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.09322034, dtype=float32),\n",
       "    'tpr': array(0.97727275, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.08333334, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.12121212, 0.12878788, 0.14393939,\n",
       "            0.15151516, 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.65909094, 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9985 , 0.9946 , 0.9907 , 0.986  , 0.9844 , 0.984  ,\n",
       "            0.983  , 0.982  , 0.9814 , 0.981  , 0.9785 , 0.9775 , 0.977  ,\n",
       "            0.976  , 0.9756 , 0.9746 , 0.972  , 0.97   , 0.969  , 0.9688 ,\n",
       "            0.9683 , 0.9673 , 0.967  , 0.966  , 0.9644 , 0.964  , 0.9634 ,\n",
       "            0.9614 , 0.961  , 0.959  , 0.9585 , 0.9575 , 0.956  , 0.951  ,\n",
       "            0.9507 , 0.9497 , 0.949  , 0.9473 , 0.947  , 0.946  , 0.945  ,\n",
       "            0.9434 , 0.941  , 0.9385 , 0.936  , 0.934  , 0.9326 , 0.9307 ,\n",
       "            0.923  , 0.922  , 0.921  , 0.9194 , 0.9185 , 0.918  , 0.9165 ,\n",
       "            0.913  , 0.9126 , 0.9116 , 0.911  , 0.9077 , 0.9023 , 0.902  ,\n",
       "            0.901  , 0.8994 , 0.899  , 0.8975 , 0.896  , 0.894  , 0.8926 ,\n",
       "            0.8916 , 0.8813 , 0.8716 , 0.8706 , 0.867  , 0.8604 , 0.8594 ,\n",
       "            0.8564 , 0.8535 , 0.8525 , 0.8457 , 0.8394 , 0.8384 , 0.825  ,\n",
       "            0.8223 , 0.82   , 0.818  , 0.814  , 0.804  , 0.7964 , 0.7944 ,\n",
       "            0.7935 , 0.786  , 0.783  , 0.7812 , 0.763  , 0.7617 , 0.751  ,\n",
       "            0.7485 , 0.7397 , 0.7373 , 0.7285 , 0.707  , 0.706  , 0.6963 ,\n",
       "            0.6904 , 0.677  , 0.6567 , 0.6543 , 0.6494 , 0.629  , 0.602  ,\n",
       "            0.5884 , 0.5874 , 0.577  , 0.567  , 0.5635 , 0.56   , 0.546  ,\n",
       "            0.544  , 0.542  , 0.5215 , 0.52   , 0.513  , 0.5044 , 0.504  ,\n",
       "            0.4822 , 0.4812 , 0.478  , 0.4663 , 0.4531 , 0.4233 , 0.4219 ,\n",
       "            0.4133 , 0.4119 , 0.4094 , 0.4092 , 0.3987 , 0.3865 , 0.3713 ,\n",
       "            0.3657 , 0.3604 , 0.3582 , 0.3557 , 0.3484 , 0.348  , 0.3442 ,\n",
       "            0.34   , 0.3354 , 0.334  , 0.3318 , 0.3203 , 0.318  , 0.3176 ,\n",
       "            0.3022 , 0.302  , 0.2998 , 0.298  , 0.2915 , 0.2913 , 0.2908 ,\n",
       "            0.2822 , 0.281  , 0.275  , 0.2737 , 0.2703 , 0.2607 , 0.2598 ,\n",
       "            0.2576 , 0.2563 , 0.246  , 0.2444 , 0.2367 , 0.2347 , 0.2316 ,\n",
       "            0.2283 , 0.2218 , 0.2189 , 0.2162 , 0.2156 , 0.2109 , 0.2104 ,\n",
       "            0.2084 , 0.207  , 0.1929 , 0.1746 , 0.1744 , 0.1718 , 0.1697 ,\n",
       "            0.1675 , 0.1672 , 0.1661 , 0.1625 , 0.1512 , 0.1503 , 0.1489 ,\n",
       "            0.1475 , 0.1464 , 0.1461 , 0.1445 , 0.1425 , 0.1409 , 0.138  ,\n",
       "            0.1366 , 0.1361 , 0.1351 , 0.1323 , 0.1313 , 0.1309 , 0.127  ,\n",
       "            0.1262 , 0.1261 , 0.111  , 0.11084, 0.10913, 0.1069 , 0.1056 ,\n",
       "            0.1045 , 0.1007 , 0.09467, 0.09283, 0.09106, 0.0904 , 0.0871 ,\n",
       "            0.0866 , 0.08496, 0.083  , 0.0824 , 0.08105, 0.0763 , 0.06805,\n",
       "            0.0678 , 0.06223, 0.0469 , 0.0324 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.08474576, dtype=float32),\n",
       "    'tpr': array(0.9469697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06060606, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.12878788, 0.13636364,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.23484848,\n",
       "            0.24242425, 0.25757575, 0.2651515 , 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.38636363, 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.57575756, 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9985 , 0.9946 , 0.99   , 0.9854 , 0.9844 , 0.9834 ,\n",
       "            0.982  , 0.9814 , 0.981  , 0.9805 , 0.98   , 0.9775 , 0.9766 ,\n",
       "            0.976  , 0.975  , 0.974  , 0.972  , 0.97   , 0.969  , 0.9683 ,\n",
       "            0.968  , 0.967  , 0.9663 , 0.966  , 0.9644 , 0.963  , 0.962  ,\n",
       "            0.9595 , 0.959  , 0.958  , 0.9565 , 0.954  , 0.951  , 0.9507 ,\n",
       "            0.9497 , 0.9487 , 0.947  , 0.946  , 0.945  , 0.9443 , 0.944  ,\n",
       "            0.938  , 0.9355 , 0.933  , 0.9326 , 0.932  , 0.9307 , 0.922  ,\n",
       "            0.9214 , 0.918  , 0.917  , 0.915  , 0.914  , 0.912  , 0.9116 ,\n",
       "            0.9106 , 0.91   , 0.908  , 0.9043 , 0.9004 , 0.8994 , 0.8965 ,\n",
       "            0.8955 , 0.893  , 0.89   , 0.889  , 0.887  , 0.8745 , 0.8687 ,\n",
       "            0.8657 , 0.8643 , 0.8633 , 0.861  , 0.8555 , 0.852  , 0.8496 ,\n",
       "            0.848  , 0.8477 , 0.8413 , 0.8345 , 0.8296 , 0.8174 , 0.814  ,\n",
       "            0.81   , 0.808  , 0.8047 , 0.7944 , 0.7866 , 0.786  , 0.782  ,\n",
       "            0.7783 , 0.775  , 0.7744 , 0.751  , 0.747  , 0.7437 , 0.7334 ,\n",
       "            0.7295 , 0.7207 , 0.7134 , 0.6885 , 0.6875 , 0.6816 , 0.6772 ,\n",
       "            0.6587 , 0.6416 , 0.6245 , 0.611  , 0.579  , 0.568  , 0.5566 ,\n",
       "            0.5435 , 0.541  , 0.539  , 0.5293 , 0.517  , 0.5156 , 0.4993 ,\n",
       "            0.4963 , 0.4927 , 0.4814 , 0.4773 , 0.4636 , 0.4597 , 0.4534 ,\n",
       "            0.4465 , 0.4277 , 0.4028 , 0.3936 , 0.3933 , 0.3916 , 0.3843 ,\n",
       "            0.3804 , 0.3782 , 0.3574 , 0.3516 , 0.3445 , 0.3394 , 0.3389 ,\n",
       "            0.3364 , 0.3213 , 0.3203 , 0.3171 , 0.317  , 0.3125 , 0.3074 ,\n",
       "            0.297  , 0.2937 , 0.2925 , 0.2815 , 0.2798 , 0.2756 , 0.2734 ,\n",
       "            0.2722 , 0.272  , 0.27   , 0.2588 , 0.2554 , 0.254  , 0.2507 ,\n",
       "            0.2474 , 0.2413 , 0.2386 , 0.2382 , 0.2366 , 0.2272 , 0.223  ,\n",
       "            0.2189 , 0.2167 , 0.2158 , 0.2104 , 0.2076 , 0.2043 , 0.2006 ,\n",
       "            0.1954 , 0.1929 , 0.1923 , 0.1913 , 0.1896 , 0.1863 , 0.1699 ,\n",
       "            0.1567 , 0.1561 , 0.1539 , 0.152  , 0.1517 , 0.1503 , 0.1488 ,\n",
       "            0.142  , 0.1364 , 0.1337 , 0.1333 , 0.1312 , 0.1279 , 0.1272 ,\n",
       "            0.1262 , 0.126  , 0.1249 , 0.1229 , 0.12286, 0.12103, 0.11993,\n",
       "            0.11816, 0.1174 , 0.11316, 0.1124 , 0.10876, 0.09656, 0.0964 ,\n",
       "            0.09503, 0.093  , 0.0909 , 0.0901 , 0.0868 , 0.08105, 0.07935,\n",
       "            0.0786 , 0.0771 , 0.0749 , 0.07465, 0.0724 , 0.07227, 0.07007,\n",
       "            0.06854, 0.0642 , 0.05664, 0.05612, 0.05127, 0.03995, 0.02759],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.07627118, dtype=float32),\n",
       "    'tpr': array(0.9621212, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12878788, 0.14393939, 0.15151516, 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.34848484, 0.36363637, 0.37121212, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9985 , 0.995  , 0.9907 , 0.9863 , 0.985  , 0.9844 ,\n",
       "            0.984  , 0.983  , 0.9824 , 0.982  , 0.981  , 0.98   , 0.979  ,\n",
       "            0.9785 , 0.978  , 0.977  , 0.9766 , 0.9756 , 0.974  , 0.9727 ,\n",
       "            0.9717 , 0.9707 , 0.969  , 0.9688 , 0.9683 , 0.9673 , 0.9663 ,\n",
       "            0.966  , 0.9644 , 0.964  , 0.962  , 0.9604 , 0.96   , 0.9595 ,\n",
       "            0.958  , 0.9556 , 0.954  , 0.9536 , 0.9526 , 0.949  , 0.9487 ,\n",
       "            0.947  , 0.9463 , 0.9453 , 0.94   , 0.9375 , 0.937  , 0.936  ,\n",
       "            0.935  , 0.934  , 0.9253 , 0.9243 , 0.9224 , 0.92   , 0.9165 ,\n",
       "            0.916  , 0.9155 , 0.915  , 0.9146 , 0.914  , 0.911  , 0.9106 ,\n",
       "            0.91   , 0.905  , 0.9043 , 0.902  , 0.9014 , 0.8984 , 0.897  ,\n",
       "            0.895  , 0.894  , 0.89   , 0.884  , 0.8784 , 0.872  , 0.8687 ,\n",
       "            0.868  , 0.863  , 0.8623 , 0.861  , 0.856  , 0.8535 , 0.8506 ,\n",
       "            0.8496 , 0.8403 , 0.839  , 0.8345 , 0.8247 , 0.815  , 0.8135 ,\n",
       "            0.8115 , 0.8066 , 0.7964 , 0.7925 , 0.786  , 0.7837 , 0.781  ,\n",
       "            0.7793 , 0.779  , 0.758  , 0.747  , 0.7397 , 0.7393 , 0.735  ,\n",
       "            0.7266 , 0.7183 , 0.6934 , 0.689  , 0.6826 , 0.6543 , 0.644  ,\n",
       "            0.6323 , 0.6313 , 0.6167 , 0.5693 , 0.5654 , 0.5625 , 0.5513 ,\n",
       "            0.5464 , 0.5425 , 0.536  , 0.5215 , 0.503  , 0.502  , 0.5005 ,\n",
       "            0.494  , 0.4907 , 0.4824 , 0.4756 , 0.456  , 0.4517 , 0.4421 ,\n",
       "            0.4375 , 0.4124 , 0.4    , 0.39   , 0.3865 , 0.3801 , 0.3706 ,\n",
       "            0.3647 , 0.343  , 0.338  , 0.3362 , 0.3308 , 0.328  , 0.327  ,\n",
       "            0.3257 , 0.3215 , 0.3096 , 0.3071 , 0.3003 , 0.2993 , 0.2954 ,\n",
       "            0.2761 , 0.2747 , 0.2666 , 0.2632 , 0.2612 , 0.2605 , 0.2588 ,\n",
       "            0.258  , 0.257  , 0.2522 , 0.252  , 0.2388 , 0.2384 , 0.2367 ,\n",
       "            0.2286 , 0.2263 , 0.2256 , 0.2244 , 0.2212 , 0.217  , 0.2145 ,\n",
       "            0.2115 , 0.2047 , 0.1974 , 0.1973 , 0.1962 , 0.1941 , 0.1923 ,\n",
       "            0.1901 , 0.1853 , 0.1766 , 0.1714 , 0.1575 , 0.1573 , 0.1511 ,\n",
       "            0.1493 , 0.146  , 0.1426 , 0.1414 , 0.1401 , 0.1309 , 0.1283 ,\n",
       "            0.1271 , 0.1256 , 0.12366, 0.1232 , 0.12103, 0.1188 , 0.1184 ,\n",
       "            0.1134 , 0.1118 , 0.11145, 0.111  , 0.1086 , 0.108  , 0.1067 ,\n",
       "            0.10614, 0.1054 , 0.1009 , 0.09436, 0.0942 , 0.093  , 0.09204,\n",
       "            0.0888 , 0.088  , 0.08466, 0.07904, 0.0785 , 0.07764, 0.07544,\n",
       "            0.07477, 0.07434, 0.0703 , 0.0683 , 0.06683, 0.0628 , 0.0551 ,\n",
       "            0.0547 , 0.04987, 0.0343 , 0.02333], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.06779661, dtype=float32),\n",
       "    'tpr': array(0.9469697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.13636364, 0.15151516, 0.1590909 , 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.65909094, 0.6666667 ,\n",
       "            0.6818182 , 0.68939394, 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.81060606, 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9985 , 0.9946 , 0.99   , 0.985  , 0.984  , 0.983  ,\n",
       "            0.982  , 0.9814 , 0.981  , 0.9805 , 0.9795 , 0.979  , 0.9775 ,\n",
       "            0.977  , 0.9766 , 0.976  , 0.9756 , 0.974  , 0.9736 , 0.971  ,\n",
       "            0.9707 , 0.9697 , 0.9683 , 0.968  , 0.967  , 0.966  , 0.965  ,\n",
       "            0.9644 , 0.9614 , 0.961  , 0.9595 , 0.9575 , 0.957  , 0.9546 ,\n",
       "            0.953  , 0.952  , 0.9517 , 0.951  , 0.9473 , 0.9463 , 0.946  ,\n",
       "            0.9453 , 0.944  , 0.942  , 0.9414 , 0.9404 , 0.9355 , 0.9336 ,\n",
       "            0.933  , 0.932  , 0.93   , 0.923  , 0.9185 , 0.9126 , 0.912  ,\n",
       "            0.911  , 0.9106 , 0.9087 , 0.908  , 0.9077 , 0.904  , 0.9033 ,\n",
       "            0.9004 , 0.899  , 0.8965 , 0.894  , 0.8926 , 0.8896 , 0.8887 ,\n",
       "            0.883  , 0.877  , 0.8667 , 0.864  , 0.854  , 0.8535 , 0.845  ,\n",
       "            0.844  , 0.842  , 0.84   , 0.8345 , 0.833  , 0.817  , 0.8135 ,\n",
       "            0.803  , 0.7983 , 0.7964 , 0.794  , 0.783  , 0.7812 , 0.7734 ,\n",
       "            0.7695 , 0.7686 , 0.768  , 0.743  , 0.738  , 0.725  , 0.7217 ,\n",
       "            0.715  , 0.7007 , 0.694  , 0.6704 , 0.6675 , 0.6665 , 0.664  ,\n",
       "            0.6357 , 0.63   , 0.6147 , 0.5957 , 0.5913 , 0.5454 , 0.5425 ,\n",
       "            0.538  , 0.5317 , 0.52   , 0.519  , 0.5073 , 0.502  , 0.4824 ,\n",
       "            0.48   , 0.4714 , 0.4668 , 0.463  , 0.452  , 0.4414 , 0.4358 ,\n",
       "            0.422  , 0.4216 , 0.4214 , 0.3914 , 0.373  , 0.3687 , 0.3643 ,\n",
       "            0.3552 , 0.3523 , 0.3494 , 0.3481 , 0.3228 , 0.3215 , 0.3152 ,\n",
       "            0.3147 , 0.3125 , 0.3093 , 0.2932 , 0.2915 , 0.286  , 0.2827 ,\n",
       "            0.2817 , 0.28   , 0.2756 , 0.2717 , 0.2595 , 0.2554 , 0.25   ,\n",
       "            0.2498 , 0.246  , 0.2452 , 0.2444 , 0.2429 , 0.2363 , 0.2346 ,\n",
       "            0.2301 , 0.2244 , 0.2224 , 0.215  , 0.2147 , 0.214  , 0.2125 ,\n",
       "            0.2119 , 0.2013 , 0.1962 , 0.196  , 0.1918 , 0.1897 , 0.1843 ,\n",
       "            0.1813 , 0.1798 , 0.1771 , 0.1757 , 0.1735 , 0.1669 , 0.1664 ,\n",
       "            0.1638 , 0.1633 , 0.1498 , 0.1344 , 0.1339 , 0.1333 , 0.1313 ,\n",
       "            0.129  , 0.1289 , 0.1287 , 0.124  , 0.11597, 0.11163, 0.111  ,\n",
       "            0.1101 , 0.1099 , 0.1097 , 0.1078 , 0.10706, 0.10614, 0.1025 ,\n",
       "            0.10144, 0.1009 , 0.09753, 0.0967 , 0.0964 , 0.0957 , 0.09515,\n",
       "            0.0932 , 0.0904 , 0.0827 , 0.0821 , 0.08136, 0.0786 , 0.0763 ,\n",
       "            0.0761 , 0.07306, 0.0678 , 0.0666 , 0.0644 , 0.0642 , 0.0613 ,\n",
       "            0.0611 , 0.05975, 0.0575 , 0.05655, 0.0547 , 0.05203, 0.04578,\n",
       "            0.0451 , 0.04092, 0.02975, 0.02002], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04237288, dtype=float32),\n",
       "    'tpr': array(0.9469697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.12121212, 0.12878788, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.67424244, 0.6818182 , 0.6818182 ,\n",
       "            0.68939394, 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9985 , 0.9946 , 0.9897 , 0.984  , 0.983  , 0.982  ,\n",
       "            0.9814 , 0.981  , 0.9805 , 0.9795 , 0.979  , 0.9785 , 0.978  ,\n",
       "            0.976  , 0.975  , 0.9746 , 0.974  , 0.973  , 0.972  , 0.9717 ,\n",
       "            0.969  , 0.9688 , 0.9673 , 0.966  , 0.9653 , 0.965  , 0.964  ,\n",
       "            0.9624 , 0.9614 , 0.9595 , 0.9585 , 0.957  , 0.956  , 0.955  ,\n",
       "            0.9546 , 0.952  , 0.9507 , 0.949  , 0.948  , 0.9478 , 0.944  ,\n",
       "            0.9434 , 0.943  , 0.9424 , 0.941  , 0.9395 , 0.9385 , 0.9375 ,\n",
       "            0.936  , 0.9316 , 0.9297 , 0.929  , 0.9277 , 0.927  , 0.919  ,\n",
       "            0.918  , 0.912  , 0.907  , 0.9067 , 0.9062 , 0.9053 , 0.9023 ,\n",
       "            0.902  , 0.8994 , 0.898  , 0.8955 , 0.894  , 0.8906 , 0.889  ,\n",
       "            0.888  , 0.8867 , 0.885  , 0.883  , 0.881  , 0.88   , 0.8765 ,\n",
       "            0.87   , 0.8584 , 0.856  , 0.854  , 0.853  , 0.8467 , 0.8438 ,\n",
       "            0.8345 , 0.834  , 0.8315 , 0.823  , 0.8223 , 0.805  , 0.799  ,\n",
       "            0.795  , 0.7876 , 0.7856 , 0.7847 , 0.7734 , 0.7666 , 0.76   ,\n",
       "            0.7573 , 0.757  , 0.7534 , 0.7485 , 0.7256 , 0.725  , 0.7114 ,\n",
       "            0.705  , 0.698  , 0.683  , 0.6777 , 0.6504 , 0.6494 , 0.6475 ,\n",
       "            0.645  , 0.6206 , 0.6123 , 0.5903 , 0.5728 , 0.565  , 0.5273 ,\n",
       "            0.525  , 0.513  , 0.5034 , 0.503  , 0.5    , 0.489  , 0.4736 ,\n",
       "            0.464  , 0.4578 , 0.451  , 0.4504 , 0.4395 , 0.434  , 0.4163 ,\n",
       "            0.4153 , 0.4028 , 0.4001 , 0.3965 , 0.3735 , 0.3533 , 0.3438 ,\n",
       "            0.3403 , 0.3315 , 0.3289 , 0.3267 , 0.3223 , 0.304  , 0.303  ,\n",
       "            0.3018 , 0.2993 , 0.2957 , 0.2915 , 0.2798 , 0.2747 , 0.2656 ,\n",
       "            0.263  , 0.2622 , 0.2588 , 0.2563 , 0.2556 , 0.239  , 0.2386 ,\n",
       "            0.2363 , 0.2339 , 0.2301 , 0.2277 , 0.2274 , 0.2246 , 0.217  ,\n",
       "            0.2153 , 0.2115 , 0.2075 , 0.2051 , 0.202  , 0.2002 , 0.1991 ,\n",
       "            0.1964 , 0.1927 , 0.1887 , 0.1803 , 0.18   , 0.1758 , 0.1743 ,\n",
       "            0.1715 , 0.1687 , 0.1682 , 0.162  , 0.1608 , 0.1586 , 0.1526 ,\n",
       "            0.1521 , 0.1512 , 0.1464 , 0.1328 , 0.1223 , 0.12177, 0.1207 ,\n",
       "            0.12024, 0.1194 , 0.1192 , 0.11633, 0.1097 , 0.10504, 0.1009 ,\n",
       "            0.10016, 0.0997 , 0.09875, 0.09705, 0.0967 , 0.0955 , 0.0942 ,\n",
       "            0.09283, 0.0922 , 0.09174, 0.0885 , 0.0879 , 0.0873 , 0.0856 ,\n",
       "            0.08527, 0.0818 , 0.0801 , 0.07465, 0.07367, 0.0734 , 0.0707 ,\n",
       "            0.0678 , 0.06757, 0.0651 , 0.0601 , 0.05942, 0.05737, 0.05664,\n",
       "            0.0541 , 0.0538 , 0.0526 , 0.05005, 0.0495 , 0.04672, 0.04587,\n",
       "            0.0397 , 0.03876, 0.03506, 0.02611, 0.0173 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.03389831, dtype=float32),\n",
       "    'tpr': array(0.9318182, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.6818182 , 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.998   , 0.994   , 0.989   , 0.982   , 0.9814  ,\n",
       "            0.98    , 0.9795  , 0.9785  , 0.9775  , 0.977   , 0.9766  ,\n",
       "            0.976   , 0.9746  , 0.974   , 0.973   , 0.9727  , 0.972   ,\n",
       "            0.971   , 0.9707  , 0.97    , 0.9688  , 0.967   , 0.9663  ,\n",
       "            0.9653  , 0.9644  , 0.963   , 0.9624  , 0.9614  , 0.959   ,\n",
       "            0.958   , 0.9565  , 0.9556  , 0.955   , 0.951   , 0.9507  ,\n",
       "            0.95    , 0.948   , 0.9473  , 0.945   , 0.9443  , 0.941   ,\n",
       "            0.9395  , 0.9385  , 0.938   , 0.9355  , 0.935   , 0.933   ,\n",
       "            0.9307  , 0.9287  , 0.926   , 0.925   , 0.924   , 0.922   ,\n",
       "            0.921   , 0.9146  , 0.913   , 0.906   , 0.902   , 0.9     ,\n",
       "            0.899   , 0.8975  , 0.896   , 0.8936  , 0.89    , 0.889   ,\n",
       "            0.887   , 0.8857  , 0.8813  , 0.8804  , 0.8794  , 0.8755  ,\n",
       "            0.8726  , 0.872   , 0.8706  , 0.866   , 0.8594  , 0.847   ,\n",
       "            0.8457  , 0.8447  , 0.841   , 0.8354  , 0.835   , 0.8325  ,\n",
       "            0.825   , 0.8213  , 0.8184  , 0.815   , 0.8135  , 0.811   ,\n",
       "            0.786   , 0.782   , 0.7812  , 0.771   , 0.7695  , 0.769   ,\n",
       "            0.7583  , 0.7505  , 0.7446  , 0.7437  , 0.7383  , 0.7363  ,\n",
       "            0.7324  , 0.711   , 0.7056  , 0.6924  , 0.687   , 0.673   ,\n",
       "            0.6562  , 0.653   , 0.6265  , 0.6255  , 0.624   , 0.6157  ,\n",
       "            0.5996  , 0.593   , 0.569   , 0.547   , 0.527   , 0.504   ,\n",
       "            0.501   , 0.4844  , 0.4814  , 0.4805  , 0.4788  , 0.4692  ,\n",
       "            0.4407  , 0.434   , 0.4321  , 0.4287  , 0.425   , 0.4111  ,\n",
       "            0.4065  , 0.3962  , 0.3838  , 0.381   , 0.374   , 0.3706  ,\n",
       "            0.3518  , 0.3345  , 0.323   , 0.3105  , 0.3083  , 0.3035  ,\n",
       "            0.3005  , 0.2954  , 0.2874  , 0.2856  , 0.2852  , 0.2825  ,\n",
       "            0.2742  , 0.2734  , 0.2664  , 0.258   , 0.2487  , 0.2422  ,\n",
       "            0.2375  , 0.2328  , 0.2299  , 0.229   , 0.2211  , 0.2203  ,\n",
       "            0.2144  , 0.213   , 0.2123  , 0.2073  , 0.2029  , 0.1987  ,\n",
       "            0.1984  , 0.1956  , 0.1896  , 0.1887  , 0.1874  , 0.187   ,\n",
       "            0.1829  , 0.1761  , 0.1759  , 0.1687  , 0.1661  , 0.1597  ,\n",
       "            0.1592  , 0.1566  , 0.1552  , 0.1545  , 0.1537  , 0.1498  ,\n",
       "            0.145   , 0.1407  , 0.1354  , 0.1346  , 0.1343  , 0.12463 ,\n",
       "            0.11456 , 0.1101  , 0.1099  , 0.10913 , 0.10596 , 0.1041  ,\n",
       "            0.10126 , 0.09436 , 0.0935  , 0.09106 , 0.0906  , 0.0904  ,\n",
       "            0.0876  , 0.0873  , 0.0859  , 0.08435 , 0.083   , 0.0806  ,\n",
       "            0.0804  , 0.0799  , 0.0792  , 0.0788  , 0.07697 , 0.07666 ,\n",
       "            0.0716  , 0.06995 , 0.06635 , 0.0655  , 0.06537 , 0.0628  ,\n",
       "            0.0591  , 0.05865 , 0.0575  , 0.05203 , 0.05194 , 0.05014 ,\n",
       "            0.0483  , 0.04602 , 0.04596 , 0.04535 , 0.04282 , 0.0424  ,\n",
       "            0.04083 , 0.0395  , 0.03366 , 0.03247 , 0.02937 , 0.02284 ,\n",
       "            0.015015], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.02542373, dtype=float32),\n",
       "    'tpr': array(0.9166667, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03787879,\n",
       "            0.0530303 , 0.06818182, 0.07575758, 0.08333334, 0.09848485,\n",
       "            0.11363637, 0.12121212, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.998   , 0.993   , 0.988   , 0.9795  , 0.977   ,\n",
       "            0.976   , 0.975   , 0.974   , 0.9736  , 0.97    , 0.9697  ,\n",
       "            0.9688  , 0.9683  , 0.968   , 0.967   , 0.966   , 0.965   ,\n",
       "            0.961   , 0.96    , 0.9595  , 0.9575  , 0.957   , 0.9565  ,\n",
       "            0.9546  , 0.9536  , 0.951   , 0.9507  , 0.9497  , 0.9463  ,\n",
       "            0.946   , 0.943   , 0.9424  , 0.941   , 0.938   , 0.937   ,\n",
       "            0.935   , 0.933   , 0.932   , 0.9316  , 0.9272  , 0.927   ,\n",
       "            0.9253  , 0.922   , 0.919   , 0.9175  , 0.916   , 0.9146  ,\n",
       "            0.914   , 0.9126  , 0.9077  , 0.906   , 0.9014  , 0.891   ,\n",
       "            0.8906  , 0.8896  , 0.889   , 0.8853  , 0.883   , 0.882   ,\n",
       "            0.877   , 0.8726  , 0.8696  , 0.867   , 0.8647  , 0.8613  ,\n",
       "            0.8604  , 0.8584  , 0.8564  , 0.8535  , 0.853   , 0.8506  ,\n",
       "            0.846   , 0.8306  , 0.8296  , 0.8267  , 0.821   , 0.82    ,\n",
       "            0.8164  , 0.8105  , 0.8076  , 0.8013  , 0.7964  , 0.7944  ,\n",
       "            0.7935  , 0.791   , 0.7627  , 0.7617  , 0.751   , 0.75    ,\n",
       "            0.748   , 0.746   , 0.7383  , 0.7207  , 0.7188  , 0.717   ,\n",
       "            0.7134  , 0.7046  , 0.704   , 0.6875  , 0.6694  , 0.6685  ,\n",
       "            0.655   , 0.6406  , 0.622   , 0.6216  , 0.591   , 0.585   ,\n",
       "            0.579   , 0.573   , 0.562   , 0.5366  , 0.505   , 0.4824  ,\n",
       "            0.4753  , 0.47    , 0.4536  , 0.4492  , 0.446   , 0.4426  ,\n",
       "            0.44    , 0.413   , 0.4016  , 0.3953  , 0.3943  , 0.388   ,\n",
       "            0.3833  , 0.3713  , 0.3674  , 0.3599  , 0.3447  , 0.3406  ,\n",
       "            0.3354  , 0.3264  , 0.311   , 0.297   , 0.2883  , 0.2712  ,\n",
       "            0.2708  , 0.2693  , 0.267   , 0.2646  , 0.263   , 0.2542  ,\n",
       "            0.253   , 0.2505  , 0.2498  , 0.2496  , 0.2391  , 0.2295  ,\n",
       "            0.2198  , 0.2142  , 0.206   , 0.2034  , 0.2007  , 0.2001  ,\n",
       "            0.1995  , 0.1965  , 0.1962  , 0.1865  , 0.1837  , 0.1831  ,\n",
       "            0.1794  , 0.1746  , 0.1738  , 0.1735  , 0.172   , 0.1707  ,\n",
       "            0.1681  , 0.1625  , 0.1558  , 0.1509  , 0.1501  , 0.146   ,\n",
       "            0.1444  , 0.139   , 0.1383  , 0.1373  , 0.1333  , 0.133   ,\n",
       "            0.1277  , 0.1274  , 0.1257  , 0.1152  , 0.1142  , 0.11163 ,\n",
       "            0.1025  , 0.1     , 0.0979  , 0.0964  , 0.09515 , 0.0922  ,\n",
       "            0.0895  , 0.0873  , 0.08527 , 0.0808  , 0.0804  , 0.07935 ,\n",
       "            0.0788  , 0.0778  , 0.0761  , 0.076   , 0.07587 , 0.0745  ,\n",
       "            0.07385 , 0.0721  , 0.0716  , 0.0703  , 0.0682  , 0.06793 ,\n",
       "            0.0678  , 0.0631  , 0.06305 , 0.06256 , 0.05655 , 0.05612 ,\n",
       "            0.05582 , 0.0553  , 0.0533  , 0.04895 , 0.0483  , 0.04813 ,\n",
       "            0.0436  , 0.04272 , 0.04193 , 0.03955 , 0.0378  , 0.03775 ,\n",
       "            0.03726 , 0.03442 , 0.0343  , 0.03424 , 0.03247 , 0.02676 ,\n",
       "            0.02533 , 0.02298 , 0.01984 , 0.012825], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.02542373, dtype=float32),\n",
       "    'tpr': array(0.90909094, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.11016949, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.0530303 , 0.06060606, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.12121212, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.998  , 0.993  , 0.9873 , 0.9795 , 0.979  , 0.977  ,\n",
       "            0.976  , 0.975  , 0.974  , 0.9736 , 0.971  , 0.969  , 0.9688 ,\n",
       "            0.9683 , 0.968  , 0.967  , 0.966  , 0.965  , 0.9644 , 0.959  ,\n",
       "            0.958  , 0.9575 , 0.9565 , 0.955  , 0.954  , 0.9536 , 0.953  ,\n",
       "            0.949  , 0.948  , 0.9478 , 0.947  , 0.9443 , 0.944  , 0.943  ,\n",
       "            0.9404 , 0.9395 , 0.9375 , 0.9336 , 0.931  , 0.9297 , 0.929  ,\n",
       "            0.9287 , 0.9263 , 0.9243 , 0.9214 , 0.9185 , 0.9165 , 0.9146 ,\n",
       "            0.9106 , 0.9097 , 0.902  , 0.9014 , 0.8965 , 0.8877 , 0.8867 ,\n",
       "            0.8853 , 0.8843 , 0.884  , 0.88   , 0.879  , 0.875  , 0.87   ,\n",
       "            0.865  , 0.861  , 0.858  , 0.857  , 0.8564 , 0.856  , 0.8525 ,\n",
       "            0.852  , 0.8477 , 0.847  , 0.845  , 0.8413 , 0.834  , 0.825  ,\n",
       "            0.8213 , 0.816  , 0.8154 , 0.8115 , 0.805  , 0.8    , 0.795  ,\n",
       "            0.794  , 0.7915 , 0.784  , 0.7837 , 0.7734 , 0.76   , 0.7544 ,\n",
       "            0.7446 , 0.744  , 0.7427 , 0.7363 , 0.7324 , 0.709  , 0.7056 ,\n",
       "            0.705  , 0.702  , 0.689  , 0.6777 , 0.673  , 0.652  , 0.6484 ,\n",
       "            0.6377 , 0.619  , 0.617  , 0.587  , 0.576  , 0.5723 , 0.565  ,\n",
       "            0.5576 , 0.544  , 0.5054 , 0.484  , 0.4812 , 0.4631 , 0.4492 ,\n",
       "            0.4446 , 0.4265 , 0.4185 , 0.417  , 0.4133 , 0.392  , 0.3882 ,\n",
       "            0.3865 , 0.3745 , 0.3694 , 0.3633 , 0.3618 , 0.3467 , 0.3386 ,\n",
       "            0.3364 , 0.3296 , 0.3154 , 0.3025 , 0.288  , 0.271  , 0.2666 ,\n",
       "            0.2656 , 0.2554 , 0.253  , 0.2437 , 0.2433 , 0.243  , 0.2382 ,\n",
       "            0.2356 , 0.235  , 0.2314 , 0.223  , 0.2197 , 0.2109 , 0.2065 ,\n",
       "            0.197  , 0.1967 , 0.1959 , 0.1936 , 0.1915 , 0.1871 , 0.1798 ,\n",
       "            0.1791 , 0.179  , 0.178  , 0.1703 , 0.1659 , 0.1609 , 0.1606 ,\n",
       "            0.1598 , 0.1594 , 0.1562 , 0.1544 , 0.1539 , 0.1493 , 0.1433 ,\n",
       "            0.1376 , 0.1373 , 0.1365 , 0.134  , 0.1324 , 0.1318 , 0.1309 ,\n",
       "            0.1298 , 0.1262 , 0.1184 , 0.11475, 0.1138 , 0.1122 , 0.1101 ,\n",
       "            0.10504, 0.1009 , 0.0898 , 0.0896 , 0.0879 , 0.0871 , 0.0866 ,\n",
       "            0.0851 , 0.083  , 0.0827 , 0.0732 , 0.07263, 0.0708 , 0.0707 ,\n",
       "            0.06964, 0.06805, 0.0678 , 0.06696, 0.066  , 0.0651 , 0.06396,\n",
       "            0.0635 , 0.06335, 0.0612 , 0.05878, 0.05865, 0.05603, 0.05594,\n",
       "            0.0533 , 0.05203, 0.05136, 0.051  , 0.05023, 0.0495 , 0.04443,\n",
       "            0.0441 , 0.04352, 0.0401 , 0.03854, 0.0379 , 0.03607, 0.0359 ,\n",
       "            0.03366, 0.03073, 0.03056, 0.02965, 0.02821, 0.0237 , 0.0223 ,\n",
       "            0.02022, 0.01653, 0.01057], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.01694915, dtype=float32),\n",
       "    'tpr': array(0.90909094, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.11016949, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.34848484, 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9976  , 0.9917  , 0.9844  , 0.975   , 0.9746  ,\n",
       "            0.973   , 0.9727  , 0.972   , 0.971   , 0.97    , 0.9688  ,\n",
       "            0.9683  , 0.967   , 0.966   , 0.964   , 0.9624  , 0.962   ,\n",
       "            0.9614  , 0.96    , 0.958   , 0.956   , 0.9556  , 0.955   ,\n",
       "            0.954   , 0.952   , 0.9507  , 0.9487  , 0.9453  , 0.945   ,\n",
       "            0.944   , 0.943   , 0.94    , 0.935   , 0.9336  , 0.933   ,\n",
       "            0.93    , 0.929   , 0.927   , 0.9253  , 0.925   , 0.916   ,\n",
       "            0.9146  , 0.9136  , 0.912   , 0.9067  , 0.904   , 0.9033  ,\n",
       "            0.903   , 0.901   , 0.897   , 0.895   , 0.892   , 0.8887  ,\n",
       "            0.8755  , 0.8745  , 0.8716  , 0.87    , 0.8696  , 0.865   ,\n",
       "            0.8613  , 0.857   , 0.856   , 0.855   , 0.847   , 0.846   ,\n",
       "            0.8447  , 0.8403  , 0.8384  , 0.838   , 0.835   , 0.834   ,\n",
       "            0.8315  , 0.826   , 0.8237  , 0.8086  , 0.8037  , 0.801   ,\n",
       "            0.799   , 0.792   , 0.7866  , 0.7837  , 0.7827  , 0.779   ,\n",
       "            0.7686  , 0.7646  , 0.761   , 0.7544  , 0.7256  , 0.7227  ,\n",
       "            0.716   , 0.7134  , 0.7114  , 0.711   , 0.703   , 0.6846  ,\n",
       "            0.6816  , 0.6797  , 0.676   , 0.6636  , 0.6523  , 0.649   ,\n",
       "            0.622   , 0.611   , 0.604   , 0.5967  , 0.5776  , 0.577   ,\n",
       "            0.5464  , 0.542   , 0.5327  , 0.5317  , 0.518   , 0.5166  ,\n",
       "            0.4717  , 0.4492  , 0.4321  , 0.4275  , 0.4116  , 0.402   ,\n",
       "            0.396   , 0.3877  , 0.382   , 0.379   , 0.3613  , 0.345   ,\n",
       "            0.342   , 0.3408  , 0.3362  , 0.3245  , 0.32    , 0.3137  ,\n",
       "            0.31    , 0.2969  , 0.2952  , 0.285   , 0.2654  , 0.2637  ,\n",
       "            0.2433  , 0.243   , 0.2355  , 0.234   , 0.2318  , 0.2211  ,\n",
       "            0.2167  , 0.2163  , 0.2129  , 0.2128  , 0.21    , 0.1985  ,\n",
       "            0.1984  , 0.1896  , 0.186   , 0.1848  , 0.1727  , 0.1704  ,\n",
       "            0.1676  , 0.1659  , 0.1644  , 0.1636  , 0.1606  , 0.1558  ,\n",
       "            0.1543  , 0.1537  , 0.1495  , 0.1451  , 0.1448  , 0.1447  ,\n",
       "            0.1438  , 0.1398  , 0.1349  , 0.134   , 0.1323  , 0.1321  ,\n",
       "            0.1284  , 0.1188  , 0.11694 , 0.1166  , 0.115   , 0.1144  ,\n",
       "            0.11316 , 0.1118  , 0.11145 , 0.10376 , 0.09845 , 0.096   ,\n",
       "            0.0937  , 0.0906  , 0.0831  , 0.0788  , 0.07794 , 0.07654 ,\n",
       "            0.07367 , 0.07355 , 0.0716  , 0.0702  , 0.06696 , 0.0635  ,\n",
       "            0.06177 , 0.0612  , 0.0603  , 0.05942 , 0.0576  , 0.05728 ,\n",
       "            0.05685 , 0.0548  , 0.0546  , 0.0542  , 0.05194 , 0.04977 ,\n",
       "            0.04968 , 0.04468 , 0.04434 , 0.0441  , 0.04346 , 0.04312 ,\n",
       "            0.04178 , 0.04114 , 0.0371  , 0.03705 , 0.03574 , 0.03348 ,\n",
       "            0.03204 , 0.03192 , 0.03137 , 0.02982 , 0.02971 , 0.0278  ,\n",
       "            0.02461 , 0.02428 , 0.02289 , 0.01901 , 0.01744 , 0.01578 ,\n",
       "            0.01343 , 0.008446], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.01694915, dtype=float32),\n",
       "    'tpr': array(0.8712121, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05932203, 0.05932203,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.07575758,\n",
       "            0.09090909, 0.10606061, 0.12121212, 0.12878788, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.17424242, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9976  , 0.991   , 0.983   , 0.972   , 0.971   ,\n",
       "            0.9697  , 0.9688  , 0.9683  , 0.967   , 0.965   , 0.9604  ,\n",
       "            0.96    , 0.9575  , 0.957   , 0.955   , 0.954   , 0.953   ,\n",
       "            0.9473  , 0.9463  , 0.9453  , 0.944   , 0.943   , 0.9404  ,\n",
       "            0.938   , 0.9375  , 0.937   , 0.935   , 0.9326  , 0.931   ,\n",
       "            0.9263  , 0.9253  , 0.9224  , 0.9214  , 0.9185  , 0.918   ,\n",
       "            0.9175  , 0.914   , 0.913   , 0.9106  , 0.9067  , 0.9062  ,\n",
       "            0.903   , 0.902   , 0.899   , 0.894   , 0.892   , 0.8906  ,\n",
       "            0.8896  , 0.889   , 0.8877  , 0.886   , 0.878   , 0.8716  ,\n",
       "            0.87    , 0.858   , 0.857   , 0.853   , 0.8496  , 0.8486  ,\n",
       "            0.8457  , 0.84    , 0.833   , 0.825   , 0.8247  , 0.8193  ,\n",
       "            0.8164  , 0.8145  , 0.8096  , 0.8086  , 0.8076  , 0.8057  ,\n",
       "            0.8047  , 0.804   , 0.7964  , 0.784   , 0.7837  , 0.7754  ,\n",
       "            0.7725  , 0.769   , 0.7627  , 0.751   , 0.7505  , 0.7495  ,\n",
       "            0.741   , 0.7407  , 0.733   , 0.7285  , 0.716   , 0.695   ,\n",
       "            0.694   , 0.691   , 0.6855  , 0.6836  , 0.6777  , 0.6665  ,\n",
       "            0.651   , 0.6455  , 0.642   , 0.6406  , 0.621   , 0.6167  ,\n",
       "            0.597   , 0.5747  , 0.572   , 0.569   , 0.558   , 0.54    ,\n",
       "            0.537   , 0.508   , 0.4978  , 0.49    , 0.4846  , 0.4817  ,\n",
       "            0.478   , 0.4204  , 0.4006  , 0.3943  , 0.3835  , 0.381   ,\n",
       "            0.369   , 0.358   , 0.3496  , 0.3337  , 0.3323  , 0.3289  ,\n",
       "            0.3132  , 0.3042  , 0.302   , 0.2961  , 0.2869  , 0.286   ,\n",
       "            0.2842  , 0.281   , 0.2615  , 0.2583  , 0.2455  , 0.2383  ,\n",
       "            0.2347  , 0.2158  , 0.2142  , 0.2104  , 0.21    , 0.204   ,\n",
       "            0.1956  , 0.1935  , 0.189   , 0.1857  , 0.1799  , 0.1752  ,\n",
       "            0.1707  , 0.1671  , 0.1646  , 0.1626  , 0.1604  , 0.1549  ,\n",
       "            0.1489  , 0.1442  , 0.1437  , 0.1411  , 0.1392  , 0.1387  ,\n",
       "            0.1378  , 0.1359  , 0.131   , 0.1302  , 0.1292  , 0.1285  ,\n",
       "            0.1279  , 0.12115 , 0.1196  , 0.1172  , 0.115   , 0.1095  ,\n",
       "            0.1063  , 0.10596 , 0.1025  , 0.0967  , 0.096   , 0.0955  ,\n",
       "            0.09283 , 0.0903  , 0.0899  , 0.0888  , 0.0859  , 0.07947 ,\n",
       "            0.076   , 0.0732  , 0.0716  , 0.0673  , 0.0672  , 0.0655  ,\n",
       "            0.06464 , 0.06384 , 0.05997 , 0.0577  , 0.05698 , 0.0533  ,\n",
       "            0.05145 , 0.05127 , 0.0509  , 0.0505  , 0.0495  , 0.04895 ,\n",
       "            0.04813 , 0.0463  , 0.04486 , 0.04477 , 0.04395 , 0.04376 ,\n",
       "            0.04224 , 0.04068 , 0.04062 , 0.03622 , 0.03574 , 0.0356  ,\n",
       "            0.03528 , 0.03403 , 0.03348 , 0.0329  , 0.0323  , 0.03004 ,\n",
       "            0.02998 , 0.02806 , 0.02686 , 0.02567 , 0.02556 , 0.0247  ,\n",
       "            0.02347 , 0.02333 , 0.02208 , 0.01927 , 0.01909 , 0.0188  ,\n",
       "            0.01724 , 0.01473 , 0.012924, 0.01164 , 0.01082 , 0.006668],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.01694915, dtype=float32),\n",
       "    'tpr': array(0.8636364, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05932203, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.17424242, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.997   , 0.9893  , 0.9795  , 0.968   , 0.9673  ,\n",
       "            0.966   , 0.965   , 0.9634  , 0.9614  , 0.9604  , 0.9595  ,\n",
       "            0.959   , 0.957   , 0.955   , 0.9507  , 0.95    , 0.9497  ,\n",
       "            0.949   , 0.9473  , 0.9463  , 0.9453  , 0.945   , 0.943   ,\n",
       "            0.9414  , 0.9404  , 0.935   , 0.9346  , 0.9326  , 0.9307  ,\n",
       "            0.9287  , 0.9263  , 0.921   , 0.9165  , 0.916   , 0.913   ,\n",
       "            0.9126  , 0.912   , 0.9116  , 0.91    , 0.9097  , 0.9062  ,\n",
       "            0.905   , 0.8906  , 0.8896  , 0.889   , 0.8887  , 0.887   ,\n",
       "            0.8857  , 0.879   , 0.878   , 0.8755  , 0.8726  , 0.872   ,\n",
       "            0.871   , 0.869   , 0.868   , 0.8545  , 0.85    , 0.8457  ,\n",
       "            0.8384  , 0.836   , 0.829   , 0.826   , 0.8203  , 0.8154  ,\n",
       "            0.813   , 0.811   , 0.8057  , 0.805   , 0.804   , 0.801   ,\n",
       "            0.8003  , 0.8     , 0.7944  , 0.792   , 0.778   , 0.777   ,\n",
       "            0.7495  , 0.7476  , 0.746   , 0.7446  , 0.744   , 0.742   ,\n",
       "            0.7334  , 0.73    , 0.722   , 0.7075  , 0.7036  , 0.6826  ,\n",
       "            0.6616  , 0.6587  , 0.658   , 0.6562  , 0.6543  , 0.6484  ,\n",
       "            0.6406  , 0.632   , 0.631   , 0.6147  , 0.6104  , 0.5977  ,\n",
       "            0.5635  , 0.557   , 0.553   , 0.523   , 0.5225  , 0.507   ,\n",
       "            0.5005  , 0.4846  , 0.4736  , 0.4692  , 0.4636  , 0.4539  ,\n",
       "            0.444   , 0.3872  , 0.3765  , 0.3655  , 0.3525  , 0.3467  ,\n",
       "            0.3335  , 0.323   , 0.3208  , 0.318   , 0.306   , 0.2883  ,\n",
       "            0.286   , 0.2734  , 0.2722  , 0.2642  , 0.259   , 0.2568  ,\n",
       "            0.2566  , 0.2374  , 0.2366  , 0.2314  , 0.2109  , 0.2094  ,\n",
       "            0.2042  , 0.1948  , 0.1917  , 0.191   , 0.1835  , 0.1803  ,\n",
       "            0.1749  , 0.1741  , 0.1681  , 0.1666  , 0.1615  , 0.1538  ,\n",
       "            0.1515  , 0.1492  , 0.1481  , 0.1472  , 0.1365  , 0.135   ,\n",
       "            0.1305  , 0.1274  , 0.12366 , 0.1217  , 0.12146 , 0.1188  ,\n",
       "            0.1178  , 0.11536 , 0.11395 , 0.1134  , 0.112   , 0.1078  ,\n",
       "            0.1054  , 0.10175 , 0.10156 , 0.0997  , 0.0993  , 0.09705 ,\n",
       "            0.0962  , 0.0945  , 0.09283 , 0.0891  , 0.0877  , 0.0876  ,\n",
       "            0.08386 , 0.0836  , 0.08154 , 0.08136 , 0.0772  , 0.0724  ,\n",
       "            0.06964 , 0.0694  , 0.06757 , 0.06097 , 0.06085 , 0.05856 ,\n",
       "            0.05707 , 0.05582 , 0.0537  , 0.05225 , 0.05005 , 0.04968 ,\n",
       "            0.0478  , 0.04715 , 0.04578 , 0.04526 , 0.04153 , 0.04132 ,\n",
       "            0.04083 , 0.03964 , 0.03918 , 0.03906 , 0.0386  , 0.03854 ,\n",
       "            0.03616 , 0.0359  , 0.0323  , 0.03204 , 0.03186 , 0.0313  ,\n",
       "            0.03102 , 0.03044 , 0.02992 , 0.02971 , 0.02855 , 0.0277  ,\n",
       "            0.0263  , 0.02626 , 0.02457 , 0.02328 , 0.02225 , 0.0222  ,\n",
       "            0.02129 , 0.02017 , 0.0201  , 0.01909 , 0.01666 , 0.01634 ,\n",
       "            0.01622 , 0.01257 , 0.01248 , 0.01107 , 0.00993 , 0.00822 ,\n",
       "            0.004963], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00847458, dtype=float32),\n",
       "    'tpr': array(0.84090906, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.0530303 , 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.16666667,\n",
       "            0.17424242, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9966  , 0.989   , 0.978   , 0.9663  , 0.964   ,\n",
       "            0.963   , 0.9614  , 0.959   , 0.957   , 0.9565  , 0.956   ,\n",
       "            0.9546  , 0.951   , 0.949   , 0.9478  , 0.947   , 0.945   ,\n",
       "            0.943   , 0.9424  , 0.9414  , 0.9395  , 0.9385  , 0.9355  ,\n",
       "            0.9336  , 0.933   , 0.9307  , 0.9277  , 0.925   , 0.922   ,\n",
       "            0.92    , 0.914   , 0.9077  , 0.9053  , 0.905   , 0.9043  ,\n",
       "            0.9033  , 0.9023  , 0.901   , 0.899   , 0.898   , 0.8823  ,\n",
       "            0.8813  , 0.881   , 0.877   , 0.8745  , 0.874   , 0.871   ,\n",
       "            0.8687  , 0.8643  , 0.864   , 0.857   , 0.856   , 0.851   ,\n",
       "            0.841   , 0.833   , 0.83    , 0.8257  , 0.823   , 0.8193  ,\n",
       "            0.8164  , 0.812   , 0.8105  , 0.7954  , 0.793   , 0.7856  ,\n",
       "            0.7837  , 0.7827  , 0.78    , 0.7793  , 0.7783  , 0.778   ,\n",
       "            0.7676  , 0.7646  , 0.7593  , 0.7583  , 0.7354  , 0.7344  ,\n",
       "            0.7183  , 0.7163  , 0.7153  , 0.711   , 0.707   , 0.706   ,\n",
       "            0.702   , 0.693   , 0.6875  , 0.686   , 0.6455  , 0.6436  ,\n",
       "            0.6396  , 0.6377  , 0.637   , 0.6357  , 0.626   , 0.622   ,\n",
       "            0.6123  , 0.6006  , 0.597   , 0.5967  , 0.5757  , 0.562   ,\n",
       "            0.525   , 0.5225  , 0.5024  , 0.4993  , 0.4863  , 0.484   ,\n",
       "            0.4797  , 0.4534  , 0.448   , 0.4326  , 0.4312  , 0.4287  ,\n",
       "            0.4153  , 0.3486  , 0.3474  , 0.3345  , 0.3276  , 0.325   ,\n",
       "            0.2993  , 0.286   , 0.2837  , 0.2832  , 0.2822  , 0.256   ,\n",
       "            0.2505  , 0.2451  , 0.2415  , 0.241   , 0.2391  , 0.2257  ,\n",
       "            0.2233  , 0.2213  , 0.2145  , 0.1976  , 0.1827  , 0.1764  ,\n",
       "            0.1763  , 0.1761  , 0.173   , 0.1699  , 0.1669  , 0.1552  ,\n",
       "            0.1521  , 0.1504  , 0.1476  , 0.1399  , 0.1359  , 0.1329  ,\n",
       "            0.1327  , 0.1278  , 0.124   , 0.12024 , 0.1194  , 0.11676 ,\n",
       "            0.1138  , 0.1105  , 0.1093  , 0.1086  , 0.1082  , 0.1021  ,\n",
       "            0.10126 , 0.1011  , 0.1007  , 0.0991  , 0.09875 , 0.0962  ,\n",
       "            0.0914  , 0.0885  , 0.0883  , 0.08466 , 0.08374 , 0.0808  ,\n",
       "            0.0801  , 0.0799  , 0.0788  , 0.07825 , 0.0778  , 0.07574 ,\n",
       "            0.074   , 0.07367 , 0.07355 , 0.07104 , 0.0693  , 0.06647 ,\n",
       "            0.06256 , 0.06085 , 0.059   , 0.0542  , 0.0533  , 0.05252 ,\n",
       "            0.0504  , 0.04932 , 0.04752 , 0.04663 , 0.04453 , 0.04428 ,\n",
       "            0.044   , 0.04047 , 0.03876 , 0.03796 , 0.03662 , 0.03372 ,\n",
       "            0.03366 , 0.0334  , 0.0332  , 0.03198 , 0.03125 , 0.03096 ,\n",
       "            0.03038 , 0.03021 , 0.02876 , 0.0286  , 0.02646 , 0.02596 ,\n",
       "            0.02571 , 0.02504 , 0.02489 , 0.02466 , 0.0232  , 0.02277 ,\n",
       "            0.02258 , 0.02158 , 0.02153 , 0.02092 , 0.01979 , 0.01912 ,\n",
       "            0.01823 , 0.01813 , 0.01724 , 0.01718 , 0.01543 , 0.01333 ,\n",
       "            0.013275, 0.01263 , 0.009895, 0.00881 , 0.008415, 0.00749 ,\n",
       "            0.006145, 0.003565], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00847458, dtype=float32),\n",
       "    'tpr': array(0.8181818, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05932203, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.10606061, 0.12121212, 0.12878788,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.17424242, 0.18939394,\n",
       "            0.1969697 , 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9956  , 0.986   , 0.972   , 0.9595  , 0.957   ,\n",
       "            0.954   , 0.952   , 0.951   , 0.95    , 0.9497  , 0.948   ,\n",
       "            0.9453  , 0.944   , 0.936   , 0.934   , 0.9336  , 0.933   ,\n",
       "            0.9307  , 0.927   , 0.9263  , 0.925   , 0.921   , 0.918   ,\n",
       "            0.917   , 0.9136  , 0.905   , 0.9004  , 0.9     , 0.896   ,\n",
       "            0.895   , 0.893   , 0.8887  , 0.8823  , 0.8813  , 0.881   ,\n",
       "            0.8765  , 0.867   , 0.8633  , 0.858   , 0.8545  , 0.8535  ,\n",
       "            0.853   , 0.8525  , 0.8438  , 0.842   , 0.841   , 0.836   ,\n",
       "            0.835   , 0.8335  , 0.8276  , 0.8257  , 0.8154  , 0.815   ,\n",
       "            0.7944  , 0.787   , 0.784   , 0.7764  , 0.776   , 0.775   ,\n",
       "            0.77    , 0.759   , 0.7583  , 0.755   , 0.7544  , 0.7515  ,\n",
       "            0.742   , 0.7383  , 0.7373  , 0.727   , 0.7114  , 0.691   ,\n",
       "            0.688   , 0.6875  , 0.684   , 0.6797  , 0.678   , 0.661   ,\n",
       "            0.658   , 0.656   , 0.653   , 0.631   , 0.6226  , 0.592   ,\n",
       "            0.5884  , 0.583   , 0.582   , 0.58    , 0.5786  , 0.577   ,\n",
       "            0.573   , 0.567   , 0.566   , 0.561   , 0.538   , 0.535   ,\n",
       "            0.5254  , 0.4846  , 0.4832  , 0.444   , 0.429   , 0.4165  ,\n",
       "            0.4153  , 0.4087  , 0.4048  , 0.3958  , 0.3857  , 0.384   ,\n",
       "            0.3582  , 0.3076  , 0.294   , 0.2842  , 0.2793  , 0.2646  ,\n",
       "            0.2502  , 0.2458  , 0.244   , 0.2362  , 0.2318  , 0.222   ,\n",
       "            0.209   , 0.1982  , 0.1935  , 0.1918  , 0.1891  , 0.1882  ,\n",
       "            0.183   , 0.1746  , 0.1625  , 0.1556  , 0.1533  , 0.1509  ,\n",
       "            0.1498  , 0.1428  , 0.1412  , 0.1393  , 0.1317  , 0.1311  ,\n",
       "            0.1293  , 0.1243  , 0.1217  , 0.1134  , 0.111   , 0.10724 ,\n",
       "            0.10486 , 0.0986  , 0.09705 , 0.094   , 0.093   , 0.09106 ,\n",
       "            0.0869  , 0.0845  , 0.0827  , 0.08105 , 0.08093 , 0.07965 ,\n",
       "            0.07904 , 0.0771  , 0.07587 , 0.074   , 0.07355 , 0.0715  ,\n",
       "            0.0694  , 0.06757 , 0.06647 , 0.0661  , 0.06244 , 0.06223 ,\n",
       "            0.0619  , 0.06165 , 0.06076 , 0.05865 , 0.05814 , 0.0553  ,\n",
       "            0.0539  , 0.05014 , 0.04794 , 0.0471  , 0.047   , 0.04526 ,\n",
       "            0.04163 , 0.03986 , 0.0397  , 0.03726 , 0.0363  , 0.03372 ,\n",
       "            0.03302 , 0.03278 , 0.03137 , 0.03108 , 0.03085 , 0.02992 ,\n",
       "            0.02925 , 0.0267  , 0.02562 , 0.02551 , 0.02542 , 0.02527 ,\n",
       "            0.02391 , 0.02324 , 0.02242 , 0.02203 , 0.0217  , 0.02133 ,\n",
       "            0.01976 , 0.01938 , 0.0192  , 0.01823 , 0.01816 , 0.01799 ,\n",
       "            0.01653 , 0.01646 , 0.0159  , 0.01584 , 0.015015, 0.0145  ,\n",
       "            0.013794, 0.01312 , 0.01307 , 0.01238 , 0.01169 , 0.01164 ,\n",
       "            0.01103 , 0.009415, 0.00923 , 0.00885 , 0.00685 , 0.005844,\n",
       "            0.00562 , 0.004963, 0.004265, 0.002388], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00847458, dtype=float32),\n",
       "    'tpr': array(0.81060606, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.7881356 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.530303  , 0.5378788 , 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9956  , 0.9863  , 0.9707  , 0.9604  , 0.9565  ,\n",
       "            0.9536  , 0.9517  , 0.951   , 0.9507  , 0.95    , 0.949   ,\n",
       "            0.9478  , 0.945   , 0.944   , 0.943   , 0.941   , 0.937   ,\n",
       "            0.935   , 0.9326  , 0.932   , 0.929   , 0.9277  , 0.927   ,\n",
       "            0.9253  , 0.924   , 0.923   , 0.9194  , 0.916   , 0.9146  ,\n",
       "            0.913   , 0.9116  , 0.906   , 0.903   , 0.9004  , 0.8936  ,\n",
       "            0.893   , 0.8887  , 0.8877  , 0.8867  , 0.886   , 0.878   ,\n",
       "            0.8735  , 0.8726  , 0.866   , 0.8623  , 0.86    , 0.851   ,\n",
       "            0.848   , 0.8423  , 0.842   , 0.8413  , 0.8374  , 0.836   ,\n",
       "            0.8315  , 0.831   , 0.83    , 0.8286  , 0.825   , 0.821   ,\n",
       "            0.8125  , 0.8115  , 0.7905  , 0.773   , 0.7705  , 0.7695  ,\n",
       "            0.769   , 0.763   , 0.7534  , 0.7505  , 0.7495  , 0.749   ,\n",
       "            0.7485  , 0.746   , 0.736   , 0.7314  , 0.7285  , 0.691   ,\n",
       "            0.686   , 0.682   , 0.678   , 0.675   , 0.669   , 0.6675  ,\n",
       "            0.658   , 0.651   , 0.6147  , 0.613   , 0.6123  , 0.6104  ,\n",
       "            0.6064  , 0.5703  , 0.5684  , 0.567   , 0.5654  , 0.559   ,\n",
       "            0.5527  , 0.551   , 0.5464  , 0.541   , 0.5376  , 0.523   ,\n",
       "            0.5215  , 0.497   , 0.4678  , 0.4663  , 0.4128  , 0.4001  ,\n",
       "            0.3904  , 0.3884  , 0.388   , 0.3772  , 0.3682  , 0.3672  ,\n",
       "            0.367   , 0.3418  , 0.3262  , 0.2886  , 0.2783  , 0.2598  ,\n",
       "            0.2374  , 0.2362  , 0.2327  , 0.2261  , 0.2135  , 0.2119  ,\n",
       "            0.2045  , 0.1936  , 0.1848  , 0.1753  , 0.1705  , 0.1641  ,\n",
       "            0.162   , 0.1588  , 0.1556  , 0.1508  , 0.135   , 0.1315  ,\n",
       "            0.1302  , 0.12054 , 0.1178  , 0.11615 , 0.1158  , 0.1128  ,\n",
       "            0.1126  , 0.11145 , 0.1045  , 0.10034 , 0.0959  , 0.09186 ,\n",
       "            0.0914  , 0.0895  , 0.0888  , 0.0848  , 0.08124 , 0.07904 ,\n",
       "            0.076   , 0.07556 , 0.07184 , 0.0707  , 0.07007 , 0.06995 ,\n",
       "            0.06866 , 0.0672  , 0.0635  , 0.0629  , 0.0627  , 0.06177 ,\n",
       "            0.06052 , 0.0601  , 0.05844 , 0.0545  , 0.0543  , 0.0535  ,\n",
       "            0.053   , 0.05118 , 0.05005 , 0.04987 , 0.0485  , 0.0469  ,\n",
       "            0.0463  , 0.0456  , 0.04553 , 0.04257 , 0.04233 , 0.04068 ,\n",
       "            0.04053 , 0.03732 , 0.03583 , 0.03418 , 0.0334  , 0.03253 ,\n",
       "            0.02954 , 0.02914 , 0.0286  , 0.02759 , 0.02748 , 0.02655 ,\n",
       "            0.02538 , 0.02527 , 0.02475 , 0.02208 , 0.02124 , 0.01987 ,\n",
       "            0.01909 , 0.01906 , 0.01872 , 0.01816 , 0.01778 , 0.01678 ,\n",
       "            0.01634 , 0.01596 , 0.0159  , 0.01584 , 0.01578 , 0.01519 ,\n",
       "            0.01343 , 0.01297 , 0.012924, 0.01287 , 0.01267 , 0.01253 ,\n",
       "            0.011826, 0.01129 , 0.0107  , 0.01065 , 0.01057 , 0.01029 ,\n",
       "            0.00993 , 0.009895, 0.00885 , 0.00752 , 0.007065, 0.005386,\n",
       "            0.00435 , 0.003855, 0.00368 , 0.002811, 0.001495], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00847458, dtype=float32),\n",
       "    'tpr': array(0.8030303, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.14393939, 0.15151516,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9609e-01, 9.8779e-01, 9.7217e-01, 9.6680e-01,\n",
       "            9.5947e-01, 9.5752e-01, 9.5654e-01, 9.5557e-01, 9.5508e-01,\n",
       "            9.5361e-01, 9.5264e-01, 9.5117e-01, 9.4971e-01, 9.4775e-01,\n",
       "            9.4678e-01, 9.4385e-01, 9.4336e-01, 9.4189e-01, 9.3701e-01,\n",
       "            9.3652e-01, 9.3408e-01, 9.2920e-01, 9.2871e-01, 9.2773e-01,\n",
       "            9.2578e-01, 9.2529e-01, 9.2432e-01, 9.2041e-01, 9.1553e-01,\n",
       "            9.0771e-01, 9.0674e-01, 9.0381e-01, 9.0088e-01, 8.9941e-01,\n",
       "            8.9746e-01, 8.9209e-01, 8.8916e-01, 8.8867e-01, 8.8525e-01,\n",
       "            8.8184e-01, 8.7744e-01, 8.7305e-01, 8.7158e-01, 8.7061e-01,\n",
       "            8.7012e-01, 8.6719e-01, 8.5449e-01, 8.5205e-01, 8.5107e-01,\n",
       "            8.4473e-01, 8.4082e-01, 8.3887e-01, 8.3838e-01, 8.3789e-01,\n",
       "            8.3594e-01, 8.3398e-01, 8.3350e-01, 8.3301e-01, 8.2617e-01,\n",
       "            8.2568e-01, 8.2373e-01, 8.2129e-01, 7.9980e-01, 7.8027e-01,\n",
       "            7.7197e-01, 7.7100e-01, 7.6758e-01, 7.6660e-01, 7.6465e-01,\n",
       "            7.6318e-01, 7.6123e-01, 7.5977e-01, 7.5928e-01, 7.4707e-01,\n",
       "            7.4268e-01, 7.3730e-01, 7.2998e-01, 6.8945e-01, 6.8457e-01,\n",
       "            6.7822e-01, 6.7383e-01, 6.6748e-01, 6.5967e-01, 6.5820e-01,\n",
       "            6.5381e-01, 6.4844e-01, 6.0938e-01, 5.8887e-01, 5.7861e-01,\n",
       "            5.7568e-01, 5.7373e-01, 5.7227e-01, 5.6592e-01, 5.6201e-01,\n",
       "            5.6055e-01, 5.5762e-01, 5.5371e-01, 5.5176e-01, 5.4736e-01,\n",
       "            5.3125e-01, 5.2344e-01, 5.2295e-01, 5.1465e-01, 4.9414e-01,\n",
       "            4.7827e-01, 4.6509e-01, 4.6313e-01, 4.0576e-01, 3.9185e-01,\n",
       "            3.8232e-01, 3.8159e-01, 3.6523e-01, 3.6108e-01, 3.5815e-01,\n",
       "            3.4131e-01, 3.3423e-01, 3.2324e-01, 2.9785e-01, 2.7930e-01,\n",
       "            2.6660e-01, 2.3914e-01, 2.3022e-01, 2.1497e-01, 2.1204e-01,\n",
       "            1.9373e-01, 1.9287e-01, 1.9189e-01, 1.8066e-01, 1.6626e-01,\n",
       "            1.6443e-01, 1.6260e-01, 1.5869e-01, 1.5234e-01, 1.4319e-01,\n",
       "            1.3684e-01, 1.2854e-01, 1.2744e-01, 1.2433e-01, 1.1737e-01,\n",
       "            1.1377e-01, 1.1218e-01, 1.0687e-01, 1.0449e-01, 9.4360e-02,\n",
       "            9.1858e-02, 9.0271e-02, 8.8806e-02, 8.7891e-02, 8.6914e-02,\n",
       "            8.5999e-02, 8.2703e-02, 7.5989e-02, 7.3669e-02, 7.3181e-02,\n",
       "            7.2754e-02, 7.1594e-02, 6.8542e-02, 6.6711e-02, 6.5125e-02,\n",
       "            6.5002e-02, 6.1890e-02, 6.0852e-02, 6.0089e-02, 5.6030e-02,\n",
       "            5.5115e-02, 5.4596e-02, 5.2704e-02, 5.0415e-02, 5.0049e-02,\n",
       "            4.9042e-02, 4.8035e-02, 4.7424e-02, 4.7150e-02, 4.6387e-02,\n",
       "            4.5013e-02, 4.4678e-02, 4.3701e-02, 4.3274e-02, 4.2633e-02,\n",
       "            3.8971e-02, 3.8116e-02, 3.6621e-02, 3.6346e-02, 3.6224e-02,\n",
       "            3.5217e-02, 3.4546e-02, 3.4027e-02, 3.3966e-02, 3.3539e-02,\n",
       "            3.0624e-02, 2.9755e-02, 2.9251e-02, 2.8336e-02, 2.7802e-02,\n",
       "            2.6855e-02, 2.6001e-02, 2.4521e-02, 2.2415e-02, 2.1210e-02,\n",
       "            2.0966e-02, 2.0889e-02, 1.8341e-02, 1.8158e-02, 1.7639e-02,\n",
       "            1.6464e-02, 1.4900e-02, 1.3634e-02, 1.3588e-02, 1.3428e-02,\n",
       "            1.3168e-02, 1.3023e-02, 1.2672e-02, 1.2573e-02, 1.1467e-02,\n",
       "            1.1032e-02, 1.0986e-02, 1.0902e-02, 1.0735e-02, 1.0612e-02,\n",
       "            1.0567e-02, 1.0452e-02, 1.0330e-02, 9.6359e-03, 9.3384e-03,\n",
       "            9.0561e-03, 8.8501e-03, 8.6136e-03, 8.4763e-03, 8.4457e-03,\n",
       "            8.3771e-03, 7.1220e-03, 6.7978e-03, 6.2180e-03, 6.0043e-03,\n",
       "            5.6419e-03, 4.2305e-03, 3.3760e-03, 2.9812e-03, 2.2964e-03,\n",
       "            1.7414e-03, 8.8978e-04], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00847458, dtype=float32),\n",
       "    'tpr': array(0.77272725, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7627119 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.45454547, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9609e-01, 9.8633e-01, 9.7168e-01, 9.6826e-01,\n",
       "            9.6143e-01, 9.5850e-01, 9.5508e-01, 9.5361e-01, 9.5215e-01,\n",
       "            9.4971e-01, 9.4873e-01, 9.4824e-01, 9.4678e-01, 9.4629e-01,\n",
       "            9.4531e-01, 9.4336e-01, 9.4189e-01, 9.3994e-01, 9.3896e-01,\n",
       "            9.3750e-01, 9.3262e-01, 9.2871e-01, 9.2480e-01, 9.2383e-01,\n",
       "            9.2041e-01, 9.1992e-01, 9.1846e-01, 9.1602e-01, 9.1113e-01,\n",
       "            9.0771e-01, 9.0576e-01, 9.0381e-01, 8.9551e-01, 8.8623e-01,\n",
       "            8.8281e-01, 8.7891e-01, 8.7793e-01, 8.7549e-01, 8.7451e-01,\n",
       "            8.7207e-01, 8.6719e-01, 8.6670e-01, 8.6279e-01, 8.5791e-01,\n",
       "            8.5498e-01, 8.4912e-01, 8.4863e-01, 8.4570e-01, 8.3936e-01,\n",
       "            8.3740e-01, 8.3398e-01, 8.3203e-01, 8.2764e-01, 8.2275e-01,\n",
       "            8.1738e-01, 8.1543e-01, 8.1396e-01, 8.1201e-01, 8.0859e-01,\n",
       "            8.0566e-01, 8.0176e-01, 7.8662e-01, 7.7539e-01, 7.7246e-01,\n",
       "            7.7051e-01, 7.6758e-01, 7.6709e-01, 7.6562e-01, 7.5439e-01,\n",
       "            7.4512e-01, 7.4414e-01, 7.3828e-01, 7.3438e-01, 7.3242e-01,\n",
       "            7.2803e-01, 7.2314e-01, 6.9971e-01, 6.9189e-01, 6.9043e-01,\n",
       "            6.6113e-01, 6.6064e-01, 6.3428e-01, 6.3086e-01, 6.2207e-01,\n",
       "            6.1572e-01, 5.9814e-01, 5.7520e-01, 5.6738e-01, 5.5029e-01,\n",
       "            5.4492e-01, 5.4248e-01, 5.3955e-01, 5.2295e-01, 5.2148e-01,\n",
       "            5.1660e-01, 5.1221e-01, 5.1172e-01, 5.0928e-01, 5.0537e-01,\n",
       "            4.9927e-01, 4.8022e-01, 4.7412e-01, 4.7266e-01, 4.5801e-01,\n",
       "            4.5190e-01, 4.4824e-01, 4.2822e-01, 3.6792e-01, 3.6084e-01,\n",
       "            3.4888e-01, 3.4839e-01, 3.4546e-01, 3.3643e-01, 3.1616e-01,\n",
       "            2.9053e-01, 2.7759e-01, 2.6367e-01, 2.6001e-01, 2.5195e-01,\n",
       "            2.3462e-01, 2.0154e-01, 1.9824e-01, 1.9043e-01, 1.8054e-01,\n",
       "            1.7529e-01, 1.6101e-01, 1.4661e-01, 1.4490e-01, 1.3782e-01,\n",
       "            1.3281e-01, 1.3269e-01, 1.2695e-01, 1.1932e-01, 1.1658e-01,\n",
       "            1.0706e-01, 9.7534e-02, 9.5703e-02, 9.2224e-02, 9.1858e-02,\n",
       "            9.1064e-02, 9.0759e-02, 8.9294e-02, 7.9895e-02, 7.6111e-02,\n",
       "            7.2083e-02, 7.1472e-02, 6.8909e-02, 6.7200e-02, 6.6101e-02,\n",
       "            6.4636e-02, 6.2103e-02, 5.9204e-02, 5.8136e-02, 5.5115e-02,\n",
       "            5.2917e-02, 5.2032e-02, 5.1666e-02, 5.0598e-02, 4.9500e-02,\n",
       "            4.8492e-02, 4.8126e-02, 4.6387e-02, 4.5776e-02, 4.4678e-02,\n",
       "            4.2480e-02, 4.2023e-02, 4.1840e-02, 3.9062e-02, 3.8818e-02,\n",
       "            3.7903e-02, 3.7109e-02, 3.6163e-02, 3.5614e-02, 3.5339e-02,\n",
       "            3.5217e-02, 3.4485e-02, 3.4363e-02, 3.2410e-02, 3.0853e-02,\n",
       "            3.0380e-02, 2.9312e-02, 2.8809e-02, 2.8549e-02, 2.8381e-02,\n",
       "            2.5131e-02, 2.4750e-02, 2.4139e-02, 2.3605e-02, 2.3560e-02,\n",
       "            2.3193e-02, 2.3148e-02, 2.2156e-02, 2.2110e-02, 1.9989e-02,\n",
       "            1.9913e-02, 1.9241e-02, 1.8768e-02, 1.8646e-02, 1.7776e-02,\n",
       "            1.6785e-02, 1.6525e-02, 1.4671e-02, 1.4282e-02, 1.3847e-02,\n",
       "            1.2970e-02, 1.2009e-02, 1.1688e-02, 1.0330e-02, 1.0132e-02,\n",
       "            1.0010e-02, 9.6741e-03, 8.9874e-03, 8.8806e-03, 8.4763e-03,\n",
       "            8.4457e-03, 8.1253e-03, 8.0948e-03, 8.0032e-03, 7.3166e-03,\n",
       "            7.0953e-03, 7.0114e-03, 6.6681e-03, 6.6147e-03, 6.4888e-03,\n",
       "            6.4621e-03, 6.2904e-03, 6.1684e-03, 6.1226e-03, 5.2795e-03,\n",
       "            5.0392e-03, 4.9629e-03, 4.5395e-03, 4.4327e-03, 4.1504e-03,\n",
       "            3.9291e-03, 3.0518e-03, 2.4338e-03, 2.1248e-03, 1.2064e-03,\n",
       "            9.6607e-04, 4.6015e-04], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00847458, dtype=float32),\n",
       "    'tpr': array(0.75757575, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.06818182, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.12121212, 0.12878788, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.24242425, 0.25757575, 0.2651515 ,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9707e-01, 9.8975e-01, 9.7314e-01, 9.6338e-01,\n",
       "            9.6240e-01, 9.5947e-01, 9.5752e-01, 9.5703e-01, 9.5508e-01,\n",
       "            9.5459e-01, 9.5215e-01, 9.5117e-01, 9.4922e-01, 9.4727e-01,\n",
       "            9.4482e-01, 9.4043e-01, 9.3799e-01, 9.3701e-01, 9.3311e-01,\n",
       "            9.3262e-01, 9.3115e-01, 9.2920e-01, 9.2676e-01, 9.2529e-01,\n",
       "            9.1943e-01, 9.1406e-01, 9.1211e-01, 9.1064e-01, 9.0234e-01,\n",
       "            8.8477e-01, 8.7988e-01, 8.7793e-01, 8.7744e-01, 8.7695e-01,\n",
       "            8.7549e-01, 8.7109e-01, 8.6963e-01, 8.6572e-01, 8.6328e-01,\n",
       "            8.5840e-01, 8.5791e-01, 8.5742e-01, 8.5645e-01, 8.5596e-01,\n",
       "            8.5352e-01, 8.4180e-01, 8.3643e-01, 8.3545e-01, 8.3154e-01,\n",
       "            8.2959e-01, 8.2568e-01, 8.2324e-01, 8.2178e-01, 8.2129e-01,\n",
       "            8.0615e-01, 7.9443e-01, 7.8760e-01, 7.7686e-01, 7.7441e-01,\n",
       "            7.7393e-01, 7.6904e-01, 7.6807e-01, 7.6758e-01, 7.6660e-01,\n",
       "            7.6611e-01, 7.6562e-01, 7.5977e-01, 7.5488e-01, 7.4414e-01,\n",
       "            7.3877e-01, 7.2168e-01, 7.1924e-01, 6.8848e-01, 6.8799e-01,\n",
       "            6.8555e-01, 6.5723e-01, 6.5479e-01, 6.3965e-01, 6.3916e-01,\n",
       "            6.2354e-01, 5.9131e-01, 5.7715e-01, 5.6299e-01, 5.4053e-01,\n",
       "            5.4004e-01, 5.3906e-01, 5.3564e-01, 5.3271e-01, 5.3174e-01,\n",
       "            5.2295e-01, 5.1074e-01, 5.0781e-01, 5.0537e-01, 4.8950e-01,\n",
       "            4.8291e-01, 4.7778e-01, 4.7192e-01, 4.6851e-01, 4.4116e-01,\n",
       "            4.3604e-01, 4.2334e-01, 4.1211e-01, 3.7524e-01, 3.6084e-01,\n",
       "            3.5034e-01, 3.5010e-01, 3.4155e-01, 3.2788e-01, 3.2666e-01,\n",
       "            3.1421e-01, 3.0225e-01, 2.4292e-01, 2.3621e-01, 2.2742e-01,\n",
       "            2.2400e-01, 2.0422e-01, 1.9958e-01, 1.9226e-01, 1.7920e-01,\n",
       "            1.5808e-01, 1.5051e-01, 1.5002e-01, 1.3953e-01, 1.3782e-01,\n",
       "            1.2646e-01, 1.1963e-01, 1.1841e-01, 1.0992e-01, 1.0107e-01,\n",
       "            9.6375e-02, 9.0393e-02, 8.2520e-02, 8.0383e-02, 8.0078e-02,\n",
       "            7.6111e-02, 7.0557e-02, 6.9946e-02, 6.1523e-02, 6.1432e-02,\n",
       "            6.0089e-02, 5.6549e-02, 5.6030e-02, 5.4901e-02, 5.1544e-02,\n",
       "            5.1453e-02, 5.0140e-02, 4.9866e-02, 4.7424e-02, 4.6539e-02,\n",
       "            4.2816e-02, 4.1077e-02, 4.0009e-02, 3.9856e-02, 3.7109e-02,\n",
       "            3.5217e-02, 3.4607e-02, 3.4546e-02, 3.4088e-02, 3.3661e-02,\n",
       "            3.3386e-02, 3.3264e-02, 3.2593e-02, 3.1982e-02, 3.1616e-02,\n",
       "            3.1250e-02, 3.1082e-02, 2.8870e-02, 2.8763e-02, 2.7954e-02,\n",
       "            2.6764e-02, 2.6611e-02, 2.6199e-02, 2.4750e-02, 2.4521e-02,\n",
       "            2.1576e-02, 2.1088e-02, 2.0920e-02, 2.0142e-02, 1.9913e-02,\n",
       "            1.9348e-02, 1.9241e-02, 1.8646e-02, 1.8616e-02, 1.7517e-02,\n",
       "            1.6785e-02, 1.6342e-02, 1.5541e-02, 1.4839e-02, 1.4503e-02,\n",
       "            1.4061e-02, 1.3741e-02, 1.3374e-02, 1.2970e-02, 1.2871e-02,\n",
       "            1.1871e-02, 1.1551e-02, 1.0529e-02, 9.3384e-03, 9.1934e-03,\n",
       "            8.4763e-03, 8.4457e-03, 8.3160e-03, 8.1558e-03, 7.6675e-03,\n",
       "            6.6910e-03, 6.5384e-03, 6.4621e-03, 6.2408e-03, 6.0043e-03,\n",
       "            5.9357e-03, 5.8441e-03, 5.6190e-03, 5.5771e-03, 5.5542e-03,\n",
       "            5.5351e-03, 5.5122e-03, 5.1384e-03, 5.1003e-03, 5.0011e-03,\n",
       "            4.2000e-03, 4.1504e-03, 4.1161e-03, 3.8395e-03, 3.5648e-03,\n",
       "            3.4561e-03, 3.2234e-03, 2.7466e-03, 2.6836e-03, 2.3880e-03,\n",
       "            2.0580e-03, 1.8311e-03, 1.5850e-03, 5.6362e-04, 5.0545e-04,\n",
       "            2.1994e-04], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00847458, dtype=float32),\n",
       "    'tpr': array(0.7348485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.36363637, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9805e-01, 9.9219e-01, 9.7803e-01, 9.7754e-01,\n",
       "            9.6924e-01, 9.6875e-01, 9.6582e-01, 9.6533e-01, 9.6387e-01,\n",
       "            9.6289e-01, 9.6143e-01, 9.6094e-01, 9.5898e-01, 9.5801e-01,\n",
       "            9.5752e-01, 9.5654e-01, 9.5459e-01, 9.5215e-01, 9.4775e-01,\n",
       "            9.4531e-01, 9.4385e-01, 9.4092e-01, 9.3994e-01, 9.3652e-01,\n",
       "            9.3408e-01, 9.3359e-01, 9.3311e-01, 9.2822e-01, 9.2139e-01,\n",
       "            9.2090e-01, 9.1943e-01, 9.1895e-01, 9.1602e-01, 9.1016e-01,\n",
       "            8.9355e-01, 8.9307e-01, 8.8916e-01, 8.8574e-01, 8.8281e-01,\n",
       "            8.7695e-01, 8.7549e-01, 8.7061e-01, 8.6914e-01, 8.6621e-01,\n",
       "            8.6475e-01, 8.6426e-01, 8.6230e-01, 8.5742e-01, 8.5059e-01,\n",
       "            8.4424e-01, 8.4375e-01, 8.3838e-01, 8.3789e-01, 8.3398e-01,\n",
       "            8.3203e-01, 8.2959e-01, 8.2861e-01, 8.2764e-01, 8.1396e-01,\n",
       "            7.9492e-01, 7.7686e-01, 7.7588e-01, 7.7246e-01, 7.7197e-01,\n",
       "            7.7148e-01, 7.7100e-01, 7.6758e-01, 7.6562e-01, 7.6367e-01,\n",
       "            7.5635e-01, 7.4561e-01, 7.4072e-01, 7.2510e-01, 7.1582e-01,\n",
       "            6.8896e-01, 6.8164e-01, 6.7676e-01, 6.5186e-01, 6.3379e-01,\n",
       "            6.2939e-01, 6.1621e-01, 5.8252e-01, 5.5273e-01, 5.4834e-01,\n",
       "            5.3076e-01, 5.2930e-01, 5.2637e-01, 5.2197e-01, 5.2051e-01,\n",
       "            5.1953e-01, 5.0342e-01, 4.9121e-01, 4.8950e-01, 4.7632e-01,\n",
       "            4.6460e-01, 4.5996e-01, 4.5312e-01, 4.4336e-01, 4.3408e-01,\n",
       "            4.1846e-01, 4.1772e-01, 3.8330e-01, 3.7036e-01, 3.5229e-01,\n",
       "            3.3789e-01, 3.2739e-01, 3.2568e-01, 3.0249e-01, 3.0029e-01,\n",
       "            2.8906e-01, 2.8418e-01, 2.7612e-01, 2.1484e-01, 2.1375e-01,\n",
       "            1.9116e-01, 1.8347e-01, 1.7200e-01, 1.6748e-01, 1.6321e-01,\n",
       "            1.5295e-01, 1.3379e-01, 1.2720e-01, 1.2360e-01, 1.1719e-01,\n",
       "            1.1395e-01, 1.0614e-01, 9.8938e-02, 9.7229e-02, 8.1543e-02,\n",
       "            7.5012e-02, 7.4219e-02, 7.3425e-02, 6.5857e-02, 6.2317e-02,\n",
       "            5.8136e-02, 5.7800e-02, 5.6854e-02, 5.1178e-02, 4.6722e-02,\n",
       "            4.3762e-02, 4.3121e-02, 4.2175e-02, 3.9703e-02, 3.9062e-02,\n",
       "            3.7903e-02, 3.7262e-02, 3.7201e-02, 3.6621e-02, 3.5889e-02,\n",
       "            3.1311e-02, 3.1143e-02, 3.0441e-02, 2.9419e-02, 2.7222e-02,\n",
       "            2.6413e-02, 2.6306e-02, 2.5223e-02, 2.4933e-02, 2.4567e-02,\n",
       "            2.4384e-02, 2.4094e-02, 2.3285e-02, 2.3071e-02, 2.2980e-02,\n",
       "            2.2293e-02, 2.2079e-02, 2.1912e-02, 2.0889e-02, 2.0599e-02,\n",
       "            2.0493e-02, 1.9455e-02, 1.8799e-02, 1.8616e-02, 1.8402e-02,\n",
       "            1.8188e-02, 1.7380e-02, 1.5671e-02, 1.5015e-02, 1.4671e-02,\n",
       "            1.3687e-02, 1.3374e-02, 1.3329e-02, 1.3069e-02, 1.3023e-02,\n",
       "            1.2772e-02, 1.2428e-02, 1.2238e-02, 1.2192e-02, 1.0818e-02,\n",
       "            1.0696e-02, 1.0292e-02, 1.0208e-02, 9.9335e-03, 9.8190e-03,\n",
       "            9.0561e-03, 8.3466e-03, 8.2169e-03, 8.0948e-03, 8.0032e-03,\n",
       "            7.5760e-03, 7.3166e-03, 6.1684e-03, 5.8899e-03, 5.7983e-03,\n",
       "            5.7755e-03, 5.6648e-03, 5.6419e-03, 4.5395e-03, 4.4327e-03,\n",
       "            4.3983e-03, 4.3831e-03, 4.1656e-03, 3.9291e-03, 3.9005e-03,\n",
       "            3.8548e-03, 3.6926e-03, 3.5515e-03, 3.5114e-03, 3.4161e-03,\n",
       "            3.2597e-03, 3.2349e-03, 2.9469e-03, 2.9125e-03, 2.7256e-03,\n",
       "            2.4338e-03, 2.3880e-03, 2.3327e-03, 2.2087e-03, 2.0504e-03,\n",
       "            1.9951e-03, 1.9875e-03, 1.5068e-03, 1.4782e-03, 1.4725e-03,\n",
       "            1.1292e-03, 1.0948e-03, 9.5463e-04, 2.9588e-04, 2.5320e-04,\n",
       "            1.0312e-04], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00847458, dtype=float32),\n",
       "    'tpr': array(0.7121212, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.23484848,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9854e-01, 9.9365e-01, 9.8096e-01, 9.7949e-01,\n",
       "            9.7314e-01, 9.7217e-01, 9.6973e-01, 9.6924e-01, 9.6826e-01,\n",
       "            9.6631e-01, 9.6582e-01, 9.6533e-01, 9.6289e-01, 9.6143e-01,\n",
       "            9.6094e-01, 9.6045e-01, 9.5850e-01, 9.5508e-01, 9.5264e-01,\n",
       "            9.4922e-01, 9.4678e-01, 9.4531e-01, 9.4336e-01, 9.3945e-01,\n",
       "            9.3799e-01, 9.3750e-01, 9.3652e-01, 9.3359e-01, 9.2432e-01,\n",
       "            9.2334e-01, 9.1797e-01, 9.1357e-01, 8.9893e-01, 8.9746e-01,\n",
       "            8.9453e-01, 8.9014e-01, 8.8867e-01, 8.8477e-01, 8.7549e-01,\n",
       "            8.7158e-01, 8.7012e-01, 8.6670e-01, 8.6621e-01, 8.6328e-01,\n",
       "            8.6279e-01, 8.5791e-01, 8.5645e-01, 8.5352e-01, 8.4521e-01,\n",
       "            8.4424e-01, 8.4375e-01, 8.4180e-01, 8.4033e-01, 8.3301e-01,\n",
       "            8.3203e-01, 8.2324e-01, 8.1543e-01, 8.1445e-01, 7.9297e-01,\n",
       "            7.9053e-01, 7.7393e-01, 7.7197e-01, 7.6953e-01, 7.6709e-01,\n",
       "            7.6611e-01, 7.6514e-01, 7.6416e-01, 7.6172e-01, 7.5586e-01,\n",
       "            7.4707e-01, 7.4463e-01, 7.3877e-01, 7.3242e-01, 7.2314e-01,\n",
       "            7.0654e-01, 6.7822e-01, 6.6357e-01, 6.5771e-01, 6.4258e-01,\n",
       "            6.3330e-01, 6.2451e-01, 6.1230e-01, 6.0693e-01, 5.6738e-01,\n",
       "            5.1807e-01, 5.1709e-01, 5.1562e-01, 5.1025e-01, 5.0146e-01,\n",
       "            4.9756e-01, 4.9097e-01, 4.7559e-01, 4.7388e-01, 4.5923e-01,\n",
       "            4.5874e-01, 4.4019e-01, 4.3359e-01, 4.0601e-01, 3.9233e-01,\n",
       "            3.8818e-01, 3.8330e-01, 3.8184e-01, 3.4937e-01, 3.2520e-01,\n",
       "            3.1250e-01, 3.0884e-01, 2.9736e-01, 2.9248e-01, 2.7612e-01,\n",
       "            2.6221e-01, 2.4939e-01, 2.4695e-01, 2.3157e-01, 1.9250e-01,\n",
       "            1.8030e-01, 1.5259e-01, 1.4648e-01, 1.4551e-01, 1.4343e-01,\n",
       "            1.2262e-01, 1.2244e-01, 1.0876e-01, 1.0742e-01, 9.8572e-02,\n",
       "            9.7046e-02, 9.1370e-02, 8.8196e-02, 8.2520e-02, 7.8369e-02,\n",
       "            5.8990e-02, 5.6122e-02, 5.4993e-02, 5.3406e-02, 5.0995e-02,\n",
       "            4.5959e-02, 4.4861e-02, 4.1534e-02, 3.9948e-02, 3.6285e-02,\n",
       "            3.3539e-02, 3.2654e-02, 2.9144e-02, 2.8976e-02, 2.8442e-02,\n",
       "            2.8015e-02, 2.7695e-02, 2.7115e-02, 2.6703e-02, 2.5955e-02,\n",
       "            2.5513e-02, 2.4338e-02, 2.3697e-02, 2.0172e-02, 1.9608e-02,\n",
       "            1.9272e-02, 1.8433e-02, 1.8341e-02, 1.7776e-02, 1.7517e-02,\n",
       "            1.7303e-02, 1.6403e-02, 1.5541e-02, 1.5251e-02, 1.4954e-02,\n",
       "            1.4900e-02, 1.4732e-02, 1.4671e-02, 1.4389e-02, 1.4282e-02,\n",
       "            1.4061e-02, 1.3634e-02, 1.3481e-02, 1.2573e-02, 1.2009e-02,\n",
       "            1.1826e-02, 1.1505e-02, 1.1162e-02, 1.0651e-02, 1.0170e-02,\n",
       "            9.1629e-03, 9.0179e-03, 8.5144e-03, 8.4457e-03, 8.4152e-03,\n",
       "            8.0338e-03, 7.9651e-03, 7.6942e-03, 7.5760e-03, 7.2327e-03,\n",
       "            7.1754e-03, 6.8245e-03, 6.1684e-03, 6.0043e-03, 5.9357e-03,\n",
       "            5.7983e-03, 5.2795e-03, 4.9629e-03, 4.6272e-03, 4.5738e-03,\n",
       "            4.5547e-03, 4.4518e-03, 3.9902e-03, 3.9139e-03, 3.8242e-03,\n",
       "            3.7956e-03, 3.2234e-03, 2.9125e-03, 2.8896e-03, 2.8229e-03,\n",
       "            2.5616e-03, 2.5311e-03, 2.5024e-03, 2.4719e-03, 2.4433e-03,\n",
       "            2.3880e-03, 2.2526e-03, 2.2335e-03, 2.2163e-03, 2.2087e-03,\n",
       "            1.7481e-03, 1.7338e-03, 1.7271e-03, 1.5545e-03, 1.5430e-03,\n",
       "            1.5125e-03, 1.3781e-03, 1.2550e-03, 1.2493e-03, 1.2016e-03,\n",
       "            1.0042e-03, 1.0004e-03, 8.8978e-04, 7.4387e-04, 7.2670e-04,\n",
       "            6.1893e-04, 5.4836e-04, 1.3447e-04, 1.1146e-04, 4.2319e-05],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00847458, dtype=float32),\n",
       "    'tpr': array(0.74242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.10169491, 0.11864407,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.08333334,\n",
       "            0.09848485, 0.11363637, 0.12121212, 0.12878788, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.72727275, 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9902e-01, 9.9561e-01, 9.8926e-01, 9.8584e-01,\n",
       "            9.8438e-01, 9.8291e-01, 9.8096e-01, 9.7998e-01, 9.7754e-01,\n",
       "            9.7705e-01, 9.7559e-01, 9.7510e-01, 9.7363e-01, 9.7314e-01,\n",
       "            9.7168e-01, 9.6826e-01, 9.6484e-01, 9.6289e-01, 9.6240e-01,\n",
       "            9.6143e-01, 9.6045e-01, 9.5898e-01, 9.5801e-01, 9.5215e-01,\n",
       "            9.5117e-01, 9.5068e-01, 9.4922e-01, 9.4629e-01, 9.4434e-01,\n",
       "            9.4189e-01, 9.2529e-01, 9.2041e-01, 9.1992e-01, 9.1602e-01,\n",
       "            9.1211e-01, 9.0967e-01, 9.0918e-01, 9.0674e-01, 9.0527e-01,\n",
       "            9.0186e-01, 8.9502e-01, 8.9160e-01, 8.9062e-01, 8.8721e-01,\n",
       "            8.8037e-01, 8.7402e-01, 8.6816e-01, 8.6621e-01, 8.6426e-01,\n",
       "            8.6230e-01, 8.6133e-01, 8.5986e-01, 8.5889e-01, 8.4814e-01,\n",
       "            8.4766e-01, 8.3740e-01, 8.3350e-01, 8.3105e-01, 8.2715e-01,\n",
       "            8.2666e-01, 8.2568e-01, 8.2520e-01, 8.1885e-01, 8.1152e-01,\n",
       "            8.0664e-01, 8.0566e-01, 8.0029e-01, 7.7393e-01, 7.6904e-01,\n",
       "            7.6807e-01, 7.5830e-01, 7.4365e-01, 7.3730e-01, 7.0459e-01,\n",
       "            6.8555e-01, 6.7969e-01, 6.7432e-01, 6.3721e-01, 6.3672e-01,\n",
       "            6.0400e-01, 5.9375e-01, 5.6201e-01, 5.5566e-01, 5.4883e-01,\n",
       "            5.4785e-01, 5.3564e-01, 5.3271e-01, 5.2881e-01, 5.2148e-01,\n",
       "            4.9756e-01, 4.8779e-01, 4.5874e-01, 4.5337e-01, 4.4165e-01,\n",
       "            4.3896e-01, 4.2334e-01, 3.8135e-01, 3.6694e-01, 3.5083e-01,\n",
       "            3.4595e-01, 3.3105e-01, 3.3057e-01, 3.1616e-01, 3.1079e-01,\n",
       "            3.0322e-01, 2.9150e-01, 2.7954e-01, 2.6099e-01, 2.2571e-01,\n",
       "            2.0496e-01, 1.9788e-01, 1.4966e-01, 1.4587e-01, 1.3855e-01,\n",
       "            1.2817e-01, 1.2537e-01, 1.1578e-01, 1.1316e-01, 1.0577e-01,\n",
       "            9.7717e-02, 9.3201e-02, 8.9783e-02, 8.7708e-02, 7.8369e-02,\n",
       "            7.4890e-02, 5.7495e-02, 5.0812e-02, 4.5441e-02, 4.3274e-02,\n",
       "            4.2084e-02, 4.1931e-02, 3.5736e-02, 3.5339e-02, 3.1738e-02,\n",
       "            3.1250e-02, 2.7908e-02, 2.7481e-02, 2.6505e-02, 2.5131e-02,\n",
       "            2.2369e-02, 2.1332e-02, 2.0645e-02, 2.0294e-02, 1.9196e-02,\n",
       "            1.8509e-02, 1.8402e-02, 1.6922e-02, 1.6785e-02, 1.6724e-02,\n",
       "            1.6159e-02, 1.5427e-02, 1.4503e-02, 1.3741e-02, 1.3168e-02,\n",
       "            1.2672e-02, 1.2627e-02, 1.2573e-02, 1.2100e-02, 1.1917e-02,\n",
       "            1.1551e-02, 1.1292e-02, 1.0857e-02, 1.0406e-02, 1.0246e-02,\n",
       "            9.8572e-03, 9.7122e-03, 9.6741e-03, 9.6359e-03, 9.4833e-03,\n",
       "            9.1934e-03, 8.5754e-03, 8.1558e-03, 8.0643e-03, 7.9041e-03,\n",
       "            7.7248e-03, 7.6675e-03, 7.4615e-03, 7.4043e-03, 6.7444e-03,\n",
       "            6.3400e-03, 5.9586e-03, 5.3215e-03, 5.1804e-03, 5.0812e-03,\n",
       "            5.0201e-03, 4.3640e-03, 4.2801e-03, 4.1161e-03, 3.7498e-03,\n",
       "            3.5515e-03, 3.5381e-03, 3.4428e-03, 3.4294e-03, 3.3512e-03,\n",
       "            3.2597e-03, 3.2101e-03, 2.8229e-03, 2.7676e-03, 2.6417e-03,\n",
       "            2.4624e-03, 2.4433e-03, 2.4338e-03, 2.2259e-03, 2.1324e-03,\n",
       "            2.1076e-03, 2.0752e-03, 2.0103e-03, 1.9798e-03, 1.8530e-03,\n",
       "            1.8311e-03, 1.8177e-03, 1.8101e-03, 1.4439e-03, 1.3409e-03,\n",
       "            1.2302e-03, 1.1339e-03, 1.0204e-03, 9.3985e-04, 9.2173e-04,\n",
       "            8.3590e-04, 8.2302e-04, 7.1526e-04, 6.5899e-04, 6.3372e-04,\n",
       "            5.3358e-04, 5.2357e-04, 5.0116e-04, 4.3392e-04, 3.8457e-04,\n",
       "            3.7694e-04, 2.8467e-04, 6.6578e-05, 4.7922e-05, 1.7107e-05],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.74242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09848485, 0.10606061, 0.12878788, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9951e-01, 9.9658e-01, 9.8877e-01, 9.8779e-01,\n",
       "            9.8389e-01, 9.8242e-01, 9.8193e-01, 9.8096e-01, 9.8047e-01,\n",
       "            9.7998e-01, 9.7900e-01, 9.7705e-01, 9.7559e-01, 9.7412e-01,\n",
       "            9.7168e-01, 9.6924e-01, 9.6631e-01, 9.6533e-01, 9.6436e-01,\n",
       "            9.6289e-01, 9.6191e-01, 9.6045e-01, 9.5557e-01, 9.5459e-01,\n",
       "            9.5068e-01, 9.5020e-01, 9.4824e-01, 9.4775e-01, 9.4580e-01,\n",
       "            9.4336e-01, 9.2773e-01, 9.2432e-01, 9.2188e-01, 9.1895e-01,\n",
       "            9.1309e-01, 9.1162e-01, 9.0771e-01, 9.0479e-01, 9.0381e-01,\n",
       "            9.0234e-01, 8.9941e-01, 8.9551e-01, 8.9502e-01, 8.9160e-01,\n",
       "            8.8281e-01, 8.8037e-01, 8.7988e-01, 8.7842e-01, 8.7793e-01,\n",
       "            8.7549e-01, 8.6719e-01, 8.6133e-01, 8.5693e-01, 8.5498e-01,\n",
       "            8.5449e-01, 8.4668e-01, 8.3105e-01, 8.2666e-01, 8.2568e-01,\n",
       "            8.1689e-01, 8.1543e-01, 8.1250e-01, 8.0957e-01, 8.0664e-01,\n",
       "            8.0420e-01, 8.0176e-01, 8.0078e-01, 7.9834e-01, 7.9199e-01,\n",
       "            7.9102e-01, 7.8467e-01, 7.8418e-01, 7.6562e-01, 7.6074e-01,\n",
       "            7.3291e-01, 7.1436e-01, 6.9678e-01, 6.8018e-01, 6.6455e-01,\n",
       "            6.6113e-01, 6.5332e-01, 6.3916e-01, 6.2500e-01, 5.9814e-01,\n",
       "            5.4688e-01, 5.4590e-01, 5.3564e-01, 5.2393e-01, 5.2148e-01,\n",
       "            5.1221e-01, 5.1123e-01, 5.0830e-01, 5.0684e-01, 4.8218e-01,\n",
       "            4.8193e-01, 4.7021e-01, 4.6069e-01, 4.5142e-01, 3.9185e-01,\n",
       "            3.8208e-01, 3.5669e-01, 3.5376e-01, 3.3447e-01, 3.2617e-01,\n",
       "            3.1372e-01, 3.1055e-01, 2.9419e-01, 2.8320e-01, 2.7295e-01,\n",
       "            2.5171e-01, 2.5073e-01, 2.4817e-01, 2.3792e-01, 1.8457e-01,\n",
       "            1.7468e-01, 1.6101e-01, 1.3965e-01, 1.2549e-01, 1.0504e-01,\n",
       "            1.0358e-01, 1.0284e-01, 9.9121e-02, 8.8806e-02, 8.2275e-02,\n",
       "            8.0811e-02, 7.4890e-02, 7.4524e-02, 6.8054e-02, 6.3721e-02,\n",
       "            6.1768e-02, 4.7089e-02, 4.1626e-02, 3.6072e-02, 3.1860e-02,\n",
       "            3.0731e-02, 2.7908e-02, 2.6917e-02, 2.4567e-02, 2.2629e-02,\n",
       "            2.2110e-02, 2.2034e-02, 2.0721e-02, 2.0416e-02, 1.9638e-02,\n",
       "            1.9302e-02, 1.8829e-02, 1.7303e-02, 1.4839e-02, 1.4114e-02,\n",
       "            1.3687e-02, 1.2970e-02, 1.2871e-02, 1.2573e-02, 1.2428e-02,\n",
       "            1.2009e-02, 1.1330e-02, 1.0818e-02, 9.9335e-03, 9.5978e-03,\n",
       "            9.3002e-03, 9.2316e-03, 9.0561e-03, 8.7128e-03, 8.6441e-03,\n",
       "            7.8430e-03, 7.4043e-03, 7.2899e-03, 7.1220e-03, 6.9847e-03,\n",
       "            6.9580e-03, 6.7978e-03, 6.4392e-03, 6.2637e-03, 6.1684e-03,\n",
       "            6.1455e-03, 6.0730e-03, 5.7983e-03, 5.6419e-03, 5.3635e-03,\n",
       "            5.3215e-03, 5.1994e-03, 5.1193e-03, 4.7913e-03, 4.7569e-03,\n",
       "            4.6997e-03, 4.3983e-03, 4.0855e-03, 3.4027e-03, 3.2101e-03,\n",
       "            3.0746e-03, 2.7905e-03, 2.5311e-03, 2.3499e-03, 2.2526e-03,\n",
       "            2.1992e-03, 2.1572e-03, 2.1400e-03, 2.1324e-03, 2.0905e-03,\n",
       "            1.9341e-03, 1.9045e-03, 1.7004e-03, 1.5736e-03, 1.5612e-03,\n",
       "            1.4496e-03, 1.4381e-03, 1.4324e-03, 1.3885e-03, 1.3351e-03,\n",
       "            1.3199e-03, 1.2693e-03, 1.2493e-03, 1.2350e-03, 1.1511e-03,\n",
       "            1.1292e-03, 1.1206e-03, 1.0567e-03, 9.5081e-04, 8.7976e-04,\n",
       "            7.3195e-04, 6.8521e-04, 6.7472e-04, 6.0225e-04, 4.6372e-04,\n",
       "            4.5466e-04, 4.0936e-04, 4.0770e-04, 4.0293e-04, 3.1495e-04,\n",
       "            2.9826e-04, 2.6131e-04, 2.4152e-04, 2.3973e-04, 2.3413e-04,\n",
       "            1.6999e-04, 1.6606e-04, 1.2147e-04, 2.3544e-05, 1.8358e-05,\n",
       "            5.9605e-06], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.7348485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.2457627 , 0.2542373 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.08333334, 0.09848485, 0.10606061, 0.11363637, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.17424242,\n",
       "            0.18939394, 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9951e-01, 9.9805e-01, 9.9121e-01, 9.8975e-01,\n",
       "            9.8779e-01, 9.8730e-01, 9.8682e-01, 9.8584e-01, 9.8535e-01,\n",
       "            9.8438e-01, 9.8340e-01, 9.8193e-01, 9.8096e-01, 9.8047e-01,\n",
       "            9.7949e-01, 9.7705e-01, 9.7559e-01, 9.7266e-01, 9.7119e-01,\n",
       "            9.7070e-01, 9.6875e-01, 9.6387e-01, 9.6045e-01, 9.5850e-01,\n",
       "            9.5801e-01, 9.5703e-01, 9.5654e-01, 9.5508e-01, 9.5312e-01,\n",
       "            9.3848e-01, 9.3555e-01, 9.3262e-01, 9.3115e-01, 9.2578e-01,\n",
       "            9.1748e-01, 9.1650e-01, 9.1602e-01, 9.1406e-01, 9.1260e-01,\n",
       "            9.1064e-01, 9.0625e-01, 9.0430e-01, 8.9746e-01, 8.9453e-01,\n",
       "            8.9307e-01, 8.9209e-01, 8.9014e-01, 8.8916e-01, 8.7939e-01,\n",
       "            8.7012e-01, 8.6230e-01, 8.5107e-01, 8.4668e-01, 8.4619e-01,\n",
       "            8.4277e-01, 8.3203e-01, 8.3154e-01, 8.2812e-01, 8.2666e-01,\n",
       "            8.2520e-01, 8.1689e-01, 8.1543e-01, 8.1494e-01, 8.1250e-01,\n",
       "            8.0762e-01, 8.0713e-01, 8.0322e-01, 7.9883e-01, 7.9346e-01,\n",
       "            7.8809e-01, 7.8271e-01, 7.7930e-01, 7.3730e-01, 7.2363e-01,\n",
       "            7.0215e-01, 6.9336e-01, 6.7725e-01, 6.6992e-01, 6.6650e-01,\n",
       "            6.2988e-01, 6.1230e-01, 6.0547e-01, 5.5664e-01, 5.5566e-01,\n",
       "            5.3076e-01, 5.2588e-01, 5.2295e-01, 5.2002e-01, 5.1514e-01,\n",
       "            5.0439e-01, 4.9146e-01, 4.8730e-01, 4.6509e-01, 4.6484e-01,\n",
       "            4.6021e-01, 4.2944e-01, 3.8403e-01, 3.6963e-01, 3.3789e-01,\n",
       "            3.3496e-01, 3.1763e-01, 3.0591e-01, 3.0225e-01, 2.8320e-01,\n",
       "            2.7173e-01, 2.7002e-01, 2.6318e-01, 2.4402e-01, 2.3145e-01,\n",
       "            2.2607e-01, 2.2437e-01, 1.7639e-01, 1.5149e-01, 1.4490e-01,\n",
       "            1.3074e-01, 1.0950e-01, 9.0271e-02, 8.8684e-02, 8.6304e-02,\n",
       "            8.2520e-02, 7.6965e-02, 7.1350e-02, 6.5002e-02, 6.2805e-02,\n",
       "            6.2225e-02, 5.4413e-02, 5.3589e-02, 4.9774e-02, 3.9703e-02,\n",
       "            3.5614e-02, 3.0731e-02, 2.3102e-02, 2.2156e-02, 2.0096e-02,\n",
       "            1.9608e-02, 1.9562e-02, 1.6464e-02, 1.6022e-02, 1.5900e-02,\n",
       "            1.5671e-02, 1.5076e-02, 1.5015e-02, 1.4503e-02, 1.4282e-02,\n",
       "            1.3954e-02, 1.1292e-02, 1.0452e-02, 9.8953e-03, 9.5596e-03,\n",
       "            9.4528e-03, 9.1248e-03, 8.8120e-03, 8.6746e-03, 7.7858e-03,\n",
       "            7.2899e-03, 7.0953e-03, 6.8779e-03, 6.6681e-03, 6.6147e-03,\n",
       "            6.4392e-03, 5.7297e-03, 5.6419e-03, 5.6000e-03, 5.1613e-03,\n",
       "            5.1193e-03, 4.7569e-03, 4.4174e-03, 4.3983e-03, 4.2648e-03,\n",
       "            4.0398e-03, 3.9749e-03, 3.8853e-03, 3.8090e-03, 3.7956e-03,\n",
       "            3.7079e-03, 3.6926e-03, 3.6068e-03, 3.5248e-03, 3.4695e-03,\n",
       "            3.2730e-03, 3.2349e-03, 3.2101e-03, 2.9697e-03, 2.9354e-03,\n",
       "            2.8896e-03, 2.8782e-03, 2.4433e-03, 1.9646e-03, 1.9045e-03,\n",
       "            1.7824e-03, 1.5793e-03, 1.5364e-03, 1.5192e-03, 1.4896e-03,\n",
       "            1.4610e-03, 1.4381e-03, 1.4267e-03, 1.2159e-03, 1.1921e-03,\n",
       "            1.0729e-03, 1.0605e-03, 1.0443e-03, 1.0319e-03, 9.5844e-04,\n",
       "            9.3269e-04, 8.8978e-04, 8.8644e-04, 8.1682e-04, 8.1062e-04,\n",
       "            8.0109e-04, 7.9155e-04, 7.6723e-04, 7.6437e-04, 7.5817e-04,\n",
       "            7.2098e-04, 7.1239e-04, 6.5899e-04, 5.7459e-04, 4.9162e-04,\n",
       "            4.6372e-04, 4.3225e-04, 3.8147e-04, 3.4189e-04, 2.5320e-04,\n",
       "            2.2697e-04, 2.2173e-04, 1.9872e-04, 1.9562e-04, 1.5473e-04,\n",
       "            1.5116e-04, 1.4317e-04, 1.3876e-04, 1.1593e-04, 1.1325e-04,\n",
       "            7.9036e-05, 7.7248e-05, 5.6088e-05, 9.9540e-06, 7.0930e-06,\n",
       "            2.1458e-06], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.68939394, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.27966103, 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.31060606, 0.3181818 , 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9951e-01, 9.9805e-01, 9.9072e-01, 9.8975e-01,\n",
       "            9.8926e-01, 9.8779e-01, 9.8633e-01, 9.8584e-01, 9.8535e-01,\n",
       "            9.8486e-01, 9.8438e-01, 9.8389e-01, 9.8340e-01, 9.8291e-01,\n",
       "            9.8145e-01, 9.7803e-01, 9.7754e-01, 9.7656e-01, 9.7314e-01,\n",
       "            9.7217e-01, 9.7168e-01, 9.6729e-01, 9.6631e-01, 9.6582e-01,\n",
       "            9.6533e-01, 9.6191e-01, 9.5947e-01, 9.5752e-01, 9.5410e-01,\n",
       "            9.4922e-01, 9.4824e-01, 9.4775e-01, 9.3848e-01, 9.3555e-01,\n",
       "            9.2432e-01, 9.1992e-01, 9.1699e-01, 9.1504e-01, 9.0918e-01,\n",
       "            9.0576e-01, 9.0527e-01, 8.9990e-01, 8.9893e-01, 8.9307e-01,\n",
       "            8.8330e-01, 8.8135e-01, 8.8037e-01, 8.7939e-01, 8.7744e-01,\n",
       "            8.7012e-01, 8.6475e-01, 8.5547e-01, 8.5352e-01, 8.4326e-01,\n",
       "            8.3789e-01, 8.3691e-01, 8.2275e-01, 8.1787e-01, 8.1738e-01,\n",
       "            8.1494e-01, 8.1348e-01, 8.0371e-01, 7.8955e-01, 7.8564e-01,\n",
       "            7.8369e-01, 7.7930e-01, 7.7490e-01, 7.7344e-01, 7.6660e-01,\n",
       "            7.6221e-01, 7.5439e-01, 7.5146e-01, 7.5098e-01, 7.4414e-01,\n",
       "            6.7969e-01, 6.6895e-01, 6.5918e-01, 6.5381e-01, 6.4111e-01,\n",
       "            6.4014e-01, 6.1133e-01, 5.7910e-01, 5.5664e-01, 5.4590e-01,\n",
       "            5.2051e-01, 5.2002e-01, 4.9048e-01, 4.7144e-01, 4.6777e-01,\n",
       "            4.6655e-01, 4.5020e-01, 4.4922e-01, 4.4580e-01, 4.3921e-01,\n",
       "            4.1675e-01, 3.9746e-01, 3.8647e-01, 3.8525e-01, 3.2495e-01,\n",
       "            2.9736e-01, 2.7173e-01, 2.5854e-01, 2.5269e-01, 2.5000e-01,\n",
       "            2.2852e-01, 2.2388e-01, 2.1655e-01, 2.1179e-01, 2.0129e-01,\n",
       "            1.7358e-01, 1.6956e-01, 1.5881e-01, 1.4453e-01, 1.0724e-01,\n",
       "            1.0376e-01, 1.0126e-01, 6.9397e-02, 6.7932e-02, 6.4758e-02,\n",
       "            6.1646e-02, 5.9113e-02, 5.4199e-02, 4.7333e-02, 4.4525e-02,\n",
       "            3.7476e-02, 3.7262e-02, 3.5675e-02, 3.5400e-02, 3.3264e-02,\n",
       "            2.7374e-02, 2.5757e-02, 2.2324e-02, 1.4839e-02, 1.3794e-02,\n",
       "            1.3634e-02, 1.1551e-02, 1.0567e-02, 1.0529e-02, 1.0094e-02,\n",
       "            1.0056e-02, 9.7809e-03, 8.7814e-03, 8.3771e-03, 8.0338e-03,\n",
       "            8.0032e-03, 7.7553e-03, 7.4883e-03, 6.6910e-03, 6.0730e-03,\n",
       "            5.6000e-03, 5.5542e-03, 5.2795e-03, 5.1193e-03, 4.9057e-03,\n",
       "            4.6806e-03, 4.3297e-03, 3.9291e-03, 3.8090e-03, 3.7498e-03,\n",
       "            3.6221e-03, 3.4962e-03, 3.4695e-03, 3.2482e-03, 3.0632e-03,\n",
       "            3.0518e-03, 3.0155e-03, 2.8458e-03, 2.4338e-03, 2.1820e-03,\n",
       "            2.1648e-03, 2.1572e-03, 2.1324e-03, 2.1248e-03, 2.0828e-03,\n",
       "            2.0504e-03, 1.9722e-03, 1.9264e-03, 1.8673e-03, 1.8244e-03,\n",
       "            1.7824e-03, 1.7681e-03, 1.7548e-03, 1.6489e-03, 1.6041e-03,\n",
       "            1.5545e-03, 1.5488e-03, 1.4496e-03, 1.3990e-03, 1.1244e-03,\n",
       "            9.6226e-04, 8.9693e-04, 8.6927e-04, 8.4257e-04, 7.8249e-04,\n",
       "            7.5531e-04, 7.4100e-04, 6.2895e-04, 6.1655e-04, 5.8603e-04,\n",
       "            5.7697e-04, 5.2547e-04, 5.1928e-04, 5.1117e-04, 4.7278e-04,\n",
       "            4.5824e-04, 4.2725e-04, 4.1580e-04, 4.0603e-04, 3.9506e-04,\n",
       "            3.5691e-04, 3.5000e-04, 3.4475e-04, 3.3021e-04, 3.1757e-04,\n",
       "            3.0780e-04, 2.9588e-04, 2.2173e-04, 2.1660e-04, 1.8811e-04,\n",
       "            1.5116e-04, 1.2052e-04, 9.6083e-05, 9.3877e-05, 8.2850e-05,\n",
       "            8.1539e-05, 6.9737e-05, 6.2048e-05, 6.1572e-05, 5.7399e-05,\n",
       "            4.4703e-05, 4.4346e-05, 2.9802e-05, 2.9087e-05, 2.0325e-05,\n",
       "            2.9206e-06, 2.2650e-06, 5.9605e-07], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.7348485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7118644 , 0.720339  , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.04545455, 0.06060606, 0.07575758, 0.08333334, 0.09848485,\n",
       "            0.10606061, 0.12121212, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.68939394, 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 1.0000e+00, 9.9902e-01, 9.9512e-01, 9.9365e-01,\n",
       "            9.9316e-01, 9.9219e-01, 9.9121e-01, 9.9023e-01, 9.8975e-01,\n",
       "            9.8926e-01, 9.8828e-01, 9.8779e-01, 9.8584e-01, 9.8438e-01,\n",
       "            9.8145e-01, 9.8096e-01, 9.8047e-01, 9.7754e-01, 9.7607e-01,\n",
       "            9.7461e-01, 9.7314e-01, 9.7217e-01, 9.7021e-01, 9.6973e-01,\n",
       "            9.6924e-01, 9.6533e-01, 9.5557e-01, 9.5361e-01, 9.5312e-01,\n",
       "            9.4727e-01, 9.4385e-01, 9.3994e-01, 9.3896e-01, 9.3213e-01,\n",
       "            9.2969e-01, 9.2725e-01, 9.2627e-01, 9.2578e-01, 9.2383e-01,\n",
       "            9.2041e-01, 9.1992e-01, 9.1650e-01, 9.1113e-01, 9.0771e-01,\n",
       "            9.0137e-01, 8.9551e-01, 8.7695e-01, 8.7549e-01, 8.5986e-01,\n",
       "            8.5938e-01, 8.5547e-01, 8.5107e-01, 8.4912e-01, 8.4814e-01,\n",
       "            8.4424e-01, 8.3887e-01, 8.3691e-01, 8.3398e-01, 8.2764e-01,\n",
       "            8.2568e-01, 8.2520e-01, 8.2178e-01, 8.1885e-01, 8.1396e-01,\n",
       "            8.0908e-01, 8.0273e-01, 7.5928e-01, 7.2998e-01, 7.1045e-01,\n",
       "            7.0752e-01, 6.9922e-01, 6.8555e-01, 6.0498e-01, 6.0352e-01,\n",
       "            5.7764e-01, 5.6689e-01, 5.4492e-01, 5.4150e-01, 5.4102e-01,\n",
       "            5.2002e-01, 5.1562e-01, 5.1025e-01, 4.8853e-01, 4.7461e-01,\n",
       "            4.6729e-01, 4.3506e-01, 4.0332e-01, 3.9893e-01, 3.8745e-01,\n",
       "            3.6353e-01, 2.8491e-01, 2.8223e-01, 2.7588e-01, 2.5928e-01,\n",
       "            2.5195e-01, 2.5024e-01, 2.4329e-01, 2.3401e-01, 2.2974e-01,\n",
       "            2.1375e-01, 2.1252e-01, 1.8237e-01, 1.5625e-01, 1.5454e-01,\n",
       "            1.2421e-01, 1.0376e-01, 9.5520e-02, 7.1350e-02, 6.9519e-02,\n",
       "            6.3232e-02, 6.1188e-02, 5.7709e-02, 5.2124e-02, 4.7516e-02,\n",
       "            4.4586e-02, 3.6835e-02, 3.3478e-02, 3.2654e-02, 3.1311e-02,\n",
       "            2.9541e-02, 2.6917e-02, 2.4933e-02, 2.1698e-02, 1.1116e-02,\n",
       "            1.0780e-02, 1.0651e-02, 1.0330e-02, 9.6741e-03, 9.2316e-03,\n",
       "            8.1863e-03, 7.7553e-03, 7.6065e-03, 7.5760e-03, 7.4883e-03,\n",
       "            7.2594e-03, 7.2327e-03, 7.2060e-03, 6.2180e-03, 5.1994e-03,\n",
       "            4.7569e-03, 4.6272e-03, 4.5052e-03, 4.2992e-03, 4.2305e-03,\n",
       "            3.9597e-03, 3.8853e-03, 3.4962e-03, 3.4294e-03, 3.2730e-03,\n",
       "            3.2349e-03, 2.9354e-03, 2.6207e-03, 2.5616e-03, 2.3689e-03,\n",
       "            2.2964e-03, 2.1648e-03, 1.9798e-03, 1.8826e-03, 1.8311e-03,\n",
       "            1.7414e-03, 1.7004e-03, 1.5917e-03, 1.5669e-03, 1.5430e-03,\n",
       "            1.4668e-03, 1.4553e-03, 1.3943e-03, 1.3666e-03, 1.3514e-03,\n",
       "            1.2741e-03, 1.2693e-03, 1.2646e-03, 1.2445e-03, 1.0986e-03,\n",
       "            1.0862e-03, 9.7370e-04, 9.1124e-04, 9.0408e-04, 7.7009e-04,\n",
       "            7.4387e-04, 7.2098e-04, 6.6423e-04, 6.5899e-04, 6.5374e-04,\n",
       "            5.3358e-04, 4.9543e-04, 4.8971e-04, 4.8590e-04, 4.2892e-04,\n",
       "            3.9506e-04, 3.8290e-04, 3.7861e-04, 3.4189e-04, 3.3665e-04,\n",
       "            3.3545e-04, 3.0780e-04, 2.8467e-04, 2.6536e-04, 2.6321e-04,\n",
       "            2.5320e-04, 2.5129e-04, 2.4343e-04, 2.3234e-04, 1.9562e-04,\n",
       "            1.8525e-04, 1.8239e-04, 1.7536e-04, 1.7130e-04, 1.5116e-04,\n",
       "            1.0973e-04, 9.5367e-05, 7.2539e-05, 5.3883e-05, 4.7565e-05,\n",
       "            4.5061e-05, 4.3631e-05, 3.8505e-05, 3.7909e-05, 2.7955e-05,\n",
       "            2.6286e-05, 2.0921e-05, 2.0325e-05, 1.3411e-05, 1.3113e-05,\n",
       "            9.1791e-06, 1.1921e-06, 8.3447e-07, 1.7881e-07], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.719697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.12711865, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06818182, 0.08333334, 0.09848485,\n",
       "            0.10606061, 0.11363637, 0.12121212, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.20454545, 0.21212122, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.57575756,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 1.0000e+00, 9.9951e-01, 9.9512e-01, 9.9463e-01,\n",
       "            9.9414e-01, 9.9365e-01, 9.9316e-01, 9.9219e-01, 9.9170e-01,\n",
       "            9.9121e-01, 9.8975e-01, 9.8877e-01, 9.8828e-01, 9.8682e-01,\n",
       "            9.8584e-01, 9.8389e-01, 9.8340e-01, 9.8291e-01, 9.8096e-01,\n",
       "            9.8047e-01, 9.7803e-01, 9.7510e-01, 9.7461e-01, 9.7314e-01,\n",
       "            9.7217e-01, 9.6924e-01, 9.6826e-01, 9.6191e-01, 9.6045e-01,\n",
       "            9.5410e-01, 9.5068e-01, 9.4678e-01, 9.4580e-01, 9.4043e-01,\n",
       "            9.3896e-01, 9.3799e-01, 9.3604e-01, 9.3115e-01, 9.3018e-01,\n",
       "            9.2822e-01, 9.2334e-01, 9.1895e-01, 9.1797e-01, 9.1113e-01,\n",
       "            9.0967e-01, 9.0234e-01, 8.9893e-01, 8.7988e-01, 8.7158e-01,\n",
       "            8.6816e-01, 8.6719e-01, 8.6182e-01, 8.6035e-01, 8.5059e-01,\n",
       "            8.4229e-01, 8.3691e-01, 8.3154e-01, 8.2959e-01, 8.2812e-01,\n",
       "            8.2227e-01, 8.2178e-01, 8.1641e-01, 8.1445e-01, 8.1250e-01,\n",
       "            8.0518e-01, 7.9590e-01, 7.3730e-01, 7.1582e-01, 7.0020e-01,\n",
       "            6.9727e-01, 6.9678e-01, 6.9336e-01, 6.6504e-01, 6.0645e-01,\n",
       "            6.0156e-01, 5.7568e-01, 5.7471e-01, 5.4883e-01, 5.2393e-01,\n",
       "            5.2100e-01, 5.1074e-01, 5.0635e-01, 4.9268e-01, 4.8389e-01,\n",
       "            4.7559e-01, 4.6094e-01, 4.3481e-01, 4.2676e-01, 3.9258e-01,\n",
       "            3.6401e-01, 3.4473e-01, 3.0859e-01, 2.7026e-01, 2.6611e-01,\n",
       "            2.5415e-01, 2.2925e-01, 2.2205e-01, 2.1863e-01, 2.1838e-01,\n",
       "            2.1106e-01, 2.0911e-01, 1.7200e-01, 1.6809e-01, 1.6748e-01,\n",
       "            1.4807e-01, 1.2952e-01, 9.6863e-02, 9.3323e-02, 7.5195e-02,\n",
       "            5.9113e-02, 5.7281e-02, 4.8676e-02, 4.7607e-02, 4.4922e-02,\n",
       "            4.0161e-02, 3.8696e-02, 3.8330e-02, 2.9312e-02, 2.6505e-02,\n",
       "            2.4994e-02, 2.1774e-02, 2.0599e-02, 2.0447e-02, 1.7914e-02,\n",
       "            8.2855e-03, 7.9651e-03, 7.2060e-03, 6.8779e-03, 6.6910e-03,\n",
       "            5.5771e-03, 5.4054e-03, 5.3864e-03, 5.2795e-03, 5.0392e-03,\n",
       "            4.9248e-03, 4.8866e-03, 4.4861e-03, 4.4670e-03, 3.5934e-03,\n",
       "            3.4428e-03, 3.3512e-03, 3.2101e-03, 2.9583e-03, 2.8000e-03,\n",
       "            2.7256e-03, 2.3975e-03, 2.3594e-03, 2.2430e-03, 2.0828e-03,\n",
       "            1.9798e-03, 1.8826e-03, 1.7204e-03, 1.5669e-03, 1.5488e-03,\n",
       "            1.4210e-03, 1.4162e-03, 1.2398e-03, 1.1835e-03, 1.1654e-03,\n",
       "            1.1377e-03, 1.1072e-03, 1.0900e-03, 1.0815e-03, 1.0691e-03,\n",
       "            1.0405e-03, 1.0042e-03, 9.9277e-04, 8.7595e-04, 8.2636e-04,\n",
       "            8.0729e-04, 7.8535e-04, 7.2384e-04, 7.1526e-04, 7.0143e-04,\n",
       "            6.6948e-04, 6.0701e-04, 5.9748e-04, 5.8842e-04, 5.3358e-04,\n",
       "            5.0354e-04, 4.9353e-04, 4.7112e-04, 4.5466e-04, 4.3559e-04,\n",
       "            4.0293e-04, 3.7551e-04, 3.4881e-04, 2.9135e-04, 2.8467e-04,\n",
       "            2.7800e-04, 2.5511e-04, 2.4533e-04, 2.2697e-04, 2.2173e-04,\n",
       "            1.9872e-04, 1.9717e-04, 1.9109e-04, 1.7405e-04, 1.5593e-04,\n",
       "            1.4770e-04, 1.4424e-04, 1.4317e-04, 1.3447e-04, 1.3030e-04,\n",
       "            1.2827e-04, 1.2732e-04, 1.1504e-04, 9.6858e-05, 9.3877e-05,\n",
       "            9.1732e-05, 8.4817e-05, 7.9691e-05, 5.0247e-05, 4.9114e-05,\n",
       "            3.1710e-05, 2.6047e-05, 2.3007e-05, 1.9372e-05, 1.8477e-05,\n",
       "            1.6689e-05, 1.6212e-05, 1.1742e-05, 1.1206e-05, 9.0003e-06,\n",
       "            8.4639e-06, 5.6028e-06, 5.4836e-06, 3.8147e-06, 4.7684e-07,\n",
       "            2.3842e-07, 5.9605e-08], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.72727275, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.04545455,\n",
       "            0.0530303 , 0.06818182, 0.07575758, 0.08333334, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 1.0000e+00, 9.9951e-01, 9.9658e-01, 9.9609e-01,\n",
       "            9.9561e-01, 9.9512e-01, 9.9463e-01, 9.9414e-01, 9.9365e-01,\n",
       "            9.9268e-01, 9.9170e-01, 9.9121e-01, 9.9072e-01, 9.8926e-01,\n",
       "            9.8828e-01, 9.8779e-01, 9.8682e-01, 9.8535e-01, 9.8291e-01,\n",
       "            9.8096e-01, 9.8047e-01, 9.7852e-01, 9.7803e-01, 9.7607e-01,\n",
       "            9.7363e-01, 9.7021e-01, 9.6924e-01, 9.6289e-01, 9.6045e-01,\n",
       "            9.5801e-01, 9.5361e-01, 9.5215e-01, 9.5166e-01, 9.4727e-01,\n",
       "            9.4629e-01, 9.4189e-01, 9.3945e-01, 9.3701e-01, 9.3311e-01,\n",
       "            9.3164e-01, 9.3066e-01, 9.2529e-01, 9.1895e-01, 9.1797e-01,\n",
       "            9.1406e-01, 8.9209e-01, 8.8916e-01, 8.8867e-01, 8.8574e-01,\n",
       "            8.8232e-01, 8.6865e-01, 8.5645e-01, 8.5254e-01, 8.5107e-01,\n",
       "            8.5010e-01, 8.4717e-01, 8.4619e-01, 8.4570e-01, 8.3936e-01,\n",
       "            8.3252e-01, 8.3203e-01, 8.2812e-01, 8.2422e-01, 8.2129e-01,\n",
       "            8.1250e-01, 8.0908e-01, 7.6025e-01, 7.4219e-01, 7.1582e-01,\n",
       "            7.1143e-01, 7.1094e-01, 7.0947e-01, 6.8457e-01, 6.3135e-01,\n",
       "            6.0938e-01, 6.0449e-01, 6.0303e-01, 5.4346e-01, 5.4053e-01,\n",
       "            5.3369e-01, 5.2783e-01, 5.2588e-01, 5.1758e-01, 4.9072e-01,\n",
       "            4.8755e-01, 4.6338e-01, 4.4092e-01, 4.3506e-01, 3.9307e-01,\n",
       "            3.4937e-01, 3.4277e-01, 3.0664e-01, 2.7563e-01, 2.7295e-01,\n",
       "            2.4402e-01, 2.3145e-01, 2.2168e-01, 2.1497e-01, 2.0752e-01,\n",
       "            2.0154e-01, 1.9092e-01, 1.6602e-01, 1.5979e-01, 1.5027e-01,\n",
       "            1.4404e-01, 1.1279e-01, 9.1248e-02, 8.5083e-02, 6.1188e-02,\n",
       "            5.3711e-02, 5.2032e-02, 4.2023e-02, 4.0009e-02, 3.9337e-02,\n",
       "            3.6621e-02, 3.5278e-02, 2.9755e-02, 2.5513e-02, 2.3331e-02,\n",
       "            2.2507e-02, 2.0065e-02, 1.9241e-02, 1.8295e-02, 1.5961e-02,\n",
       "            1.5305e-02, 6.9046e-03, 5.9814e-03, 5.6419e-03, 4.8485e-03,\n",
       "            4.4861e-03, 4.4518e-03, 4.3983e-03, 4.3488e-03, 4.2000e-03,\n",
       "            3.8853e-03, 3.8700e-03, 3.5515e-03, 3.3627e-03, 3.3245e-03,\n",
       "            3.2730e-03, 3.1605e-03, 2.8000e-03, 2.7370e-03, 2.6627e-03,\n",
       "            2.2793e-03, 2.1915e-03, 2.0905e-03, 1.8749e-03, 1.8387e-03,\n",
       "            1.7138e-03, 1.5249e-03, 1.4954e-03, 1.2894e-03, 1.2789e-03,\n",
       "            1.2693e-03, 9.8515e-04, 9.6226e-04, 9.0742e-04, 8.8978e-04,\n",
       "            8.8310e-04, 8.3923e-04, 8.2970e-04, 7.8869e-04, 7.4387e-04,\n",
       "            7.2956e-04, 7.2384e-04, 7.0143e-04, 6.9618e-04, 6.7711e-04,\n",
       "            6.2370e-04, 6.2132e-04, 5.7697e-04, 4.6730e-04, 4.6563e-04,\n",
       "            4.2224e-04, 4.1580e-04, 4.1413e-04, 4.0126e-04, 3.9363e-04,\n",
       "            3.5000e-04, 3.2496e-04, 3.2258e-04, 3.1257e-04, 3.0065e-04,\n",
       "            2.9826e-04, 2.9588e-04, 2.7800e-04, 2.7370e-04, 2.6941e-04,\n",
       "            2.5320e-04, 2.2173e-04, 1.9407e-04, 1.8966e-04, 1.6093e-04,\n",
       "            1.4770e-04, 1.4544e-04, 1.4424e-04, 1.3447e-04, 1.2827e-04,\n",
       "            1.2338e-04, 1.1235e-04, 1.0973e-04, 1.0073e-04, 9.2447e-05,\n",
       "            8.5473e-05, 7.8440e-05, 7.7248e-05, 7.0333e-05, 6.3002e-05,\n",
       "            6.0141e-05, 5.8293e-05, 5.0664e-05, 4.8697e-05, 4.8339e-05,\n",
       "            4.0352e-05, 2.9087e-05, 2.3544e-05, 1.4722e-05, 1.4186e-05,\n",
       "            1.2815e-05, 8.5235e-06, 8.1658e-06, 7.2718e-06, 7.0333e-06,\n",
       "            5.0664e-06, 4.8876e-06, 4.0531e-06, 3.6955e-06, 2.4438e-06,\n",
       "            2.3842e-06, 1.6689e-06, 1.7881e-07, 5.9605e-08, 0.0000e+00],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.7121212, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9661017 , 0.9745763 , 0.9830508 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03787879,\n",
       "            0.06060606, 0.06818182, 0.07575758, 0.08333334, 0.10606061,\n",
       "            0.12121212, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.17424242, 0.18181819, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.32575756, 0.33333334, 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 1.0000e+00, 9.9951e-01, 9.9805e-01, 9.9707e-01,\n",
       "            9.9609e-01, 9.9561e-01, 9.9512e-01, 9.9463e-01, 9.9414e-01,\n",
       "            9.9316e-01, 9.9268e-01, 9.9219e-01, 9.9170e-01, 9.9121e-01,\n",
       "            9.8926e-01, 9.8877e-01, 9.8682e-01, 9.8633e-01, 9.8584e-01,\n",
       "            9.8486e-01, 9.8389e-01, 9.8193e-01, 9.7852e-01, 9.7754e-01,\n",
       "            9.7266e-01, 9.7217e-01, 9.6631e-01, 9.6533e-01, 9.6289e-01,\n",
       "            9.5312e-01, 9.4629e-01, 9.4482e-01, 9.4434e-01, 9.4385e-01,\n",
       "            9.4238e-01, 9.3896e-01, 9.3848e-01, 9.3799e-01, 9.3506e-01,\n",
       "            9.3018e-01, 9.1699e-01, 9.0186e-01, 8.9551e-01, 8.7695e-01,\n",
       "            8.7549e-01, 8.7451e-01, 8.7305e-01, 8.6670e-01, 8.6426e-01,\n",
       "            8.6133e-01, 8.5938e-01, 8.5254e-01, 8.4814e-01, 8.4180e-01,\n",
       "            8.3740e-01, 8.3496e-01, 8.2666e-01, 8.2129e-01, 8.2080e-01,\n",
       "            8.1738e-01, 7.7979e-01, 7.5195e-01, 7.4658e-01, 7.4609e-01,\n",
       "            7.2607e-01, 7.0020e-01, 6.9141e-01, 5.7666e-01, 5.7080e-01,\n",
       "            5.6494e-01, 5.6006e-01, 5.5273e-01, 5.5029e-01, 5.3955e-01,\n",
       "            5.0879e-01, 4.9365e-01, 4.9219e-01, 4.5972e-01, 4.4312e-01,\n",
       "            4.3701e-01, 4.2651e-01, 4.1064e-01, 3.5840e-01, 3.4888e-01,\n",
       "            3.4766e-01, 2.9785e-01, 2.4768e-01, 2.1252e-01, 2.0959e-01,\n",
       "            2.0898e-01, 2.0557e-01, 1.8701e-01, 1.6956e-01, 1.6772e-01,\n",
       "            1.5918e-01, 1.4685e-01, 1.1951e-01, 1.1536e-01, 1.0486e-01,\n",
       "            1.0193e-01, 7.7393e-02, 7.4341e-02, 5.3894e-02, 4.2633e-02,\n",
       "            3.4302e-02, 3.2654e-02, 3.0731e-02, 2.9648e-02, 2.3193e-02,\n",
       "            2.2934e-02, 1.9562e-02, 1.7242e-02, 1.6922e-02, 1.5839e-02,\n",
       "            1.3847e-02, 1.3535e-02, 1.2337e-02, 1.2146e-02, 1.1505e-02,\n",
       "            4.5395e-03, 4.2496e-03, 3.9749e-03, 3.2234e-03, 3.1471e-03,\n",
       "            2.8343e-03, 2.8000e-03, 2.5806e-03, 2.5501e-03, 2.3327e-03,\n",
       "            2.3232e-03, 2.2793e-03, 2.2697e-03, 2.1400e-03, 2.0580e-03,\n",
       "            1.9951e-03, 1.9722e-03, 1.5974e-03, 1.5068e-03, 1.4839e-03,\n",
       "            1.4610e-03, 1.2550e-03, 1.1740e-03, 1.0166e-03, 9.9659e-04,\n",
       "            8.3923e-04, 8.1348e-04, 7.8869e-04, 6.3133e-04, 5.9986e-04,\n",
       "            5.9557e-04, 5.6362e-04, 5.4216e-04, 5.3358e-04, 4.9734e-04,\n",
       "            4.6563e-04, 4.4775e-04, 4.1890e-04, 4.0936e-04, 3.9983e-04,\n",
       "            3.6836e-04, 3.6693e-04, 3.5429e-04, 3.5000e-04, 3.1996e-04,\n",
       "            2.8014e-04, 2.6727e-04, 2.5725e-04, 2.3973e-04, 2.3413e-04,\n",
       "            2.1994e-04, 2.1660e-04, 2.0182e-04, 1.9717e-04, 1.8966e-04,\n",
       "            1.8096e-04, 1.6868e-04, 1.6475e-04, 1.6093e-04, 1.4997e-04,\n",
       "            1.4770e-04, 1.4198e-04, 1.2732e-04, 1.2052e-04, 1.1325e-04,\n",
       "            1.1063e-04, 9.2447e-05, 8.4817e-05, 8.3506e-05, 7.2539e-05,\n",
       "            7.0333e-05, 6.9737e-05, 6.2048e-05, 6.1572e-05, 5.0247e-05,\n",
       "            4.7565e-05, 4.7207e-05, 4.6849e-05, 4.0710e-05, 3.7909e-05,\n",
       "            3.1173e-05, 3.0220e-05, 2.8849e-05, 2.7537e-05, 2.5868e-05,\n",
       "            2.5690e-05, 2.4498e-05, 2.3901e-05, 1.7643e-05, 1.4722e-05,\n",
       "            1.0133e-05, 7.1526e-06, 6.1393e-06, 5.6624e-06, 3.4571e-06,\n",
       "            3.1590e-06, 2.9802e-06, 2.8014e-06, 1.9670e-06, 1.7285e-06,\n",
       "            1.4901e-06, 9.5367e-07, 6.5565e-07, 5.9605e-08, 0.0000e+00],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.719697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9661017 , 0.9745763 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.07575758, 0.09090909, 0.09848485,\n",
       "            0.11363637, 0.12121212, 0.13636364, 0.15151516, 0.1590909 ,\n",
       "            0.17424242, 0.18181819, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25757575,\n",
       "            0.2651515 , 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 1.0000e+00, 9.9951e-01, 9.9854e-01, 9.9805e-01,\n",
       "            9.9756e-01, 9.9707e-01, 9.9658e-01, 9.9609e-01, 9.9561e-01,\n",
       "            9.9512e-01, 9.9463e-01, 9.9414e-01, 9.9316e-01, 9.9268e-01,\n",
       "            9.9219e-01, 9.9170e-01, 9.9023e-01, 9.8926e-01, 9.8828e-01,\n",
       "            9.8730e-01, 9.8633e-01, 9.8584e-01, 9.8535e-01, 9.8145e-01,\n",
       "            9.8047e-01, 9.7949e-01, 9.7656e-01, 9.7217e-01, 9.6680e-01,\n",
       "            9.6631e-01, 9.6484e-01, 9.5703e-01, 9.5508e-01, 9.5459e-01,\n",
       "            9.5264e-01, 9.5117e-01, 9.5020e-01, 9.4873e-01, 9.4775e-01,\n",
       "            9.4434e-01, 9.4385e-01, 9.4336e-01, 9.4287e-01, 9.1846e-01,\n",
       "            9.1064e-01, 9.0088e-01, 8.9209e-01, 8.8770e-01, 8.8672e-01,\n",
       "            8.8379e-01, 8.8232e-01, 8.8184e-01, 8.8135e-01, 8.7158e-01,\n",
       "            8.7061e-01, 8.6523e-01, 8.6182e-01, 8.5986e-01, 8.5059e-01,\n",
       "            8.5010e-01, 8.4961e-01, 8.4814e-01, 8.4180e-01, 8.3154e-01,\n",
       "            8.3057e-01, 8.2568e-01, 8.1152e-01, 8.0225e-01, 7.8906e-01,\n",
       "            7.8369e-01, 7.4561e-01, 7.4365e-01, 7.1924e-01, 7.1436e-01,\n",
       "            6.6113e-01, 6.0498e-01, 5.9961e-01, 5.8203e-01, 5.5664e-01,\n",
       "            5.2490e-01, 5.2051e-01, 5.1562e-01, 5.1270e-01, 5.0342e-01,\n",
       "            4.9585e-01, 4.4214e-01, 4.2578e-01, 4.2529e-01, 4.1211e-01,\n",
       "            3.8721e-01, 3.6401e-01, 3.5474e-01, 3.4961e-01, 2.9102e-01,\n",
       "            2.5879e-01, 2.1387e-01, 1.9812e-01, 1.9641e-01, 1.7383e-01,\n",
       "            1.6711e-01, 1.4502e-01, 1.3489e-01, 1.3306e-01, 1.3000e-01,\n",
       "            1.0431e-01, 9.9792e-02, 8.6914e-02, 8.4351e-02, 7.0801e-02,\n",
       "            6.4636e-02, 5.0995e-02, 3.7598e-02, 2.7740e-02, 2.6962e-02,\n",
       "            2.4750e-02, 1.8295e-02, 1.5839e-02, 1.5305e-02, 1.4900e-02,\n",
       "            1.4732e-02, 1.4336e-02, 1.3428e-02, 1.0490e-02, 9.9335e-03,\n",
       "            8.1253e-03, 7.8125e-03, 7.4310e-03, 3.6354e-03, 3.2864e-03,\n",
       "            2.4147e-03, 2.3327e-03, 2.3136e-03, 2.1400e-03, 1.9646e-03,\n",
       "            1.9188e-03, 1.7071e-03, 1.6813e-03, 1.6289e-03, 1.4610e-03,\n",
       "            1.3514e-03, 1.2894e-03, 1.2550e-03, 1.1787e-03, 1.1511e-03,\n",
       "            1.0986e-03, 1.0691e-03, 1.0481e-03, 8.6594e-04, 8.3303e-04,\n",
       "            8.2970e-04, 8.2302e-04, 7.1239e-04, 5.5265e-04, 5.3787e-04,\n",
       "            5.2738e-04, 4.7278e-04, 4.4942e-04, 4.0293e-04, 3.9506e-04,\n",
       "            3.6407e-04, 3.2496e-04, 3.1257e-04, 3.1018e-04, 2.6727e-04,\n",
       "            2.5129e-04, 2.3973e-04, 2.2697e-04, 2.2519e-04, 2.1827e-04,\n",
       "            2.0993e-04, 1.9872e-04, 1.8239e-04, 1.6999e-04, 1.6344e-04,\n",
       "            1.4997e-04, 1.4091e-04, 1.3661e-04, 1.3232e-04, 1.2827e-04,\n",
       "            1.2636e-04, 1.2338e-04, 1.1867e-04, 1.1325e-04, 1.1235e-04,\n",
       "            1.0228e-04, 1.0151e-04, 9.1732e-05, 9.0301e-05, 8.2850e-05,\n",
       "            7.8440e-05, 7.4267e-05, 6.8665e-05, 6.6578e-05, 6.1572e-05,\n",
       "            5.4777e-05, 4.9889e-05, 4.9114e-05, 4.2677e-05, 4.1008e-05,\n",
       "            3.8803e-05, 3.5346e-05, 2.7120e-05, 2.6703e-05, 2.6286e-05,\n",
       "            2.5690e-05, 2.2471e-05, 1.9670e-05, 1.7226e-05, 1.6570e-05,\n",
       "            1.5438e-05, 1.4305e-05, 1.3947e-05, 1.3828e-05, 1.3292e-05,\n",
       "            1.2815e-05, 1.1683e-05, 8.4043e-06, 7.7486e-06, 4.7684e-06,\n",
       "            3.5167e-06, 3.0398e-06, 2.5034e-06, 1.4901e-06, 1.3709e-06,\n",
       "            1.3113e-06, 1.1921e-06, 8.9407e-07, 8.3447e-07, 7.7486e-07,\n",
       "            6.5565e-07, 4.1723e-07, 2.9802e-07, 0.0000e+00], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.7121212, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.91525424, 0.94067794,\n",
       "            0.9491525 , 0.9661017 , 0.9745763 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01515152, 0.02272727, 0.03787879, 0.06060606,\n",
       "            0.06818182, 0.08333334, 0.10606061, 0.11363637, 0.12878788,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.1969697 , 0.20454545, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.34848484, 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 1.0000e+00, 9.9902e-01, 9.9854e-01, 9.9805e-01,\n",
       "            9.9756e-01, 9.9707e-01, 9.9658e-01, 9.9609e-01, 9.9561e-01,\n",
       "            9.9512e-01, 9.9463e-01, 9.9414e-01, 9.9365e-01, 9.9316e-01,\n",
       "            9.9170e-01, 9.9072e-01, 9.9023e-01, 9.8975e-01, 9.8779e-01,\n",
       "            9.8730e-01, 9.8633e-01, 9.8584e-01, 9.8145e-01, 9.7852e-01,\n",
       "            9.7656e-01, 9.7412e-01, 9.7070e-01, 9.6729e-01, 9.6436e-01,\n",
       "            9.6240e-01, 9.5850e-01, 9.5801e-01, 9.5459e-01, 9.5361e-01,\n",
       "            9.5215e-01, 9.4629e-01, 9.4238e-01, 9.3262e-01, 9.2529e-01,\n",
       "            9.2090e-01, 9.0967e-01, 9.0430e-01, 9.0039e-01, 8.9941e-01,\n",
       "            8.9404e-01, 8.8379e-01, 8.8232e-01, 8.8184e-01, 8.8086e-01,\n",
       "            8.7793e-01, 8.7451e-01, 8.6963e-01, 8.6182e-01, 8.5840e-01,\n",
       "            8.5596e-01, 8.5352e-01, 8.4863e-01, 8.4619e-01, 8.4229e-01,\n",
       "            8.3398e-01, 8.0176e-01, 7.5342e-01, 7.4463e-01, 7.3340e-01,\n",
       "            7.2998e-01, 7.1143e-01, 7.0947e-01, 6.0596e-01, 5.7324e-01,\n",
       "            5.6982e-01, 5.6152e-01, 5.4834e-01, 5.4102e-01, 5.0977e-01,\n",
       "            4.8779e-01, 4.7046e-01, 4.6875e-01, 4.4141e-01, 4.2920e-01,\n",
       "            4.2773e-01, 4.2334e-01, 3.6646e-01, 3.3252e-01, 2.7783e-01,\n",
       "            2.6611e-01, 2.0862e-01, 1.9055e-01, 1.8567e-01, 1.8286e-01,\n",
       "            1.8079e-01, 1.4465e-01, 1.4111e-01, 1.3672e-01, 1.3306e-01,\n",
       "            1.1676e-01, 1.0724e-01, 8.9783e-02, 7.5745e-02, 6.6956e-02,\n",
       "            5.3711e-02, 3.4027e-02, 3.1143e-02, 2.1942e-02, 2.1744e-02,\n",
       "            2.0966e-02, 1.8097e-02, 1.5541e-02, 1.4557e-02, 1.2009e-02,\n",
       "            1.0094e-02, 9.0866e-03, 7.7248e-03, 7.4043e-03, 6.9847e-03,\n",
       "            5.7983e-03, 2.7466e-03, 2.5311e-03, 2.0580e-03, 2.0275e-03,\n",
       "            1.5612e-03, 1.4381e-03, 1.3199e-03, 1.2598e-03, 1.1606e-03,\n",
       "            1.0815e-03, 1.0567e-03, 1.0166e-03, 9.3985e-04, 9.1839e-04,\n",
       "            9.0408e-04, 8.8978e-04, 8.7595e-04, 8.2302e-04, 7.0143e-04,\n",
       "            6.9332e-04, 6.6948e-04, 6.5136e-04, 5.5075e-04, 4.9734e-04,\n",
       "            4.4417e-04, 3.1257e-04, 3.0303e-04, 2.9826e-04, 2.7585e-04,\n",
       "            2.7370e-04, 2.2876e-04, 2.1315e-04, 1.9872e-04, 1.9562e-04,\n",
       "            1.7679e-04, 1.6999e-04, 1.5962e-04, 1.5473e-04, 1.3554e-04,\n",
       "            1.3137e-04, 1.2934e-04, 1.1593e-04, 1.1235e-04, 1.0639e-04,\n",
       "            1.0556e-04, 8.8215e-05, 8.6129e-05, 8.4817e-05, 8.4162e-05,\n",
       "            7.9691e-05, 7.4267e-05, 7.2002e-05, 6.7115e-05, 6.3539e-05,\n",
       "            6.3002e-05, 6.2048e-05, 5.8293e-05, 5.0247e-05, 4.7207e-05,\n",
       "            4.6849e-05, 4.5776e-05, 4.5419e-05, 3.9160e-05, 3.7074e-05,\n",
       "            3.6776e-05, 3.3736e-05, 3.3498e-05, 2.9981e-05, 2.8610e-05,\n",
       "            2.7299e-05, 2.3007e-05, 1.8060e-05, 1.7643e-05, 1.7524e-05,\n",
       "            1.7345e-05, 1.7226e-05, 1.6987e-05, 1.6332e-05, 1.4305e-05,\n",
       "            1.0967e-05, 1.0729e-05, 8.8215e-06, 8.5831e-06, 6.4969e-06,\n",
       "            6.0201e-06, 5.9009e-06, 5.7817e-06, 5.6624e-06, 5.2452e-06,\n",
       "            4.7684e-06, 3.5763e-06, 2.0862e-06, 1.9073e-06, 1.7881e-06,\n",
       "            1.0133e-06, 5.9605e-07, 5.3644e-07, 4.7684e-07, 2.9802e-07,\n",
       "            2.3842e-07, 1.7881e-07, 1.1921e-07, 0.0000e+00], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.7348485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.33050847, 0.33898306,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.89830506, 0.91525424, 0.9491525 ,\n",
       "            0.9745763 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01515152, 0.02272727, 0.04545455, 0.07575758,\n",
       "            0.10606061, 0.12878788, 0.14393939, 0.1590909 , 0.17424242,\n",
       "            0.18181819, 0.1969697 , 0.20454545, 0.21969697, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.3560606 , 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 1.0000e+00, 9.9951e-01, 9.9902e-01, 9.9854e-01,\n",
       "            9.9805e-01, 9.9756e-01, 9.9707e-01, 9.9609e-01, 9.9561e-01,\n",
       "            9.9463e-01, 9.9414e-01, 9.9365e-01, 9.9316e-01, 9.9219e-01,\n",
       "            9.9170e-01, 9.9121e-01, 9.9072e-01, 9.8779e-01, 9.8486e-01,\n",
       "            9.8438e-01, 9.8340e-01, 9.8291e-01, 9.7803e-01, 9.7461e-01,\n",
       "            9.7412e-01, 9.7314e-01, 9.7266e-01, 9.7119e-01, 9.6826e-01,\n",
       "            9.6680e-01, 9.6582e-01, 9.6191e-01, 9.5459e-01, 9.5166e-01,\n",
       "            9.4678e-01, 9.4336e-01, 9.3896e-01, 9.2920e-01, 9.2822e-01,\n",
       "            9.2285e-01, 9.2188e-01, 9.1650e-01, 9.1406e-01, 9.1260e-01,\n",
       "            9.0332e-01, 9.0088e-01, 8.9697e-01, 8.9600e-01, 8.9355e-01,\n",
       "            8.9307e-01, 8.8965e-01, 8.8721e-01, 8.8184e-01, 8.7842e-01,\n",
       "            8.7500e-01, 8.5352e-01, 8.5059e-01, 8.4424e-01, 7.9248e-01,\n",
       "            7.8564e-01, 7.7588e-01, 7.6416e-01, 7.6123e-01, 7.4316e-01,\n",
       "            7.2803e-01, 6.4941e-01, 6.4600e-01, 6.4258e-01, 6.4160e-01,\n",
       "            6.0303e-01, 5.9814e-01, 5.9668e-01, 5.4248e-01, 5.4199e-01,\n",
       "            5.2734e-01, 5.0879e-01, 4.9512e-01, 4.8120e-01, 4.7729e-01,\n",
       "            4.7437e-01, 4.0356e-01, 3.7329e-01, 3.0151e-01, 2.5610e-01,\n",
       "            2.3596e-01, 2.2888e-01, 2.0215e-01, 2.0166e-01, 1.9519e-01,\n",
       "            1.8005e-01, 1.7822e-01, 1.3257e-01, 1.2988e-01, 1.2927e-01,\n",
       "            1.1536e-01, 1.1438e-01, 7.3059e-02, 6.4758e-02, 5.7709e-02,\n",
       "            5.4993e-02, 3.5736e-02, 2.4429e-02, 2.3239e-02, 2.2461e-02,\n",
       "            2.2324e-02, 1.9302e-02, 1.8646e-02, 1.7776e-02, 1.1597e-02,\n",
       "            1.1551e-02, 9.5215e-03, 9.4147e-03, 9.2697e-03, 9.0866e-03,\n",
       "            8.2550e-03, 8.1863e-03, 4.1504e-03, 2.5120e-03, 2.3689e-03,\n",
       "            1.9264e-03, 1.8530e-03, 1.3943e-03, 1.2445e-03, 1.1835e-03,\n",
       "            1.0986e-03, 1.0443e-03, 1.0242e-03, 9.5081e-04, 8.8644e-04,\n",
       "            8.2302e-04, 7.9155e-04, 7.7915e-04, 7.7009e-04, 7.3195e-04,\n",
       "            7.1526e-04, 5.9986e-04, 5.7936e-04, 5.6601e-04, 5.6362e-04,\n",
       "            4.8590e-04, 4.7278e-04, 4.5300e-04, 3.0065e-04, 2.6131e-04,\n",
       "            2.5511e-04, 2.3055e-04, 2.2697e-04, 1.8966e-04, 1.7262e-04,\n",
       "            1.6475e-04, 1.4651e-04, 1.4198e-04, 1.2827e-04, 1.1867e-04,\n",
       "            1.1414e-04, 1.0973e-04, 9.6858e-05, 9.6083e-05, 9.3877e-05,\n",
       "            9.0301e-05, 7.3135e-05, 7.0333e-05, 6.7592e-05, 6.3539e-05,\n",
       "            6.2525e-05, 5.8770e-05, 5.7817e-05, 5.0247e-05, 4.8339e-05,\n",
       "            4.0352e-05, 3.9160e-05, 3.7074e-05, 3.6180e-05, 3.5644e-05,\n",
       "            3.3736e-05, 3.3200e-05, 3.2425e-05, 2.8431e-05, 2.6047e-05,\n",
       "            2.5868e-05, 2.5690e-05, 2.4319e-05, 2.1935e-05, 2.0921e-05,\n",
       "            2.0325e-05, 1.9252e-05, 1.7643e-05, 1.4484e-05, 1.3709e-05,\n",
       "            1.3649e-05, 1.3411e-05, 1.3232e-05, 1.0729e-05, 8.8811e-06,\n",
       "            8.8215e-06, 8.6427e-06, 8.1658e-06, 7.9274e-06, 6.4969e-06,\n",
       "            4.1127e-06, 3.3975e-06, 3.1590e-06, 2.9206e-06, 2.8610e-06,\n",
       "            2.6226e-06, 2.3246e-06, 1.6093e-06, 1.4305e-06, 1.1921e-06,\n",
       "            8.3447e-07, 4.1723e-07, 2.3842e-07, 1.7881e-07, 1.1921e-07,\n",
       "            5.9605e-08, 0.0000e+00], dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(1., dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "            0.10833333, 0.10833333, 0.11666667, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15833333, 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.18333334, 0.18333334, 0.19166666, 0.2       , 0.2       ,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.275     , 0.275     , 0.29166666, 0.3       , 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.33333334, 0.33333334, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.36666667, 0.36666667, 0.36666667,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.425     , 0.425     ,\n",
       "            0.425     , 0.425     , 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.48333332, 0.48333332,\n",
       "            0.49166667, 0.5       , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.80833334, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.95      , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.02307692, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.03076923, 0.03846154, 0.04615385,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.07692308, 0.07692308, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.08461539, 0.09230769,\n",
       "            0.09230769, 0.1       , 0.11538462, 0.12307692, 0.12307692,\n",
       "            0.12307692, 0.13846155, 0.15384616, 0.16923077, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.18461539, 0.18461539, 0.1923077 ,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.22307692, 0.23076923, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.24615385, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2923077 , 0.3       , 0.3       , 0.31538463, 0.32307693,\n",
       "            0.32307693, 0.33076924, 0.35384616, 0.35384616, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46153846, 0.46923077,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.50769234,\n",
       "            0.52307695, 0.5307692 , 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.64615387, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.97692305,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8306, 0.803 , 0.786 , 0.782 , 0.7817, 0.776 , 0.774 ,\n",
       "            0.772 , 0.769 , 0.7686, 0.765 , 0.7646, 0.7617, 0.7603, 0.76  ,\n",
       "            0.7563, 0.756 , 0.7544, 0.7534, 0.7524, 0.7515, 0.751 , 0.7505,\n",
       "            0.75  , 0.749 , 0.748 , 0.747 , 0.746 , 0.7446, 0.743 , 0.742 ,\n",
       "            0.7417, 0.7397, 0.7383, 0.737 , 0.736 , 0.735 , 0.7334, 0.733 ,\n",
       "            0.732 , 0.73  , 0.7295, 0.729 , 0.7285, 0.7275, 0.727 , 0.726 ,\n",
       "            0.725 , 0.7217, 0.7207, 0.72  , 0.719 , 0.718 , 0.7173, 0.716 ,\n",
       "            0.715 , 0.7134, 0.713 , 0.7124, 0.712 , 0.709 , 0.708 , 0.707 ,\n",
       "            0.7065, 0.706 , 0.7056, 0.705 , 0.7036, 0.7026, 0.702 , 0.7017,\n",
       "            0.6997, 0.699 , 0.698 , 0.697 , 0.6963, 0.6953, 0.695 , 0.6943,\n",
       "            0.693 , 0.6914, 0.691 , 0.6904, 0.6895, 0.689 , 0.6885, 0.6875,\n",
       "            0.687 , 0.6865, 0.686 , 0.6855, 0.685 , 0.684 , 0.6836, 0.683 ,\n",
       "            0.682 , 0.68  , 0.6763, 0.675 , 0.6714, 0.67  , 0.6694, 0.669 ,\n",
       "            0.6685, 0.6675, 0.6655, 0.664 , 0.6636, 0.663 , 0.661 , 0.6577,\n",
       "            0.657 , 0.6562, 0.6553, 0.655 , 0.6533, 0.6523, 0.651 , 0.6494,\n",
       "            0.6475, 0.6445, 0.642 , 0.6416, 0.641 , 0.6406, 0.6387, 0.6377,\n",
       "            0.637 , 0.6367, 0.636 , 0.6353, 0.632 , 0.6313, 0.63  , 0.6294,\n",
       "            0.628 , 0.6265, 0.6255, 0.6245, 0.623 , 0.62  , 0.6157, 0.609 ,\n",
       "            0.5967, 0.595 , 0.592 , 0.589 , 0.587 , 0.5864, 0.586 , 0.5796,\n",
       "            0.5786, 0.578 , 0.5776, 0.5767, 0.575 , 0.5737, 0.572 , 0.5713,\n",
       "            0.571 , 0.57  , 0.5693, 0.569 , 0.5684, 0.568 , 0.567 , 0.5664,\n",
       "            0.566 , 0.5654, 0.565 , 0.5645, 0.564 , 0.5635, 0.562 , 0.5615,\n",
       "            0.5605, 0.5596, 0.5586, 0.558 , 0.557 , 0.5566, 0.556 , 0.555 ,\n",
       "            0.5547, 0.5537, 0.5527, 0.5522, 0.5503, 0.5493, 0.549 , 0.5483,\n",
       "            0.547 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(1., dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.01666667, 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.09166667, 0.09166667, 0.09166667, 0.1       ,\n",
       "            0.1       , 0.11666667, 0.11666667, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15833333, 0.16666667, 0.18333334,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.21666667, 0.21666667, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.23333333, 0.24166666, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.275     , 0.275     , 0.275     , 0.28333333,\n",
       "            0.29166666, 0.30833334, 0.30833334, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.31666666, 0.325     , 0.325     ,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.35833332, 0.35833332,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.375     , 0.38333333,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.4       , 0.4       , 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.425     , 0.425     ,\n",
       "            0.425     , 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.7416667 , 0.7583333 ,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.825     , 0.8333333 , 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.02307692, 0.03076923,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.05384615, 0.05384615,\n",
       "            0.06153846, 0.07692308, 0.08461539, 0.09230769, 0.09230769,\n",
       "            0.09230769, 0.09230769, 0.09230769, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.11538462, 0.11538462, 0.12307692,\n",
       "            0.13846155, 0.14615385, 0.16923077, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.18461539, 0.2       , 0.2       , 0.2       ,\n",
       "            0.2       , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.22307692, 0.22307692, 0.23076923, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.2923077 , 0.31538463, 0.33076924,\n",
       "            0.33846155, 0.33846155, 0.35384616, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4       , 0.41538462, 0.43076923, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.53846157, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.5923077 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.63076925, 0.64615387, 0.65384614,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.76153845, 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.97692305,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.963 , 0.9478, 0.947 , 0.936 , 0.9355, 0.9336, 0.932 ,\n",
       "            0.9287, 0.9277, 0.9272, 0.927 , 0.926 , 0.924 , 0.9233, 0.923 ,\n",
       "            0.9214, 0.921 , 0.9204, 0.92  , 0.9194, 0.9155, 0.9146, 0.9136,\n",
       "            0.912 , 0.9116, 0.911 , 0.9106, 0.9097, 0.909 , 0.9087, 0.906 ,\n",
       "            0.9053, 0.905 , 0.9043, 0.904 , 0.9033, 0.903 , 0.9023, 0.9014,\n",
       "            0.9004, 0.9   , 0.899 , 0.898 , 0.8975, 0.8965, 0.895 , 0.8936,\n",
       "            0.893 , 0.8926, 0.891 , 0.8906, 0.89  , 0.8887, 0.8877, 0.886 ,\n",
       "            0.8843, 0.8833, 0.883 , 0.8813, 0.881 , 0.879 , 0.878 , 0.8774,\n",
       "            0.8765, 0.876 , 0.875 , 0.8745, 0.8726, 0.872 , 0.8706, 0.869 ,\n",
       "            0.868 , 0.8677, 0.867 , 0.8667, 0.866 , 0.8647, 0.863 , 0.8623,\n",
       "            0.8613, 0.861 , 0.8604, 0.859 , 0.8584, 0.8574, 0.857 , 0.856 ,\n",
       "            0.849 , 0.848 , 0.845 , 0.844 , 0.8438, 0.843 , 0.842 , 0.8413,\n",
       "            0.841 , 0.8403, 0.8384, 0.838 , 0.837 , 0.836 , 0.8354, 0.835 ,\n",
       "            0.834 , 0.832 , 0.8315, 0.831 , 0.8267, 0.825 , 0.823 , 0.8223,\n",
       "            0.8154, 0.814 , 0.8135, 0.8125, 0.8115, 0.8096, 0.805 , 0.803 ,\n",
       "            0.8022, 0.8013, 0.7993, 0.7964, 0.796 , 0.7915, 0.7886, 0.788 ,\n",
       "            0.787 , 0.785 , 0.784 , 0.7827, 0.7803, 0.7793, 0.7783, 0.775 ,\n",
       "            0.774 , 0.765 , 0.763 , 0.7485, 0.7334, 0.7227, 0.7197, 0.7144,\n",
       "            0.714 , 0.7114, 0.707 , 0.705 , 0.6904, 0.6865, 0.6846, 0.681 ,\n",
       "            0.6807, 0.678 , 0.6777, 0.675 , 0.6743, 0.674 , 0.6724, 0.6704,\n",
       "            0.668 , 0.6675, 0.6646, 0.664 , 0.6616, 0.661 , 0.659 , 0.6587,\n",
       "            0.656 , 0.654 , 0.6533, 0.6523, 0.651 , 0.6504, 0.648 , 0.6436,\n",
       "            0.6416, 0.64  , 0.6396, 0.632 , 0.6313, 0.63  , 0.6294, 0.629 ,\n",
       "            0.6274, 0.627 , 0.6235, 0.621 , 0.62  , 0.6177, 0.6157, 0.6147,\n",
       "            0.6133, 0.6074], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(1., dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.04166667, 0.05      ,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.075     , 0.075     , 0.075     , 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.09166667, 0.1       , 0.1       ,\n",
       "            0.1       , 0.1       , 0.1       , 0.11666667, 0.125     ,\n",
       "            0.125     , 0.125     , 0.125     , 0.13333334, 0.15      ,\n",
       "            0.15      , 0.16666667, 0.16666667, 0.16666667, 0.18333334,\n",
       "            0.19166666, 0.20833333, 0.21666667, 0.225     , 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25      , 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.29166666, 0.29166666, 0.3       , 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.36666667, 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.39166668, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45      , 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.5       , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.04615385, 0.05384615, 0.06923077, 0.06923077,\n",
       "            0.07692308, 0.1       , 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13076924, 0.13846155, 0.14615385, 0.14615385,\n",
       "            0.15384616, 0.16923077, 0.17692308, 0.1923077 , 0.20769231,\n",
       "            0.20769231, 0.20769231, 0.21538462, 0.23076923, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.2846154 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.31538463, 0.33076924, 0.33076924, 0.33076924,\n",
       "            0.34615386, 0.34615386, 0.35384616, 0.36153847, 0.36153847,\n",
       "            0.36153847, 0.36153847, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.37692308, 0.3923077 , 0.3923077 , 0.4076923 ,\n",
       "            0.42307693, 0.43846154, 0.43846154, 0.45384616, 0.45384616,\n",
       "            0.46153846, 0.4846154 , 0.4846154 , 0.50769234, 0.5153846 ,\n",
       "            0.5307692 , 0.53846157, 0.5538462 , 0.56153846, 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.61538464, 0.61538464,\n",
       "            0.6230769 , 0.6230769 , 0.63076925, 0.63846153, 0.63846153,\n",
       "            0.65384614, 0.6615385 , 0.6615385 , 0.66923076, 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7076923 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.7692308 , 0.8       , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.85384613, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.8923077 , 0.9153846 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9766, 0.9683, 0.965 , 0.963 , 0.9604, 0.958 , 0.9565,\n",
       "            0.955 , 0.9536, 0.952 , 0.9497, 0.9487, 0.948 , 0.9478, 0.947 ,\n",
       "            0.9463, 0.946 , 0.945 , 0.9443, 0.9434, 0.943 , 0.9424, 0.942 ,\n",
       "            0.94  , 0.9395, 0.938 , 0.9375, 0.9365, 0.936 , 0.9355, 0.935 ,\n",
       "            0.934 , 0.9336, 0.933 , 0.932 , 0.9316, 0.931 , 0.9307, 0.93  ,\n",
       "            0.9287, 0.928 , 0.9277, 0.9272, 0.927 , 0.9253, 0.925 , 0.9243,\n",
       "            0.924 , 0.923 , 0.9224, 0.9214, 0.92  , 0.9185, 0.918 , 0.917 ,\n",
       "            0.9165, 0.916 , 0.9155, 0.9146, 0.914 , 0.9136, 0.913 , 0.911 ,\n",
       "            0.9106, 0.91  , 0.9097, 0.909 , 0.9087, 0.908 , 0.9077, 0.906 ,\n",
       "            0.9053, 0.905 , 0.904 , 0.9033, 0.903 , 0.9023, 0.901 , 0.9004,\n",
       "            0.9   , 0.8994, 0.8984, 0.8965, 0.896 , 0.8955, 0.895 , 0.8936,\n",
       "            0.8916, 0.89  , 0.888 , 0.8877, 0.887 , 0.886 , 0.8853, 0.8833,\n",
       "            0.883 , 0.88  , 0.8774, 0.8755, 0.8745, 0.8735, 0.872 , 0.8706,\n",
       "            0.869 , 0.8687, 0.867 , 0.8667, 0.866 , 0.8657, 0.864 , 0.8633,\n",
       "            0.862 , 0.858 , 0.8574, 0.855 , 0.854 , 0.852 , 0.851 , 0.8467,\n",
       "            0.8447, 0.8433, 0.8403, 0.836 , 0.832 , 0.829 , 0.818 , 0.813 ,\n",
       "            0.8066, 0.7993, 0.7886, 0.786 , 0.7827, 0.7803, 0.769 , 0.7544,\n",
       "            0.7495, 0.746 , 0.7446, 0.742 , 0.7373, 0.7324, 0.732 , 0.7275,\n",
       "            0.7236, 0.7197, 0.7188, 0.7183, 0.716 , 0.714 , 0.712 , 0.711 ,\n",
       "            0.708 , 0.705 , 0.7036, 0.7026, 0.7007, 0.7   , 0.6997, 0.699 ,\n",
       "            0.696 , 0.695 , 0.6943, 0.693 , 0.6914, 0.685 , 0.6836, 0.6816,\n",
       "            0.679 , 0.6763, 0.676 , 0.6753, 0.673 , 0.667 , 0.6665, 0.6655,\n",
       "            0.665 , 0.6626, 0.66  , 0.653 , 0.6523, 0.651 , 0.65  , 0.648 ,\n",
       "            0.646 , 0.6436, 0.6406, 0.638 , 0.6313], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(1., dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.10833333, 0.10833333, 0.10833333, 0.125     , 0.125     ,\n",
       "            0.125     , 0.125     , 0.13333334, 0.13333334, 0.13333334,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.19166666, 0.19166666, 0.2       , 0.2       , 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.25      , 0.25      , 0.25833333,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.325     , 0.325     ,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.35833332, 0.35833332, 0.36666667, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.49166667, 0.5       , 0.5       ,\n",
       "            0.5083333 , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.73333335, 0.7416667 , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.8833333 , 0.89166665, 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.96666664, 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.1       , 0.11538462, 0.13076924,\n",
       "            0.14615385, 0.15384616, 0.16923077, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.25384617,\n",
       "            0.26923078, 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.36153847, 0.36153847, 0.36923078, 0.37692308, 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.4846154 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.54615384,\n",
       "            0.54615384, 0.5538462 , 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5846154 , 0.5923077 , 0.6076923 , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6923077 , 0.7076923 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.73846155, 0.74615383, 0.74615383, 0.75384617,\n",
       "            0.75384617, 0.76153845, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.8       , 0.8153846 ,\n",
       "            0.8153846 , 0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.83076924, 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.976 , 0.973 , 0.972 , 0.968 , 0.9663, 0.966 , 0.9653,\n",
       "            0.965 , 0.963 , 0.9624, 0.962 , 0.9614, 0.9585, 0.9546, 0.954 ,\n",
       "            0.9536, 0.953 , 0.9526, 0.9517, 0.951 , 0.95  , 0.9487, 0.9478,\n",
       "            0.9463, 0.944 , 0.9434, 0.9424, 0.941 , 0.9404, 0.9385, 0.9375,\n",
       "            0.9355, 0.9336, 0.9326, 0.932 , 0.931 , 0.9297, 0.928 , 0.9277,\n",
       "            0.9272, 0.927 , 0.9253, 0.924 , 0.922 , 0.921 , 0.92  , 0.9194,\n",
       "            0.9165, 0.916 , 0.913 , 0.9126, 0.9097, 0.909 , 0.9087, 0.9077,\n",
       "            0.907 , 0.9062, 0.906 , 0.905 , 0.9043, 0.904 , 0.903 , 0.9014,\n",
       "            0.901 , 0.9   , 0.8994, 0.899 , 0.8984, 0.898 , 0.8965, 0.8955,\n",
       "            0.8945, 0.893 , 0.8926, 0.892 , 0.891 , 0.8906, 0.89  , 0.8896,\n",
       "            0.888 , 0.8877, 0.886 , 0.8857, 0.8853, 0.8843, 0.8833, 0.883 ,\n",
       "            0.882 , 0.8813, 0.881 , 0.8794, 0.879 , 0.876 , 0.8755, 0.8745,\n",
       "            0.8735, 0.873 , 0.8726, 0.872 , 0.8716, 0.8706, 0.869 , 0.8677,\n",
       "            0.866 , 0.8657, 0.864 , 0.8633, 0.8623, 0.8613, 0.861 , 0.8594,\n",
       "            0.859 , 0.856 , 0.8555, 0.853 , 0.852 , 0.8516, 0.8506, 0.849 ,\n",
       "            0.8486, 0.8477, 0.845 , 0.8438, 0.842 , 0.8413, 0.8403, 0.84  ,\n",
       "            0.839 , 0.8374, 0.8364, 0.835 , 0.828 , 0.826 , 0.824 , 0.8228,\n",
       "            0.8154, 0.8125, 0.8096, 0.809 , 0.8076, 0.8057, 0.8047, 0.8027,\n",
       "            0.7876, 0.786 , 0.781 , 0.7715, 0.771 , 0.7686, 0.7583, 0.757 ,\n",
       "            0.7544, 0.7495, 0.7476, 0.7466, 0.7285, 0.7227, 0.718 , 0.7163,\n",
       "            0.707 , 0.7065, 0.705 , 0.704 , 0.7017, 0.701 , 0.7   , 0.698 ,\n",
       "            0.6963, 0.696 , 0.6943, 0.694 , 0.692 , 0.6885, 0.687 , 0.6865,\n",
       "            0.6846, 0.6826, 0.6807, 0.679 , 0.6763, 0.676 , 0.672 , 0.6694,\n",
       "            0.667 , 0.666 , 0.662 , 0.6597, 0.6553, 0.6543, 0.646 , 0.6445,\n",
       "            0.6416, 0.6377, 0.637 , 0.633 , 0.6304, 0.627 , 0.6177],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(1., dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.075     , 0.075     , 0.075     , 0.075     , 0.08333334,\n",
       "            0.09166667, 0.09166667, 0.1       , 0.11666667, 0.11666667,\n",
       "            0.11666667, 0.125     , 0.125     , 0.13333334, 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.19166666, 0.2       , 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.3       ,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.81666666, 0.825     , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.06153846, 0.07692308, 0.08461539,\n",
       "            0.1       , 0.11538462, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.4       , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.46923077, 0.46923077, 0.47692308, 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.88461536, 0.8923077 ,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9230769 , 0.9307692 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9834, 0.9795, 0.9775, 0.9746, 0.974 , 0.9717, 0.969 ,\n",
       "            0.9688, 0.968 , 0.9663, 0.9653, 0.965 , 0.9644, 0.964 , 0.963 ,\n",
       "            0.961 , 0.9604, 0.96  , 0.9595, 0.959 , 0.9585, 0.9575, 0.9565,\n",
       "            0.9556, 0.9546, 0.954 , 0.9536, 0.9517, 0.951 , 0.949 , 0.947 ,\n",
       "            0.946 , 0.945 , 0.943 , 0.9414, 0.941 , 0.9385, 0.938 , 0.9375,\n",
       "            0.937 , 0.9355, 0.934 , 0.933 , 0.9316, 0.931 , 0.9277, 0.927 ,\n",
       "            0.9263, 0.922 , 0.921 , 0.9204, 0.9185, 0.9175, 0.916 , 0.9155,\n",
       "            0.914 , 0.913 , 0.911 , 0.9106, 0.9097, 0.908 , 0.9077, 0.907 ,\n",
       "            0.9062, 0.904 , 0.9033, 0.903 , 0.902 , 0.9014, 0.901 , 0.9   ,\n",
       "            0.8994, 0.898 , 0.897 , 0.8965, 0.8955, 0.8945, 0.894 , 0.8916,\n",
       "            0.891 , 0.89  , 0.8896, 0.889 , 0.8887, 0.8877, 0.887 , 0.885 ,\n",
       "            0.884 , 0.8833, 0.883 , 0.8823, 0.8794, 0.8745, 0.8726, 0.87  ,\n",
       "            0.868 , 0.8633, 0.8594, 0.8584, 0.8564, 0.8535, 0.8525, 0.8516,\n",
       "            0.851 , 0.85  , 0.8486, 0.8467, 0.8447, 0.844 , 0.8438, 0.8423,\n",
       "            0.8384, 0.836 , 0.835 , 0.834 , 0.833 , 0.8315, 0.831 , 0.8306,\n",
       "            0.8276, 0.827 , 0.8267, 0.825 , 0.8237, 0.8223, 0.8203, 0.82  ,\n",
       "            0.8193, 0.8145, 0.811 , 0.8105, 0.805 , 0.8047, 0.802 , 0.801 ,\n",
       "            0.8   , 0.797 , 0.7964, 0.795 , 0.7944, 0.7925, 0.7905, 0.788 ,\n",
       "            0.7866, 0.786 , 0.7856, 0.7837, 0.783 , 0.7773, 0.7725, 0.766 ,\n",
       "            0.7646, 0.7637, 0.7617, 0.7603, 0.7593, 0.759 , 0.7583, 0.756 ,\n",
       "            0.7544, 0.7524, 0.748 , 0.7476, 0.7446, 0.7417, 0.7383, 0.7334,\n",
       "            0.731 , 0.7217, 0.719 , 0.717 , 0.709 , 0.7056, 0.705 , 0.6934,\n",
       "            0.693 , 0.6875, 0.6855, 0.6846, 0.683 , 0.681 , 0.6777, 0.6753,\n",
       "            0.6733, 0.6724, 0.672 , 0.6714, 0.67  , 0.6675, 0.663 , 0.6606,\n",
       "            0.6597, 0.655 , 0.6514, 0.6494, 0.649 , 0.6436, 0.641 , 0.6387,\n",
       "            0.6367, 0.6353, 0.635 , 0.6333, 0.628 , 0.6216, 0.617 , 0.6147,\n",
       "            0.613 , 0.6123, 0.61  , 0.6094, 0.609 , 0.596 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(1., dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.06666667, 0.06666667, 0.06666667, 0.075     , 0.075     ,\n",
       "            0.075     , 0.075     , 0.075     , 0.075     , 0.08333334,\n",
       "            0.09166667, 0.09166667, 0.1       , 0.10833333, 0.10833333,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.525     , 0.53333336, 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.69166666, 0.7083333 ,\n",
       "            0.725     , 0.7416667 , 0.7583333 , 0.76666665, 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.875     , 0.8833333 , 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.975     ,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.2       , 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.35384616, 0.37692308, 0.3846154 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.42307693, 0.43076923, 0.44615385,\n",
       "            0.45384616, 0.46923077, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.66923076, 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.86153847, 0.86923075,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.88461536, 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.989 , 0.986 , 0.9854, 0.981 , 0.98  , 0.9795, 0.978 ,\n",
       "            0.9756, 0.975 , 0.9746, 0.974 , 0.973 , 0.972 , 0.971 , 0.9707,\n",
       "            0.9697, 0.969 , 0.9683, 0.968 , 0.9663, 0.966 , 0.9653, 0.964 ,\n",
       "            0.963 , 0.9624, 0.962 , 0.961 , 0.9595, 0.9585, 0.9575, 0.957 ,\n",
       "            0.9556, 0.955 , 0.9546, 0.954 , 0.953 , 0.951 , 0.95  , 0.949 ,\n",
       "            0.9478, 0.9473, 0.9443, 0.944 , 0.943 , 0.94  , 0.9395, 0.938 ,\n",
       "            0.937 , 0.9326, 0.928 , 0.925 , 0.9243, 0.922 , 0.92  , 0.9194,\n",
       "            0.919 , 0.917 , 0.915 , 0.913 , 0.9126, 0.9116, 0.911 , 0.909 ,\n",
       "            0.908 , 0.9067, 0.906 , 0.9053, 0.905 , 0.904 , 0.9033, 0.901 ,\n",
       "            0.8994, 0.899 , 0.8984, 0.898 , 0.897 , 0.8965, 0.8936, 0.893 ,\n",
       "            0.89  , 0.889 , 0.887 , 0.8853, 0.88  , 0.877 , 0.875 , 0.8735,\n",
       "            0.872 , 0.8716, 0.871 , 0.8706, 0.8657, 0.8633, 0.8584, 0.856 ,\n",
       "            0.8506, 0.85  , 0.848 , 0.846 , 0.844 , 0.8423, 0.8413, 0.841 ,\n",
       "            0.8374, 0.8354, 0.835 , 0.8306, 0.83  , 0.8296, 0.8286, 0.821 ,\n",
       "            0.8193, 0.8135, 0.8066, 0.7983, 0.794 , 0.789 , 0.7886, 0.788 ,\n",
       "            0.7866, 0.786 , 0.784 , 0.781 , 0.778 , 0.7725, 0.771 , 0.77  ,\n",
       "            0.7695, 0.767 , 0.7666, 0.766 , 0.7646, 0.7573, 0.756 , 0.7554,\n",
       "            0.753 , 0.747 , 0.7446, 0.7383, 0.738 , 0.7373, 0.7363, 0.7354,\n",
       "            0.734 , 0.733 , 0.7324, 0.7124, 0.709 , 0.7085, 0.708 , 0.706 ,\n",
       "            0.7056, 0.7046, 0.7036, 0.7026, 0.7   , 0.6978, 0.692 , 0.69  ,\n",
       "            0.689 , 0.6875, 0.6865, 0.682 , 0.681 , 0.6787, 0.6772, 0.6763,\n",
       "            0.674 , 0.6733, 0.6655, 0.664 , 0.6636, 0.663 , 0.66  , 0.6587,\n",
       "            0.658 , 0.6577, 0.656 , 0.655 , 0.654 , 0.6533, 0.651 , 0.6475,\n",
       "            0.645 , 0.6445, 0.642 , 0.641 , 0.638 , 0.637 , 0.636 , 0.6357,\n",
       "            0.633 , 0.63  , 0.6284, 0.6255, 0.6235, 0.623 , 0.618 , 0.615 ,\n",
       "            0.6147, 0.6143, 0.611 , 0.606 , 0.6035, 0.603 , 0.5903, 0.588 ,\n",
       "            0.5864, 0.582 , 0.58  , 0.5664], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(1., dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.09166667, 0.1       ,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.11666667, 0.125     ,\n",
       "            0.125     , 0.13333334, 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.21666667, 0.23333333, 0.23333333, 0.24166666, 0.25833333,\n",
       "            0.275     , 0.28333333, 0.3       , 0.30833334, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.8833333 ,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.02307692, 0.03076923, 0.03846154,\n",
       "            0.05384615, 0.06153846, 0.06923077, 0.08461539, 0.09230769,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.16923077, 0.18461539, 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2769231 , 0.2846154 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.3846154 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5769231 , 0.5846154 , 0.5923077 , 0.6076923 ,\n",
       "            0.61538464, 0.63076925, 0.63846153, 0.64615387, 0.6615385 ,\n",
       "            0.6769231 , 0.6923077 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.992 , 0.9897, 0.986 , 0.9854, 0.9844, 0.9814, 0.9805,\n",
       "            0.98  , 0.9785, 0.977 , 0.9756, 0.975 , 0.974 , 0.9736, 0.973 ,\n",
       "            0.9727, 0.972 , 0.9717, 0.971 , 0.9697, 0.9688, 0.967 , 0.966 ,\n",
       "            0.965 , 0.964 , 0.9634, 0.963 , 0.961 , 0.96  , 0.9595, 0.9585,\n",
       "            0.958 , 0.957 , 0.9565, 0.956 , 0.9556, 0.955 , 0.9546, 0.953 ,\n",
       "            0.952 , 0.9507, 0.95  , 0.9424, 0.942 , 0.94  , 0.938 , 0.9375,\n",
       "            0.9336, 0.9307, 0.93  , 0.929 , 0.927 , 0.9263, 0.922 , 0.9194,\n",
       "            0.918 , 0.9175, 0.917 , 0.916 , 0.915 , 0.914 , 0.9126, 0.912 ,\n",
       "            0.9077, 0.907 , 0.9053, 0.905 , 0.9043, 0.903 , 0.9023, 0.902 ,\n",
       "            0.9014, 0.8965, 0.8926, 0.8916, 0.891 , 0.89  , 0.8857, 0.8823,\n",
       "            0.8813, 0.8804, 0.879 , 0.8765, 0.8755, 0.8657, 0.864 , 0.863 ,\n",
       "            0.862 , 0.86  , 0.8564, 0.854 , 0.8506, 0.849 , 0.8477, 0.842 ,\n",
       "            0.8403, 0.8364, 0.8354, 0.8335, 0.8296, 0.8257, 0.821 , 0.82  ,\n",
       "            0.8184, 0.8164, 0.813 , 0.806 , 0.802 , 0.793 , 0.788 , 0.781 ,\n",
       "            0.778 , 0.7773, 0.777 , 0.773 , 0.7695, 0.767 , 0.765 , 0.7646,\n",
       "            0.758 , 0.755 , 0.7476, 0.743 , 0.731 , 0.719 , 0.714 , 0.711 ,\n",
       "            0.703 , 0.7026, 0.698 , 0.6978, 0.6924, 0.6904, 0.6885, 0.682 ,\n",
       "            0.6807, 0.675 , 0.6675, 0.6636, 0.663 , 0.6626, 0.6597, 0.656 ,\n",
       "            0.652 , 0.6514, 0.65  , 0.6484, 0.647 , 0.645 , 0.638 , 0.636 ,\n",
       "            0.6304, 0.6294, 0.629 , 0.627 , 0.626 , 0.622 , 0.62  , 0.6177,\n",
       "            0.616 , 0.6147, 0.613 , 0.6113, 0.61  , 0.608 , 0.606 , 0.6045,\n",
       "            0.603 , 0.6006, 0.6   , 0.5986, 0.5977, 0.597 , 0.5913, 0.591 ,\n",
       "            0.5903, 0.5884, 0.5864, 0.585 , 0.583 , 0.579 , 0.577 , 0.575 ,\n",
       "            0.5747, 0.5737, 0.571 , 0.569 , 0.5605, 0.56  , 0.559 , 0.5586,\n",
       "            0.557 , 0.555 , 0.5547, 0.5537, 0.553 , 0.552 , 0.5483, 0.5474,\n",
       "            0.545 , 0.5425, 0.5405, 0.5386, 0.538 , 0.535 , 0.5317, 0.5312,\n",
       "            0.531 , 0.5254, 0.524 , 0.52  , 0.518 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.81666666, dtype=float32),\n",
       "    'tpr': array(0.99230766, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.06666667, 0.075     , 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.325     , 0.33333334,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.43333334,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.5       , 0.5083333 , 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.75      , 0.7583333 , 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06923077, 0.08461539, 0.09230769,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16923077, 0.17692308, 0.18461539, 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2769231 , 0.2923077 ,\n",
       "            0.30769232, 0.31538463, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.37692308, 0.3846154 , 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.6923077 , 0.7076923 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.93846154, 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.995 , 0.993 , 0.9927, 0.9897, 0.989 , 0.9883, 0.985 ,\n",
       "            0.984 , 0.983 , 0.982 , 0.981 , 0.98  , 0.9795, 0.9785, 0.978 ,\n",
       "            0.977 , 0.9766, 0.976 , 0.975 , 0.974 , 0.9736, 0.973 , 0.971 ,\n",
       "            0.97  , 0.969 , 0.9688, 0.9683, 0.967 , 0.9653, 0.964 , 0.9614,\n",
       "            0.961 , 0.9604, 0.96  , 0.9595, 0.959 , 0.9585, 0.958 , 0.957 ,\n",
       "            0.956 , 0.955 , 0.9526, 0.947 , 0.946 , 0.9453, 0.945 , 0.9424,\n",
       "            0.939 , 0.938 , 0.935 , 0.933 , 0.931 , 0.9307, 0.929 , 0.9287,\n",
       "            0.9277, 0.9263, 0.9243, 0.924 , 0.92  , 0.9194, 0.919 , 0.9185,\n",
       "            0.916 , 0.913 , 0.91  , 0.9097, 0.9087, 0.908 , 0.9077, 0.9043,\n",
       "            0.9033, 0.902 , 0.8984, 0.8965, 0.895 , 0.8926, 0.891 , 0.888 ,\n",
       "            0.885 , 0.8843, 0.8804, 0.8784, 0.878 , 0.875 , 0.874 , 0.8726,\n",
       "            0.868 , 0.8657, 0.864 , 0.86  , 0.856 , 0.849 , 0.8413, 0.841 ,\n",
       "            0.838 , 0.8335, 0.8306, 0.83  , 0.8296, 0.827 , 0.824 , 0.8154,\n",
       "            0.8096, 0.809 , 0.8066, 0.8013, 0.7964, 0.7944, 0.783 , 0.775 ,\n",
       "            0.774 , 0.7734, 0.772 , 0.766 , 0.76  , 0.7563, 0.7524, 0.751 ,\n",
       "            0.7495, 0.7407, 0.7397, 0.7383, 0.7373, 0.7324, 0.722 , 0.719 ,\n",
       "            0.708 , 0.7075, 0.684 , 0.6826, 0.6763, 0.673 , 0.6724, 0.6655,\n",
       "            0.663 , 0.6626, 0.658 , 0.6543, 0.649 , 0.6475, 0.643 , 0.6426,\n",
       "            0.6416, 0.639 , 0.6387, 0.6367, 0.634 , 0.625 , 0.614 , 0.609 ,\n",
       "            0.6084, 0.605 , 0.6035, 0.6016, 0.5986, 0.5977, 0.594 , 0.593 ,\n",
       "            0.5894, 0.589 , 0.587 , 0.5796, 0.579 , 0.5786, 0.575 , 0.5737,\n",
       "            0.572 , 0.5693, 0.5684, 0.5674, 0.563 , 0.5625, 0.562 , 0.561 ,\n",
       "            0.558 , 0.5537, 0.553 , 0.551 , 0.549 , 0.546 , 0.543 , 0.5396,\n",
       "            0.5317, 0.5312, 0.531 , 0.53  , 0.5293, 0.5264, 0.525 , 0.524 ,\n",
       "            0.523 , 0.522 , 0.507 , 0.4966, 0.484 , 0.4763, 0.4734, 0.4714,\n",
       "            0.4707, 0.463 , 0.457 , 0.456 , 0.4534, 0.4524, 0.45  , 0.4458,\n",
       "            0.4456, 0.444 , 0.4402, 0.432 , 0.431 , 0.4285, 0.4202, 0.4111,\n",
       "            0.4097, 0.3884], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.69166666, dtype=float32),\n",
       "    'tpr': array(0.99230766, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.275     ,\n",
       "            0.28333333, 0.3       , 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.51666665, 0.525     , 0.5416667 , 0.55833334,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.05384615, 0.06923077, 0.07692308, 0.08461539,\n",
       "            0.09230769, 0.10769231, 0.12307692, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.26153848, 0.26923078, 0.2846154 , 0.2923077 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.31538463, 0.32307693,\n",
       "            0.33846155, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9966, 0.995 , 0.9946, 0.992 , 0.9917, 0.991 , 0.9883,\n",
       "            0.988 , 0.9873, 0.9863, 0.986 , 0.9844, 0.9834, 0.983 , 0.982 ,\n",
       "            0.9814, 0.981 , 0.9805, 0.9795, 0.979 , 0.9785, 0.978 , 0.977 ,\n",
       "            0.976 , 0.975 , 0.974 , 0.9736, 0.9717, 0.971 , 0.9707, 0.97  ,\n",
       "            0.9683, 0.968 , 0.9673, 0.9653, 0.965 , 0.9644, 0.963 , 0.96  ,\n",
       "            0.9595, 0.957 , 0.952 , 0.9517, 0.951 , 0.9507, 0.9497, 0.946 ,\n",
       "            0.945 , 0.942 , 0.94  , 0.9395, 0.937 , 0.9365, 0.936 , 0.9346,\n",
       "            0.9336, 0.9307, 0.93  , 0.9287, 0.9277, 0.927 , 0.9243, 0.924 ,\n",
       "            0.921 , 0.9204, 0.917 , 0.9165, 0.9155, 0.915 , 0.908 , 0.9077,\n",
       "            0.907 , 0.9053, 0.9014, 0.9004, 0.9   , 0.898 , 0.896 , 0.894 ,\n",
       "            0.8906, 0.889 , 0.888 , 0.8843, 0.883 , 0.882 , 0.8755, 0.8745,\n",
       "            0.8716, 0.8696, 0.867 , 0.8623, 0.86  , 0.8467, 0.8438, 0.8354,\n",
       "            0.835 , 0.8345, 0.8315, 0.8286, 0.8267, 0.825 , 0.824 , 0.816 ,\n",
       "            0.812 , 0.8057, 0.805 , 0.804 , 0.801 , 0.8003, 0.7993, 0.776 ,\n",
       "            0.775 , 0.7734, 0.769 , 0.768 , 0.761 , 0.755 , 0.753 , 0.748 ,\n",
       "            0.746 , 0.7427, 0.7344, 0.7324, 0.73  , 0.7227, 0.722 , 0.719 ,\n",
       "            0.7183, 0.7163, 0.6846, 0.678 , 0.667 , 0.666 , 0.657 , 0.6553,\n",
       "            0.6533, 0.6494, 0.6465, 0.6304, 0.629 , 0.6284, 0.627 , 0.6235,\n",
       "            0.616 , 0.6094, 0.609 , 0.6055, 0.6025, 0.601 , 0.6   , 0.595 ,\n",
       "            0.5947, 0.588 , 0.581 , 0.5767, 0.5757, 0.5728, 0.572 , 0.571 ,\n",
       "            0.5703, 0.5664, 0.562 , 0.5596, 0.5586, 0.5576, 0.551 , 0.547 ,\n",
       "            0.546 , 0.543 , 0.5425, 0.538 , 0.537 , 0.5366, 0.532 , 0.5317,\n",
       "            0.529 , 0.525 , 0.523 , 0.519 , 0.5137, 0.5107, 0.509 , 0.501 ,\n",
       "            0.4978, 0.4976, 0.4956, 0.4941, 0.494 , 0.4922, 0.4885, 0.4863,\n",
       "            0.4802, 0.4727, 0.4722, 0.4702, 0.469 , 0.4678, 0.443 , 0.4302,\n",
       "            0.4258, 0.4155, 0.4006, 0.3992, 0.3967, 0.3948, 0.3894, 0.389 ,\n",
       "            0.3857, 0.3848, 0.3765, 0.3762, 0.3733, 0.3723, 0.3662, 0.3594,\n",
       "            0.3477, 0.3452, 0.3381, 0.3333, 0.2966], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.59166664, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.10833333, 0.11666667, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.18333334, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.29166666, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.05384615, 0.06923077, 0.07692308, 0.08461539,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.16153847, 0.16923077, 0.18461539,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.26153848, 0.26923078, 0.2769231 , 0.2846154 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.34615386, 0.35384616, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.4       , 0.4076923 , 0.42307693, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.7307692 , 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8       , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9       , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9976, 0.9966, 0.9956, 0.994 , 0.9937, 0.9927, 0.99  ,\n",
       "            0.9897, 0.9893, 0.989 , 0.9883, 0.9873, 0.987 , 0.9863, 0.9854,\n",
       "            0.985 , 0.9844, 0.9834, 0.9824, 0.982 , 0.9814, 0.981 , 0.979 ,\n",
       "            0.9785, 0.9775, 0.977 , 0.9766, 0.976 , 0.9756, 0.9746, 0.9727,\n",
       "            0.9717, 0.9707, 0.9697, 0.9683, 0.968 , 0.9673, 0.9663, 0.963 ,\n",
       "            0.961 , 0.959 , 0.9565, 0.956 , 0.955 , 0.9517, 0.9497, 0.949 ,\n",
       "            0.9463, 0.946 , 0.9443, 0.943 , 0.94  , 0.938 , 0.9365, 0.9346,\n",
       "            0.934 , 0.9336, 0.932 , 0.93  , 0.9287, 0.927 , 0.926 , 0.923 ,\n",
       "            0.9224, 0.922 , 0.918 , 0.917 , 0.9165, 0.91  , 0.9077, 0.905 ,\n",
       "            0.904 , 0.902 , 0.898 , 0.8975, 0.897 , 0.8955, 0.8945, 0.89  ,\n",
       "            0.889 , 0.887 , 0.883 , 0.882 , 0.8784, 0.8755, 0.8687, 0.8657,\n",
       "            0.865 , 0.8555, 0.843 , 0.842 , 0.8335, 0.833 , 0.8286, 0.8276,\n",
       "            0.8247, 0.8237, 0.821 , 0.819 , 0.8154, 0.8115, 0.803 , 0.799 ,\n",
       "            0.7974, 0.794 , 0.7925, 0.792 , 0.7744, 0.7607, 0.7593, 0.7583,\n",
       "            0.751 , 0.744 , 0.737 , 0.7344, 0.7324, 0.731 , 0.724 , 0.72  ,\n",
       "            0.7197, 0.717 , 0.6973, 0.6914, 0.684 , 0.6694, 0.659 , 0.645 ,\n",
       "            0.6367, 0.6353, 0.634 , 0.6333, 0.63  , 0.616 , 0.614 , 0.613 ,\n",
       "            0.6084, 0.5957, 0.5894, 0.5825, 0.582 , 0.58  , 0.5776, 0.576 ,\n",
       "            0.569 , 0.566 , 0.5625, 0.562 , 0.561 , 0.558 , 0.5483, 0.545 ,\n",
       "            0.544 , 0.54  , 0.5347, 0.5337, 0.533 , 0.532 , 0.5312, 0.5264,\n",
       "            0.526 , 0.524 , 0.5215, 0.5186, 0.514 , 0.5137, 0.5093, 0.5083,\n",
       "            0.5073, 0.5063, 0.5044, 0.504 , 0.4976, 0.4966, 0.4888, 0.487 ,\n",
       "            0.484 , 0.482 , 0.4812, 0.4788, 0.4783, 0.4758, 0.4612, 0.461 ,\n",
       "            0.457 , 0.4563, 0.4553, 0.4546, 0.451 , 0.4507, 0.446 , 0.4458,\n",
       "            0.4333, 0.4272, 0.427 , 0.423 , 0.4104, 0.4067, 0.402 , 0.3896,\n",
       "            0.3774, 0.3762, 0.3633, 0.3416, 0.3396, 0.3315, 0.329 , 0.3281,\n",
       "            0.328 , 0.3262, 0.3237, 0.313 , 0.3125, 0.3103, 0.31  , 0.3054,\n",
       "            0.296 , 0.279 , 0.2761, 0.2722, 0.2656, 0.222 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.45, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.175     , 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.05384615, 0.06923077, 0.07692308, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.13076924, 0.13846155,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.2       , 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.24615385, 0.26923078, 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.31538463, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.998 , 0.997 , 0.9966, 0.9956, 0.995 , 0.994 , 0.992 ,\n",
       "            0.9917, 0.991 , 0.9907, 0.99  , 0.9897, 0.9893, 0.989 , 0.9873,\n",
       "            0.987 , 0.9863, 0.9844, 0.984 , 0.9824, 0.9814, 0.9805, 0.98  ,\n",
       "            0.9795, 0.978 , 0.9775, 0.9766, 0.9756, 0.973 , 0.972 , 0.9717,\n",
       "            0.971 , 0.969 , 0.9653, 0.9644, 0.9634, 0.962 , 0.961 , 0.9604,\n",
       "            0.96  , 0.959 , 0.958 , 0.956 , 0.9546, 0.954 , 0.9536, 0.953 ,\n",
       "            0.95  , 0.9497, 0.9487, 0.948 , 0.9434, 0.9424, 0.94  , 0.9385,\n",
       "            0.937 , 0.935 , 0.9346, 0.932 , 0.9307, 0.929 , 0.9272, 0.927 ,\n",
       "            0.9263, 0.9214, 0.9136, 0.9116, 0.911 , 0.9087, 0.9067, 0.906 ,\n",
       "            0.903 , 0.9004, 0.8984, 0.897 , 0.8955, 0.893 , 0.892 , 0.8906,\n",
       "            0.8857, 0.885 , 0.8843, 0.882 , 0.8735, 0.869 , 0.8667, 0.8657,\n",
       "            0.8623, 0.8555, 0.8423, 0.837 , 0.834 , 0.8315, 0.828 , 0.823 ,\n",
       "            0.821 , 0.8203, 0.818 , 0.8125, 0.8066, 0.8013, 0.8   , 0.7964,\n",
       "            0.794 , 0.7896, 0.782 , 0.7817, 0.772 , 0.7515, 0.7495, 0.745 ,\n",
       "            0.7383, 0.7324, 0.732 , 0.723 , 0.721 , 0.72  , 0.7188, 0.717 ,\n",
       "            0.7163, 0.7056, 0.7036, 0.6714, 0.6665, 0.6616, 0.6514, 0.6284,\n",
       "            0.628 , 0.6255, 0.622 , 0.6094, 0.6064, 0.603 , 0.601 , 0.599 ,\n",
       "            0.588 , 0.579 , 0.566 , 0.5615, 0.5547, 0.548 , 0.5474, 0.5425,\n",
       "            0.5405, 0.533 , 0.527 , 0.5264, 0.5244, 0.5215, 0.521 , 0.5195,\n",
       "            0.514 , 0.5107, 0.5103, 0.51  , 0.504 , 0.5015, 0.499 , 0.4983,\n",
       "            0.4934, 0.493 , 0.4902, 0.4893, 0.489 , 0.4854, 0.4844, 0.4841,\n",
       "            0.4824, 0.482 , 0.4802, 0.4758, 0.4753, 0.4695, 0.463 , 0.4563,\n",
       "            0.4482, 0.4448, 0.444 , 0.4426, 0.4414, 0.4355, 0.4329, 0.4275,\n",
       "            0.4238, 0.423 , 0.4216, 0.4158, 0.4143, 0.4102, 0.405 , 0.4026,\n",
       "            0.3977, 0.3867, 0.3845, 0.37  , 0.3628, 0.3582, 0.35  , 0.348 ,\n",
       "            0.3413, 0.3298, 0.3296, 0.3115, 0.2893, 0.28  , 0.278 , 0.277 ,\n",
       "            0.276 , 0.2756, 0.273 , 0.2642, 0.2573, 0.2546, 0.2524, 0.2517,\n",
       "            0.2507, 0.2386, 0.2244, 0.2168, 0.215 , 0.2085, 0.1605],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.34166667, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.06666667, 0.06666667, 0.06666667,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.02307692, 0.03076923, 0.04615385,\n",
       "            0.05384615, 0.06153846, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.11538462, 0.13076924, 0.13846155, 0.14615385, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.2       , 0.20769231, 0.22307692,\n",
       "            0.23076923, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.46153846, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6230769 , 0.64615387, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7846154 ,\n",
       "            0.7923077 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9985, 0.9976, 0.996 , 0.9956, 0.9946, 0.9937, 0.993 ,\n",
       "            0.9927, 0.9917, 0.9907, 0.99  , 0.9893, 0.9883, 0.988 , 0.9873,\n",
       "            0.987 , 0.985 , 0.9844, 0.984 , 0.9834, 0.983 , 0.9824, 0.9814,\n",
       "            0.9805, 0.98  , 0.9795, 0.979 , 0.9775, 0.9766, 0.9756, 0.974 ,\n",
       "            0.972 , 0.9717, 0.9688, 0.967 , 0.9663, 0.9644, 0.9634, 0.9604,\n",
       "            0.96  , 0.9595, 0.958 , 0.9575, 0.954 , 0.951 , 0.9487, 0.9478,\n",
       "            0.947 , 0.9414, 0.941 , 0.9404, 0.9385, 0.9365, 0.935 , 0.9326,\n",
       "            0.9307, 0.93  , 0.929 , 0.926 , 0.9253, 0.925 , 0.914 , 0.9126,\n",
       "            0.911 , 0.909 , 0.9062, 0.9033, 0.9023, 0.902 , 0.8965, 0.8955,\n",
       "            0.894 , 0.893 , 0.892 , 0.8887, 0.888 , 0.887 , 0.886 , 0.88  ,\n",
       "            0.8774, 0.866 , 0.865 , 0.8647, 0.8643, 0.861 , 0.8555, 0.8423,\n",
       "            0.8276, 0.826 , 0.8223, 0.821 , 0.817 , 0.816 , 0.8037, 0.8   ,\n",
       "            0.7964, 0.7954, 0.794 , 0.7905, 0.7847, 0.7783, 0.7744, 0.7617,\n",
       "            0.7607, 0.7446, 0.741 , 0.7275, 0.7217, 0.721 , 0.72  , 0.7085,\n",
       "            0.708 , 0.705 , 0.704 , 0.7007, 0.693 , 0.692 , 0.687 , 0.6763,\n",
       "            0.6504, 0.6396, 0.636 , 0.6094, 0.607 , 0.6025, 0.6016, 0.59  ,\n",
       "            0.5884, 0.5825, 0.58  , 0.5796, 0.5786, 0.561 , 0.5435, 0.5425,\n",
       "            0.5366, 0.5195, 0.5186, 0.5107, 0.508 , 0.501 , 0.4927, 0.4924,\n",
       "            0.4907, 0.4849, 0.484 , 0.479 , 0.4788, 0.474 , 0.4717, 0.4714,\n",
       "            0.4707, 0.4692, 0.4685, 0.4624, 0.4585, 0.4558, 0.4556, 0.4546,\n",
       "            0.4543, 0.4526, 0.4521, 0.4512, 0.449 , 0.4468, 0.4463, 0.4438,\n",
       "            0.442 , 0.4373, 0.4304, 0.4268, 0.4146, 0.4094, 0.409 , 0.4043,\n",
       "            0.3953, 0.3936, 0.3923, 0.3914, 0.3901, 0.3887, 0.38  , 0.378 ,\n",
       "            0.3735, 0.366 , 0.3657, 0.3557, 0.3545, 0.3472, 0.347 , 0.3406,\n",
       "            0.3206, 0.32  , 0.3154, 0.304 , 0.3027, 0.293 , 0.292 , 0.2913,\n",
       "            0.2686, 0.2494, 0.2367, 0.2362, 0.2358, 0.2328, 0.2294, 0.2285,\n",
       "            0.2162, 0.2161, 0.213 , 0.2104, 0.2045, 0.2037, 0.196 , 0.1831,\n",
       "            0.1743, 0.1692, 0.1685, 0.1198], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.30833334, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.04166667, 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.08461539, 0.09230769,\n",
       "            0.10769231, 0.11538462, 0.13076924, 0.13846155, 0.15384616,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.2       , 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.24615385, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2923077 , 0.30769232, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.34615386, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9985 , 0.998  , 0.9976 , 0.9966 , 0.996  , 0.9956 ,\n",
       "            0.994  , 0.9937 , 0.9927 , 0.992  , 0.9917 , 0.991  , 0.9907 ,\n",
       "            0.9893 , 0.989  , 0.9873 , 0.987  , 0.9863 , 0.986  , 0.9854 ,\n",
       "            0.984  , 0.9834 , 0.983  , 0.9824 , 0.982  , 0.9814 , 0.98   ,\n",
       "            0.979  , 0.9766 , 0.976  , 0.975  , 0.9746 , 0.9717 , 0.9673 ,\n",
       "            0.967  , 0.9663 , 0.964  , 0.9634 , 0.9614 , 0.961  , 0.9595 ,\n",
       "            0.958  , 0.9575 , 0.957  , 0.9546 , 0.954  , 0.9526 , 0.9517 ,\n",
       "            0.947  , 0.9453 , 0.944  , 0.941  , 0.9395 , 0.938  , 0.937  ,\n",
       "            0.9346 , 0.934  , 0.93   , 0.9297 , 0.929  , 0.925  , 0.9243 ,\n",
       "            0.923  , 0.917  , 0.9126 , 0.911  , 0.909  , 0.9077 , 0.9062 ,\n",
       "            0.9004 , 0.9    , 0.899  , 0.8984 , 0.897  , 0.894  , 0.8936 ,\n",
       "            0.891  , 0.8906 , 0.886  , 0.885  , 0.8833 , 0.8823 , 0.8696 ,\n",
       "            0.869  , 0.8594 , 0.858  , 0.8516 , 0.85   , 0.8364 , 0.831  ,\n",
       "            0.8267 , 0.8257 , 0.8223 , 0.816  , 0.8105 , 0.808  , 0.806  ,\n",
       "            0.802  , 0.8    , 0.793  , 0.7876 , 0.786  , 0.782  , 0.775  ,\n",
       "            0.765  , 0.764  , 0.758  , 0.7324 , 0.727  , 0.7227 , 0.7197 ,\n",
       "            0.7085 , 0.704  , 0.7026 , 0.697  , 0.6963 , 0.6875 , 0.6836 ,\n",
       "            0.677  , 0.674  , 0.6636 , 0.6357 , 0.634  , 0.6143 , 0.6006 ,\n",
       "            0.5977 , 0.597  , 0.588  , 0.576  , 0.567  , 0.565  , 0.563  ,\n",
       "            0.558  , 0.5527 , 0.5513 , 0.528  , 0.5137 , 0.5063 , 0.503  ,\n",
       "            0.4905 , 0.4893 , 0.4885 , 0.4849 , 0.4768 , 0.473  , 0.4678 ,\n",
       "            0.463  , 0.462  , 0.4617 , 0.4597 , 0.4558 , 0.4507 , 0.4504 ,\n",
       "            0.4502 , 0.4487 , 0.447  , 0.4434 , 0.4358 , 0.4346 , 0.4338 ,\n",
       "            0.4336 , 0.4314 , 0.43   , 0.4287 , 0.4258 , 0.4248 , 0.4233 ,\n",
       "            0.4226 , 0.4158 , 0.4143 , 0.4116 , 0.4067 , 0.4062 , 0.401  ,\n",
       "            0.4001 , 0.3835 , 0.383  , 0.3806 , 0.3777 , 0.3687 , 0.3662 ,\n",
       "            0.362  , 0.361  , 0.3591 , 0.3562 , 0.3528 , 0.349  , 0.3481 ,\n",
       "            0.3423 , 0.3418 , 0.3289 , 0.3171 , 0.3154 , 0.3147 , 0.3118 ,\n",
       "            0.3096 , 0.3035 , 0.2854 , 0.2805 , 0.2798 , 0.2756 , 0.27   ,\n",
       "            0.266  , 0.2656 , 0.2563 , 0.2278 , 0.2181 , 0.2177 , 0.211  ,\n",
       "            0.2091 , 0.2039 , 0.2034 , 0.1946 , 0.193  , 0.1903 , 0.1893 ,\n",
       "            0.1846 , 0.1844 , 0.1737 , 0.154  , 0.1517 , 0.1489 , 0.1428 ,\n",
       "            0.10016], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.29166666, dtype=float32),\n",
       "    'tpr': array(0.97692305, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.15384616, 0.16923077, 0.17692308, 0.2       , 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.25384617, 0.26923078, 0.2769231 ,\n",
       "            0.2923077 , 0.30769232, 0.31538463, 0.33076924, 0.34615386,\n",
       "            0.35384616, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.56153846, 0.5692308 , 0.5846154 , 0.5923077 , 0.61538464,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.8230769 , 0.8230769 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.999 , 0.998 , 0.9976, 0.997 , 0.9966, 0.996 , 0.9956,\n",
       "            0.9946, 0.994 , 0.993 , 0.9927, 0.992 , 0.9917, 0.991 , 0.9897,\n",
       "            0.9893, 0.9883, 0.987 , 0.9863, 0.985 , 0.9844, 0.984 , 0.983 ,\n",
       "            0.9824, 0.982 , 0.9805, 0.9795, 0.977 , 0.976 , 0.9756, 0.975 ,\n",
       "            0.9717, 0.9683, 0.968 , 0.9673, 0.9663, 0.964 , 0.9634, 0.961 ,\n",
       "            0.9604, 0.9595, 0.9585, 0.958 , 0.957 , 0.9546, 0.9536, 0.9526,\n",
       "            0.951 , 0.95  , 0.947 , 0.945 , 0.944 , 0.9404, 0.939 , 0.938 ,\n",
       "            0.936 , 0.9336, 0.931 , 0.9287, 0.9253, 0.9243, 0.922 , 0.916 ,\n",
       "            0.913 , 0.9097, 0.9087, 0.907 , 0.9067, 0.9004, 0.899 , 0.8984,\n",
       "            0.894 , 0.893 , 0.891 , 0.89  , 0.885 , 0.8843, 0.883 , 0.88  ,\n",
       "            0.8794, 0.8667, 0.8643, 0.858 , 0.8486, 0.846 , 0.8374, 0.8315,\n",
       "            0.8257, 0.8193, 0.819 , 0.8184, 0.8125, 0.8076, 0.8027, 0.7983,\n",
       "            0.795 , 0.7896, 0.783 , 0.782 , 0.7812, 0.7773, 0.77  , 0.769 ,\n",
       "            0.7554, 0.7534, 0.7344, 0.7217, 0.7124, 0.708 , 0.7075, 0.688 ,\n",
       "            0.6846, 0.6826, 0.6797, 0.6763, 0.662 , 0.658 , 0.6562, 0.654 ,\n",
       "            0.6533, 0.6523, 0.6147, 0.61  , 0.602 , 0.5776, 0.5767, 0.573 ,\n",
       "            0.565 , 0.5464, 0.545 , 0.5415, 0.539 , 0.5356, 0.5166, 0.5156,\n",
       "            0.5054, 0.4902, 0.4836, 0.4756, 0.4734, 0.4666, 0.456 , 0.4556,\n",
       "            0.4443, 0.4438, 0.4424, 0.4421, 0.4387, 0.4333, 0.4329, 0.432 ,\n",
       "            0.4263, 0.4246, 0.4207, 0.4197, 0.4128, 0.4087, 0.407 , 0.4036,\n",
       "            0.4028, 0.402 , 0.3977, 0.3972, 0.3967, 0.3965, 0.3953, 0.393 ,\n",
       "            0.3882, 0.3833, 0.3733, 0.3728, 0.3699, 0.3677, 0.3613, 0.354 ,\n",
       "            0.3516, 0.3499, 0.3489, 0.3455, 0.3352, 0.3298, 0.3286, 0.3267,\n",
       "            0.326 , 0.3247, 0.3228, 0.316 , 0.31  , 0.303 , 0.298 , 0.2961,\n",
       "            0.2957, 0.2888, 0.2844, 0.282 , 0.2756, 0.2664, 0.261 , 0.2537,\n",
       "            0.251 , 0.2483, 0.2477, 0.2444, 0.2316, 0.2051, 0.1943, 0.1921,\n",
       "            0.1891, 0.1876, 0.1869, 0.179 , 0.178 , 0.1707, 0.1661, 0.1658,\n",
       "            0.1631, 0.1515, 0.139 , 0.1295, 0.1285, 0.1239, 0.0821],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.26666668, dtype=float32),\n",
       "    'tpr': array(0.97692305, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.1       , 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.02307692, 0.03076923, 0.04615385,\n",
       "            0.05384615, 0.06923077, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16923077,\n",
       "            0.17692308, 0.2       , 0.20769231, 0.21538462, 0.23076923,\n",
       "            0.23846154, 0.25384617, 0.26153848, 0.26923078, 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.31538463, 0.32307693, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.45384616, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 , 0.8230769 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.999  , 0.998  , 0.997  , 0.9966 , 0.996  , 0.9946 ,\n",
       "            0.994  , 0.993  , 0.9927 , 0.992  , 0.991  , 0.99   , 0.9897 ,\n",
       "            0.9893 , 0.989  , 0.987  , 0.9863 , 0.986  , 0.9854 , 0.985  ,\n",
       "            0.984  , 0.983  , 0.9824 , 0.982  , 0.981  , 0.9805 , 0.9795 ,\n",
       "            0.9775 , 0.9766 , 0.976  , 0.974  , 0.9736 , 0.97   , 0.9683 ,\n",
       "            0.9663 , 0.9653 , 0.963  , 0.9624 , 0.961  , 0.9595 , 0.959  ,\n",
       "            0.9565 , 0.955  , 0.954  , 0.953  , 0.9517 , 0.9497 , 0.9463 ,\n",
       "            0.9434 , 0.9424 , 0.942  , 0.9375 , 0.937  , 0.9365 , 0.934  ,\n",
       "            0.932  , 0.9307 , 0.93   , 0.9263 , 0.9253 , 0.925  , 0.9243 ,\n",
       "            0.9233 , 0.919  , 0.9136 , 0.9116 , 0.908  , 0.9053 , 0.905  ,\n",
       "            0.9023 , 0.8984 , 0.8965 , 0.8955 , 0.895  , 0.89   , 0.8887 ,\n",
       "            0.888  , 0.886  , 0.882  , 0.8813 , 0.8804 , 0.8735 , 0.867  ,\n",
       "            0.8604 , 0.8535 , 0.853  , 0.8438 , 0.832  , 0.824  , 0.822  ,\n",
       "            0.8164 , 0.812  , 0.807  , 0.8066 , 0.8027 , 0.8013 , 0.7944 ,\n",
       "            0.7856 , 0.7803 , 0.775  , 0.774  , 0.7715 , 0.769  , 0.767  ,\n",
       "            0.7607 , 0.7446 , 0.742  , 0.732  , 0.7085 , 0.708  , 0.695  ,\n",
       "            0.6943 , 0.6816 , 0.6646 , 0.663  , 0.6587 , 0.658  , 0.6567 ,\n",
       "            0.6353 , 0.6343 , 0.63   , 0.6284 , 0.6123 , 0.587  , 0.5815 ,\n",
       "            0.581  , 0.557  , 0.5557 , 0.529  , 0.528  , 0.523  , 0.519  ,\n",
       "            0.5146 , 0.5137 , 0.506  , 0.4822 , 0.4812 , 0.4773 , 0.462  ,\n",
       "            0.4568 , 0.4492 , 0.4426 , 0.435  , 0.4219 , 0.4207 , 0.4185 ,\n",
       "            0.4155 , 0.4114 , 0.409  , 0.4053 , 0.3997 , 0.3972 , 0.3923 ,\n",
       "            0.3914 , 0.3906 , 0.3901 , 0.3853 , 0.3833 , 0.3801 , 0.3762 ,\n",
       "            0.3738 , 0.372  , 0.3716 , 0.3682 , 0.366  , 0.3657 , 0.3645 ,\n",
       "            0.359  , 0.3577 , 0.353  , 0.3474 , 0.3416 , 0.3372 , 0.3271 ,\n",
       "            0.3247 , 0.3225 , 0.3186 , 0.3164 , 0.316  , 0.3132 , 0.3066 ,\n",
       "            0.3013 , 0.2996 , 0.2974 , 0.2947 , 0.287  , 0.284  , 0.2715 ,\n",
       "            0.271  , 0.2708 , 0.2676 , 0.267  , 0.2573 , 0.2534 , 0.2456 ,\n",
       "            0.2441 , 0.2407 , 0.2351 , 0.229  , 0.224  , 0.2213 , 0.2205 ,\n",
       "            0.2124 , 0.2015 , 0.1797 , 0.1658 , 0.1656 , 0.1647 , 0.1644 ,\n",
       "            0.1602 , 0.1555 , 0.149  , 0.1461 , 0.1454 , 0.1404 , 0.1375 ,\n",
       "            0.137  , 0.1274 , 0.12   , 0.1074 , 0.10486, 0.1043 , 0.06384],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.23333333, dtype=float32),\n",
       "    'tpr': array(0.9692308, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.18333334, 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.02307692, 0.03076923, 0.04615385,\n",
       "            0.05384615, 0.06153846, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.20769231, 0.21538462,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.31538463, 0.32307693,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.5307692 , 0.53846157,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.77692306, 0.7846154 , 0.7923077 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.999  , 0.998  , 0.997  , 0.9966 , 0.9956 , 0.995  ,\n",
       "            0.9946 , 0.994  , 0.993  , 0.9927 , 0.992  , 0.9917 , 0.991  ,\n",
       "            0.99   , 0.9893 , 0.989  , 0.987  , 0.9863 , 0.986  , 0.985  ,\n",
       "            0.984  , 0.9834 , 0.983  , 0.982  , 0.9814 , 0.9805 , 0.98   ,\n",
       "            0.979  , 0.978  , 0.977  , 0.976  , 0.9736 , 0.972  , 0.9688 ,\n",
       "            0.9683 , 0.9653 , 0.964  , 0.962  , 0.9614 , 0.961  , 0.9585 ,\n",
       "            0.9575 , 0.957  , 0.955  , 0.953  , 0.9517 , 0.951  , 0.95   ,\n",
       "            0.9478 , 0.9453 , 0.941  , 0.9395 , 0.9375 , 0.935  , 0.9346 ,\n",
       "            0.9307 , 0.93   , 0.9287 , 0.928  , 0.9272 , 0.9243 , 0.924  ,\n",
       "            0.9233 , 0.923  , 0.922  , 0.9204 , 0.916  , 0.91   , 0.9067 ,\n",
       "            0.9033 , 0.903  , 0.8975 , 0.8965 , 0.894  , 0.8916 , 0.891  ,\n",
       "            0.887  , 0.886  , 0.8804 , 0.88   , 0.878  , 0.8755 , 0.8687 ,\n",
       "            0.8574 , 0.855  , 0.848  , 0.845  , 0.839  , 0.8174 , 0.817  ,\n",
       "            0.809  , 0.8047 , 0.804  , 0.801  , 0.798  , 0.7954 , 0.791  ,\n",
       "            0.785  , 0.7764 , 0.767  , 0.7666 , 0.766  , 0.7607 , 0.7583 ,\n",
       "            0.752  , 0.7515 , 0.7324 , 0.7275 , 0.7173 , 0.6934 , 0.6816 ,\n",
       "            0.6807 , 0.6763 , 0.664  , 0.649  , 0.643  , 0.6333 , 0.632  ,\n",
       "            0.631  , 0.614  , 0.6133 , 0.6055 , 0.6035 , 0.6016 , 0.584  ,\n",
       "            0.5596 , 0.5586 , 0.558  , 0.5386 , 0.5337 , 0.506  , 0.502  ,\n",
       "            0.4988 , 0.4973 , 0.4956 , 0.4836 , 0.476  , 0.4617 , 0.446  ,\n",
       "            0.4397 , 0.4314 , 0.4277 , 0.4248 , 0.4246 , 0.41   , 0.3994 ,\n",
       "            0.3923 , 0.3894 , 0.3882 , 0.3877 , 0.3845 , 0.376  , 0.3699 ,\n",
       "            0.3674 , 0.3652 , 0.365  , 0.3638 , 0.3635 , 0.3625 , 0.3574 ,\n",
       "            0.3513 , 0.351  , 0.3503 , 0.348  , 0.3477 , 0.345  , 0.3447 ,\n",
       "            0.337  , 0.3364 , 0.3347 , 0.3252 , 0.324  , 0.3235 , 0.3223 ,\n",
       "            0.3125 , 0.3115 , 0.308  , 0.2988 , 0.295  , 0.2898 , 0.289  ,\n",
       "            0.2869 , 0.286  , 0.281  , 0.2788 , 0.2727 , 0.2717 , 0.2708 ,\n",
       "            0.2695 , 0.2654 , 0.26   , 0.2598 , 0.247  , 0.2433 , 0.2378 ,\n",
       "            0.2368 , 0.2362 , 0.2303 , 0.2255 , 0.2222 , 0.2156 , 0.2147 ,\n",
       "            0.21   , 0.2059 , 0.2026 , 0.1982 , 0.1952 , 0.191  , 0.1846 ,\n",
       "            0.16   , 0.1498 , 0.1447 , 0.1434 , 0.1432 , 0.1338 , 0.133  ,\n",
       "            0.1272 , 0.1261 , 0.1225 , 0.1217 , 0.12024, 0.1095 , 0.1023 ,\n",
       "            0.0899 , 0.0895 , 0.0887 , 0.05127], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.23333333, dtype=float32),\n",
       "    'tpr': array(0.97692305, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.18333334, 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.28333333, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.04615385,\n",
       "            0.05384615, 0.06153846, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.16153847, 0.17692308, 0.2       , 0.20769231, 0.21538462,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33846155, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3923077 , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.5153846 , 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.75384617, 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.86923075, 0.8769231 ,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.999  , 0.9985 , 0.998  , 0.997  , 0.996  , 0.9956 ,\n",
       "            0.995  , 0.9946 , 0.9937 , 0.993  , 0.9927 , 0.992  , 0.9917 ,\n",
       "            0.991  , 0.99   , 0.9897 , 0.988  , 0.9873 , 0.987  , 0.9863 ,\n",
       "            0.986  , 0.985  , 0.9844 , 0.984  , 0.983  , 0.9824 , 0.982  ,\n",
       "            0.9814 , 0.981  , 0.9805 , 0.979  , 0.9785 , 0.978  , 0.9756 ,\n",
       "            0.9746 , 0.9717 , 0.97   , 0.967  , 0.9644 , 0.964  , 0.963  ,\n",
       "            0.961  , 0.9604 , 0.9595 , 0.958  , 0.9565 , 0.9536 , 0.9526 ,\n",
       "            0.9517 , 0.951  , 0.946  , 0.944  , 0.9434 , 0.9395 , 0.9355 ,\n",
       "            0.935  , 0.9346 , 0.9336 , 0.9326 , 0.932  , 0.9316 , 0.9277 ,\n",
       "            0.927  , 0.9263 , 0.926  , 0.9233 , 0.9155 , 0.9136 , 0.913  ,\n",
       "            0.9097 , 0.9053 , 0.905  , 0.904  , 0.899  , 0.897  , 0.895  ,\n",
       "            0.894  , 0.889  , 0.8887 , 0.887  , 0.8823 , 0.8804 , 0.8774 ,\n",
       "            0.8745 , 0.8667 , 0.8604 , 0.8535 , 0.851  , 0.8413 , 0.8154 ,\n",
       "            0.815  , 0.8076 , 0.806  , 0.8037 , 0.8022 , 0.8013 , 0.797  ,\n",
       "            0.7925 , 0.7876 , 0.778  , 0.7686 , 0.7676 , 0.765  , 0.7617 ,\n",
       "            0.7524 , 0.7437 , 0.7407 , 0.739  , 0.7285 , 0.687  , 0.681  ,\n",
       "            0.676  , 0.6655 , 0.66   , 0.659  , 0.6313 , 0.617  , 0.6147 ,\n",
       "            0.613  , 0.612  , 0.6016 , 0.601  , 0.5874 , 0.586  , 0.5815 ,\n",
       "            0.572  , 0.556  , 0.538  , 0.5312 , 0.5225 , 0.5176 , 0.5146 ,\n",
       "            0.504  , 0.4924 , 0.4822 , 0.4622 , 0.4563 , 0.4526 , 0.4282 ,\n",
       "            0.421  , 0.4207 , 0.419  , 0.4124 , 0.4077 , 0.3965 , 0.389  ,\n",
       "            0.3865 , 0.3828 , 0.382  , 0.381  , 0.3757 , 0.3752 , 0.3684 ,\n",
       "            0.3674 , 0.363  , 0.3538 , 0.3503 , 0.3484 , 0.3455 , 0.3376 ,\n",
       "            0.3367 , 0.3345 , 0.3342 , 0.3328 , 0.3313 , 0.3293 , 0.3262 ,\n",
       "            0.3179 , 0.3167 , 0.3066 , 0.3054 , 0.3015 , 0.2983 , 0.298  ,\n",
       "            0.2905 , 0.289  , 0.2883 , 0.283  , 0.2815 , 0.2686 , 0.2676 ,\n",
       "            0.266  , 0.2654 , 0.2646 , 0.2612 , 0.2595 , 0.2537 , 0.2502 ,\n",
       "            0.2496 , 0.2456 , 0.2401 , 0.2395 , 0.237  , 0.2322 , 0.2313 ,\n",
       "            0.224  , 0.2134 , 0.211  , 0.2089 , 0.2034 , 0.2002 , 0.199  ,\n",
       "            0.1981 , 0.1979 , 0.1929 , 0.1927 , 0.1892 , 0.1882 , 0.1581 ,\n",
       "            0.1531 , 0.1476 , 0.1398 , 0.138  , 0.1376 , 0.137  , 0.1284 ,\n",
       "            0.1278 , 0.1259 , 0.1252 , 0.1204 , 0.115  , 0.10895, 0.0974 ,\n",
       "            0.09186, 0.0848 , 0.08386, 0.05014], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.21666667, dtype=float32),\n",
       "    'tpr': array(0.9692308, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.07692308, 0.09230769,\n",
       "            0.1       , 0.13076924, 0.13846155, 0.15384616, 0.16923077,\n",
       "            0.17692308, 0.2       , 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.2769231 , 0.2769231 ,\n",
       "            0.2923077 , 0.31538463, 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.5307692 , 0.53846157, 0.53846157, 0.54615384, 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.999  , 0.9985 , 0.998  , 0.997  , 0.9966 , 0.996  ,\n",
       "            0.995  , 0.9946 , 0.994  , 0.993  , 0.9927 , 0.9917 , 0.99   ,\n",
       "            0.9897 , 0.989  , 0.9873 , 0.986  , 0.9854 , 0.985  , 0.9844 ,\n",
       "            0.984  , 0.983  , 0.9824 , 0.982  , 0.981  , 0.98   , 0.9775 ,\n",
       "            0.9766 , 0.976  , 0.9756 , 0.9746 , 0.973  , 0.9697 , 0.967  ,\n",
       "            0.9663 , 0.966  , 0.965  , 0.963  , 0.9624 , 0.959  , 0.9585 ,\n",
       "            0.958  , 0.9565 , 0.9556 , 0.955  , 0.951  , 0.9487 , 0.948  ,\n",
       "            0.942  , 0.94   , 0.936  , 0.9355 , 0.93   , 0.929  , 0.928  ,\n",
       "            0.9277 , 0.9272 , 0.9263 , 0.9243 , 0.924  , 0.9204 , 0.9194 ,\n",
       "            0.919  , 0.916  , 0.9106 , 0.9062 , 0.9033 , 0.8994 , 0.8965 ,\n",
       "            0.8955 , 0.8936 , 0.89   , 0.888  , 0.884  , 0.879  , 0.878  ,\n",
       "            0.877  , 0.873  , 0.8716 , 0.868  , 0.866  , 0.8535 , 0.853  ,\n",
       "            0.8413 , 0.832  , 0.8247 , 0.8057 , 0.7993 , 0.793  , 0.7876 ,\n",
       "            0.786  , 0.7856 , 0.7837 , 0.7803 , 0.7686 , 0.768  , 0.7617 ,\n",
       "            0.7583 , 0.7485 , 0.747  , 0.7466 , 0.7417 , 0.73   , 0.725  ,\n",
       "            0.721  , 0.714  , 0.7056 , 0.6675 , 0.665  , 0.649  , 0.6406 ,\n",
       "            0.6353 , 0.628  , 0.613  , 0.5938 , 0.588  , 0.581  , 0.574  ,\n",
       "            0.5674 , 0.5586 , 0.558  , 0.5547 , 0.551  , 0.5376 , 0.515  ,\n",
       "            0.5117 , 0.511  , 0.502  , 0.482  , 0.4795 , 0.4714 , 0.4695 ,\n",
       "            0.4607 , 0.4324 , 0.4314 , 0.4275 , 0.4001 , 0.3887 , 0.3833 ,\n",
       "            0.3828 , 0.3823 , 0.3796 , 0.3716 , 0.3682 , 0.3606 , 0.3555 ,\n",
       "            0.3477 , 0.3425 , 0.3408 , 0.34   , 0.3396 , 0.3367 , 0.3354 ,\n",
       "            0.3318 , 0.3289 , 0.3254 , 0.323  , 0.3186 , 0.3157 , 0.3154 ,\n",
       "            0.313  , 0.3127 , 0.3103 , 0.3083 , 0.304  , 0.296  , 0.2944 ,\n",
       "            0.2874 , 0.2842 , 0.283  , 0.2766 , 0.272  , 0.268  , 0.2678 ,\n",
       "            0.2627 , 0.2622 , 0.2534 , 0.2493 , 0.247  , 0.2428 , 0.2388 ,\n",
       "            0.2351 , 0.2339 , 0.2328 , 0.2297 , 0.2289 , 0.2278 , 0.2257 ,\n",
       "            0.222  , 0.2202 , 0.2104 , 0.2013 , 0.1993 , 0.1919 , 0.1893 ,\n",
       "            0.1874 , 0.1873 , 0.1797 , 0.179  , 0.1781 , 0.1764 , 0.1737 ,\n",
       "            0.1727 , 0.1707 , 0.1666 , 0.1638 , 0.1542 , 0.1384 , 0.1305 ,\n",
       "            0.12317, 0.122  , 0.1201 , 0.1142 , 0.1128 , 0.1078 , 0.1047 ,\n",
       "            0.1036 , 0.1021 , 0.0997 , 0.09875, 0.0906 , 0.07764, 0.0741 ,\n",
       "            0.0707 , 0.06757, 0.0384 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.175, dtype=float32),\n",
       "    'tpr': array(0.96153843, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.04615385,\n",
       "            0.05384615, 0.06153846, 0.06923077, 0.07692308, 0.09230769,\n",
       "            0.1       , 0.12307692, 0.13076924, 0.14615385, 0.15384616,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.21538462,\n",
       "            0.22307692, 0.23846154, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2846154 , 0.2923077 , 0.30769232, 0.31538463, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3923077 , 0.4       , 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.54615384, 0.56153846,\n",
       "            0.5692308 , 0.5846154 , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7923077 , 0.8       , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.999  , 0.9985 , 0.998  , 0.997  , 0.996  , 0.9956 ,\n",
       "            0.995  , 0.9946 , 0.9937 , 0.993  , 0.992  , 0.9917 , 0.9907 ,\n",
       "            0.9893 , 0.989  , 0.9883 , 0.9863 , 0.986  , 0.9854 , 0.985  ,\n",
       "            0.9834 , 0.983  , 0.9824 , 0.981  , 0.98   , 0.9795 , 0.978  ,\n",
       "            0.9775 , 0.977  , 0.9766 , 0.976  , 0.975  , 0.971  , 0.9688 ,\n",
       "            0.9673 , 0.966  , 0.9634 , 0.959  , 0.958  , 0.9556 , 0.9526 ,\n",
       "            0.952  , 0.9517 , 0.948  , 0.9473 , 0.947  , 0.9424 , 0.94   ,\n",
       "            0.9395 , 0.9365 , 0.9316 , 0.928  , 0.9272 , 0.9263 , 0.922  ,\n",
       "            0.9194 , 0.919  , 0.9185 , 0.918  , 0.916  , 0.9155 , 0.909  ,\n",
       "            0.905  , 0.903  , 0.9023 , 0.8984 , 0.8945 , 0.8916 , 0.886  ,\n",
       "            0.882  , 0.8813 , 0.881  , 0.876  , 0.8745 , 0.873  , 0.8696 ,\n",
       "            0.866  , 0.8633 , 0.862  , 0.855  , 0.84   , 0.827  , 0.8267 ,\n",
       "            0.82   , 0.8193 , 0.793  , 0.787  , 0.7812 , 0.78   , 0.7744 ,\n",
       "            0.774  , 0.77   , 0.754  , 0.7534 , 0.752  , 0.751  , 0.739  ,\n",
       "            0.7334 , 0.7246 , 0.7207 , 0.7153 , 0.7085 , 0.703  , 0.671  ,\n",
       "            0.6694 , 0.6523 , 0.6465 , 0.6245 , 0.608  , 0.605  , 0.599  ,\n",
       "            0.5884 , 0.568  , 0.5674 , 0.5586 , 0.555  , 0.5464 , 0.538  ,\n",
       "            0.5312 , 0.5273 , 0.4944 , 0.4895 , 0.4893 , 0.488  , 0.4858 ,\n",
       "            0.4766 , 0.447  , 0.446  , 0.4355 , 0.4336 , 0.4075 , 0.4067 ,\n",
       "            0.4036 , 0.3765 , 0.361  , 0.3596 , 0.358  , 0.3513 , 0.3462 ,\n",
       "            0.344  , 0.341  , 0.334  , 0.3245 , 0.321  , 0.3164 , 0.3154 ,\n",
       "            0.3123 , 0.304  , 0.302  , 0.3013 , 0.296  , 0.2947 , 0.2935 ,\n",
       "            0.2913 , 0.2886 , 0.288  , 0.2866 , 0.2864 , 0.2847 , 0.2825 ,\n",
       "            0.2808 , 0.2756 , 0.2751 , 0.2727 , 0.268  , 0.2632 , 0.258  ,\n",
       "            0.2532 , 0.2478 , 0.2462 , 0.243  , 0.2274 , 0.2266 , 0.2264 ,\n",
       "            0.222  , 0.2211 , 0.2191 , 0.2145 , 0.2109 , 0.2091 , 0.2084 ,\n",
       "            0.207  , 0.2037 , 0.2012 , 0.1987 , 0.1921 , 0.1909 , 0.178  ,\n",
       "            0.1721 , 0.1678 , 0.1672 , 0.1665 , 0.1661 , 0.1609 , 0.1603 ,\n",
       "            0.1593 , 0.1569 , 0.1556 , 0.1543 , 0.1512 , 0.138  , 0.1351 ,\n",
       "            0.1333 , 0.1198 , 0.10706, 0.10596, 0.1043 , 0.0979 , 0.0909 ,\n",
       "            0.0899 , 0.0876 , 0.086  , 0.08435, 0.0831 , 0.08167, 0.074  ,\n",
       "            0.0661 , 0.05878, 0.05685, 0.02898], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.16666667, dtype=float32),\n",
       "    'tpr': array(0.96153843, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.09166667, 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.09230769, 0.1       , 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.25384617, 0.26153848, 0.26923078, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.30769232, 0.31538463, 0.33076924,\n",
       "            0.33846155, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.41538462, 0.43076923,\n",
       "            0.43846154, 0.46153846, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.5692308 , 0.5769231 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.999  , 0.9985 , 0.998  , 0.9976 , 0.997  , 0.996  ,\n",
       "            0.9956 , 0.995  , 0.9946 , 0.994  , 0.993  , 0.9927 , 0.992  ,\n",
       "            0.9917 , 0.9907 , 0.9897 , 0.9893 , 0.989  , 0.987  , 0.9863 ,\n",
       "            0.986  , 0.9854 , 0.985  , 0.9844 , 0.984  , 0.9834 , 0.983  ,\n",
       "            0.982  , 0.9814 , 0.981  , 0.9805 , 0.979  , 0.978  , 0.977  ,\n",
       "            0.9766 , 0.976  , 0.972  , 0.969  , 0.9673 , 0.9663 , 0.966  ,\n",
       "            0.9644 , 0.96   , 0.959  , 0.954  , 0.953  , 0.9526 , 0.948  ,\n",
       "            0.9473 , 0.9463 , 0.9434 , 0.939  , 0.9375 , 0.932  , 0.9287 ,\n",
       "            0.9253 , 0.924  , 0.923  , 0.92   , 0.9194 , 0.918  , 0.917  ,\n",
       "            0.9165 , 0.916  , 0.913  , 0.909  , 0.903  , 0.9014 , 0.9    ,\n",
       "            0.897  , 0.892  , 0.8906 , 0.885  , 0.8804 , 0.88   , 0.8745 ,\n",
       "            0.873  , 0.871  , 0.8706 , 0.868  , 0.8643 , 0.8604 , 0.859  ,\n",
       "            0.8535 , 0.853  , 0.8384 , 0.8237 , 0.8228 , 0.817  , 0.816  ,\n",
       "            0.7856 , 0.7837 , 0.7764 , 0.7744 , 0.769  , 0.765  , 0.753  ,\n",
       "            0.7476 , 0.746  , 0.7446 , 0.734  , 0.732  , 0.7285 , 0.728  ,\n",
       "            0.7163 , 0.7153 , 0.707  , 0.6963 , 0.692  , 0.659  , 0.6587 ,\n",
       "            0.6406 , 0.6357 , 0.607  , 0.594  , 0.5864 , 0.571  , 0.548  ,\n",
       "            0.5415 , 0.5376 , 0.536  , 0.529  , 0.514  , 0.5015 , 0.4978 ,\n",
       "            0.4797 , 0.4736 , 0.4717 , 0.4673 , 0.4653 , 0.457  , 0.4316 ,\n",
       "            0.4263 , 0.415  , 0.4146 , 0.3867 , 0.3855 , 0.3809 , 0.3796 ,\n",
       "            0.359  , 0.35   , 0.3347 , 0.3333 , 0.3306 , 0.33   , 0.328  ,\n",
       "            0.319  , 0.3147 , 0.3137 , 0.3057 , 0.3018 , 0.295  , 0.2925 ,\n",
       "            0.2832 , 0.282  , 0.2805 , 0.2786 , 0.2761 , 0.276  , 0.2717 ,\n",
       "            0.2686 , 0.2673 , 0.2664 , 0.266  , 0.2632 , 0.2605 , 0.2595 ,\n",
       "            0.2566 , 0.253  , 0.251  , 0.2483 , 0.2451 , 0.2301 , 0.2299 ,\n",
       "            0.226  , 0.2252 , 0.2244 , 0.2177 , 0.2089 , 0.206  , 0.2032 ,\n",
       "            0.2028 , 0.2013 , 0.1985 , 0.1931 , 0.1901 , 0.19   , 0.1892 ,\n",
       "            0.1836 , 0.1831 , 0.183  , 0.1808 , 0.1744 , 0.1699 , 0.1592 ,\n",
       "            0.1588 , 0.154  , 0.1521 , 0.1497 , 0.1495 , 0.1486 , 0.1455 ,\n",
       "            0.1445 , 0.1442 , 0.1416 , 0.1373 , 0.1282 , 0.1243 , 0.1186 ,\n",
       "            0.1082 , 0.096  , 0.09515, 0.0945 , 0.09235, 0.0862 , 0.0824 ,\n",
       "            0.08105, 0.0799 , 0.0798 , 0.07544, 0.07275, 0.0712 , 0.06525,\n",
       "            0.0619 , 0.05234, 0.05167, 0.04868, 0.02423], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.15, dtype=float32),\n",
       "    'tpr': array(0.96153843, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.425     , 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.11538462, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.16923077, 0.17692308, 0.1923077 , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.42307693, 0.43076923, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.61538464, 0.6230769 ,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.999  , 0.9985 , 0.998  , 0.9976 , 0.997  , 0.9966 ,\n",
       "            0.9956 , 0.995  , 0.9946 , 0.994  , 0.9937 , 0.993  , 0.9927 ,\n",
       "            0.9917 , 0.9907 , 0.9897 , 0.989  , 0.987  , 0.9863 , 0.986  ,\n",
       "            0.985  , 0.9844 , 0.984  , 0.9834 , 0.9824 , 0.982  , 0.9814 ,\n",
       "            0.981  , 0.9795 , 0.9785 , 0.978  , 0.9775 , 0.977  , 0.9766 ,\n",
       "            0.9727 , 0.9697 , 0.9683 , 0.9673 , 0.967  , 0.9644 , 0.9604 ,\n",
       "            0.9595 , 0.954  , 0.9536 , 0.953  , 0.9526 , 0.948  , 0.947  ,\n",
       "            0.945  , 0.944  , 0.9395 , 0.938  , 0.936  , 0.9326 , 0.929  ,\n",
       "            0.9263 , 0.9233 , 0.922  , 0.9204 , 0.92   , 0.9194 , 0.918  ,\n",
       "            0.917  , 0.9165 , 0.916  , 0.9116 , 0.9097 , 0.903  , 0.902  ,\n",
       "            0.898  , 0.8965 , 0.8916 , 0.891  , 0.8853 , 0.881  , 0.879  ,\n",
       "            0.8745 , 0.8735 , 0.868  , 0.8677 , 0.8647 , 0.8604 , 0.856  ,\n",
       "            0.853  , 0.8374 , 0.824  , 0.8213 , 0.817  , 0.815  , 0.782  ,\n",
       "            0.779  , 0.7744 , 0.7686 , 0.765  , 0.7637 , 0.747  , 0.744  ,\n",
       "            0.74   , 0.7334 , 0.7314 , 0.7256 , 0.725  , 0.714  , 0.7124 ,\n",
       "            0.704  , 0.6934 , 0.6753 , 0.656  , 0.655  , 0.6284 , 0.59   ,\n",
       "            0.589  , 0.582  , 0.555  , 0.539  , 0.5347 , 0.529  , 0.5166 ,\n",
       "            0.516  , 0.5005 , 0.4905 , 0.4756 , 0.4727 , 0.4692 , 0.4663 ,\n",
       "            0.4653 , 0.454  , 0.4446 , 0.4421 , 0.4258 , 0.4124 , 0.4075 ,\n",
       "            0.399  , 0.3774 , 0.3728 , 0.3552 , 0.3545 , 0.3481 , 0.342  ,\n",
       "            0.33   , 0.3188 , 0.3157 , 0.3135 , 0.3074 , 0.3064 , 0.3013 ,\n",
       "            0.2993 , 0.2888 , 0.2864 , 0.2795 , 0.2756 , 0.269  , 0.2637 ,\n",
       "            0.263  , 0.2627 , 0.2612 , 0.2598 , 0.2595 , 0.2588 , 0.2556 ,\n",
       "            0.2534 , 0.2496 , 0.2466 , 0.2449 , 0.2434 , 0.2397 , 0.2374 ,\n",
       "            0.2351 , 0.2338 , 0.2285 , 0.2129 , 0.2118 , 0.2115 , 0.2084 ,\n",
       "            0.2074 , 0.2035 , 0.1987 , 0.1959 , 0.1918 , 0.186  , 0.1859 ,\n",
       "            0.1858 , 0.1774 , 0.1758 , 0.1737 , 0.1735 , 0.1733 , 0.1678 ,\n",
       "            0.167  , 0.165  , 0.162  , 0.1605 , 0.1558 , 0.154  , 0.1464 ,\n",
       "            0.1444 , 0.1409 , 0.1399 , 0.1392 , 0.138  , 0.136  , 0.1274 ,\n",
       "            0.1261 , 0.1243 , 0.1226 , 0.119  , 0.1134 , 0.1011 , 0.09076,\n",
       "            0.089  , 0.0885 , 0.0877 , 0.0818 , 0.07935, 0.0772 , 0.07574,\n",
       "            0.0741 , 0.06915, 0.06903, 0.06757, 0.0602 , 0.0591 , 0.0495 ,\n",
       "            0.04752, 0.0457 , 0.02191], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.11666667, dtype=float32),\n",
       "    'tpr': array(0.96153843, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.04615385,\n",
       "            0.05384615, 0.06153846, 0.06923077, 0.07692308, 0.09230769,\n",
       "            0.1       , 0.11538462, 0.13076924, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.21538462, 0.22307692, 0.23846154, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.2846154 , 0.31538463, 0.33076924, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.5692308 , 0.5846154 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.999  , 0.9985 , 0.998  , 0.997  , 0.996  , 0.9956 ,\n",
       "            0.995  , 0.9946 , 0.9937 , 0.993  , 0.992  , 0.9917 , 0.9907 ,\n",
       "            0.9897 , 0.989  , 0.9883 , 0.9873 , 0.986  , 0.9854 , 0.985  ,\n",
       "            0.9844 , 0.9824 , 0.9814 , 0.981  , 0.98   , 0.9785 , 0.977  ,\n",
       "            0.9766 , 0.976  , 0.9756 , 0.974  , 0.969  , 0.968  , 0.967  ,\n",
       "            0.9653 , 0.9624 , 0.961  , 0.9595 , 0.956  , 0.955  , 0.9517 ,\n",
       "            0.948  , 0.9478 , 0.9473 , 0.943  , 0.942  , 0.941  , 0.938  ,\n",
       "            0.932  , 0.9316 , 0.9287 , 0.925  , 0.9214 , 0.917  , 0.915  ,\n",
       "            0.9146 , 0.9106 , 0.9097 , 0.908  , 0.9077 , 0.9    , 0.8984 ,\n",
       "            0.8955 , 0.8936 , 0.89   , 0.889  , 0.8867 , 0.883  , 0.8774 ,\n",
       "            0.8716 , 0.8706 , 0.8696 , 0.867  , 0.8667 , 0.8643 , 0.8613 ,\n",
       "            0.8486 , 0.8447 , 0.84   , 0.8364 , 0.8237 , 0.8193 , 0.812  ,\n",
       "            0.799  , 0.7954 , 0.7686 , 0.768  , 0.7646 , 0.7583 , 0.757  ,\n",
       "            0.743  , 0.7393 , 0.7246 , 0.721  , 0.7188 , 0.7183 , 0.7134 ,\n",
       "            0.7104 , 0.705  , 0.686  , 0.6772 , 0.6763 , 0.673  , 0.6562 ,\n",
       "            0.627  , 0.621  , 0.614  , 0.6064 , 0.5684 , 0.5586 , 0.554  ,\n",
       "            0.526  , 0.5215 , 0.5063 , 0.4966 , 0.495  , 0.4902 , 0.472  ,\n",
       "            0.466  , 0.462  , 0.444  , 0.441  , 0.4324 , 0.4287 , 0.4248 ,\n",
       "            0.4155 , 0.4128 , 0.4028 , 0.3875 , 0.3765 , 0.3718 , 0.3496 ,\n",
       "            0.3398 , 0.3323 , 0.3298 , 0.3289 , 0.3154 , 0.3071 , 0.2957 ,\n",
       "            0.295  , 0.2903 , 0.2864 , 0.2778 , 0.2751 , 0.2683 , 0.2637 ,\n",
       "            0.2622 , 0.2485 , 0.2473 , 0.2471 , 0.2456 , 0.244  , 0.2433 ,\n",
       "            0.2429 , 0.2378 , 0.2346 , 0.2316 , 0.2311 , 0.2292 , 0.2289 ,\n",
       "            0.2268 , 0.226  , 0.2244 , 0.2207 , 0.2168 , 0.2137 , 0.2123 ,\n",
       "            0.2006 , 0.1976 , 0.1931 , 0.1913 , 0.1909 , 0.1887 , 0.1859 ,\n",
       "            0.1766 , 0.1748 , 0.1747 , 0.172  , 0.1711 , 0.1665 , 0.163  ,\n",
       "            0.1589 , 0.1582 , 0.1552 , 0.1531 , 0.1528 , 0.1481 , 0.1458 ,\n",
       "            0.1451 , 0.1447 , 0.1439 , 0.1356 , 0.1312 , 0.1305 , 0.1301 ,\n",
       "            0.13   , 0.1267 , 0.1245 , 0.11597, 0.11316, 0.1128 , 0.1101 ,\n",
       "            0.1067 , 0.0986 , 0.09186, 0.0823 , 0.08105, 0.0805 , 0.0801 ,\n",
       "            0.0733 , 0.0716 , 0.07135, 0.0662 , 0.0661 , 0.06232, 0.0602 ,\n",
       "            0.05856, 0.0544 , 0.0533 , 0.04544, 0.04303, 0.03918, 0.01851],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.10833333, dtype=float32),\n",
       "    'tpr': array(0.96153843, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.04615385,\n",
       "            0.05384615, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.11538462, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16923077, 0.17692308, 0.1923077 , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.32307693, 0.33846155, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.47692308, 0.5       ,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.999  , 0.9985 , 0.998  , 0.997  , 0.996  , 0.995  ,\n",
       "            0.9946 , 0.994  , 0.9937 , 0.993  , 0.992  , 0.9917 , 0.991  ,\n",
       "            0.99   , 0.9893 , 0.989  , 0.988  , 0.986  , 0.9854 , 0.9844 ,\n",
       "            0.984  , 0.983  , 0.982  , 0.981  , 0.9805 , 0.9795 , 0.979  ,\n",
       "            0.9775 , 0.977  , 0.9766 , 0.976  , 0.9746 , 0.974  , 0.97   ,\n",
       "            0.967  , 0.9663 , 0.966  , 0.9634 , 0.9604 , 0.9585 , 0.9565 ,\n",
       "            0.956  , 0.955  , 0.949  , 0.9487 , 0.948  , 0.946  , 0.943  ,\n",
       "            0.9385 , 0.931  , 0.928  , 0.9253 , 0.9224 , 0.922  , 0.915  ,\n",
       "            0.9126 , 0.912  , 0.9116 , 0.911  , 0.9106 , 0.9097 , 0.908  ,\n",
       "            0.9077 , 0.9033 , 0.8994 , 0.8965 , 0.8926 , 0.892  , 0.8853 ,\n",
       "            0.884  , 0.882  , 0.879  , 0.8735 , 0.8677 , 0.866  , 0.8647 ,\n",
       "            0.8643 , 0.859  , 0.857  , 0.8545 , 0.845  , 0.842  , 0.8384 ,\n",
       "            0.837  , 0.822  , 0.813  , 0.8057 , 0.8003 , 0.7954 , 0.7617 ,\n",
       "            0.7607 , 0.757  , 0.7476 , 0.7417 , 0.7305 , 0.7183 , 0.716  ,\n",
       "            0.7124 , 0.71   , 0.701  , 0.6953 , 0.69   , 0.6855 , 0.676  ,\n",
       "            0.6675 , 0.6523 , 0.6377 , 0.6245 , 0.621  , 0.598  , 0.5938 ,\n",
       "            0.5557 , 0.5503 , 0.549  , 0.508  , 0.504  , 0.478  , 0.4749 ,\n",
       "            0.4705 , 0.4666 , 0.4478 , 0.4465 , 0.4436 , 0.429  , 0.4248 ,\n",
       "            0.4187 , 0.4163 , 0.4104 , 0.3953 , 0.3862 , 0.372  , 0.3687 ,\n",
       "            0.3503 , 0.3386 , 0.3323 , 0.317  , 0.3154 , 0.3115 , 0.308  ,\n",
       "            0.3013 , 0.2961 , 0.2822 , 0.281  , 0.274  , 0.2737 , 0.268  ,\n",
       "            0.2532 , 0.253  , 0.2505 , 0.2438 , 0.2397 , 0.2335 , 0.231  ,\n",
       "            0.2303 , 0.2302 , 0.2301 , 0.2286 , 0.2281 , 0.2255 , 0.2234 ,\n",
       "            0.2222 , 0.2216 , 0.2191 , 0.2145 , 0.214  , 0.2109 , 0.208  ,\n",
       "            0.2018 , 0.2002 , 0.19   , 0.1891 , 0.1841 , 0.1794 , 0.179  ,\n",
       "            0.1774 , 0.1726 , 0.171  , 0.1707 , 0.1647 , 0.1632 , 0.1594 ,\n",
       "            0.1581 , 0.1575 , 0.1505 , 0.146  , 0.1459 , 0.1451 , 0.1439 ,\n",
       "            0.1401 , 0.1367 , 0.1365 , 0.1359 , 0.1307 , 0.1296 , 0.1273 ,\n",
       "            0.1267 , 0.12476, 0.1241 , 0.1225 , 0.12067, 0.1124 , 0.1084 ,\n",
       "            0.103  , 0.10156, 0.1005 , 0.0991 , 0.0962 , 0.0876 , 0.07764,\n",
       "            0.07654, 0.0764 , 0.0753 , 0.06915, 0.06805, 0.0667 , 0.06396,\n",
       "            0.0629 , 0.05844, 0.05823, 0.05676, 0.0504 , 0.05032, 0.04193,\n",
       "            0.03986, 0.0378 , 0.01724], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.09166667, dtype=float32),\n",
       "    'tpr': array(0.96153843, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.09166667, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.18333334, 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.02307692, 0.03076923, 0.04615385,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.1       , 0.10769231,\n",
       "            0.12307692, 0.13846155, 0.15384616, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.20769231, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.25384617, 0.26153848, 0.26923078, 0.2923077 ,\n",
       "            0.3       , 0.31538463, 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.61538464, 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.6615385 , 0.6846154 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.999  , 0.998  , 0.997  , 0.9966 , 0.995  , 0.994  ,\n",
       "            0.993  , 0.9927 , 0.991  , 0.9907 , 0.99   , 0.9893 , 0.987  ,\n",
       "            0.986  , 0.9854 , 0.984  , 0.9834 , 0.9824 , 0.9805 , 0.9795 ,\n",
       "            0.979  , 0.9775 , 0.977  , 0.9766 , 0.976  , 0.9756 , 0.974  ,\n",
       "            0.9736 , 0.9727 , 0.9717 , 0.97   , 0.967  , 0.9653 , 0.965  ,\n",
       "            0.9595 , 0.958  , 0.9565 , 0.955  , 0.949  , 0.948  , 0.9478 ,\n",
       "            0.9473 , 0.9404 , 0.94   , 0.9395 , 0.9385 , 0.9365 , 0.935  ,\n",
       "            0.9307 , 0.9287 , 0.9263 , 0.922  , 0.9214 , 0.914  , 0.913  ,\n",
       "            0.9106 , 0.9097 , 0.906  , 0.9033 , 0.901  , 0.8975 , 0.897  ,\n",
       "            0.8955 , 0.895  , 0.8945 , 0.89   , 0.883  , 0.879  , 0.877  ,\n",
       "            0.8765 , 0.8706 , 0.865  , 0.8633 , 0.861  , 0.856  , 0.8535 ,\n",
       "            0.85   , 0.8486 , 0.8467 , 0.837  , 0.822  , 0.819  , 0.8125 ,\n",
       "            0.8086 , 0.802  , 0.801  , 0.7666 , 0.766  , 0.755  , 0.749  ,\n",
       "            0.74   , 0.7397 , 0.737  , 0.723  , 0.712  , 0.7085 , 0.7026 ,\n",
       "            0.692  , 0.6885 , 0.6875 , 0.6816 , 0.672  , 0.646  , 0.639  ,\n",
       "            0.6367 , 0.631  , 0.622  , 0.586  , 0.5845 , 0.5737 , 0.568  ,\n",
       "            0.532  , 0.513  , 0.5127 , 0.4944 , 0.4749 , 0.4573 , 0.453  ,\n",
       "            0.446  , 0.4402 , 0.4343 , 0.4243 , 0.4233 , 0.3958 , 0.3945 ,\n",
       "            0.3857 , 0.3848 , 0.3699 , 0.3694 , 0.366  , 0.3584 , 0.3445 ,\n",
       "            0.3318 , 0.3254 , 0.31   , 0.304  , 0.296  , 0.2935 , 0.2903 ,\n",
       "            0.289  , 0.2874 , 0.2832 , 0.2698 , 0.264  , 0.261  , 0.247  ,\n",
       "            0.2386 , 0.2375 , 0.2368 , 0.2335 , 0.2202 , 0.2195 , 0.2167 ,\n",
       "            0.2158 , 0.2147 , 0.2134 , 0.2086 , 0.2084 , 0.2073 , 0.2069 ,\n",
       "            0.2015 , 0.2001 , 0.1984 , 0.1981 , 0.1954 , 0.1953 , 0.1942 ,\n",
       "            0.1927 , 0.1912 , 0.1884 , 0.1877 , 0.1791 , 0.1715 , 0.171  ,\n",
       "            0.1688 , 0.167  , 0.1652 , 0.1578 , 0.1571 , 0.1543 , 0.1511 ,\n",
       "            0.1482 , 0.1466 , 0.1458 , 0.1395 , 0.1365 , 0.1345 , 0.1322 ,\n",
       "            0.1289 , 0.1271 , 0.1268 , 0.12305, 0.12177, 0.1188 , 0.1186 ,\n",
       "            0.11755, 0.11475, 0.1142 , 0.1138 , 0.111  , 0.108  , 0.1025 ,\n",
       "            0.10034, 0.0922 , 0.0904 , 0.0903 , 0.0893 , 0.07935, 0.07806,\n",
       "            0.07056, 0.0688 , 0.06793, 0.066  , 0.06244, 0.06143, 0.0572 ,\n",
       "            0.055  , 0.0531 , 0.05194, 0.0483 , 0.0468 , 0.04596, 0.0437 ,\n",
       "            0.03824, 0.03574, 0.03073, 0.01428], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.08333334, dtype=float32),\n",
       "    'tpr': array(0.95384616, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.19166666, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.12307692,\n",
       "            0.13846155, 0.15384616, 0.16153847, 0.16923077, 0.18461539,\n",
       "            0.1923077 , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.25384617, 0.26923078, 0.2769231 , 0.3       , 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.6615385 , 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.999  , 0.998  , 0.9976 , 0.997  , 0.9966 , 0.996  ,\n",
       "            0.995  , 0.9946 , 0.9937 , 0.9927 , 0.992  , 0.9917 , 0.99   ,\n",
       "            0.9897 , 0.9893 , 0.9883 , 0.986  , 0.9854 , 0.984  , 0.983  ,\n",
       "            0.982  , 0.981  , 0.9805 , 0.9785 , 0.977  , 0.975  , 0.9746 ,\n",
       "            0.974  , 0.973  , 0.9717 , 0.971  , 0.9707 , 0.9697 , 0.969  ,\n",
       "            0.968  , 0.9634 , 0.962  , 0.961  , 0.9556 , 0.954  , 0.9526 ,\n",
       "            0.9507 , 0.9453 , 0.944  , 0.9434 , 0.943  , 0.936  , 0.935  ,\n",
       "            0.9346 , 0.932  , 0.931  , 0.929  , 0.9233 , 0.9204 , 0.916  ,\n",
       "            0.9146 , 0.9062 , 0.9053 , 0.9033 , 0.903  , 0.9023 , 0.8984 ,\n",
       "            0.8965 , 0.893  , 0.89   , 0.889  , 0.888  , 0.8877 , 0.886  ,\n",
       "            0.8853 , 0.8804 , 0.8745 , 0.8716 , 0.87   , 0.8696 , 0.8657 ,\n",
       "            0.865  , 0.858  , 0.8545 , 0.852  , 0.845  , 0.844  , 0.842  ,\n",
       "            0.84   , 0.838  , 0.836  , 0.8257 , 0.81   , 0.8086 , 0.8    ,\n",
       "            0.7905 , 0.7847 , 0.752  , 0.7505 , 0.739  , 0.734  , 0.7246 ,\n",
       "            0.724  , 0.7236 , 0.699  , 0.6973 , 0.689  , 0.684  , 0.6743 ,\n",
       "            0.672  , 0.667  , 0.664  , 0.651  , 0.628  , 0.623  , 0.6187 ,\n",
       "            0.6074 , 0.6016 , 0.567  , 0.5664 , 0.553  , 0.549  , 0.511  ,\n",
       "            0.4954 , 0.4944 , 0.459  , 0.448  , 0.4365 , 0.4285 , 0.424  ,\n",
       "            0.409  , 0.403  , 0.4016 , 0.4006 , 0.3735 , 0.372  , 0.3684 ,\n",
       "            0.3657 , 0.3525 , 0.349  , 0.3481 , 0.3293 , 0.3264 , 0.3157 ,\n",
       "            0.3037 , 0.294  , 0.2832 , 0.2803 , 0.2756 , 0.273  , 0.271  ,\n",
       "            0.27   , 0.2532 , 0.2515 , 0.2458 , 0.2355 , 0.2266 , 0.226  ,\n",
       "            0.2257 , 0.2255 , 0.2166 , 0.2089 , 0.2058 , 0.2035 , 0.2012 ,\n",
       "            0.2009 , 0.196  , 0.1946 , 0.1936 , 0.1904 , 0.188  , 0.1871 ,\n",
       "            0.1866 , 0.1852 , 0.1836 , 0.1821 , 0.182  , 0.1819 , 0.1798 ,\n",
       "            0.1771 , 0.177  , 0.1608 , 0.1588 , 0.1561 , 0.1544 , 0.153  ,\n",
       "            0.1509 , 0.1456 , 0.143  , 0.141  , 0.1383 , 0.137  , 0.1366 ,\n",
       "            0.1335 , 0.1332 , 0.1299 , 0.12476, 0.12177, 0.1194 , 0.1188 ,\n",
       "            0.11395, 0.112  , 0.1099 , 0.1084 , 0.108  , 0.1076 , 0.1063 ,\n",
       "            0.10394, 0.1032 , 0.10144, 0.0993 , 0.094  , 0.0856 , 0.08405,\n",
       "            0.0825 , 0.082  , 0.07385, 0.0721 , 0.06305, 0.0621 , 0.0619 ,\n",
       "            0.06076, 0.0534 , 0.0531 , 0.05252, 0.0504 , 0.0496 , 0.04715,\n",
       "            0.0452 , 0.0437 , 0.0397 , 0.0389 , 0.0324 , 0.03102, 0.02849,\n",
       "            0.01257], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.075, dtype=float32),\n",
       "    'tpr': array(0.95384616, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.33333334, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03846154,\n",
       "            0.04615385, 0.06153846, 0.06923077, 0.07692308, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.21538462, 0.22307692, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2846154 , 0.3       , 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.999  , 0.998  , 0.9976 , 0.9966 , 0.996  , 0.9946 ,\n",
       "            0.994  , 0.9937 , 0.992  , 0.9917 , 0.99   , 0.9897 , 0.9893 ,\n",
       "            0.9883 , 0.988  , 0.9854 , 0.984  , 0.9824 , 0.982  , 0.9814 ,\n",
       "            0.981  , 0.9805 , 0.977  , 0.9766 , 0.975  , 0.9746 , 0.973  ,\n",
       "            0.9727 , 0.972  , 0.971  , 0.9697 , 0.9688 , 0.968  , 0.9614 ,\n",
       "            0.961  , 0.9585 , 0.955  , 0.952  , 0.951  , 0.9497 , 0.945  ,\n",
       "            0.9434 , 0.942  , 0.9395 , 0.935  , 0.934  , 0.9336 , 0.93   ,\n",
       "            0.9287 , 0.9263 , 0.9224 , 0.921  , 0.9146 , 0.9097 , 0.905  ,\n",
       "            0.9033 , 0.902  , 0.898  , 0.897  , 0.8955 , 0.895  , 0.8906 ,\n",
       "            0.8887 , 0.8877 , 0.8867 , 0.886  , 0.8843 , 0.879  , 0.8735 ,\n",
       "            0.872  , 0.868  , 0.8633 , 0.863  , 0.8613 , 0.8604 , 0.858  ,\n",
       "            0.849  , 0.8467 , 0.8433 , 0.837  , 0.834  , 0.8335 , 0.833  ,\n",
       "            0.832  , 0.8306 , 0.8154 , 0.8066 , 0.805  , 0.796  , 0.787  ,\n",
       "            0.778  , 0.7734 , 0.747  , 0.7446 , 0.7266 , 0.7197 , 0.7188 ,\n",
       "            0.711  , 0.7104 , 0.692  , 0.6826 , 0.6753 , 0.6704 , 0.664  ,\n",
       "            0.659  , 0.657  , 0.6523 , 0.6265 , 0.6206 , 0.6167 , 0.612  ,\n",
       "            0.5806 , 0.5796 , 0.558  , 0.5493 , 0.5444 , 0.5386 , 0.49   ,\n",
       "            0.4873 , 0.4858 , 0.436  , 0.4314 , 0.4158 , 0.4006 , 0.4004 ,\n",
       "            0.3896 , 0.381  , 0.3801 , 0.3752 , 0.3591 , 0.3528 , 0.3489 ,\n",
       "            0.3477 , 0.345  , 0.3384 , 0.3333 , 0.3135 , 0.3108 , 0.307  ,\n",
       "            0.289  , 0.282  , 0.2737 , 0.2644 , 0.2634 , 0.2588 , 0.2573 ,\n",
       "            0.2522 , 0.2405 , 0.2327 , 0.2302 , 0.219  , 0.2175 , 0.2148 ,\n",
       "            0.2124 , 0.1984 , 0.1981 , 0.1943 , 0.1907 , 0.1903 , 0.1884 ,\n",
       "            0.1865 , 0.1855 , 0.1833 , 0.182  , 0.1792 , 0.179  , 0.1763 ,\n",
       "            0.1758 , 0.1754 , 0.1752 , 0.1747 , 0.1746 , 0.1726 , 0.167  ,\n",
       "            0.1661 , 0.1652 , 0.1498 , 0.1461 , 0.1455 , 0.1434 , 0.1422 ,\n",
       "            0.1373 , 0.1337 , 0.1318 , 0.131  , 0.1307 , 0.1288 , 0.1265 ,\n",
       "            0.1238 , 0.12067, 0.1204 , 0.11554, 0.1126 , 0.1099 , 0.1084 ,\n",
       "            0.108  , 0.1005 , 0.0998 , 0.0997 , 0.0991 , 0.0981 , 0.0972 ,\n",
       "            0.09686, 0.0967 , 0.09656, 0.09485, 0.0904 , 0.0857 , 0.0801 ,\n",
       "            0.07684, 0.0761 , 0.0752 , 0.07355, 0.06995, 0.0673 , 0.05878,\n",
       "            0.05814, 0.05685, 0.0548 , 0.0504 , 0.04803, 0.0468 , 0.04672,\n",
       "            0.04303, 0.04257, 0.04108, 0.03677, 0.03476, 0.02898, 0.0278 ,\n",
       "            0.02666, 0.01129], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.075, dtype=float32),\n",
       "    'tpr': array(0.9461538, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.075     , 0.08333334, 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.19166666, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06923077, 0.07692308, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.15384616, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.24615385, 0.25384617, 0.26153848, 0.2769231 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46923077, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9985  , 0.9976  , 0.997   , 0.9966  , 0.9956  ,\n",
       "            0.994   , 0.9937  , 0.9927  , 0.991   , 0.9907  , 0.99    ,\n",
       "            0.9883  , 0.988   , 0.9873  , 0.987   , 0.9863  , 0.983   ,\n",
       "            0.9824  , 0.98    , 0.9795  , 0.9785  , 0.978   , 0.977   ,\n",
       "            0.976   , 0.9746  , 0.973   , 0.971   , 0.9707  , 0.969   ,\n",
       "            0.9688  , 0.968   , 0.9673  , 0.9663  , 0.965   , 0.963   ,\n",
       "            0.9624  , 0.962   , 0.955   , 0.954   , 0.9507  , 0.9443  ,\n",
       "            0.944   , 0.9424  , 0.942   , 0.935   , 0.9336  , 0.9326  ,\n",
       "            0.929   , 0.9243  , 0.9214  , 0.9204  , 0.918   , 0.9097  ,\n",
       "            0.909   , 0.9053  , 0.9023  , 0.899   , 0.8877  , 0.886   ,\n",
       "            0.8857  , 0.8853  , 0.8843  , 0.8794  , 0.879   , 0.876   ,\n",
       "            0.8755  , 0.8696  , 0.869   , 0.8687  , 0.867   , 0.863   ,\n",
       "            0.8613  , 0.857   , 0.8506  , 0.8486  , 0.848   , 0.846   ,\n",
       "            0.8438  , 0.8394  , 0.8286  , 0.827   , 0.823   , 0.82    ,\n",
       "            0.8145  , 0.814   , 0.8135  , 0.804   , 0.8022  , 0.7983  ,\n",
       "            0.78    , 0.7744  , 0.7617  , 0.7607  , 0.747   , 0.746   ,\n",
       "            0.7075  , 0.701   , 0.6978  , 0.697   , 0.687   , 0.686   ,\n",
       "            0.6855  , 0.654   , 0.6436  , 0.643   , 0.6396  , 0.635   ,\n",
       "            0.6323  , 0.6187  , 0.6094  , 0.5986  , 0.5815  , 0.57    ,\n",
       "            0.562   , 0.552   , 0.5493  , 0.5205  , 0.5083  , 0.507   ,\n",
       "            0.4856  , 0.4602  , 0.442   , 0.4343  , 0.3994  , 0.387   ,\n",
       "            0.3848  , 0.3728  , 0.3704  , 0.3577  , 0.3535  , 0.3467  ,\n",
       "            0.3335  , 0.3252  , 0.3213  , 0.3203  , 0.311   , 0.3108  ,\n",
       "            0.3057  , 0.2886  , 0.2825  , 0.279   , 0.2642  , 0.2625  ,\n",
       "            0.2588  , 0.253   , 0.2384  , 0.235   , 0.231   , 0.2302  ,\n",
       "            0.223   , 0.2139  , 0.2006  , 0.1991  , 0.1976  , 0.1919  ,\n",
       "            0.1897  , 0.1849  , 0.1844  , 0.1808  , 0.1807  , 0.1788  ,\n",
       "            0.1761  , 0.1759  , 0.1699  , 0.1688  , 0.1669  , 0.1659  ,\n",
       "            0.1656  , 0.1627  , 0.1622  , 0.1609  , 0.1537  , 0.1531  ,\n",
       "            0.1526  , 0.1467  , 0.1455  , 0.1434  , 0.1406  , 0.1405  ,\n",
       "            0.1377  , 0.1359  , 0.1335  , 0.1315  , 0.12177 , 0.12115 ,\n",
       "            0.1207  , 0.12036 , 0.1198  , 0.1184  , 0.11816 , 0.11554 ,\n",
       "            0.1103  , 0.10596 , 0.1058  , 0.1043  , 0.1023  , 0.1     ,\n",
       "            0.0955  , 0.0893  , 0.0879  , 0.0876  , 0.0869  , 0.0868  ,\n",
       "            0.0865  , 0.0862  , 0.08496 , 0.07947 , 0.07837 , 0.0774  ,\n",
       "            0.07654 , 0.075   , 0.0725  , 0.0684  , 0.0677  , 0.0661  ,\n",
       "            0.0656  , 0.05988 , 0.05728 , 0.0543  , 0.04987 , 0.04858 ,\n",
       "            0.04752 , 0.0432  , 0.03934 , 0.0387  , 0.03824 , 0.0367  ,\n",
       "            0.0363  , 0.03583 , 0.0334  , 0.03198 , 0.02988 , 0.02676 ,\n",
       "            0.02242 , 0.02211 , 0.0203  , 0.008545], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.06666667, dtype=float32),\n",
       "    'tpr': array(0.9461538, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.075     , 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16923077,\n",
       "            0.17692308, 0.1923077 , 0.20769231, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2923077 , 0.30769232, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9985 , 0.998  , 0.997  , 0.9966 , 0.996  , 0.9956 ,\n",
       "            0.994  , 0.9937 , 0.993  , 0.9927 , 0.9917 , 0.991  , 0.9893 ,\n",
       "            0.989  , 0.9883 , 0.988  , 0.9873 , 0.9863 , 0.984  , 0.982  ,\n",
       "            0.98   , 0.9785 , 0.978  , 0.9746 , 0.974  , 0.9736 , 0.973  ,\n",
       "            0.972  , 0.971  , 0.97   , 0.9697 , 0.9688 , 0.9683 , 0.9653 ,\n",
       "            0.965  , 0.9644 , 0.9624 , 0.957  , 0.9556 , 0.951  , 0.9478 ,\n",
       "            0.9453 , 0.9443 , 0.944  , 0.9385 , 0.937  , 0.9336 , 0.9297 ,\n",
       "            0.9277 , 0.9253 , 0.925  , 0.921  , 0.9204 , 0.914  , 0.913  ,\n",
       "            0.91   , 0.905  , 0.9004 , 0.898  , 0.892  , 0.889  , 0.885  ,\n",
       "            0.884  , 0.883  , 0.8784 , 0.8745 , 0.873  , 0.8726 , 0.872  ,\n",
       "            0.871  , 0.867  , 0.862  , 0.8564 , 0.8545 , 0.853  , 0.8438 ,\n",
       "            0.8433 , 0.8384 , 0.838  , 0.83   , 0.827  , 0.8267 , 0.8223 ,\n",
       "            0.816  , 0.815  , 0.812  , 0.81   , 0.8076 , 0.8022 , 0.791  ,\n",
       "            0.783  , 0.7803 , 0.7676 , 0.7637 , 0.746  , 0.744  , 0.7134 ,\n",
       "            0.7056 , 0.696  , 0.6895 , 0.6846 , 0.6772 , 0.6763 , 0.657  ,\n",
       "            0.641  , 0.639  , 0.6353 , 0.6304 , 0.622  , 0.6143 , 0.58   ,\n",
       "            0.5747 , 0.5684 , 0.566  , 0.5303 , 0.5156 , 0.511  , 0.506  ,\n",
       "            0.497  , 0.4905 , 0.4421 , 0.44   , 0.4363 , 0.382  , 0.3809 ,\n",
       "            0.367  , 0.3477 , 0.3381 , 0.3376 , 0.3306 , 0.329  , 0.3186 ,\n",
       "            0.3113 , 0.3108 , 0.3071 , 0.2942 , 0.2937 , 0.2896 , 0.282  ,\n",
       "            0.274  , 0.263  , 0.2617 , 0.2478 , 0.2451 , 0.2422 , 0.2292 ,\n",
       "            0.2256 , 0.2166 , 0.2148 , 0.2106 , 0.2103 , 0.1931 , 0.1885 ,\n",
       "            0.187  , 0.1869 , 0.181  , 0.1792 , 0.1763 , 0.1727 , 0.1683 ,\n",
       "            0.1643 , 0.1633 , 0.1593 , 0.1564 , 0.1543 , 0.1533 , 0.1528 ,\n",
       "            0.1519 , 0.1509 , 0.1505 , 0.1475 , 0.1451 , 0.1433 , 0.142  ,\n",
       "            0.1417 , 0.1401 , 0.1395 , 0.139  , 0.1329 , 0.126  , 0.122  ,\n",
       "            0.1198 , 0.1172 , 0.11694, 0.10895, 0.1084 , 0.1078 , 0.1065 ,\n",
       "            0.10486, 0.1041 , 0.1009 , 0.10016, 0.0959 , 0.0933 , 0.09235,\n",
       "            0.0901 , 0.08466, 0.08417, 0.0828 , 0.08167, 0.0801 , 0.0774 ,\n",
       "            0.0772 , 0.07666, 0.0763 , 0.0742 , 0.0733 , 0.07043, 0.06866,\n",
       "            0.0636 , 0.06042, 0.0601 , 0.05814, 0.0575 , 0.0536 , 0.053  ,\n",
       "            0.0462 , 0.0457 , 0.045  , 0.0417 , 0.03802, 0.03683, 0.03607,\n",
       "            0.03534, 0.0347 , 0.0334 , 0.03217, 0.03079, 0.02791, 0.0258 ,\n",
       "            0.02153, 0.02072, 0.01942, 0.00784], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04166667, dtype=float32),\n",
       "    'tpr': array(0.93846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.075     , 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.175     , 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.34615386, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5923077 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9985 , 0.9976 , 0.9966 , 0.996  , 0.9956 , 0.995  ,\n",
       "            0.993  , 0.9927 , 0.991  , 0.99   , 0.9897 , 0.9893 , 0.9873 ,\n",
       "            0.987  , 0.9863 , 0.986  , 0.985  , 0.9844 , 0.9814 , 0.981  ,\n",
       "            0.978  , 0.976  , 0.9756 , 0.975  , 0.9746 , 0.974  , 0.97   ,\n",
       "            0.9697 , 0.9683 , 0.968  , 0.966  , 0.9653 , 0.965  , 0.9644 ,\n",
       "            0.964  , 0.9634 , 0.963  , 0.9585 , 0.958  , 0.9565 , 0.9497 ,\n",
       "            0.948  , 0.9424 , 0.9375 , 0.936  , 0.9355 , 0.9287 , 0.9272 ,\n",
       "            0.9214 , 0.9204 , 0.917  , 0.913  , 0.9116 , 0.909  , 0.908  ,\n",
       "            0.9033 , 0.8994 , 0.896  , 0.892  , 0.888  , 0.8853 , 0.875  ,\n",
       "            0.873  , 0.8706 , 0.87   , 0.8677 , 0.8633 , 0.8574 , 0.8564 ,\n",
       "            0.856  , 0.8525 , 0.845  , 0.8438 , 0.8374 , 0.835  , 0.832  ,\n",
       "            0.8267 , 0.821  , 0.8184 , 0.8174 , 0.8066 , 0.802  , 0.8    ,\n",
       "            0.796  , 0.7935 , 0.7905 , 0.7896 , 0.787  , 0.7827 , 0.7695 ,\n",
       "            0.7686 , 0.7593 , 0.7505 , 0.7383 , 0.737  , 0.7144 , 0.7124 ,\n",
       "            0.678  , 0.6675 , 0.6636 , 0.6606 , 0.655  , 0.6484 , 0.6475 ,\n",
       "            0.6235 , 0.6055 , 0.603  , 0.6006 , 0.5996 , 0.5913 , 0.5786 ,\n",
       "            0.5728 , 0.549  , 0.5317 , 0.5283 , 0.5244 , 0.4944 , 0.474  ,\n",
       "            0.4736 , 0.47   , 0.4648 , 0.4426 , 0.4058 , 0.4055 , 0.3953 ,\n",
       "            0.3455 , 0.335  , 0.332  , 0.3145 , 0.301  , 0.2993 , 0.299  ,\n",
       "            0.2856 , 0.2847 , 0.2844 , 0.2815 , 0.2747 , 0.262  , 0.2612 ,\n",
       "            0.2605 , 0.2493 , 0.2394 , 0.2303 , 0.2297 , 0.2242 , 0.2229 ,\n",
       "            0.2217 , 0.2104 , 0.1959 , 0.1941 , 0.1924 , 0.1864 , 0.1808 ,\n",
       "            0.1743 , 0.1718 , 0.1649 , 0.159  , 0.1543 , 0.1542 , 0.1519 ,\n",
       "            0.1508 , 0.1506 , 0.149  , 0.1412 , 0.1399 , 0.1383 , 0.1382 ,\n",
       "            0.1377 , 0.1372 , 0.137  , 0.1326 , 0.1285 , 0.1284 , 0.1271 ,\n",
       "            0.1266 , 0.1235 , 0.12036, 0.118  , 0.1172 , 0.11316, 0.1099 ,\n",
       "            0.1076 , 0.1074 , 0.0991 , 0.09753, 0.0967 , 0.096  , 0.09534,\n",
       "            0.0935 , 0.0925 , 0.0903 , 0.0896 , 0.0882 , 0.0854 , 0.08496,\n",
       "            0.08154, 0.0798 , 0.07355, 0.0734 , 0.0715 , 0.0707 , 0.07056,\n",
       "            0.0673 , 0.0662 , 0.0661 , 0.06586, 0.06476, 0.06152, 0.05988,\n",
       "            0.05655, 0.05634, 0.0548 , 0.05243, 0.05234, 0.0496 , 0.0463 ,\n",
       "            0.0452 , 0.0436 , 0.0397 , 0.03876, 0.0386 , 0.0329 , 0.0315 ,\n",
       "            0.0305 , 0.02937, 0.02931, 0.02817, 0.02676, 0.0265 , 0.02542,\n",
       "            0.02328, 0.01987, 0.01672, 0.01659, 0.01584, 0.00617],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.03333334, dtype=float32),\n",
       "    'tpr': array(0.9230769, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.075     , 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.14166667, 0.15833333,\n",
       "            0.16666667, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.11538462, 0.12307692,\n",
       "            0.14615385, 0.15384616, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.31538463,\n",
       "            0.32307693, 0.33846155, 0.34615386, 0.35384616, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.998   , 0.997   , 0.9966  , 0.9956  , 0.994   ,\n",
       "            0.9937  , 0.992   , 0.9917  , 0.9907  , 0.9893  , 0.988   ,\n",
       "            0.9873  , 0.985   , 0.9844  , 0.983   , 0.9824  , 0.978   ,\n",
       "            0.9775  , 0.974   , 0.973   , 0.9727  , 0.972   , 0.97    ,\n",
       "            0.969   , 0.9663  , 0.965   , 0.9634  , 0.962   , 0.9614  ,\n",
       "            0.961   , 0.96    , 0.9595  , 0.9585  , 0.9575  , 0.9565  ,\n",
       "            0.952   , 0.951   , 0.9507  , 0.947   , 0.942   , 0.9414  ,\n",
       "            0.9336  , 0.9277  , 0.9263  , 0.9243  , 0.918   , 0.916   ,\n",
       "            0.9116  , 0.9077  , 0.905   , 0.899   , 0.898   , 0.8955  ,\n",
       "            0.8926  , 0.8896  , 0.8853  , 0.8755  , 0.8745  , 0.872   ,\n",
       "            0.857   , 0.8564  , 0.8555  , 0.85    , 0.848   , 0.841   ,\n",
       "            0.8403  , 0.8374  , 0.837   , 0.832   , 0.8306  , 0.825   ,\n",
       "            0.8223  , 0.8184  , 0.813   , 0.809   , 0.8086  , 0.7993  ,\n",
       "            0.798   , 0.7964  , 0.786   , 0.777   , 0.7764  , 0.775   ,\n",
       "            0.7676  , 0.767   , 0.7656  , 0.7554  , 0.7524  , 0.746   ,\n",
       "            0.7334  , 0.733   , 0.721   , 0.7104  , 0.7056  , 0.6846  ,\n",
       "            0.678   , 0.644   , 0.638   , 0.631   , 0.624   , 0.617   ,\n",
       "            0.591   , 0.572   , 0.571   , 0.566   , 0.558   , 0.5435  ,\n",
       "            0.535   , 0.5166  , 0.4937  , 0.4922  , 0.4868  , 0.4587  ,\n",
       "            0.44    , 0.4368  , 0.4338  , 0.426   , 0.4028  , 0.3738  ,\n",
       "            0.3708  , 0.3608  , 0.3025  , 0.3015  , 0.2869  , 0.283   ,\n",
       "            0.2688  , 0.2683  , 0.259   , 0.254   , 0.2537  , 0.2462  ,\n",
       "            0.2458  , 0.2323  , 0.2319  , 0.2269  , 0.2212  , 0.2079  ,\n",
       "            0.2048  , 0.2045  , 0.1984  , 0.1925  , 0.1919  , 0.1918  ,\n",
       "            0.1747  , 0.169   , 0.1685  , 0.1633  , 0.157   , 0.1565  ,\n",
       "            0.154   , 0.1427  , 0.1393  , 0.1381  , 0.1357  , 0.1344  ,\n",
       "            0.1332  , 0.1296  , 0.126   , 0.12463 , 0.1238  , 0.12335 ,\n",
       "            0.1222  , 0.1207  , 0.1204  , 0.1193  , 0.1188  , 0.1172  ,\n",
       "            0.1136  , 0.1118  , 0.10913 , 0.10895 , 0.1078  , 0.10486 ,\n",
       "            0.10284 , 0.10156 , 0.0995  , 0.0967  , 0.0942  , 0.086   ,\n",
       "            0.0851  , 0.08417 , 0.0827  , 0.0823  , 0.08136 , 0.07794 ,\n",
       "            0.07764 , 0.0774  , 0.07697 , 0.074   , 0.0716  , 0.07056 ,\n",
       "            0.0698  , 0.06915 , 0.0644  , 0.06165 , 0.06152 , 0.0612  ,\n",
       "            0.05737 , 0.05676 , 0.05603 , 0.05582 , 0.053   , 0.0511  ,\n",
       "            0.0485  , 0.04822 , 0.0476  , 0.04453 , 0.04443 , 0.04428 ,\n",
       "            0.04312 , 0.04193 , 0.03986 , 0.03754 , 0.0346  , 0.0341  ,\n",
       "            0.03366 , 0.0326  , 0.02722 , 0.0263  , 0.02551 , 0.02547 ,\n",
       "            0.02342 , 0.0232  , 0.02307 , 0.02199 , 0.01999 , 0.01994 ,\n",
       "            0.015076, 0.013535, 0.01333 , 0.012924, 0.005062], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.03333334, dtype=float32),\n",
       "    'tpr': array(0.9076923, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.075     , 0.075     , 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.13333334,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.12307692, 0.13846155,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.26153848, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.35384616, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5923077 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9976 , 0.9966 , 0.9956 , 0.995  , 0.993  , 0.9927 ,\n",
       "            0.9907 , 0.99   , 0.989  , 0.9873 , 0.986  , 0.985  , 0.982  ,\n",
       "            0.98   , 0.9795 , 0.974  , 0.973  , 0.9688 , 0.968  , 0.9673 ,\n",
       "            0.967  , 0.965  , 0.9634 , 0.96   , 0.9595 , 0.9565 , 0.9556 ,\n",
       "            0.9546 , 0.9536 , 0.953  , 0.9517 , 0.9497 , 0.9487 , 0.944  ,\n",
       "            0.9424 , 0.9414 , 0.9355 , 0.9326 , 0.9316 , 0.9214 , 0.9165 ,\n",
       "            0.912  , 0.9116 , 0.911  , 0.905  , 0.903  , 0.8965 , 0.891  ,\n",
       "            0.8906 , 0.8823 , 0.8804 , 0.88   , 0.8735 , 0.87   , 0.868  ,\n",
       "            0.857  , 0.855  , 0.8545 , 0.853  , 0.838  , 0.837  , 0.8345 ,\n",
       "            0.8296 , 0.823  , 0.8184 , 0.8154 , 0.814  , 0.813  , 0.806  ,\n",
       "            0.8022 , 0.7954 , 0.795  , 0.794  , 0.788  , 0.783  , 0.7803 ,\n",
       "            0.7705 , 0.77   , 0.768  , 0.761  , 0.7495 , 0.7485 , 0.746  ,\n",
       "            0.7397 , 0.7383 , 0.736  , 0.721  , 0.715  , 0.703  , 0.7007 ,\n",
       "            0.693  , 0.6846 , 0.677  , 0.667  , 0.6504 , 0.64   , 0.604  ,\n",
       "            0.6016 , 0.5957 , 0.5825 , 0.5796 , 0.579  , 0.574  , 0.5513 ,\n",
       "            0.5356 , 0.535  , 0.528  , 0.519  , 0.5146 , 0.506  , 0.4885 ,\n",
       "            0.4778 , 0.4465 , 0.4407 , 0.4355 , 0.412  , 0.4006 , 0.3894 ,\n",
       "            0.3862 , 0.3796 , 0.354  , 0.3352 , 0.3289 , 0.3186 , 0.2654 ,\n",
       "            0.2612 , 0.2474 , 0.2438 , 0.2318 , 0.2314 , 0.2247 , 0.2234 ,\n",
       "            0.2145 , 0.2144 , 0.2115 , 0.2114 , 0.1958 , 0.1954 , 0.1953 ,\n",
       "            0.1931 , 0.1831 , 0.1747 , 0.1736 , 0.173  , 0.171  , 0.1637 ,\n",
       "            0.1605 , 0.1552 , 0.1455 , 0.1436 , 0.1393 , 0.1367 , 0.1362 ,\n",
       "            0.1277 , 0.126  , 0.1214 , 0.1186 , 0.118  , 0.11633, 0.1134 ,\n",
       "            0.10876, 0.1084 , 0.108  , 0.10724, 0.1067 , 0.1056 , 0.1025 ,\n",
       "            0.10144, 0.1011 , 0.0979 , 0.09753, 0.0962 , 0.09174, 0.09106,\n",
       "            0.089  , 0.0883 , 0.0862 , 0.08527, 0.0845 , 0.08344, 0.0827 ,\n",
       "            0.0804 , 0.0724 , 0.07184, 0.07007, 0.06995, 0.0689 , 0.06854,\n",
       "            0.066  , 0.0642 , 0.0631 , 0.06256, 0.05942, 0.0589 , 0.05856,\n",
       "            0.05698, 0.0556 , 0.0532 , 0.05292, 0.0495 , 0.04654, 0.04587,\n",
       "            0.04544, 0.04535, 0.0451 , 0.04288, 0.04218, 0.0403 , 0.03882,\n",
       "            0.03644, 0.03635, 0.03607, 0.0341 , 0.0339 , 0.0334 , 0.02982,\n",
       "            0.02821, 0.02791, 0.02737, 0.02733, 0.02174, 0.02153, 0.02045,\n",
       "            0.02042, 0.01935, 0.01865, 0.01862, 0.01752, 0.0161 , 0.0156 ,\n",
       "            0.01192, 0.0107 , 0.01061, 0.01025, 0.00387], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.03333334, dtype=float32),\n",
       "    'tpr': array(0.86153847, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.3       , 0.30833334, 0.31666666, 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65833336,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2769231 , 0.2923077 ,\n",
       "            0.3       , 0.31538463, 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.47692308, 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.8384615 , 0.84615386, 0.85384613, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.997   , 0.9956  , 0.994   , 0.9937  , 0.992   ,\n",
       "            0.991   , 0.9893  , 0.9883  , 0.9873  , 0.986   , 0.9844  ,\n",
       "            0.984   , 0.982   , 0.9795  , 0.9785  , 0.977   , 0.9756  ,\n",
       "            0.975   , 0.9707  , 0.97    , 0.965   , 0.9634  , 0.9604  ,\n",
       "            0.959   , 0.9585  , 0.957   , 0.9536  , 0.9497  , 0.949   ,\n",
       "            0.948   , 0.9478  , 0.946   , 0.945   , 0.944   , 0.943   ,\n",
       "            0.942   , 0.9395  , 0.9365  , 0.9355  , 0.934   , 0.925   ,\n",
       "            0.924   , 0.918   , 0.9155  , 0.901   , 0.9004  , 0.8994  ,\n",
       "            0.897   , 0.8965  , 0.8945  , 0.892   , 0.879   , 0.8784  ,\n",
       "            0.8726  , 0.8696  , 0.867   , 0.865   , 0.854   , 0.845   ,\n",
       "            0.8384  , 0.8267  , 0.824   , 0.8228  , 0.818   , 0.8174  ,\n",
       "            0.813   , 0.8076  , 0.806   , 0.798   , 0.7974  , 0.795   ,\n",
       "            0.787   , 0.7866  , 0.784   , 0.7744  , 0.773   , 0.7705  ,\n",
       "            0.7646  , 0.763   , 0.759   , 0.7563  , 0.7446  , 0.7285  ,\n",
       "            0.7246  , 0.723   , 0.7207  , 0.709   , 0.708   , 0.7056  ,\n",
       "            0.6973  , 0.6963  , 0.696   , 0.692   , 0.6787  , 0.6694  ,\n",
       "            0.668   , 0.6577  , 0.649   , 0.6396  , 0.6274  , 0.598   ,\n",
       "            0.581   , 0.5723  , 0.5684  , 0.554   , 0.542   , 0.528   ,\n",
       "            0.5273  , 0.5264  , 0.5225  , 0.4912  , 0.4849  , 0.4832  ,\n",
       "            0.4673  , 0.4575  , 0.4524  , 0.4521  , 0.4475  , 0.416   ,\n",
       "            0.4104  , 0.37    , 0.3606  , 0.355   , 0.3484  , 0.3457  ,\n",
       "            0.3242  , 0.3164  , 0.3093  , 0.2925  , 0.2795  , 0.2224  ,\n",
       "            0.2177  , 0.2124  , 0.2006  , 0.1974  , 0.1931  , 0.1912  ,\n",
       "            0.191   , 0.1796  , 0.173   , 0.1718  , 0.1692  , 0.1653  ,\n",
       "            0.1635  , 0.1621  , 0.1572  , 0.1571  , 0.157   , 0.1537  ,\n",
       "            0.1514  , 0.1494  , 0.1354  , 0.135   , 0.1263  , 0.1214  ,\n",
       "            0.118   , 0.11755 , 0.1126  , 0.1093  , 0.1047  , 0.1007  ,\n",
       "            0.10034 , 0.0991  , 0.09436 , 0.0925  , 0.0922  , 0.09076 ,\n",
       "            0.0904  , 0.0857  , 0.0848  , 0.08405 , 0.08386 , 0.0823  ,\n",
       "            0.0821  , 0.08105 , 0.08093 , 0.0806  , 0.0786  , 0.0763  ,\n",
       "            0.0761  , 0.07465 , 0.07275 , 0.0716  , 0.07104 , 0.06995 ,\n",
       "            0.0684  , 0.06683 , 0.05988 , 0.05954 , 0.05676 , 0.05573 ,\n",
       "            0.0556  , 0.0552  , 0.0544  , 0.05203 , 0.05136 , 0.051   ,\n",
       "            0.04886 , 0.04813 , 0.04724 , 0.0471  , 0.045   , 0.04443 ,\n",
       "            0.04337 , 0.04193 , 0.04108 , 0.03574 , 0.0356  , 0.03555 ,\n",
       "            0.03506 , 0.03378 , 0.03326 , 0.03174 , 0.02914 , 0.02908 ,\n",
       "            0.02893 , 0.02866 , 0.02827 , 0.02696 , 0.02692 , 0.026   ,\n",
       "            0.02457 , 0.024   , 0.02303 , 0.02225 , 0.01968 , 0.01898 ,\n",
       "            0.01872 , 0.01785 , 0.01628 , 0.01543 , 0.01525 , 0.015076,\n",
       "            0.014175, 0.01401 , 0.01107 , 0.00916 , 0.008575, 0.008286,\n",
       "            0.007576, 0.003273], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.01666667, dtype=float32),\n",
       "    'tpr': array(0.8384615, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.05      ,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.10833333,\n",
       "            0.11666667, 0.11666667, 0.125     , 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.24615385, 0.25384617,\n",
       "            0.26923078, 0.2769231 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9966  , 0.9946  , 0.9937  , 0.993   , 0.9897  ,\n",
       "            0.989   , 0.987   , 0.9863  , 0.984   , 0.9834  , 0.9805  ,\n",
       "            0.977   , 0.975   , 0.9746  , 0.974   , 0.973   , 0.972   ,\n",
       "            0.9717  , 0.9683  , 0.9644  , 0.9634  , 0.957   , 0.9565  ,\n",
       "            0.956   , 0.9536  , 0.952   , 0.95    , 0.942   , 0.94    ,\n",
       "            0.9385  , 0.9375  , 0.937   , 0.9336  , 0.932   , 0.9316  ,\n",
       "            0.93    , 0.928   , 0.9233  , 0.923   , 0.92    , 0.913   ,\n",
       "            0.91    , 0.909   , 0.897   , 0.8936  , 0.8906  , 0.8813  ,\n",
       "            0.881   , 0.8755  , 0.8726  , 0.8716  , 0.8574  , 0.856   ,\n",
       "            0.855   , 0.846   , 0.8433  , 0.8394  , 0.83    , 0.824   ,\n",
       "            0.8154  , 0.807   , 0.806   , 0.8     , 0.795   , 0.7915  ,\n",
       "            0.789   , 0.7876  , 0.7827  , 0.7803  , 0.767   , 0.7666  ,\n",
       "            0.7637  , 0.7627  , 0.7593  , 0.755   , 0.754   , 0.746   ,\n",
       "            0.7427  , 0.737   , 0.7275  , 0.7236  , 0.7227  , 0.7217  ,\n",
       "            0.718   , 0.715   , 0.7085  , 0.694   , 0.689   , 0.6885  ,\n",
       "            0.687   , 0.6836  , 0.6646  , 0.6597  , 0.655   , 0.639   ,\n",
       "            0.636   , 0.619   , 0.615   , 0.6113  , 0.605   , 0.5957  ,\n",
       "            0.5835  , 0.5684  , 0.5283  , 0.5264  , 0.5234  , 0.4976  ,\n",
       "            0.4956  , 0.4912  , 0.4856  , 0.4797  , 0.4666  , 0.4653  ,\n",
       "            0.4414  , 0.4377  , 0.4355  , 0.435   , 0.4114  , 0.403   ,\n",
       "            0.3713  , 0.3667  , 0.32    , 0.3108  , 0.3093  , 0.3086  ,\n",
       "            0.2964  , 0.2825  , 0.2742  , 0.2573  , 0.256   , 0.2407  ,\n",
       "            0.1892  , 0.1885  , 0.1882  , 0.1733  , 0.1643  , 0.164   ,\n",
       "            0.1602  , 0.158   , 0.139   , 0.1381  , 0.1368  , 0.1359  ,\n",
       "            0.1343  , 0.132   , 0.131   , 0.126   , 0.1241  , 0.124   ,\n",
       "            0.1238  , 0.1152  , 0.1097  , 0.1069  , 0.1036  , 0.0995  ,\n",
       "            0.0962  , 0.0959  , 0.0933  , 0.0925  , 0.0885  , 0.0877  ,\n",
       "            0.086   , 0.0851  , 0.0833  , 0.0828  , 0.0771  , 0.07684 ,\n",
       "            0.07666 , 0.0749  , 0.0741  , 0.0694  , 0.06866 , 0.06805 ,\n",
       "            0.0677  , 0.06757 , 0.06744 , 0.0661  , 0.066   , 0.06586 ,\n",
       "            0.0637  , 0.06244 , 0.06052 , 0.05856 , 0.0576  , 0.05707 ,\n",
       "            0.0539  , 0.05127 , 0.051   , 0.04886 , 0.04794 , 0.04663 ,\n",
       "            0.04553 , 0.04535 , 0.04395 , 0.04337 , 0.04312 , 0.04178 ,\n",
       "            0.04083 , 0.03986 , 0.03934 , 0.03928 , 0.03833 , 0.03818 ,\n",
       "            0.03607 , 0.0346  , 0.03125 , 0.03038 , 0.03033 , 0.02959 ,\n",
       "            0.02744 , 0.02696 , 0.02686 , 0.0267  , 0.02615 , 0.02606 ,\n",
       "            0.025   , 0.02423 , 0.02263 , 0.02242 , 0.02208 , 0.02148 ,\n",
       "            0.02077 , 0.02045 , 0.01994 , 0.01927 , 0.0184  , 0.01578 ,\n",
       "            0.01484 , 0.0139  , 0.01359 , 0.01322 , 0.01277 , 0.01267 ,\n",
       "            0.011734, 0.01033 , 0.007904, 0.00755 , 0.006985, 0.006798,\n",
       "            0.002663], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.01666667, dtype=float32),\n",
       "    'tpr': array(0.8153846, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.06666667, 0.06666667,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.1       , 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.11666667, 0.125     , 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.06153846, 0.06923077, 0.08461539,\n",
       "            0.09230769, 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.995   , 0.9927  , 0.992   , 0.9917  , 0.9863  ,\n",
       "            0.985   , 0.984   , 0.983   , 0.9805  , 0.976   , 0.97    ,\n",
       "            0.9697  , 0.969   , 0.9663  , 0.966   , 0.9653  , 0.958   ,\n",
       "            0.957   , 0.956   , 0.95    , 0.948   , 0.947   , 0.9434  ,\n",
       "            0.943   , 0.9424  , 0.9404  , 0.9336  , 0.932   , 0.929   ,\n",
       "            0.9287  , 0.9263  , 0.9243  , 0.924   , 0.9185  , 0.915   ,\n",
       "            0.9136  , 0.913   , 0.9126  , 0.9077  , 0.9062  , 0.9043  ,\n",
       "            0.9014  , 0.892   , 0.8857  , 0.8833  , 0.88    , 0.8594  ,\n",
       "            0.8584  , 0.853   , 0.851   , 0.8496  , 0.839   , 0.8325  ,\n",
       "            0.829   , 0.8267  , 0.82    , 0.8164  , 0.8057  , 0.8022  ,\n",
       "            0.792   , 0.7886  , 0.7686  , 0.767   , 0.7617  , 0.761   ,\n",
       "            0.757   , 0.755   , 0.7534  , 0.745   , 0.732   , 0.7305  ,\n",
       "            0.7285  , 0.728   , 0.7227  , 0.721   , 0.7188  , 0.717   ,\n",
       "            0.7144  , 0.697   , 0.694   , 0.688   , 0.684   , 0.683   ,\n",
       "            0.6826  , 0.681   , 0.677   , 0.676   , 0.6626  , 0.655   ,\n",
       "            0.6523  , 0.6514  , 0.635   , 0.6113  , 0.611   , 0.6084  ,\n",
       "            0.591   , 0.5835  , 0.582   , 0.5693  , 0.555   , 0.5547  ,\n",
       "            0.549   , 0.548   , 0.5312  , 0.4827  , 0.4785  , 0.473   ,\n",
       "            0.4512  , 0.4478  , 0.4404  , 0.4353  , 0.4297  , 0.4292  ,\n",
       "            0.4282  , 0.4006  , 0.3992  , 0.3892  , 0.3806  , 0.3657  ,\n",
       "            0.3557  , 0.3274  , 0.3235  , 0.2803  , 0.263   , 0.2546  ,\n",
       "            0.2445  , 0.2441  , 0.2433  , 0.2394  , 0.2213  , 0.1971  ,\n",
       "            0.1967  , 0.1647  , 0.1635  , 0.1523  , 0.1393  , 0.1392  ,\n",
       "            0.1309  , 0.1272  , 0.1236  , 0.11816 , 0.1134  , 0.113   ,\n",
       "            0.1054  , 0.10376 , 0.1025  , 0.1019  , 0.0998  , 0.09894 ,\n",
       "            0.09534 , 0.09503 , 0.094   , 0.09283 , 0.09235 , 0.08496 ,\n",
       "            0.08093 , 0.0804  , 0.07654 , 0.07544 , 0.0753  , 0.0749  ,\n",
       "            0.0717  , 0.0708  , 0.0689  , 0.06647 , 0.0662  , 0.0656  ,\n",
       "            0.06476 , 0.06085 , 0.06076 , 0.059   , 0.05792 , 0.0576  ,\n",
       "            0.05728 , 0.05573 , 0.0546  , 0.0544  , 0.05283 , 0.05252 ,\n",
       "            0.05234 , 0.05154 , 0.05136 , 0.04968 , 0.0484  , 0.04468 ,\n",
       "            0.04453 , 0.0437  , 0.0432  , 0.04163 , 0.04132 , 0.03845 ,\n",
       "            0.0371  , 0.0369  , 0.03677 , 0.0367  , 0.03516 , 0.0347  ,\n",
       "            0.03348 , 0.03333 , 0.0332  , 0.0329  , 0.03108 , 0.02954 ,\n",
       "            0.02914 , 0.02908 , 0.02893 , 0.02855 , 0.0262  , 0.02527 ,\n",
       "            0.02484 , 0.02272 , 0.02237 , 0.02097 , 0.0208  , 0.02025 ,\n",
       "            0.02002 , 0.01979 , 0.01924 , 0.01888 , 0.01862 , 0.01744 ,\n",
       "            0.0171  , 0.01659 , 0.01628 , 0.01616 , 0.01572 , 0.015305,\n",
       "            0.01484 , 0.01297 , 0.012825, 0.0121  , 0.0116  , 0.01107 ,\n",
       "            0.01065 , 0.01061 , 0.01033 , 0.0096  , 0.008545, 0.006565,\n",
       "            0.006096, 0.00562 , 0.005577, 0.002125], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.01666667, dtype=float32),\n",
       "    'tpr': array(0.8153846, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.05      ,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.1       , 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.28333333, 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.25384617, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.995   , 0.9927  , 0.992   , 0.99    , 0.9863  ,\n",
       "            0.985   , 0.984   , 0.982   , 0.981   , 0.9795  , 0.978   ,\n",
       "            0.9775  , 0.971   , 0.9688  , 0.9683  , 0.967   , 0.9653  ,\n",
       "            0.963   , 0.959   , 0.9585  , 0.9546  , 0.9507  , 0.949   ,\n",
       "            0.9487  , 0.9453  , 0.943   , 0.935   , 0.934   , 0.9307  ,\n",
       "            0.93    , 0.9277  , 0.9224  , 0.922   , 0.9214  , 0.918   ,\n",
       "            0.9175  , 0.917   , 0.9126  , 0.911   , 0.908   , 0.907   ,\n",
       "            0.9067  , 0.9014  , 0.8984  , 0.8955  , 0.88    , 0.876   ,\n",
       "            0.8633  , 0.8613  , 0.855   , 0.8516  , 0.834   , 0.8335  ,\n",
       "            0.824   , 0.8237  , 0.8203  , 0.8037  , 0.8022  , 0.797   ,\n",
       "            0.7803  , 0.7593  , 0.7583  , 0.7544  , 0.751   , 0.7427  ,\n",
       "            0.742   , 0.731   , 0.7305  , 0.7285  , 0.728   , 0.721   ,\n",
       "            0.72    , 0.718   , 0.708   , 0.701   , 0.692   , 0.69    ,\n",
       "            0.686   , 0.68    , 0.677   , 0.6763  , 0.6733  , 0.6606  ,\n",
       "            0.6567  , 0.651   , 0.6504  , 0.6426  , 0.6396  , 0.6274  ,\n",
       "            0.6133  , 0.5894  , 0.5884  , 0.584   , 0.571   , 0.5693  ,\n",
       "            0.568   , 0.5503  , 0.546   , 0.542   , 0.5327  , 0.5166  ,\n",
       "            0.479   , 0.4634  , 0.4539  , 0.4438  , 0.4324  , 0.421   ,\n",
       "            0.4146  , 0.4126  , 0.4094  , 0.385   , 0.3838  , 0.3826  ,\n",
       "            0.3652  , 0.359   , 0.3489  , 0.343   , 0.3262  , 0.322   ,\n",
       "            0.2778  , 0.243   , 0.2352  , 0.2269  , 0.2189  , 0.2133  ,\n",
       "            0.2118  , 0.1907  , 0.1627  , 0.1569  , 0.1542  , 0.1488  ,\n",
       "            0.1368  , 0.1298  , 0.12445 , 0.11084 , 0.1047  , 0.10376 ,\n",
       "            0.1023  , 0.09875 , 0.0974  , 0.0955  , 0.0874  , 0.08466 ,\n",
       "            0.08154 , 0.07837 , 0.07794 , 0.0764  , 0.076   , 0.07385 ,\n",
       "            0.0707  , 0.07007 , 0.06915 , 0.06903 , 0.06854 , 0.06647 ,\n",
       "            0.06198 , 0.06152 , 0.0602  , 0.05844 , 0.05823 , 0.05542 ,\n",
       "            0.0545  , 0.0532  , 0.053   , 0.05243 , 0.05118 , 0.05023 ,\n",
       "            0.05014 , 0.04877 , 0.04868 , 0.04788 , 0.0476  , 0.0461  ,\n",
       "            0.04535 , 0.04202 , 0.04083 , 0.0403  , 0.03964 , 0.03918 ,\n",
       "            0.03775 , 0.0372  , 0.0356  , 0.035   , 0.0341  , 0.0332  ,\n",
       "            0.0315  , 0.0313  , 0.03108 , 0.02954 , 0.02887 , 0.0286  ,\n",
       "            0.02791 , 0.02785 , 0.02737 , 0.02641 , 0.02591 , 0.02489 ,\n",
       "            0.0247  , 0.02396 , 0.02377 , 0.0232  , 0.0225  , 0.02162 ,\n",
       "            0.02136 , 0.02129 , 0.0205  , 0.02025 , 0.0189  , 0.01865 ,\n",
       "            0.01704 , 0.01685 , 0.01622 , 0.01445 , 0.014114, 0.01406 ,\n",
       "            0.0139  , 0.013794, 0.01374 , 0.01348 , 0.01287 , 0.01229 ,\n",
       "            0.011734, 0.01155 , 0.01133 , 0.01053 , 0.01037 , 0.01033 ,\n",
       "            0.00982 , 0.00952 , 0.009125, 0.00909 , 0.007637, 0.005844,\n",
       "            0.0058  , 0.004963, 0.00483 , 0.002068], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.01666667, dtype=float32),\n",
       "    'tpr': array(0.8153846, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.1       , 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.53333336, 0.5416667 , 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.7       , 0.7083333 , 0.725     , 0.73333335,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.02307692, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.11538462, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9956  , 0.993   , 0.991   , 0.9863  , 0.986   ,\n",
       "            0.984   , 0.983   , 0.982   , 0.981   , 0.979   , 0.9727  ,\n",
       "            0.972   , 0.969   , 0.968   , 0.9663  , 0.962   , 0.9604  ,\n",
       "            0.9595  , 0.9556  , 0.952   , 0.9517  , 0.95    , 0.9463  ,\n",
       "            0.944   , 0.936   , 0.9355  , 0.9346  , 0.9336  , 0.9277  ,\n",
       "            0.922   , 0.92    , 0.917   , 0.9165  , 0.916   , 0.9106  ,\n",
       "            0.9097  , 0.907   , 0.9067  , 0.901   , 0.895   , 0.8906  ,\n",
       "            0.889   , 0.885   , 0.861   , 0.8594  , 0.853   , 0.851   ,\n",
       "            0.8496  , 0.83    , 0.8286  , 0.819   , 0.815   , 0.8047  ,\n",
       "            0.799   , 0.7935  , 0.793   , 0.7856  , 0.782   , 0.7515  ,\n",
       "            0.751   , 0.749   , 0.745   , 0.741   , 0.736   , 0.733   ,\n",
       "            0.7256  , 0.721   , 0.72    , 0.718   , 0.716   , 0.713   ,\n",
       "            0.709   , 0.687   , 0.6855  , 0.683   , 0.6807  , 0.6743  ,\n",
       "            0.672   , 0.67    , 0.6616  , 0.657   , 0.6562  , 0.6494  ,\n",
       "            0.643   , 0.6416  , 0.638   , 0.627   , 0.622   , 0.594   ,\n",
       "            0.5767  , 0.565   , 0.5625  , 0.5527  , 0.5503  , 0.544   ,\n",
       "            0.534   , 0.5337  , 0.5283  , 0.525   , 0.5186  , 0.5166  ,\n",
       "            0.4539  , 0.4407  , 0.4395  , 0.4138  , 0.4082  , 0.4055  ,\n",
       "            0.3997  , 0.3955  , 0.3823  , 0.3774  , 0.3525  , 0.3398  ,\n",
       "            0.337   , 0.3171  , 0.3096  , 0.2979  , 0.294   , 0.251   ,\n",
       "            0.2147  , 0.211   , 0.1996  , 0.1937  , 0.1805  , 0.1766  ,\n",
       "            0.154   , 0.1475  , 0.1383  , 0.1371  , 0.12286 , 0.11676 ,\n",
       "            0.11615 , 0.10284 , 0.0935  , 0.0909  , 0.08496 , 0.08136 ,\n",
       "            0.0805  , 0.07825 , 0.0778  , 0.0771  , 0.06476 , 0.0641  ,\n",
       "            0.0631  , 0.06232 , 0.0612  , 0.0591  , 0.0578  , 0.05634 ,\n",
       "            0.05573 , 0.0549  , 0.0546  , 0.05203 , 0.05185 , 0.05167 ,\n",
       "            0.05154 , 0.04877 , 0.0476  , 0.04602 , 0.0457  , 0.045   ,\n",
       "            0.04477 , 0.04352 , 0.04257 , 0.04083 , 0.04062 , 0.0401  ,\n",
       "            0.03964 , 0.03845 , 0.03622 , 0.03607 , 0.03595 , 0.03583 ,\n",
       "            0.03522 , 0.03455 , 0.03397 , 0.03384 , 0.03125 , 0.03033 ,\n",
       "            0.02959 , 0.02931 , 0.02925 , 0.02898 , 0.02586 , 0.02538 ,\n",
       "            0.025   , 0.02489 , 0.02457 , 0.024   , 0.02284 , 0.02232 ,\n",
       "            0.02208 , 0.02129 , 0.02109 , 0.02007 , 0.01979 , 0.01869 ,\n",
       "            0.01848 , 0.01843 , 0.01785 , 0.01772 , 0.01758 , 0.01646 ,\n",
       "            0.01519 , 0.015015, 0.014786, 0.01439 , 0.01263 , 0.01234 ,\n",
       "            0.01196 , 0.0112  , 0.010735, 0.00982 , 0.00956 , 0.00927 ,\n",
       "            0.00919 , 0.00916 , 0.00909 , 0.00885 , 0.00861 , 0.008545,\n",
       "            0.00803 , 0.00784 , 0.007786, 0.007576, 0.007206, 0.007065,\n",
       "            0.006824, 0.00669 , 0.00649 , 0.004868, 0.004135, 0.0041  ,\n",
       "            0.00393 , 0.001495], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00833333, dtype=float32),\n",
       "    'tpr': array(0.77692306, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.575     , 0.5833333 , 0.6       , 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.07692308, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8153846 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9512e-01, 9.9414e-01, 9.9268e-01, 9.9170e-01,\n",
       "            9.8486e-01, 9.8389e-01, 9.8291e-01, 9.8145e-01, 9.7949e-01,\n",
       "            9.7754e-01, 9.7412e-01, 9.7119e-01, 9.6777e-01, 9.6680e-01,\n",
       "            9.6436e-01, 9.6338e-01, 9.5850e-01, 9.5752e-01, 9.5703e-01,\n",
       "            9.5605e-01, 9.4775e-01, 9.4238e-01, 9.4092e-01, 9.3994e-01,\n",
       "            9.3799e-01, 9.3604e-01, 9.3359e-01, 9.3164e-01, 9.2041e-01,\n",
       "            9.1602e-01, 9.1406e-01, 9.1211e-01, 9.0918e-01, 9.0771e-01,\n",
       "            9.0723e-01, 9.0430e-01, 9.0332e-01, 8.9844e-01, 8.9697e-01,\n",
       "            8.9648e-01, 8.8867e-01, 8.8672e-01, 8.8574e-01, 8.8428e-01,\n",
       "            8.6426e-01, 8.4668e-01, 8.4375e-01, 8.4180e-01, 8.3887e-01,\n",
       "            8.3740e-01, 8.1396e-01, 8.1006e-01, 8.0127e-01, 7.9688e-01,\n",
       "            7.8223e-01, 7.7930e-01, 7.7734e-01, 7.6172e-01, 7.5000e-01,\n",
       "            7.3877e-01, 7.3438e-01, 7.2900e-01, 7.2852e-01, 7.2461e-01,\n",
       "            7.2314e-01, 7.1582e-01, 7.0703e-01, 7.0557e-01, 6.9775e-01,\n",
       "            6.9580e-01, 6.9336e-01, 6.9092e-01, 6.8799e-01, 6.8066e-01,\n",
       "            6.7041e-01, 6.6699e-01, 6.5381e-01, 6.4648e-01, 6.4600e-01,\n",
       "            6.4209e-01, 6.3965e-01, 6.3330e-01, 6.2793e-01, 6.2598e-01,\n",
       "            6.2256e-01, 6.1963e-01, 6.1719e-01, 6.0107e-01, 5.9668e-01,\n",
       "            5.9229e-01, 5.6348e-01, 5.5615e-01, 5.5322e-01, 5.2783e-01,\n",
       "            5.2344e-01, 5.1221e-01, 5.1025e-01, 5.0537e-01, 4.9487e-01,\n",
       "            4.8657e-01, 4.8608e-01, 4.7656e-01, 4.7070e-01, 4.1016e-01,\n",
       "            3.9966e-01, 3.8257e-01, 3.7354e-01, 3.7036e-01, 3.6914e-01,\n",
       "            3.6328e-01, 3.5376e-01, 3.5254e-01, 3.5107e-01, 3.0884e-01,\n",
       "            3.0615e-01, 2.9321e-01, 2.7759e-01, 2.5586e-01, 2.5317e-01,\n",
       "            2.5024e-01, 2.1338e-01, 1.7908e-01, 1.7639e-01, 1.6431e-01,\n",
       "            1.6077e-01, 1.4563e-01, 1.3354e-01, 1.2494e-01, 1.1920e-01,\n",
       "            1.1633e-01, 1.0797e-01, 1.0303e-01, 9.2834e-02, 8.6792e-02,\n",
       "            7.9224e-02, 7.4768e-02, 7.3303e-02, 6.6101e-02, 6.3477e-02,\n",
       "            5.8350e-02, 5.8136e-02, 5.8014e-02, 5.3497e-02, 5.0995e-02,\n",
       "            4.6631e-02, 4.5776e-02, 4.5593e-02, 4.5105e-02, 4.3701e-02,\n",
       "            4.2633e-02, 4.1534e-02, 4.1138e-02, 4.0619e-02, 3.8177e-02,\n",
       "            3.8025e-02, 3.6987e-02, 3.6835e-02, 3.6346e-02, 3.4088e-02,\n",
       "            3.3966e-02, 3.3844e-02, 3.3142e-02, 3.2654e-02, 3.2043e-02,\n",
       "            3.1555e-02, 3.1143e-02, 3.0151e-02, 2.9541e-02, 2.8870e-02,\n",
       "            2.8061e-02, 2.7847e-02, 2.7527e-02, 2.6108e-02, 2.5330e-02,\n",
       "            2.5223e-02, 2.5131e-02, 2.4139e-02, 2.4048e-02, 2.3331e-02,\n",
       "            2.3102e-02, 2.2629e-02, 2.1744e-02, 2.1362e-02, 2.0966e-02,\n",
       "            2.0248e-02, 2.0065e-02, 2.0020e-02, 1.9943e-02, 1.8906e-02,\n",
       "            1.8402e-02, 1.6983e-02, 1.6403e-02, 1.5717e-02, 1.5427e-02,\n",
       "            1.4900e-02, 1.4786e-02, 1.3687e-02, 1.3481e-02, 1.3374e-02,\n",
       "            1.3329e-02, 1.3168e-02, 1.2238e-02, 1.2192e-02, 1.2100e-02,\n",
       "            1.1688e-02, 1.1642e-02, 1.0948e-02, 1.0780e-02, 1.0490e-02,\n",
       "            9.8953e-03, 9.7427e-03, 9.4147e-03, 8.7814e-03, 8.7128e-03,\n",
       "            8.6746e-03, 8.1558e-03, 7.8125e-03, 6.4621e-03, 6.3400e-03,\n",
       "            6.2408e-03, 6.2180e-03, 6.0501e-03, 5.8899e-03, 5.8212e-03,\n",
       "            5.7755e-03, 5.4054e-03, 5.3444e-03, 5.0011e-03, 4.9057e-03,\n",
       "            4.8294e-03, 4.7188e-03, 4.5738e-03, 4.5395e-03, 4.2000e-03,\n",
       "            3.3894e-03, 2.8458e-03, 2.7256e-03, 2.7046e-03, 9.4366e-04],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.01666667, dtype=float32),\n",
       "    'tpr': array(0.8, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.80833334,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01538462, 0.03076923, 0.03846154, 0.04615385,\n",
       "            0.05384615, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.15384616, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9609e-01, 9.9365e-01, 9.8828e-01, 9.8779e-01,\n",
       "            9.8730e-01, 9.8633e-01, 9.8438e-01, 9.8242e-01, 9.8145e-01,\n",
       "            9.8096e-01, 9.7607e-01, 9.7510e-01, 9.7412e-01, 9.6973e-01,\n",
       "            9.6924e-01, 9.6582e-01, 9.6533e-01, 9.5898e-01, 9.5850e-01,\n",
       "            9.5508e-01, 9.5410e-01, 9.5264e-01, 9.5166e-01, 9.4482e-01,\n",
       "            9.4238e-01, 9.3701e-01, 9.3604e-01, 9.3115e-01, 9.2822e-01,\n",
       "            9.2773e-01, 9.2529e-01, 9.2432e-01, 9.2041e-01, 9.1650e-01,\n",
       "            9.1504e-01, 9.1406e-01, 9.0820e-01, 9.0771e-01, 9.0625e-01,\n",
       "            9.0479e-01, 9.0137e-01, 8.8623e-01, 8.7012e-01, 8.6865e-01,\n",
       "            8.6279e-01, 8.5938e-01, 8.5156e-01, 8.4668e-01, 8.3740e-01,\n",
       "            8.3447e-01, 8.2812e-01, 8.2422e-01, 8.0811e-01, 8.0762e-01,\n",
       "            7.9297e-01, 7.6562e-01, 7.5830e-01, 7.5488e-01, 7.5244e-01,\n",
       "            7.5146e-01, 7.4219e-01, 7.4121e-01, 7.3584e-01, 7.2998e-01,\n",
       "            7.2607e-01, 7.1729e-01, 7.1436e-01, 7.1191e-01, 7.0752e-01,\n",
       "            6.9922e-01, 6.8848e-01, 6.8701e-01, 6.8555e-01, 6.7822e-01,\n",
       "            6.7773e-01, 6.7529e-01, 6.7285e-01, 6.6699e-01, 6.6064e-01,\n",
       "            6.5820e-01, 6.3330e-01, 6.3281e-01, 6.2500e-01, 6.0645e-01,\n",
       "            5.9375e-01, 5.8887e-01, 5.8740e-01, 5.7129e-01, 5.4834e-01,\n",
       "            5.4541e-01, 5.4150e-01, 5.3418e-01, 5.2148e-01, 5.1855e-01,\n",
       "            5.1758e-01, 5.1172e-01, 5.0781e-01, 5.0244e-01, 4.7705e-01,\n",
       "            4.5605e-01, 4.3774e-01, 4.2358e-01, 4.1406e-01, 4.0454e-01,\n",
       "            3.9355e-01, 3.9062e-01, 3.8477e-01, 3.8403e-01, 3.8086e-01,\n",
       "            3.7158e-01, 3.4692e-01, 3.1421e-01, 2.9834e-01, 2.9712e-01,\n",
       "            2.7905e-01, 2.7417e-01, 2.7026e-01, 2.2693e-01, 2.1863e-01,\n",
       "            1.8994e-01, 1.8787e-01, 1.7004e-01, 1.4917e-01, 1.3611e-01,\n",
       "            1.2610e-01, 1.1780e-01, 1.0992e-01, 9.7229e-02, 9.5032e-02,\n",
       "            9.2224e-02, 7.6111e-02, 6.8054e-02, 6.7810e-02, 6.6589e-02,\n",
       "            6.5979e-02, 6.5735e-02, 5.1453e-02, 4.7516e-02, 4.7241e-02,\n",
       "            4.5685e-02, 4.4861e-02, 4.4769e-02, 4.4525e-02, 4.3762e-02,\n",
       "            4.1077e-02, 3.8452e-02, 3.6713e-02, 3.4821e-02, 3.4363e-02,\n",
       "            3.4180e-02, 3.2898e-02, 3.2166e-02, 3.0792e-02, 3.0151e-02,\n",
       "            2.9816e-02, 2.9587e-02, 2.8763e-02, 2.7435e-02, 2.7008e-02,\n",
       "            2.6855e-02, 2.6505e-02, 2.6459e-02, 2.6062e-02, 2.5131e-02,\n",
       "            2.4429e-02, 2.4094e-02, 2.3956e-02, 2.2629e-02, 2.2079e-02,\n",
       "            2.1652e-02, 2.1454e-02, 2.0844e-02, 1.9913e-02, 1.8051e-02,\n",
       "            1.7853e-02, 1.7776e-02, 1.7044e-02, 1.6586e-02, 1.6342e-02,\n",
       "            1.6159e-02, 1.5717e-02, 1.5251e-02, 1.5190e-02, 1.4954e-02,\n",
       "            1.4786e-02, 1.4671e-02, 1.4008e-02, 1.3901e-02, 1.3687e-02,\n",
       "            1.3275e-02, 1.3123e-02, 1.3023e-02, 1.1963e-02, 1.1597e-02,\n",
       "            1.1505e-02, 1.1246e-02, 1.0780e-02, 1.0330e-02, 1.0010e-02,\n",
       "            9.8572e-03, 8.9188e-03, 8.8120e-03, 8.6746e-03, 8.5754e-03,\n",
       "            8.4763e-03, 8.0338e-03, 7.7858e-03, 7.5760e-03, 7.5493e-03,\n",
       "            7.2327e-03, 6.9046e-03, 6.8512e-03, 6.2904e-03, 6.1455e-03,\n",
       "            6.0501e-03, 5.8441e-03, 5.6648e-03, 5.3864e-03, 5.1193e-03,\n",
       "            4.7188e-03, 4.4174e-03, 4.3640e-03, 4.3488e-03, 3.7498e-03,\n",
       "            3.6354e-03, 3.4962e-03, 3.2234e-03, 3.1853e-03, 3.0632e-03,\n",
       "            2.8000e-03, 2.7580e-03, 2.6321e-03, 2.5711e-03, 2.5120e-03,\n",
       "            2.4052e-03, 9.6226e-04], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00833333, dtype=float32),\n",
       "    'tpr': array(0.74615383, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.05      ,\n",
       "            0.05833333, 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.525     , 0.53333336, 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01538462, 0.03076923, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.15384616, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9609e-01, 9.9365e-01, 9.8779e-01, 9.8682e-01,\n",
       "            9.8633e-01, 9.8584e-01, 9.8389e-01, 9.8193e-01, 9.8145e-01,\n",
       "            9.7949e-01, 9.7559e-01, 9.7461e-01, 9.7266e-01, 9.6875e-01,\n",
       "            9.6777e-01, 9.6436e-01, 9.6143e-01, 9.5850e-01, 9.5312e-01,\n",
       "            9.5264e-01, 9.5215e-01, 9.5166e-01, 9.5117e-01, 9.3945e-01,\n",
       "            9.3652e-01, 9.3311e-01, 9.3018e-01, 9.2578e-01, 9.2383e-01,\n",
       "            9.1992e-01, 9.1846e-01, 9.1553e-01, 9.1260e-01, 9.0820e-01,\n",
       "            9.0527e-01, 9.0430e-01, 9.0332e-01, 8.9893e-01, 8.9258e-01,\n",
       "            8.9111e-01, 8.6377e-01, 8.6328e-01, 8.5986e-01, 8.5840e-01,\n",
       "            8.5693e-01, 8.2764e-01, 8.2568e-01, 8.2178e-01, 8.1982e-01,\n",
       "            8.1885e-01, 8.1348e-01, 8.0176e-01, 7.9834e-01, 7.6416e-01,\n",
       "            7.4805e-01, 7.4609e-01, 7.3975e-01, 7.3535e-01, 7.2998e-01,\n",
       "            7.2412e-01, 7.1631e-01, 7.1143e-01, 7.1094e-01, 7.0215e-01,\n",
       "            6.9873e-01, 6.9775e-01, 6.9287e-01, 6.9238e-01, 6.8701e-01,\n",
       "            6.8262e-01, 6.6113e-01, 6.5771e-01, 6.5723e-01, 6.5576e-01,\n",
       "            6.4795e-01, 6.4600e-01, 6.3916e-01, 6.3184e-01, 6.1475e-01,\n",
       "            6.1377e-01, 6.1182e-01, 5.9570e-01, 5.8594e-01, 5.8350e-01,\n",
       "            5.5762e-01, 5.5713e-01, 5.3906e-01, 5.2490e-01, 5.2246e-01,\n",
       "            5.1318e-01, 5.0732e-01, 4.9487e-01, 4.9365e-01, 4.8096e-01,\n",
       "            4.7192e-01, 4.6338e-01, 4.5166e-01, 4.4238e-01, 4.3213e-01,\n",
       "            4.1992e-01, 3.9795e-01, 3.8794e-01, 3.8501e-01, 3.8379e-01,\n",
       "            3.7061e-01, 3.5791e-01, 3.4766e-01, 3.4155e-01, 3.3887e-01,\n",
       "            3.3618e-01, 3.2910e-01, 2.9199e-01, 2.7222e-01, 2.4731e-01,\n",
       "            2.4670e-01, 2.4365e-01, 2.3303e-01, 2.3096e-01, 1.9104e-01,\n",
       "            1.6711e-01, 1.5894e-01, 1.5100e-01, 1.3855e-01, 1.1395e-01,\n",
       "            1.0358e-01, 1.0016e-01, 9.3201e-02, 8.3313e-02, 7.8796e-02,\n",
       "            7.4646e-02, 6.6833e-02, 6.5613e-02, 5.7373e-02, 5.5206e-02,\n",
       "            5.0720e-02, 4.6631e-02, 4.6478e-02, 4.3854e-02, 3.7811e-02,\n",
       "            3.4027e-02, 3.2166e-02, 3.1799e-02, 3.1204e-02, 3.0106e-02,\n",
       "            2.9373e-02, 2.7115e-02, 2.5040e-02, 2.4750e-02, 2.4384e-02,\n",
       "            2.3148e-02, 2.2629e-02, 2.2507e-02, 2.2247e-02, 2.1622e-02,\n",
       "            2.1042e-02, 2.0599e-02, 1.9302e-02, 1.9012e-02, 1.8936e-02,\n",
       "            1.8051e-02, 1.7853e-02, 1.6724e-02, 1.6663e-02, 1.6464e-02,\n",
       "            1.6403e-02, 1.6281e-02, 1.6022e-02, 1.5488e-02, 1.5305e-02,\n",
       "            1.4503e-02, 1.3901e-02, 1.3794e-02, 1.3428e-02, 1.2726e-02,\n",
       "            1.2627e-02, 1.2238e-02, 1.1505e-02, 1.1330e-02, 1.1070e-02,\n",
       "            1.0857e-02, 1.0246e-02, 1.0208e-02, 1.0132e-02, 9.4833e-03,\n",
       "            9.1629e-03, 9.1248e-03, 8.9493e-03, 8.6746e-03, 8.6441e-03,\n",
       "            8.4457e-03, 8.4152e-03, 8.3160e-03, 7.6675e-03, 7.0953e-03,\n",
       "            7.0114e-03, 6.7444e-03, 6.7177e-03, 6.3896e-03, 6.1913e-03,\n",
       "            5.8441e-03, 5.5351e-03, 5.3024e-03, 5.2414e-03, 5.2185e-03,\n",
       "            4.9057e-03, 4.7379e-03, 4.6654e-03, 4.5204e-03, 4.4327e-03,\n",
       "            4.4174e-03, 4.0054e-03, 3.9139e-03, 3.7079e-03, 3.6926e-03,\n",
       "            3.6068e-03, 3.5114e-03, 3.4828e-03, 3.3627e-03, 3.3112e-03,\n",
       "            3.1357e-03, 2.8458e-03, 2.8229e-03, 2.6627e-03, 2.5501e-03,\n",
       "            2.0676e-03, 1.9951e-03, 1.9188e-03, 1.8530e-03, 1.7481e-03,\n",
       "            1.6165e-03, 1.5306e-03, 1.5011e-03, 1.4782e-03, 1.4668e-03,\n",
       "            1.2741e-03, 4.6730e-04], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00833333, dtype=float32),\n",
       "    'tpr': array(0.74615383, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25      , 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.36666667, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.7       , 0.71666664, 0.725     , 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01538462, 0.02307692, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06923077, 0.07692308, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.11538462, 0.13076924,\n",
       "            0.13846155, 0.15384616, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.26153848, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.47692308, 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9707e-01, 9.9512e-01, 9.9414e-01, 9.8975e-01,\n",
       "            9.8877e-01, 9.8828e-01, 9.8779e-01, 9.8535e-01, 9.8486e-01,\n",
       "            9.8438e-01, 9.8047e-01, 9.7900e-01, 9.7803e-01, 9.7412e-01,\n",
       "            9.7266e-01, 9.6924e-01, 9.6484e-01, 9.6289e-01, 9.5996e-01,\n",
       "            9.5898e-01, 9.5850e-01, 9.5801e-01, 9.5361e-01, 9.4189e-01,\n",
       "            9.4043e-01, 9.3945e-01, 9.3604e-01, 9.2871e-01, 9.2285e-01,\n",
       "            9.2236e-01, 9.2188e-01, 9.2041e-01, 9.1650e-01, 9.1406e-01,\n",
       "            9.1309e-01, 9.1211e-01, 9.0820e-01, 8.9746e-01, 8.9160e-01,\n",
       "            8.7598e-01, 8.7256e-01, 8.7012e-01, 8.6084e-01, 8.3984e-01,\n",
       "            8.3838e-01, 8.3350e-01, 8.2812e-01, 8.1885e-01, 8.1201e-01,\n",
       "            8.0859e-01, 7.9541e-01, 7.6270e-01, 7.5439e-01, 7.5342e-01,\n",
       "            7.4902e-01, 7.4219e-01, 7.3145e-01, 7.2803e-01, 7.2656e-01,\n",
       "            7.2266e-01, 7.1924e-01, 7.0605e-01, 7.0508e-01, 7.0117e-01,\n",
       "            6.9873e-01, 6.7822e-01, 6.7334e-01, 6.7236e-01, 6.7188e-01,\n",
       "            6.7139e-01, 6.6406e-01, 6.5918e-01, 6.5381e-01, 6.3574e-01,\n",
       "            6.1230e-01, 5.9717e-01, 5.9082e-01, 5.7422e-01, 5.7275e-01,\n",
       "            5.6445e-01, 5.6055e-01, 5.5566e-01, 5.3613e-01, 5.2686e-01,\n",
       "            5.1270e-01, 5.0684e-01, 5.0146e-01, 5.0000e-01, 4.8413e-01,\n",
       "            4.7827e-01, 4.4824e-01, 4.2627e-01, 4.2603e-01, 4.2480e-01,\n",
       "            3.9624e-01, 3.9331e-01, 3.8940e-01, 3.8184e-01, 3.7646e-01,\n",
       "            3.7183e-01, 3.5791e-01, 3.5547e-01, 3.4644e-01, 3.4473e-01,\n",
       "            3.4131e-01, 3.3130e-01, 3.0957e-01, 2.6880e-01, 2.6367e-01,\n",
       "            2.4207e-01, 2.2546e-01, 2.2302e-01, 2.2131e-01, 2.1582e-01,\n",
       "            1.8127e-01, 1.5051e-01, 1.3818e-01, 1.3806e-01, 1.2830e-01,\n",
       "            1.0052e-01, 9.5520e-02, 9.3872e-02, 7.9895e-02, 7.1350e-02,\n",
       "            6.5857e-02, 6.0852e-02, 5.1270e-02, 4.9866e-02, 4.8767e-02,\n",
       "            4.7424e-02, 4.2084e-02, 3.8452e-02, 3.5004e-02, 3.4943e-02,\n",
       "            2.9205e-02, 2.6413e-02, 2.6199e-02, 2.6001e-02, 2.5909e-02,\n",
       "            2.4796e-02, 2.1744e-02, 2.1576e-02, 2.0020e-02, 1.9119e-02,\n",
       "            1.8051e-02, 1.7990e-02, 1.7776e-02, 1.7044e-02, 1.6922e-02,\n",
       "            1.6724e-02, 1.6525e-02, 1.6342e-02, 1.5961e-02, 1.5778e-02,\n",
       "            1.5305e-02, 1.5129e-02, 1.4503e-02, 1.3588e-02, 1.2871e-02,\n",
       "            1.2337e-02, 1.1421e-02, 1.1200e-02, 1.1116e-02, 1.0780e-02,\n",
       "            1.0452e-02, 1.0132e-02, 1.0056e-02, 9.8190e-03, 9.4833e-03,\n",
       "            9.1629e-03, 8.8501e-03, 8.7433e-03, 8.6441e-03, 8.3160e-03,\n",
       "            8.2550e-03, 7.9346e-03, 7.8430e-03, 7.4043e-03, 7.3166e-03,\n",
       "            7.2327e-03, 7.2060e-03, 7.1487e-03, 6.9313e-03, 6.7711e-03,\n",
       "            6.6147e-03, 6.4888e-03, 5.8899e-03, 5.8212e-03, 5.7297e-03,\n",
       "            5.4703e-03, 5.3444e-03, 5.2795e-03, 5.2185e-03, 5.1804e-03,\n",
       "            4.4518e-03, 4.2992e-03, 4.2496e-03, 4.1656e-03, 3.8700e-03,\n",
       "            3.8395e-03, 3.6640e-03, 3.2978e-03, 3.0994e-03, 3.0632e-03,\n",
       "            2.8782e-03, 2.7905e-03, 2.7256e-03, 2.6722e-03, 2.5406e-03,\n",
       "            2.5120e-03, 2.4815e-03, 2.4624e-03, 2.2602e-03, 2.2526e-03,\n",
       "            2.1324e-03, 2.1076e-03, 2.0199e-03, 2.0103e-03, 1.9569e-03,\n",
       "            1.8969e-03, 1.8311e-03, 1.5068e-03, 1.2207e-03, 1.1654e-03,\n",
       "            1.0567e-03, 1.0118e-03, 9.8515e-04, 8.7261e-04, 8.3303e-04,\n",
       "            7.5245e-04, 7.3528e-04, 6.1417e-04, 3.2496e-04], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.7307692, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.06153846, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.16153847, 0.17692308, 0.18461539,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2923077 , 0.30769232, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9805e-01, 9.9756e-01, 9.9609e-01, 9.9219e-01,\n",
       "            9.9170e-01, 9.9121e-01, 9.8877e-01, 9.8828e-01, 9.8730e-01,\n",
       "            9.8291e-01, 9.8193e-01, 9.8096e-01, 9.7998e-01, 9.7754e-01,\n",
       "            9.7461e-01, 9.7412e-01, 9.7119e-01, 9.6631e-01, 9.6582e-01,\n",
       "            9.6484e-01, 9.6436e-01, 9.6289e-01, 9.5361e-01, 9.5117e-01,\n",
       "            9.5020e-01, 9.4824e-01, 9.4629e-01, 9.4385e-01, 9.3994e-01,\n",
       "            9.3799e-01, 9.3408e-01, 9.2627e-01, 9.2480e-01, 9.2432e-01,\n",
       "            9.1895e-01, 9.1846e-01, 9.1309e-01, 8.9697e-01, 8.9209e-01,\n",
       "            8.8916e-01, 8.8623e-01, 8.8428e-01, 8.5596e-01, 8.5547e-01,\n",
       "            8.5449e-01, 8.5254e-01, 8.4668e-01, 8.3936e-01, 8.2861e-01,\n",
       "            8.0713e-01, 7.9248e-01, 7.8613e-01, 7.7539e-01, 7.6709e-01,\n",
       "            7.6514e-01, 7.6465e-01, 7.5342e-01, 7.5000e-01, 7.4756e-01,\n",
       "            7.4414e-01, 7.4316e-01, 7.3828e-01, 7.2705e-01, 7.1436e-01,\n",
       "            7.0605e-01, 6.8848e-01, 6.8799e-01, 6.8555e-01, 6.8457e-01,\n",
       "            6.8213e-01, 6.7920e-01, 6.6553e-01, 6.4844e-01, 6.4355e-01,\n",
       "            6.1182e-01, 6.0352e-01, 5.9912e-01, 5.9180e-01, 5.8057e-01,\n",
       "            5.7812e-01, 5.6006e-01, 5.5762e-01, 5.5469e-01, 5.2686e-01,\n",
       "            4.9829e-01, 4.9731e-01, 4.9536e-01, 4.9512e-01, 4.9219e-01,\n",
       "            4.7607e-01, 4.1992e-01, 4.1821e-01, 4.0601e-01, 4.0259e-01,\n",
       "            4.0234e-01, 3.9551e-01, 3.8525e-01, 3.7256e-01, 3.6768e-01,\n",
       "            3.6401e-01, 3.4448e-01, 3.3301e-01, 3.2788e-01, 3.2593e-01,\n",
       "            3.2544e-01, 3.2251e-01, 2.9785e-01, 2.6050e-01, 2.5488e-01,\n",
       "            2.3877e-01, 2.1790e-01, 2.1716e-01, 2.1033e-01, 1.9934e-01,\n",
       "            1.7615e-01, 1.4685e-01, 1.2805e-01, 1.2128e-01, 1.1395e-01,\n",
       "            9.1736e-02, 8.1970e-02, 8.1238e-02, 6.4392e-02, 5.9113e-02,\n",
       "            5.8899e-02, 4.7150e-02, 4.3945e-02, 4.2328e-02, 4.1321e-02,\n",
       "            3.8391e-02, 3.1616e-02, 3.1494e-02, 2.7328e-02, 2.7115e-02,\n",
       "            2.1744e-02, 2.0920e-02, 2.0020e-02, 1.8982e-02, 1.6922e-02,\n",
       "            1.6724e-02, 1.6022e-02, 1.5541e-02, 1.4618e-02, 1.4557e-02,\n",
       "            1.3634e-02, 1.3535e-02, 1.3374e-02, 1.2772e-02, 1.2672e-02,\n",
       "            1.2100e-02, 1.1505e-02, 1.1070e-02, 1.1032e-02, 1.0902e-02,\n",
       "            1.0612e-02, 1.0170e-02, 9.9716e-03, 9.1248e-03, 9.0561e-03,\n",
       "            8.6441e-03, 8.4763e-03, 8.4152e-03, 8.1558e-03, 7.7248e-03,\n",
       "            7.4883e-03, 7.2899e-03, 6.7444e-03, 6.7177e-03, 6.5384e-03,\n",
       "            6.2408e-03, 6.2180e-03, 6.0043e-03, 5.9586e-03, 5.7755e-03,\n",
       "            5.6648e-03, 5.4054e-03, 5.3864e-03, 5.2414e-03, 4.8485e-03,\n",
       "            4.7913e-03, 4.6806e-03, 4.6654e-03, 4.4670e-03, 4.3640e-03,\n",
       "            4.3144e-03, 4.0855e-03, 4.0245e-03, 3.7212e-03, 3.6068e-03,\n",
       "            3.5248e-03, 3.3379e-03, 3.2978e-03, 3.2349e-03, 3.1967e-03,\n",
       "            3.1605e-03, 2.8782e-03, 2.8000e-03, 2.7046e-03, 2.6932e-03,\n",
       "            2.6112e-03, 2.5806e-03, 2.2697e-03, 2.1992e-03, 2.1248e-03,\n",
       "            1.9646e-03, 1.9188e-03, 1.8969e-03, 1.8101e-03, 1.8034e-03,\n",
       "            1.7748e-03, 1.7681e-03, 1.6108e-03, 1.5793e-03, 1.5249e-03,\n",
       "            1.4439e-03, 1.4267e-03, 1.4210e-03, 1.3514e-03, 1.2646e-03,\n",
       "            1.2016e-03, 1.1158e-03, 1.0729e-03, 9.9277e-04, 8.6594e-04,\n",
       "            7.0953e-04, 6.7997e-04, 6.5374e-04, 5.4836e-04, 5.2547e-04,\n",
       "            5.0545e-04, 4.4584e-04, 4.0936e-04, 3.7122e-04, 3.6407e-04,\n",
       "            3.0065e-04, 1.6475e-04], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.7307692, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05833333, 0.06666667,\n",
       "            0.075     , 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.325     , 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03076923, 0.03846154,\n",
       "            0.06153846, 0.07692308, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.24615385, 0.25384617, 0.26153848, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9902e-01, 9.9805e-01, 9.9707e-01, 9.9414e-01,\n",
       "            9.9365e-01, 9.9170e-01, 9.8975e-01, 9.8633e-01, 9.8486e-01,\n",
       "            9.8438e-01, 9.8242e-01, 9.8145e-01, 9.8096e-01, 9.7900e-01,\n",
       "            9.7803e-01, 9.7461e-01, 9.7314e-01, 9.7217e-01, 9.7119e-01,\n",
       "            9.7021e-01, 9.6924e-01, 9.6826e-01, 9.6484e-01, 9.5996e-01,\n",
       "            9.5605e-01, 9.5508e-01, 9.5312e-01, 9.5117e-01, 9.4531e-01,\n",
       "            9.4092e-01, 9.3945e-01, 9.3604e-01, 9.3457e-01, 9.3115e-01,\n",
       "            9.2676e-01, 9.1797e-01, 9.1455e-01, 8.9844e-01, 8.9746e-01,\n",
       "            8.9600e-01, 8.9355e-01, 8.8867e-01, 8.8721e-01, 8.6572e-01,\n",
       "            8.6084e-01, 8.5889e-01, 8.5352e-01, 8.5205e-01, 8.4717e-01,\n",
       "            8.4473e-01, 8.1445e-01, 7.9688e-01, 7.8369e-01, 7.8174e-01,\n",
       "            7.7588e-01, 7.7490e-01, 7.6318e-01, 7.6123e-01, 7.5830e-01,\n",
       "            7.5781e-01, 7.5342e-01, 7.4756e-01, 7.2998e-01, 7.2217e-01,\n",
       "            7.0752e-01, 6.9824e-01, 6.9775e-01, 6.8799e-01, 6.8115e-01,\n",
       "            6.7676e-01, 6.7627e-01, 6.7041e-01, 6.6357e-01, 6.5088e-01,\n",
       "            6.2354e-01, 6.1084e-01, 6.1035e-01, 5.8545e-01, 5.6982e-01,\n",
       "            5.6836e-01, 5.6348e-01, 5.5762e-01, 5.2686e-01, 5.2246e-01,\n",
       "            5.1318e-01, 4.9097e-01, 4.8169e-01, 4.7729e-01, 4.7461e-01,\n",
       "            4.4751e-01, 4.3994e-01, 4.1309e-01, 4.0698e-01, 4.0112e-01,\n",
       "            3.7842e-01, 3.7598e-01, 3.6255e-01, 3.5791e-01, 3.5376e-01,\n",
       "            3.4888e-01, 3.4399e-01, 3.2983e-01, 3.1982e-01, 3.0005e-01,\n",
       "            2.8687e-01, 2.8467e-01, 2.8369e-01, 2.8076e-01, 2.4023e-01,\n",
       "            2.3010e-01, 2.1851e-01, 1.9531e-01, 1.8860e-01, 1.8774e-01,\n",
       "            1.8164e-01, 1.5051e-01, 1.2756e-01, 9.9670e-02, 9.8755e-02,\n",
       "            9.1064e-02, 8.0627e-02, 6.8665e-02, 6.2103e-02, 4.9042e-02,\n",
       "            4.6295e-02, 4.4189e-02, 3.5400e-02, 3.5004e-02, 3.2043e-02,\n",
       "            3.1799e-02, 2.9419e-02, 2.1408e-02, 2.0340e-02, 1.9791e-02,\n",
       "            1.9714e-02, 1.5129e-02, 1.4557e-02, 1.4282e-02, 1.2825e-02,\n",
       "            1.2100e-02, 1.1246e-02, 1.0735e-02, 1.0651e-02, 1.0567e-02,\n",
       "            9.3384e-03, 9.0866e-03, 8.9493e-03, 8.7814e-03, 8.5754e-03,\n",
       "            8.5449e-03, 8.3771e-03, 7.6942e-03, 7.3471e-03, 7.3166e-03,\n",
       "            7.0648e-03, 6.9847e-03, 6.8245e-03, 6.7978e-03, 6.5651e-03,\n",
       "            6.2408e-03, 6.0043e-03, 5.6000e-03, 5.5542e-03, 5.3635e-03,\n",
       "            4.7379e-03, 4.6806e-03, 4.5929e-03, 4.1809e-03, 4.0550e-03,\n",
       "            3.9291e-03, 3.7956e-03, 3.6793e-03, 3.6507e-03, 3.5934e-03,\n",
       "            3.5248e-03, 3.4695e-03, 3.2978e-03, 3.2597e-03, 3.2234e-03,\n",
       "            3.0880e-03, 2.9469e-03, 2.8667e-03, 2.7905e-03, 2.7370e-03,\n",
       "            2.6531e-03, 2.6016e-03, 2.5711e-03, 2.3880e-03, 2.1572e-03,\n",
       "            2.0828e-03, 1.9188e-03, 1.9121e-03, 1.8969e-03, 1.8826e-03,\n",
       "            1.8530e-03, 1.8463e-03, 1.8244e-03, 1.7891e-03, 1.4954e-03,\n",
       "            1.4725e-03, 1.4496e-03, 1.4324e-03, 1.2646e-03, 1.2016e-03,\n",
       "            1.1921e-03, 1.0567e-03, 1.0481e-03, 1.0166e-03, 1.0118e-03,\n",
       "            9.5844e-04, 9.5463e-04, 9.4748e-04, 9.3651e-04, 8.5258e-04,\n",
       "            8.2016e-04, 7.4100e-04, 7.2956e-04, 7.2098e-04, 6.3848e-04,\n",
       "            6.1178e-04, 5.5695e-04, 5.2977e-04, 4.8780e-04, 4.4584e-04,\n",
       "            3.6693e-04, 3.5429e-04, 3.0780e-04, 2.4915e-04, 2.3782e-04,\n",
       "            2.2697e-04, 1.9872e-04, 1.8966e-04, 1.6093e-04, 1.5724e-04,\n",
       "            1.2636e-04, 5.9187e-05], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.7307692, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.06153846, 0.06923077, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9902e-01, 9.9854e-01, 9.9756e-01, 9.9561e-01,\n",
       "            9.9512e-01, 9.9463e-01, 9.9365e-01, 9.9268e-01, 9.9170e-01,\n",
       "            9.9023e-01, 9.8877e-01, 9.8633e-01, 9.8584e-01, 9.8438e-01,\n",
       "            9.8340e-01, 9.8291e-01, 9.7998e-01, 9.7803e-01, 9.7754e-01,\n",
       "            9.7656e-01, 9.7607e-01, 9.7559e-01, 9.7412e-01, 9.7070e-01,\n",
       "            9.6484e-01, 9.6240e-01, 9.6191e-01, 9.6143e-01, 9.5703e-01,\n",
       "            9.5654e-01, 9.5557e-01, 9.5215e-01, 9.5166e-01, 9.4824e-01,\n",
       "            9.4385e-01, 9.4189e-01, 9.3701e-01, 9.3652e-01, 9.3555e-01,\n",
       "            9.2725e-01, 9.2383e-01, 9.1699e-01, 9.1260e-01, 9.1064e-01,\n",
       "            9.0771e-01, 9.0479e-01, 8.9893e-01, 8.8428e-01, 8.8379e-01,\n",
       "            8.7988e-01, 8.7695e-01, 8.6768e-01, 8.6328e-01, 8.5693e-01,\n",
       "            8.2324e-01, 8.0957e-01, 7.8906e-01, 7.8857e-01, 7.8809e-01,\n",
       "            7.7881e-01, 7.7734e-01, 7.7539e-01, 7.7441e-01, 7.6953e-01,\n",
       "            7.6367e-01, 7.5830e-01, 7.3584e-01, 7.1875e-01, 7.1436e-01,\n",
       "            7.0557e-01, 7.0361e-01, 7.0264e-01, 6.9336e-01, 6.8164e-01,\n",
       "            6.7627e-01, 6.7334e-01, 6.3281e-01, 6.1768e-01, 6.0840e-01,\n",
       "            5.9863e-01, 5.9277e-01, 5.8350e-01, 5.7666e-01, 5.6885e-01,\n",
       "            5.6299e-01, 5.3369e-01, 5.3320e-01, 5.3271e-01, 5.2246e-01,\n",
       "            4.9414e-01, 4.8486e-01, 4.7021e-01, 4.5581e-01, 4.4067e-01,\n",
       "            4.1919e-01, 4.1309e-01, 3.9185e-01, 3.8770e-01, 3.7378e-01,\n",
       "            3.6938e-01, 3.6816e-01, 3.5376e-01, 3.4692e-01, 3.3911e-01,\n",
       "            3.2739e-01, 3.2373e-01, 3.0640e-01, 2.9639e-01, 2.7661e-01,\n",
       "            2.7222e-01, 2.6416e-01, 2.5781e-01, 2.2632e-01, 2.2241e-01,\n",
       "            2.1179e-01, 1.8359e-01, 1.8164e-01, 1.7920e-01, 1.6052e-01,\n",
       "            1.4453e-01, 1.2317e-01, 9.1248e-02, 8.9294e-02, 7.7637e-02,\n",
       "            7.6843e-02, 5.7495e-02, 5.5511e-02, 4.3945e-02, 3.7811e-02,\n",
       "            3.4882e-02, 3.0563e-02, 2.7588e-02, 2.6855e-02, 2.6611e-02,\n",
       "            2.4185e-02, 1.7380e-02, 1.5129e-02, 1.4786e-02, 1.3168e-02,\n",
       "            1.2924e-02, 1.1330e-02, 1.0452e-02, 9.4147e-03, 8.7128e-03,\n",
       "            8.4457e-03, 7.7553e-03, 7.6942e-03, 7.0648e-03, 7.0381e-03,\n",
       "            6.9580e-03, 6.6910e-03, 6.3133e-03, 6.1913e-03, 5.9814e-03,\n",
       "            5.7983e-03, 5.6419e-03, 5.5542e-03, 5.4893e-03, 5.4054e-03,\n",
       "            5.3864e-03, 5.2795e-03, 5.1613e-03, 4.9629e-03, 4.9248e-03,\n",
       "            4.7913e-03, 4.0245e-03, 3.8548e-03, 3.6068e-03, 3.1242e-03,\n",
       "            3.0270e-03, 2.7370e-03, 2.6932e-03, 2.6417e-03, 2.6016e-03,\n",
       "            2.5215e-03, 2.4815e-03, 2.3785e-03, 2.3689e-03, 2.3232e-03,\n",
       "            2.2869e-03, 2.2430e-03, 2.1248e-03, 2.0905e-03, 2.0504e-03,\n",
       "            2.0103e-03, 2.0027e-03, 1.8034e-03, 1.7481e-03, 1.6489e-03,\n",
       "            1.5306e-03, 1.4896e-03, 1.4553e-03, 1.4162e-03, 1.3561e-03,\n",
       "            1.3046e-03, 1.2693e-03, 1.2646e-03, 1.1835e-03, 1.1377e-03,\n",
       "            1.1158e-03, 1.1120e-03, 1.0948e-03, 9.4748e-04, 8.4925e-04,\n",
       "            8.4591e-04, 8.1682e-04, 7.9155e-04, 7.8869e-04, 7.6437e-04,\n",
       "            6.8808e-04, 6.3372e-04, 5.9986e-04, 5.7459e-04, 5.4216e-04,\n",
       "            5.3358e-04, 4.6182e-04, 4.5657e-04, 4.4584e-04, 4.3726e-04,\n",
       "            4.1246e-04, 3.9673e-04, 3.8457e-04, 3.5000e-04, 3.1757e-04,\n",
       "            3.0065e-04, 2.8682e-04, 2.6941e-04, 2.5916e-04, 2.5129e-04,\n",
       "            1.7405e-04, 1.2243e-04, 1.1593e-04, 1.1235e-04, 1.0228e-04,\n",
       "            9.4593e-05, 7.7844e-05, 7.4863e-05, 5.8770e-05, 3.0696e-05],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.7, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.16666667, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.46666667, 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.05384615, 0.06153846, 0.06923077, 0.07692308, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.31538463, 0.32307693, 0.33076924, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9951e-01, 9.9854e-01, 9.9756e-01, 9.9707e-01,\n",
       "            9.9561e-01, 9.9512e-01, 9.9463e-01, 9.9365e-01, 9.9219e-01,\n",
       "            9.8975e-01, 9.8926e-01, 9.8779e-01, 9.8682e-01, 9.8486e-01,\n",
       "            9.8291e-01, 9.8242e-01, 9.8145e-01, 9.7998e-01, 9.7803e-01,\n",
       "            9.7656e-01, 9.7559e-01, 9.7510e-01, 9.7314e-01, 9.7168e-01,\n",
       "            9.6289e-01, 9.6191e-01, 9.5898e-01, 9.5801e-01, 9.5654e-01,\n",
       "            9.5068e-01, 9.5020e-01, 9.4824e-01, 9.4434e-01, 9.4336e-01,\n",
       "            9.3994e-01, 9.3604e-01, 9.3311e-01, 9.2285e-01, 9.0479e-01,\n",
       "            9.0234e-01, 9.0088e-01, 9.0039e-01, 8.8477e-01, 8.8428e-01,\n",
       "            8.7109e-01, 8.6816e-01, 8.6768e-01, 8.5986e-01, 8.5840e-01,\n",
       "            8.5059e-01, 8.2617e-01, 7.9932e-01, 7.8613e-01, 7.8564e-01,\n",
       "            7.8516e-01, 7.7344e-01, 7.6611e-01, 7.6562e-01, 7.6465e-01,\n",
       "            7.5977e-01, 7.4609e-01, 7.4023e-01, 7.3975e-01, 7.2900e-01,\n",
       "            7.2656e-01, 7.1240e-01, 7.0557e-01, 7.0264e-01, 6.9385e-01,\n",
       "            6.8848e-01, 6.6260e-01, 6.6211e-01, 6.5527e-01, 6.5186e-01,\n",
       "            6.1084e-01, 6.1035e-01, 5.9570e-01, 5.7861e-01, 5.5811e-01,\n",
       "            5.4004e-01, 5.2832e-01, 5.2637e-01, 5.1367e-01, 5.0342e-01,\n",
       "            4.9365e-01, 4.7900e-01, 4.6436e-01, 4.4971e-01, 4.4482e-01,\n",
       "            4.3457e-01, 4.1821e-01, 4.0820e-01, 3.6816e-01, 3.6133e-01,\n",
       "            3.5986e-01, 3.5059e-01, 3.3691e-01, 3.2788e-01, 3.2617e-01,\n",
       "            3.2324e-01, 3.2251e-01, 3.1689e-01, 3.0225e-01, 3.0005e-01,\n",
       "            2.5830e-01, 2.4634e-01, 2.3792e-01, 2.0496e-01, 1.9788e-01,\n",
       "            1.9641e-01, 1.9128e-01, 1.7908e-01, 1.7554e-01, 1.7249e-01,\n",
       "            1.5601e-01, 1.4001e-01, 1.3647e-01, 1.3550e-01, 1.0913e-01,\n",
       "            9.6680e-02, 6.5369e-02, 6.4392e-02, 5.8655e-02, 5.2429e-02,\n",
       "            4.5197e-02, 3.8910e-02, 3.1204e-02, 2.5269e-02, 2.5177e-02,\n",
       "            2.4841e-02, 1.9836e-02, 1.7776e-02, 1.7441e-02, 1.7303e-02,\n",
       "            1.2238e-02, 1.0651e-02, 8.5144e-03, 7.9651e-03, 7.6675e-03,\n",
       "            7.0648e-03, 6.7444e-03, 5.3215e-03, 5.2795e-03, 4.8485e-03,\n",
       "            4.7569e-03, 4.7188e-03, 4.4327e-03, 4.1656e-03, 3.9902e-03,\n",
       "            3.9291e-03, 3.9139e-03, 3.8548e-03, 3.7804e-03, 3.6640e-03,\n",
       "            3.5801e-03, 3.4828e-03, 3.4428e-03, 3.3379e-03, 3.3245e-03,\n",
       "            3.3112e-03, 3.1853e-03, 3.0632e-03, 3.0403e-03, 2.8000e-03,\n",
       "            2.7142e-03, 2.2259e-03, 2.1992e-03, 2.1820e-03, 1.8969e-03,\n",
       "            1.8463e-03, 1.5850e-03, 1.5669e-03, 1.5306e-03, 1.5011e-03,\n",
       "            1.4105e-03, 1.3618e-03, 1.3561e-03, 1.3456e-03, 1.3199e-03,\n",
       "            1.2646e-03, 1.2255e-03, 1.2064e-03, 1.1692e-03, 1.1377e-03,\n",
       "            1.0605e-03, 1.0366e-03, 1.0204e-03, 1.0042e-03, 9.4366e-04,\n",
       "            9.3985e-04, 8.7261e-04, 8.4925e-04, 8.2636e-04, 7.2384e-04,\n",
       "            7.1812e-04, 7.0429e-04, 6.2370e-04, 6.0940e-04, 5.9557e-04,\n",
       "            5.7936e-04, 5.5504e-04, 4.8208e-04, 4.5133e-04, 4.4942e-04,\n",
       "            4.4775e-04, 4.2391e-04, 4.2224e-04, 4.1723e-04, 3.9363e-04,\n",
       "            3.5834e-04, 3.0541e-04, 2.9588e-04, 2.8920e-04, 2.7370e-04,\n",
       "            2.6727e-04, 2.6536e-04, 2.4915e-04, 2.2697e-04, 2.1315e-04,\n",
       "            2.0826e-04, 2.0027e-04, 1.9407e-04, 1.8525e-04, 1.6737e-04,\n",
       "            1.5473e-04, 1.4317e-04, 1.3340e-04, 1.2732e-04, 1.2529e-04,\n",
       "            1.2338e-04, 7.5459e-05, 5.2691e-05, 4.9889e-05, 4.7922e-05,\n",
       "            4.1962e-05, 3.9756e-05, 3.1710e-05, 3.0696e-05, 2.3365e-05,\n",
       "            1.0729e-05], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.72307694, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15      , 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.2       , 0.20833333, 0.21666667, 0.23333333,\n",
       "            0.24166666, 0.25      , 0.26666668, 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.05384615, 0.06923077, 0.07692308, 0.08461539, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9951e-01, 9.9902e-01, 9.9854e-01, 9.9805e-01,\n",
       "            9.9756e-01, 9.9707e-01, 9.9658e-01, 9.9512e-01, 9.9316e-01,\n",
       "            9.9170e-01, 9.9121e-01, 9.9023e-01, 9.8926e-01, 9.8828e-01,\n",
       "            9.8779e-01, 9.8682e-01, 9.8535e-01, 9.8389e-01, 9.8242e-01,\n",
       "            9.8193e-01, 9.8047e-01, 9.7656e-01, 9.7363e-01, 9.7217e-01,\n",
       "            9.7168e-01, 9.6924e-01, 9.6826e-01, 9.6680e-01, 9.6387e-01,\n",
       "            9.6289e-01, 9.6045e-01, 9.5801e-01, 9.5703e-01, 9.5654e-01,\n",
       "            9.5605e-01, 9.5410e-01, 9.3555e-01, 9.3018e-01, 9.2480e-01,\n",
       "            9.2432e-01, 9.1650e-01, 9.1602e-01, 9.0283e-01, 9.0088e-01,\n",
       "            8.9893e-01, 8.9795e-01, 8.9697e-01, 8.9551e-01, 8.8525e-01,\n",
       "            8.8232e-01, 8.4473e-01, 8.4375e-01, 8.4180e-01, 8.3691e-01,\n",
       "            8.3545e-01, 8.3350e-01, 8.2129e-01, 8.1641e-01, 8.1201e-01,\n",
       "            7.9639e-01, 7.9590e-01, 7.8857e-01, 7.8369e-01, 7.7734e-01,\n",
       "            7.7539e-01, 7.7344e-01, 7.6904e-01, 7.6514e-01, 7.5781e-01,\n",
       "            7.2754e-01, 7.2461e-01, 7.1777e-01, 7.1729e-01, 6.8750e-01,\n",
       "            6.7139e-01, 6.6797e-01, 6.4404e-01, 6.2695e-01, 6.2451e-01,\n",
       "            6.0498e-01, 5.9326e-01, 5.5957e-01, 5.5664e-01, 5.4492e-01,\n",
       "            5.4248e-01, 5.2734e-01, 5.0635e-01, 4.9561e-01, 4.9536e-01,\n",
       "            4.9219e-01, 4.5679e-01, 4.2969e-01, 4.1797e-01, 4.0967e-01,\n",
       "            3.8306e-01, 3.7915e-01, 3.7793e-01, 3.7476e-01, 3.7061e-01,\n",
       "            3.6646e-01, 3.6597e-01, 3.6279e-01, 3.1274e-01, 2.8638e-01,\n",
       "            2.4805e-01, 2.3376e-01, 2.2400e-01, 2.1082e-01, 2.0557e-01,\n",
       "            2.0178e-01, 1.8103e-01, 1.7834e-01, 1.7737e-01, 1.6028e-01,\n",
       "            1.5588e-01, 1.4966e-01, 1.4771e-01, 1.2408e-01, 1.1047e-01,\n",
       "            7.3547e-02, 7.2632e-02, 6.3965e-02, 4.6021e-02, 4.5349e-02,\n",
       "            4.4342e-02, 3.5889e-02, 2.6260e-02, 2.4704e-02, 2.2583e-02,\n",
       "            2.2156e-02, 1.7914e-02, 1.5602e-02, 1.4061e-02, 1.3374e-02,\n",
       "            9.1934e-03, 9.1629e-03, 7.3471e-03, 6.6147e-03, 5.5771e-03,\n",
       "            5.4893e-03, 5.4054e-03, 5.1384e-03, 5.0201e-03, 4.5547e-03,\n",
       "            4.0398e-03, 3.9444e-03, 3.7212e-03, 3.5381e-03, 3.4294e-03,\n",
       "            3.4027e-03, 3.3512e-03, 3.2730e-03, 3.2349e-03, 2.7256e-03,\n",
       "            2.5806e-03, 2.5406e-03, 2.3499e-03, 2.3136e-03, 2.1496e-03,\n",
       "            2.1000e-03, 2.0504e-03, 1.7338e-03, 1.4610e-03, 1.4439e-03,\n",
       "            1.4381e-03, 1.3885e-03, 1.3618e-03, 1.3351e-03, 1.3199e-03,\n",
       "            1.2350e-03, 1.2112e-03, 1.1921e-03, 1.1425e-03, 1.1072e-03,\n",
       "            1.0815e-03, 1.0242e-03, 9.5463e-04, 8.6260e-04, 8.3590e-04,\n",
       "            8.2016e-04, 7.8249e-04, 7.5245e-04, 7.4673e-04, 6.7186e-04,\n",
       "            6.3372e-04, 6.2370e-04, 6.1655e-04, 5.7459e-04, 5.7268e-04,\n",
       "            5.2357e-04, 5.1928e-04, 4.8971e-04, 4.2892e-04, 4.1580e-04,\n",
       "            4.0293e-04, 3.8743e-04, 3.8457e-04, 3.7408e-04, 3.6263e-04,\n",
       "            3.5286e-04, 3.4475e-04, 3.4070e-04, 3.1495e-04, 2.5320e-04,\n",
       "            2.4915e-04, 2.4152e-04, 2.1827e-04, 2.1482e-04, 2.0027e-04,\n",
       "            1.9562e-04, 1.8525e-04, 1.6999e-04, 1.5473e-04, 1.4424e-04,\n",
       "            1.3983e-04, 1.3554e-04, 1.1683e-04, 1.0890e-04, 1.0723e-04,\n",
       "            1.0151e-04, 9.8407e-05, 9.4593e-05, 8.2850e-05, 6.9737e-05,\n",
       "            6.4552e-05, 5.9187e-05, 5.6505e-05, 2.3186e-05, 2.1636e-05,\n",
       "            2.0802e-05, 1.7941e-05, 1.6809e-05, 1.2994e-05, 1.2636e-05,\n",
       "            9.3579e-06, 7.8678e-06], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.6769231, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05833333, 0.06666667,\n",
       "            0.075     , 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15      , 0.15833333, 0.15833333, 0.16666667,\n",
       "            0.175     , 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.49166667, 0.5083333 , 0.51666665,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03076923, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.11538462, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.20769231, 0.22307692,\n",
       "            0.23846154, 0.24615385, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9951e-01, 9.9902e-01, 9.9854e-01, 9.9756e-01,\n",
       "            9.9707e-01, 9.9658e-01, 9.9609e-01, 9.9561e-01, 9.9414e-01,\n",
       "            9.9365e-01, 9.9219e-01, 9.9170e-01, 9.9023e-01, 9.8926e-01,\n",
       "            9.8730e-01, 9.8535e-01, 9.8486e-01, 9.8438e-01, 9.8340e-01,\n",
       "            9.8291e-01, 9.8193e-01, 9.8145e-01, 9.7852e-01, 9.7266e-01,\n",
       "            9.7070e-01, 9.6631e-01, 9.6387e-01, 9.6338e-01, 9.6143e-01,\n",
       "            9.5898e-01, 9.5605e-01, 9.5410e-01, 9.4824e-01, 9.4580e-01,\n",
       "            9.4336e-01, 9.3164e-01, 9.2871e-01, 9.2725e-01, 9.2627e-01,\n",
       "            9.0820e-01, 9.0771e-01, 9.0527e-01, 9.0479e-01, 8.9502e-01,\n",
       "            8.9307e-01, 8.9014e-01, 8.8770e-01, 8.8574e-01, 8.8184e-01,\n",
       "            8.4570e-01, 8.3691e-01, 8.2666e-01, 8.0322e-01, 7.9932e-01,\n",
       "            7.9639e-01, 7.9004e-01, 7.8564e-01, 7.8125e-01, 7.7930e-01,\n",
       "            7.7783e-01, 7.6953e-01, 7.3340e-01, 7.2900e-01, 7.2705e-01,\n",
       "            6.9971e-01, 6.9629e-01, 6.9287e-01, 6.8457e-01, 6.8262e-01,\n",
       "            6.8213e-01, 6.6357e-01, 6.3623e-01, 6.2744e-01, 6.2451e-01,\n",
       "            6.1035e-01, 5.9375e-01, 5.8154e-01, 5.6494e-01, 5.6006e-01,\n",
       "            4.9927e-01, 4.9756e-01, 4.9048e-01, 4.8950e-01, 4.7729e-01,\n",
       "            4.4482e-01, 4.2358e-01, 4.0161e-01, 3.8013e-01, 3.7378e-01,\n",
       "            3.7036e-01, 3.5303e-01, 3.4668e-01, 3.4302e-01, 3.3765e-01,\n",
       "            3.3618e-01, 3.3276e-01, 3.2275e-01, 3.1177e-01, 3.0298e-01,\n",
       "            2.8296e-01, 2.4634e-01, 2.2021e-01, 2.0862e-01, 1.8567e-01,\n",
       "            1.8262e-01, 1.6736e-01, 1.6479e-01, 1.6113e-01, 1.5283e-01,\n",
       "            1.4600e-01, 1.2927e-01, 1.1920e-01, 1.1859e-01, 1.1499e-01,\n",
       "            1.1316e-01, 9.0271e-02, 8.4045e-02, 5.8899e-02, 4.8950e-02,\n",
       "            3.8757e-02, 3.5675e-02, 3.4088e-02, 2.1530e-02, 2.1286e-02,\n",
       "            1.7853e-02, 1.5541e-02, 1.4732e-02, 1.2772e-02, 1.0529e-02,\n",
       "            1.0406e-02, 1.0292e-02, 7.0648e-03, 6.0730e-03, 4.3297e-03,\n",
       "            3.8700e-03, 3.3512e-03, 3.1853e-03, 3.0403e-03, 2.7256e-03,\n",
       "            2.6531e-03, 2.5616e-03, 2.3594e-03, 2.2526e-03, 2.1496e-03,\n",
       "            2.1076e-03, 1.9493e-03, 1.8463e-03, 1.8244e-03, 1.7681e-03,\n",
       "            1.7481e-03, 1.5850e-03, 1.5545e-03, 1.4954e-03, 1.4896e-03,\n",
       "            1.4839e-03, 1.4381e-03, 1.3781e-03, 1.2789e-03, 1.2398e-03,\n",
       "            1.1835e-03, 1.1244e-03, 1.1120e-03, 9.3269e-04, 9.2173e-04,\n",
       "            8.1062e-04, 7.7629e-04, 7.5245e-04, 6.8235e-04, 6.1178e-04,\n",
       "            5.8174e-04, 5.4836e-04, 5.4216e-04, 5.3596e-04, 4.8971e-04,\n",
       "            4.6921e-04, 4.6563e-04, 4.4942e-04, 4.4250e-04, 4.3058e-04,\n",
       "            4.0603e-04, 3.8290e-04, 3.7122e-04, 3.5429e-04, 3.4595e-04,\n",
       "            3.2759e-04, 3.1495e-04, 2.8253e-04, 2.7800e-04, 2.6941e-04,\n",
       "            2.3413e-04, 2.3055e-04, 2.0993e-04, 2.0659e-04, 1.9717e-04,\n",
       "            1.9407e-04, 1.8668e-04, 1.8382e-04, 1.7405e-04, 1.7262e-04,\n",
       "            1.5843e-04, 1.4651e-04, 1.3447e-04, 1.3340e-04, 1.2434e-04,\n",
       "            1.0073e-04, 9.4593e-05, 9.1732e-05, 9.1016e-05, 8.4162e-05,\n",
       "            7.3135e-05, 7.1406e-05, 6.1095e-05, 5.7817e-05, 5.0247e-05,\n",
       "            4.6492e-05, 4.6134e-05, 4.1962e-05, 4.0352e-05, 4.0054e-05,\n",
       "            3.8207e-05, 3.3200e-05, 3.0696e-05, 2.9325e-05, 1.8358e-05,\n",
       "            9.5367e-06, 8.8215e-06, 8.6427e-06, 6.6161e-06, 5.3644e-06,\n",
       "            5.0664e-06, 3.5763e-06, 2.1458e-06], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.6769231, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.04166667, 0.05      ,\n",
       "            0.05      , 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15      , 0.15      , 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.525     , 0.53333336, 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03076923, 0.03846154,\n",
       "            0.05384615, 0.06153846, 0.06923077, 0.07692308, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.22307692, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9951e-01, 9.9902e-01, 9.9854e-01, 9.9805e-01,\n",
       "            9.9756e-01, 9.9707e-01, 9.9658e-01, 9.9609e-01, 9.9561e-01,\n",
       "            9.9414e-01, 9.9365e-01, 9.9219e-01, 9.9170e-01, 9.9121e-01,\n",
       "            9.9023e-01, 9.8926e-01, 9.8633e-01, 9.8535e-01, 9.8340e-01,\n",
       "            9.8291e-01, 9.8242e-01, 9.8047e-01, 9.7900e-01, 9.7803e-01,\n",
       "            9.7510e-01, 9.7021e-01, 9.6777e-01, 9.6533e-01, 9.6289e-01,\n",
       "            9.6094e-01, 9.5996e-01, 9.5947e-01, 9.5459e-01, 9.5264e-01,\n",
       "            9.5166e-01, 9.4336e-01, 9.3994e-01, 9.3848e-01, 9.3701e-01,\n",
       "            9.2480e-01, 9.2285e-01, 9.1699e-01, 9.1455e-01, 9.0576e-01,\n",
       "            8.9648e-01, 8.9160e-01, 8.8818e-01, 8.7891e-01, 8.7744e-01,\n",
       "            8.7354e-01, 8.7158e-01, 8.7061e-01, 8.6670e-01, 8.1689e-01,\n",
       "            8.1543e-01, 8.0762e-01, 7.9639e-01, 7.7734e-01, 7.7441e-01,\n",
       "            7.6172e-01, 7.5879e-01, 7.5049e-01, 7.4902e-01, 7.4512e-01,\n",
       "            7.4414e-01, 7.3535e-01, 7.0703e-01, 6.8945e-01, 6.7041e-01,\n",
       "            6.6016e-01, 6.5137e-01, 6.4990e-01, 6.2793e-01, 6.2646e-01,\n",
       "            6.2256e-01, 6.1670e-01, 5.9912e-01, 5.6836e-01, 5.5908e-01,\n",
       "            5.4688e-01, 5.3662e-01, 5.0098e-01, 4.4165e-01, 4.3311e-01,\n",
       "            4.3188e-01, 4.2090e-01, 4.0869e-01, 3.7427e-01, 3.6206e-01,\n",
       "            3.2886e-01, 3.1934e-01, 3.1299e-01, 3.0176e-01, 2.9248e-01,\n",
       "            2.9224e-01, 2.9102e-01, 2.8760e-01, 2.8174e-01, 2.7246e-01,\n",
       "            2.6270e-01, 2.5806e-01, 2.5586e-01, 2.4854e-01, 2.3840e-01,\n",
       "            2.0654e-01, 1.6699e-01, 1.5552e-01, 1.5063e-01, 1.3672e-01,\n",
       "            1.2585e-01, 1.1969e-01, 1.1658e-01, 1.0876e-01, 1.0651e-01,\n",
       "            9.3506e-02, 8.8196e-02, 8.1238e-02, 7.5867e-02, 6.0638e-02,\n",
       "            5.9540e-02, 5.8990e-02, 4.4281e-02, 3.0670e-02, 2.4521e-02,\n",
       "            2.3865e-02, 2.1744e-02, 1.6724e-02, 1.2337e-02, 1.0567e-02,\n",
       "            9.6359e-03, 8.6441e-03, 8.2855e-03, 6.8512e-03, 6.5880e-03,\n",
       "            5.5771e-03, 4.2801e-03, 3.9005e-03, 2.4719e-03, 2.4052e-03,\n",
       "            1.8606e-03, 1.7748e-03, 1.6232e-03, 1.5364e-03, 1.4267e-03,\n",
       "            1.4210e-03, 1.3828e-03, 1.3514e-03, 1.3094e-03, 1.1292e-03,\n",
       "            1.0166e-03, 9.1839e-04, 8.2636e-04, 8.2302e-04, 7.9155e-04,\n",
       "            7.8869e-04, 7.7343e-04, 6.7472e-04, 6.6137e-04, 6.5899e-04,\n",
       "            6.5660e-04, 6.3372e-04, 6.0940e-04, 5.8174e-04, 5.4216e-04,\n",
       "            5.2357e-04, 5.1117e-04, 4.6372e-04, 4.4417e-04, 4.3225e-04,\n",
       "            4.2558e-04, 4.0293e-04, 3.1495e-04, 2.9588e-04, 2.7156e-04,\n",
       "            2.6941e-04, 2.6727e-04, 2.4915e-04, 2.4724e-04, 2.3973e-04,\n",
       "            2.3234e-04, 2.0993e-04, 2.0182e-04, 1.9717e-04, 1.8966e-04,\n",
       "            1.8525e-04, 1.8382e-04, 1.7536e-04, 1.5116e-04, 1.3661e-04,\n",
       "            1.3030e-04, 1.2147e-04, 1.2052e-04, 1.1593e-04, 1.0151e-04,\n",
       "            9.9957e-05, 9.5367e-05, 9.4593e-05, 8.2850e-05, 7.7844e-05,\n",
       "            7.2002e-05, 6.7115e-05, 6.6042e-05, 6.3539e-05, 4.9889e-05,\n",
       "            4.9114e-05, 4.7922e-05, 4.0710e-05, 3.7909e-05, 3.4809e-05,\n",
       "            3.4511e-05, 3.4273e-05, 3.3736e-05, 2.7120e-05, 2.4855e-05,\n",
       "            2.3544e-05, 2.2471e-05, 2.1100e-05, 1.8954e-05, 1.8656e-05,\n",
       "            1.8477e-05, 1.5795e-05, 1.4961e-05, 1.3947e-05, 1.3530e-05,\n",
       "            7.3314e-06, 3.9339e-06, 3.8147e-06, 3.5167e-06, 2.5630e-06,\n",
       "            2.0862e-06, 1.9670e-06, 1.3113e-06, 8.3447e-07], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.6923077, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.04166667, 0.05      ,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.14166667, 0.15      ,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.02307692, 0.03846154, 0.05384615,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.10769231, 0.12307692,\n",
       "            0.13846155, 0.14615385, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.26153848, 0.26923078,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.9307692 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 1.0000e+00, 9.9951e-01, 9.9902e-01, 9.9854e-01,\n",
       "            9.9805e-01, 9.9756e-01, 9.9707e-01, 9.9658e-01, 9.9512e-01,\n",
       "            9.9463e-01, 9.9219e-01, 9.9170e-01, 9.9072e-01, 9.9023e-01,\n",
       "            9.8926e-01, 9.8633e-01, 9.8584e-01, 9.8340e-01, 9.8242e-01,\n",
       "            9.7998e-01, 9.7900e-01, 9.7754e-01, 9.7461e-01, 9.7168e-01,\n",
       "            9.7119e-01, 9.7070e-01, 9.6924e-01, 9.5898e-01, 9.5850e-01,\n",
       "            9.5508e-01, 9.5459e-01, 9.5166e-01, 9.5020e-01, 9.4336e-01,\n",
       "            9.3750e-01, 9.3359e-01, 9.2871e-01, 9.2822e-01, 9.2725e-01,\n",
       "            9.2383e-01, 9.2334e-01, 9.2285e-01, 9.1211e-01, 9.0527e-01,\n",
       "            9.0430e-01, 8.8281e-01, 8.6963e-01, 8.5205e-01, 8.5156e-01,\n",
       "            8.4277e-01, 8.2617e-01, 8.2422e-01, 8.1396e-01, 8.1299e-01,\n",
       "            8.1055e-01, 8.0371e-01, 8.0078e-01, 7.7881e-01, 7.6221e-01,\n",
       "            7.5928e-01, 7.5146e-01, 7.3633e-01, 7.2266e-01, 7.1484e-01,\n",
       "            6.9531e-01, 6.7334e-01, 6.6455e-01, 6.4209e-01, 6.4111e-01,\n",
       "            6.2891e-01, 6.2061e-01, 6.1230e-01, 5.8350e-01, 5.7812e-01,\n",
       "            5.7227e-01, 5.6836e-01, 5.4932e-01, 5.0732e-01, 4.8535e-01,\n",
       "            4.5166e-01, 4.4727e-01, 4.4189e-01, 4.1553e-01, 3.8623e-01,\n",
       "            3.8159e-01, 3.6597e-01, 3.6157e-01, 3.4448e-01, 3.4277e-01,\n",
       "            3.2520e-01, 3.2104e-01, 3.1934e-01, 3.1543e-01, 3.1519e-01,\n",
       "            3.0371e-01, 2.8076e-01, 2.7319e-01, 2.4902e-01, 2.1863e-01,\n",
       "            1.8506e-01, 1.6724e-01, 1.5466e-01, 1.5381e-01, 1.4685e-01,\n",
       "            1.4099e-01, 1.3818e-01, 1.2274e-01, 1.1902e-01, 1.1102e-01,\n",
       "            1.0376e-01, 9.1858e-02, 8.8318e-02, 8.5571e-02, 8.1787e-02,\n",
       "            7.8796e-02, 5.6244e-02, 4.0375e-02, 2.8931e-02, 2.2079e-02,\n",
       "            2.2034e-02, 1.5488e-02, 1.3741e-02, 1.1642e-02, 1.0696e-02,\n",
       "            8.9493e-03, 7.5493e-03, 6.7177e-03, 5.5771e-03, 5.4054e-03,\n",
       "            4.5052e-03, 2.9240e-03, 2.4929e-03, 1.8892e-03, 1.8463e-03,\n",
       "            1.8177e-03, 1.5612e-03, 1.5430e-03, 1.4496e-03, 1.4381e-03,\n",
       "            1.3618e-03, 1.0481e-03, 9.0027e-04, 8.6594e-04, 8.3303e-04,\n",
       "            7.9775e-04, 7.7629e-04, 7.6723e-04, 7.3814e-04, 7.1812e-04,\n",
       "            7.1239e-04, 6.7186e-04, 6.4611e-04, 6.0225e-04, 5.9986e-04,\n",
       "            5.5075e-04, 5.0354e-04, 4.9925e-04, 4.4250e-04, 4.2391e-04,\n",
       "            4.1413e-04, 3.9816e-04, 3.6550e-04, 3.5143e-04, 3.1757e-04,\n",
       "            2.8014e-04, 2.7370e-04, 2.6941e-04, 2.5725e-04, 2.5511e-04,\n",
       "            2.3592e-04, 2.2697e-04, 1.9872e-04, 1.9109e-04, 1.8668e-04,\n",
       "            1.8525e-04, 1.7810e-04, 1.7536e-04, 1.5962e-04, 1.4997e-04,\n",
       "            1.2732e-04, 1.1867e-04, 1.1593e-04, 1.1063e-04, 1.0973e-04,\n",
       "            1.0806e-04, 1.0228e-04, 1.0073e-04, 8.8871e-05, 8.7500e-05,\n",
       "            7.6592e-05, 7.4863e-05, 7.1406e-05, 6.7115e-05, 6.6042e-05,\n",
       "            6.5565e-05, 5.9187e-05, 5.8293e-05, 5.7399e-05, 5.5194e-05,\n",
       "            5.1022e-05, 4.5419e-05, 4.5061e-05, 3.7909e-05, 3.6478e-05,\n",
       "            3.5942e-05, 3.5644e-05, 3.4273e-05, 3.1710e-05, 2.5272e-05,\n",
       "            2.2113e-05, 1.9550e-05, 1.7524e-05, 1.7345e-05, 1.6451e-05,\n",
       "            1.6332e-05, 1.5914e-05, 1.3292e-05, 1.1563e-05, 1.0073e-05,\n",
       "            8.9407e-06, 8.5235e-06, 7.0930e-06, 6.8545e-06, 6.6161e-06,\n",
       "            6.1989e-06, 1.8477e-06, 1.5497e-06, 1.4305e-06, 1.0133e-06,\n",
       "            8.3447e-07, 7.7486e-07, 6.5565e-07, 4.7684e-07], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.6846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15      , 0.15      ,\n",
       "            0.15833333, 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.41666666,\n",
       "            0.425     , 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.80833334, 0.8333333 , 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.9583333 , 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01538462, 0.03076923, 0.05384615, 0.07692308,\n",
       "            0.09230769, 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.15384616, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 1.0000e+00, 9.9951e-01, 9.9902e-01, 9.9854e-01,\n",
       "            9.9805e-01, 9.9756e-01, 9.9707e-01, 9.9658e-01, 9.9609e-01,\n",
       "            9.9561e-01, 9.9512e-01, 9.9414e-01, 9.9365e-01, 9.9268e-01,\n",
       "            9.8926e-01, 9.8682e-01, 9.8633e-01, 9.8486e-01, 9.8291e-01,\n",
       "            9.8193e-01, 9.8096e-01, 9.7998e-01, 9.7949e-01, 9.7803e-01,\n",
       "            9.7559e-01, 9.7412e-01, 9.7266e-01, 9.7119e-01, 9.6631e-01,\n",
       "            9.6436e-01, 9.5947e-01, 9.5703e-01, 9.5361e-01, 9.5264e-01,\n",
       "            9.4775e-01, 9.4678e-01, 9.3994e-01, 9.3604e-01, 9.3408e-01,\n",
       "            9.3164e-01, 9.3018e-01, 9.2676e-01, 9.2627e-01, 9.1406e-01,\n",
       "            8.9941e-01, 8.9453e-01, 8.7939e-01, 8.7793e-01, 8.6328e-01,\n",
       "            8.6035e-01, 8.5986e-01, 8.4912e-01, 8.4277e-01, 8.3545e-01,\n",
       "            8.3203e-01, 7.8760e-01, 7.7393e-01, 7.5928e-01, 7.4609e-01,\n",
       "            7.2803e-01, 7.1777e-01, 7.0215e-01, 6.9336e-01, 6.7871e-01,\n",
       "            6.6846e-01, 6.5088e-01, 6.4307e-01, 6.4160e-01, 6.3818e-01,\n",
       "            6.1670e-01, 6.0840e-01, 5.9033e-01, 5.8984e-01, 5.8398e-01,\n",
       "            5.6787e-01, 5.3320e-01, 4.8267e-01, 4.7290e-01, 4.6167e-01,\n",
       "            4.5728e-01, 4.5581e-01, 4.4043e-01, 3.9600e-01, 3.6719e-01,\n",
       "            3.3057e-01, 3.2349e-01, 3.2056e-01, 3.1885e-01, 3.1519e-01,\n",
       "            3.1372e-01, 3.0322e-01, 3.0127e-01, 2.9199e-01, 2.7148e-01,\n",
       "            2.4170e-01, 2.3682e-01, 2.3389e-01, 2.2473e-01, 1.7065e-01,\n",
       "            1.5381e-01, 1.4868e-01, 1.4087e-01, 1.3940e-01, 1.2524e-01,\n",
       "            1.1920e-01, 1.1816e-01, 1.1755e-01, 9.1370e-02, 8.8013e-02,\n",
       "            8.0933e-02, 7.9468e-02, 6.3965e-02, 6.3599e-02, 5.2917e-02,\n",
       "            4.7791e-02, 2.9083e-02, 2.0294e-02, 1.9501e-02, 1.8875e-02,\n",
       "            1.5427e-02, 8.0643e-03, 7.0648e-03, 6.7711e-03, 6.0043e-03,\n",
       "            5.3635e-03, 4.7188e-03, 4.1504e-03, 4.1161e-03, 2.8229e-03,\n",
       "            2.0828e-03, 1.4668e-03, 1.4267e-03, 1.2741e-03, 1.2302e-03,\n",
       "            1.0729e-03, 9.9277e-04, 9.7752e-04, 8.8978e-04, 8.0395e-04,\n",
       "            7.9155e-04, 7.2098e-04, 5.7268e-04, 4.9925e-04, 4.4417e-04,\n",
       "            4.4084e-04, 4.2892e-04, 4.1080e-04, 4.0936e-04, 3.9983e-04,\n",
       "            3.9053e-04, 3.6550e-04, 3.5429e-04, 3.4738e-04, 3.4595e-04,\n",
       "            3.1996e-04, 2.9588e-04, 2.6131e-04, 2.5725e-04, 2.4152e-04,\n",
       "            2.2876e-04, 2.0027e-04, 1.8811e-04, 1.7810e-04, 1.5473e-04,\n",
       "            1.3661e-04, 1.3340e-04, 1.2827e-04, 1.1325e-04, 1.1146e-04,\n",
       "            1.0228e-04, 9.9182e-05, 9.6858e-05, 9.5367e-05, 8.6844e-05,\n",
       "            8.5473e-05, 7.6592e-05, 7.3135e-05, 6.6042e-05, 6.5565e-05,\n",
       "            6.0618e-05, 6.0141e-05, 5.6922e-05, 5.4359e-05, 5.2691e-05,\n",
       "            4.7922e-05, 4.0710e-05, 3.8505e-05, 3.7909e-05, 3.7074e-05,\n",
       "            3.6478e-05, 3.5346e-05, 3.1173e-05, 3.0935e-05, 3.0458e-05,\n",
       "            2.7776e-05, 2.7299e-05, 2.3544e-05, 2.3365e-05, 1.9848e-05,\n",
       "            1.9372e-05, 1.8775e-05, 1.7524e-05, 1.7226e-05, 1.3709e-05,\n",
       "            1.3292e-05, 1.0848e-05, 9.0003e-06, 7.7486e-06, 6.6161e-06,\n",
       "            5.8413e-06, 5.7220e-06, 4.7684e-06, 4.4107e-06, 3.8743e-06,\n",
       "            3.7551e-06, 3.3379e-06, 3.2187e-06, 2.7418e-06, 9.5367e-07,\n",
       "            6.5565e-07, 5.9605e-07, 3.5763e-07, 2.9802e-07, 2.3842e-07,\n",
       "            1.7881e-07], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.65384614, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.13333334, 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.29166666, 0.3       , 0.30833334, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.9583333 , 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.03846154, 0.06153846, 0.06923077,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13846155, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23846154,\n",
       "            0.24615385, 0.26153848, 0.26923078, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.8923077 ,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 1.0000e+00, 9.9951e-01, 9.9902e-01, 9.9854e-01,\n",
       "            9.9805e-01, 9.9707e-01, 9.9658e-01, 9.9609e-01, 9.9561e-01,\n",
       "            9.9512e-01, 9.9219e-01, 9.9121e-01, 9.8877e-01, 9.8633e-01,\n",
       "            9.8389e-01, 9.8242e-01, 9.8047e-01, 9.7949e-01, 9.7900e-01,\n",
       "            9.7803e-01, 9.7559e-01, 9.7168e-01, 9.6973e-01, 9.6631e-01,\n",
       "            9.6094e-01, 9.5654e-01, 9.5508e-01, 9.5264e-01, 9.5117e-01,\n",
       "            9.5020e-01, 9.4824e-01, 9.4531e-01, 9.2725e-01, 9.2139e-01,\n",
       "            9.2090e-01, 9.1943e-01, 9.1406e-01, 9.1113e-01, 9.0869e-01,\n",
       "            8.9795e-01, 8.9648e-01, 8.9551e-01, 8.7158e-01, 8.6084e-01,\n",
       "            8.5400e-01, 8.5352e-01, 8.4766e-01, 8.3496e-01, 8.3350e-01,\n",
       "            7.9053e-01, 7.8418e-01, 7.7979e-01, 7.7100e-01, 7.6807e-01,\n",
       "            7.6611e-01, 7.5586e-01, 7.5342e-01, 7.3145e-01, 7.2314e-01,\n",
       "            6.9238e-01, 6.8164e-01, 6.7139e-01, 6.5723e-01, 6.5137e-01,\n",
       "            6.1914e-01, 6.0400e-01, 6.0303e-01, 5.7080e-01, 5.6836e-01,\n",
       "            5.5811e-01, 5.5762e-01, 5.2295e-01, 5.0000e-01, 4.8462e-01,\n",
       "            4.8047e-01, 4.7437e-01, 4.2139e-01, 4.0649e-01, 4.0527e-01,\n",
       "            3.2715e-01, 3.2129e-01, 3.0249e-01, 2.9980e-01, 2.9492e-01,\n",
       "            2.9395e-01, 2.8247e-01, 2.7808e-01, 2.7539e-01, 2.7441e-01,\n",
       "            2.6367e-01, 2.6221e-01, 2.3975e-01, 2.1497e-01, 2.0557e-01,\n",
       "            2.0007e-01, 1.9739e-01, 1.8921e-01, 1.8433e-01, 1.2988e-01,\n",
       "            1.1200e-01, 9.7900e-02, 9.0088e-02, 8.7402e-02, 8.3130e-02,\n",
       "            7.0557e-02, 6.5979e-02, 6.4209e-02, 6.3232e-02, 6.2683e-02,\n",
       "            5.9540e-02, 4.9957e-02, 4.7333e-02, 3.9795e-02, 3.9642e-02,\n",
       "            2.9251e-02, 2.0599e-02, 1.4008e-02, 1.2337e-02, 1.2146e-02,\n",
       "            9.7122e-03, 5.4054e-03, 4.8485e-03, 4.4327e-03, 4.4174e-03,\n",
       "            3.1471e-03, 2.6417e-03, 2.4433e-03, 2.1915e-03, 1.9722e-03,\n",
       "            1.1692e-03, 1.0691e-03, 9.4748e-04, 9.3651e-04, 8.8978e-04,\n",
       "            8.0109e-04, 7.9775e-04, 6.8521e-04, 5.9080e-04, 4.8041e-04,\n",
       "            3.7122e-04, 3.6263e-04, 2.9826e-04, 2.5511e-04, 2.5320e-04,\n",
       "            2.4343e-04, 2.3234e-04, 2.1660e-04, 2.1148e-04, 2.0504e-04,\n",
       "            2.0182e-04, 2.0027e-04, 1.9562e-04, 1.9407e-04, 1.9264e-04,\n",
       "            1.7262e-04, 1.2434e-04, 1.2147e-04, 1.1772e-04, 1.1683e-04,\n",
       "            1.1146e-04, 1.1063e-04, 1.0890e-04, 9.9957e-05, 9.1732e-05,\n",
       "            8.8871e-05, 8.2195e-05, 7.6592e-05, 7.5996e-05, 7.1406e-05,\n",
       "            6.5029e-05, 5.6505e-05, 5.5194e-05, 5.4359e-05, 4.9114e-05,\n",
       "            4.8339e-05, 4.6492e-05, 4.3988e-05, 4.3631e-05, 4.0054e-05,\n",
       "            3.4273e-05, 3.3736e-05, 3.0935e-05, 2.9087e-05, 2.7955e-05,\n",
       "            2.6882e-05, 2.5272e-05, 2.4855e-05, 2.3544e-05, 2.3186e-05,\n",
       "            1.8477e-05, 1.7345e-05, 1.7226e-05, 1.6212e-05, 1.5795e-05,\n",
       "            1.5318e-05, 1.4484e-05, 1.4424e-05, 1.3947e-05, 1.2934e-05,\n",
       "            1.2636e-05, 1.2398e-05, 1.1861e-05, 9.0003e-06, 8.8215e-06,\n",
       "            8.6427e-06, 8.4043e-06, 8.2850e-06, 7.2718e-06, 5.6028e-06,\n",
       "            5.0664e-06, 3.8743e-06, 3.6359e-06, 3.5763e-06, 3.5167e-06,\n",
       "            3.4571e-06, 3.1590e-06, 2.6226e-06, 2.2054e-06, 1.8477e-06,\n",
       "            1.7285e-06, 1.6689e-06, 1.4901e-06, 1.3113e-06, 1.2517e-06,\n",
       "            1.1325e-06, 2.9802e-07, 2.3842e-07, 1.7881e-07, 1.1921e-07,\n",
       "            5.9605e-08], dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(1., dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.19402985, 0.20149253, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.26865673,\n",
       "            0.2835821 , 0.29850745, 0.29850745, 0.29850745, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.3432836 ,\n",
       "            0.35074627, 0.35074627, 0.35820895, 0.36567163, 0.38059703,\n",
       "            0.38059703, 0.38059703, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.3955224 , 0.40298507, 0.40298507, 0.40298507, 0.41044775,\n",
       "            0.41044775, 0.41791046, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.42537314, 0.42537314, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.47761193, 0.47761193, 0.47761193, 0.47761193,\n",
       "            0.48507464, 0.48507464, 0.48507464, 0.48507464, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.7089552 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8208955 , 0.82835823,\n",
       "            0.8507463 , 0.86567163, 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00862069, 0.00862069, 0.00862069, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.03448276, 0.04310345,\n",
       "            0.04310345, 0.05172414, 0.05172414, 0.05172414, 0.05172414,\n",
       "            0.05172414, 0.06034483, 0.06034483, 0.06034483, 0.06034483,\n",
       "            0.06896552, 0.0775862 , 0.0862069 , 0.0862069 , 0.0862069 ,\n",
       "            0.09482758, 0.09482758, 0.10344828, 0.11206897, 0.11206897,\n",
       "            0.12931034, 0.12931034, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.1724138 , 0.18103448, 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.28448275, 0.29310346,\n",
       "            0.31034482, 0.31034482, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.4051724 , 0.41379312, 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.46551725, 0.47413793, 0.49137932,\n",
       "            0.5086207 , 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.80172414, 0.8103448 ,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.88793105, 0.9051724 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.94827586, 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9243, 0.923 , 0.9194, 0.9165, 0.9087, 0.9062, 0.904 ,\n",
       "            0.898 , 0.8906, 0.888 , 0.8867, 0.8857, 0.884 , 0.883 , 0.8823,\n",
       "            0.881 , 0.8794, 0.878 , 0.8765, 0.876 , 0.8706, 0.867 , 0.8667,\n",
       "            0.865 , 0.8647, 0.864 , 0.863 , 0.861 , 0.8584, 0.858 , 0.8574,\n",
       "            0.856 , 0.8555, 0.8525, 0.8516, 0.849 , 0.8486, 0.8467, 0.846 ,\n",
       "            0.845 , 0.8447, 0.8433, 0.8413, 0.8384, 0.8354, 0.835 , 0.8345,\n",
       "            0.834 , 0.8296, 0.827 , 0.826 , 0.825 , 0.8247, 0.8237, 0.823 ,\n",
       "            0.821 , 0.818 , 0.817 , 0.8164, 0.8086, 0.808 , 0.806 , 0.803 ,\n",
       "            0.8022, 0.802 , 0.7974, 0.7964, 0.796 , 0.7886, 0.788 , 0.786 ,\n",
       "            0.785 , 0.783 , 0.782 , 0.7803, 0.7793, 0.7783, 0.7773, 0.777 ,\n",
       "            0.776 , 0.775 , 0.7744, 0.7734, 0.7695, 0.7676, 0.767 , 0.7666,\n",
       "            0.766 , 0.765 , 0.764 , 0.763 , 0.7607, 0.76  , 0.7593, 0.7554,\n",
       "            0.755 , 0.7544, 0.754 , 0.75  , 0.7485, 0.7476, 0.746 , 0.7456,\n",
       "            0.7397, 0.7363, 0.7344, 0.734 , 0.733 , 0.7314, 0.7295, 0.727 ,\n",
       "            0.724 , 0.7236, 0.7227, 0.7217, 0.7207, 0.7197, 0.7188, 0.715 ,\n",
       "            0.7124, 0.709 , 0.703 , 0.7026, 0.7007, 0.6987, 0.6953, 0.691 ,\n",
       "            0.69  , 0.689 , 0.688 , 0.685 , 0.684 , 0.6836, 0.6826, 0.679 ,\n",
       "            0.676 , 0.6714, 0.67  , 0.6694, 0.668 , 0.6646, 0.663 , 0.658 ,\n",
       "            0.6562, 0.6475, 0.6445, 0.642 , 0.6416, 0.6377, 0.632 , 0.6304,\n",
       "            0.625 , 0.6235, 0.621 , 0.614 , 0.613 , 0.6123, 0.609 , 0.606 ,\n",
       "            0.605 , 0.6035, 0.603 , 0.6025, 0.5957, 0.5923, 0.5874, 0.5845,\n",
       "            0.5806, 0.579 , 0.575 , 0.5747, 0.5713, 0.5693, 0.5654, 0.563 ,\n",
       "            0.562 , 0.561 , 0.5576, 0.556 , 0.5537, 0.5513, 0.5503, 0.5474,\n",
       "            0.547 , 0.5405, 0.54  , 0.538 , 0.5356, 0.533 , 0.532 , 0.5317,\n",
       "            0.5312, 0.5303, 0.526 , 0.521 , 0.52  , 0.5195, 0.514 , 0.512 ,\n",
       "            0.5117, 0.5107, 0.5103, 0.508 , 0.507 , 0.506 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9925373, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26865673, 0.2761194 , 0.29104477, 0.29850745, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.31343284, 0.3283582 , 0.33582088,\n",
       "            0.35074627, 0.35820895, 0.35820895, 0.35820895, 0.35820895,\n",
       "            0.36567163, 0.36567163, 0.37313432, 0.38059703, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.41044775, 0.41044775, 0.41044775, 0.41044775, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.43283582, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.43283582, 0.4402985 , 0.4402985 , 0.4402985 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.47761193, 0.47761193, 0.48507464, 0.48507464,\n",
       "            0.48507464, 0.48507464, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.619403  , 0.6268657 , 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.04310345,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06034483, 0.06034483,\n",
       "            0.06034483, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.0862069 , 0.10344828, 0.10344828, 0.10344828, 0.11206897,\n",
       "            0.11206897, 0.11206897, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25      , 0.25862068, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.3275862 , 0.33620688, 0.3448276 , 0.37068966,\n",
       "            0.37931034, 0.37931034, 0.38793105, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62931037, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6896552 , 0.69827586, 0.70689654, 0.73275864,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9137931 , 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9834, 0.983 , 0.982 , 0.98  , 0.977 , 0.976 , 0.975 ,\n",
       "            0.973 , 0.9697, 0.969 , 0.9688, 0.968 , 0.967 , 0.9663, 0.9653,\n",
       "            0.965 , 0.9644, 0.964 , 0.9634, 0.9614, 0.959 , 0.9585, 0.9575,\n",
       "            0.957 , 0.9565, 0.956 , 0.9556, 0.9546, 0.9536, 0.9526, 0.952 ,\n",
       "            0.9517, 0.951 , 0.9507, 0.949 , 0.9487, 0.948 , 0.9478, 0.947 ,\n",
       "            0.946 , 0.944 , 0.9434, 0.943 , 0.9424, 0.94  , 0.939 , 0.9385,\n",
       "            0.938 , 0.9375, 0.937 , 0.9365, 0.936 , 0.9336, 0.933 , 0.9307,\n",
       "            0.93  , 0.929 , 0.928 , 0.9263, 0.924 , 0.9233, 0.923 , 0.9214,\n",
       "            0.918 , 0.9165, 0.914 , 0.9106, 0.908 , 0.906 , 0.905 , 0.904 ,\n",
       "            0.9033, 0.903 , 0.9023, 0.902 , 0.9014, 0.901 , 0.9004, 0.897 ,\n",
       "            0.8965, 0.896 , 0.8955, 0.894 , 0.8906, 0.89  , 0.889 , 0.888 ,\n",
       "            0.8877, 0.8853, 0.8843, 0.8833, 0.883 , 0.8813, 0.881 , 0.879 ,\n",
       "            0.8784, 0.878 , 0.877 , 0.875 , 0.874 , 0.8716, 0.8687, 0.868 ,\n",
       "            0.8643, 0.8633, 0.8613, 0.859 , 0.8574, 0.8555, 0.8506, 0.85  ,\n",
       "            0.8496, 0.847 , 0.844 , 0.843 , 0.84  , 0.8374, 0.835 , 0.8325,\n",
       "            0.831 , 0.8286, 0.825 , 0.8237, 0.821 , 0.8184, 0.818 , 0.812 ,\n",
       "            0.809 , 0.8086, 0.8076, 0.8037, 0.803 , 0.8013, 0.798 , 0.7974,\n",
       "            0.796 , 0.7915, 0.7905, 0.79  , 0.7866, 0.782 , 0.779 , 0.775 ,\n",
       "            0.7627, 0.7583, 0.755 , 0.7476, 0.7456, 0.744 , 0.741 , 0.7334,\n",
       "            0.717 , 0.7144, 0.712 , 0.704 , 0.702 , 0.701 , 0.699 , 0.6934,\n",
       "            0.692 , 0.6836, 0.673 , 0.6685, 0.666 , 0.657 , 0.6553, 0.652 ,\n",
       "            0.6514, 0.642 , 0.637 , 0.6367, 0.6357, 0.629 , 0.6206, 0.6196,\n",
       "            0.617 , 0.6157, 0.6084, 0.602 , 0.5947, 0.592 , 0.5845, 0.58  ,\n",
       "            0.5786, 0.574 , 0.573 , 0.569 , 0.5684, 0.568 , 0.566 , 0.5615,\n",
       "            0.5605, 0.5596, 0.5576, 0.553 , 0.55  , 0.5425, 0.542 , 0.533 ,\n",
       "            0.52  , 0.519 , 0.517 , 0.5166, 0.515 , 0.5107, 0.5093, 0.5083,\n",
       "            0.4875], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.96268654, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.01492537, 0.02238806, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14925373, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.18656716, 0.20149253, 0.20149253, 0.20895523,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.32089552,\n",
       "            0.32089552, 0.3283582 , 0.3432836 , 0.35074627, 0.35074627,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3880597 , 0.3880597 , 0.3880597 ,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.41044775, 0.41044775, 0.41044775, 0.41044775, 0.41044775,\n",
       "            0.41044775, 0.41791046, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.41791046, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.03448276, 0.03448276,\n",
       "            0.04310345, 0.04310345, 0.05172414, 0.06034483, 0.06034483,\n",
       "            0.06896552, 0.06896552, 0.0775862 , 0.0862069 , 0.10344828,\n",
       "            0.11206897, 0.11206897, 0.11206897, 0.11206897, 0.12931034,\n",
       "            0.13793103, 0.13793103, 0.13793103, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.15517241, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.1724138 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.20689656, 0.20689656, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.2672414 , 0.27586207, 0.28448275, 0.30172414,\n",
       "            0.31034482, 0.31034482, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.94827586, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.983 , 0.9814, 0.98  , 0.977 , 0.976 , 0.975 , 0.973 ,\n",
       "            0.9717, 0.971 , 0.9697, 0.969 , 0.968 , 0.967 , 0.966 , 0.9653,\n",
       "            0.965 , 0.964 , 0.963 , 0.9614, 0.959 , 0.9585, 0.958 , 0.9575,\n",
       "            0.957 , 0.9565, 0.9556, 0.955 , 0.9536, 0.953 , 0.952 , 0.9517,\n",
       "            0.9507, 0.95  , 0.9497, 0.949 , 0.948 , 0.9478, 0.9473, 0.947 ,\n",
       "            0.9463, 0.945 , 0.9434, 0.943 , 0.942 , 0.9404, 0.9395, 0.9375,\n",
       "            0.937 , 0.9365, 0.9346, 0.934 , 0.9336, 0.933 , 0.932 , 0.9316,\n",
       "            0.931 , 0.9307, 0.9287, 0.927 , 0.9243, 0.922 , 0.9214, 0.921 ,\n",
       "            0.92  , 0.9194, 0.9185, 0.918 , 0.9165, 0.916 , 0.915 , 0.9146,\n",
       "            0.914 , 0.9136, 0.912 , 0.9116, 0.911 , 0.909 , 0.9087, 0.908 ,\n",
       "            0.9077, 0.906 , 0.9053, 0.904 , 0.9033, 0.903 , 0.902 , 0.9   ,\n",
       "            0.8994, 0.899 , 0.898 , 0.8965, 0.896 , 0.8936, 0.8926, 0.8916,\n",
       "            0.89  , 0.8896, 0.886 , 0.8857, 0.883 , 0.882 , 0.878 , 0.876 ,\n",
       "            0.8745, 0.872 , 0.8716, 0.871 , 0.869 , 0.8687, 0.868 , 0.8677,\n",
       "            0.867 , 0.8667, 0.8633, 0.8613, 0.8604, 0.855 , 0.8525, 0.8506,\n",
       "            0.849 , 0.848 , 0.844 , 0.842 , 0.839 , 0.8345, 0.833 , 0.8306,\n",
       "            0.8296, 0.826 , 0.825 , 0.8184, 0.8174, 0.817 , 0.8164, 0.8154,\n",
       "            0.815 , 0.8135, 0.8115, 0.8105, 0.7915, 0.782 , 0.7817, 0.776 ,\n",
       "            0.7744, 0.7695, 0.763 , 0.7607, 0.759 , 0.751 , 0.7466, 0.742 ,\n",
       "            0.7266, 0.726 , 0.725 , 0.7236, 0.723 , 0.7227, 0.717 , 0.712 ,\n",
       "            0.707 , 0.6934, 0.692 , 0.6865, 0.686 , 0.685 , 0.678 , 0.675 ,\n",
       "            0.671 , 0.6675, 0.6616, 0.655 , 0.6533, 0.653 , 0.6484, 0.644 ,\n",
       "            0.635 , 0.6333, 0.6323, 0.6304, 0.6113, 0.6084, 0.6074, 0.59  ,\n",
       "            0.5884, 0.5874, 0.5806, 0.5796, 0.57  , 0.5674, 0.565 , 0.564 ,\n",
       "            0.554 , 0.5537, 0.5503, 0.54  , 0.539 , 0.538 , 0.536 , 0.5176,\n",
       "            0.5054, 0.5024, 0.502 , 0.4954, 0.4836, 0.4807, 0.4766, 0.4417],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9402985, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.01492537, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.1119403 , 0.11940298, 0.12686567, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.14925373, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.18656716, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23134328,\n",
       "            0.23880596, 0.23880596, 0.26119402, 0.26119402, 0.26119402,\n",
       "            0.26865673, 0.26865673, 0.2761194 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.33582088, 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.35820895, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.3955224 , 0.3955224 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.41044775, 0.41044775,\n",
       "            0.41044775, 0.41044775, 0.41044775, 0.41044775, 0.41044775,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4402985 , 0.4402985 , 0.4402985 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00862069,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.04310345, 0.05172414,\n",
       "            0.05172414, 0.05172414, 0.06034483, 0.06896552, 0.06896552,\n",
       "            0.06896552, 0.0775862 , 0.0862069 , 0.10344828, 0.11206897,\n",
       "            0.11206897, 0.12068965, 0.12068965, 0.12931034, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.14655173, 0.15517241, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.1724138 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.19827586, 0.20689656, 0.22413793,\n",
       "            0.22413793, 0.23275863, 0.23275863, 0.23275863, 0.23275863,\n",
       "            0.23275863, 0.2413793 , 0.2413793 , 0.2413793 , 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.28448275, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.36206895, 0.36206895, 0.36206895, 0.37068966, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.41379312, 0.41379312,\n",
       "            0.43103448, 0.43965518, 0.45689654, 0.46551725, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.69827586, 0.70689654, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9727, 0.9707, 0.97  , 0.966 , 0.9653, 0.965 , 0.963 ,\n",
       "            0.962 , 0.9604, 0.96  , 0.9595, 0.959 , 0.9585, 0.955 , 0.9546,\n",
       "            0.954 , 0.9536, 0.953 , 0.9526, 0.952 , 0.9517, 0.951 , 0.9507,\n",
       "            0.9497, 0.9487, 0.9478, 0.9473, 0.947 , 0.9453, 0.944 , 0.9434,\n",
       "            0.9424, 0.942 , 0.9404, 0.94  , 0.9395, 0.939 , 0.9375, 0.9365,\n",
       "            0.9355, 0.935 , 0.934 , 0.933 , 0.9326, 0.932 , 0.9316, 0.931 ,\n",
       "            0.9307, 0.93  , 0.9297, 0.929 , 0.9287, 0.9277, 0.9272, 0.9263,\n",
       "            0.9253, 0.925 , 0.923 , 0.922 , 0.9214, 0.921 , 0.919 , 0.918 ,\n",
       "            0.917 , 0.9165, 0.916 , 0.915 , 0.914 , 0.9116, 0.9106, 0.91  ,\n",
       "            0.909 , 0.9087, 0.907 , 0.9062, 0.9053, 0.9043, 0.9033, 0.903 ,\n",
       "            0.9023, 0.901 , 0.9004, 0.9   , 0.899 , 0.8984, 0.8975, 0.8965,\n",
       "            0.8955, 0.894 , 0.8936, 0.8906, 0.89  , 0.889 , 0.888 , 0.8867,\n",
       "            0.8853, 0.882 , 0.879 , 0.878 , 0.8765, 0.8755, 0.875 , 0.8735,\n",
       "            0.8726, 0.872 , 0.8696, 0.8687, 0.868 , 0.862 , 0.861 , 0.8594,\n",
       "            0.8584, 0.856 , 0.854 , 0.8525, 0.851 , 0.848 , 0.847 , 0.8467,\n",
       "            0.846 , 0.8457, 0.845 , 0.835 , 0.833 , 0.8315, 0.824 , 0.8223,\n",
       "            0.8193, 0.815 , 0.8135, 0.8115, 0.8105, 0.809 , 0.8066, 0.795 ,\n",
       "            0.7944, 0.792 , 0.79  , 0.784 , 0.775 , 0.773 , 0.7646, 0.76  ,\n",
       "            0.7515, 0.747 , 0.7393, 0.7383, 0.729 , 0.7266, 0.7217, 0.7207,\n",
       "            0.7197, 0.715 , 0.7124, 0.711 , 0.709 , 0.7085, 0.6953, 0.6943,\n",
       "            0.686 , 0.6855, 0.6787, 0.672 , 0.6675, 0.662 , 0.6606, 0.6567,\n",
       "            0.6543, 0.646 , 0.6445, 0.636 , 0.626 , 0.6245, 0.6226, 0.621 ,\n",
       "            0.6187, 0.5996, 0.5977, 0.5923, 0.5776, 0.573 , 0.5728, 0.566 ,\n",
       "            0.5654, 0.565 , 0.5645, 0.5493, 0.545 , 0.541 , 0.5312, 0.5283,\n",
       "            0.521 , 0.517 , 0.5117, 0.51  , 0.5054, 0.504 , 0.4834, 0.4775,\n",
       "            0.4668, 0.4573, 0.441 , 0.436 , 0.4287, 0.381 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8880597, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.06716418, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.08208955, 0.09701493,\n",
       "            0.1119403 , 0.12686567, 0.14925373, 0.14925373, 0.14925373,\n",
       "            0.14925373, 0.1641791 , 0.1716418 , 0.1716418 , 0.17910448,\n",
       "            0.19402985, 0.19402985, 0.20149253, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.24626866, 0.24626866, 0.26865673, 0.26865673,\n",
       "            0.29104477, 0.30597016, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.32089552, 0.3283582 , 0.3283582 , 0.3283582 , 0.3283582 ,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 , 0.35074627,\n",
       "            0.36567163, 0.37313432, 0.37313432, 0.37313432, 0.3880597 ,\n",
       "            0.3880597 , 0.3880597 , 0.3880597 , 0.3880597 , 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41044775, 0.41044775,\n",
       "            0.41044775, 0.41044775, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.41791046, 0.42537314,\n",
       "            0.42537314, 0.43283582, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.48507464, 0.5       , 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06896552, 0.0775862 , 0.0775862 , 0.0862069 ,\n",
       "            0.0862069 , 0.09482758, 0.11206897, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.18103448, 0.18103448,\n",
       "            0.18965517, 0.18965517, 0.18965517, 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.29310346, 0.30172414, 0.31896552,\n",
       "            0.3275862 , 0.3275862 , 0.33620688, 0.3448276 , 0.36206895,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43103448, 0.43103448,\n",
       "            0.43103448, 0.43965518, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.4827586 , 0.49137932, 0.5       , 0.5       ,\n",
       "            0.5086207 , 0.5086207 , 0.51724136, 0.5344828 , 0.5603448 ,\n",
       "            0.5689655 , 0.5689655 , 0.5689655 , 0.57758623, 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.7155172 , 0.7241379 , 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.82758623, 0.82758623,\n",
       "            0.8362069 , 0.8362069 , 0.8448276 , 0.8534483 , 0.87068963,\n",
       "            0.87068963, 0.88793105, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9688, 0.9673, 0.964 , 0.9614, 0.961 , 0.956 , 0.953 ,\n",
       "            0.9526, 0.952 , 0.9507, 0.949 , 0.9473, 0.947 , 0.9463, 0.9453,\n",
       "            0.944 , 0.9424, 0.941 , 0.9404, 0.9385, 0.938 , 0.9365, 0.936 ,\n",
       "            0.9355, 0.935 , 0.934 , 0.933 , 0.9326, 0.932 , 0.9307, 0.9277,\n",
       "            0.9272, 0.927 , 0.9263, 0.9253, 0.925 , 0.924 , 0.9224, 0.921 ,\n",
       "            0.92  , 0.9175, 0.9165, 0.916 , 0.9155, 0.9136, 0.913 , 0.912 ,\n",
       "            0.9116, 0.911 , 0.91  , 0.9087, 0.9077, 0.9062, 0.9053, 0.904 ,\n",
       "            0.9033, 0.9014, 0.901 , 0.9004, 0.8994, 0.899 , 0.8975, 0.897 ,\n",
       "            0.8965, 0.896 , 0.8955, 0.895 , 0.8945, 0.894 , 0.8926, 0.8916,\n",
       "            0.891 , 0.89  , 0.8887, 0.888 , 0.8877, 0.887 , 0.886 , 0.8853,\n",
       "            0.8843, 0.884 , 0.883 , 0.882 , 0.88  , 0.878 , 0.8755, 0.874 ,\n",
       "            0.873 , 0.8726, 0.872 , 0.868 , 0.8643, 0.864 , 0.8633, 0.8623,\n",
       "            0.8574, 0.8564, 0.856 , 0.8555, 0.855 , 0.854 , 0.853 , 0.8525,\n",
       "            0.849 , 0.848 , 0.8457, 0.844 , 0.8438, 0.84  , 0.839 , 0.8364,\n",
       "            0.8354, 0.8247, 0.8223, 0.8184, 0.8145, 0.8125, 0.8096, 0.8076,\n",
       "            0.8047, 0.8013, 0.801 , 0.796 , 0.7886, 0.7827, 0.772 , 0.7715,\n",
       "            0.7686, 0.7656, 0.7593, 0.757 , 0.753 , 0.74  , 0.737 , 0.735 ,\n",
       "            0.7324, 0.7314, 0.731 , 0.7217, 0.719 , 0.717 , 0.7163, 0.714 ,\n",
       "            0.707 , 0.7   , 0.696 , 0.6904, 0.689 , 0.6797, 0.678 , 0.671 ,\n",
       "            0.668 , 0.665 , 0.659 , 0.656 , 0.655 , 0.6494, 0.6367, 0.636 ,\n",
       "            0.6357, 0.632 , 0.628 , 0.616 , 0.615 , 0.6133, 0.613 , 0.591 ,\n",
       "            0.588 , 0.582 , 0.568 , 0.5674, 0.567 , 0.5605, 0.559 , 0.5522,\n",
       "            0.551 , 0.5356, 0.533 , 0.5283, 0.519 , 0.5024, 0.498 , 0.4973,\n",
       "            0.4956, 0.4927, 0.4902, 0.4812, 0.477 , 0.469 , 0.458 , 0.4358,\n",
       "            0.4233, 0.4028, 0.397 , 0.3865, 0.3286], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8731343, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.05223881, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.08955224, 0.08955224, 0.09701493, 0.09701493,\n",
       "            0.09701493, 0.09701493, 0.09701493, 0.09701493, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.13432837, 0.14925373,\n",
       "            0.15671642, 0.15671642, 0.15671642, 0.15671642, 0.1716418 ,\n",
       "            0.1716418 , 0.17910448, 0.17910448, 0.18656716, 0.18656716,\n",
       "            0.20149253, 0.20149253, 0.20149253, 0.20895523, 0.20895523,\n",
       "            0.21641791, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.25373134, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29104477, 0.30597016, 0.31343284, 0.32089552, 0.32089552,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.35074627, 0.35820895, 0.35820895,\n",
       "            0.35820895, 0.35820895, 0.36567163, 0.36567163, 0.36567163,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3880597 ,\n",
       "            0.3880597 , 0.3880597 , 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41791046, 0.41791046, 0.42537314, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4552239 , 0.47014925, 0.47761193, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.30172414, 0.31896552, 0.33620688,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.37068966, 0.37068966,\n",
       "            0.38793105, 0.38793105, 0.39655173, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.45689654, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.4827586 , 0.5       , 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5344828 , 0.54310346, 0.55172414, 0.5689655 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.6034483 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.63793105,\n",
       "            0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.70689654, 0.7155172 ,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 , 0.7241379 ,\n",
       "            0.7241379 , 0.7241379 , 0.73275864, 0.73275864, 0.73275864,\n",
       "            0.7413793 , 0.7413793 , 0.7413793 , 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.9051724 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.976 , 0.9736, 0.9683, 0.968 , 0.9663, 0.9624, 0.961 ,\n",
       "            0.959 , 0.9585, 0.958 , 0.957 , 0.954 , 0.953 , 0.951 , 0.949 ,\n",
       "            0.948 , 0.9478, 0.947 , 0.9463, 0.945 , 0.9404, 0.94  , 0.9385,\n",
       "            0.938 , 0.934 , 0.9336, 0.9326, 0.931 , 0.9307, 0.93  , 0.9297,\n",
       "            0.9287, 0.9243, 0.9233, 0.9194, 0.919 , 0.9185, 0.918 , 0.9175,\n",
       "            0.916 , 0.9155, 0.915 , 0.9146, 0.912 , 0.911 , 0.9106, 0.91  ,\n",
       "            0.9097, 0.909 , 0.908 , 0.9053, 0.9043, 0.9014, 0.9004, 0.899 ,\n",
       "            0.897 , 0.896 , 0.8955, 0.895 , 0.894 , 0.8936, 0.8926, 0.8916,\n",
       "            0.891 , 0.89  , 0.889 , 0.888 , 0.887 , 0.8867, 0.886 , 0.883 ,\n",
       "            0.881 , 0.88  , 0.8794, 0.879 , 0.8784, 0.8774, 0.877 , 0.8765,\n",
       "            0.8755, 0.8745, 0.874 , 0.8735, 0.8726, 0.872 , 0.871 , 0.8706,\n",
       "            0.869 , 0.8677, 0.8667, 0.865 , 0.8623, 0.8613, 0.861 , 0.8604,\n",
       "            0.8594, 0.859 , 0.8584, 0.857 , 0.856 , 0.8555, 0.855 , 0.8525,\n",
       "            0.8516, 0.8496, 0.849 , 0.8477, 0.8467, 0.845 , 0.844 , 0.8433,\n",
       "            0.843 , 0.8423, 0.842 , 0.8413, 0.8403, 0.84  , 0.8384, 0.838 ,\n",
       "            0.8374, 0.835 , 0.833 , 0.829 , 0.8267, 0.8223, 0.822 , 0.817 ,\n",
       "            0.8135, 0.8105, 0.804 , 0.8022, 0.799 , 0.796 , 0.795 , 0.794 ,\n",
       "            0.7935, 0.793 , 0.7925, 0.7896, 0.7866, 0.7793, 0.7686, 0.759 ,\n",
       "            0.7583, 0.7485, 0.7446, 0.744 , 0.7437, 0.7373, 0.7354, 0.7256,\n",
       "            0.723 , 0.7188, 0.7173, 0.7144, 0.7104, 0.702 , 0.701 , 0.6978,\n",
       "            0.691 , 0.686 , 0.677 , 0.6724, 0.6685, 0.6675, 0.6616, 0.6597,\n",
       "            0.652 , 0.647 , 0.644 , 0.6377, 0.6367, 0.622 , 0.6206, 0.62  ,\n",
       "            0.6133, 0.6006, 0.599 , 0.5986, 0.5767, 0.568 , 0.566 , 0.564 ,\n",
       "            0.5474, 0.5396, 0.5366, 0.5312, 0.5293, 0.529 , 0.508 , 0.5015,\n",
       "            0.4897, 0.488 , 0.473 , 0.4683, 0.4617, 0.4614, 0.4558, 0.4485,\n",
       "            0.4448, 0.4397, 0.4326, 0.3982, 0.383 , 0.3577, 0.351 , 0.3381,\n",
       "            0.2722], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8432836, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.06716418, 0.06716418, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.08955224, 0.08955224, 0.09701493, 0.09701493,\n",
       "            0.09701493, 0.09701493, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.18656716, 0.18656716,\n",
       "            0.19402985, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.3880597 , 0.3880597 , 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.12068965, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.4827586 , 0.49137932, 0.49137932,\n",
       "            0.5       , 0.5344828 , 0.54310346, 0.5603448 , 0.5689655 ,\n",
       "            0.5689655 , 0.57758623, 0.57758623, 0.5862069 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.67241377, 0.67241377, 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.75      ,\n",
       "            0.7586207 , 0.7586207 , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.8189655 , 0.8362069 , 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.8448276 , 0.8448276 , 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9814, 0.9766, 0.9727, 0.9697, 0.9663, 0.9653, 0.965 ,\n",
       "            0.964 , 0.962 , 0.96  , 0.9595, 0.956 , 0.954 , 0.952 , 0.951 ,\n",
       "            0.9487, 0.948 , 0.9478, 0.9463, 0.9414, 0.941 , 0.9395, 0.937 ,\n",
       "            0.936 , 0.9346, 0.934 , 0.9336, 0.933 , 0.9326, 0.931 , 0.93  ,\n",
       "            0.927 , 0.9243, 0.924 , 0.9224, 0.922 , 0.9214, 0.92  , 0.9194,\n",
       "            0.9185, 0.9165, 0.9146, 0.914 , 0.9136, 0.911 , 0.9097, 0.9062,\n",
       "            0.903 , 0.9014, 0.9004, 0.899 , 0.8984, 0.898 , 0.897 , 0.8955,\n",
       "            0.8906, 0.8896, 0.889 , 0.8867, 0.8857, 0.8853, 0.8843, 0.8833,\n",
       "            0.883 , 0.882 , 0.8794, 0.8774, 0.873 , 0.87  , 0.8677, 0.867 ,\n",
       "            0.8667, 0.8613, 0.86  , 0.859 , 0.858 , 0.857 , 0.8564, 0.856 ,\n",
       "            0.855 , 0.8525, 0.8516, 0.848 , 0.847 , 0.844 , 0.842 , 0.8413,\n",
       "            0.8384, 0.838 , 0.837 , 0.8364, 0.836 , 0.8354, 0.8335, 0.8315,\n",
       "            0.831 , 0.83  , 0.8296, 0.829 , 0.828 , 0.8267, 0.8257, 0.8237,\n",
       "            0.8228, 0.8223, 0.821 , 0.817 , 0.816 , 0.8154, 0.8145, 0.8125,\n",
       "            0.812 , 0.8105, 0.81  , 0.8096, 0.8076, 0.807 , 0.805 , 0.8047,\n",
       "            0.8022, 0.7993, 0.797 , 0.7964, 0.793 , 0.7915, 0.789 , 0.7886,\n",
       "            0.7866, 0.784 , 0.7817, 0.781 , 0.78  , 0.7793, 0.778 , 0.776 ,\n",
       "            0.772 , 0.7676, 0.7656, 0.7617, 0.7603, 0.76  , 0.758 , 0.757 ,\n",
       "            0.754 , 0.742 , 0.741 , 0.74  , 0.736 , 0.7344, 0.7334, 0.731 ,\n",
       "            0.7246, 0.7183, 0.7163, 0.7144, 0.7056, 0.703 , 0.701 , 0.697 ,\n",
       "            0.695 , 0.6943, 0.682 , 0.6816, 0.6807, 0.6772, 0.6714, 0.6484,\n",
       "            0.6475, 0.6455, 0.637 , 0.6367, 0.6357, 0.6323, 0.6284, 0.628 ,\n",
       "            0.623 , 0.613 , 0.595 , 0.593 , 0.5913, 0.588 , 0.5737, 0.5713,\n",
       "            0.5586, 0.5557, 0.552 , 0.5386, 0.5376, 0.5225, 0.516 , 0.5063,\n",
       "            0.505 , 0.4956, 0.4946, 0.476 , 0.4695, 0.4626, 0.4521, 0.4434,\n",
       "            0.4268, 0.424 , 0.4233, 0.42  , 0.4163, 0.4028, 0.4006, 0.3953,\n",
       "            0.3591, 0.341 , 0.3096, 0.3025, 0.2888, 0.2197], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8134328, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05970149, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.18656716, 0.20149253, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35820895, 0.37313432,\n",
       "            0.38059703, 0.38059703, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.40298507, 0.41044775, 0.41791046, 0.43283582,\n",
       "            0.4402985 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.11206897, 0.12931034, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.20689656,\n",
       "            0.21551724, 0.23275863, 0.2413793 , 0.25      , 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.55172414, 0.57758623, 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6810345 , 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.79310346, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.87931037, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.985 , 0.979 , 0.9756, 0.971 , 0.969 , 0.9663, 0.9653,\n",
       "            0.9634, 0.963 , 0.961 , 0.9585, 0.957 , 0.9565, 0.9517, 0.9473,\n",
       "            0.947 , 0.9453, 0.944 , 0.942 , 0.9404, 0.9395, 0.939 , 0.9385,\n",
       "            0.9375, 0.9365, 0.935 , 0.928 , 0.9272, 0.927 , 0.926 , 0.9253,\n",
       "            0.925 , 0.923 , 0.9224, 0.9214, 0.921 , 0.9194, 0.9165, 0.9155,\n",
       "            0.915 , 0.9146, 0.9126, 0.91  , 0.909 , 0.9087, 0.9043, 0.899 ,\n",
       "            0.8984, 0.898 , 0.8936, 0.8926, 0.8916, 0.8906, 0.8887, 0.8877,\n",
       "            0.887 , 0.8857, 0.885 , 0.8833, 0.8813, 0.879 , 0.8765, 0.8745,\n",
       "            0.8706, 0.87  , 0.867 , 0.8643, 0.8613, 0.861 , 0.86  , 0.8574,\n",
       "            0.857 , 0.8555, 0.854 , 0.853 , 0.851 , 0.847 , 0.846 , 0.8447,\n",
       "            0.842 , 0.8394, 0.839 , 0.8384, 0.838 , 0.837 , 0.8364, 0.836 ,\n",
       "            0.8345, 0.8335, 0.833 , 0.831 , 0.823 , 0.8223, 0.82  , 0.817 ,\n",
       "            0.813 , 0.8105, 0.8047, 0.802 , 0.797 , 0.7964, 0.7954, 0.7915,\n",
       "            0.79  , 0.7886, 0.788 , 0.7866, 0.7827, 0.7817, 0.7812, 0.7793,\n",
       "            0.7773, 0.7754, 0.7725, 0.7715, 0.7705, 0.7695, 0.7686, 0.767 ,\n",
       "            0.766 , 0.7637, 0.762 , 0.7617, 0.7607, 0.76  , 0.759 , 0.7563,\n",
       "            0.7534, 0.752 , 0.75  , 0.7495, 0.7485, 0.7446, 0.7417, 0.737 ,\n",
       "            0.736 , 0.7354, 0.733 , 0.7324, 0.7295, 0.7275, 0.7246, 0.723 ,\n",
       "            0.7227, 0.719 , 0.7188, 0.717 , 0.716 , 0.715 , 0.7114, 0.707 ,\n",
       "            0.7065, 0.7056, 0.698 , 0.695 , 0.689 , 0.6875, 0.6836, 0.6826,\n",
       "            0.6807, 0.6797, 0.678 , 0.677 , 0.6714, 0.669 , 0.6655, 0.665 ,\n",
       "            0.6562, 0.639 , 0.636 , 0.634 , 0.622 , 0.6187, 0.617 , 0.614 ,\n",
       "            0.612 , 0.6074, 0.6055, 0.605 , 0.6035, 0.601 , 0.5923, 0.5664,\n",
       "            0.5645, 0.564 , 0.5576, 0.5513, 0.5493, 0.549 , 0.5474, 0.542 ,\n",
       "            0.541 , 0.5273, 0.512 , 0.5024, 0.4993, 0.4824, 0.4692, 0.4653,\n",
       "            0.461 , 0.4565, 0.4553, 0.4265, 0.4192, 0.413 , 0.408 , 0.398 ,\n",
       "            0.388 , 0.3809, 0.373 , 0.372 , 0.3684, 0.3538, 0.3462, 0.3198,\n",
       "            0.3005, 0.263 , 0.2556, 0.2411, 0.1729], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.80597013, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.08955224, 0.08955224,\n",
       "            0.09701493, 0.09701493, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.12686567, 0.12686567, 0.13432837, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26865673,\n",
       "            0.2761194 , 0.2761194 , 0.29850745, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.37313432, 0.38059703, 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.12068965, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.23275863, 0.25      ,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.4051724 ,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.988 , 0.982 , 0.979 , 0.974 , 0.9736, 0.973 , 0.9683,\n",
       "            0.967 , 0.966 , 0.9653, 0.9634, 0.9624, 0.9614, 0.959 , 0.9546,\n",
       "            0.949 , 0.9478, 0.9473, 0.947 , 0.946 , 0.9453, 0.9443, 0.944 ,\n",
       "            0.943 , 0.942 , 0.941 , 0.939 , 0.935 , 0.933 , 0.932 , 0.9297,\n",
       "            0.9272, 0.9263, 0.925 , 0.924 , 0.922 , 0.9204, 0.9185, 0.918 ,\n",
       "            0.916 , 0.915 , 0.9146, 0.9126, 0.908 , 0.9043, 0.902 , 0.901 ,\n",
       "            0.899 , 0.897 , 0.895 , 0.893 , 0.8916, 0.8906, 0.8867, 0.886 ,\n",
       "            0.885 , 0.883 , 0.882 , 0.88  , 0.875 , 0.8726, 0.8716, 0.871 ,\n",
       "            0.8706, 0.87  , 0.868 , 0.8647, 0.8633, 0.862 , 0.8613, 0.849 ,\n",
       "            0.848 , 0.8438, 0.843 , 0.8423, 0.8335, 0.8325, 0.8286, 0.828 ,\n",
       "            0.827 , 0.8257, 0.8247, 0.8223, 0.8193, 0.816 , 0.8154, 0.813 ,\n",
       "            0.8105, 0.81  , 0.807 , 0.8057, 0.803 , 0.8022, 0.8   , 0.799 ,\n",
       "            0.7974, 0.794 , 0.7915, 0.791 , 0.7866, 0.7793, 0.7754, 0.7715,\n",
       "            0.7656, 0.7646, 0.763 , 0.762 , 0.75  , 0.748 , 0.747 , 0.7466,\n",
       "            0.7446, 0.7407, 0.7393, 0.735 , 0.73  , 0.7295, 0.7256, 0.724 ,\n",
       "            0.7227, 0.7207, 0.714 , 0.7104, 0.71  , 0.7085, 0.705 , 0.703 ,\n",
       "            0.7026, 0.702 , 0.701 , 0.698 , 0.697 , 0.695 , 0.6934, 0.6875,\n",
       "            0.687 , 0.686 , 0.6816, 0.68  , 0.678 , 0.6763, 0.676 , 0.6753,\n",
       "            0.674 , 0.673 , 0.6724, 0.672 , 0.67  , 0.669 , 0.6675, 0.667 ,\n",
       "            0.666 , 0.6606, 0.66  , 0.652 , 0.6504, 0.65  , 0.6484, 0.646 ,\n",
       "            0.6455, 0.642 , 0.638 , 0.637 , 0.6367, 0.636 , 0.632 , 0.63  ,\n",
       "            0.6255, 0.621 , 0.617 , 0.6123, 0.6035, 0.599 , 0.5986, 0.5933,\n",
       "            0.5923, 0.588 , 0.5864, 0.5845, 0.5806, 0.578 , 0.577 , 0.5757,\n",
       "            0.5493, 0.544 , 0.5396, 0.539 , 0.537 , 0.528 , 0.5273, 0.5254,\n",
       "            0.5107, 0.5103, 0.5083, 0.508 , 0.469 , 0.4631, 0.4526, 0.4512,\n",
       "            0.4321, 0.4277, 0.4177, 0.4167, 0.3882, 0.3865, 0.381 , 0.3792,\n",
       "            0.3672, 0.3574, 0.3489, 0.3386, 0.3298, 0.326 , 0.3115, 0.3022,\n",
       "            0.2886, 0.267 , 0.2235, 0.2163, 0.2015, 0.1361], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7761194, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.08955224, 0.08955224, 0.09701493, 0.09701493, 0.10447761,\n",
       "            0.10447761, 0.10447761, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.20895523, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26865673, 0.2761194 , 0.2835821 , 0.29850745,\n",
       "            0.30597016, 0.32089552, 0.3283582 , 0.3283582 , 0.33582088,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.09482758,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.21551724, 0.23275863, 0.25      , 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.36206895, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.43103448,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5948276 , 0.6034483 , 0.62931037, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.7586207 , 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.8103448 , 0.8103448 , 0.8189655 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.991  , 0.986  , 0.9834 , 0.9795 , 0.9775 , 0.9736 ,\n",
       "            0.971  , 0.9697 , 0.969  , 0.9683 , 0.968  , 0.9673 , 0.967  ,\n",
       "            0.9624 , 0.9585 , 0.9556 , 0.9536 , 0.953  , 0.9526 , 0.9517 ,\n",
       "            0.951  , 0.9507 , 0.9497 , 0.949  , 0.9473 , 0.947  , 0.9414 ,\n",
       "            0.941  , 0.9404 , 0.9385 , 0.9346 , 0.9336 , 0.93   , 0.9272 ,\n",
       "            0.9263 , 0.9253 , 0.924  , 0.9224 , 0.92   , 0.918  , 0.9165 ,\n",
       "            0.9146 , 0.9062 , 0.906  , 0.9053 , 0.904  , 0.9033 , 0.901  ,\n",
       "            0.8994 , 0.897  , 0.8965 , 0.895  , 0.8945 , 0.893  , 0.8857 ,\n",
       "            0.8853 , 0.8833 , 0.878  , 0.875  , 0.8726 , 0.872  , 0.8716 ,\n",
       "            0.871  , 0.869  , 0.868  , 0.863  , 0.8613 , 0.8525 , 0.852  ,\n",
       "            0.8486 , 0.8374 , 0.835  , 0.8345 , 0.828  , 0.819  , 0.8164 ,\n",
       "            0.8096 , 0.8086 , 0.806  , 0.8047 , 0.8003 , 0.8    , 0.799  ,\n",
       "            0.7983 , 0.7964 , 0.796  , 0.791  , 0.7896 , 0.788  , 0.785  ,\n",
       "            0.7837 , 0.7705 , 0.7617 , 0.7603 , 0.7593 , 0.7534 , 0.751  ,\n",
       "            0.746  , 0.738  , 0.7344 , 0.7334 , 0.722  , 0.7207 , 0.7183 ,\n",
       "            0.718  , 0.7104 , 0.709  , 0.7085 , 0.7065 , 0.706  , 0.702  ,\n",
       "            0.7017 , 0.7007 , 0.6934 , 0.69   , 0.689  , 0.6885 , 0.6865 ,\n",
       "            0.682  , 0.6797 , 0.6777 , 0.6743 , 0.672  , 0.669  , 0.6675 ,\n",
       "            0.6646 , 0.664  , 0.6616 , 0.659  , 0.6587 , 0.658  , 0.6514 ,\n",
       "            0.6494 , 0.645  , 0.6436 , 0.642  , 0.641  , 0.6387 , 0.6357 ,\n",
       "            0.6353 , 0.632  , 0.6304 , 0.625  , 0.6245 , 0.6235 , 0.6226 ,\n",
       "            0.622  , 0.6206 , 0.6196 , 0.6187 , 0.618  , 0.617  , 0.613  ,\n",
       "            0.612  , 0.6113 , 0.61   , 0.607  , 0.604  , 0.5996 , 0.5933 ,\n",
       "            0.5903 , 0.59   , 0.5894 , 0.588  , 0.587  , 0.585  , 0.5815 ,\n",
       "            0.58   , 0.576  , 0.5747 , 0.5737 , 0.573  , 0.5723 , 0.57   ,\n",
       "            0.569  , 0.5674 , 0.564  , 0.5635 , 0.5615 , 0.56   , 0.559  ,\n",
       "            0.554  , 0.541  , 0.535  , 0.517  , 0.513  , 0.51   , 0.505  ,\n",
       "            0.5015 , 0.4983 , 0.4912 , 0.4832 , 0.4824 , 0.4385 , 0.4358 ,\n",
       "            0.4324 , 0.4236 , 0.3967 , 0.3943 , 0.3818 , 0.381  , 0.3606 ,\n",
       "            0.3604 , 0.3494 , 0.3418 , 0.3306 , 0.3276 , 0.3235 , 0.301  ,\n",
       "            0.292  , 0.2886 , 0.2732 , 0.2634 , 0.2573 , 0.2355 , 0.19   ,\n",
       "            0.1821 , 0.1666 , 0.10706], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.73134327, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.08955224, 0.08955224, 0.09701493,\n",
       "            0.09701493, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1641791 , 0.1716418 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20149253, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.49253732, 0.5       , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5597015 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.6791045 , 0.6865672 , 0.70149255,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.09482758,\n",
       "            0.10344828, 0.12931034, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18965517, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.2413793 , 0.25862068, 0.27586207, 0.28448275,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.88793105, 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9927, 0.988 , 0.986 , 0.9824, 0.9795, 0.976 , 0.9736,\n",
       "            0.973 , 0.9727, 0.972 , 0.9717, 0.9707, 0.9663, 0.9634, 0.9624,\n",
       "            0.958 , 0.9565, 0.955 , 0.9546, 0.954 , 0.9536, 0.953 , 0.9526,\n",
       "            0.951 , 0.9487, 0.9478, 0.947 , 0.945 , 0.9404, 0.9385, 0.9375,\n",
       "            0.9346, 0.933 , 0.932 , 0.9316, 0.931 , 0.9287, 0.9277, 0.925 ,\n",
       "            0.922 , 0.9214, 0.92  , 0.9194, 0.9155, 0.913 , 0.9077, 0.9067,\n",
       "            0.9023, 0.902 , 0.9004, 0.9   , 0.899 , 0.8955, 0.8936, 0.89  ,\n",
       "            0.889 , 0.8887, 0.886 , 0.883 , 0.881 , 0.8794, 0.879 , 0.8784,\n",
       "            0.8774, 0.877 , 0.8765, 0.876 , 0.8745, 0.869 , 0.858 , 0.856 ,\n",
       "            0.8555, 0.855 , 0.84  , 0.837 , 0.834 , 0.832 , 0.828 , 0.82  ,\n",
       "            0.812 , 0.811 , 0.806 , 0.805 , 0.799 , 0.7964, 0.796 , 0.795 ,\n",
       "            0.793 , 0.7905, 0.7837, 0.783 , 0.7827, 0.782 , 0.78  , 0.7715,\n",
       "            0.7676, 0.761 , 0.758 , 0.7446, 0.741 , 0.733 , 0.7305, 0.7285,\n",
       "            0.7266, 0.717 , 0.712 , 0.709 , 0.7065, 0.7017, 0.6987, 0.6943,\n",
       "            0.6875, 0.6836, 0.6787, 0.6772, 0.677 , 0.6763, 0.671 , 0.67  ,\n",
       "            0.6665, 0.6626, 0.6616, 0.661 , 0.6597, 0.6587, 0.6553, 0.6475,\n",
       "            0.6465, 0.6445, 0.6426, 0.6396, 0.638 , 0.6343, 0.6333, 0.63  ,\n",
       "            0.624 , 0.6235, 0.613 , 0.609 , 0.608 , 0.6064, 0.602 , 0.5986,\n",
       "            0.595 , 0.59  , 0.5854, 0.584 , 0.5815, 0.5757, 0.5737, 0.5728,\n",
       "            0.5684, 0.568 , 0.5654, 0.564 , 0.5635, 0.5576, 0.556 , 0.554 ,\n",
       "            0.5527, 0.5522, 0.549 , 0.548 , 0.5474, 0.5464, 0.543 , 0.5425,\n",
       "            0.542 , 0.5396, 0.538 , 0.537 , 0.5366, 0.536 , 0.5356, 0.5347,\n",
       "            0.534 , 0.5317, 0.531 , 0.529 , 0.528 , 0.5273, 0.526 , 0.5254,\n",
       "            0.5244, 0.5234, 0.523 , 0.522 , 0.4954, 0.4946, 0.4941, 0.4917,\n",
       "            0.4888, 0.4868, 0.476 , 0.4714, 0.4524, 0.4517, 0.428 , 0.4036,\n",
       "            0.3962, 0.3914, 0.361 , 0.3596, 0.3467, 0.346 , 0.3452, 0.3376,\n",
       "            0.313 , 0.3064, 0.3057, 0.302 , 0.294 , 0.2646, 0.2551, 0.252 ,\n",
       "            0.2382, 0.2314, 0.2269, 0.2094, 0.1631, 0.1555, 0.1384, 0.0851],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.53731346, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.05970149, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.1716418 , 0.17910448, 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.20895523, 0.21641791,\n",
       "            0.23134328, 0.23880596, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.09482758,\n",
       "            0.10344828, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.25      ,\n",
       "            0.2672414 , 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.38793105, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.79310346, 0.79310346, 0.79310346,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.994  , 0.9893 , 0.988  , 0.985  , 0.9844 , 0.9814 ,\n",
       "            0.9785 , 0.976  , 0.975  , 0.974  , 0.9736 , 0.973  , 0.9727 ,\n",
       "            0.9673 , 0.9653 , 0.965  , 0.9614 , 0.9595 , 0.958  , 0.9575 ,\n",
       "            0.957  , 0.9565 , 0.956  , 0.9556 , 0.955  , 0.9546 , 0.9526 ,\n",
       "            0.952  , 0.9517 , 0.9507 , 0.948  , 0.946  , 0.9414 , 0.941  ,\n",
       "            0.94   , 0.936  , 0.9346 , 0.932  , 0.9287 , 0.9243 , 0.9233 ,\n",
       "            0.923  , 0.922  , 0.9204 , 0.9185 , 0.9175 , 0.916  , 0.909  ,\n",
       "            0.9053 , 0.905  , 0.9033 , 0.901  , 0.9004 , 0.8965 , 0.8955 ,\n",
       "            0.894  , 0.89   , 0.8896 , 0.888  , 0.887  , 0.8867 , 0.8833 ,\n",
       "            0.8823 , 0.8813 , 0.881  , 0.8774 , 0.8765 , 0.8755 , 0.8735 ,\n",
       "            0.8667 , 0.8584 , 0.858  , 0.8574 , 0.841  , 0.8384 , 0.834  ,\n",
       "            0.8335 , 0.8228 , 0.8203 , 0.813  , 0.807  , 0.804  , 0.803  ,\n",
       "            0.8022 , 0.7993 , 0.7983 , 0.798  , 0.7905 , 0.7866 , 0.7837 ,\n",
       "            0.7827 , 0.7803 , 0.7705 , 0.7695 , 0.7666 , 0.7593 , 0.7544 ,\n",
       "            0.751  , 0.7383 , 0.736  , 0.73   , 0.714  , 0.7065 , 0.7046 ,\n",
       "            0.6978 , 0.697  , 0.6943 , 0.6934 , 0.686  , 0.682  , 0.6816 ,\n",
       "            0.6807 , 0.6772 , 0.6763 , 0.673  , 0.6616 , 0.6533 , 0.6494 ,\n",
       "            0.6475 , 0.647  , 0.6445 , 0.6436 , 0.64   , 0.637  , 0.6367 ,\n",
       "            0.6323 , 0.632  , 0.6313 , 0.625  , 0.6245 , 0.623  , 0.6226 ,\n",
       "            0.6206 , 0.619  , 0.6167 , 0.605  , 0.602  , 0.5894 , 0.586  ,\n",
       "            0.5815 , 0.576  , 0.5728 , 0.56   , 0.5596 , 0.5576 , 0.5527 ,\n",
       "            0.551  , 0.5493 , 0.5483 , 0.544  , 0.539  , 0.5386 , 0.534  ,\n",
       "            0.532  , 0.53   , 0.5283 , 0.527  , 0.5254 , 0.523  , 0.5225 ,\n",
       "            0.5205 , 0.5176 , 0.516  , 0.515  , 0.514  , 0.5127 , 0.511  ,\n",
       "            0.5103 , 0.507  , 0.505  , 0.503  , 0.5024 , 0.4968 , 0.4966 ,\n",
       "            0.496  , 0.4932 , 0.4924 , 0.491  , 0.4907 , 0.4883 , 0.484  ,\n",
       "            0.4824 , 0.4817 , 0.481  , 0.48   , 0.4792 , 0.479  , 0.4768 ,\n",
       "            0.4736 , 0.473  , 0.472  , 0.4717 , 0.4712 , 0.4702 , 0.468  ,\n",
       "            0.4673 , 0.466  , 0.4658 , 0.4648 , 0.4626 , 0.462  , 0.4617 ,\n",
       "            0.4587 , 0.4417 , 0.422  , 0.4214 , 0.4133 , 0.3694 , 0.3606 ,\n",
       "            0.3582 , 0.3281 , 0.3274 , 0.3262 , 0.313  , 0.3123 , 0.3118 ,\n",
       "            0.2854 , 0.279  , 0.2761 , 0.2717 , 0.2598 , 0.2307 , 0.2212 ,\n",
       "            0.2173 , 0.2063 , 0.206  , 0.194  , 0.1844 , 0.1389 , 0.1317 ,\n",
       "            0.11456, 0.06744], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.37313432, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.15671642, 0.1641791 , 0.1716418 , 0.1716418 ,\n",
       "            0.17910448, 0.17910448, 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20149253, 0.20895523, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35074627, 0.35820895,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.23275863,\n",
       "            0.25      , 0.2672414 , 0.27586207, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.76724136, 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.7844828 , 0.79310346, 0.79310346,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9946 , 0.99   , 0.9893 , 0.987  , 0.9863 , 0.9824 ,\n",
       "            0.98   , 0.9785 , 0.978  , 0.9775 , 0.977  , 0.9766 , 0.975  ,\n",
       "            0.974  , 0.9697 , 0.969  , 0.9673 , 0.9653 , 0.961  , 0.9604 ,\n",
       "            0.96   , 0.9595 , 0.959  , 0.9585 , 0.9575 , 0.957  , 0.9565 ,\n",
       "            0.956  , 0.9536 , 0.9517 , 0.9507 , 0.9478 , 0.9434 , 0.943  ,\n",
       "            0.941  , 0.9365 , 0.936  , 0.934  , 0.931  , 0.9263 , 0.926  ,\n",
       "            0.9233 , 0.9224 , 0.92   , 0.9185 , 0.916  , 0.909  , 0.906  ,\n",
       "            0.9053 , 0.905  , 0.9023 , 0.8984 , 0.896  , 0.895  , 0.894  ,\n",
       "            0.893  , 0.892  , 0.8906 , 0.8896 , 0.887  , 0.886  , 0.8853 ,\n",
       "            0.8823 , 0.88   , 0.879  , 0.878  , 0.8726 , 0.8716 , 0.871  ,\n",
       "            0.862  , 0.861  , 0.8594 , 0.859  , 0.8384 , 0.832  , 0.83   ,\n",
       "            0.826  , 0.814  , 0.81   , 0.809  , 0.8027 , 0.8003 , 0.7993 ,\n",
       "            0.7964 , 0.7954 , 0.786  , 0.784  , 0.783  , 0.779  , 0.7744 ,\n",
       "            0.772  , 0.771  , 0.7705 , 0.7627 , 0.758  , 0.753  , 0.7515 ,\n",
       "            0.745  , 0.7344 , 0.7217 , 0.7173 , 0.713  , 0.6934 , 0.691  ,\n",
       "            0.687  , 0.6807 , 0.678  , 0.673  , 0.6636 , 0.6626 , 0.658  ,\n",
       "            0.6567 , 0.649  , 0.6436 , 0.6367 , 0.6353 , 0.633  , 0.632  ,\n",
       "            0.6284 , 0.6265 , 0.6245 , 0.614  , 0.6113 , 0.6074 , 0.6055 ,\n",
       "            0.605  , 0.6035 , 0.6006 , 0.5977 , 0.5913 , 0.591  , 0.5767 ,\n",
       "            0.574  , 0.5737 , 0.573  , 0.5664 , 0.561  , 0.5586 , 0.552  ,\n",
       "            0.532  , 0.5283 , 0.5273 , 0.5244 , 0.522  , 0.5195 , 0.5117 ,\n",
       "            0.5103 , 0.508  , 0.503  , 0.5015 , 0.4978 , 0.4941 , 0.4912 ,\n",
       "            0.49   , 0.489  , 0.4883 , 0.4878 , 0.486  , 0.4768 , 0.4763 ,\n",
       "            0.475  , 0.4749 , 0.4731 , 0.4697 , 0.4675 , 0.4653 , 0.465  ,\n",
       "            0.4617 , 0.456  , 0.4558 , 0.4507 , 0.446  , 0.4458 , 0.4456 ,\n",
       "            0.444  , 0.443  , 0.4385 , 0.438  , 0.4377 , 0.4353 , 0.4346 ,\n",
       "            0.4338 , 0.4312 , 0.4307 , 0.429  , 0.428  , 0.4275 , 0.424  ,\n",
       "            0.4204 , 0.418  , 0.417  , 0.415  , 0.4128 , 0.4114 , 0.411  ,\n",
       "            0.4104 , 0.408  , 0.4067 , 0.4062 , 0.4043 , 0.4028 , 0.4019 ,\n",
       "            0.4014 , 0.3955 , 0.388  , 0.3845 , 0.3843 , 0.3818 , 0.3796 ,\n",
       "            0.329  , 0.3257 , 0.3147 , 0.3123 , 0.2893 , 0.288  , 0.2874 ,\n",
       "            0.2751 , 0.2747 , 0.267  , 0.2494 , 0.2422 , 0.2352 , 0.223  ,\n",
       "            0.1954 , 0.1859 , 0.1819 , 0.1741 , 0.1609 , 0.1608 , 0.1174 ,\n",
       "            0.1105 , 0.0932 , 0.05292], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.32089552, dtype=float32),\n",
       "    'tpr': array(0.9913793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.18656716,\n",
       "            0.19402985, 0.19402985, 0.20149253, 0.20895523, 0.20895523,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.6791045 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.09482758,\n",
       "            0.10344828, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25862068, 0.2672414 , 0.28448275, 0.29310346, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9956 , 0.9917 , 0.9907 , 0.9883 , 0.9844 , 0.982  ,\n",
       "            0.9814 , 0.981  , 0.98   , 0.9795 , 0.9775 , 0.977  , 0.9766 ,\n",
       "            0.9736 , 0.973  , 0.971  , 0.97   , 0.966  , 0.965  , 0.9634 ,\n",
       "            0.963  , 0.9624 , 0.962  , 0.9614 , 0.961  , 0.96   , 0.9595 ,\n",
       "            0.959  , 0.958  , 0.9565 , 0.9546 , 0.954  , 0.947  , 0.946  ,\n",
       "            0.9404 , 0.9395 , 0.939  , 0.9375 , 0.9365 , 0.9336 , 0.929  ,\n",
       "            0.928  , 0.927  , 0.9253 , 0.9233 , 0.923  , 0.92   , 0.911  ,\n",
       "            0.9106 , 0.9097 , 0.9087 , 0.908  , 0.9077 , 0.904  , 0.902  ,\n",
       "            0.9014 , 0.8994 , 0.8975 , 0.897  , 0.895  , 0.8945 , 0.8926 ,\n",
       "            0.8906 , 0.888  , 0.8877 , 0.8853 , 0.885  , 0.882  , 0.876  ,\n",
       "            0.8726 , 0.8696 , 0.868  , 0.8657 , 0.8613 , 0.861  , 0.844  ,\n",
       "            0.837  , 0.83   , 0.8223 , 0.8184 , 0.8105 , 0.8096 , 0.8    ,\n",
       "            0.7974 , 0.7964 , 0.7905 , 0.7827 , 0.7817 , 0.7803 , 0.78   ,\n",
       "            0.775  , 0.766  , 0.7656 , 0.7646 , 0.764  , 0.757  , 0.747  ,\n",
       "            0.742  , 0.7407 , 0.718  , 0.7056 , 0.7046 , 0.6963 , 0.6816 ,\n",
       "            0.681  , 0.68   , 0.6665 , 0.6646 , 0.6597 , 0.6562 , 0.6533 ,\n",
       "            0.647  , 0.64   , 0.6357 , 0.6343 , 0.632  , 0.617  , 0.6167 ,\n",
       "            0.614  , 0.6123 , 0.6113 , 0.604  , 0.6006 , 0.599  , 0.5986 ,\n",
       "            0.5967 , 0.593  , 0.5845 , 0.584  , 0.5796 , 0.5757 , 0.5684 ,\n",
       "            0.5566 , 0.553  , 0.55   , 0.5464 , 0.5444 , 0.5376 , 0.5293 ,\n",
       "            0.523  , 0.522  , 0.5117 , 0.511  , 0.5015 , 0.4978 , 0.4946 ,\n",
       "            0.482  , 0.4797 , 0.478  , 0.4768 , 0.4763 , 0.4722 , 0.468  ,\n",
       "            0.4678 , 0.4653 , 0.4636 , 0.4614 , 0.456  , 0.4517 , 0.449  ,\n",
       "            0.4478 , 0.443  , 0.44   , 0.437  , 0.4368 , 0.436  , 0.429  ,\n",
       "            0.4272 , 0.4258 , 0.4229 , 0.422  , 0.4219 , 0.4175 , 0.4153 ,\n",
       "            0.4148 , 0.4146 , 0.4092 , 0.4075 , 0.403  , 0.3977 , 0.3918 ,\n",
       "            0.3916 , 0.3896 , 0.3892 , 0.3884 , 0.3857 , 0.376  , 0.3752 ,\n",
       "            0.374  , 0.3735 , 0.3726 , 0.3706 , 0.37   , 0.3665 , 0.3635 ,\n",
       "            0.362  , 0.3613 , 0.3574 , 0.3555 , 0.3538 , 0.3533 , 0.3516 ,\n",
       "            0.3464 , 0.3354 , 0.327  , 0.3228 , 0.297  , 0.2961 , 0.2957 ,\n",
       "            0.2793 , 0.2673 , 0.2583 , 0.256  , 0.249  , 0.2449 , 0.2437 ,\n",
       "            0.2261 , 0.2124 , 0.2058 , 0.1941 , 0.1677 , 0.1605 , 0.1588 ,\n",
       "            0.1542 , 0.1486 , 0.1406 , 0.1354 , 0.0995 , 0.0933 , 0.07697,\n",
       "            0.04218], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.2835821, dtype=float32),\n",
       "    'tpr': array(0.9913793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14179105, 0.14925373, 0.15671642, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.1716418 , 0.17910448, 0.19402985,\n",
       "            0.19402985, 0.19402985, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06896552, 0.0775862 , 0.0862069 , 0.10344828,\n",
       "            0.12068965, 0.12931034, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.22413793, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.29310346, 0.30172414, 0.31034482, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.57758623, 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7758621 , 0.7844828 , 0.79310346, 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.996  , 0.9927 , 0.9917 , 0.9897 , 0.986  , 0.9834 ,\n",
       "            0.983  , 0.982  , 0.9814 , 0.9795 , 0.9785 , 0.978  , 0.976  ,\n",
       "            0.9746 , 0.973  , 0.9727 , 0.9683 , 0.9673 , 0.967  , 0.966  ,\n",
       "            0.9653 , 0.9644 , 0.964  , 0.9634 , 0.9624 , 0.962  , 0.9614 ,\n",
       "            0.96   , 0.9595 , 0.959  , 0.957  , 0.9507 , 0.9497 , 0.949  ,\n",
       "            0.943  , 0.942  , 0.941  , 0.9385 , 0.938  , 0.933  , 0.93   ,\n",
       "            0.9297 , 0.9277 , 0.924  , 0.923  , 0.9194 , 0.9136 , 0.913  ,\n",
       "            0.912  , 0.9116 , 0.91   , 0.9097 , 0.909  , 0.908  , 0.906  ,\n",
       "            0.9    , 0.8994 , 0.8984 , 0.8965 , 0.896  , 0.893  , 0.8906 ,\n",
       "            0.89   , 0.887  , 0.8867 , 0.8853 , 0.884  , 0.875  , 0.8726 ,\n",
       "            0.871  , 0.8677 , 0.865  , 0.8594 , 0.8447 , 0.836  , 0.831  ,\n",
       "            0.824  , 0.8105 , 0.806  , 0.801  , 0.7983 , 0.7935 , 0.7915 ,\n",
       "            0.7876 , 0.7812 , 0.775  , 0.7725 , 0.771  , 0.7676 , 0.7637 ,\n",
       "            0.761  , 0.758  , 0.755  , 0.7476 , 0.743  , 0.7305 , 0.7285 ,\n",
       "            0.698  , 0.6943 , 0.68   , 0.6763 , 0.6743 , 0.6724 , 0.666  ,\n",
       "            0.6455 , 0.645  , 0.6436 , 0.643  , 0.634  , 0.632  , 0.627  ,\n",
       "            0.6235 , 0.623  , 0.6113 , 0.603  , 0.6025 , 0.6016 , 0.598  ,\n",
       "            0.595  , 0.591  , 0.5874 , 0.587  , 0.576  , 0.574  , 0.5674 ,\n",
       "            0.566  , 0.5615 , 0.559  , 0.556  , 0.546  , 0.5386 , 0.536  ,\n",
       "            0.5312 , 0.5283 , 0.525  , 0.51   , 0.5054 , 0.5044 , 0.5034 ,\n",
       "            0.499  , 0.498  , 0.492  , 0.479  , 0.478  , 0.456  , 0.4553 ,\n",
       "            0.455  , 0.4526 , 0.452  , 0.451  , 0.4495 , 0.4478 , 0.4424 ,\n",
       "            0.4417 , 0.4382 , 0.4338 , 0.425  , 0.4246 , 0.4177 , 0.412  ,\n",
       "            0.409  , 0.408  , 0.4065 , 0.402  , 0.4006 , 0.3984 , 0.3967 ,\n",
       "            0.3958 , 0.3933 , 0.3892 , 0.383  , 0.3826 , 0.3806 , 0.38   ,\n",
       "            0.3782 , 0.3733 , 0.3726 , 0.365  , 0.3586 , 0.355  , 0.351  ,\n",
       "            0.348  , 0.3477 , 0.3474 , 0.3398 , 0.3381 , 0.336  , 0.331  ,\n",
       "            0.3267 , 0.3262 , 0.3245 , 0.323  , 0.3228 , 0.3188 , 0.3171 ,\n",
       "            0.3142 , 0.3135 , 0.3113 , 0.3093 , 0.3079 , 0.3052 , 0.2976 ,\n",
       "            0.2957 , 0.2935 , 0.2817 , 0.2788 , 0.272  , 0.2695 , 0.2678 ,\n",
       "            0.2627 , 0.2534 , 0.2502 , 0.234  , 0.2325 , 0.2313 , 0.2197 ,\n",
       "            0.2181 , 0.2064 , 0.1882 , 0.1819 , 0.1718 , 0.1464 , 0.1434 ,\n",
       "            0.1384 , 0.1338 , 0.1284 , 0.12445, 0.11597, 0.086  , 0.0802 ,\n",
       "            0.065  , 0.0345 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.23880596, dtype=float32),\n",
       "    'tpr': array(0.9913793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.01492537, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.06716418, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.15671642, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.17910448, 0.18656716,\n",
       "            0.18656716, 0.18656716, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.35074627, 0.35820895, 0.36567163, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18965517, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.29310346, 0.31034482, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.51724136, 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.76724136, 0.76724136,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.79310346, 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9966 , 0.9937 , 0.9927 , 0.9907 , 0.99   , 0.987  ,\n",
       "            0.985  , 0.984  , 0.9834 , 0.983  , 0.981  , 0.9805 , 0.9795 ,\n",
       "            0.978  , 0.9756 , 0.975  , 0.974  , 0.9697 , 0.9683 , 0.9673 ,\n",
       "            0.967  , 0.9663 , 0.966  , 0.9653 , 0.9644 , 0.964  , 0.9634 ,\n",
       "            0.963  , 0.961  , 0.96   , 0.959  , 0.9536 , 0.9517 , 0.951  ,\n",
       "            0.945  , 0.9424 , 0.9414 , 0.941  , 0.9395 , 0.935  , 0.932  ,\n",
       "            0.9297 , 0.928  , 0.923  , 0.9224 , 0.917  , 0.914  , 0.913  ,\n",
       "            0.9126 , 0.9097 , 0.9087 , 0.908  , 0.902  , 0.9    , 0.8994 ,\n",
       "            0.898  , 0.8975 , 0.896  , 0.8916 , 0.89   , 0.8887 , 0.887  ,\n",
       "            0.8867 , 0.884  , 0.882  , 0.872  , 0.8716 , 0.871  , 0.867  ,\n",
       "            0.8647 , 0.8643 , 0.8564 , 0.8433 , 0.833  , 0.8286 , 0.8267 ,\n",
       "            0.8    , 0.797  , 0.7954 , 0.795  , 0.7896 , 0.7876 , 0.784  ,\n",
       "            0.7773 , 0.776  , 0.7656 , 0.7637 , 0.758  , 0.757  , 0.7563 ,\n",
       "            0.749  , 0.744  , 0.7354 , 0.7344 , 0.7173 , 0.7153 , 0.679  ,\n",
       "            0.6753 , 0.674  , 0.6597 , 0.6567 , 0.6504 , 0.637  , 0.6323 ,\n",
       "            0.6294 , 0.624  , 0.621  , 0.6147 , 0.611  , 0.61   , 0.6035 ,\n",
       "            0.584  , 0.5815 , 0.5796 , 0.5776 , 0.5757 , 0.575  , 0.5703 ,\n",
       "            0.569  , 0.568  , 0.555  , 0.5547 , 0.545  , 0.5425 , 0.541  ,\n",
       "            0.5327 , 0.5317 , 0.5225 , 0.5073 , 0.5054 , 0.5034 , 0.5024 ,\n",
       "            0.4963 , 0.4915 , 0.4897 , 0.489  , 0.4812 , 0.4773 , 0.477  ,\n",
       "            0.4753 , 0.4473 , 0.4424 , 0.4314 , 0.43   , 0.4292 , 0.4272 ,\n",
       "            0.4253 , 0.4248 , 0.4236 , 0.4119 , 0.411  , 0.409  , 0.405  ,\n",
       "            0.4011 , 0.4006 , 0.3977 , 0.3972 , 0.391  , 0.377  , 0.3765 ,\n",
       "            0.3752 , 0.3733 , 0.3694 , 0.3687 , 0.3652 , 0.3633 , 0.3623 ,\n",
       "            0.3538 , 0.3525 , 0.3464 , 0.3462 , 0.3435 , 0.3423 , 0.34   ,\n",
       "            0.3367 , 0.327  , 0.3198 , 0.3184 , 0.3164 , 0.3098 , 0.3071 ,\n",
       "            0.306  , 0.3018 , 0.2974 , 0.296  , 0.2944 , 0.2932 , 0.2869 ,\n",
       "            0.283  , 0.2825 , 0.2769 , 0.2764 , 0.2734 , 0.273  , 0.2708 ,\n",
       "            0.267  , 0.2664 , 0.265  , 0.2625 , 0.2603 , 0.2573 , 0.2517 ,\n",
       "            0.2449 , 0.244  , 0.243  , 0.2429 , 0.2388 , 0.2303 , 0.2263 ,\n",
       "            0.2203 , 0.217  , 0.2139 , 0.2091 , 0.2051 , 0.2024 , 0.193  ,\n",
       "            0.1909 , 0.1848 , 0.1625 , 0.157  , 0.1467 , 0.1257 , 0.1238 ,\n",
       "            0.1166 , 0.11163, 0.1086 , 0.108  , 0.0962 , 0.07275, 0.0677 ,\n",
       "            0.0538 , 0.0278 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.19402985, dtype=float32),\n",
       "    'tpr': array(0.98275864, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.11940298, 0.11940298,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.14925373, 0.15671642,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.1716418 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.22413793,\n",
       "            0.2413793 , 0.25862068, 0.2672414 , 0.27586207, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7758621 , 0.79310346,\n",
       "            0.80172414, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.997  , 0.994  , 0.9937 , 0.9917 , 0.991  , 0.988  ,\n",
       "            0.986  , 0.9854 , 0.985  , 0.9834 , 0.983  , 0.9824 , 0.982  ,\n",
       "            0.98   , 0.9795 , 0.979  , 0.976  , 0.9756 , 0.974  , 0.971  ,\n",
       "            0.97   , 0.9697 , 0.9688 , 0.9683 , 0.968  , 0.967  , 0.9663 ,\n",
       "            0.9653 , 0.965  , 0.9644 , 0.964  , 0.962  , 0.9614 , 0.961  ,\n",
       "            0.9546 , 0.9536 , 0.953  , 0.947  , 0.945  , 0.9424 , 0.9404 ,\n",
       "            0.94   , 0.9385 , 0.9375 , 0.932  , 0.9287 , 0.9277 , 0.9204 ,\n",
       "            0.9194 , 0.9146 , 0.914  , 0.9136 , 0.9126 , 0.911  , 0.9077 ,\n",
       "            0.905  , 0.902  , 0.9    , 0.898  , 0.8965 , 0.8955 , 0.895  ,\n",
       "            0.887  , 0.8853 , 0.884  , 0.8833 , 0.876  , 0.8696 , 0.868  ,\n",
       "            0.865  , 0.8643 , 0.864  , 0.8594 , 0.8516 , 0.838  , 0.826  ,\n",
       "            0.8257 , 0.824  , 0.7944 , 0.792  , 0.791  , 0.781  , 0.775  ,\n",
       "            0.7734 , 0.771  , 0.7705 , 0.7515 , 0.751  , 0.7476 , 0.7407 ,\n",
       "            0.7393 , 0.7373 , 0.737  , 0.7285 , 0.723  , 0.7163 , 0.6987 ,\n",
       "            0.696  , 0.662  , 0.661  , 0.6504 , 0.6445 , 0.629  , 0.6284 ,\n",
       "            0.6187 , 0.611  , 0.6084 , 0.605  , 0.5933 , 0.593  , 0.5923 ,\n",
       "            0.5864 , 0.583  , 0.5615 , 0.56   , 0.557  , 0.55   , 0.5493 ,\n",
       "            0.549  , 0.54   , 0.531  , 0.521  , 0.5195 , 0.516  , 0.512  ,\n",
       "            0.506  , 0.502  , 0.4944 , 0.4937 , 0.4868 , 0.4846 , 0.483  ,\n",
       "            0.4707 , 0.4702 , 0.4602 , 0.4578 , 0.4563 , 0.4548 , 0.446  ,\n",
       "            0.443  , 0.4385 , 0.4358 , 0.4224 , 0.407  , 0.4067 , 0.402  ,\n",
       "            0.4011 , 0.4004 , 0.3938 , 0.3914 , 0.3875 , 0.385  , 0.3835 ,\n",
       "            0.3782 , 0.3708 , 0.3696 , 0.3694 , 0.369  , 0.3525 , 0.3523 ,\n",
       "            0.3508 , 0.3499 , 0.3486 , 0.3462 , 0.344  , 0.3438 , 0.3425 ,\n",
       "            0.3274 , 0.3232 , 0.3154 , 0.3152 , 0.313  , 0.303  , 0.3    ,\n",
       "            0.297  , 0.2969 , 0.2942 , 0.2898 , 0.2886 , 0.2734 , 0.271  ,\n",
       "            0.2666 , 0.2664 , 0.2654 , 0.265  , 0.2585 , 0.258  , 0.2563 ,\n",
       "            0.2494 , 0.2456 , 0.2449 , 0.2445 , 0.244  , 0.2405 , 0.235  ,\n",
       "            0.2343 , 0.2302 , 0.2285 , 0.2281 , 0.2239 , 0.223  , 0.2202 ,\n",
       "            0.2197 , 0.2167 , 0.2137 , 0.2113 , 0.2091 , 0.2089 , 0.2043 ,\n",
       "            0.1987 , 0.1973 , 0.197  , 0.1954 , 0.1815 , 0.1803 , 0.1799 ,\n",
       "            0.1704 , 0.1682 , 0.1671 , 0.164  , 0.1621 , 0.1414 , 0.1362 ,\n",
       "            0.1283 , 0.1095 , 0.1065 , 0.10034, 0.0962 , 0.09283, 0.0927 ,\n",
       "            0.08167, 0.0612 , 0.05664, 0.0446 , 0.02225], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1641791, dtype=float32),\n",
       "    'tpr': array(0.98275864, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.06716418, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.1119403 , 0.1119403 , 0.11940298,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.15671642, 0.1641791 , 0.1641791 ,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.23275863, 0.25862068, 0.2672414 , 0.28448275,\n",
       "            0.29310346, 0.31034482, 0.31896552, 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.997  , 0.995  , 0.994  , 0.992  , 0.9917 , 0.989  ,\n",
       "            0.9873 , 0.987  , 0.9863 , 0.986  , 0.985  , 0.9844 , 0.984  ,\n",
       "            0.9834 , 0.9814 , 0.981  , 0.9805 , 0.9775 , 0.977  , 0.9756 ,\n",
       "            0.9736 , 0.972  , 0.9717 , 0.9707 , 0.97   , 0.9697 , 0.969  ,\n",
       "            0.9683 , 0.967  , 0.9663 , 0.966  , 0.964  , 0.9634 , 0.963  ,\n",
       "            0.957  , 0.956  , 0.9556 , 0.949  , 0.9473 , 0.9453 , 0.9424 ,\n",
       "            0.9414 , 0.9404 , 0.9346 , 0.9316 , 0.929  , 0.9224 , 0.921  ,\n",
       "            0.9175 , 0.917  , 0.9155 , 0.9136 , 0.913  , 0.9106 , 0.9097 ,\n",
       "            0.9062 , 0.9053 , 0.903  , 0.9    , 0.8994 , 0.8975 , 0.8965 ,\n",
       "            0.889  , 0.8887 , 0.887  , 0.886  , 0.8853 , 0.885  , 0.877  ,\n",
       "            0.8726 , 0.87   , 0.866  , 0.8657 , 0.865  , 0.861  , 0.853  ,\n",
       "            0.8394 , 0.8276 , 0.8267 , 0.823  , 0.7954 , 0.791  , 0.789  ,\n",
       "            0.7803 , 0.772  , 0.771  , 0.7705 , 0.77   , 0.763  , 0.7495 ,\n",
       "            0.7485 , 0.747  , 0.7383 , 0.735  , 0.733  , 0.73   , 0.726  ,\n",
       "            0.7217 , 0.7124 , 0.694  , 0.6914 , 0.655  , 0.6484 , 0.643  ,\n",
       "            0.6396 , 0.622  , 0.62   , 0.6133 , 0.6016 , 0.589  , 0.5874 ,\n",
       "            0.5767 , 0.5723 , 0.5693 , 0.554  , 0.551  , 0.546  , 0.542  ,\n",
       "            0.5415 , 0.537  , 0.5366 , 0.53   , 0.522  , 0.5093 , 0.5063 ,\n",
       "            0.4976 , 0.4924 , 0.491  , 0.485  , 0.479  , 0.4775 , 0.4702 ,\n",
       "            0.4663 , 0.4644 , 0.4578 , 0.4563 , 0.4478 , 0.4426 , 0.4421 ,\n",
       "            0.4343 , 0.4243 , 0.423  , 0.4214 , 0.421  , 0.4058 , 0.395  ,\n",
       "            0.3945 , 0.391  , 0.3894 , 0.383  , 0.3767 , 0.3704 , 0.368  ,\n",
       "            0.367  , 0.3662 , 0.3555 , 0.3535 , 0.3528 , 0.3518 , 0.3447 ,\n",
       "            0.3362 , 0.3357 , 0.3313 , 0.3308 , 0.329  , 0.3286 , 0.327  ,\n",
       "            0.3262 , 0.3254 , 0.3086 , 0.307  , 0.2988 , 0.298  , 0.2898 ,\n",
       "            0.2847 , 0.2817 , 0.2783 , 0.2764 , 0.2751 , 0.2664 , 0.2659 ,\n",
       "            0.2537 , 0.2498 , 0.2489 , 0.2482 , 0.2429 , 0.2422 , 0.2382 ,\n",
       "            0.2374 , 0.236  , 0.228  , 0.2277 , 0.2272 , 0.2249 , 0.2247 ,\n",
       "            0.2224 , 0.2161 , 0.2157 , 0.212  , 0.2094 , 0.2085 , 0.2056 ,\n",
       "            0.2047 , 0.2009 , 0.1998 , 0.1984 , 0.1934 , 0.1925 , 0.1912 ,\n",
       "            0.1884 , 0.1842 , 0.1814 , 0.18   , 0.1782 , 0.1772 , 0.1752 ,\n",
       "            0.1631 , 0.1614 , 0.1525 , 0.1504 , 0.1487 , 0.1484 , 0.1434 ,\n",
       "            0.1249 , 0.12   , 0.1126 , 0.09705, 0.0925 , 0.0871 , 0.0827 ,\n",
       "            0.08105, 0.0804 , 0.0702 , 0.05243, 0.0483 , 0.0376 , 0.01823],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1641791, dtype=float32),\n",
       "    'tpr': array(0.9655172, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.10447761, 0.1119403 ,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14179105, 0.15671642, 0.1641791 , 0.1641791 ,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.4827586 , 0.49137932, 0.5086207 , 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.76724136, 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.7844828 , 0.80172414, 0.8103448 ,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9976 , 0.9956 , 0.9946 , 0.9927 , 0.992  , 0.9897 ,\n",
       "            0.989  , 0.988  , 0.9873 , 0.987  , 0.9863 , 0.985  , 0.9844 ,\n",
       "            0.9834 , 0.983  , 0.9824 , 0.9805 , 0.9795 , 0.9785 , 0.9766 ,\n",
       "            0.975  , 0.9746 , 0.973  , 0.9727 , 0.972  , 0.9717 , 0.971  ,\n",
       "            0.9707 , 0.9697 , 0.9683 , 0.968  , 0.9673 , 0.966  , 0.9653 ,\n",
       "            0.965  , 0.9634 , 0.961  , 0.9575 , 0.957  , 0.951  , 0.95   ,\n",
       "            0.9487 , 0.9463 , 0.946  , 0.945  , 0.9424 , 0.9395 , 0.934  ,\n",
       "            0.933  , 0.9253 , 0.9233 , 0.9214 , 0.919  , 0.9185 , 0.918  ,\n",
       "            0.916  , 0.9146 , 0.911  , 0.9053 , 0.904  , 0.902  , 0.901  ,\n",
       "            0.899  , 0.8945 , 0.894  , 0.893  , 0.891  , 0.8896 , 0.887  ,\n",
       "            0.8784 , 0.876  , 0.8716 , 0.8706 , 0.87   , 0.8643 , 0.86   ,\n",
       "            0.852  , 0.8447 , 0.831  , 0.829  , 0.827  , 0.794  , 0.7876 ,\n",
       "            0.783  , 0.7773 , 0.772  , 0.7705 , 0.7686 , 0.752  , 0.7515 ,\n",
       "            0.7505 , 0.7437 , 0.7393 , 0.733  , 0.7295 , 0.7236 , 0.719  ,\n",
       "            0.7163 , 0.7124 , 0.686  , 0.683  , 0.653  , 0.6313 , 0.63   ,\n",
       "            0.612  , 0.608  , 0.604  , 0.5977 , 0.5903 , 0.5835 , 0.5674 ,\n",
       "            0.566  , 0.5645 , 0.555  , 0.5483 , 0.547  , 0.5454 , 0.536  ,\n",
       "            0.5283 , 0.527  , 0.5215 , 0.5176 , 0.5146 , 0.495  , 0.4922 ,\n",
       "            0.4807 , 0.4785 , 0.4675 , 0.4666 , 0.465  , 0.4595 , 0.4512 ,\n",
       "            0.4468 , 0.446  , 0.4458 , 0.4404 , 0.4358 , 0.4316 , 0.4236 ,\n",
       "            0.4158 , 0.406  , 0.405  , 0.4028 , 0.3992 , 0.394  , 0.382  ,\n",
       "            0.3784 , 0.3782 , 0.3767 , 0.3623 , 0.3582 , 0.3494 , 0.349  ,\n",
       "            0.3477 , 0.3403 , 0.3352 , 0.335  , 0.3345 , 0.3298 , 0.3223 ,\n",
       "            0.3176 , 0.3157 , 0.3132 , 0.313  , 0.3127 , 0.312  , 0.3076 ,\n",
       "            0.3062 , 0.3057 , 0.287  , 0.28   , 0.279  , 0.268  , 0.264  ,\n",
       "            0.2634 , 0.257  , 0.2556 , 0.2542 , 0.2437 , 0.2411 , 0.2335 ,\n",
       "            0.2286 , 0.2278 , 0.2277 , 0.2203 , 0.2186 , 0.2184 , 0.2177 ,\n",
       "            0.2168 , 0.215  , 0.2134 , 0.2074 , 0.2069 , 0.2031 , 0.202  ,\n",
       "            0.1954 , 0.1948 , 0.191  , 0.1885 , 0.1874 , 0.1848 , 0.1841 ,\n",
       "            0.1812 , 0.1782 , 0.1775 , 0.1771 , 0.1711 , 0.17   , 0.1676 ,\n",
       "            0.1665 , 0.1631 , 0.1597 , 0.1575 , 0.1542 , 0.1531 , 0.1439 ,\n",
       "            0.141  , 0.1409 , 0.134  , 0.1339 , 0.1321 , 0.1287 , 0.1238 ,\n",
       "            0.108  , 0.10376, 0.0964 , 0.0857 , 0.07837, 0.0734 , 0.0709 ,\n",
       "            0.06903, 0.06805, 0.05844, 0.04434, 0.04077, 0.0312 , 0.01473],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.14179105, dtype=float32),\n",
       "    'tpr': array(0.9655172, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.12686567, 0.13432837, 0.14179105, 0.14179105,\n",
       "            0.15671642, 0.1641791 , 0.1641791 , 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.35820895, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06896552, 0.0775862 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.19827586, 0.21551724, 0.23275863, 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9976 , 0.9956 , 0.995  , 0.993  , 0.9927 , 0.99   ,\n",
       "            0.989  , 0.988  , 0.987  , 0.9863 , 0.986  , 0.9854 , 0.984  ,\n",
       "            0.9834 , 0.983  , 0.981  , 0.9795 , 0.9785 , 0.9775 , 0.9756 ,\n",
       "            0.9736 , 0.973  , 0.9727 , 0.971  , 0.9707 , 0.9697 , 0.969  ,\n",
       "            0.9683 , 0.9663 , 0.966  , 0.964  , 0.9614 , 0.959  , 0.9585 ,\n",
       "            0.9526 , 0.9507 , 0.95   , 0.946  , 0.9453 , 0.9443 , 0.943  ,\n",
       "            0.94   , 0.934  , 0.933  , 0.924  , 0.9233 , 0.9204 , 0.92   ,\n",
       "            0.9194 , 0.9175 , 0.916  , 0.9155 , 0.913  , 0.9106 , 0.909  ,\n",
       "            0.905  , 0.9043 , 0.901  , 0.9004 , 0.899  , 0.893  , 0.8916 ,\n",
       "            0.889  , 0.8877 , 0.8867 , 0.877  , 0.874  , 0.8696 , 0.869  ,\n",
       "            0.867  , 0.8623 , 0.858  , 0.8506 , 0.8413 , 0.8267 , 0.826  ,\n",
       "            0.824  , 0.7915 , 0.783  , 0.777  , 0.7734 , 0.765  , 0.7627 ,\n",
       "            0.7617 , 0.7573 , 0.744  , 0.743  , 0.741  , 0.737  , 0.7295 ,\n",
       "            0.7227 , 0.7207 , 0.7153 , 0.711  , 0.7046 , 0.701  , 0.6753 ,\n",
       "            0.672  , 0.64   , 0.621  , 0.615  , 0.6143 , 0.599  , 0.594  ,\n",
       "            0.592  , 0.583  , 0.577  , 0.572  , 0.549  , 0.5444 , 0.5405 ,\n",
       "            0.5366 , 0.5337 , 0.533  , 0.528  , 0.5225 , 0.509  , 0.5083 ,\n",
       "            0.503  , 0.499  , 0.4976 , 0.479  , 0.4763 , 0.4644 , 0.447  ,\n",
       "            0.4458 , 0.443  , 0.4402 , 0.4343 , 0.4329 , 0.429  , 0.4272 ,\n",
       "            0.42   , 0.4192 , 0.419  , 0.4126 , 0.4016 , 0.3877 , 0.3843 ,\n",
       "            0.3809 , 0.3777 , 0.3743 , 0.3699 , 0.3655 , 0.3652 , 0.3647 ,\n",
       "            0.362  , 0.3435 , 0.34   , 0.3298 , 0.3186 , 0.3154 , 0.315  ,\n",
       "            0.3103 , 0.3057 , 0.2996 , 0.2966 , 0.2952 , 0.2942 , 0.2935 ,\n",
       "            0.2925 , 0.2913 , 0.2883 , 0.2798 , 0.2773 , 0.2686 , 0.2646 ,\n",
       "            0.2595 , 0.257  , 0.2429 , 0.2413 , 0.2401 , 0.2355 , 0.2351 ,\n",
       "            0.2283 , 0.2205 , 0.2162 , 0.2147 , 0.2098 , 0.205  , 0.2009 ,\n",
       "            0.199  , 0.1985 , 0.1976 , 0.1962 , 0.1941 , 0.1929 , 0.1903 ,\n",
       "            0.1879 , 0.1835 , 0.1823 , 0.1819 , 0.1763 , 0.1744 , 0.1724 ,\n",
       "            0.1677 , 0.1666 , 0.1659 , 0.1649 , 0.1646 , 0.1611 , 0.1587 ,\n",
       "            0.1569 , 0.1537 , 0.1523 , 0.15   , 0.1455 , 0.1425 , 0.141  ,\n",
       "            0.1387 , 0.1364 , 0.1339 , 0.1287 , 0.1254 , 0.12286, 0.1204 ,\n",
       "            0.1195 , 0.11755, 0.11084, 0.10614, 0.09515, 0.09106, 0.08435,\n",
       "            0.07556, 0.06805, 0.0635 , 0.0621 , 0.05954, 0.059  , 0.05005,\n",
       "            0.0379 , 0.0347 , 0.0263 , 0.0121 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.13432837, dtype=float32),\n",
       "    'tpr': array(0.95689654, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.07462686, 0.08208955, 0.08955224, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.11940298, 0.12686567, 0.13432837, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.1641791 ,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.3432836 , 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0862069 ,\n",
       "            0.10344828, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.19827586,\n",
       "            0.20689656, 0.23275863, 0.2413793 , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.29310346, 0.30172414, 0.31034482, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.7758621 , 0.79310346,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9976  , 0.996   , 0.9956  , 0.9937  , 0.9927  ,\n",
       "            0.9907  , 0.9897  , 0.9893  , 0.988   , 0.9873  , 0.986   ,\n",
       "            0.985   , 0.984   , 0.9834  , 0.9824  , 0.981   , 0.98    ,\n",
       "            0.979   , 0.977   , 0.9756  , 0.9746  , 0.974   , 0.973   ,\n",
       "            0.9717  , 0.971   , 0.9697  , 0.9683  , 0.967   , 0.9663  ,\n",
       "            0.966   , 0.964   , 0.9634  , 0.9595  , 0.959   , 0.953   ,\n",
       "            0.9526  , 0.9507  , 0.9478  , 0.9473  , 0.947   , 0.943   ,\n",
       "            0.9424  , 0.935   , 0.9336  , 0.927   , 0.926   , 0.922   ,\n",
       "            0.9214  , 0.9204  , 0.92    , 0.9194  , 0.919   , 0.9175  ,\n",
       "            0.916   , 0.914   , 0.911   , 0.9077  , 0.904   , 0.903   ,\n",
       "            0.899   , 0.898   , 0.8955  , 0.8945  , 0.894   , 0.8916  ,\n",
       "            0.889   , 0.887   , 0.88    , 0.872   , 0.8696  , 0.869   ,\n",
       "            0.867   , 0.8594  , 0.854   , 0.8467  , 0.8438  , 0.8286  ,\n",
       "            0.823   , 0.822   , 0.7886  , 0.777   , 0.7715  , 0.768   ,\n",
       "            0.761   , 0.756   , 0.755   , 0.7446  , 0.743   , 0.7324  ,\n",
       "            0.729   , 0.728   , 0.7188  , 0.7153  , 0.7144  , 0.7007  ,\n",
       "            0.699   , 0.694   , 0.663   , 0.659   , 0.631   , 0.611   ,\n",
       "            0.6     , 0.597   , 0.5854  , 0.5845  , 0.574   , 0.5723  ,\n",
       "            0.5684  , 0.564   , 0.5376  , 0.5327  , 0.5317  , 0.529   ,\n",
       "            0.528   , 0.52    , 0.5166  , 0.5107  , 0.5005  , 0.4958  ,\n",
       "            0.4934  , 0.4927  , 0.4834  , 0.48    , 0.4636  , 0.4614  ,\n",
       "            0.453   , 0.4348  , 0.4336  , 0.429   , 0.4272  , 0.4177  ,\n",
       "            0.4172  , 0.412   , 0.4087  , 0.4077  , 0.4072  , 0.4004  ,\n",
       "            0.3972  , 0.38    , 0.376   , 0.3662  , 0.3638  , 0.361   ,\n",
       "            0.3596  , 0.3567  , 0.3562  , 0.3538  , 0.3528  , 0.3496  ,\n",
       "            0.3276  , 0.3252  , 0.314   , 0.3032  , 0.2998  , 0.2986  ,\n",
       "            0.2966  , 0.294   , 0.291   , 0.2847  , 0.2834  , 0.2832  ,\n",
       "            0.2786  , 0.2761  , 0.2756  , 0.2734  , 0.2705  , 0.2654  ,\n",
       "            0.2627  , 0.252   , 0.2471  , 0.2441  , 0.2368  , 0.229   ,\n",
       "            0.2257  , 0.2242  , 0.217   , 0.2166  , 0.2145  , 0.2031  ,\n",
       "            0.2018  , 0.201   , 0.1956  , 0.1869  , 0.1844  , 0.1824  ,\n",
       "            0.182   , 0.1813  , 0.1803  , 0.18    , 0.1799  , 0.1771  ,\n",
       "            0.1738  , 0.1707  , 0.1697  , 0.164   , 0.1635  , 0.1625  ,\n",
       "            0.1586  , 0.1571  , 0.1531  , 0.1519  , 0.1511  , 0.151   ,\n",
       "            0.1504  , 0.1477  , 0.1451  , 0.1395  , 0.1393  , 0.1389  ,\n",
       "            0.1366  , 0.1292  , 0.1282  , 0.1279  , 0.1255  , 0.1225  ,\n",
       "            0.1207  , 0.11615 , 0.1128  , 0.1101  , 0.10895 , 0.1074  ,\n",
       "            0.1058  , 0.0986  , 0.0942  , 0.0845  , 0.08093 , 0.07477 ,\n",
       "            0.0671  , 0.05975 , 0.05573 , 0.0547  , 0.05194 , 0.05167 ,\n",
       "            0.04352 , 0.03265 , 0.02982 , 0.02242 , 0.010056], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1119403, dtype=float32),\n",
       "    'tpr': array(0.95689654, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.07462686, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.08955224, 0.08955224, 0.08955224,\n",
       "            0.09701493, 0.09701493, 0.10447761, 0.1119403 , 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1641791 , 0.1641791 ,\n",
       "            0.1716418 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9976  , 0.996   , 0.9956  , 0.9937  , 0.9927  ,\n",
       "            0.9907  , 0.9897  , 0.9893  , 0.988   , 0.9873  , 0.987   ,\n",
       "            0.986   , 0.9854  , 0.9834  , 0.983   , 0.9824  , 0.9805  ,\n",
       "            0.98    , 0.979   , 0.977   , 0.9756  , 0.9746  , 0.974   ,\n",
       "            0.9736  , 0.973   , 0.9727  , 0.971   , 0.969   , 0.9688  ,\n",
       "            0.968   , 0.9663  , 0.9653  , 0.965   , 0.9634  , 0.963   ,\n",
       "            0.9585  , 0.953   , 0.9517  , 0.9497  , 0.9463  , 0.946   ,\n",
       "            0.9453  , 0.9414  , 0.933   , 0.9316  , 0.927   , 0.923   ,\n",
       "            0.919   , 0.918   , 0.9175  , 0.9165  , 0.9136  , 0.9126  ,\n",
       "            0.9077  , 0.906   , 0.9004  , 0.9     , 0.895   , 0.8945  ,\n",
       "            0.8926  , 0.8916  , 0.89    , 0.8887  , 0.885   , 0.883   ,\n",
       "            0.8774  , 0.8687  , 0.864   , 0.8623  , 0.8613  , 0.8525  ,\n",
       "            0.8467  , 0.84    , 0.839   , 0.8228  , 0.8174  , 0.8154  ,\n",
       "            0.7817  , 0.766   , 0.7603  , 0.7583  , 0.752   , 0.749   ,\n",
       "            0.743   , 0.7407  , 0.737   , 0.733   , 0.7173  , 0.717   ,\n",
       "            0.715   , 0.706   , 0.705   , 0.701   , 0.686   , 0.6855  ,\n",
       "            0.677   , 0.646   , 0.642   , 0.617   , 0.5957  , 0.5786  ,\n",
       "            0.5747  , 0.5703  , 0.567   , 0.557   , 0.556   , 0.552   ,\n",
       "            0.546   , 0.517   , 0.515   , 0.5137  , 0.5083  , 0.505   ,\n",
       "            0.503   , 0.496   , 0.4856  , 0.48    , 0.4773  , 0.477   ,\n",
       "            0.472   , 0.4622  , 0.454   , 0.444   , 0.4421  , 0.4368  ,\n",
       "            0.4114  , 0.4045  , 0.4016  , 0.4011  , 0.401   , 0.3977  ,\n",
       "            0.3926  , 0.3909  , 0.3828  , 0.3787  , 0.3777  , 0.3745  ,\n",
       "            0.3552  , 0.3508  , 0.3494  , 0.344   , 0.342   , 0.341   ,\n",
       "            0.3403  , 0.3386  , 0.336   , 0.3357  , 0.3206  , 0.309   ,\n",
       "            0.3083  , 0.2961  , 0.2957  , 0.2817  , 0.2769  , 0.2764  ,\n",
       "            0.2742  , 0.269   , 0.2688  , 0.268   , 0.266   , 0.261   ,\n",
       "            0.257   , 0.2566  , 0.2494  , 0.2478  , 0.2418  , 0.2388  ,\n",
       "            0.2347  , 0.2301  , 0.2229  , 0.2161  , 0.2106  , 0.2056  ,\n",
       "            0.2029  , 0.199   , 0.1978  , 0.1935  , 0.1865  , 0.1838  ,\n",
       "            0.1805  , 0.1797  , 0.1656  , 0.1652  , 0.1646  , 0.1643  ,\n",
       "            0.1631  , 0.161   , 0.1597  , 0.1594  , 0.1577  , 0.1555  ,\n",
       "            0.1517  , 0.1478  , 0.1467  , 0.1459  , 0.1445  , 0.1409  ,\n",
       "            0.1382  , 0.1378  , 0.1367  , 0.1361  , 0.1351  , 0.1337  ,\n",
       "            0.1311  , 0.1251  , 0.1238  , 0.12366 , 0.1223  , 0.1144  ,\n",
       "            0.1142  , 0.1118  , 0.11163 , 0.1065  , 0.1058  , 0.1036  ,\n",
       "            0.09875 , 0.09753 , 0.09705 , 0.0955  , 0.0939  , 0.0862  ,\n",
       "            0.082   , 0.0741  , 0.0708  , 0.0643  , 0.0589  , 0.05127 ,\n",
       "            0.0478  , 0.04742 , 0.0446  , 0.04376 , 0.03677 , 0.02785 ,\n",
       "            0.02538 , 0.0189  , 0.008286], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.08955224, dtype=float32),\n",
       "    'tpr': array(0.9310345, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08955224, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.09701493, 0.09701493, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.1641791 ,\n",
       "            0.1641791 , 0.1716418 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.32089552, 0.3283582 , 0.33582088, 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.23275863, 0.2413793 , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.29310346, 0.31034482, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9976  , 0.996   , 0.9956  , 0.993   , 0.9927  ,\n",
       "            0.99    , 0.9897  , 0.989   , 0.988   , 0.9873  , 0.987   ,\n",
       "            0.9863  , 0.9854  , 0.985   , 0.983   , 0.9824  , 0.982   ,\n",
       "            0.98    , 0.9795  , 0.979   , 0.977   , 0.9766  , 0.976   ,\n",
       "            0.974   , 0.9736  , 0.9727  , 0.9717  , 0.9707  , 0.97    ,\n",
       "            0.9673  , 0.9653  , 0.963   , 0.9624  , 0.962   , 0.961   ,\n",
       "            0.9565  , 0.952   , 0.9497  , 0.9473  , 0.9434  , 0.943   ,\n",
       "            0.9395  , 0.9385  , 0.9297  , 0.9277  , 0.9253  , 0.918   ,\n",
       "            0.916   , 0.9155  , 0.9146  , 0.914   , 0.9136  , 0.9116  ,\n",
       "            0.91    , 0.909   , 0.9077  , 0.903   , 0.902   , 0.895   ,\n",
       "            0.8945  , 0.888   , 0.8877  , 0.887   , 0.8843  , 0.884   ,\n",
       "            0.878   , 0.877   , 0.8726  , 0.863   , 0.8555  , 0.852   ,\n",
       "            0.8486  , 0.843   , 0.834   , 0.8315  , 0.828   , 0.8135  ,\n",
       "            0.808   , 0.8076  , 0.7715  , 0.75    , 0.7456  , 0.744   ,\n",
       "            0.74    , 0.731   , 0.7246  , 0.724   , 0.7183  , 0.717   ,\n",
       "            0.6997  , 0.6987  , 0.6943  , 0.692   , 0.684   , 0.682   ,\n",
       "            0.667   , 0.663   , 0.6567  , 0.62    , 0.6157  , 0.601   ,\n",
       "            0.5767  , 0.5557  , 0.553   , 0.5415  , 0.54    , 0.5396  ,\n",
       "            0.5386  , 0.522   , 0.5186  , 0.4968  , 0.4922  , 0.488   ,\n",
       "            0.4844  , 0.4836  , 0.4717  , 0.4678  , 0.4614  , 0.4546  ,\n",
       "            0.4512  , 0.448   , 0.44    , 0.4294  , 0.42    , 0.4187  ,\n",
       "            0.416   , 0.381   , 0.3804  , 0.3772  , 0.3767  , 0.373   ,\n",
       "            0.3708  , 0.3652  , 0.3638  , 0.358   , 0.3499  , 0.348   ,\n",
       "            0.3374  , 0.3335  , 0.328   , 0.3252  , 0.3228  , 0.3193  ,\n",
       "            0.3171  , 0.3167  , 0.31    , 0.305   , 0.289   , 0.2878  ,\n",
       "            0.283   , 0.2766  , 0.2751  , 0.2617  , 0.2578  , 0.2527  ,\n",
       "            0.252   , 0.2502  , 0.2493  , 0.2434  , 0.2417  , 0.2402  ,\n",
       "            0.239   , 0.2343  , 0.2185  , 0.2173  , 0.2166  , 0.212   ,\n",
       "            0.2086  , 0.2085  , 0.1964  , 0.1901  , 0.1874  , 0.1829  ,\n",
       "            0.1771  , 0.1748  , 0.1746  , 0.1675  , 0.1672  , 0.1671  ,\n",
       "            0.1614  , 0.1528  , 0.152   , 0.1497  , 0.1488  , 0.1426  ,\n",
       "            0.141   , 0.1399  , 0.1395  , 0.138   , 0.1372  , 0.1346  ,\n",
       "            0.134   , 0.1292  , 0.1266  , 0.1256  , 0.1243  , 0.12305 ,\n",
       "            0.1213  , 0.121   , 0.1201  , 0.1197  , 0.1186  , 0.11597 ,\n",
       "            0.1136  , 0.1134  , 0.111   , 0.1045  , 0.0972  , 0.09686 ,\n",
       "            0.0945  , 0.0933  , 0.09283 , 0.0927  , 0.0896  , 0.0879  ,\n",
       "            0.0874  , 0.0854  , 0.08374 , 0.08124 , 0.0712  , 0.0673  ,\n",
       "            0.0656  , 0.0627  , 0.05664 , 0.05225 , 0.04492 , 0.04208 ,\n",
       "            0.04147 , 0.03912 , 0.03812 , 0.03198 , 0.02419 , 0.02194 ,\n",
       "            0.01628 , 0.006985], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.08955224, dtype=float32),\n",
       "    'tpr': array(0.92241377, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.08955224, 0.08955224,\n",
       "            0.09701493, 0.09701493, 0.09701493, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.1716418 , 0.1716418 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.23275863,\n",
       "            0.2413793 , 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31896552, 0.3275862 , 0.3448276 , 0.35344827,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.75      , 0.7586207 , 0.7586207 ,\n",
       "            0.76724136, 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9976  , 0.9956  , 0.9927  , 0.992   , 0.99    ,\n",
       "            0.9897  , 0.9883  , 0.988   , 0.9873  , 0.9863  , 0.986   ,\n",
       "            0.9854  , 0.985   , 0.984   , 0.9834  , 0.983   , 0.981   ,\n",
       "            0.98    , 0.9795  , 0.9775  , 0.977   , 0.9766  , 0.9746  ,\n",
       "            0.974   , 0.971   , 0.9707  , 0.9688  , 0.966   , 0.9653  ,\n",
       "            0.964   , 0.9634  , 0.961   , 0.96    , 0.959   , 0.9546  ,\n",
       "            0.953   , 0.9473  , 0.9453  , 0.944   , 0.9434  , 0.94    ,\n",
       "            0.9355  , 0.9297  , 0.9263  , 0.9233  , 0.918   , 0.916   ,\n",
       "            0.9146  , 0.914   , 0.911   , 0.9106  , 0.9097  , 0.909   ,\n",
       "            0.907   , 0.904   , 0.903   , 0.902   , 0.895   , 0.889   ,\n",
       "            0.887   , 0.884   , 0.8833  , 0.8823  , 0.881   , 0.8774  ,\n",
       "            0.8726  , 0.871   , 0.8623  , 0.854   , 0.8438  , 0.837   ,\n",
       "            0.833   , 0.8306  , 0.823   , 0.8174  , 0.812   , 0.803   ,\n",
       "            0.7993  , 0.762   , 0.736   , 0.7314  , 0.731   , 0.7295  ,\n",
       "            0.7266  , 0.721   , 0.713   , 0.7124  , 0.7085  , 0.6953  ,\n",
       "            0.6875  , 0.6807  , 0.678   , 0.6772  , 0.6655  , 0.661   ,\n",
       "            0.644   , 0.637   , 0.5986  , 0.594   , 0.5903  , 0.5596  ,\n",
       "            0.5376  , 0.5337  , 0.532   , 0.5273  , 0.5205  , 0.512   ,\n",
       "            0.502   , 0.4922  , 0.4893  , 0.4841  , 0.4783  , 0.4758  ,\n",
       "            0.4612  , 0.4563  , 0.4487  , 0.4458  , 0.4417  , 0.4414  ,\n",
       "            0.4382  , 0.4258  , 0.4194  , 0.4062  , 0.4038  , 0.3997  ,\n",
       "            0.399   , 0.3706  , 0.368   , 0.3586  , 0.3582  , 0.3572  ,\n",
       "            0.3542  , 0.353   , 0.3508  , 0.3428  , 0.3362  , 0.327   ,\n",
       "            0.3235  , 0.3179  , 0.3135  , 0.3098  , 0.3064  , 0.3057  ,\n",
       "            0.3008  , 0.2986  , 0.2979  , 0.2866  , 0.2812  , 0.273   ,\n",
       "            0.272   , 0.2705  , 0.261   , 0.2607  , 0.2477  , 0.2424  ,\n",
       "            0.2383  , 0.2375  , 0.2374  , 0.2332  , 0.2328  , 0.2323  ,\n",
       "            0.2281  , 0.2261  , 0.2257  , 0.223   , 0.2042  , 0.2032  ,\n",
       "            0.2007  , 0.1982  , 0.1971  , 0.1779  , 0.177   , 0.1714  ,\n",
       "            0.1661  , 0.1643  , 0.1611  , 0.1577  , 0.1571  , 0.156   ,\n",
       "            0.1526  , 0.15    , 0.1426  , 0.1409  , 0.1366  , 0.1356  ,\n",
       "            0.1302  , 0.13    , 0.1289  , 0.128   , 0.1262  , 0.1254  ,\n",
       "            0.1251  , 0.12213 , 0.1204  , 0.1186  , 0.11597 , 0.1126  ,\n",
       "            0.11127 , 0.111   , 0.1099  , 0.1097  , 0.1095  , 0.1082  ,\n",
       "            0.10394 , 0.1034  , 0.1032  , 0.10016 , 0.09485 , 0.09186 ,\n",
       "            0.0879  , 0.0874  , 0.08527 , 0.08374 , 0.0828  , 0.0806  ,\n",
       "            0.07947 , 0.0786  , 0.07697 , 0.07556 , 0.07263 , 0.06323 ,\n",
       "            0.05954 , 0.05865 , 0.05612 , 0.05023 , 0.0468  , 0.0397  ,\n",
       "            0.03754 , 0.0365  , 0.0346  , 0.03333 , 0.02802 , 0.02121 ,\n",
       "            0.01924 , 0.014175, 0.00598 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.08955224, dtype=float32),\n",
       "    'tpr': array(0.9137931, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.08955224, 0.08955224, 0.09701493, 0.09701493, 0.09701493,\n",
       "            0.09701493, 0.10447761, 0.11940298, 0.12686567, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.15671642,\n",
       "            0.15671642, 0.1716418 , 0.17910448, 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12931034, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.51724136, 0.5258621 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.7844828 , 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.8189655 , 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9976 , 0.996  , 0.9956 , 0.9927 , 0.992  , 0.99   ,\n",
       "            0.9897 , 0.989  , 0.9873 , 0.9863 , 0.986  , 0.9854 , 0.985  ,\n",
       "            0.982  , 0.979  , 0.9785 , 0.978  , 0.9766 , 0.9756 , 0.973  ,\n",
       "            0.9727 , 0.972  , 0.9717 , 0.971  , 0.9697 , 0.9683 , 0.9673 ,\n",
       "            0.967  , 0.965  , 0.9624 , 0.962  , 0.9614 , 0.959  , 0.9585 ,\n",
       "            0.956  , 0.9556 , 0.9507 , 0.9487 , 0.9463 , 0.9395 , 0.937  ,\n",
       "            0.9346 , 0.9253 , 0.925  , 0.923  , 0.912  , 0.9116 , 0.911  ,\n",
       "            0.9106 , 0.9087 , 0.908  , 0.9062 , 0.904  , 0.9    , 0.8975 ,\n",
       "            0.895  , 0.8906 , 0.888  , 0.884  , 0.8823 , 0.881  , 0.8765 ,\n",
       "            0.876  , 0.872  , 0.869  , 0.866  , 0.855  , 0.845  , 0.8447 ,\n",
       "            0.84   , 0.8276 , 0.8247 , 0.8213 , 0.819  , 0.8013 , 0.799  ,\n",
       "            0.7896 , 0.7607 , 0.736  , 0.7305 , 0.7275 , 0.7217 , 0.709  ,\n",
       "            0.708  , 0.6978 , 0.692  , 0.6787 , 0.6763 , 0.6733 , 0.667  ,\n",
       "            0.6646 , 0.659  , 0.6436 , 0.643  , 0.6226 , 0.5977 , 0.593  ,\n",
       "            0.569  , 0.555  , 0.5312 , 0.5166 , 0.515  , 0.5117 , 0.5054 ,\n",
       "            0.4973 , 0.4902 , 0.474  , 0.4666 , 0.46   , 0.4558 , 0.4412 ,\n",
       "            0.429  , 0.4285 , 0.4219 , 0.42   , 0.4175 , 0.408  , 0.4036 ,\n",
       "            0.3936 , 0.3926 , 0.385  , 0.3496 , 0.349  , 0.3435 , 0.3403 ,\n",
       "            0.335  , 0.333  , 0.3281 , 0.3237 , 0.3208 , 0.3127 , 0.3088 ,\n",
       "            0.3074 , 0.306  , 0.3047 , 0.3035 , 0.2966 , 0.2937 , 0.2837 ,\n",
       "            0.2817 , 0.2793 , 0.2776 , 0.2766 , 0.263  , 0.258  , 0.2467 ,\n",
       "            0.2462 , 0.2433 , 0.2306 , 0.2283 , 0.2274 , 0.2273 , 0.2269 ,\n",
       "            0.2238 , 0.2156 , 0.212  , 0.2118 , 0.2114 , 0.2081 , 0.2042 ,\n",
       "            0.1931 , 0.1898 , 0.1859 , 0.1852 , 0.1833 , 0.1796 , 0.1726 ,\n",
       "            0.167  , 0.1644 , 0.16   , 0.1549 , 0.1523 , 0.1484 , 0.1465 ,\n",
       "            0.1426 , 0.1404 , 0.1393 , 0.1279 , 0.1278 , 0.1245 , 0.1235 ,\n",
       "            0.1226 , 0.12103, 0.1192 , 0.11755, 0.1166 , 0.11633, 0.1124 ,\n",
       "            0.112  , 0.1097 , 0.1082 , 0.1076 , 0.1065 , 0.10596, 0.103  ,\n",
       "            0.1023 , 0.10175, 0.1005 , 0.10016, 0.0997 , 0.09827, 0.09534,\n",
       "            0.0932 , 0.0901 , 0.0873 , 0.0865 , 0.0804 , 0.07947, 0.0775 ,\n",
       "            0.0774 , 0.0753 , 0.07306, 0.07263, 0.0712 , 0.06995, 0.06915,\n",
       "            0.0677 , 0.0656 , 0.05676, 0.0533 , 0.05225, 0.05005, 0.044  ,\n",
       "            0.04138, 0.03476, 0.03302, 0.03174, 0.0305 , 0.0287 , 0.02414,\n",
       "            0.01837, 0.01659, 0.01219, 0.00508], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.05970149, dtype=float32),\n",
       "    'tpr': array(0.9051724, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.08955224, 0.08955224, 0.09701493, 0.09701493, 0.09701493,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.11940298, 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.15671642, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.09482758, 0.11206897, 0.12931034, 0.13793103, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.35344827,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9976  , 0.996   , 0.9956  , 0.9927  , 0.9917  ,\n",
       "            0.9897  , 0.9893  , 0.9883  , 0.987   , 0.986   , 0.9854  ,\n",
       "            0.9844  , 0.9814  , 0.981   , 0.9785  , 0.9775  , 0.977   ,\n",
       "            0.976   , 0.975   , 0.9746  , 0.972   , 0.9717  , 0.971   ,\n",
       "            0.9707  , 0.969   , 0.9673  , 0.9663  , 0.966   , 0.9644  ,\n",
       "            0.9634  , 0.961   , 0.9604  , 0.96    , 0.9565  , 0.9546  ,\n",
       "            0.949   , 0.9473  , 0.945   , 0.936   , 0.9355  , 0.935   ,\n",
       "            0.934   , 0.931   , 0.9224  , 0.9204  , 0.9194  , 0.909   ,\n",
       "            0.908   , 0.9077  , 0.9053  , 0.905   , 0.904   , 0.9033  ,\n",
       "            0.903   , 0.9004  , 0.8975  , 0.893   , 0.891   , 0.887   ,\n",
       "            0.886   , 0.8813  , 0.879   , 0.877   , 0.8745  , 0.874   ,\n",
       "            0.8696  , 0.8677  , 0.867   , 0.86    , 0.847   , 0.838   ,\n",
       "            0.8335  , 0.8286  , 0.817   , 0.8145  , 0.8115  , 0.809   ,\n",
       "            0.791   , 0.7896  , 0.7803  , 0.752   , 0.722   , 0.7183  ,\n",
       "            0.717   , 0.706   , 0.6934  , 0.693   , 0.687   , 0.679   ,\n",
       "            0.664   , 0.659   , 0.658   , 0.657   , 0.648   , 0.6475  ,\n",
       "            0.635   , 0.624   , 0.621   , 0.6016  , 0.5757  , 0.571   ,\n",
       "            0.5522  , 0.5376  , 0.515   , 0.4988  , 0.4954  , 0.4922  ,\n",
       "            0.4885  , 0.4832  , 0.4768  , 0.4631  , 0.456   , 0.4448  ,\n",
       "            0.4404  , 0.426   , 0.4182  , 0.4062  , 0.406   , 0.3958  ,\n",
       "            0.3948  , 0.391   , 0.3909  , 0.385   , 0.3823  , 0.3728  ,\n",
       "            0.3723  , 0.3665  , 0.3628  , 0.3315  , 0.3225  , 0.322   ,\n",
       "            0.3203  , 0.3176  , 0.311   , 0.3035  , 0.294   , 0.2925  ,\n",
       "            0.2913  , 0.289   , 0.2856  , 0.2847  , 0.2805  , 0.2795  ,\n",
       "            0.2742  , 0.2683  , 0.2646  , 0.258   , 0.2534  , 0.2527  ,\n",
       "            0.2487  , 0.2458  , 0.241   , 0.2297  , 0.2268  , 0.2144  ,\n",
       "            0.214   , 0.2125  , 0.2114  , 0.2106  , 0.2094  , 0.2076  ,\n",
       "            0.1979  , 0.1973  , 0.1959  , 0.1844  , 0.1782  , 0.1758  ,\n",
       "            0.172   , 0.1685  , 0.1592  , 0.159   , 0.1554  , 0.1536  ,\n",
       "            0.1484  , 0.1469  , 0.143   , 0.1384  , 0.1355  , 0.1306  ,\n",
       "            0.1267  , 0.1263  , 0.12476 , 0.1223  , 0.1188  , 0.113   ,\n",
       "            0.112   , 0.1078  , 0.1063  , 0.10284 , 0.10266 , 0.0991  ,\n",
       "            0.09753 , 0.09503 , 0.0939  , 0.0933  , 0.09283 , 0.0922  ,\n",
       "            0.09155 , 0.089   , 0.0879  , 0.0863  , 0.0857  , 0.0856  ,\n",
       "            0.0845  , 0.082   , 0.08093 , 0.0742  , 0.0732  , 0.06793 ,\n",
       "            0.0678  , 0.0667  , 0.0651  , 0.0649  , 0.06464 , 0.0645  ,\n",
       "            0.06232 , 0.0621  , 0.06085 , 0.0543  , 0.04663 , 0.0463  ,\n",
       "            0.04468 , 0.04337 , 0.0389  , 0.03732 , 0.03067 , 0.02965 ,\n",
       "            0.02791 , 0.02707 , 0.02513 , 0.02112 , 0.01622 , 0.01467 ,\n",
       "            0.010735, 0.004383], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.05223881, dtype=float32),\n",
       "    'tpr': array(0.9051724, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.09701493, 0.09701493, 0.09701493,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.11940298, 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.15671642, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.09482758, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.7586207 , 0.7586207 , 0.76724136, 0.7844828 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9976  , 0.996   , 0.9956  , 0.992   , 0.991   ,\n",
       "            0.9893  , 0.989   , 0.988   , 0.9863  , 0.985   , 0.9844  ,\n",
       "            0.984   , 0.9834  , 0.9805  , 0.98    , 0.9795  , 0.978   ,\n",
       "            0.976   , 0.9756  , 0.975   , 0.974   , 0.973   , 0.971   ,\n",
       "            0.97    , 0.9697  , 0.969   , 0.9688  , 0.9673  , 0.965   ,\n",
       "            0.964   , 0.9634  , 0.962   , 0.961   , 0.9585  , 0.958   ,\n",
       "            0.9565  , 0.953   , 0.952   , 0.9517  , 0.9473  , 0.944   ,\n",
       "            0.942   , 0.932   , 0.9316  , 0.9307  , 0.9263  , 0.9175  ,\n",
       "            0.917   , 0.914   , 0.904   , 0.9033  , 0.9023  , 0.899   ,\n",
       "            0.8984  , 0.8975  , 0.897   , 0.8916  , 0.8877  , 0.883   ,\n",
       "            0.8794  , 0.879   , 0.8745  , 0.8706  , 0.868   , 0.8667  ,\n",
       "            0.8623  , 0.8594  , 0.859   , 0.853   , 0.8506  , 0.839   ,\n",
       "            0.8267  , 0.8223  , 0.813   , 0.8037  , 0.8013  , 0.8003  ,\n",
       "            0.7954  , 0.7783  , 0.778   , 0.7666  , 0.739   , 0.7036  ,\n",
       "            0.701   , 0.6865  , 0.679   , 0.673   , 0.6675  , 0.6616  ,\n",
       "            0.641   , 0.6406  , 0.6396  , 0.6377  , 0.627   , 0.624   ,\n",
       "            0.613   , 0.601   , 0.6     , 0.5767  , 0.55    , 0.5444  ,\n",
       "            0.5312  , 0.5166  , 0.495   , 0.482   , 0.47    , 0.4668  ,\n",
       "            0.4658  , 0.4526  , 0.452   , 0.4395  , 0.433   , 0.4255  ,\n",
       "            0.4226  , 0.4019  , 0.3918  , 0.387   , 0.3801  , 0.3743  ,\n",
       "            0.3687  , 0.368   , 0.3625  , 0.3594  , 0.3572  , 0.3499  ,\n",
       "            0.3496  , 0.3472  , 0.3376  , 0.3127  , 0.3022  , 0.2998  ,\n",
       "            0.298   , 0.2961  , 0.2869  , 0.2825  , 0.279   , 0.2751  ,\n",
       "            0.2744  , 0.2688  , 0.2646  , 0.2615  , 0.2588  , 0.257   ,\n",
       "            0.2444  , 0.2434  , 0.2346  , 0.2311  , 0.229   , 0.2286  ,\n",
       "            0.2277  , 0.2238  , 0.213   , 0.2098  , 0.1981  , 0.1974  ,\n",
       "            0.1971  , 0.1968  , 0.1943  , 0.1915  , 0.1887  , 0.1824  ,\n",
       "            0.1797  , 0.1791  , 0.1654  , 0.1614  , 0.1603  , 0.1552  ,\n",
       "            0.1525  , 0.1428  , 0.1414  , 0.1388  , 0.136   , 0.134   ,\n",
       "            0.1313  , 0.1276  , 0.12366 , 0.11993 , 0.119   , 0.1134  ,\n",
       "            0.112   , 0.10876 , 0.10724 , 0.10144 , 0.1005  , 0.0957  ,\n",
       "            0.09503 , 0.09467 , 0.09235 , 0.0885  , 0.0876  , 0.08527 ,\n",
       "            0.08496 , 0.0836  , 0.08344 , 0.0823  , 0.0821  , 0.0806  ,\n",
       "            0.0798  , 0.07935 , 0.07825 , 0.0778  , 0.07684 , 0.07654 ,\n",
       "            0.076   , 0.07367 , 0.07263 , 0.07184 , 0.0643  , 0.0637  ,\n",
       "            0.06042 , 0.05966 , 0.05823 , 0.0577  , 0.05664 , 0.05655 ,\n",
       "            0.0553  , 0.0548  , 0.0541  , 0.05283 , 0.0469  , 0.04138 ,\n",
       "            0.0397  , 0.0395  , 0.03705 , 0.0339  , 0.03296 , 0.0267  ,\n",
       "            0.02611 , 0.02414 , 0.0237  , 0.0217  , 0.0183  , 0.014175,\n",
       "            0.012726, 0.00927 , 0.00375 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04477612, dtype=float32),\n",
       "    'tpr': array(0.8965517, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.09701493, 0.09701493, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14179105, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.1637931 , 0.1724138 , 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9976  , 0.996   , 0.9956  , 0.992   , 0.991   ,\n",
       "            0.9893  , 0.988   , 0.9873  , 0.985   , 0.9844  , 0.984   ,\n",
       "            0.9834  , 0.9824  , 0.982   , 0.979   , 0.9785  , 0.9756  ,\n",
       "            0.972   , 0.9717  , 0.971   , 0.9697  , 0.969   , 0.9688  ,\n",
       "            0.9673  , 0.967   , 0.9653  , 0.964   , 0.963   , 0.9624  ,\n",
       "            0.9614  , 0.9604  , 0.9595  , 0.9565  , 0.955   , 0.954   ,\n",
       "            0.9517  , 0.951   , 0.9507  , 0.9424  , 0.942   , 0.94    ,\n",
       "            0.9233  , 0.9224  , 0.9204  , 0.9194  , 0.9136  , 0.9097  ,\n",
       "            0.9014  , 0.901   , 0.899   , 0.895   , 0.893   , 0.888   ,\n",
       "            0.8853  , 0.8843  , 0.884   , 0.8823  , 0.877   , 0.8755  ,\n",
       "            0.8745  , 0.865   , 0.863   , 0.862   , 0.8613  , 0.858   ,\n",
       "            0.854   , 0.853   , 0.8506  , 0.845   , 0.84    , 0.838   ,\n",
       "            0.8296  , 0.821   , 0.8184  , 0.801   , 0.7983  , 0.793   ,\n",
       "            0.7886  , 0.7847  , 0.7803  , 0.77    , 0.753   , 0.743   ,\n",
       "            0.7295  , 0.6904  , 0.689   , 0.6885  , 0.6704  , 0.656   ,\n",
       "            0.652   , 0.628   , 0.627   , 0.619   , 0.6113  , 0.6094  ,\n",
       "            0.604   , 0.6035  , 0.592   , 0.579   , 0.5703  , 0.5625  ,\n",
       "            0.5547  , 0.527   , 0.521   , 0.4998  , 0.4985  , 0.4792  ,\n",
       "            0.4539  , 0.448   , 0.4424  , 0.4363  , 0.4316  , 0.423   ,\n",
       "            0.4124  , 0.4058  , 0.3938  , 0.3936  , 0.3687  , 0.3586  ,\n",
       "            0.3572  , 0.3555  , 0.346   , 0.3376  , 0.3362  , 0.3337  ,\n",
       "            0.3298  , 0.329   , 0.328   , 0.3208  , 0.3157  , 0.3105  ,\n",
       "            0.2878  , 0.2788  , 0.2761  , 0.2683  , 0.2654  , 0.2622  ,\n",
       "            0.2607  , 0.2583  , 0.2554  , 0.254   , 0.2445  , 0.2407  ,\n",
       "            0.2257  , 0.2203  , 0.2195  , 0.2172  , 0.217   , 0.2129  ,\n",
       "            0.2128  , 0.2123  , 0.2073  , 0.206   , 0.1962  , 0.1947  ,\n",
       "            0.1927  , 0.189   , 0.1821  , 0.1803  , 0.1799  , 0.1781  ,\n",
       "            0.1764  , 0.1711  , 0.1653  , 0.1622  , 0.1603  , 0.1598  ,\n",
       "            0.1543  , 0.1458  , 0.138   , 0.1348  , 0.1343  , 0.1316  ,\n",
       "            0.1197  , 0.1172  , 0.11694 , 0.11554 , 0.1134  , 0.11316 ,\n",
       "            0.1097  , 0.1056  , 0.1052  , 0.1009  , 0.1     , 0.094   ,\n",
       "            0.0903  , 0.0901  , 0.0893  , 0.0883  , 0.08344 , 0.083   ,\n",
       "            0.0802  , 0.0753  , 0.0749  , 0.07367 , 0.07263 , 0.07196 ,\n",
       "            0.07184 , 0.0716  , 0.06854 , 0.0678  , 0.0672  , 0.0671  ,\n",
       "            0.06683 , 0.0666  , 0.06586 , 0.0649  , 0.06464 , 0.0644  ,\n",
       "            0.06323 , 0.0629  , 0.06198 , 0.0537  , 0.0535  , 0.053   ,\n",
       "            0.05023 , 0.05005 , 0.0496  , 0.04858 , 0.04822 , 0.04794 ,\n",
       "            0.04733 , 0.0469  , 0.04578 , 0.04346 , 0.0384  , 0.03607 ,\n",
       "            0.03442 , 0.03204 , 0.02975 , 0.02937 , 0.02838 , 0.02303 ,\n",
       "            0.02237 , 0.0208  , 0.02042 , 0.01862 , 0.0156  , 0.012054,\n",
       "            0.01082 , 0.007812, 0.00311 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04477612, dtype=float32),\n",
       "    'tpr': array(0.88793105, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05970149, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.09701493, 0.09701493, 0.09701493, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.11940298, 0.12686567, 0.12686567,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7238806 , 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.10344828, 0.11206897, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.18103448, 0.19827586,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.2672414 ,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.997   , 0.996   , 0.9956  , 0.9917  , 0.9907  ,\n",
       "            0.989   , 0.9873  , 0.9854  , 0.984   , 0.9834  , 0.9824  ,\n",
       "            0.982   , 0.9795  , 0.978   , 0.9756  , 0.9727  , 0.971   ,\n",
       "            0.9683  , 0.9673  , 0.967   , 0.9653  , 0.965   , 0.963   ,\n",
       "            0.961   , 0.96    , 0.958   , 0.9575  , 0.9546  , 0.9536  ,\n",
       "            0.9526  , 0.9487  , 0.9478  , 0.9473  , 0.9463  , 0.94    ,\n",
       "            0.9375  , 0.935   , 0.917   , 0.912   , 0.91    , 0.909   ,\n",
       "            0.908   , 0.9062  , 0.8984  , 0.8965  , 0.894   , 0.889   ,\n",
       "            0.8857  , 0.8804  , 0.8784  , 0.8755  , 0.8677  , 0.866   ,\n",
       "            0.8633  , 0.861   , 0.86    , 0.858   , 0.854   , 0.846   ,\n",
       "            0.8403  , 0.84    , 0.839   , 0.835   , 0.831   , 0.8257  ,\n",
       "            0.82    , 0.818   , 0.8086  , 0.8057  , 0.8003  , 0.787   ,\n",
       "            0.776   , 0.7744  , 0.772   , 0.771   , 0.758   , 0.756   ,\n",
       "            0.7256  , 0.716   , 0.7114  , 0.675   , 0.6724  , 0.672   ,\n",
       "            0.6445  , 0.637   , 0.6216  , 0.5986  , 0.592   , 0.59    ,\n",
       "            0.585   , 0.579   , 0.5723  , 0.5654  , 0.5576  , 0.543   ,\n",
       "            0.527   , 0.523   , 0.522   , 0.504   , 0.4978  , 0.4778  ,\n",
       "            0.461   , 0.4592  , 0.425   , 0.424   , 0.4092  , 0.4084  ,\n",
       "            0.3984  , 0.3972  , 0.3843  , 0.3806  , 0.3645  , 0.3613  ,\n",
       "            0.3352  , 0.3245  , 0.3242  , 0.319   , 0.3127  , 0.309   ,\n",
       "            0.308   , 0.306   , 0.304   , 0.3035  , 0.2915  , 0.291   ,\n",
       "            0.2832  , 0.2659  , 0.2605  , 0.2542  , 0.247   , 0.2448  ,\n",
       "            0.2383  , 0.2363  , 0.2351  , 0.2316  , 0.2278  , 0.2249  ,\n",
       "            0.2242  , 0.2123  , 0.2007  , 0.1959  , 0.1954  , 0.1941  ,\n",
       "            0.1909  , 0.1904  , 0.1885  , 0.186   , 0.1841  , 0.1774  ,\n",
       "            0.1753  , 0.1671  , 0.1663  , 0.1646  , 0.1638  , 0.1636  ,\n",
       "            0.1608  , 0.1569  , 0.1565  , 0.1558  , 0.1467  , 0.1409  ,\n",
       "            0.1393  , 0.137   , 0.1284  , 0.1257  , 0.1226  , 0.1198  ,\n",
       "            0.111   , 0.10913 , 0.1065  , 0.10284 , 0.1025  , 0.1005  ,\n",
       "            0.09753 , 0.0972  , 0.094   , 0.0935  , 0.0933  , 0.0922  ,\n",
       "            0.0882  , 0.0866  , 0.0792  , 0.0775  , 0.07666 , 0.07355 ,\n",
       "            0.0729  , 0.07275 , 0.07007 , 0.06573 , 0.0631  , 0.0628  ,\n",
       "            0.06256 , 0.06052 , 0.06042 , 0.05997 , 0.05988 , 0.0592  ,\n",
       "            0.0578  , 0.0577  , 0.05582 , 0.0552  , 0.0548  , 0.0543  ,\n",
       "            0.0539  , 0.0533  , 0.0531  , 0.05185 , 0.0461  , 0.0452  ,\n",
       "            0.0451  , 0.04248 , 0.04208 , 0.04132 , 0.04053 , 0.0403  ,\n",
       "            0.04    , 0.03995 , 0.03912 , 0.03607 , 0.03168 , 0.03033 ,\n",
       "            0.02887 , 0.0262  , 0.02434 , 0.02405 , 0.02347 , 0.01883 ,\n",
       "            0.0184  , 0.01692 , 0.015015, 0.01267 , 0.00982 , 0.00878 ,\n",
       "            0.006313, 0.002472], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.03731343, dtype=float32),\n",
       "    'tpr': array(0.86206895, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.08955224, 0.08955224, 0.09701493, 0.09701493,\n",
       "            0.10447761, 0.10447761, 0.1119403 , 0.1119403 , 0.11940298,\n",
       "            0.11940298, 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.7089552 , 0.7164179 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.10344828, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.19827586,\n",
       "            0.20689656, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5948276 , 0.6034483 , 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.8534483 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9966  , 0.9946  , 0.994   , 0.989   , 0.988   ,\n",
       "            0.986   , 0.985   , 0.984   , 0.9805  , 0.9795  , 0.9785  ,\n",
       "            0.978   , 0.9775  , 0.974   , 0.9717  , 0.9688  , 0.9673  ,\n",
       "            0.965   , 0.9644  , 0.9624  , 0.961   , 0.9604  , 0.96    ,\n",
       "            0.958   , 0.9575  , 0.955   , 0.9517  , 0.951   , 0.95    ,\n",
       "            0.9463  , 0.9453  , 0.943   , 0.94    , 0.938   , 0.934   ,\n",
       "            0.9316  , 0.93    , 0.9277  , 0.925   , 0.9067  , 0.9033  ,\n",
       "            0.9004  , 0.8984  , 0.898   , 0.8926  , 0.8896  , 0.877   ,\n",
       "            0.8765  , 0.874   , 0.8735  , 0.8687  , 0.867   , 0.858   ,\n",
       "            0.856   , 0.852   , 0.851   , 0.849   , 0.8477  , 0.843   ,\n",
       "            0.831   , 0.8267  , 0.824   , 0.8237  , 0.82    , 0.8193  ,\n",
       "            0.814   , 0.809   , 0.8037  , 0.79    , 0.787   , 0.7734  ,\n",
       "            0.7524  , 0.7397  , 0.7393  , 0.732   , 0.7314  , 0.731   ,\n",
       "            0.7227  , 0.7065  , 0.691   , 0.677   , 0.6353  , 0.6284  ,\n",
       "            0.622   , 0.6     , 0.5933  , 0.584   , 0.566   , 0.556   ,\n",
       "            0.555   , 0.5444  , 0.538   , 0.5376  , 0.5137  , 0.507   ,\n",
       "            0.5005  , 0.4956  , 0.4941  , 0.4636  , 0.4448  , 0.4382  ,\n",
       "            0.4326  , 0.4321  , 0.4185  , 0.4014  , 0.3733  , 0.371   ,\n",
       "            0.3623  , 0.3608  , 0.3535  , 0.3416  , 0.3367  , 0.3333  ,\n",
       "            0.3208  , 0.3005  , 0.2893  , 0.2847  , 0.277   , 0.2751  ,\n",
       "            0.2693  , 0.2673  , 0.2656  , 0.2634  , 0.2632  , 0.2617  ,\n",
       "            0.2605  , 0.2362  , 0.236   , 0.2334  , 0.2263  , 0.2229  ,\n",
       "            0.2216  , 0.2142  , 0.2128  , 0.2096  , 0.2065  , 0.2028  ,\n",
       "            0.2012  , 0.193   , 0.1737  , 0.1719  , 0.1709  , 0.1646  ,\n",
       "            0.1631  , 0.1617  , 0.1594  , 0.1578  , 0.1566  , 0.1523  ,\n",
       "            0.1499  , 0.1497  , 0.1489  , 0.147   , 0.1466  , 0.1422  ,\n",
       "            0.1421  , 0.1403  , 0.1381  , 0.1377  , 0.1284  , 0.128   ,\n",
       "            0.1214  , 0.121   , 0.1144  , 0.1105  , 0.1076  , 0.1052  ,\n",
       "            0.0935  , 0.0933  , 0.09235 , 0.0887  , 0.08344 , 0.082   ,\n",
       "            0.08124 , 0.0805  , 0.0804  , 0.07904 , 0.0785  , 0.07684 ,\n",
       "            0.07556 , 0.0742  , 0.07135 , 0.0684  , 0.0641  , 0.06323 ,\n",
       "            0.06143 , 0.06085 , 0.06064 , 0.05865 , 0.058   , 0.0532  ,\n",
       "            0.05243 , 0.05194 , 0.05154 , 0.0496  , 0.0494  , 0.04877 ,\n",
       "            0.04794 , 0.0477  , 0.0457  , 0.0456  , 0.0451  , 0.045   ,\n",
       "            0.04468 , 0.04385 , 0.0437  , 0.04327 , 0.04224 , 0.04218 ,\n",
       "            0.0376  , 0.0367  , 0.0355  , 0.03455 , 0.03436 , 0.0343  ,\n",
       "            0.03314 , 0.03253 , 0.0315  , 0.03143 , 0.03067 , 0.02881 ,\n",
       "            0.0286  , 0.02509 , 0.0248  , 0.02365 , 0.02045 , 0.01953 ,\n",
       "            0.0188  , 0.01877 , 0.01525 , 0.0149  , 0.01369 , 0.01317 ,\n",
       "            0.01147 , 0.009895, 0.00803 , 0.00715 , 0.00508 , 0.001942],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.02238806, dtype=float32),\n",
       "    'tpr': array(0.8534483, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.09701493, 0.10447761,\n",
       "            0.10447761, 0.10447761, 0.1119403 , 0.1119403 , 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18965517, 0.20689656, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.8534483 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.996   , 0.9946  , 0.9937  , 0.9873  , 0.986   ,\n",
       "            0.9844  , 0.983   , 0.9824  , 0.978   , 0.977   , 0.976   ,\n",
       "            0.9756  , 0.975   , 0.974   , 0.97    , 0.9688  , 0.9663  ,\n",
       "            0.963   , 0.962   , 0.958   , 0.9575  , 0.9565  , 0.9546  ,\n",
       "            0.954   , 0.9507  , 0.9478  , 0.9473  , 0.945   , 0.941   ,\n",
       "            0.937   , 0.9336  , 0.932   , 0.9316  , 0.924   , 0.9224  ,\n",
       "            0.921   , 0.9175  , 0.8936  , 0.8896  , 0.8857  , 0.8833  ,\n",
       "            0.883   , 0.879   , 0.874   , 0.8623  , 0.862   , 0.859   ,\n",
       "            0.8574  , 0.855   , 0.8525  , 0.839   , 0.834   , 0.831   ,\n",
       "            0.8306  , 0.8296  , 0.828   , 0.8257  , 0.815   , 0.806   ,\n",
       "            0.805   , 0.8037  , 0.8027  , 0.8003  , 0.7974  , 0.7915  ,\n",
       "            0.787   , 0.7793  , 0.764   , 0.7627  , 0.752   , 0.724   ,\n",
       "            0.713   , 0.711   , 0.7056  , 0.705   , 0.6987  , 0.6973  ,\n",
       "            0.6772  , 0.6465  , 0.64    , 0.607   , 0.5986  , 0.5903  ,\n",
       "            0.569   , 0.5503  , 0.548   , 0.532   , 0.524   , 0.519   ,\n",
       "            0.5093  , 0.5044  , 0.5034  , 0.4683  , 0.4648  , 0.464   ,\n",
       "            0.4597  , 0.4595  , 0.415   , 0.4077  , 0.4011  , 0.4     ,\n",
       "            0.3872  , 0.381   , 0.3728  , 0.339   , 0.3354  , 0.328   ,\n",
       "            0.321   , 0.315   , 0.3093  , 0.3079  , 0.2957  , 0.285   ,\n",
       "            0.275   , 0.2615  , 0.2515  , 0.2434  , 0.241   , 0.2386  ,\n",
       "            0.2375  , 0.235   , 0.231   , 0.2242  , 0.2238  , 0.2233  ,\n",
       "            0.207   , 0.2043  , 0.1985  , 0.1921  , 0.1918  , 0.19    ,\n",
       "            0.1886  , 0.1864  , 0.1815  , 0.1749  , 0.1653  , 0.1599  ,\n",
       "            0.1523  , 0.1449  , 0.1431  , 0.1409  , 0.1406  , 0.138   ,\n",
       "            0.1371  , 0.1357  , 0.1353  , 0.1351  , 0.1322  , 0.13    ,\n",
       "            0.1299  , 0.1257  , 0.1255  , 0.1251  , 0.12305 , 0.1197  ,\n",
       "            0.1178  , 0.11554 , 0.1101  , 0.1082  , 0.1     , 0.09515 ,\n",
       "            0.09485 , 0.0925  , 0.09235 , 0.0914  , 0.08167 , 0.08093 ,\n",
       "            0.07764 , 0.0775  , 0.07196 , 0.06995 , 0.0693  , 0.06866 ,\n",
       "            0.06793 , 0.06683 , 0.0662  , 0.0655  , 0.06177 , 0.05737 ,\n",
       "            0.05283 , 0.0527  , 0.05252 , 0.05167 , 0.0509  , 0.05032 ,\n",
       "            0.0484  , 0.04453 , 0.04428 , 0.0432  , 0.04263 , 0.04257 ,\n",
       "            0.04062 , 0.0403  , 0.03928 , 0.0387  , 0.03845 , 0.0378  ,\n",
       "            0.0372  , 0.037   , 0.0369  , 0.03644 , 0.03635 , 0.03622 ,\n",
       "            0.03455 , 0.0343  , 0.03067 , 0.03027 , 0.0286  , 0.02785 ,\n",
       "            0.02774 , 0.02759 , 0.02696 , 0.02655 , 0.02606 , 0.02438 ,\n",
       "            0.02373 , 0.02338 , 0.02284 , 0.0206  , 0.01956 , 0.01862 ,\n",
       "            0.01659 , 0.01525 , 0.0149  , 0.014336, 0.01155 , 0.01147 ,\n",
       "            0.0107  , 0.010056, 0.008575, 0.00746 , 0.006004, 0.005344,\n",
       "            0.003796, 0.001399], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.01492537, dtype=float32),\n",
       "    'tpr': array(0.8103448, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.09701493, 0.10447761, 0.10447761, 0.10447761, 0.1119403 ,\n",
       "            0.1119403 , 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8448276 , 0.8534483 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.      , 0.995   , 0.994   , 0.992   , 0.985   , 0.983   ,\n",
       "            0.9814  , 0.981   , 0.976   , 0.9756  , 0.974   , 0.9736  ,\n",
       "            0.972   , 0.9707  , 0.9688  , 0.9683  , 0.966   , 0.963   ,\n",
       "            0.9604  , 0.9595  , 0.9556  , 0.955   , 0.9536  , 0.953   ,\n",
       "            0.9517  , 0.949   , 0.9473  , 0.944   , 0.9424  , 0.942   ,\n",
       "            0.935   , 0.933   , 0.9307  , 0.9272  , 0.9263  , 0.9243  ,\n",
       "            0.917   , 0.912   , 0.9087  , 0.9077  , 0.897   , 0.886   ,\n",
       "            0.8813  , 0.8774  , 0.8745  , 0.8667  , 0.8633  , 0.8584  ,\n",
       "            0.848   , 0.8477  , 0.843   , 0.8423  , 0.8403  , 0.827   ,\n",
       "            0.8223  , 0.818   , 0.817   , 0.8145  , 0.8115  , 0.7993  ,\n",
       "            0.7974  , 0.791   , 0.789   , 0.7886  , 0.788   , 0.785   ,\n",
       "            0.783   , 0.7827  , 0.7764  , 0.7725  , 0.7637  , 0.7476  ,\n",
       "            0.7466  , 0.7295  , 0.705   , 0.694   , 0.685   , 0.68    ,\n",
       "            0.6797  , 0.6714  , 0.6562  , 0.651   , 0.611   , 0.5967  ,\n",
       "            0.5757  , 0.569   , 0.56    , 0.5444  , 0.519   , 0.507   ,\n",
       "            0.499   , 0.492   , 0.4907  , 0.477   , 0.4727  , 0.44    ,\n",
       "            0.4329  , 0.4324  , 0.432   , 0.4058  , 0.376   , 0.3696  ,\n",
       "            0.3691  , 0.358   , 0.3555  , 0.3484  , 0.3374  , 0.3118  ,\n",
       "            0.3096  , 0.2988  , 0.292   , 0.2861  , 0.278   , 0.2676  ,\n",
       "            0.258   , 0.2576  , 0.2527  , 0.2388  , 0.2299  , 0.2166  ,\n",
       "            0.2163  , 0.2144  , 0.1991  , 0.1989  , 0.1919  , 0.1865  ,\n",
       "            0.1855  , 0.1852  , 0.181   , 0.1803  , 0.1752  , 0.1718  ,\n",
       "            0.1654  , 0.164   , 0.1635  , 0.1632  , 0.1621  , 0.1586  ,\n",
       "            0.1447  , 0.1361  , 0.1354  , 0.1289  , 0.1257  , 0.1252  ,\n",
       "            0.12146 , 0.12085 , 0.119   , 0.1184  , 0.11816 , 0.11475 ,\n",
       "            0.1142  , 0.1118  , 0.11163 , 0.11145 , 0.11127 , 0.1097  ,\n",
       "            0.1019  , 0.0997  , 0.0981  , 0.0964  , 0.09467 , 0.0893  ,\n",
       "            0.08386 , 0.08124 , 0.0801  , 0.07544 , 0.0752  , 0.0717  ,\n",
       "            0.0715  , 0.0709  , 0.0678  , 0.0673  , 0.0628  , 0.06042 ,\n",
       "            0.05997 , 0.05865 , 0.05814 , 0.0578  , 0.0572  , 0.05646 ,\n",
       "            0.0533  , 0.0456  , 0.04553 , 0.04492 , 0.04486 , 0.04282 ,\n",
       "            0.04138 , 0.04083 , 0.0403  , 0.0397  , 0.0376  , 0.03732 ,\n",
       "            0.03644 , 0.03616 , 0.03436 , 0.03418 , 0.03366 , 0.03302 ,\n",
       "            0.03253 , 0.03235 , 0.0323  , 0.03223 , 0.03174 , 0.03143 ,\n",
       "            0.03137 , 0.03096 , 0.03091 , 0.03085 , 0.02931 , 0.02806 ,\n",
       "            0.0263  , 0.02547 , 0.0237  , 0.02365 , 0.02225 , 0.02153 ,\n",
       "            0.02148 , 0.02145 , 0.02072 , 0.0195  , 0.0193  , 0.01802 ,\n",
       "            0.01678 , 0.01666 , 0.01495 , 0.01423 , 0.01343 , 0.01224 ,\n",
       "            0.01133 , 0.01045 , 0.00871 , 0.008514, 0.008125, 0.007317,\n",
       "            0.006073, 0.005386, 0.004467, 0.003975, 0.002823, 0.001017],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.01492537, dtype=float32),\n",
       "    'tpr': array(0.79310346, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.09701493, 0.09701493,\n",
       "            0.10447761, 0.10447761, 0.1119403 , 0.1119403 , 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.19402985,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9365e-01, 9.9316e-01, 9.9023e-01, 9.8096e-01,\n",
       "            9.7998e-01, 9.7949e-01, 9.7852e-01, 9.7803e-01, 9.7363e-01,\n",
       "            9.7217e-01, 9.7119e-01, 9.6973e-01, 9.6924e-01, 9.6533e-01,\n",
       "            9.6387e-01, 9.6143e-01, 9.5898e-01, 9.5752e-01, 9.5605e-01,\n",
       "            9.5508e-01, 9.5020e-01, 9.4922e-01, 9.4873e-01, 9.4727e-01,\n",
       "            9.4580e-01, 9.4434e-01, 9.4336e-01, 9.4141e-01, 9.3994e-01,\n",
       "            9.3701e-01, 9.3262e-01, 9.2676e-01, 9.2285e-01, 9.2041e-01,\n",
       "            9.1797e-01, 9.1309e-01, 9.1260e-01, 9.1211e-01, 9.0918e-01,\n",
       "            8.9893e-01, 8.9307e-01, 8.8428e-01, 8.7451e-01, 8.6719e-01,\n",
       "            8.6670e-01, 8.6230e-01, 8.5840e-01, 8.4521e-01, 8.3838e-01,\n",
       "            8.3447e-01, 8.3301e-01, 8.2959e-01, 8.2764e-01, 8.2617e-01,\n",
       "            8.1641e-01, 8.1152e-01, 8.0811e-01, 8.0518e-01, 7.9688e-01,\n",
       "            7.9492e-01, 7.8418e-01, 7.7930e-01, 7.6855e-01, 7.6758e-01,\n",
       "            7.6611e-01, 7.6416e-01, 7.6025e-01, 7.5684e-01, 7.5439e-01,\n",
       "            7.5342e-01, 7.5146e-01, 7.3730e-01, 7.2217e-01, 7.1924e-01,\n",
       "            6.9092e-01, 6.7285e-01, 6.6553e-01, 6.3525e-01, 6.3428e-01,\n",
       "            6.3184e-01, 6.3135e-01, 6.2402e-01, 5.9131e-01, 5.5957e-01,\n",
       "            5.4639e-01, 5.3467e-01, 5.2344e-01, 5.1123e-01, 5.0977e-01,\n",
       "            4.6851e-01, 4.6606e-01, 4.6411e-01, 4.4897e-01, 4.3750e-01,\n",
       "            4.2358e-01, 4.2285e-01, 4.2163e-01, 3.9331e-01, 3.9258e-01,\n",
       "            3.8965e-01, 3.7793e-01, 3.3887e-01, 3.2666e-01, 3.2251e-01,\n",
       "            3.1787e-01, 3.1689e-01, 3.1616e-01, 2.9492e-01, 2.9053e-01,\n",
       "            2.8320e-01, 2.6392e-01, 2.6294e-01, 2.5635e-01, 2.5562e-01,\n",
       "            2.3401e-01, 2.2400e-01, 2.1631e-01, 2.0959e-01, 2.0605e-01,\n",
       "            2.0593e-01, 2.0020e-01, 1.8628e-01, 1.8274e-01, 1.8030e-01,\n",
       "            1.6602e-01, 1.5552e-01, 1.5430e-01, 1.5320e-01, 1.5186e-01,\n",
       "            1.5027e-01, 1.4612e-01, 1.4600e-01, 1.4502e-01, 1.4050e-01,\n",
       "            1.3806e-01, 1.3794e-01, 1.3538e-01, 1.2891e-01, 1.2146e-01,\n",
       "            1.1597e-01, 1.1456e-01, 1.0876e-01, 1.0504e-01, 1.0468e-01,\n",
       "            1.0266e-01, 1.0229e-01, 9.4849e-02, 9.4666e-02, 9.3994e-02,\n",
       "            9.2834e-02, 9.1858e-02, 9.1736e-02, 9.0881e-02, 8.8684e-02,\n",
       "            8.8196e-02, 8.3862e-02, 8.0505e-02, 7.9651e-02, 7.7515e-02,\n",
       "            7.6294e-02, 7.4646e-02, 7.0679e-02, 7.0435e-02, 6.3232e-02,\n",
       "            6.3049e-02, 5.8441e-02, 5.6763e-02, 5.6641e-02, 5.5939e-02,\n",
       "            5.3101e-02, 5.0140e-02, 4.9774e-02, 4.7607e-02, 4.6295e-02,\n",
       "            4.5593e-02, 4.5013e-02, 4.4769e-02, 4.4342e-02, 4.3213e-02,\n",
       "            4.0253e-02, 3.6224e-02, 3.5950e-02, 3.5736e-02, 3.4302e-02,\n",
       "            3.3325e-02, 3.2043e-02, 3.0914e-02, 2.9984e-02, 2.9922e-02,\n",
       "            2.9709e-02, 2.9419e-02, 2.8442e-02, 2.8168e-02, 2.6962e-02,\n",
       "            2.6108e-02, 2.5665e-02, 2.5421e-02, 2.4750e-02, 2.4185e-02,\n",
       "            2.3819e-02, 2.3727e-02, 2.3514e-02, 2.3285e-02, 2.3193e-02,\n",
       "            2.2369e-02, 2.1652e-02, 2.0920e-02, 1.9684e-02, 1.9241e-02,\n",
       "            1.8188e-02, 1.7715e-02, 1.7044e-02, 1.6785e-02, 1.6403e-02,\n",
       "            1.6022e-02, 1.5900e-02, 1.5366e-02, 1.4786e-02, 1.3374e-02,\n",
       "            1.2871e-02, 1.2627e-02, 1.1597e-02, 1.0902e-02, 1.0452e-02,\n",
       "            9.8953e-03, 8.9874e-03, 8.2550e-03, 7.3738e-03, 6.2904e-03,\n",
       "            6.0272e-03, 5.8899e-03, 5.1193e-03, 4.1809e-03, 3.7498e-03,\n",
       "            3.1853e-03, 2.8229e-03, 1.9951e-03, 6.9618e-04], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00746269, dtype=float32),\n",
       "    'tpr': array(0.7758621, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.07462686, 0.08208955, 0.08955224, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.10447761, 0.10447761, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1716418 , 0.17910448,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01724138, 0.02586207, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.70689654, 0.7155172 , 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9365e-01, 9.9023e-01, 9.8145e-01, 9.8047e-01,\n",
       "            9.7949e-01, 9.7803e-01, 9.7461e-01, 9.7363e-01, 9.7119e-01,\n",
       "            9.6680e-01, 9.6484e-01, 9.6240e-01, 9.6094e-01, 9.5996e-01,\n",
       "            9.5752e-01, 9.4727e-01, 9.4580e-01, 9.4531e-01, 9.4336e-01,\n",
       "            9.4287e-01, 9.4092e-01, 9.3750e-01, 9.3701e-01, 9.3652e-01,\n",
       "            9.3555e-01, 9.3408e-01, 9.2773e-01, 9.2529e-01, 9.2432e-01,\n",
       "            9.2236e-01, 9.1895e-01, 9.1602e-01, 9.1455e-01, 9.1357e-01,\n",
       "            9.1162e-01, 9.0869e-01, 8.9502e-01, 8.8721e-01, 8.8477e-01,\n",
       "            8.7646e-01, 8.7500e-01, 8.5547e-01, 8.5059e-01, 8.4424e-01,\n",
       "            8.3984e-01, 8.3301e-01, 8.2764e-01, 8.2227e-01, 8.2178e-01,\n",
       "            8.1396e-01, 8.0420e-01, 7.9883e-01, 7.9688e-01, 7.9590e-01,\n",
       "            7.9541e-01, 7.7979e-01, 7.7539e-01, 7.7295e-01, 7.7246e-01,\n",
       "            7.6221e-01, 7.5977e-01, 7.5439e-01, 7.4854e-01, 7.4609e-01,\n",
       "            7.2998e-01, 7.2852e-01, 7.2070e-01, 7.1387e-01, 7.1338e-01,\n",
       "            7.1045e-01, 6.9678e-01, 6.9336e-01, 6.8164e-01, 6.8066e-01,\n",
       "            6.7236e-01, 6.2305e-01, 6.2012e-01, 6.1963e-01, 5.7520e-01,\n",
       "            5.5664e-01, 5.2783e-01, 5.1465e-01, 5.0537e-01, 4.9170e-01,\n",
       "            4.6338e-01, 4.5972e-01, 4.4653e-01, 4.1724e-01, 4.1699e-01,\n",
       "            4.0308e-01, 4.0210e-01, 3.9380e-01, 3.8647e-01, 3.7671e-01,\n",
       "            3.5620e-01, 3.4399e-01, 3.3765e-01, 3.3545e-01, 3.0444e-01,\n",
       "            3.0029e-01, 2.9614e-01, 2.9370e-01, 2.9321e-01, 2.8052e-01,\n",
       "            2.5415e-01, 2.4451e-01, 2.4219e-01, 2.3462e-01, 2.2949e-01,\n",
       "            2.2888e-01, 2.2119e-01, 1.9604e-01, 1.9275e-01, 1.8933e-01,\n",
       "            1.7786e-01, 1.7212e-01, 1.7188e-01, 1.6919e-01, 1.6345e-01,\n",
       "            1.6101e-01, 1.5552e-01, 1.3318e-01, 1.3025e-01, 1.2732e-01,\n",
       "            1.2720e-01, 1.2390e-01, 1.2250e-01, 1.1841e-01, 1.1816e-01,\n",
       "            1.1420e-01, 1.1377e-01, 1.0468e-01, 1.0358e-01, 9.9304e-02,\n",
       "            9.7717e-02, 9.1064e-02, 8.7891e-02, 8.3618e-02, 8.3313e-02,\n",
       "            8.2275e-02, 8.0933e-02, 7.9895e-02, 7.8247e-02, 7.6111e-02,\n",
       "            7.5562e-02, 7.4768e-02, 7.3853e-02, 7.2876e-02, 7.1472e-02,\n",
       "            6.8787e-02, 6.5857e-02, 6.4880e-02, 6.2683e-02, 6.1523e-02,\n",
       "            5.9875e-02, 5.9204e-02, 5.8899e-02, 5.5817e-02, 5.4291e-02,\n",
       "            4.8950e-02, 4.6295e-02, 4.5959e-02, 4.4861e-02, 4.4678e-02,\n",
       "            4.4525e-02, 4.1840e-02, 4.1138e-02, 4.0314e-02, 3.9795e-02,\n",
       "            3.8025e-02, 3.7537e-02, 3.7201e-02, 3.7109e-02, 3.6499e-02,\n",
       "            3.5828e-02, 3.5553e-02, 3.3142e-02, 2.9373e-02, 2.8336e-02,\n",
       "            2.7954e-02, 2.7802e-02, 2.5909e-02, 2.4796e-02, 2.3956e-02,\n",
       "            2.3819e-02, 2.2415e-02, 2.2156e-02, 2.1820e-02, 2.1744e-02,\n",
       "            2.1530e-02, 2.0645e-02, 2.0142e-02, 2.0065e-02, 2.0020e-02,\n",
       "            1.9913e-02, 1.9196e-02, 1.9119e-02, 1.8616e-02, 1.8585e-02,\n",
       "            1.8402e-02, 1.7990e-02, 1.7242e-02, 1.6220e-02, 1.5305e-02,\n",
       "            1.4229e-02, 1.4008e-02, 1.3954e-02, 1.3329e-02, 1.3123e-02,\n",
       "            1.2871e-02, 1.2627e-02, 1.1642e-02, 1.1292e-02, 1.1162e-02,\n",
       "            1.0986e-02, 1.0529e-02, 9.6359e-03, 9.1934e-03, 8.4152e-03,\n",
       "            7.8430e-03, 7.4883e-03, 7.4310e-03, 6.7444e-03, 5.5351e-03,\n",
       "            5.1613e-03, 4.2152e-03, 4.2000e-03, 4.1504e-03, 3.5515e-03,\n",
       "            2.8782e-03, 2.5806e-03, 2.1248e-03, 1.8826e-03, 1.3351e-03,\n",
       "            4.4417e-04], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.7586207, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.05970149, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08955224, 0.08955224,\n",
       "            0.08955224, 0.08955224, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.18656716, 0.19402985, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.6492537 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9414e-01, 9.9365e-01, 9.9023e-01, 9.8291e-01,\n",
       "            9.8096e-01, 9.7949e-01, 9.7705e-01, 9.7607e-01, 9.7510e-01,\n",
       "            9.7314e-01, 9.6875e-01, 9.6533e-01, 9.6338e-01, 9.5996e-01,\n",
       "            9.5898e-01, 9.5703e-01, 9.4678e-01, 9.4434e-01, 9.4238e-01,\n",
       "            9.4092e-01, 9.3945e-01, 9.3799e-01, 9.3750e-01, 9.3701e-01,\n",
       "            9.3652e-01, 9.3359e-01, 9.3066e-01, 9.2725e-01, 9.2529e-01,\n",
       "            9.2188e-01, 9.1797e-01, 9.1748e-01, 9.1309e-01, 9.0967e-01,\n",
       "            9.0186e-01, 8.8770e-01, 8.7939e-01, 8.7451e-01, 8.5986e-01,\n",
       "            8.5352e-01, 8.5156e-01, 8.4521e-01, 8.4229e-01, 8.3594e-01,\n",
       "            8.3252e-01, 8.3105e-01, 8.1348e-01, 8.1201e-01, 8.0664e-01,\n",
       "            8.0371e-01, 7.9785e-01, 7.8906e-01, 7.8076e-01, 7.7832e-01,\n",
       "            7.7588e-01, 7.7490e-01, 7.7344e-01, 7.7148e-01, 7.6025e-01,\n",
       "            7.5684e-01, 7.4707e-01, 7.4219e-01, 7.2803e-01, 7.2217e-01,\n",
       "            7.1924e-01, 7.1338e-01, 7.1191e-01, 7.1045e-01, 6.9287e-01,\n",
       "            6.7725e-01, 6.7676e-01, 6.7188e-01, 6.5234e-01, 6.2109e-01,\n",
       "            6.1670e-01, 6.1621e-01, 6.1475e-01, 6.1377e-01, 6.0791e-01,\n",
       "            5.6982e-01, 5.0635e-01, 4.9365e-01, 4.9194e-01, 4.9097e-01,\n",
       "            4.8071e-01, 4.5337e-01, 4.3457e-01, 4.0894e-01, 4.0601e-01,\n",
       "            4.0308e-01, 3.9014e-01, 3.8818e-01, 3.7817e-01, 3.4302e-01,\n",
       "            3.3545e-01, 3.3179e-01, 3.3105e-01, 3.2568e-01, 2.8833e-01,\n",
       "            2.8662e-01, 2.8027e-01, 2.6294e-01, 2.6050e-01, 2.4890e-01,\n",
       "            2.2803e-01, 2.2351e-01, 2.1997e-01, 2.1680e-01, 2.1057e-01,\n",
       "            2.0984e-01, 1.8835e-01, 1.8433e-01, 1.8201e-01, 1.7725e-01,\n",
       "            1.6467e-01, 1.6052e-01, 1.5002e-01, 1.4807e-01, 1.4062e-01,\n",
       "            1.3818e-01, 1.2286e-01, 1.1963e-01, 1.0797e-01, 1.0742e-01,\n",
       "            1.0577e-01, 1.0016e-01, 9.9792e-02, 9.6375e-02, 9.6191e-02,\n",
       "            9.3323e-02, 9.1858e-02, 8.9478e-02, 8.8806e-02, 8.2825e-02,\n",
       "            8.2092e-02, 8.1787e-02, 7.9895e-02, 7.9773e-02, 7.8064e-02,\n",
       "            7.4341e-02, 7.3181e-02, 7.1960e-02, 6.9519e-02, 6.8787e-02,\n",
       "            6.8665e-02, 6.8420e-02, 6.2561e-02, 6.1890e-02, 5.9326e-02,\n",
       "            5.8014e-02, 5.7587e-02, 5.7190e-02, 5.6122e-02, 5.3009e-02,\n",
       "            4.9042e-02, 4.7699e-02, 4.6478e-02, 4.4861e-02, 4.4769e-02,\n",
       "            4.4525e-02, 4.1931e-02, 4.1779e-02, 4.1229e-02, 4.1138e-02,\n",
       "            3.6987e-02, 3.6560e-02, 3.5004e-02, 3.4088e-02, 3.3722e-02,\n",
       "            3.3386e-02, 3.3325e-02, 3.2654e-02, 3.2349e-02, 3.1921e-02,\n",
       "            3.1372e-02, 2.9419e-02, 2.8931e-02, 2.8015e-02, 2.6108e-02,\n",
       "            2.5955e-02, 2.5864e-02, 2.4475e-02, 2.2537e-02, 2.1011e-02,\n",
       "            2.0889e-02, 2.0218e-02, 2.0142e-02, 1.8799e-02, 1.8341e-02,\n",
       "            1.7853e-02, 1.7578e-02, 1.7517e-02, 1.6922e-02, 1.6724e-02,\n",
       "            1.6663e-02, 1.6098e-02, 1.6022e-02, 1.5839e-02, 1.5541e-02,\n",
       "            1.4786e-02, 1.4175e-02, 1.3847e-02, 1.3275e-02, 1.2291e-02,\n",
       "            1.1421e-02, 1.1375e-02, 1.1200e-02, 1.0948e-02, 9.8190e-03,\n",
       "            9.7427e-03, 9.4528e-03, 9.1248e-03, 8.9874e-03, 8.2169e-03,\n",
       "            8.1863e-03, 7.8430e-03, 7.5188e-03, 6.3400e-03, 6.2904e-03,\n",
       "            5.7068e-03, 5.4283e-03, 5.1804e-03, 3.6793e-03, 3.4695e-03,\n",
       "            2.8229e-03, 2.8000e-03, 2.7580e-03, 2.3422e-03, 1.8826e-03,\n",
       "            1.6937e-03, 1.3723e-03, 1.2112e-03, 8.6260e-04, 2.7585e-04],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.76724136, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08208955, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.51492536, 0.52238804,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.86206895, 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9561e-01, 9.9512e-01, 9.9219e-01, 9.8828e-01,\n",
       "            9.8633e-01, 9.8340e-01, 9.8096e-01, 9.8047e-01, 9.7754e-01,\n",
       "            9.7363e-01, 9.7070e-01, 9.6582e-01, 9.6436e-01, 9.6289e-01,\n",
       "            9.5752e-01, 9.5264e-01, 9.5068e-01, 9.4971e-01, 9.4580e-01,\n",
       "            9.4434e-01, 9.4336e-01, 9.4287e-01, 9.4238e-01, 9.4189e-01,\n",
       "            9.4141e-01, 9.3994e-01, 9.3652e-01, 9.3311e-01, 9.3018e-01,\n",
       "            9.2822e-01, 9.1992e-01, 9.1943e-01, 9.1260e-01, 9.0918e-01,\n",
       "            9.0771e-01, 8.9893e-01, 8.9062e-01, 8.7061e-01, 8.6670e-01,\n",
       "            8.5938e-01, 8.5352e-01, 8.4570e-01, 8.4033e-01, 8.3984e-01,\n",
       "            8.3545e-01, 8.3447e-01, 8.2422e-01, 8.1738e-01, 8.1641e-01,\n",
       "            8.1396e-01, 8.0566e-01, 8.0127e-01, 8.0029e-01, 7.9150e-01,\n",
       "            7.8955e-01, 7.8027e-01, 7.7539e-01, 7.7100e-01, 7.6660e-01,\n",
       "            7.6562e-01, 7.6221e-01, 7.6123e-01, 7.3389e-01, 7.2900e-01,\n",
       "            7.2754e-01, 7.2461e-01, 7.1924e-01, 7.1777e-01, 7.1143e-01,\n",
       "            7.0996e-01, 7.0801e-01, 6.9336e-01, 6.7480e-01, 6.7285e-01,\n",
       "            6.6260e-01, 6.5283e-01, 6.5186e-01, 6.2109e-01, 6.2061e-01,\n",
       "            6.1084e-01, 5.9229e-01, 5.6592e-01, 5.1660e-01, 5.0928e-01,\n",
       "            4.9585e-01, 4.8438e-01, 4.7852e-01, 4.6191e-01, 4.4482e-01,\n",
       "            4.1455e-01, 4.0820e-01, 4.0259e-01, 3.9697e-01, 3.8501e-01,\n",
       "            3.7207e-01, 3.6499e-01, 3.3789e-01, 3.3057e-01, 3.2886e-01,\n",
       "            3.2642e-01, 3.0566e-01, 2.9907e-01, 2.9688e-01, 2.9443e-01,\n",
       "            2.4365e-01, 2.4146e-01, 2.3682e-01, 2.2595e-01, 2.2119e-01,\n",
       "            2.0630e-01, 2.0044e-01, 2.0007e-01, 1.9678e-01, 1.8982e-01,\n",
       "            1.8433e-01, 1.7310e-01, 1.5918e-01, 1.5356e-01, 1.4966e-01,\n",
       "            1.4880e-01, 1.4819e-01, 1.4221e-01, 1.1719e-01, 1.1658e-01,\n",
       "            1.1145e-01, 1.0541e-01, 1.0266e-01, 9.0759e-02, 8.4473e-02,\n",
       "            8.3862e-02, 8.3435e-02, 8.2092e-02, 8.0383e-02, 7.8796e-02,\n",
       "            7.7087e-02, 7.6538e-02, 7.5867e-02, 7.5317e-02, 7.5012e-02,\n",
       "            7.3669e-02, 7.3059e-02, 7.2632e-02, 7.0557e-02, 6.9641e-02,\n",
       "            6.7932e-02, 6.6956e-02, 6.6345e-02, 6.5857e-02, 6.4758e-02,\n",
       "            6.2103e-02, 5.9662e-02, 5.6030e-02, 4.8584e-02, 4.5776e-02,\n",
       "            4.4922e-02, 4.4006e-02, 4.3701e-02, 4.3030e-02, 4.0375e-02,\n",
       "            4.0009e-02, 3.9856e-02, 3.7964e-02, 3.7598e-02, 3.7323e-02,\n",
       "            3.5339e-02, 3.5004e-02, 3.3203e-02, 3.3142e-02, 3.2776e-02,\n",
       "            3.2471e-02, 3.2043e-02, 3.1799e-02, 3.1082e-02, 3.0914e-02,\n",
       "            3.0563e-02, 3.0212e-02, 2.9984e-02, 2.9922e-02, 2.8107e-02,\n",
       "            2.4521e-02, 2.4277e-02, 2.3956e-02, 2.3331e-02, 2.2034e-02,\n",
       "            2.1820e-02, 2.0767e-02, 1.9058e-02, 1.8875e-02, 1.8768e-02,\n",
       "            1.8692e-02, 1.8265e-02, 1.7044e-02, 1.6846e-02, 1.6785e-02,\n",
       "            1.6586e-02, 1.6525e-02, 1.5839e-02, 1.5717e-02, 1.5541e-02,\n",
       "            1.5129e-02, 1.5076e-02, 1.4954e-02, 1.3901e-02, 1.2627e-02,\n",
       "            1.1871e-02, 1.1116e-02, 1.1070e-02, 1.0902e-02, 1.0094e-02,\n",
       "            9.7122e-03, 9.5596e-03, 9.0179e-03, 8.8120e-03, 8.6441e-03,\n",
       "            7.2594e-03, 6.7177e-03, 6.1913e-03, 5.9357e-03, 5.5771e-03,\n",
       "            5.5351e-03, 5.2795e-03, 5.0201e-03, 4.8676e-03, 4.2648e-03,\n",
       "            3.9749e-03, 3.6068e-03, 3.4161e-03, 2.2793e-03, 2.2602e-03,\n",
       "            1.8177e-03, 1.8034e-03, 1.6937e-03, 1.4954e-03, 1.2112e-03,\n",
       "            1.0691e-03, 8.3303e-04, 7.3528e-04, 5.1737e-04, 1.5724e-04],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.75, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05970149, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08208955, 0.08208955,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.1119403 , 0.11940298, 0.12686567, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6865672 , 0.69402987, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.06034483, 0.0775862 , 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9561e-01, 9.9463e-01, 9.9219e-01, 9.8926e-01,\n",
       "            9.8779e-01, 9.8193e-01, 9.7949e-01, 9.7656e-01, 9.7510e-01,\n",
       "            9.7119e-01, 9.6582e-01, 9.6289e-01, 9.6143e-01, 9.5947e-01,\n",
       "            9.5410e-01, 9.5264e-01, 9.5215e-01, 9.4922e-01, 9.4824e-01,\n",
       "            9.4629e-01, 9.4531e-01, 9.4287e-01, 9.4189e-01, 9.4141e-01,\n",
       "            9.4092e-01, 9.4043e-01, 9.3750e-01, 9.3652e-01, 9.3555e-01,\n",
       "            9.3213e-01, 9.3164e-01, 9.2676e-01, 9.1846e-01, 9.1162e-01,\n",
       "            9.1113e-01, 9.0332e-01, 8.9600e-01, 8.8770e-01, 8.8232e-01,\n",
       "            8.7842e-01, 8.6963e-01, 8.4814e-01, 8.4473e-01, 8.3887e-01,\n",
       "            8.3740e-01, 8.3594e-01, 8.3203e-01, 8.2666e-01, 8.0811e-01,\n",
       "            8.0420e-01, 8.0078e-01, 7.9102e-01, 7.8760e-01, 7.8467e-01,\n",
       "            7.7393e-01, 7.7148e-01, 7.6758e-01, 7.6709e-01, 7.6367e-01,\n",
       "            7.5586e-01, 7.4951e-01, 7.4805e-01, 7.4609e-01, 7.2998e-01,\n",
       "            7.1436e-01, 7.1338e-01, 7.0801e-01, 7.0410e-01, 6.9922e-01,\n",
       "            6.9580e-01, 6.8311e-01, 6.7529e-01, 6.7334e-01, 6.5771e-01,\n",
       "            6.5283e-01, 6.4502e-01, 6.3721e-01, 6.3672e-01, 5.9814e-01,\n",
       "            5.8984e-01, 5.8691e-01, 5.4199e-01, 5.1807e-01, 4.9634e-01,\n",
       "            4.8706e-01, 4.5142e-01, 4.3774e-01, 4.1919e-01, 4.1772e-01,\n",
       "            4.1260e-01, 3.8892e-01, 3.8354e-01, 3.7256e-01, 3.6938e-01,\n",
       "            3.5254e-01, 3.4180e-01, 3.3838e-01, 2.9858e-01, 2.9663e-01,\n",
       "            2.9468e-01, 2.7856e-01, 2.7197e-01, 2.7075e-01, 2.7026e-01,\n",
       "            2.3523e-01, 2.1277e-01, 2.0276e-01, 1.9910e-01, 1.9226e-01,\n",
       "            1.7676e-01, 1.7480e-01, 1.7468e-01, 1.7029e-01, 1.6577e-01,\n",
       "            1.5479e-01, 1.5112e-01, 1.3928e-01, 1.3611e-01, 1.3208e-01,\n",
       "            1.3086e-01, 1.2927e-01, 1.2103e-01, 1.1047e-01, 9.6680e-02,\n",
       "            8.7891e-02, 8.5571e-02, 8.5083e-02, 7.4341e-02, 7.1350e-02,\n",
       "            6.9153e-02, 6.5369e-02, 6.4087e-02, 6.2561e-02, 6.2225e-02,\n",
       "            6.1646e-02, 6.1523e-02, 6.0760e-02, 5.9967e-02, 5.9204e-02,\n",
       "            5.8777e-02, 5.6976e-02, 5.6244e-02, 5.4291e-02, 5.3711e-02,\n",
       "            5.3589e-02, 5.3497e-02, 5.3101e-02, 5.2917e-02, 5.1666e-02,\n",
       "            4.9042e-02, 4.5776e-02, 4.5532e-02, 4.2877e-02, 4.1687e-02,\n",
       "            3.9948e-02, 3.4943e-02, 3.1982e-02, 3.1204e-02, 3.1143e-02,\n",
       "            3.0334e-02, 3.0273e-02, 2.9648e-02, 2.9312e-02, 2.8595e-02,\n",
       "            2.7222e-02, 2.6855e-02, 2.6703e-02, 2.5864e-02, 2.5665e-02,\n",
       "            2.5375e-02, 2.4612e-02, 2.4384e-02, 2.4277e-02, 2.4231e-02,\n",
       "            2.3727e-02, 2.3605e-02, 2.1912e-02, 2.1820e-02, 2.1042e-02,\n",
       "            2.0218e-02, 1.9684e-02, 1.9608e-02, 1.8768e-02, 1.8646e-02,\n",
       "            1.8433e-02, 1.7380e-02, 1.6098e-02, 1.5541e-02, 1.4732e-02,\n",
       "            1.4618e-02, 1.4389e-02, 1.4282e-02, 1.4114e-02, 1.3069e-02,\n",
       "            1.2825e-02, 1.2527e-02, 1.2383e-02, 1.2337e-02, 1.2146e-02,\n",
       "            1.2054e-02, 1.1780e-02, 1.1688e-02, 1.1505e-02, 1.1330e-02,\n",
       "            1.0406e-02, 8.9493e-03, 8.2550e-03, 8.1558e-03, 8.0948e-03,\n",
       "            7.5493e-03, 7.2327e-03, 7.0648e-03, 6.9580e-03, 6.4125e-03,\n",
       "            6.3629e-03, 6.1226e-03, 5.6190e-03, 5.3635e-03, 4.4861e-03,\n",
       "            4.2152e-03, 4.0245e-03, 3.8700e-03, 3.6354e-03, 3.6068e-03,\n",
       "            3.4561e-03, 3.2978e-03, 2.9697e-03, 2.6207e-03, 2.5024e-03,\n",
       "            2.2163e-03, 2.1000e-03, 1.3666e-03, 1.3514e-03, 1.0900e-03,\n",
       "            1.0862e-03, 1.0004e-03, 8.9359e-04, 7.2384e-04, 6.3133e-04,\n",
       "            4.8399e-04, 4.2558e-04, 2.9826e-04, 8.6129e-05], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.73275864, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6865672 , 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.15517241, 0.1637931 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.79310346, 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9512e-01, 9.9463e-01, 9.9121e-01, 9.8828e-01,\n",
       "            9.8584e-01, 9.7998e-01, 9.7754e-01, 9.7607e-01, 9.7168e-01,\n",
       "            9.7070e-01, 9.6729e-01, 9.5996e-01, 9.5801e-01, 9.5459e-01,\n",
       "            9.5068e-01, 9.4629e-01, 9.4141e-01, 9.3848e-01, 9.3652e-01,\n",
       "            9.3604e-01, 9.3359e-01, 9.3311e-01, 9.3066e-01, 9.3018e-01,\n",
       "            9.2578e-01, 9.2529e-01, 9.2236e-01, 9.2188e-01, 9.1455e-01,\n",
       "            9.1113e-01, 8.9551e-01, 8.9502e-01, 8.8916e-01, 8.8525e-01,\n",
       "            8.6670e-01, 8.6572e-01, 8.5596e-01, 8.4961e-01, 8.3545e-01,\n",
       "            8.2178e-01, 8.1494e-01, 8.1396e-01, 8.1250e-01, 8.0225e-01,\n",
       "            7.9492e-01, 7.8760e-01, 7.7441e-01, 7.6758e-01, 7.6367e-01,\n",
       "            7.5830e-01, 7.5488e-01, 7.5342e-01, 7.4268e-01, 7.3486e-01,\n",
       "            7.2900e-01, 7.2754e-01, 7.1191e-01, 7.0996e-01, 7.0166e-01,\n",
       "            7.0020e-01, 6.9629e-01, 6.9531e-01, 6.7773e-01, 6.7334e-01,\n",
       "            6.6455e-01, 6.6309e-01, 6.5918e-01, 6.5576e-01, 6.5381e-01,\n",
       "            6.4209e-01, 6.2793e-01, 6.1719e-01, 6.1475e-01, 6.0107e-01,\n",
       "            5.8057e-01, 5.7959e-01, 5.7324e-01, 5.6934e-01, 5.4443e-01,\n",
       "            5.4150e-01, 5.2539e-01, 4.9097e-01, 4.4238e-01, 4.2334e-01,\n",
       "            4.1870e-01, 3.8257e-01, 3.7109e-01, 3.6206e-01, 3.3496e-01,\n",
       "            3.2837e-01, 3.2373e-01, 3.2324e-01, 3.2300e-01, 3.1934e-01,\n",
       "            2.9053e-01, 2.8760e-01, 2.7295e-01, 2.4695e-01, 2.3792e-01,\n",
       "            2.3096e-01, 2.2632e-01, 2.1655e-01, 2.1033e-01, 1.9824e-01,\n",
       "            1.7175e-01, 1.6492e-01, 1.5918e-01, 1.4612e-01, 1.4490e-01,\n",
       "            1.3330e-01, 1.3318e-01, 1.2231e-01, 1.2146e-01, 1.2042e-01,\n",
       "            1.1615e-01, 1.1163e-01, 1.0248e-01, 1.0034e-01, 9.8083e-02,\n",
       "            9.7412e-02, 9.1248e-02, 7.3303e-02, 6.6101e-02, 6.2317e-02,\n",
       "            6.2225e-02, 5.7922e-02, 5.5115e-02, 5.2521e-02, 4.9957e-02,\n",
       "            4.9042e-02, 4.8035e-02, 4.4281e-02, 4.3518e-02, 4.1779e-02,\n",
       "            4.1321e-02, 3.9703e-02, 3.9429e-02, 3.9124e-02, 3.7964e-02,\n",
       "            3.7598e-02, 3.6835e-02, 3.6621e-02, 3.5950e-02, 3.4882e-02,\n",
       "            3.4760e-02, 3.4485e-02, 3.3966e-02, 3.1311e-02, 3.0914e-02,\n",
       "            3.0792e-02, 3.0151e-02, 2.9373e-02, 2.7481e-02, 2.7222e-02,\n",
       "            2.2079e-02, 2.1866e-02, 2.0370e-02, 2.0096e-02, 2.0065e-02,\n",
       "            1.9714e-02, 1.9608e-02, 1.8585e-02, 1.7914e-02, 1.7776e-02,\n",
       "            1.7303e-02, 1.7242e-02, 1.6586e-02, 1.6159e-02, 1.6098e-02,\n",
       "            1.5541e-02, 1.5251e-02, 1.5076e-02, 1.4618e-02, 1.4450e-02,\n",
       "            1.3374e-02, 1.3329e-02, 1.3069e-02, 1.2672e-02, 1.2383e-02,\n",
       "            1.2238e-02, 1.2054e-02, 1.1871e-02, 1.1780e-02, 1.1688e-02,\n",
       "            1.0948e-02, 1.0208e-02, 1.0132e-02, 9.8572e-03, 9.2316e-03,\n",
       "            9.1934e-03, 8.9493e-03, 8.8120e-03, 8.7814e-03, 8.2550e-03,\n",
       "            8.1253e-03, 8.0032e-03, 7.9651e-03, 7.7858e-03, 7.4615e-03,\n",
       "            7.1487e-03, 6.8512e-03, 6.6147e-03, 6.3133e-03, 6.2408e-03,\n",
       "            5.8441e-03, 5.4054e-03, 4.8485e-03, 4.7913e-03, 4.6463e-03,\n",
       "            4.3831e-03, 4.1809e-03, 4.0855e-03, 4.0550e-03, 3.6068e-03,\n",
       "            3.3760e-03, 3.2482e-03, 3.2234e-03, 2.5711e-03, 2.4719e-03,\n",
       "            2.4529e-03, 2.2526e-03, 2.1992e-03, 2.0676e-03, 1.9951e-03,\n",
       "            1.9045e-03, 1.6813e-03, 1.5545e-03, 1.5249e-03, 1.2646e-03,\n",
       "            1.1969e-03, 7.8249e-04, 7.4673e-04, 6.1417e-04, 6.0463e-04,\n",
       "            5.4836e-04, 5.0354e-04, 4.1723e-04, 3.5000e-04, 2.6131e-04,\n",
       "            2.2876e-04, 1.5724e-04, 4.3631e-05], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.7413793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.09701493, 0.09701493, 0.10447761, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.35074627,\n",
       "            0.35820895, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6119403 , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9707e-01, 9.9658e-01, 9.9414e-01, 9.9219e-01,\n",
       "            9.8975e-01, 9.8633e-01, 9.8438e-01, 9.8291e-01, 9.7949e-01,\n",
       "            9.7559e-01, 9.7266e-01, 9.6875e-01, 9.6729e-01, 9.6436e-01,\n",
       "            9.6094e-01, 9.6045e-01, 9.5312e-01, 9.5215e-01, 9.5166e-01,\n",
       "            9.4971e-01, 9.4922e-01, 9.4873e-01, 9.4482e-01, 9.4385e-01,\n",
       "            9.4238e-01, 9.4189e-01, 9.4141e-01, 9.4092e-01, 9.3457e-01,\n",
       "            9.2773e-01, 9.2383e-01, 9.1504e-01, 9.1357e-01, 9.1162e-01,\n",
       "            9.0527e-01, 8.8770e-01, 8.7988e-01, 8.7842e-01, 8.7402e-01,\n",
       "            8.6475e-01, 8.4619e-01, 8.3252e-01, 8.2959e-01, 8.2324e-01,\n",
       "            8.1982e-01, 8.1641e-01, 8.1201e-01, 8.0322e-01, 8.0127e-01,\n",
       "            7.9297e-01, 7.9150e-01, 7.7734e-01, 7.7588e-01, 7.7393e-01,\n",
       "            7.5830e-01, 7.5781e-01, 7.5439e-01, 7.5146e-01, 7.3535e-01,\n",
       "            7.2559e-01, 7.2461e-01, 6.9775e-01, 6.9678e-01, 6.9336e-01,\n",
       "            6.9287e-01, 6.8799e-01, 6.8652e-01, 6.8311e-01, 6.7871e-01,\n",
       "            6.6699e-01, 6.5234e-01, 6.5137e-01, 6.2988e-01, 6.2402e-01,\n",
       "            6.2207e-01, 6.1768e-01, 6.1133e-01, 6.0742e-01, 6.0254e-01,\n",
       "            5.6299e-01, 5.6055e-01, 5.4102e-01, 5.3223e-01, 5.1025e-01,\n",
       "            4.7192e-01, 4.5166e-01, 3.9453e-01, 3.6694e-01, 3.6572e-01,\n",
       "            3.5547e-01, 3.4253e-01, 3.4180e-01, 3.3032e-01, 3.1934e-01,\n",
       "            3.0640e-01, 3.0518e-01, 3.0078e-01, 2.9688e-01, 2.8662e-01,\n",
       "            2.5391e-01, 2.4512e-01, 2.3865e-01, 2.3474e-01, 2.2437e-01,\n",
       "            2.1753e-01, 1.6785e-01, 1.6174e-01, 1.6052e-01, 1.4954e-01,\n",
       "            1.4551e-01, 1.2390e-01, 1.2213e-01, 1.2036e-01, 1.1554e-01,\n",
       "            1.1243e-01, 1.0840e-01, 1.0449e-01, 1.0229e-01, 1.0193e-01,\n",
       "            9.8450e-02, 9.6375e-02, 9.3323e-02, 9.0576e-02, 8.2092e-02,\n",
       "            6.5491e-02, 6.1096e-02, 5.3009e-02, 5.2521e-02, 5.0232e-02,\n",
       "            5.0140e-02, 4.7791e-02, 4.7241e-02, 4.0619e-02, 4.0100e-02,\n",
       "            3.8696e-02, 3.6224e-02, 3.6011e-02, 3.5492e-02, 3.4607e-02,\n",
       "            3.3783e-02, 3.3539e-02, 3.3325e-02, 3.2837e-02, 3.2532e-02,\n",
       "            3.2104e-02, 2.9984e-02, 2.8442e-02, 2.8015e-02, 2.7740e-02,\n",
       "            2.6917e-02, 2.6352e-02, 2.5955e-02, 2.1942e-02, 2.1698e-02,\n",
       "            2.1164e-02, 2.0798e-02, 2.0645e-02, 1.9196e-02, 1.8936e-02,\n",
       "            1.8402e-02, 1.6663e-02, 1.5488e-02, 1.5076e-02, 1.4954e-02,\n",
       "            1.4900e-02, 1.4282e-02, 1.3687e-02, 1.3588e-02, 1.2924e-02,\n",
       "            1.2573e-02, 1.2482e-02, 1.2337e-02, 1.2054e-02, 1.1551e-02,\n",
       "            1.1292e-02, 1.1200e-02, 1.1116e-02, 1.0857e-02, 1.0452e-02,\n",
       "            1.0056e-02, 9.7122e-03, 9.3765e-03, 9.3002e-03, 8.7433e-03,\n",
       "            8.3771e-03, 8.2169e-03, 8.1863e-03, 8.0948e-03, 8.0032e-03,\n",
       "            7.6675e-03, 7.5493e-03, 7.4043e-03, 7.2594e-03, 7.1220e-03,\n",
       "            6.7978e-03, 6.4888e-03, 6.4125e-03, 6.2408e-03, 6.1226e-03,\n",
       "            5.9128e-03, 5.6000e-03, 5.3864e-03, 5.2795e-03, 5.2185e-03,\n",
       "            4.8866e-03, 4.3640e-03, 4.2305e-03, 4.1656e-03, 3.6354e-03,\n",
       "            3.6221e-03, 3.0994e-03, 3.0270e-03, 2.6531e-03, 2.6207e-03,\n",
       "            2.5902e-03, 2.2163e-03, 2.1915e-03, 1.9493e-03, 1.9341e-03,\n",
       "            1.5488e-03, 1.3666e-03, 1.2255e-03, 1.2064e-03, 1.1511e-03,\n",
       "            1.1292e-03, 9.9277e-04, 7.5531e-04, 7.1239e-04, 4.9543e-04,\n",
       "            4.2558e-04, 3.6693e-04, 3.4738e-04, 3.1018e-04, 3.0780e-04,\n",
       "            2.6941e-04, 2.1148e-04, 1.4198e-04, 1.2338e-04, 8.4162e-05,\n",
       "            2.2113e-05], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.7413793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.09701493, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01724138, 0.02586207, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9756e-01, 9.9561e-01, 9.9463e-01, 9.9219e-01,\n",
       "            9.8926e-01, 9.8877e-01, 9.8584e-01, 9.8535e-01, 9.8486e-01,\n",
       "            9.7998e-01, 9.7754e-01, 9.7412e-01, 9.7266e-01, 9.6924e-01,\n",
       "            9.6631e-01, 9.6436e-01, 9.6289e-01, 9.5947e-01, 9.5850e-01,\n",
       "            9.5801e-01, 9.5752e-01, 9.5605e-01, 9.5361e-01, 9.5166e-01,\n",
       "            9.5117e-01, 9.5020e-01, 9.4922e-01, 9.4727e-01, 9.4385e-01,\n",
       "            9.3896e-01, 9.3213e-01, 9.2285e-01, 9.2139e-01, 9.1895e-01,\n",
       "            9.1357e-01, 8.9893e-01, 8.9648e-01, 8.8721e-01, 8.7549e-01,\n",
       "            8.7451e-01, 8.6182e-01, 8.5107e-01, 8.4180e-01, 8.3447e-01,\n",
       "            8.2910e-01, 8.2617e-01, 8.1689e-01, 8.1543e-01, 8.1104e-01,\n",
       "            8.0127e-01, 7.9883e-01, 7.9736e-01, 7.9688e-01, 7.7197e-01,\n",
       "            7.5586e-01, 7.5146e-01, 7.4365e-01, 7.3828e-01, 7.3291e-01,\n",
       "            7.3242e-01, 7.2314e-01, 7.2021e-01, 7.1729e-01, 7.0898e-01,\n",
       "            7.0312e-01, 7.0264e-01, 7.0020e-01, 6.8457e-01, 6.8311e-01,\n",
       "            6.8213e-01, 6.7090e-01, 6.4746e-01, 6.4404e-01, 6.4258e-01,\n",
       "            6.4062e-01, 6.3770e-01, 6.3379e-01, 6.0156e-01, 5.7861e-01,\n",
       "            5.7715e-01, 5.6738e-01, 5.2490e-01, 5.2002e-01, 5.0977e-01,\n",
       "            4.9146e-01, 4.6997e-01, 4.0942e-01, 3.5376e-01, 3.5352e-01,\n",
       "            3.4180e-01, 3.4082e-01, 3.3398e-01, 3.1201e-01, 3.0640e-01,\n",
       "            3.0078e-01, 2.9810e-01, 2.9419e-01, 2.5269e-01, 2.4622e-01,\n",
       "            2.4597e-01, 2.4219e-01, 2.3657e-01, 2.3352e-01, 2.2778e-01,\n",
       "            2.2046e-01, 1.6772e-01, 1.6101e-01, 1.4014e-01, 1.3513e-01,\n",
       "            1.1841e-01, 1.1536e-01, 1.1340e-01, 1.1145e-01, 1.0339e-01,\n",
       "            9.6191e-02, 9.5886e-02, 9.5337e-02, 9.3201e-02, 9.2346e-02,\n",
       "            8.4473e-02, 7.9346e-02, 7.5439e-02, 5.8777e-02, 5.8228e-02,\n",
       "            5.5420e-02, 4.8767e-02, 4.6539e-02, 4.4189e-02, 3.9856e-02,\n",
       "            3.8544e-02, 3.5400e-02, 3.5065e-02, 3.3264e-02, 3.2959e-02,\n",
       "            3.2349e-02, 3.0914e-02, 3.0624e-02, 3.0045e-02, 2.9144e-02,\n",
       "            2.8061e-02, 2.5558e-02, 2.5421e-02, 2.5040e-02, 2.4887e-02,\n",
       "            2.3605e-02, 2.2583e-02, 2.1454e-02, 2.0020e-02, 1.8799e-02,\n",
       "            1.8265e-02, 1.8051e-02, 1.7639e-02, 1.7380e-02, 1.7303e-02,\n",
       "            1.6342e-02, 1.6022e-02, 1.5778e-02, 1.5076e-02, 1.4732e-02,\n",
       "            1.3901e-02, 1.3847e-02, 1.3794e-02, 1.3123e-02, 1.3069e-02,\n",
       "            1.2825e-02, 1.2726e-02, 1.1963e-02, 1.1688e-02, 1.1200e-02,\n",
       "            1.0651e-02, 1.0529e-02, 9.9335e-03, 9.7809e-03, 9.4147e-03,\n",
       "            9.0179e-03, 8.7433e-03, 8.6746e-03, 8.4763e-03, 8.0948e-03,\n",
       "            8.0338e-03, 7.7858e-03, 7.5493e-03, 7.0381e-03, 7.0114e-03,\n",
       "            6.9847e-03, 6.4621e-03, 6.3400e-03, 6.2637e-03, 6.0501e-03,\n",
       "            5.9814e-03, 5.8899e-03, 5.4054e-03, 5.3215e-03, 5.1804e-03,\n",
       "            5.1613e-03, 5.0812e-03, 4.9629e-03, 4.9248e-03, 4.7722e-03,\n",
       "            4.7188e-03, 4.6463e-03, 4.4327e-03, 4.4174e-03, 4.3144e-03,\n",
       "            4.1008e-03, 3.8700e-03, 3.7498e-03, 3.6507e-03, 3.6221e-03,\n",
       "            3.4695e-03, 2.9926e-03, 2.9469e-03, 2.7466e-03, 2.4929e-03,\n",
       "            2.0676e-03, 1.7891e-03, 1.7824e-03, 1.5793e-03, 1.5192e-03,\n",
       "            1.4896e-03, 1.2693e-03, 1.2016e-03, 9.1839e-04, 8.5592e-04,\n",
       "            7.5817e-04, 7.3814e-04, 6.6423e-04, 6.3133e-04, 6.2132e-04,\n",
       "            5.6791e-04, 5.4836e-04, 4.0460e-04, 3.8004e-04, 2.6536e-04,\n",
       "            2.3413e-04, 1.8966e-04, 1.7953e-04, 1.6737e-04, 1.5962e-04,\n",
       "            1.3983e-04, 1.0723e-04, 7.2539e-05, 6.2048e-05, 4.1306e-05,\n",
       "            1.0312e-05], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.7241379, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9854e-01, 9.9805e-01, 9.9658e-01, 9.9609e-01,\n",
       "            9.9365e-01, 9.9170e-01, 9.9121e-01, 9.8877e-01, 9.8730e-01,\n",
       "            9.8096e-01, 9.7803e-01, 9.7754e-01, 9.7607e-01, 9.7314e-01,\n",
       "            9.7119e-01, 9.7070e-01, 9.6777e-01, 9.6436e-01, 9.6387e-01,\n",
       "            9.6289e-01, 9.6045e-01, 9.5898e-01, 9.5850e-01, 9.5605e-01,\n",
       "            9.5508e-01, 9.5361e-01, 9.4971e-01, 9.4385e-01, 9.4189e-01,\n",
       "            9.3311e-01, 9.3018e-01, 9.2334e-01, 9.0723e-01, 9.0674e-01,\n",
       "            9.0625e-01, 8.9746e-01, 8.6768e-01, 8.5596e-01, 8.5352e-01,\n",
       "            8.5254e-01, 8.4082e-01, 8.3203e-01, 8.2568e-01, 8.2227e-01,\n",
       "            8.2178e-01, 8.1836e-01, 8.1055e-01, 8.0420e-01, 7.9688e-01,\n",
       "            7.9346e-01, 7.8027e-01, 7.7148e-01, 7.5342e-01, 7.4219e-01,\n",
       "            7.3584e-01, 7.3340e-01, 7.3291e-01, 7.2363e-01, 7.1289e-01,\n",
       "            7.1045e-01, 7.0996e-01, 7.0605e-01, 6.9678e-01, 6.9092e-01,\n",
       "            6.8115e-01, 6.6602e-01, 6.6064e-01, 6.3916e-01, 6.3281e-01,\n",
       "            6.3232e-01, 6.2891e-01, 6.2744e-01, 6.1768e-01, 6.1377e-01,\n",
       "            5.9717e-01, 5.6104e-01, 5.4785e-01, 5.4443e-01, 5.1807e-01,\n",
       "            5.1172e-01, 4.8682e-01, 4.8511e-01, 4.5508e-01, 4.4946e-01,\n",
       "            3.8940e-01, 3.3521e-01, 3.3032e-01, 3.1104e-01, 2.9028e-01,\n",
       "            2.8516e-01, 2.7368e-01, 2.6978e-01, 2.6807e-01, 2.6782e-01,\n",
       "            2.5757e-01, 2.2766e-01, 2.1326e-01, 2.1289e-01, 2.0508e-01,\n",
       "            2.0166e-01, 2.0056e-01, 1.9788e-01, 1.9287e-01, 1.4673e-01,\n",
       "            1.4233e-01, 1.1047e-01, 1.0669e-01, 9.6008e-02, 9.2834e-02,\n",
       "            9.0088e-02, 8.8501e-02, 8.1543e-02, 8.0933e-02, 7.8918e-02,\n",
       "            7.8247e-02, 7.7209e-02, 6.9946e-02, 6.8787e-02, 5.9540e-02,\n",
       "            5.7587e-02, 5.4688e-02, 4.4861e-02, 4.3457e-02, 4.0375e-02,\n",
       "            3.9490e-02, 3.7537e-02, 2.7908e-02, 2.6306e-02, 2.5558e-02,\n",
       "            2.5467e-02, 2.4185e-02, 2.3956e-02, 2.3773e-02, 2.2766e-02,\n",
       "            2.1942e-02, 2.1820e-02, 2.0645e-02, 1.9836e-02, 1.9196e-02,\n",
       "            1.8478e-02, 1.6403e-02, 1.6098e-02, 1.6022e-02, 1.5602e-02,\n",
       "            1.4732e-02, 1.4389e-02, 1.3275e-02, 1.2772e-02, 1.2100e-02,\n",
       "            1.2009e-02, 1.1780e-02, 1.1467e-02, 1.1070e-02, 1.0735e-02,\n",
       "            1.0170e-02, 1.0132e-02, 9.5215e-03, 9.4833e-03, 9.0866e-03,\n",
       "            9.0561e-03, 8.7128e-03, 8.5144e-03, 7.9346e-03, 7.7553e-03,\n",
       "            7.6942e-03, 7.3738e-03, 7.3166e-03, 7.0114e-03, 6.9580e-03,\n",
       "            6.7711e-03, 6.4888e-03, 6.0730e-03, 5.9814e-03, 5.9128e-03,\n",
       "            5.7526e-03, 5.4893e-03, 5.2185e-03, 5.1384e-03, 5.0621e-03,\n",
       "            4.7722e-03, 4.6997e-03, 4.5547e-03, 4.4861e-03, 4.3831e-03,\n",
       "            4.3144e-03, 4.1504e-03, 4.0703e-03, 4.0550e-03, 3.7079e-03,\n",
       "            3.6221e-03, 3.3760e-03, 3.3512e-03, 3.2234e-03, 3.1853e-03,\n",
       "            3.1109e-03, 3.0632e-03, 3.0270e-03, 2.9469e-03, 2.8782e-03,\n",
       "            2.7790e-03, 2.7256e-03, 2.6321e-03, 2.4929e-03, 2.4433e-03,\n",
       "            2.3975e-03, 2.2869e-03, 2.1152e-03, 2.0199e-03, 1.8463e-03,\n",
       "            1.6813e-03, 1.5793e-03, 1.1835e-03, 1.1740e-03, 1.0567e-03,\n",
       "            1.0242e-03, 8.8310e-04, 8.7595e-04, 7.0953e-04, 6.7186e-04,\n",
       "            5.0735e-04, 4.9543e-04, 4.2391e-04, 4.1890e-04, 4.0460e-04,\n",
       "            3.6550e-04, 3.4738e-04, 3.2759e-04, 3.0541e-04, 2.1994e-04,\n",
       "            2.0659e-04, 1.5354e-04, 1.2147e-04, 1.0389e-04, 9.3877e-05,\n",
       "            9.1732e-05, 8.6129e-05, 8.3506e-05, 5.9664e-05, 3.5942e-05,\n",
       "            3.0696e-05, 1.9968e-05, 4.7088e-06], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.73275864, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.05223881, 0.05970149, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.61206895, 0.62068963, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9902e-01, 9.9854e-01, 9.9756e-01, 9.9707e-01,\n",
       "            9.9512e-01, 9.9316e-01, 9.9121e-01, 9.9023e-01, 9.8975e-01,\n",
       "            9.8535e-01, 9.8340e-01, 9.8096e-01, 9.7949e-01, 9.7803e-01,\n",
       "            9.7559e-01, 9.7412e-01, 9.7119e-01, 9.7070e-01, 9.7021e-01,\n",
       "            9.6875e-01, 9.6826e-01, 9.6680e-01, 9.6484e-01, 9.6436e-01,\n",
       "            9.6240e-01, 9.6143e-01, 9.6045e-01, 9.5996e-01, 9.5459e-01,\n",
       "            9.5264e-01, 9.4434e-01, 9.3896e-01, 9.3262e-01, 9.2188e-01,\n",
       "            9.2041e-01, 9.1699e-01, 9.0820e-01, 8.8037e-01, 8.7451e-01,\n",
       "            8.7158e-01, 8.7061e-01, 8.6035e-01, 8.5107e-01, 8.4570e-01,\n",
       "            8.4082e-01, 8.4033e-01, 8.3545e-01, 8.2617e-01, 8.1641e-01,\n",
       "            8.1445e-01, 8.0273e-01, 7.9541e-01, 7.7783e-01, 7.7734e-01,\n",
       "            7.5488e-01, 7.4854e-01, 7.4805e-01, 7.3779e-01, 7.3193e-01,\n",
       "            7.3096e-01, 7.2314e-01, 7.1289e-01, 7.1240e-01, 7.1143e-01,\n",
       "            7.0703e-01, 6.8506e-01, 6.8408e-01, 6.6357e-01, 6.5137e-01,\n",
       "            6.4795e-01, 6.4746e-01, 6.3721e-01, 6.3574e-01, 6.2158e-01,\n",
       "            5.8057e-01, 5.6689e-01, 5.5664e-01, 5.3271e-01, 5.2637e-01,\n",
       "            5.0342e-01, 4.7339e-01, 4.5874e-01, 4.5264e-01, 4.0381e-01,\n",
       "            3.4668e-01, 3.4131e-01, 3.1885e-01, 2.8735e-01, 2.8418e-01,\n",
       "            2.7808e-01, 2.7515e-01, 2.7124e-01, 2.6025e-01, 2.2900e-01,\n",
       "            2.2424e-01, 2.1179e-01, 2.0325e-01, 1.9531e-01, 1.9275e-01,\n",
       "            1.7871e-01, 1.7786e-01, 1.7383e-01, 1.4673e-01, 1.4221e-01,\n",
       "            1.0016e-01, 9.8572e-02, 9.0576e-02, 8.7891e-02, 8.6182e-02,\n",
       "            7.9468e-02, 7.6965e-02, 7.6660e-02, 7.3303e-02, 6.9641e-02,\n",
       "            6.8665e-02, 6.4270e-02, 6.1890e-02, 4.7516e-02, 4.5349e-02,\n",
       "            4.5197e-02, 3.9429e-02, 3.8239e-02, 3.4180e-02, 3.3661e-02,\n",
       "            3.3478e-02, 3.2776e-02, 2.2980e-02, 2.2034e-02, 2.1912e-02,\n",
       "            2.1820e-02, 2.1744e-02, 2.1408e-02, 1.9989e-02, 1.9608e-02,\n",
       "            1.8692e-02, 1.8646e-02, 1.7441e-02, 1.6724e-02, 1.5900e-02,\n",
       "            1.5190e-02, 1.4671e-02, 1.2772e-02, 1.2146e-02, 1.1871e-02,\n",
       "            1.1246e-02, 1.1116e-02, 1.0857e-02, 1.0246e-02, 1.0056e-02,\n",
       "            9.2697e-03, 9.1629e-03, 9.0866e-03, 8.9874e-03, 8.8501e-03,\n",
       "            8.7128e-03, 8.6136e-03, 8.4152e-03, 7.8430e-03, 7.7553e-03,\n",
       "            7.4043e-03, 7.0381e-03, 6.9580e-03, 6.8512e-03, 6.7444e-03,\n",
       "            6.3629e-03, 6.3400e-03, 6.3133e-03, 6.1226e-03, 6.0043e-03,\n",
       "            5.9357e-03, 5.6190e-03, 5.5542e-03, 5.1003e-03, 5.0621e-03,\n",
       "            4.8676e-03, 4.5395e-03, 4.3983e-03, 4.3488e-03, 4.2496e-03,\n",
       "            3.9597e-03, 3.8395e-03, 3.6640e-03, 3.5934e-03, 3.5515e-03,\n",
       "            3.4962e-03, 3.3760e-03, 3.2597e-03, 3.1853e-03, 3.1242e-03,\n",
       "            3.0994e-03, 2.9812e-03, 2.7790e-03, 2.5806e-03, 2.5311e-03,\n",
       "            2.5120e-03, 2.3785e-03, 2.3689e-03, 2.2335e-03, 2.1400e-03,\n",
       "            2.1076e-03, 2.0580e-03, 2.0504e-03, 2.0428e-03, 1.9646e-03,\n",
       "            1.9188e-03, 1.8606e-03, 1.6422e-03, 1.5364e-03, 1.4839e-03,\n",
       "            1.4610e-03, 1.4105e-03, 1.3514e-03, 1.0900e-03, 9.3269e-04,\n",
       "            9.2888e-04, 8.0729e-04, 6.3848e-04, 5.3167e-04, 5.2357e-04,\n",
       "            4.4250e-04, 4.2725e-04, 3.1996e-04, 2.8682e-04, 2.5916e-04,\n",
       "            2.4152e-04, 2.3234e-04, 2.0993e-04, 1.9872e-04, 1.8668e-04,\n",
       "            1.8525e-04, 1.2243e-04, 1.1414e-04, 8.4162e-05, 7.0870e-05,\n",
       "            5.5194e-05, 4.9472e-05, 4.8339e-05, 4.3333e-05, 3.0935e-05,\n",
       "            1.9073e-05, 1.6034e-05, 9.9540e-06, 2.2054e-06], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.73275864, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.88793105, 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9951e-01, 9.9902e-01, 9.9854e-01, 9.9805e-01,\n",
       "            9.9658e-01, 9.9561e-01, 9.9512e-01, 9.9365e-01, 9.9316e-01,\n",
       "            9.9268e-01, 9.8779e-01, 9.8535e-01, 9.8389e-01, 9.8242e-01,\n",
       "            9.8096e-01, 9.7949e-01, 9.7754e-01, 9.7705e-01, 9.7559e-01,\n",
       "            9.7412e-01, 9.7266e-01, 9.7021e-01, 9.6973e-01, 9.6826e-01,\n",
       "            9.6582e-01, 9.6387e-01, 9.6191e-01, 9.5947e-01, 9.5752e-01,\n",
       "            9.5020e-01, 9.4971e-01, 9.4873e-01, 9.4482e-01, 9.3408e-01,\n",
       "            9.3066e-01, 9.2188e-01, 9.2041e-01, 8.9258e-01, 8.8037e-01,\n",
       "            8.7061e-01, 8.6914e-01, 8.6816e-01, 8.5791e-01, 8.5547e-01,\n",
       "            8.5352e-01, 8.4863e-01, 8.4229e-01, 8.3887e-01, 8.2959e-01,\n",
       "            8.2227e-01, 8.0615e-01, 7.9395e-01, 7.9297e-01, 7.8809e-01,\n",
       "            7.6562e-01, 7.5928e-01, 7.5635e-01, 7.4854e-01, 7.4463e-01,\n",
       "            7.3779e-01, 7.3340e-01, 7.1826e-01, 7.1777e-01, 7.1436e-01,\n",
       "            6.9873e-01, 6.9141e-01, 6.9043e-01, 6.8359e-01, 6.7529e-01,\n",
       "            6.5771e-01, 6.5527e-01, 6.3330e-01, 6.3281e-01, 6.3232e-01,\n",
       "            6.2354e-01, 5.8789e-01, 5.8252e-01, 5.5713e-01, 5.3955e-01,\n",
       "            5.3516e-01, 5.0635e-01, 5.0586e-01, 4.7461e-01, 4.2920e-01,\n",
       "            4.2822e-01, 3.9844e-01, 3.4204e-01, 3.3203e-01, 3.1445e-01,\n",
       "            2.7026e-01, 2.6562e-01, 2.6074e-01, 2.5781e-01, 2.5342e-01,\n",
       "            2.4182e-01, 2.1985e-01, 1.9849e-01, 1.9641e-01, 1.8591e-01,\n",
       "            1.7725e-01, 1.7346e-01, 1.6052e-01, 1.5234e-01, 1.5076e-01,\n",
       "            1.3354e-01, 1.3098e-01, 8.7708e-02, 7.4890e-02, 7.3181e-02,\n",
       "            7.1960e-02, 7.0557e-02, 7.0068e-02, 6.7566e-02, 6.4636e-02,\n",
       "            5.7281e-02, 5.7190e-02, 5.6763e-02, 5.2612e-02, 3.8757e-02,\n",
       "            3.6713e-02, 3.3905e-02, 3.3600e-02, 3.0624e-02, 2.8275e-02,\n",
       "            2.7328e-02, 2.6962e-02, 2.6505e-02, 1.8295e-02, 1.7517e-02,\n",
       "            1.7044e-02, 1.6281e-02, 1.6098e-02, 1.5839e-02, 1.5717e-02,\n",
       "            1.4786e-02, 1.4618e-02, 1.4336e-02, 1.3275e-02, 1.2924e-02,\n",
       "            1.1826e-02, 1.0735e-02, 1.0612e-02, 9.5596e-03, 9.3765e-03,\n",
       "            8.2855e-03, 8.1253e-03, 8.0338e-03, 7.4615e-03, 7.4043e-03,\n",
       "            7.3738e-03, 7.2594e-03, 6.8779e-03, 6.7177e-03, 6.5880e-03,\n",
       "            6.4888e-03, 6.3896e-03, 6.0043e-03, 5.9586e-03, 5.8441e-03,\n",
       "            5.7526e-03, 5.5351e-03, 5.2414e-03, 5.0812e-03, 4.9057e-03,\n",
       "            4.8676e-03, 4.6997e-03, 4.4174e-03, 4.3983e-03, 4.2152e-03,\n",
       "            4.2000e-03, 4.0398e-03, 4.0245e-03, 3.9902e-03, 3.6926e-03,\n",
       "            3.4962e-03, 3.4027e-03, 3.2978e-03, 3.2864e-03, 3.0994e-03,\n",
       "            3.0632e-03, 2.9697e-03, 2.8458e-03, 2.7466e-03, 2.5711e-03,\n",
       "            2.4433e-03, 2.3689e-03, 2.1992e-03, 2.1496e-03, 2.1152e-03,\n",
       "            1.9417e-03, 1.8969e-03, 1.8826e-03, 1.8387e-03, 1.8244e-03,\n",
       "            1.7748e-03, 1.7271e-03, 1.5974e-03, 1.5192e-03, 1.4553e-03,\n",
       "            1.4267e-03, 1.2646e-03, 1.2398e-03, 1.2064e-03, 1.2016e-03,\n",
       "            1.1292e-03, 1.1158e-03, 1.0815e-03, 1.0691e-03, 9.7370e-04,\n",
       "            8.4591e-04, 8.0729e-04, 6.5136e-04, 6.0701e-04, 5.7697e-04,\n",
       "            5.6171e-04, 3.6407e-04, 2.9588e-04, 2.9373e-04, 2.2519e-04,\n",
       "            1.6737e-04, 1.5593e-04, 1.4544e-04, 1.3030e-04, 1.2529e-04,\n",
       "            1.0723e-04, 1.0389e-04, 1.0151e-04, 9.3162e-05, 6.0618e-05,\n",
       "            5.6505e-05, 4.5061e-05, 3.3975e-05, 2.7955e-05, 2.5272e-05,\n",
       "            2.3186e-05, 2.2471e-05, 1.5676e-05, 8.4639e-06, 7.0930e-06,\n",
       "            4.1127e-06, 8.3447e-07], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.70689654, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01724138, 0.02586207, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.36206895, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 9.9951e-01, 9.9854e-01, 9.9805e-01, 9.9658e-01,\n",
       "            9.9561e-01, 9.9512e-01, 9.9365e-01, 9.9268e-01, 9.9219e-01,\n",
       "            9.8779e-01, 9.8535e-01, 9.8389e-01, 9.8193e-01, 9.8047e-01,\n",
       "            9.7900e-01, 9.7656e-01, 9.7607e-01, 9.7559e-01, 9.7510e-01,\n",
       "            9.7266e-01, 9.6973e-01, 9.6924e-01, 9.6826e-01, 9.6484e-01,\n",
       "            9.6289e-01, 9.6094e-01, 9.5801e-01, 9.5703e-01, 9.4824e-01,\n",
       "            9.4775e-01, 9.4629e-01, 9.4287e-01, 9.2920e-01, 9.2773e-01,\n",
       "            9.1602e-01, 9.1504e-01, 8.8477e-01, 8.7646e-01, 8.6035e-01,\n",
       "            8.5938e-01, 8.4814e-01, 8.4082e-01, 8.3691e-01, 8.3643e-01,\n",
       "            8.3057e-01, 8.2715e-01, 8.1055e-01, 7.9980e-01, 7.7930e-01,\n",
       "            7.7295e-01, 7.5830e-01, 7.5098e-01, 7.3828e-01, 7.3730e-01,\n",
       "            7.3682e-01, 7.2852e-01, 7.2705e-01, 6.9531e-01, 6.9287e-01,\n",
       "            6.8896e-01, 6.7480e-01, 6.7285e-01, 6.7041e-01, 6.4844e-01,\n",
       "            6.4746e-01, 6.4209e-01, 6.3135e-01, 6.2207e-01, 6.0303e-01,\n",
       "            6.0156e-01, 5.9424e-01, 5.8057e-01, 5.5322e-01, 5.4102e-01,\n",
       "            5.2637e-01, 5.2051e-01, 4.9805e-01, 4.7632e-01, 4.6875e-01,\n",
       "            4.3945e-01, 3.8745e-01, 3.6890e-01, 3.5962e-01, 3.0933e-01,\n",
       "            2.9346e-01, 2.8662e-01, 2.4072e-01, 2.3279e-01, 2.2302e-01,\n",
       "            2.1997e-01, 2.1533e-01, 2.1472e-01, 1.9177e-01, 1.6577e-01,\n",
       "            1.5369e-01, 1.5259e-01, 1.4453e-01, 1.3477e-01, 1.2146e-01,\n",
       "            1.2128e-01, 1.1456e-01, 1.1102e-01, 1.1084e-01, 7.2632e-02,\n",
       "            6.1310e-02, 5.8777e-02, 5.7190e-02, 5.5511e-02, 5.2521e-02,\n",
       "            5.2032e-02, 4.9866e-02, 4.8492e-02, 4.5013e-02, 4.4189e-02,\n",
       "            4.2480e-02, 4.0161e-02, 2.9877e-02, 2.4994e-02, 2.3468e-02,\n",
       "            2.2842e-02, 2.1820e-02, 2.1622e-02, 2.0370e-02, 1.7776e-02,\n",
       "            1.4175e-02, 1.3023e-02, 1.1688e-02, 1.1246e-02, 1.1116e-02,\n",
       "            1.0735e-02, 1.0651e-02, 9.8953e-03, 9.8572e-03, 9.7809e-03,\n",
       "            9.2316e-03, 8.5144e-03, 8.3771e-03, 7.2899e-03, 7.1754e-03,\n",
       "            7.1220e-03, 6.3400e-03, 5.5771e-03, 5.5122e-03, 5.3444e-03,\n",
       "            4.9820e-03, 4.8103e-03, 4.7913e-03, 4.5395e-03, 4.4861e-03,\n",
       "            4.3297e-03, 4.1008e-03, 3.9902e-03, 3.9597e-03, 3.9444e-03,\n",
       "            3.7498e-03, 3.7365e-03, 3.6926e-03, 3.6221e-03, 3.4428e-03,\n",
       "            3.2597e-03, 3.2101e-03, 3.0155e-03, 2.9011e-03, 2.8896e-03,\n",
       "            2.7046e-03, 2.6836e-03, 2.6627e-03, 2.6531e-03, 2.6016e-03,\n",
       "            2.4815e-03, 2.4242e-03, 2.3327e-03, 2.1572e-03, 2.1076e-03,\n",
       "            2.0752e-03, 1.9951e-03, 1.9121e-03, 1.7891e-03, 1.7548e-03,\n",
       "            1.6422e-03, 1.4496e-03, 1.3990e-03, 1.3409e-03, 1.3094e-03,\n",
       "            1.2846e-03, 1.2741e-03, 1.2016e-03, 1.1787e-03, 1.1473e-03,\n",
       "            1.0691e-03, 1.0567e-03, 1.0042e-03, 9.6989e-04, 9.5844e-04,\n",
       "            8.2302e-04, 7.7915e-04, 7.2098e-04, 7.0429e-04, 6.9332e-04,\n",
       "            6.8521e-04, 6.2895e-04, 6.2370e-04, 6.1178e-04, 6.0701e-04,\n",
       "            5.3596e-04, 4.7112e-04, 4.4584e-04, 4.0460e-04, 3.7408e-04,\n",
       "            3.4332e-04, 2.9588e-04, 1.9109e-04, 1.5235e-04, 1.5116e-04,\n",
       "            1.1414e-04, 1.1146e-04, 8.3506e-05, 7.7248e-05, 6.8665e-05,\n",
       "            6.3002e-05, 6.1095e-05, 5.1439e-05, 5.0247e-05, 4.8697e-05,\n",
       "            4.5061e-05, 2.8193e-05, 2.6047e-05, 2.0623e-05, 1.5557e-05,\n",
       "            1.2517e-05, 1.1206e-05, 1.0073e-05, 9.9540e-06, 6.7949e-06,\n",
       "            3.5167e-06, 2.9206e-06, 1.6093e-06, 2.9802e-07], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.7413793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29850745, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01724138, 0.02586207, 0.03448276, 0.05172414,\n",
       "            0.06034483, 0.06896552, 0.0775862 , 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.14655173,\n",
       "            0.15517241, 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.22413793, 0.23275863, 0.2413793 , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.95689654, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.000e+00, 1.000e+00, 9.995e-01, 9.990e-01, 9.985e-01, 9.980e-01,\n",
       "            9.976e-01, 9.971e-01, 9.966e-01, 9.927e-01, 9.917e-01, 9.912e-01,\n",
       "            9.907e-01, 9.897e-01, 9.893e-01, 9.888e-01, 9.883e-01, 9.878e-01,\n",
       "            9.868e-01, 9.858e-01, 9.854e-01, 9.775e-01, 9.771e-01, 9.746e-01,\n",
       "            9.731e-01, 9.722e-01, 9.707e-01, 9.697e-01, 9.692e-01, 9.688e-01,\n",
       "            9.609e-01, 9.604e-01, 9.600e-01, 9.526e-01, 9.336e-01, 9.316e-01,\n",
       "            9.043e-01, 9.004e-01, 8.984e-01, 8.975e-01, 8.911e-01, 8.901e-01,\n",
       "            8.853e-01, 8.823e-01, 8.789e-01, 8.774e-01, 8.589e-01, 8.472e-01,\n",
       "            8.423e-01, 8.384e-01, 8.276e-01, 8.203e-01, 8.120e-01, 7.993e-01,\n",
       "            7.896e-01, 7.827e-01, 7.817e-01, 7.793e-01, 7.720e-01, 7.612e-01,\n",
       "            7.417e-01, 7.407e-01, 7.383e-01, 7.261e-01, 7.207e-01, 7.183e-01,\n",
       "            6.929e-01, 6.885e-01, 6.797e-01, 6.436e-01, 6.396e-01, 6.387e-01,\n",
       "            6.011e-01, 5.703e-01, 5.698e-01, 5.645e-01, 5.469e-01, 5.332e-01,\n",
       "            5.298e-01, 5.039e-01, 4.453e-01, 4.429e-01, 4.060e-01, 3.838e-01,\n",
       "            3.679e-01, 3.181e-01, 2.827e-01, 2.666e-01, 2.512e-01, 2.410e-01,\n",
       "            2.360e-01, 2.109e-01, 2.045e-01, 1.942e-01, 1.838e-01, 1.805e-01,\n",
       "            1.804e-01, 1.448e-01, 1.438e-01, 1.381e-01, 1.375e-01, 1.361e-01,\n",
       "            1.332e-01, 7.666e-02, 6.915e-02, 6.561e-02, 6.549e-02, 6.439e-02,\n",
       "            6.021e-02, 5.167e-02, 4.559e-02, 4.443e-02, 4.327e-02, 4.288e-02,\n",
       "            3.366e-02, 2.748e-02, 2.596e-02, 2.504e-02, 2.324e-02, 2.280e-02,\n",
       "            2.177e-02, 2.136e-02, 1.976e-02, 1.785e-02, 1.297e-02, 1.253e-02,\n",
       "            1.196e-02, 1.107e-02, 1.103e-02, 1.049e-02, 1.021e-02, 1.017e-02,\n",
       "            9.300e-03, 8.217e-03, 8.003e-03, 7.095e-03, 6.489e-03, 6.363e-03,\n",
       "            6.168e-03, 6.145e-03, 5.322e-03, 5.302e-03, 4.608e-03, 4.417e-03,\n",
       "            3.975e-03, 3.944e-03, 3.914e-03, 3.565e-03, 3.496e-03, 3.469e-03,\n",
       "            3.389e-03, 3.325e-03, 3.260e-03, 3.160e-03, 3.147e-03, 3.040e-03,\n",
       "            2.901e-03, 2.758e-03, 2.737e-03, 2.726e-03, 2.705e-03, 2.653e-03,\n",
       "            2.512e-03, 2.493e-03, 2.296e-03, 2.279e-03, 2.270e-03, 2.174e-03,\n",
       "            2.050e-03, 2.020e-03, 1.934e-03, 1.861e-03, 1.782e-03, 1.775e-03,\n",
       "            1.768e-03, 1.623e-03, 1.519e-03, 1.467e-03, 1.367e-03, 1.335e-03,\n",
       "            1.197e-03, 1.179e-03, 1.116e-03, 1.099e-03, 1.065e-03, 1.037e-03,\n",
       "            9.737e-04, 9.074e-04, 8.659e-04, 8.593e-04, 7.496e-04, 6.986e-04,\n",
       "            6.800e-04, 6.213e-04, 5.975e-04, 5.593e-04, 5.527e-04, 5.274e-04,\n",
       "            4.306e-04, 4.125e-04, 3.829e-04, 3.815e-04, 3.684e-04, 3.569e-04,\n",
       "            3.276e-04, 3.176e-04, 3.006e-04, 2.847e-04, 2.592e-04, 1.442e-04,\n",
       "            1.187e-04, 9.030e-05, 8.959e-05, 6.109e-05, 5.269e-05, 4.506e-05,\n",
       "            4.470e-05, 4.268e-05, 3.195e-05, 2.998e-05, 2.933e-05, 2.646e-05,\n",
       "            2.509e-05, 2.229e-05, 1.395e-05, 1.281e-05, 1.121e-05, 7.033e-06,\n",
       "            6.318e-06, 5.782e-06, 5.364e-06, 4.530e-06, 4.411e-06, 3.338e-06,\n",
       "            1.431e-06, 1.192e-06, 6.557e-07, 1.192e-07], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.70689654, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.05223881, 0.05970149, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.01724138, 0.02586207, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06896552, 0.0775862 , 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.8965517 , 0.9137931 , 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 1.0000e+00, 9.9951e-01, 9.9902e-01, 9.9854e-01,\n",
       "            9.9805e-01, 9.9756e-01, 9.9658e-01, 9.9512e-01, 9.9268e-01,\n",
       "            9.9170e-01, 9.9121e-01, 9.9023e-01, 9.8975e-01, 9.8926e-01,\n",
       "            9.8828e-01, 9.8730e-01, 9.8633e-01, 9.8584e-01, 9.8438e-01,\n",
       "            9.8389e-01, 9.8193e-01, 9.8047e-01, 9.7949e-01, 9.7852e-01,\n",
       "            9.7656e-01, 9.7607e-01, 9.7461e-01, 9.7217e-01, 9.7168e-01,\n",
       "            9.6973e-01, 9.6631e-01, 9.6582e-01, 9.6533e-01, 9.5361e-01,\n",
       "            9.5117e-01, 9.4434e-01, 9.3896e-01, 9.1895e-01, 9.0918e-01,\n",
       "            8.9258e-01, 8.9111e-01, 8.8818e-01, 8.8037e-01, 8.7988e-01,\n",
       "            8.7891e-01, 8.6377e-01, 8.5840e-01, 8.4863e-01, 8.4473e-01,\n",
       "            8.4375e-01, 8.2471e-01, 8.0322e-01, 7.9883e-01, 7.9053e-01,\n",
       "            7.8662e-01, 7.8564e-01, 7.7539e-01, 7.7393e-01, 7.6611e-01,\n",
       "            7.3486e-01, 7.3242e-01, 7.2607e-01, 7.1826e-01, 7.1680e-01,\n",
       "            6.9971e-01, 6.8066e-01, 6.7480e-01, 6.7236e-01, 6.4453e-01,\n",
       "            6.3770e-01, 6.3428e-01, 6.3232e-01, 5.8887e-01, 5.8252e-01,\n",
       "            5.6787e-01, 5.5908e-01, 5.1855e-01, 5.0000e-01, 4.9365e-01,\n",
       "            4.8999e-01, 4.5605e-01, 3.8843e-01, 3.6353e-01, 3.5522e-01,\n",
       "            3.1543e-01, 3.0127e-01, 2.9004e-01, 2.4634e-01, 2.2986e-01,\n",
       "            2.1765e-01, 2.1289e-01, 2.1082e-01, 1.9055e-01, 1.5588e-01,\n",
       "            1.5271e-01, 1.3501e-01, 1.2659e-01, 1.2634e-01, 1.1517e-01,\n",
       "            1.0144e-01, 9.8572e-02, 9.5154e-02, 9.0393e-02, 6.4880e-02,\n",
       "            5.3802e-02, 5.0903e-02, 5.0232e-02, 4.7150e-02, 4.0771e-02,\n",
       "            3.8177e-02, 3.6438e-02, 3.6163e-02, 3.5156e-02, 3.3386e-02,\n",
       "            2.7008e-02, 2.1164e-02, 1.8829e-02, 1.8646e-02, 1.7776e-02,\n",
       "            1.6342e-02, 1.6281e-02, 1.5717e-02, 1.4061e-02, 1.3275e-02,\n",
       "            1.0612e-02, 1.0056e-02, 7.8125e-03, 7.4615e-03, 6.9847e-03,\n",
       "            6.9580e-03, 6.8779e-03, 6.3629e-03, 6.2408e-03, 6.1226e-03,\n",
       "            5.9814e-03, 5.1994e-03, 4.5547e-03, 4.4670e-03, 3.9139e-03,\n",
       "            3.7498e-03, 3.6068e-03, 3.2234e-03, 3.2101e-03, 2.7046e-03,\n",
       "            2.6836e-03, 2.4529e-03, 2.4338e-03, 2.3880e-03, 2.1992e-03,\n",
       "            2.1820e-03, 2.1400e-03, 2.1000e-03, 2.0428e-03, 1.9646e-03,\n",
       "            1.8530e-03, 1.8387e-03, 1.8177e-03, 1.7958e-03, 1.7414e-03,\n",
       "            1.6680e-03, 1.5249e-03, 1.5192e-03, 1.5068e-03, 1.4954e-03,\n",
       "            1.4782e-03, 1.4496e-03, 1.4324e-03, 1.3247e-03, 1.3199e-03,\n",
       "            1.3046e-03, 1.2598e-03, 1.2016e-03, 1.1473e-03, 1.1425e-03,\n",
       "            1.0862e-03, 1.0443e-03, 1.0042e-03, 9.5463e-04, 8.3303e-04,\n",
       "            7.5817e-04, 7.4959e-04, 7.2670e-04, 7.2098e-04, 6.7711e-04,\n",
       "            6.5374e-04, 6.3372e-04, 5.8842e-04, 5.6362e-04, 5.5265e-04,\n",
       "            5.2547e-04, 4.5300e-04, 4.1580e-04, 3.9506e-04, 3.6263e-04,\n",
       "            3.2496e-04, 3.2258e-04, 3.0303e-04, 2.8253e-04, 2.7156e-04,\n",
       "            2.1827e-04, 2.1148e-04, 1.9872e-04, 1.9109e-04, 1.8811e-04,\n",
       "            1.8525e-04, 1.7953e-04, 1.6606e-04, 1.5354e-04, 1.4091e-04,\n",
       "            1.3137e-04, 6.5565e-05, 5.4359e-05, 4.1008e-05, 4.0710e-05,\n",
       "            2.7299e-05, 2.2650e-05, 1.9670e-05, 1.9073e-05, 1.8954e-05,\n",
       "            1.3530e-05, 1.2696e-05, 1.2517e-05, 1.1027e-05, 1.0431e-05,\n",
       "            9.6560e-06, 5.6624e-06, 5.1260e-06, 4.5896e-06, 2.8014e-06,\n",
       "            2.5034e-06, 2.2650e-06, 2.0266e-06, 1.7285e-06, 1.6689e-06,\n",
       "            1.2517e-06, 5.3644e-07, 4.1723e-07, 2.3842e-07, 5.9605e-08],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.7241379, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01724138, 0.02586207, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06896552, 0.0775862 , 0.09482758, 0.10344828,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.18103448, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 1.0000e+00, 9.9951e-01, 9.9902e-01, 9.9854e-01,\n",
       "            9.9805e-01, 9.9756e-01, 9.9658e-01, 9.9512e-01, 9.9316e-01,\n",
       "            9.9219e-01, 9.9121e-01, 9.9023e-01, 9.8975e-01, 9.8926e-01,\n",
       "            9.8828e-01, 9.8730e-01, 9.8682e-01, 9.8535e-01, 9.8486e-01,\n",
       "            9.8340e-01, 9.8291e-01, 9.8145e-01, 9.8096e-01, 9.7998e-01,\n",
       "            9.7803e-01, 9.7656e-01, 9.7607e-01, 9.7168e-01, 9.6680e-01,\n",
       "            9.6484e-01, 9.5752e-01, 9.5410e-01, 9.5117e-01, 9.4189e-01,\n",
       "            9.2041e-01, 9.1992e-01, 9.1895e-01, 9.0137e-01, 8.9355e-01,\n",
       "            8.8721e-01, 8.8037e-01, 8.7988e-01, 8.5938e-01, 8.5889e-01,\n",
       "            8.5693e-01, 8.5107e-01, 8.4473e-01, 8.3936e-01, 8.3252e-01,\n",
       "            8.0615e-01, 8.0176e-01, 7.9590e-01, 7.8516e-01, 7.7686e-01,\n",
       "            7.7588e-01, 7.6855e-01, 7.5586e-01, 7.4805e-01, 7.3779e-01,\n",
       "            7.2754e-01, 6.8311e-01, 6.8262e-01, 6.8018e-01, 6.7676e-01,\n",
       "            6.7139e-01, 6.6943e-01, 6.6553e-01, 6.6260e-01, 6.3330e-01,\n",
       "            6.1914e-01, 5.9521e-01, 5.8789e-01, 5.8057e-01, 5.6738e-01,\n",
       "            5.3809e-01, 5.3076e-01, 5.2002e-01, 4.8706e-01, 4.3604e-01,\n",
       "            4.3335e-01, 3.3716e-01, 3.1616e-01, 2.9492e-01, 2.9370e-01,\n",
       "            2.6392e-01, 2.4023e-01, 2.3340e-01, 2.2461e-01, 1.8970e-01,\n",
       "            1.8567e-01, 1.7578e-01, 1.4941e-01, 1.3513e-01, 1.1420e-01,\n",
       "            1.0614e-01, 1.0303e-01, 9.0088e-02, 8.9600e-02, 8.5083e-02,\n",
       "            7.9651e-02, 7.5317e-02, 7.0801e-02, 6.1096e-02, 4.9774e-02,\n",
       "            4.4434e-02, 4.2389e-02, 4.0680e-02, 3.1799e-02, 3.0212e-02,\n",
       "            2.8656e-02, 2.8488e-02, 2.8442e-02, 2.6611e-02, 1.9302e-02,\n",
       "            1.8433e-02, 1.5602e-02, 1.5190e-02, 1.4008e-02, 1.3901e-02,\n",
       "            1.3168e-02, 1.0696e-02, 1.0208e-02, 8.3771e-03, 8.3160e-03,\n",
       "            7.1220e-03, 5.9128e-03, 5.5351e-03, 5.0011e-03, 4.8294e-03,\n",
       "            4.7188e-03, 4.5547e-03, 4.4174e-03, 4.2152e-03, 4.0550e-03,\n",
       "            3.9444e-03, 3.4428e-03, 2.9240e-03, 2.8458e-03, 2.7905e-03,\n",
       "            2.3975e-03, 2.2964e-03, 2.1496e-03, 2.0027e-03, 1.7824e-03,\n",
       "            1.6489e-03, 1.6041e-03, 1.5917e-03, 1.4782e-03, 1.4381e-03,\n",
       "            1.4324e-03, 1.3409e-03, 1.3151e-03, 1.2941e-03, 1.2846e-03,\n",
       "            1.2741e-03, 1.2207e-03, 1.1292e-03, 1.1120e-03, 1.0862e-03,\n",
       "            1.0777e-03, 1.0729e-03, 1.0653e-03, 1.0605e-03, 1.0567e-03,\n",
       "            1.0481e-03, 1.0319e-03, 1.0080e-03, 1.0004e-03, 9.6226e-04,\n",
       "            9.1839e-04, 8.7595e-04, 8.2970e-04, 7.8535e-04, 7.4100e-04,\n",
       "            7.3528e-04, 7.1239e-04, 7.0667e-04, 7.0143e-04, 6.9857e-04,\n",
       "            6.4611e-04, 5.5504e-04, 5.2357e-04, 4.9734e-04, 4.7851e-04,\n",
       "            4.6563e-04, 4.4584e-04, 4.2725e-04, 4.1580e-04, 4.0936e-04,\n",
       "            3.8147e-04, 3.5834e-04, 3.4070e-04, 3.1018e-04, 2.7585e-04,\n",
       "            2.6321e-04, 2.3973e-04, 2.2519e-04, 2.0659e-04, 2.0182e-04,\n",
       "            1.9407e-04, 1.8966e-04, 1.6093e-04, 1.3447e-04, 1.3030e-04,\n",
       "            1.1772e-04, 1.1683e-04, 1.1235e-04, 1.0639e-04, 9.9957e-05,\n",
       "            9.6858e-05, 8.2195e-05, 7.9691e-05, 4.0710e-05, 2.8431e-05,\n",
       "            2.1100e-05, 2.0921e-05, 1.4305e-05, 1.3292e-05, 1.1027e-05,\n",
       "            9.5963e-06, 7.9870e-06, 7.2122e-06, 6.5565e-06, 5.8413e-06,\n",
       "            5.3048e-06, 5.1856e-06, 4.9472e-06, 2.5630e-06, 2.3246e-06,\n",
       "            1.9670e-06, 1.4305e-06, 1.0729e-06, 9.5367e-07, 8.9407e-07,\n",
       "            8.3447e-07, 7.1526e-07, 5.3644e-07, 2.3842e-07, 1.7881e-07,\n",
       "            1.1921e-07, 0.0000e+00], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.6896552, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.07462686, 0.07462686,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9477612 ,\n",
       "            0.96268654, 0.9701493 , 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01724138, 0.02586207, 0.03448276, 0.05172414,\n",
       "            0.06896552, 0.0775862 , 0.0862069 , 0.09482758, 0.10344828,\n",
       "            0.11206897, 0.12931034, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 1.0000e+00, 9.9951e-01, 9.9902e-01, 9.9854e-01,\n",
       "            9.9805e-01, 9.9707e-01, 9.9512e-01, 9.9365e-01, 9.9219e-01,\n",
       "            9.9121e-01, 9.9023e-01, 9.8975e-01, 9.8828e-01, 9.8682e-01,\n",
       "            9.8584e-01, 9.8389e-01, 9.8340e-01, 9.7998e-01, 9.7852e-01,\n",
       "            9.7803e-01, 9.7607e-01, 9.7363e-01, 9.7314e-01, 9.7168e-01,\n",
       "            9.7021e-01, 9.6875e-01, 9.6582e-01, 9.5557e-01, 9.5020e-01,\n",
       "            9.4385e-01, 9.4189e-01, 9.1992e-01, 9.0039e-01, 8.9502e-01,\n",
       "            8.9355e-01, 8.7793e-01, 8.7744e-01, 8.7451e-01, 8.6084e-01,\n",
       "            8.5254e-01, 8.4717e-01, 8.3154e-01, 8.2373e-01, 8.1885e-01,\n",
       "            8.1836e-01, 8.0762e-01, 8.0664e-01, 7.6953e-01, 7.6514e-01,\n",
       "            7.6318e-01, 7.5244e-01, 7.4951e-01, 7.3145e-01, 7.1875e-01,\n",
       "            7.1143e-01, 6.9336e-01, 6.7285e-01, 6.7188e-01, 6.4844e-01,\n",
       "            6.4404e-01, 6.3428e-01, 6.1035e-01, 6.0986e-01, 6.0352e-01,\n",
       "            5.9766e-01, 5.7520e-01, 5.6592e-01, 5.2930e-01, 5.1514e-01,\n",
       "            5.1270e-01, 4.8633e-01, 4.7095e-01, 4.5703e-01, 4.4971e-01,\n",
       "            3.9600e-01, 3.5303e-01, 3.0347e-01, 2.9736e-01, 2.7832e-01,\n",
       "            2.6367e-01, 2.4060e-01, 2.2742e-01, 1.8372e-01, 1.8298e-01,\n",
       "            1.7908e-01, 1.5369e-01, 1.3440e-01, 1.3318e-01, 9.3506e-02,\n",
       "            8.9783e-02, 8.4778e-02, 8.2825e-02, 8.1665e-02, 7.5195e-02,\n",
       "            6.9275e-02, 6.1981e-02, 5.7922e-02, 5.4504e-02, 5.3314e-02,\n",
       "            4.5349e-02, 3.6835e-02, 3.6621e-02, 3.3203e-02, 3.0273e-02,\n",
       "            2.0370e-02, 1.9684e-02, 1.8692e-02, 1.7578e-02, 1.6785e-02,\n",
       "            1.3634e-02, 1.2238e-02, 1.0406e-02, 9.4528e-03, 9.4147e-03,\n",
       "            8.7433e-03, 8.6441e-03, 7.2327e-03, 7.0381e-03, 6.4392e-03,\n",
       "            4.7188e-03, 4.1656e-03, 4.1504e-03, 3.7365e-03, 3.5801e-03,\n",
       "            3.2978e-03, 2.9583e-03, 2.8114e-03, 2.7142e-03, 2.5024e-03,\n",
       "            2.4719e-03, 2.4624e-03, 2.0905e-03, 2.0676e-03, 2.0199e-03,\n",
       "            1.8387e-03, 1.6747e-03, 1.4324e-03, 1.3723e-03, 1.3304e-03,\n",
       "            1.2159e-03, 1.0729e-03, 9.9277e-04, 9.8515e-04, 9.2888e-04,\n",
       "            8.6927e-04, 8.5592e-04, 8.4591e-04, 8.3923e-04, 7.6437e-04,\n",
       "            7.5817e-04, 7.4959e-04, 7.4100e-04, 6.9332e-04, 6.7997e-04,\n",
       "            6.6137e-04, 6.5136e-04, 6.4611e-04, 6.4135e-04, 6.2656e-04,\n",
       "            6.1178e-04, 5.8842e-04, 5.6601e-04, 5.5504e-04, 5.5265e-04,\n",
       "            5.4836e-04, 5.2547e-04, 4.9353e-04, 4.5657e-04, 4.4084e-04,\n",
       "            4.2892e-04, 4.2224e-04, 4.1723e-04, 4.0126e-04, 3.6979e-04,\n",
       "            3.4070e-04, 3.3545e-04, 3.0065e-04, 2.8920e-04, 2.7585e-04,\n",
       "            2.7370e-04, 2.6727e-04, 2.5129e-04, 2.3973e-04, 2.2697e-04,\n",
       "            2.0993e-04, 1.9872e-04, 1.6737e-04, 1.4997e-04, 1.2827e-04,\n",
       "            1.2732e-04, 1.1235e-04, 1.0806e-04, 9.6083e-05, 8.8871e-05,\n",
       "            8.4162e-05, 6.7115e-05, 6.6042e-05, 6.3002e-05, 5.7817e-05,\n",
       "            5.6088e-05, 5.1022e-05, 5.0664e-05, 4.2975e-05, 3.9756e-05,\n",
       "            1.6809e-05, 1.3530e-05, 9.8944e-06, 9.8348e-06, 6.4373e-06,\n",
       "            5.3644e-06, 4.7684e-06, 4.3511e-06, 3.4571e-06, 2.8610e-06,\n",
       "            2.8014e-06, 2.5034e-06, 2.2650e-06, 2.0862e-06, 1.0729e-06,\n",
       "            9.5367e-07, 8.3447e-07, 5.9605e-07, 4.1723e-07, 3.5763e-07,\n",
       "            2.9802e-07, 1.7881e-07, 5.9605e-08, 0.0000e+00], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.7241379, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.05223881, 0.05970149, 0.05970149, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5597015 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9402985 , 0.96268654, 0.97761196,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.02586207, 0.04310345, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.13793103,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 1.0000e+00, 9.9951e-01, 9.9902e-01, 9.9805e-01,\n",
       "            9.9756e-01, 9.9658e-01, 9.9561e-01, 9.9512e-01, 9.9463e-01,\n",
       "            9.9414e-01, 9.9316e-01, 9.9268e-01, 9.9219e-01, 9.9121e-01,\n",
       "            9.9072e-01, 9.8975e-01, 9.8877e-01, 9.8682e-01, 9.8633e-01,\n",
       "            9.8584e-01, 9.8438e-01, 9.8389e-01, 9.8340e-01, 9.7998e-01,\n",
       "            9.7705e-01, 9.7021e-01, 9.6924e-01, 9.6289e-01, 9.5996e-01,\n",
       "            9.4971e-01, 9.3994e-01, 9.2578e-01, 9.2383e-01, 9.2285e-01,\n",
       "            9.1992e-01, 9.1895e-01, 9.0869e-01, 9.0039e-01, 8.9844e-01,\n",
       "            8.8867e-01, 8.8379e-01, 8.8037e-01, 8.7451e-01, 8.6426e-01,\n",
       "            8.4180e-01, 8.3740e-01, 8.3350e-01, 8.2275e-01, 8.2129e-01,\n",
       "            8.0176e-01, 7.9004e-01, 7.8320e-01, 7.6855e-01, 7.6709e-01,\n",
       "            7.6660e-01, 7.5732e-01, 7.2363e-01, 7.1240e-01, 6.9629e-01,\n",
       "            6.8604e-01, 6.7871e-01, 6.7773e-01, 6.7676e-01, 6.7236e-01,\n",
       "            6.6699e-01, 6.5234e-01, 6.3232e-01, 6.2061e-01, 5.8496e-01,\n",
       "            5.7666e-01, 5.3271e-01, 5.2197e-01, 5.1465e-01, 4.8462e-01,\n",
       "            3.7378e-01, 3.3447e-01, 3.3105e-01, 3.1299e-01, 3.0908e-01,\n",
       "            3.0884e-01, 2.9028e-01, 2.4109e-01, 2.1350e-01, 2.0886e-01,\n",
       "            1.9836e-01, 1.8030e-01, 1.7627e-01, 1.2488e-01, 1.1633e-01,\n",
       "            1.0724e-01, 9.4177e-02, 8.7585e-02, 8.5266e-02, 7.5439e-02,\n",
       "            7.1838e-02, 6.5369e-02, 5.7281e-02, 5.4810e-02, 5.2246e-02,\n",
       "            4.1779e-02, 4.0375e-02, 3.9856e-02, 3.8239e-02, 2.5711e-02,\n",
       "            2.4796e-02, 2.3376e-02, 2.2369e-02, 1.7303e-02, 1.5015e-02,\n",
       "            1.2527e-02, 1.2238e-02, 1.0452e-02, 9.7122e-03, 8.8501e-03,\n",
       "            7.4615e-03, 7.3166e-03, 6.2180e-03, 6.1226e-03, 5.0201e-03,\n",
       "            4.6654e-03, 4.0245e-03, 3.8853e-03, 3.8090e-03, 3.3112e-03,\n",
       "            3.2597e-03, 3.1242e-03, 3.0632e-03, 2.8782e-03, 2.8553e-03,\n",
       "            2.7676e-03, 2.4242e-03, 2.3785e-03, 2.2335e-03, 1.8530e-03,\n",
       "            1.5192e-03, 1.4105e-03, 1.3409e-03, 1.1787e-03, 1.0815e-03,\n",
       "            1.0529e-03, 1.0319e-03, 9.7752e-04, 9.5844e-04, 9.3985e-04,\n",
       "            8.3923e-04, 8.1062e-04, 7.5531e-04, 7.5245e-04, 7.4673e-04,\n",
       "            7.0953e-04, 7.0143e-04, 6.7472e-04, 6.4373e-04, 6.4135e-04,\n",
       "            6.1178e-04, 5.8842e-04, 5.7459e-04, 5.4216e-04, 5.2977e-04,\n",
       "            5.2357e-04, 4.9925e-04, 4.8399e-04, 4.7278e-04, 4.6921e-04,\n",
       "            4.3559e-04, 4.2892e-04, 3.9196e-04, 3.7265e-04, 3.6979e-04,\n",
       "            3.6120e-04, 3.2759e-04, 3.1257e-04, 3.0065e-04, 2.8920e-04,\n",
       "            2.7585e-04, 2.6131e-04, 2.5725e-04, 2.4343e-04, 2.2876e-04,\n",
       "            2.1482e-04, 1.8668e-04, 1.6224e-04, 1.4544e-04, 1.3661e-04,\n",
       "            1.2052e-04, 1.1504e-04, 1.0473e-04, 9.3162e-05, 7.8440e-05,\n",
       "            6.7115e-05, 5.9187e-05, 5.8293e-05, 5.3883e-05, 4.9889e-05,\n",
       "            4.1664e-05, 3.8803e-05, 3.5346e-05, 3.2425e-05, 2.9802e-05,\n",
       "            2.4140e-05, 2.3901e-05, 2.2292e-05, 8.8811e-06, 7.2718e-06,\n",
       "            5.1260e-06, 5.0664e-06, 3.2187e-06, 2.6226e-06, 2.4438e-06,\n",
       "            2.1458e-06, 1.6689e-06, 1.3709e-06, 1.3113e-06, 1.1921e-06,\n",
       "            1.1325e-06, 1.0133e-06, 9.5367e-07, 4.7684e-07, 4.1723e-07,\n",
       "            3.5763e-07, 2.3842e-07, 1.7881e-07, 1.1921e-07, 5.9605e-08,\n",
       "            0.0000e+00], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.70689654, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.91791046, 0.92537314, 0.9701493 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.02586207, 0.05172414, 0.06034483, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.13793103, 0.14655173, 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.0000e+00, 1.0000e+00, 9.9951e-01, 9.9902e-01, 9.9854e-01,\n",
       "            9.9805e-01, 9.9707e-01, 9.9658e-01, 9.9609e-01, 9.9561e-01,\n",
       "            9.9463e-01, 9.9414e-01, 9.9365e-01, 9.9268e-01, 9.9219e-01,\n",
       "            9.9121e-01, 9.9072e-01, 9.9023e-01, 9.8877e-01, 9.8828e-01,\n",
       "            9.8779e-01, 9.8730e-01, 9.8535e-01, 9.8389e-01, 9.7998e-01,\n",
       "            9.7754e-01, 9.7021e-01, 9.6338e-01, 9.5947e-01, 9.5117e-01,\n",
       "            9.4873e-01, 9.4385e-01, 9.3115e-01, 9.3066e-01, 9.1553e-01,\n",
       "            9.0967e-01, 9.0723e-01, 9.0527e-01, 8.9307e-01, 8.8916e-01,\n",
       "            8.7207e-01, 8.5840e-01, 8.5791e-01, 8.5742e-01, 8.5596e-01,\n",
       "            8.4814e-01, 8.2764e-01, 8.0908e-01, 8.0615e-01, 8.0371e-01,\n",
       "            7.7881e-01, 7.7686e-01, 7.7246e-01, 7.6904e-01, 7.4316e-01,\n",
       "            7.2754e-01, 7.2510e-01, 7.1777e-01, 6.7529e-01, 6.6455e-01,\n",
       "            6.5918e-01, 6.5039e-01, 6.4258e-01, 6.2842e-01, 6.1963e-01,\n",
       "            5.8350e-01, 5.6201e-01, 5.5518e-01, 4.9390e-01, 4.4458e-01,\n",
       "            4.0747e-01, 3.7402e-01, 3.4229e-01, 3.0518e-01, 2.9517e-01,\n",
       "            2.7563e-01, 2.6807e-01, 2.2607e-01, 2.2595e-01, 2.2021e-01,\n",
       "            2.1973e-01, 1.5942e-01, 1.5381e-01, 1.4001e-01, 1.0303e-01,\n",
       "            7.8796e-02, 7.5745e-02, 6.9641e-02, 6.9275e-02, 6.8665e-02,\n",
       "            6.0852e-02, 5.3009e-02, 5.0720e-02, 4.9683e-02, 4.5959e-02,\n",
       "            4.3854e-02, 4.0100e-02, 3.0914e-02, 2.8931e-02, 1.8539e-02,\n",
       "            1.7105e-02, 1.5602e-02, 1.3481e-02, 1.3069e-02, 1.1070e-02,\n",
       "            1.0986e-02, 9.1934e-03, 8.3771e-03, 7.5760e-03, 7.0381e-03,\n",
       "            6.8245e-03, 6.4621e-03, 5.6877e-03, 4.5204e-03, 4.4518e-03,\n",
       "            3.4428e-03, 2.9583e-03, 2.7676e-03, 2.7046e-03, 2.4338e-03,\n",
       "            2.3880e-03, 1.9569e-03, 1.9493e-03, 1.6356e-03, 1.5612e-03,\n",
       "            1.5545e-03, 1.5488e-03, 1.5430e-03, 1.2941e-03, 1.2598e-03,\n",
       "            1.2550e-03, 1.0166e-03, 9.6989e-04, 8.8310e-04, 8.5258e-04,\n",
       "            7.6723e-04, 7.2956e-04, 6.9857e-04, 6.1178e-04, 5.9986e-04,\n",
       "            5.2547e-04, 5.0354e-04, 4.7112e-04, 4.6921e-04, 4.6563e-04,\n",
       "            4.5824e-04, 4.3893e-04, 4.3392e-04, 4.1246e-04, 3.9673e-04,\n",
       "            3.8147e-04, 3.7551e-04, 3.7408e-04, 3.4881e-04, 3.4332e-04,\n",
       "            3.3808e-04, 3.2759e-04, 3.1757e-04, 3.1257e-04, 3.0541e-04,\n",
       "            3.0303e-04, 2.9826e-04, 2.9588e-04, 2.8920e-04, 2.8253e-04,\n",
       "            2.7156e-04, 2.5725e-04, 2.1660e-04, 2.1482e-04, 1.9109e-04,\n",
       "            1.8966e-04, 1.8811e-04, 1.7953e-04, 1.7262e-04, 1.6475e-04,\n",
       "            1.5593e-04, 1.4770e-04, 1.3769e-04, 1.3661e-04, 1.2732e-04,\n",
       "            1.1867e-04, 8.8215e-05, 8.7500e-05, 7.2002e-05, 6.3002e-05,\n",
       "            5.9664e-05, 5.9187e-05, 4.9889e-05, 4.2677e-05, 3.9160e-05,\n",
       "            3.3200e-05, 3.0935e-05, 2.9087e-05, 2.8610e-05, 2.6047e-05,\n",
       "            2.4140e-05, 2.3723e-05, 2.0146e-05, 1.7107e-05, 1.6809e-05,\n",
       "            1.6212e-05, 1.3113e-05, 5.9009e-06, 3.9935e-06, 2.7418e-06,\n",
       "            2.6822e-06, 1.7285e-06, 1.6689e-06, 1.5497e-06, 1.1325e-06,\n",
       "            8.3447e-07, 7.7486e-07, 6.5565e-07, 5.9605e-07, 5.3644e-07,\n",
       "            4.7684e-07, 2.3842e-07, 1.7881e-07, 1.1921e-07, 5.9605e-08,\n",
       "            0.0000e+00], dtype=float16)}}]],\n",
       " 'roc_results': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.00333333, 0.00333333, 0.00333333, 0.00666667,\n",
       "         0.01      , 0.01333333, 0.01333333, 0.01333333, 0.01666667,\n",
       "         0.02      , 0.02666667, 0.03333334, 0.04      , 0.05      ,\n",
       "         0.06      , 0.06333333, 0.08      , 0.08666667, 0.09666666,\n",
       "         0.09666666, 0.1       , 0.11333334, 0.12333333, 0.13333334,\n",
       "         0.13666667, 0.15      , 0.17333333, 0.18333334, 0.20333333,\n",
       "         0.22666667, 0.23      , 0.24666667, 0.25666666, 0.27666667,\n",
       "         0.3       , 0.31666666, 0.32666665, 0.34      , 0.35666665,\n",
       "         0.36333334, 0.36666667, 0.37333333, 0.37666667, 0.38      ,\n",
       "         0.38      , 0.38333333, 0.38333333, 0.38666666, 0.39      ,\n",
       "         0.39666668, 0.39666668, 0.40333334, 0.40666667, 0.40666667,\n",
       "         0.40666667, 0.40666667, 0.40666667, 0.41333333, 0.41666666,\n",
       "         0.42      , 0.43      , 0.43333334, 0.43333334, 0.43333334,\n",
       "         0.43333334, 0.43333334, 0.43666667, 0.44      , 0.44333333,\n",
       "         0.44333333, 0.44666666, 0.45666668, 0.45666668, 0.46      ,\n",
       "         0.46333334, 0.46333334, 0.46333334, 0.46333334, 0.47      ,\n",
       "         0.47333333, 0.47333333, 0.47333333, 0.47666666, 0.48      ,\n",
       "         0.48333332, 0.48333332, 0.48666668, 0.48666668, 0.48666668,\n",
       "         0.48666668, 0.49      , 0.5       , 0.5       , 0.5       ,\n",
       "         0.50666666, 0.50666666, 0.50666666, 0.50666666, 0.50666666,\n",
       "         0.5133333 , 0.5133333 , 0.52      , 0.5233333 , 0.53      ,\n",
       "         0.53333336, 0.54      , 0.54333335, 0.55333334, 0.55333334,\n",
       "         0.5566667 , 0.56      , 0.57      , 0.58      , 0.59      ,\n",
       "         0.5933333 , 0.5933333 , 0.61      , 0.61333334, 0.61333334,\n",
       "         0.6166667 , 0.62666667, 0.62666667, 0.63666666, 0.64666665,\n",
       "         0.6533333 , 0.66      , 0.6666667 , 0.6766667 , 0.68333334,\n",
       "         0.68333334, 0.68666667, 0.6933333 , 0.69666666, 0.69666666,\n",
       "         0.7       , 0.7033333 , 0.71      , 0.71666664, 0.72333336,\n",
       "         0.7266667 , 0.73333335, 0.7366667 , 0.7366667 , 0.74333334,\n",
       "         0.74666667, 0.75      , 0.75666666, 0.76      , 0.7633333 ,\n",
       "         0.76666665, 0.76666665, 0.7733333 , 0.78      , 0.78333336,\n",
       "         0.79      , 0.79333335, 0.79333335, 0.8       , 0.8066667 ,\n",
       "         0.81333333, 0.81666666, 0.82666665, 0.83      , 0.84      ,\n",
       "         0.8466667 , 0.85      , 0.8566667 , 0.86333334, 0.8666667 ,\n",
       "         0.8666667 , 0.87      , 0.87333333, 0.88      , 0.88666666,\n",
       "         0.89      , 0.89      , 0.8933333 , 0.89666665, 0.9       ,\n",
       "         0.9033333 , 0.9066667 , 0.9066667 , 0.9066667 , 0.9066667 ,\n",
       "         0.9066667 , 0.9066667 , 0.91      , 0.91      , 0.91333336,\n",
       "         0.9166667 , 0.92      , 0.92333335, 0.9266667 , 0.93      ,\n",
       "         0.93      , 0.93333334, 0.93333334, 0.93666667, 0.94      ,\n",
       "         0.9433333 , 0.94666666, 0.94666666, 0.94666666, 0.95      ,\n",
       "         0.95      , 0.95      , 0.9533333 , 0.9533333 , 0.9533333 ,\n",
       "         0.95666665, 0.96      , 0.96      , 0.96      , 0.96666664,\n",
       "         0.96666664, 0.96666664, 0.97      , 0.97      , 0.97333336,\n",
       "         0.97333336, 0.97333336, 0.97333336, 0.97333336, 0.9766667 ,\n",
       "         0.98      , 0.98      , 0.98      , 0.98333335, 0.9866667 ,\n",
       "         0.9866667 , 0.9866667 , 0.99      , 0.99      , 0.99      ,\n",
       "         0.99      , 0.99      , 0.99      , 0.99      , 0.99      ,\n",
       "         0.99      , 0.99      , 0.99      , 0.99      , 0.99      ,\n",
       "         0.99      , 0.99      , 0.99      , 0.99      , 0.99      ,\n",
       "         0.99      , 0.99      , 0.99333334, 0.99333334, 0.99333334,\n",
       "         0.99666667, 0.99666667, 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "        dtype=float32),\n",
       "  'tpr': array([0.        , 0.00333333, 0.00666667, 0.01333333, 0.02      ,\n",
       "         0.02333333, 0.03666667, 0.04      , 0.04666667, 0.05      ,\n",
       "         0.05333333, 0.07      , 0.08666667, 0.09      , 0.1       ,\n",
       "         0.10333333, 0.11333334, 0.11666667, 0.12333333, 0.12666667,\n",
       "         0.14      , 0.14666666, 0.15333334, 0.16333333, 0.17      ,\n",
       "         0.17      , 0.17666666, 0.18      , 0.18      , 0.18      ,\n",
       "         0.18666667, 0.18666667, 0.19      , 0.19666667, 0.2       ,\n",
       "         0.20333333, 0.21333334, 0.21333334, 0.21666667, 0.21666667,\n",
       "         0.22666667, 0.23333333, 0.24      , 0.25      , 0.26      ,\n",
       "         0.27666667, 0.28333333, 0.28333333, 0.29      , 0.3       ,\n",
       "         0.3       , 0.30666667, 0.31      , 0.31      , 0.31      ,\n",
       "         0.31333333, 0.31333333, 0.32      , 0.32333332, 0.32333332,\n",
       "         0.32333332, 0.33333334, 0.33666667, 0.34666666, 0.35      ,\n",
       "         0.35333332, 0.35666665, 0.36      , 0.36333334, 0.37333333,\n",
       "         0.38      , 0.38      , 0.38333333, 0.39      , 0.39333335,\n",
       "         0.39666668, 0.4       , 0.40333334, 0.40333334, 0.40333334,\n",
       "         0.40666667, 0.40666667, 0.41      , 0.41666666, 0.42      ,\n",
       "         0.42      , 0.42666668, 0.43      , 0.43333334, 0.43666667,\n",
       "         0.43666667, 0.44      , 0.44666666, 0.45333335, 0.45333335,\n",
       "         0.46      , 0.46333334, 0.46666667, 0.47      , 0.47333333,\n",
       "         0.47666666, 0.48      , 0.48333332, 0.49      , 0.49333334,\n",
       "         0.49666667, 0.50333333, 0.50666666, 0.51      , 0.51666665,\n",
       "         0.51666665, 0.52      , 0.52      , 0.52      , 0.52      ,\n",
       "         0.52      , 0.5233333 , 0.53      , 0.5366667 , 0.54      ,\n",
       "         0.54333335, 0.5466667 , 0.5466667 , 0.5466667 , 0.5466667 ,\n",
       "         0.5466667 , 0.55      , 0.55      , 0.55      , 0.55333334,\n",
       "         0.56666666, 0.57      , 0.57666665, 0.57666665, 0.58      ,\n",
       "         0.58      , 0.5833333 , 0.59      , 0.59      , 0.5933333 ,\n",
       "         0.5966667 , 0.5966667 , 0.5966667 , 0.5966667 , 0.60333335,\n",
       "         0.60333335, 0.60333335, 0.61      , 0.61      , 0.61      ,\n",
       "         0.61      , 0.61      , 0.61333334, 0.62      , 0.62      ,\n",
       "         0.62      , 0.62      , 0.62      , 0.62      , 0.62      ,\n",
       "         0.62      , 0.62333333, 0.6333333 , 0.6333333 , 0.6333333 ,\n",
       "         0.6333333 , 0.6333333 , 0.63666666, 0.64      , 0.64      ,\n",
       "         0.64      , 0.6433333 , 0.65      , 0.65      , 0.6533333 ,\n",
       "         0.6566667 , 0.6566667 , 0.6566667 , 0.6566667 , 0.6566667 ,\n",
       "         0.66333336, 0.6666667 , 0.67      , 0.67      , 0.67      ,\n",
       "         0.67      , 0.67333335, 0.67333335, 0.68      , 0.68      ,\n",
       "         0.68      , 0.68      , 0.68333334, 0.68666667, 0.69      ,\n",
       "         0.6933333 , 0.69666666, 0.69666666, 0.7       , 0.7       ,\n",
       "         0.7       , 0.7       , 0.7       , 0.7       , 0.7       ,\n",
       "         0.71      , 0.7133333 , 0.72      , 0.72333336, 0.72333336,\n",
       "         0.7266667 , 0.7266667 , 0.73      , 0.73333335, 0.73333335,\n",
       "         0.7366667 , 0.74666667, 0.74666667, 0.75      , 0.75333333,\n",
       "         0.75333333, 0.75333333, 0.75666666, 0.76      , 0.76      ,\n",
       "         0.7633333 , 0.77      , 0.77      , 0.7733333 , 0.7733333 ,\n",
       "         0.77666664, 0.78      , 0.78333336, 0.7866667 , 0.7866667 ,\n",
       "         0.79      , 0.79333335, 0.7966667 , 0.7966667 , 0.7966667 ,\n",
       "         0.8       , 0.80333334, 0.80333334, 0.8066667 , 0.81      ,\n",
       "         0.81333333, 0.81666666, 0.82      , 0.8233333 , 0.82666665,\n",
       "         0.83      , 0.8333333 , 0.83666664, 0.8433333 , 0.8466667 ,\n",
       "         0.85      , 0.85333335, 0.8566667 , 0.86      , 0.86333334,\n",
       "         0.8666667 , 0.87      , 0.87      , 0.87333333, 0.87666667,\n",
       "         0.87666667, 0.8833333 , 0.8833333 , 0.88666666, 0.8933333 ,\n",
       "         0.89666665, 0.9       , 0.9033333 , 0.9066667 , 0.91      ,\n",
       "         0.91333336, 0.9166667 , 0.92      , 0.92333335, 0.9266667 ,\n",
       "         0.93      , 0.93333334, 0.93666667, 0.94      , 0.9433333 ,\n",
       "         0.94666666, 0.9533333 , 0.95666665, 0.96      , 0.9633333 ,\n",
       "         0.96666664, 0.97      , 0.97333336, 0.9766667 , 0.98333335,\n",
       "         0.9866667 , 0.99      , 0.99333334, 0.99666667, 1.        ],\n",
       "        dtype=float32),\n",
       "  'thresholds': array([1.    , 0.5254, 0.5244, 0.524 , 0.5234, 0.523 , 0.5225, 0.522 ,\n",
       "         0.5215, 0.521 , 0.5205, 0.52  , 0.5195, 0.519 , 0.5186, 0.518 ,\n",
       "         0.5176, 0.517 , 0.5166, 0.516 , 0.5156, 0.515 , 0.5146, 0.514 ,\n",
       "         0.5137, 0.513 , 0.5127, 0.512 , 0.5117, 0.511 , 0.5107, 0.5103,\n",
       "         0.51  , 0.5093, 0.509 , 0.5083, 0.508 , 0.5073, 0.507 , 0.5063,\n",
       "         0.506 , 0.5054, 0.505 , 0.5044, 0.5034, 0.503 , 0.5024, 0.502 ,\n",
       "         0.5015, 0.501 , 0.5005, 0.5   , 0.4998, 0.4995, 0.4993, 0.499 ,\n",
       "         0.4985, 0.4978, 0.4976, 0.4973, 0.497 , 0.4968, 0.4966, 0.4963,\n",
       "         0.496 , 0.4958, 0.4956, 0.4954, 0.495 , 0.4949, 0.4946, 0.4944,\n",
       "         0.4941, 0.494 , 0.4937, 0.4934, 0.4932, 0.493 , 0.4924, 0.4922,\n",
       "         0.4915, 0.4912, 0.4905, 0.4902, 0.49  , 0.4897, 0.4895, 0.4893,\n",
       "         0.4888, 0.4883, 0.4878, 0.4873, 0.487 , 0.4868, 0.4866, 0.4863,\n",
       "         0.486 , 0.4858, 0.4856, 0.4854, 0.4849, 0.4844, 0.4841, 0.4834,\n",
       "         0.4824, 0.4822, 0.482 , 0.4817, 0.4814, 0.4812, 0.4807, 0.4805,\n",
       "         0.48  , 0.4797, 0.4795, 0.4792, 0.479 , 0.4788, 0.4783, 0.478 ,\n",
       "         0.4778, 0.4775, 0.4773, 0.4768, 0.4766, 0.4758, 0.4756, 0.4753,\n",
       "         0.475 , 0.4749, 0.4746, 0.4744, 0.474 , 0.4739, 0.4736, 0.4734,\n",
       "         0.4731, 0.4727, 0.4724, 0.4722, 0.472 , 0.4717, 0.4714, 0.471 ,\n",
       "         0.4707, 0.4705, 0.4702, 0.47  , 0.4697, 0.4688, 0.4685, 0.4683,\n",
       "         0.468 , 0.4678, 0.467 , 0.4668, 0.4666, 0.466 , 0.4656, 0.4648,\n",
       "         0.4646, 0.4644, 0.464 , 0.4639, 0.4636, 0.4634, 0.463 , 0.4626,\n",
       "         0.4622, 0.462 , 0.4617, 0.4614, 0.4612, 0.461 , 0.4607, 0.4604,\n",
       "         0.46  , 0.4595, 0.4592, 0.4585, 0.458 , 0.4578, 0.4573, 0.4568,\n",
       "         0.4565, 0.4563, 0.456 , 0.4558, 0.4556, 0.4553, 0.455 , 0.4548,\n",
       "         0.4546, 0.4543, 0.454 , 0.4539, 0.4531, 0.453 , 0.4526, 0.4524,\n",
       "         0.4521, 0.452 , 0.4517, 0.4514, 0.4512, 0.451 , 0.4507, 0.4504,\n",
       "         0.4502, 0.45  , 0.449 , 0.4485, 0.4482, 0.448 , 0.4478, 0.4475,\n",
       "         0.4473, 0.447 , 0.446 , 0.4456, 0.4448, 0.4446, 0.4436, 0.4434,\n",
       "         0.443 , 0.4424, 0.4414, 0.441 , 0.4404, 0.44  , 0.4382, 0.438 ,\n",
       "         0.4375, 0.4368, 0.4355, 0.4343, 0.4338, 0.4333, 0.433 , 0.432 ,\n",
       "         0.4312, 0.4304, 0.43  , 0.4294, 0.428 , 0.4277, 0.4275, 0.4272,\n",
       "         0.4268, 0.4265, 0.4263, 0.426 , 0.4253, 0.424 , 0.4238, 0.4233,\n",
       "         0.423 , 0.422 , 0.4219, 0.4216, 0.4211, 0.4202, 0.4194, 0.4187,\n",
       "         0.4185, 0.4182, 0.4177, 0.417 , 0.4163, 0.4146, 0.4114, 0.4106,\n",
       "         0.4102, 0.4087, 0.4084, 0.4026, 0.4019, 0.4016, 0.4004, 0.4001,\n",
       "         0.4   , 0.3977, 0.3975, 0.3962, 0.3953, 0.3918, 0.3916, 0.3914,\n",
       "         0.391 , 0.3901, 0.3894, 0.3867, 0.3835, 0.3826, 0.379 , 0.3772,\n",
       "         0.3735, 0.3728, 0.3706, 0.3572], dtype=float16),\n",
       "  'name': 'Original NN data1',\n",
       "  'auc': array(0.44575554, dtype=float32),\n",
       "  'model': LitClassifier(\n",
       "    (model): SimpleClassifier(\n",
       "      (layer_stack): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): BCEWithLogitsLoss()\n",
       "    (train_accuracy): BinaryAccuracy()\n",
       "    (test_accuracy): BinaryAccuracy()\n",
       "    (test_auc): BinaryAUROC()\n",
       "  )},\n",
       " 'test_loader': <torch.utils.data.dataloader.DataLoader at 0x77870f714890>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle, load_from_pickle\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison\n",
    "from predict_ensemble_and_evaluate import make_curve_monotonic\n",
    "\n",
    "# Save the data\n",
    "save_to_pickle(list_folds_best_models, list_folds_weighted_clfs, results_original_roc, test_loader, filename='pickle/NN_data1_oversampling.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4af2aaa",
   "metadata": {},
   "source": [
    "# Load pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "001facb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle, load_from_pickle\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison\n",
    "from predict_ensemble_and_evaluate import make_curve_monotonic\n",
    "\n",
    "# Load the data\n",
    "list_folds_best_models, list_folds_weighted_clfs, results_original_roc, test_loader = load_from_pickle(filename='pickle/NN_data1_oversampling.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5d9c39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the best classifiers of all folds\n",
    "results_lists = []\n",
    "results_lists.extend(list_folds_best_models)\n",
    "results_lists.extend(list_folds_weighted_clfs)\n",
    "plot_roc_comparison(\n",
    "    results_lists=results_lists,\n",
    "    names=[\"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Weighted1\", \"Weighted2\", \"Weighted3\", \"Weighted4\"],\n",
    "    results_original_roc=results_original_roc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275941a6",
   "metadata": {},
   "source": [
    "### Ensemble prediction using voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "586c430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating Ensemble ROC Curve by iterating through FPR values ---\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0000\n",
      "Soft Voting -> Achieved [TPR: 0.8467, FPR: 0.0000]\n",
      "Hard Voting -> Resulted in [TPR: 0.7667, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0204\n",
      "Soft Voting -> Achieved [TPR: 0.9400, FPR: 0.0200]\n",
      "Hard Voting -> Resulted in [TPR: 0.9333, FPR: 0.0200]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0408\n",
      "Soft Voting -> Achieved [TPR: 0.9533, FPR: 0.0367]\n",
      "Hard Voting -> Resulted in [TPR: 0.9500, FPR: 0.0267]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0612\n",
      "Soft Voting -> Achieved [TPR: 0.9567, FPR: 0.0600]\n",
      "Hard Voting -> Resulted in [TPR: 0.9533, FPR: 0.0467]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0816\n",
      "Soft Voting -> Achieved [TPR: 0.9567, FPR: 0.0800]\n",
      "Hard Voting -> Resulted in [TPR: 0.9600, FPR: 0.0533]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1020\n",
      "Soft Voting -> Achieved [TPR: 0.9700, FPR: 0.0967]\n",
      "Hard Voting -> Resulted in [TPR: 0.9700, FPR: 0.0733]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1224\n",
      "Soft Voting -> Achieved [TPR: 0.9867, FPR: 0.1200]\n",
      "Hard Voting -> Resulted in [TPR: 0.9833, FPR: 0.1167]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1429\n",
      "Soft Voting -> Achieved [TPR: 0.9900, FPR: 0.1300]\n",
      "Hard Voting -> Resulted in [TPR: 0.9867, FPR: 0.1233]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1633\n",
      "Soft Voting -> Achieved [TPR: 0.9933, FPR: 0.1467]\n",
      "Hard Voting -> Resulted in [TPR: 0.9867, FPR: 0.1233]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1837\n",
      "Soft Voting -> Achieved [TPR: 0.9933, FPR: 0.1467]\n",
      "Hard Voting -> Resulted in [TPR: 0.9867, FPR: 0.1233]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2041\n",
      "Soft Voting -> Achieved [TPR: 0.9933, FPR: 0.1467]\n",
      "Hard Voting -> Resulted in [TPR: 0.9867, FPR: 0.1233]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2245\n",
      "Soft Voting -> Achieved [TPR: 0.9933, FPR: 0.1467]\n",
      "Hard Voting -> Resulted in [TPR: 0.9867, FPR: 0.1233]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2449\n",
      "Soft Voting -> Achieved [TPR: 0.9967, FPR: 0.2400]\n",
      "Hard Voting -> Resulted in [TPR: 0.9967, FPR: 0.2267]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2653\n",
      "Soft Voting -> Achieved [TPR: 0.9967, FPR: 0.2400]\n",
      "Hard Voting -> Resulted in [TPR: 0.9967, FPR: 0.2267]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2857\n",
      "Soft Voting -> Achieved [TPR: 0.9967, FPR: 0.2400]\n",
      "Hard Voting -> Resulted in [TPR: 0.9967, FPR: 0.2267]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3061\n",
      "Soft Voting -> Achieved [TPR: 0.9967, FPR: 0.2400]\n",
      "Hard Voting -> Resulted in [TPR: 0.9967, FPR: 0.2267]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3265\n",
      "Soft Voting -> Achieved [TPR: 0.9967, FPR: 0.2400]\n",
      "Hard Voting -> Resulted in [TPR: 0.9967, FPR: 0.2267]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3469\n",
      "Soft Voting -> Achieved [TPR: 0.9967, FPR: 0.2400]\n",
      "Hard Voting -> Resulted in [TPR: 0.9967, FPR: 0.2267]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3673\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.3500]\n",
      "Hard Voting -> Resulted in [TPR: 0.9967, FPR: 0.2267]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3878\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.3500]\n",
      "Hard Voting -> Resulted in [TPR: 0.9967, FPR: 0.2267]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4082\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.3500]\n",
      "Hard Voting -> Resulted in [TPR: 0.9967, FPR: 0.2267]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4286\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.3500]\n",
      "Hard Voting -> Resulted in [TPR: 0.9967, FPR: 0.2267]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4490\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.3500]\n",
      "Hard Voting -> Resulted in [TPR: 0.9967, FPR: 0.2267]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4694\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.3500]\n",
      "Hard Voting -> Resulted in [TPR: 0.9967, FPR: 0.2267]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4898\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.3500]\n",
      "Hard Voting -> Resulted in [TPR: 0.9967, FPR: 0.2267]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.5102\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.3500]\n",
      "Hard Voting -> Resulted in [TPR: 0.9967, FPR: 0.2267]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.5306\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.3500]\n",
      "Hard Voting -> Resulted in [TPR: 0.9967, FPR: 0.2267]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.5510\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.3500]\n",
      "Hard Voting -> Resulted in [TPR: 0.9967, FPR: 0.2267]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.5714\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.2233]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "\n",
      "--- Filtering curves to be monotonic ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Loop through all the FPR values to generate the ensemble ROC curve ---\n",
    "\n",
    "ensemble_results_soft = []\n",
    "ensemble_results_hard = []\n",
    "\n",
    "print(\"\\n--- Generating Ensemble ROC Curve by iterating through FPR values ---\")\n",
    "# We iterate from a low to high target_fpr to trace the curve\n",
    "for target_fpr in np.linspace(0.0, 1.0, 50): \n",
    "    # 1. Assign the function's output to a single variable first.\n",
    "    result_tuple = predict_ensemble_and_evaluate(\n",
    "        list_folds_best_models=list_folds_best_models,\n",
    "        test_loader=test_loader,\n",
    "        target_fpr=target_fpr\n",
    "    )\n",
    "    \n",
    "    if result_tuple is not None:\n",
    "        \n",
    "        for voting_method, metrics in result_tuple.items():\n",
    "            # Create a dictionary for each point and append it to the list\n",
    "            if voting_method == 'soft_voting':\n",
    "                point_dict = {'fpr': metrics['fpr'], 'tpr': metrics['tpr']}\n",
    "                ensemble_results_soft.append(point_dict)\n",
    "            else:\n",
    "                point_dict = {'fpr': metrics['fpr'], 'tpr': metrics['tpr']}\n",
    "                ensemble_results_hard.append(point_dict)\n",
    "            \n",
    "        \n",
    "# Ensure the curve starts at (0, 0)\n",
    "    if not ensemble_results_soft or ensemble_results_soft[0]['fpr'] > 0.0:\n",
    "        ensemble_results_soft.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if ensemble_results_soft[-1]['fpr'] < 1.0 or ensemble_results_soft[-1]['tpr'] < 1.0:\n",
    "        ensemble_results_soft.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    if not ensemble_results_hard or ensemble_results_hard[0]['fpr'] > 0.0:\n",
    "        ensemble_results_hard.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if ensemble_results_hard[-1]['fpr'] < 1.0 or ensemble_results_hard[-1]['tpr'] < 1.0:\n",
    "        ensemble_results_hard.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    # --- NEW: Post-process the lists to make them monotonic ---\n",
    "print(\"\\n--- Filtering curves to be monotonic ---\")\n",
    "ensemble_results_soft = make_curve_monotonic(ensemble_results_soft)\n",
    "ensemble_results_hard = make_curve_monotonic(ensemble_results_hard)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bae1a225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Plotting all ROC curves for comparison ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the best classifiers of all folds\n",
    "results_lists = []\n",
    "results_lists.extend(list_folds_best_models)\n",
    "results_lists.extend(list_folds_weighted_clfs)\n",
    "results_lists.append(ensemble_results_soft)\n",
    "results_lists.append(ensemble_results_hard)\n",
    "\n",
    "\n",
    "# --- Plot the final comparison ---\n",
    "print(\"\\n--- Plotting all ROC curves for comparison ---\")\n",
    "plot_roc_comparison(\n",
    "    results_lists=results_lists,\n",
    "    names=[\"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Weighted1\", \"Weighted2\", \"Weighted3\", \"Weighted4\", \"Ensemble_voting_soft\", \"Ensemble_voting_hard\"],\n",
    "    results_original_roc=results_original_roc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f504bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_performance_tester(classifier_list, test_loader):\n",
    "\n",
    "    list_weighted_clfs = []  # Reset the list for final testing\n",
    "    for i, model_info in enumerate(classifier_list):\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator='gpu',\n",
    "            devices=1,\n",
    "            #strategy='ddp_notebook',\n",
    "            max_epochs=NUM_EPOCHS, # Number of epochs for THIS stage\n",
    "            callbacks=[checkpoint_callback, progress_bar],\n",
    "            logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=f\"stage_{i+1}\"),\n",
    "            precision='16-mixed'\n",
    "            )\n",
    "\n",
    "        model = model_info[\"model\"]\n",
    "        raw_threshold = model_info[\"threshold\"]\n",
    "\n",
    "\n",
    "        # CORRECTED: Use isinstance() to check if model is a string\n",
    "        if isinstance(model, str):\n",
    "            print(f\"Skipping model {i+1} as it is a string placeholder: '{model}'\")\n",
    "            continue\n",
    "\n",
    "        # Check if the stored threshold is a NumPy number or a PyTorch Tensor\n",
    "        if isinstance(raw_threshold, (np.number, torch.Tensor)):\n",
    "            # If it is, we can safely call .item() to extract the Python float\n",
    "            threshold = raw_threshold.item()\n",
    "        else:\n",
    "            # Otherwise, it's already a float or something that can be cast to one\n",
    "            threshold = float(raw_threshold)\n",
    "        model.current_test_threshold = threshold  # Set the threshold for this model\n",
    "\n",
    "        # This code will now only run if 'model' is a PyTorch Lightning module\n",
    "        # and not a string.\n",
    "        print(f\"--- Testing model {i+1} ---\")\n",
    "\n",
    "        trainer.test(model, dataloaders=test_loader, ckpt_path=None)\n",
    "        \n",
    "        results_classifier = model.last_test_results.copy()\n",
    "        current_model = {\n",
    "            \"model\": model,\n",
    "            \"fpr\": results_classifier[\"fpr\"],\n",
    "            \"tpr\": results_classifier[\"tpr\"],\n",
    "            \"threshold\": results_classifier[\"threshold\"],\n",
    "            \"full_roc\": results_classifier[\"full_roc\"]\n",
    "        }\n",
    "        list_weighted_clfs.append(current_model)\n",
    "\n",
    "    # Ensure the curve starts at (0, 0)\n",
    "    if not list_weighted_clfs or list_weighted_clfs[0]['fpr'] > 0.0:\n",
    "        list_weighted_clfs.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if list_weighted_clfs[-1]['fpr'] < 1.0 or list_weighted_clfs[-1]['tpr'] < 1.0:\n",
    "        list_weighted_clfs.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    return list_weighted_clfs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLlabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
