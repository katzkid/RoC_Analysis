{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33420fde",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d11cd5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d840881",
   "metadata": {},
   "source": [
    "## Display function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c24af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for displaying ROC curves of multiple classifiers\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def plot_roc_connected_points(results_list, results_original_roc, name=\"All Classifiers\"):\n",
    "    \"\"\"\n",
    "    Creates a plot showing the performance of all classifiers as points,\n",
    "    and connects them with a line, sorted by FPR.\n",
    "\n",
    "    Args:\n",
    "        results_list: A list of dictionaries, where each dict contains 'fpr', 'tpr'.\n",
    "    \"\"\"\n",
    "    if not results_list:\n",
    "        print(\"No results to plot.\")\n",
    "        return\n",
    "\n",
    "    # Convert results to a pandas DataFrame for easy sorting\n",
    "    df = pd.DataFrame(results_list)\n",
    "    \n",
    "    # Sort the models by their False Positive Rate to create a left-to-right line\n",
    "    df_sorted = df.sort_values(by='fpr').reset_index(drop=True)\n",
    "    \n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    # Plot all the individual model points as a scatter plot\n",
    "    # This helps see the actual performance of each model\n",
    "    plt.scatter(df_sorted['fpr'], df_sorted['tpr'], c='black', marker='o', \n",
    "                alpha=0.6, s=100, zorder=3) # zorder=3 puts dots on top\n",
    "\n",
    "    # Plot the line connecting the points\n",
    "    plt.plot(df_sorted['fpr'], df_sorted['tpr'], color='red', lw=1.5,\n",
    "             alpha=0.8, label=f'{name} (AUC = {auc(df_sorted[\"fpr\"], df_sorted[\"tpr\"]):.2f})')\n",
    "    \n",
    "    #plot the original ROC curve\n",
    "    plt.plot(results_original_roc[\"fpr\"], results_original_roc[\"tpr\"], color='blue', \n",
    "             label=f'{results_original_roc[\"name\"]} (AUC = {results_original_roc[\"auc\"]:.2f})')\n",
    "\n",
    "    # Plot the \"no-skill\" line for reference\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.title('Performance Path of All Trained Classifiers')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23b1ea",
   "metadata": {},
   "source": [
    "## Best ROC envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e350c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def get_best_roc_envelope(results_list, results_original_roc=None):\n",
    "    \"\"\"\n",
    "    Constructs the upper envelope of multiple ROC curves to find the best\n",
    "    possible operating points from a collection of classifiers.\n",
    "\n",
    "    This function is guaranteed to produce a list of points that starts at\n",
    "    (FPR=0, TPR=0) and ends at (FPR=1, TPR=1), making it suitable for direct\n",
    "    plotting and AUC calculation.\n",
    "\n",
    "    Args:\n",
    "        results_list (list): A list of dictionaries. Each dictionary must\n",
    "                             contain a 'model' name and the full ROC results\n",
    "                             under the 'full_roc' key.\n",
    "        results_original_roc (dict, optional): A dictionary containing the\n",
    "                                               ROC results of a baseline model,\n",
    "                                               which will also be included in\n",
    "                                               the comparison. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        list: A sorted list of dictionaries representing the optimal ROC\n",
    "              envelope. Each dictionary includes 'model', 'fpr', 'tpr',\n",
    "              and 'threshold'.\n",
    "    \"\"\"\n",
    "    all_points = []\n",
    "\n",
    "    # Step 1: Gather all ROC points from all provided models\n",
    "    all_results = results_list[:]\n",
    "    if results_original_roc:\n",
    "        all_results.append({\n",
    "            'model': 'original_baseline',\n",
    "            'full_roc': results_original_roc\n",
    "        })\n",
    "\n",
    "    for result in all_results:\n",
    "        model_name = result.get('model', 'Unknown Model')\n",
    "        roc = result.get('full_roc')\n",
    "        if not roc: continue\n",
    "\n",
    "        fprs = roc.get('fpr', [])\n",
    "        tprs = roc.get('tpr', [])\n",
    "        thresholds = roc.get('thresholds', [])\n",
    "\n",
    "        for i in range(len(fprs)):\n",
    "            threshold = thresholds[i] if i < len(thresholds) else thresholds[-1]\n",
    "            all_points.append({\n",
    "                'model': model_name, 'fpr': fprs[i],\n",
    "                'tpr': tprs[i], 'threshold': threshold\n",
    "            })\n",
    "\n",
    "    # Handle case with no data by returning a default diagonal line\n",
    "    if not all_points:\n",
    "        return [\n",
    "            {'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf},\n",
    "            {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}\n",
    "        ]\n",
    "\n",
    "    # Step 2: Sort all points by FPR (asc), then by TPR (desc)\n",
    "    all_points.sort(key=lambda p: (p['fpr'], -p['tpr']))\n",
    "\n",
    "    # Step 3: Build the core ROC envelope\n",
    "    best_roc_envelope = []\n",
    "    max_tpr_so_far = -1.0\n",
    "    for point in all_points:\n",
    "        # Add a point only if it has a strictly higher TPR\n",
    "        if point['tpr'] > max_tpr_so_far:\n",
    "            # To prevent adding multiple points at the same FPR, check if the last point\n",
    "            # has the same FPR and replace it if so (since this one has a higher TPR)\n",
    "            if best_roc_envelope and best_roc_envelope[-1]['fpr'] == point['fpr']:\n",
    "                best_roc_envelope[-1] = point\n",
    "            else:\n",
    "                best_roc_envelope.append(point)\n",
    "            max_tpr_so_far = point['tpr']\n",
    "    \n",
    "    # Step 4: Manually add extremities if they are missing\n",
    "    \n",
    "    # Ensure the curve starts at (0, 0)\n",
    "    if not best_roc_envelope or best_roc_envelope[0]['fpr'] > 0.0:\n",
    "        best_roc_envelope.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if best_roc_envelope[-1]['fpr'] < 1.0 or best_roc_envelope[-1]['tpr'] < 1.0:\n",
    "        best_roc_envelope.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    return best_roc_envelope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b781e9",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c3deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def generate_data(dataset):\n",
    "    if dataset == \"data1\":\n",
    "        no_predictors = 2\n",
    "        no_samples = 1600\n",
    "        no_classes = 2\n",
    "        #kerneltype = 'linear'  #comment out for polynomial kernel\n",
    "        #kerneltype = 'poly'  #comment out for linear kernel\n",
    "\n",
    "\n",
    "\n",
    "        n_samples_per_cluster = 400\n",
    "        n_clusters = 4\n",
    "\n",
    "        # Create the clusters deterministically\n",
    "        np.random.seed(0) # for reproducibility\n",
    "\n",
    "        X = np.zeros((n_samples_per_cluster * n_clusters, 2))\n",
    "        y = np.zeros(n_samples_per_cluster * n_clusters)\n",
    "\n",
    "        # Cluster centers in corners of a square\n",
    "        centers = [[0, 0], [2, 0], [0, 2], [2, 2]]\n",
    "\n",
    "        # Assign points to clusters deterministically\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = slice(i * n_samples_per_cluster, (i + 1) * n_samples_per_cluster)\n",
    "            X[cluster_indices] = centers[i] + np.random.normal(scale=0.5, size=(n_samples_per_cluster, 2))\n",
    "            if i == 0 or i == 3:\n",
    "                y[cluster_indices] = 0\n",
    "            else:\n",
    "                y[cluster_indices] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #Visualize\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap='viridis', s=50)\n",
    "        plt.title('Four Clusters of Equal Size')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "\n",
    "        #add intercept to X\n",
    "        #X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # # shuffle data\n",
    "        # permutation = np.random.permutation(no_samples)\n",
    "        # X = X[permutation]\n",
    "        # y = y[permutation]\n",
    "\n",
    "\n",
    "        #Split data into training and testing sets\n",
    "        # Step 1: Split off the 1000 training samples. The rest (600) go into a temporary pool.\n",
    "        # We can use absolute numbers for the size.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=1000,  # Specify exactly 1000 samples for training\n",
    "            random_state=42,\n",
    "            stratify=y        # Crucial for classification: keeps class proportions the same\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "        train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        val_data = test_data\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "    elif dataset == \"data2\":\n",
    "        no_predictors = 2\n",
    "        no_samples = 1600\n",
    "        no_classes = 2\n",
    "        #kerneltype = 'linear'  #comment out for polynomial kernel\n",
    "        #kerneltype = 'poly'  #comment out for linear kernel\n",
    "\n",
    "\n",
    "\n",
    "        n_samples_per_cluster = 400\n",
    "        n_clusters = 4\n",
    "\n",
    "        # Create the clusters deterministically\n",
    "        np.random.seed(0) # for reproducibility\n",
    "\n",
    "        X = np.zeros((n_samples_per_cluster * n_clusters, 2))\n",
    "        y = np.zeros(n_samples_per_cluster * n_clusters)\n",
    "\n",
    "        # Cluster centers in corners of a square\n",
    "        centers = [[0, 0], [2, 0], [1, 2], [1, 2]]\n",
    "\n",
    "        # Assign points to clusters deterministically\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = slice(i * n_samples_per_cluster, (i + 1) * n_samples_per_cluster)\n",
    "            X[cluster_indices] = centers[i] + np.random.normal(scale=0.5, size=(n_samples_per_cluster, 2))\n",
    "            if i == 0 or i == 3:\n",
    "                y[cluster_indices] = 0\n",
    "            else:\n",
    "                y[cluster_indices] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #Visualize\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap='viridis', s=50)\n",
    "        plt.title('Four Clusters of Equal Size')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "\n",
    "        #add intercept to X\n",
    "        #X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # # shuffle data\n",
    "        # permutation = np.random.permutation(no_samples)\n",
    "        # X = X[permutation]\n",
    "        # y = y[permutation]\n",
    "\n",
    "\n",
    "        #Split data into training and testing sets\n",
    "        # Step 1: Split off the 1000 training samples. The rest (600) go into a temporary pool.\n",
    "        # We can use absolute numbers for the size.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=1000,  # Specify exactly 1000 samples for training\n",
    "            random_state=42,\n",
    "            stratify=y        # Crucial for classification: keeps class proportions the same\n",
    "        )\n",
    "\n",
    "\n",
    "        train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        val_data = test_data\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "    elif dataset == \"pneumoniaMNIST\":\n",
    "        import medmnist\n",
    "        print(medmnist.__version__)\n",
    "        # read in the PneumoniaMNIST dataset\n",
    "        from medmnist import PneumoniaMNIST\n",
    "        train_data = PneumoniaMNIST(split='train', download=True, size=224)\n",
    "        test_data = PneumoniaMNIST(split='test', download=True, size=224)\n",
    "        val_data = PneumoniaMNIST(split='val', download=True, size=224)\n",
    "        # print the dataset info\n",
    "        print(f\"Number of training samples: {len(train_data)}\")\n",
    "        print(f\"Number of test samples: {len(test_data)}\")\n",
    "        print(f\"Number of validation samples: {len(val_data)}\")\n",
    "\n",
    "    return train_data, test_data, val_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c59034e",
   "metadata": {},
   "source": [
    "## Data1: NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74133e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a060ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "IMAGE_SIZE = 224\n",
    "NUM_CLASSES = 1\n",
    "NUM_CHANNELS = 1\n",
    "NUM_EPOCHS = 1\n",
    "NUM_WORKERS = 4\n",
    "K_FOLDS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a702675",
   "metadata": {},
   "source": [
    "### Lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3760e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "\n",
    "# A simple classifier head\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_features=2, hidden_units=32, num_classes=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_features (int): Number of input features (2 for your data)\n",
    "            hidden_units (int): Number of neurons in the hidden layer\n",
    "            num_classes (int): Number of output classes (1 for binary)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            # --- Hidden Layer 1 ---\n",
    "            # Takes 2 features in, outputs a hidden representation of size 32\n",
    "            nn.Linear(in_features=input_features, out_features=hidden_units),\n",
    "            nn.ReLU(),  # <-- The crucial non-linear activation function\n",
    "\n",
    "            # --- Output Layer ---\n",
    "            # Takes the 16-unit hidden representation, outputs 1 logit\n",
    "            nn.Linear(in_features=hidden_units, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)\n",
    "\n",
    "# A new LightningModule just for training the classifier\n",
    "class LitClassifier(pl.LightningModule):\n",
    "    def __init__(self, input_features=512, hidden_units=32, num_classes=1, learning_rate=1e-4, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = SimpleClassifier(\n",
    "            input_features=self.hparams.input_features,\n",
    "            hidden_units=self.hparams.hidden_units,\n",
    "            num_classes=self.hparams.num_classes\n",
    "        )\n",
    "\n",
    "        self.current_test_threshold = 0.5  # Default threshold for binary classification\n",
    "        self.strict_loading = False \n",
    "\n",
    "        # This ensures the model's structure is correct upon initialization\n",
    "        if self.hparams.pos_weight is not None:\n",
    "            self.criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(self.hparams.pos_weight))\n",
    "        else:\n",
    "            self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        \n",
    "        \n",
    "        # --- METRICS ---\n",
    "        self.train_accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.test_accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.test_auc = torchmetrics.AUROC(task=\"binary\")\n",
    "        \n",
    "        # This list will store outputs from each test step\n",
    "        self.test_step_outputs = []\n",
    "        # This dictionary will hold the final results\n",
    "        self.last_test_results = {}\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        features, labels = batch\n",
    "        outputs = self(features)\n",
    "        \n",
    "        # For the loss function, labels need to be reshaped to match outputs\n",
    "        loss = self.criterion(outputs, labels.float().view(-1, 1))\n",
    "        \n",
    "        # For metrics, squeeze predictions to match labels' shape\n",
    "        self.train_accuracy(outputs.squeeze(), labels.int())\n",
    "        \n",
    "        self.log('classifier_train_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('classifier_train_acc', self.train_accuracy, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        features, labels = batch\n",
    "        outputs = self.model(features)\n",
    "        loss = self.criterion(outputs, labels.float().view(-1, 1))\n",
    "\n",
    "        # Append predictions and labels to our list for aggregation\n",
    "        self.test_step_outputs.append({\"preds\": outputs.detach(), \"labels\": labels.detach()})\n",
    "        \n",
    "        self.log('test_loss', loss)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        if not self.test_step_outputs:\n",
    "            return # Avoid errors if test loop was empty\n",
    "\n",
    "        # Concatenate all predictions and labels\n",
    "        all_preds = torch.cat([x['preds'] for x in self.test_step_outputs])\n",
    "        all_labels = torch.cat([x['labels'] for x in self.test_step_outputs])\n",
    "\n",
    "        # --- FIX: Squeeze BOTH predictions and labels to ensure they match ---\n",
    "        squeezed_preds = all_preds.squeeze()\n",
    "        all_probs = torch.sigmoid(squeezed_preds)\n",
    "        # The labels tensor might also be [N, 1], so we squeeze it as well.\n",
    "        int_labels = all_labels.squeeze().int()\n",
    "\n",
    "        # Calculate final scalar metrics\n",
    "        test_acc = self.test_accuracy(squeezed_preds, int_labels)\n",
    "        test_auc_val = self.test_auc(squeezed_preds, int_labels)\n",
    "\n",
    "\n",
    "        # Get the confusion matrix stats at the default 0.0 logit threshold\n",
    "        tp, fp, tn, fn, _ = torchmetrics.functional.stat_scores(\n",
    "            all_probs, int_labels, task=\"binary\", threshold=self.current_test_threshold\n",
    "        ) \n",
    "        \n",
    "        # Calculate TPR and FPR from these raw scores\n",
    "        epsilon = 1e-6\n",
    "        tpr_at_0 = tp / (tp + fn + epsilon)\n",
    "        fpr_at_0 = fp / (fp + tn + epsilon)\n",
    "\n",
    "        # Calculate data for the full ROC Curve\n",
    "        fpr_full, tpr_full, thresholds_full = torchmetrics.functional.roc(\n",
    "            torch.sigmoid(squeezed_preds),\n",
    "            int_labels,\n",
    "            task=\"binary\"\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"\\n--- Final Classifier Test Metrics ---\")\n",
    "        print(f\"Accuracy: {test_acc:.4f}\")\n",
    "        print(f\"AUC: {test_auc_val:.4f}\")\n",
    "        print(\"-------------------------------------\\n\")\n",
    "        \n",
    "        self.last_test_results = {\n",
    "            \"w\": self.hparams.get('w'),\n",
    "            \"fpr\": fpr_at_0.cpu().numpy(),\n",
    "            \"tpr\": tpr_at_0.cpu().numpy(),\n",
    "            \"threshold\": self.current_test_threshold,\n",
    "            \"auc\": test_auc_val.cpu().numpy(),\n",
    "            \"accuracy\": test_acc.cpu().numpy(),\n",
    "            \"full_roc\": {\n",
    "                \"fpr\": fpr_full.cpu().numpy(),\n",
    "                \"tpr\": tpr_full.cpu().numpy(),\n",
    "                \"thresholds\": thresholds_full.cpu().numpy()\n",
    "            }\n",
    "        }\n",
    "        self.test_step_outputs.clear()\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ea652",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4f28dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1000, 2), (1000,)\n",
      "Test data shape: (600, 2), (600,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "train_data, test_data, val_data = generate_data(\"data1\")\n",
    "\n",
    "\n",
    "train_data_tensor = data.TensorDataset(torch.tensor(train_data[:, :-1], dtype=torch.float32),\n",
    "                                        torch.tensor(train_data[:, -1], dtype=torch.float32))\n",
    "train_loader = data.DataLoader(train_data_tensor, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS) #over-write later for k-fold cross-validation\n",
    "test_data_tensor = data.TensorDataset(torch.tensor(test_data[:, :-1], dtype=torch.float32),\n",
    "                                       torch.tensor(test_data[:, -1], dtype=torch.float32))\n",
    "test_loader = data.DataLoader(test_data_tensor, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "# initialize fold\n",
    "kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8065beae",
   "metadata": {},
   "source": [
    "### Regular training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "261a6f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Training for 1 epochs on train_loader ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (16) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52eaa744021e4229bddee7c084953230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v17.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v17.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model from Phase 1 saved to: /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v17.ckpt\n",
      "\n",
      "--- Testing model from Phase 1 checkpoint: /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v17.ckpt ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc66ae79b634a86a378815bd9d07b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4683\n",
      "AUC: 0.4458\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7087163925170898\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Manually Calculating Metrics on Test Set ---\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[190 110]\n",
      " [210  90]]\n",
      "\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.47      0.63      0.54       300\n",
      "     Class 1       0.45      0.30      0.36       300\n",
      "\n",
      "    accuracy                           0.47       600\n",
      "   macro avg       0.46      0.47      0.45       600\n",
      "weighted avg       0.46      0.47      0.45       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# --- Place any constants or unchanging objects outside the loop ---\n",
    "pl.seed_everything(42, workers=True)\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. Instantiate the LightningModule\n",
    "model = LitClassifier(input_features=2, hidden_units=32, learning_rate=LEARNING_RATE)\n",
    "\n",
    "checkpoint_callback_full_model = ModelCheckpoint(\n",
    "    monitor='classifier_train_acc',  # Monitor training accuracy\n",
    "    every_n_epochs=1,                # Save model every epoch\n",
    "    dirpath='checkpoints/',\n",
    "    filename='simple-clf-{epoch:02d}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "train_trainer_1 = pl.Trainer(\n",
    "    accelerator='gpu',                 # Use GPUs\n",
    "    devices=1,                         # Number of GPUs to use\n",
    "    #strategy='ddp_notebook',                    # DistributedDataParallel strategy (best for multi-GPU)\n",
    "    max_epochs=NUM_EPOCHS,              # Total number of epochs\n",
    "    callbacks=[checkpoint_callback_full_model, progress_bar],\n",
    "    logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=\"simple-clf-train\"),\n",
    ")\n",
    "\n",
    "test_trainer_1 = pl.Trainer(\n",
    "    accelerator='gpu',\n",
    "    devices=1,  # Use only one GPU\n",
    "    logger = pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=\"simple-clf-test\"),\n",
    "    # Add the callback here so the Trainer can find the 'best' path\n",
    "    callbacks=[checkpoint_callback_full_model],\n",
    "    precision='16-mixed'  # Use mixed precision for testing\n",
    ")\n",
    "\n",
    "# --- Phase 1 Training ---\n",
    "print(f\"--- Starting Training for {NUM_EPOCHS} epochs on train_loader ---\")\n",
    "train_trainer_1.fit(model, train_dataloaders=train_loader)\n",
    "\n",
    "# CRITICAL: Save the path to the best model from this phase\n",
    "path_after_phase1 = checkpoint_callback_full_model.best_model_path\n",
    "print(f\"Best model from Phase 1 saved to: {path_after_phase1}\")\n",
    "\n",
    "# --- Test 1: Evaluate the model from after Phase 1 ---\n",
    "print(f\"\\n--- Testing model from Phase 1 checkpoint: {path_after_phase1} ---\")\n",
    "model.current_test_title = \"ROC Curve after training on DataLoader 1\"\n",
    "model = LitClassifier.load_from_checkpoint(path_after_phase1)  # Load the model from Phase 1\n",
    "model.eval().to('cuda:0')  # Ensure the model is in evaluation mode and on GPU\n",
    "test_trainer_1.test(model, dataloaders=test_loader, ckpt_path=path_after_phase1)\n",
    "results_phase1 = model.last_test_results.copy()\n",
    "results_original_roc = {\"fpr\": results_phase1[\"full_roc\"][\"fpr\"], \"tpr\": results_phase1[\"full_roc\"][\"tpr\"], \"thresholds\": results_phase1[\"full_roc\"][\"thresholds\"], \"name\": \"Original NN data1\", \"auc\": results_phase1[\"auc\"], \"model\": model}\n",
    "\n",
    "# Metrics\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "model.eval() # Set to evaluation mode\n",
    "\n",
    "final_predictions = [] # This will store binary predictions (0s or 1s)\n",
    "true_labels = []\n",
    "\n",
    "print(\"\\n--- Manually Calculating Metrics on Test Set ---\")\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        # Move input data to the same device as the model\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # 1. Get the raw model output (logits) and convert to probabilities\n",
    "        outputs = torch.sigmoid(model(inputs))\n",
    "\n",
    "        # 2. Convert probabilities to binary class predictions (0 or 1) using a 0.5 threshold\n",
    "        preds = (outputs > 0.5).int()\n",
    "\n",
    "        final_predictions.extend(preds.cpu().numpy().flatten())\n",
    "        true_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "# Ensure they are numpy arrays for sklearn\n",
    "true_labels = np.array(true_labels)\n",
    "final_predictions = np.array(final_predictions)\n",
    "\n",
    "# Now, calculate metrics using the correct binary predictions\n",
    "print(\"\\n--- Confusion Matrix ---\")\n",
    "cm = confusion_matrix(true_labels, final_predictions)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "report = classification_report(true_labels, final_predictions, target_names=['Class 0', 'Class 1'], zero_division=0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6c2d0a",
   "metadata": {},
   "source": [
    "### Weighted ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "226e70dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSIFIERS = 50\n",
    "w = np.linspace(0.001, 0.999, NUM_CLASSIFIERS, endpoint=True)\n",
    "pos_weights = w/(1-w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19d1bd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 1/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1980f91104344a0ead101bee00107e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['criterion.pos_weight']\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v18.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v18.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v18.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v18.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55d901a09ae4897bfe1c92635622c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3624\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7597287893295288\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ae1a63a8364b02b2d7e404e488c44f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9cfbe4abe94e20bdab60a38e446b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3965\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7998822927474976\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf969fe22ca64db6ac97587d101751e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3df1108cf74e0fbfb679184fec00d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4234\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8500174880027771\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5322a310f0b8492fb4efd71fb377d985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e0dd2d49bf4b30a7e2bcba0a1ed786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4395\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9073290824890137\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e51914f67fc14b2eb367404bd50f45f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec221b364b9f4e408a2cee942b6c3ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4515\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9717537760734558\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e587f5e4bd949cdb1fae098b7b82b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f9e94eab164dc59f849a2795a24bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4558\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0089677572250366\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e6f2d52acf46368254ea5275787758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c374df5c4b74eda84341144c644a520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4587\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0133905410766602\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa71df406ff42ba944a0add71be316f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a3130bd68342fa899c65fbe89eccd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4617\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9730748534202576\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e992a392ae9c455c9c85e92c3b922ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ef84701a13479fb88c44fa98553903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4665\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9234933257102966\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d6d10708ea436c9d92a5892f6aed48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba13c83ff49495c85a8f75a415ebac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4744\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8758061528205872\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad4a678f107419181ab5bee7635b351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a48d81baacb4e0fa53afb0cbd2d5a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4911\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8384931087493896\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb5a0bf138904c5495b2063e158b0ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8176dcc6d8664f1393a05d0b08500fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.5287\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7932234406471252\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79dbdb21608b4463b4c2124269107494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3352a4b7364d42a987b17388497ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.6283\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.756634533405304\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794600a60fb0448bae0e135f2c49b1d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457ef0a3eb464bbbbc6a743d538b37df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.7542\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7261484265327454\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80225e98670c42d2ad2457b26e961c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbdf3c94b67b451ca094eddc1ebd9b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.8295\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7093010544776917\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2c135a1a784763a7e18ba4ab2ae5cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "266c460e6e604808b4cb2b97585a2050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.9098\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6740606427192688\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c274da4c83b349a7a2f9a93b7f2a341d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1ee6269814477a859f1593d62ac337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.9380\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6547136306762695\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07bd0a6cc5f640c798c652ff6bd9afaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a25270d1fa4febb2d88333654b8a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5200\n",
      "AUC: 0.9559\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6362302303314209\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09640c7f70e742b5a9445afe35b18760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c00528c8aae4d20aaee60b8a7f03fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5760\n",
      "AUC: 0.9587\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6163405179977417\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b7dc777f5954e54aa10578382067af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79368b3e167241a194828624be3db43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6520\n",
      "AUC: 0.9689\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5975120067596436\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d39eac7fb049118f683bdb21a4b257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa7b95a8afd4a6fbd1ba1a3b582511e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6880\n",
      "AUC: 0.9659\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5829055309295654\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27323cf56e5a406c908ede6d0fd6c822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2eaf03b5bc4343816dea225e474429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7120\n",
      "AUC: 0.9694\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5692366361618042\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a90adcb76c47948747d700dcc53b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01bf93088cb546e0bc2d0dd2420936de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7840\n",
      "AUC: 0.9720\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5562064051628113\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f08f66c84f89491db32f65cb8e1f1c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e4bd0a57d7445e9e9b25bba057ddb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8480\n",
      "AUC: 0.9730\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5440255403518677\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84800251e4045e68f53a46ec8c8292e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03e94b7c4874f98888249f78afc8860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9000\n",
      "AUC: 0.9744\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5331938862800598\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a67830f54a34c14a84615da201a5f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28e86587d554531aba7af38cce5e3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9160\n",
      "AUC: 0.9751\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5237040519714355\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0878644956449eb3701850b876b172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63d4d297bdb493bb092336159385885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9120\n",
      "AUC: 0.9769\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5147244334220886\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccda3cddc9fb427fb8ff7bcd53d6a4d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9cabefcb0aa44348d1ce840d485c403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9280\n",
      "AUC: 0.9788\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5051102638244629\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dceebd9efb34fd29b76cdad64b35c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181cb0126554406cac116d6796da3037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9000\n",
      "AUC: 0.9803\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.49645107984542847\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2bbbbbc900479f8273d67f509403df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1282e6188d99482188d1dad98adecbb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8800\n",
      "AUC: 0.9820\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4885621964931488\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b289523e9b5489cad4e86a61ac42e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bdb5e76a51d45b6b2ddaa9caecb0939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8760\n",
      "AUC: 0.9835\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4760471284389496\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea44d334247c493c96519eecdc82bffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1dfd918db143cabe1232a9367e3040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8360\n",
      "AUC: 0.9828\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.47460752725601196\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a187e4f2880449b48cad9f00c9fe5399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6592c24f19aa41b7a36980958758764a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8080\n",
      "AUC: 0.9840\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4679884612560272\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7af939a533245238df6054b7f443682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a09b3e86d524e4eb0992434bdde340a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7880\n",
      "AUC: 0.9837\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46489909291267395\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6fc52158bb54f61aba3d1bc06b58e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22a3dcb9835405585e0cb1e3257f29d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7560\n",
      "AUC: 0.9841\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46303990483283997\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19427cd5d1834066afb82bc942297d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4595fdab17c4a629b7d92ddd5bcfc8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7560\n",
      "AUC: 0.9846\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.45988935232162476\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a3bd87934d4d97b163cceb0ec11ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3e40f24fd94cb28bcf6f7a3215f35e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.9839\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4615151286125183\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e703d6763252471da3540cf4e7be0ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8139b70e014d85867ea6db9a8f5982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7080\n",
      "AUC: 0.9848\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4616716206073761\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7c6e90d6164dc8a0cce957146d4b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94513e9f711346a6baeea31cbc72431f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6880\n",
      "AUC: 0.9853\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46391236782073975\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664333fcc5a349bf8a08389a745ed433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152ef6e156a647218e29867b4a80fc5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6720\n",
      "AUC: 0.9852\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46831732988357544\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c5326fb6c041c3b22f2b1db04a046a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b55d1188f8437abcc58742d4c28a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6720\n",
      "AUC: 0.9857\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.47003164887428284\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa01c1df4ed4df88cda7860b9359c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b86b07a900421382a5d1253802358d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6520\n",
      "AUC: 0.9858\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.47852733731269836\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92eb487275414221a643cc1a100147f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53de6925014f467d992a897330b74127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6360\n",
      "AUC: 0.9856\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.49548399448394775\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd22170788994e25a06a662db242ddd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0191e0e9f3c0457fb3620e557bf40685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6360\n",
      "AUC: 0.9856\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5077981352806091\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd25cfe5bf64d18af2034680aa7c3a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e164f2ae6b1e428292fd7776abb7ad76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6360\n",
      "AUC: 0.9854\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5277338624000549\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b893a05d0c243c8865b8484af81580f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd4c26bc76b144ad8aecec629ce6fbeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6360\n",
      "AUC: 0.9844\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5620203018188477\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a32e35a51394a92b6587a98f35a6e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88551e923b3e4aa982fa3125d599c357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6320\n",
      "AUC: 0.9835\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6102191209793091\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44aeeddf9365448e9bc63f4f671d18a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4249c3414c48948e4aef56cde19b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6200\n",
      "AUC: 0.9810\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6763134598731995\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eba387b406a4af3b10effd26c9fd926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81cf33190bf42feaafb0057c57765c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6160\n",
      "AUC: 0.9771\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7576197981834412\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e85d22d264840e991d78fe9b958dfa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6220d240aef46a79ccce260bbd284a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6160\n",
      "AUC: 0.9723\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8234801888465881\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 2/4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23b7ac9a551448aa1c60149fee56f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac9abe530c914d11924d28c09f7c7a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5481\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.717371940612793\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dfc563d261446cbb1517db2da3b0acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c3708cdc244b5080ec42aa42966723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5431\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7450451254844666\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d3c5db155f4cb3b8a00d8b4e183e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c5d8bab8e54472b7bba3a6964dc2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5415\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7811105251312256\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b78ae2a76c04eb69e2e052b0c1a9fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9cde198a1b442a97c5bf2b2d6b41a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5404\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8234179615974426\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b036ecf69c4973a5d6bba07c3c0ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992e05ca09394cc2ad657420c4ae7821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5435\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8687893748283386\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b18c8ae915049bc8c9d7353b6b2ca25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e080b1b6dc438880a279b7fd5a38cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5471\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9173064231872559\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "642f8337fc704d2c9f45c340d72bb289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5099b7a611243e09701620b080a47f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5589\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9456800818443298\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19241eb5ee3e4accb70ea8e4e58d0618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea8e84214044bc6861932415b6c21d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5765\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9509041905403137\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916abd6c6d4542469b2aa906eb7f0e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95643207746e4ed0be080d6b344aecc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.6062\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9339728951454163\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b9ac5272ca469cb2fbb3cd9fab7c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0608309c1d64451ca849f2c300ddaaa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.6577\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8939749002456665\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367da1cf1b6d4446a309779ac38dfda4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf088ec45144431aad75b4d377c5d3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.7103\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8550652265548706\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72b2f95aa53498e833e05a3b5b6c2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3131fb850da4c36b04c452690ce5d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.7675\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8201225399971008\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8caa91501ddf49e7aa729fed17dc7990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc4499b160f4fbca214319d5459e63d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.8366\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7815849184989929\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c64a0ffc684a7eae7f18fc89e09b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ac0d2eed19484cb56bc66d8dc05322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.9155\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7512733340263367\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df60d5f2b064691bc6d2ebc8b8dd7e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814e1c76e09d45a0b1f2cc6ec3617a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.9283\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7199587225914001\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914a8eda5da34841a3d4d1c23941c029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d20a08844efa43909dc24ae66192f231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.9288\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6923511028289795\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b290f657deb049cf85290491c70573c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c547bdc7ceaa4ee8949cc95a40d31b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.9188\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.668609619140625\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dda632154e14966b263927bf37426ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91d77a801264edc85aeb203b4b521d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5520\n",
      "AUC: 0.9170\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.644666850566864\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4504c586af2d4d89a1f12415d8a58eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8550b0fee42a471f958992676615e7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6320\n",
      "AUC: 0.9105\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6201967000961304\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14bbdfa83a8e4143aa9bcd5c2fa046b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472da831b5db429f952df22b47af561a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6480\n",
      "AUC: 0.9076\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6054437160491943\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a41e06bcc841ad841ed302c02be7f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bac6f6edb1e43389df556dd16941163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6760\n",
      "AUC: 0.9049\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5848287343978882\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a076210205a4da9958a457f27646998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5da4ba9e4a64c3790835e0dc455bf77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.9128\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5707404017448425\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54703aa4947a438fa25f715f8a998356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce50a3bfbb048eabd8f05db7281ed48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6920\n",
      "AUC: 0.9188\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5530725121498108\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c5a7a187ad4bb29eee504c6aab576b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0175ce2e3e4c6aa890548bc14acea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6800\n",
      "AUC: 0.9211\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5372450947761536\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ed844e3eef4dbb9dc3662401723a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a2432ab852458c8bfa9527d45d39dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.9260\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5211023688316345\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb6c85ba58649208f7ade6666e6be0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5641dab8494edf87b90ae7b5d66294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6960\n",
      "AUC: 0.9369\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5060869455337524\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54cd6e13d956415e9fbcac4e551f34e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d5940395214798b27287e158648e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.9456\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.49144843220710754\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db131fec4f04fd9b58429345a4205d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691b7b970cd348b88cfa5d8b2c02785d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7680\n",
      "AUC: 0.9483\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.47750750184059143\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f80a968537401e845103bf0cbcc666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fed76f041a483ba627c52d0b4564df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8160\n",
      "AUC: 0.9537\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4642047584056854\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa2a8f4d530491aaeecf5ba09f132ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5ea5ff67b84bd499b694d1646d354f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8400\n",
      "AUC: 0.9579\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.450749933719635\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733585cd358845b9a5ef33c2aa720ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a61d926733004d09a2973f5adee9a0a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8720\n",
      "AUC: 0.9615\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4383755028247833\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46db13a3f3b04e2984d12efb137051ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10ed89829bc47069aa5378ba44d595c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8880\n",
      "AUC: 0.9620\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4283220171928406\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb797ff1ed3b4153b093c35aed7ab1d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65262a4f2c894e34b28bb7ae1e65d7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9040\n",
      "AUC: 0.9656\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4170258641242981\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8884bf5407409fb9b877bd8cd8bddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff9a35eafb94a12971c20037b66e839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9000\n",
      "AUC: 0.9669\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.40810224413871765\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec39b5049014a89b722d4812dc38081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10faa7faeeda4663b7b6ebf04d8dc929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9080\n",
      "AUC: 0.9693\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3989730477333069\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6bef237b22c48929a6d120816c420a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07276f08dd2442ddb39c4ce0217974bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9160\n",
      "AUC: 0.9730\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3886931538581848\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b227eff98d4f708b67437b54687769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac1780a4e214a65a6f3ad96bcda9862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9240\n",
      "AUC: 0.9757\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3790704011917114\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7f9acae79a418ab7751423c7d671bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae84af369b73411ea17b4f728e3fc7d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9280\n",
      "AUC: 0.9766\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3731974959373474\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894650f5c0e4457997349a3174b1df88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ca1b3414b34c7fbf27c5c775a3f7d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9280\n",
      "AUC: 0.9775\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.367520809173584\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0008ea72a8401da3ae5ea08e31f3d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8404cf9b56d542699397a004473ce305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9160\n",
      "AUC: 0.9779\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.36424607038497925\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ffc8f1966144b66ad61dc16d621f1f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0f59dd1ada4641852e60eaf77cceba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9120\n",
      "AUC: 0.9796\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.35819339752197266\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af38d3991ee4829a755d90a4341ed4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51b1400725040119c9d2ddb66e56192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8920\n",
      "AUC: 0.9795\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3583759665489197\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26763f9091aa47e89b322c12aa480a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c8f14176c324b0699da7dbd9175f09d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8760\n",
      "AUC: 0.9786\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.36118069291114807\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7829df269dda45398bbecbb3d31b5e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ca669cab344899a8a7f9e753712bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8600\n",
      "AUC: 0.9790\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3625585436820984\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf78aa894be4ac3bf10e9dba1b47020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7d6d2d19f3420085c2d8dd37cfc5bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8240\n",
      "AUC: 0.9787\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3666326403617859\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fbdaf07b1c4fb6a3d17ced518b50c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee7b57e0e4274f5fabee20952c66537f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8200\n",
      "AUC: 0.9778\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.372514933347702\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee7f80521ff4350839541d22f4630e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4866f93be3457298f9e50269d0397e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7760\n",
      "AUC: 0.9740\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.39283594489097595\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e47709a68b44f885f548af1f4c0102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f920cabc392a477fb3e1550fe895ee10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.9725\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.40876996517181396\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ddc7631e4cf4223b7776f956830f2c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c24e16223840b3a3caa2c5b850ac71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.9672\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.44346338510513306\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c415838808194eff969a9907dd838ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016f0560ea1a4948ab0ebbb23d290b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7040\n",
      "AUC: 0.9629\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4677903652191162\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 3/4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e874ea69172487eba1a5e2f967d5597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32d5ef0bc57408ea05591868a9ab86a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.3578\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7646703124046326\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c6eda59e584d7eabf3909b82f4b2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e501adca73fb4235b2497bbb57fb2c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.3447\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8073998093605042\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6019385325f04d42b9c61ed16a1f2f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c37cb5712f41c5a79ccdc2d89812ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.3569\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8571241497993469\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478aa5daf46e4447969beecb24f6b073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b1e6784e35c4a75932e888177261f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.3740\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9122894406318665\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc448f2efb04515bf03ab710f5bc4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c8bf564313b4c308326f7fb76377b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.3892\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9674577116966248\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a325144edbd94968aca8d0c12679431f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a48f5de101f48649771305cbde405fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.4008\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0163524150848389\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74085d552b7241ff86572627dd4743c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa296d3a589341699e1eb0ba7a2b57ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.4124\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.046737551689148\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4558eeec92ed48fcae373f6bf2b71b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a7b1160544479cb65f5f545cd3efca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.4202\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0376032590866089\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4b2ec749154f2096b7b1c4dfc362bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb4f5d163d04ff8845e20688da7082f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.4272\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9943113923072815\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b47fec6d234340b7b38cbf826d1715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e10d749be04d7e8d9f6d2834a929cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.4509\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9544631242752075\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d0d81b6fa8643549d27721fb9011cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc23ddb1b4184551968ee46f5b33b694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.5366\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.900882363319397\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3d1d80f8924616b732b82ab2e4ec17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a164294bbf54f9988e0be589613de80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.6301\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8538217544555664\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91fe73d0e0454b95b887d3868496bbf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa792c9b72747d2b80cd83fbb3bcaf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.7157\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.807612419128418\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9361e655f6493ab90a20b9c90c9c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c052af021d9c40a9b4e86f739f92ed0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.8365\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7581682205200195\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad1e4a466264eafaa058e8022f669ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90795dad9d04d989a8086ff3f2378c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.8946\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7294301986694336\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959eb24e55054519abe433fd16c796b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b2920d2c9da4824bc3d3eb1139522c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.9414\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6935791969299316\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36603df1cf584c70993aea81673abb4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4b82843b9f496aaf6194422099ad96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4880\n",
      "AUC: 0.9606\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6606057286262512\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc3d92f553543378c0843473f4590b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda9d462590d48dcbdabfb062123d4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5240\n",
      "AUC: 0.9677\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.636092483997345\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e3431e67e941d5b13c7947d148478a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55394f5e26b47c894b8ca91789519b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5480\n",
      "AUC: 0.9755\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6007143259048462\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b639d803ebd42639f2c2a129c2d6f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a016d5ddd045ebad558cb1c4e736e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6080\n",
      "AUC: 0.9787\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5747458934783936\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e87a9dcb8c468a9e67e11c4e7858b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f0105f842048e3a4f6e256ead2cb31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7520\n",
      "AUC: 0.9804\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5471512675285339\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b54872005259440f87c4c1e93985e6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b8ac1b43b624115a6206904c8847bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8240\n",
      "AUC: 0.9802\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5269227027893066\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994ae6f5c81d4cc7a854b1c0e23fc294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69dff64d1cc64bbe848e1fac4cd92b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8800\n",
      "AUC: 0.9803\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5050925612449646\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c2e09dc4cf4c0a8cf3a61c21710da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fea4a81ed4a494ca7bfebc771b1040b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9080\n",
      "AUC: 0.9811\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4864676892757416\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9508f255da474545896d804ddf646587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9168920ab1154bef9b32c17425e61cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9400\n",
      "AUC: 0.9809\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46862009167671204\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c085a3b4ccb64e3580175d2e4b113e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef0adbf8d97450985b6e58a3e613c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9480\n",
      "AUC: 0.9813\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.45410534739494324\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078870d8be5a4b44b8c5d391054f42c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19e3d10744b440b808afa2c8186bbaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9440\n",
      "AUC: 0.9816\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.43962836265563965\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2cfda449cb40c2a911eeaabc339d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a7e485a9bc41b883a382f3673c9ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9360\n",
      "AUC: 0.9815\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4254854917526245\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e29f5955884481a74088e2a1b74ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1b9608cbea427292050c18b720a96f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9360\n",
      "AUC: 0.9819\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.41257503628730774\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12a050db0674c98a46aaf1c4fd7468c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b179926e8f64e24a3570ceefd6fe82e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9200\n",
      "AUC: 0.9814\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.40312251448631287\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a621555e9ca54ad4a033b1373aa30805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2a528f6b8e414aa54adbf99b9e3b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9200\n",
      "AUC: 0.9821\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3922138810157776\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e2a9ca635404e89abd50e9ea2594317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b822e292d83d4d7eacefade118f07e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9200\n",
      "AUC: 0.9829\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3806627094745636\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea45391351f4798abccd2fd2f9ab6ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e8521f2fb84d6c8a33553014725a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8960\n",
      "AUC: 0.9827\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.37510231137275696\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5cad75fa8eb4c2e947e080cf0e4fa04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d0b553c98b4a62b393fa3eae92c717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8640\n",
      "AUC: 0.9826\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3690491318702698\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a970714b5f249d691e8cb1e70a32500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee2beeb903c4a31a6d6cc0417dcb957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8600\n",
      "AUC: 0.9829\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.36349326372146606\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d86bfb31684679ba3a79eb8f5bf7d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd6de7cfe29423b8e929039afb96aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8560\n",
      "AUC: 0.9830\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3575969338417053\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e4e25c90fb44128f5507afef9578fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9996102589094c50847f11ec32be082d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8520\n",
      "AUC: 0.9832\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.34994566440582275\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261553e8dcbb4ad38239bac7e421fb30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f404dce4f1943b3a6c0e4f24027af11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8400\n",
      "AUC: 0.9834\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.34980419278144836\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec228c2a9d446639e19d53c61bef891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302d921ce1d44b0197c1d09e06b87dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8360\n",
      "AUC: 0.9836\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.35030269622802734\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2c7bbaea3d4b94b09b4446a05cac75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c92760a8684269b5a2fe438a051bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8360\n",
      "AUC: 0.9837\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3482760787010193\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef452bd16f3499b9bad60883c9c6279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b20b5e250443da82b41a456de7c33e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8200\n",
      "AUC: 0.9835\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3532532751560211\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f1aff460cf42f4a17c2c8f787507c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c62c7e404e43e0bafd3b5895c57923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8040\n",
      "AUC: 0.9834\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3600814640522003\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6edcb637327b490ca95938a4b399bb31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e87dca011d94aeb8ac72972072da7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8120\n",
      "AUC: 0.9836\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.36376574635505676\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b1acedda6b04b42b104ae2e0498533e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2e0643363d413eb4e1bcb28a375a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7960\n",
      "AUC: 0.9836\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3749501705169678\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b17220e9cc454ae18b2d2f456f362181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c2058d6f49a4e54982918d472d9f166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7680\n",
      "AUC: 0.9834\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.39176681637763977\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b0b90e117741ca96858641a44f7382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9596fb15ec24e5599a54cba218080d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.9831\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4122205078601837\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88ec55805ef4e88a375bd8e67cf09f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b555742322f84c82a0e8d18c5738f52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.9822\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4413783550262451\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50aff8b3bb744df9bce46f141d5fcbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb7d3a81a524634967ccfff15d7684e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.9820\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46460089087486267\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4a21d8395f4b71bebd1441e8d13eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df46f37f7f86499b8ccbd17159b1b69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7040\n",
      "AUC: 0.9810\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5206246972084045\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "850925ce9aaa43209f10026c1285e13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41bd0f6ebd884a068ee58d1606e87f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7000\n",
      "AUC: 0.9795\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.564780056476593\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "--- Starting Fold 4/4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f7596babe84606b84913afc709b1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02762265f94a4f72819cff85ad76af50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4104\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7925464510917664\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5e621f0e714872ae0368776154d0c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea7702b5a3c44baa5f383f543a7d1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4246\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8388370275497437\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d47a8d916104e17bbf09d2fa0594fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3213a61314a422387c1891af6c543ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4354\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8921871185302734\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6d2aa3006740109f10720a1cb542b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549c499dfdbe4f54b0a3bde3369adbff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4429\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9488739967346191\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bed7e3e578144aabcb4d1f7b1858854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f69029f00594ea6a23bb70948838484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4494\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9820002317428589\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f51506991d4058b7d27c0bd4ade470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eeea3788b274e668bf866ac020bd59f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4540\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.962270200252533\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e2ea276178948cabd23810430dfe517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1201a70e9fc4c3fbe3a2445571a366d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4607\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9231041669845581\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d990e28839d4bdcae76d624e15fe7f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c18e7bb528bf4870a1ecfba30df86490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4774\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8794955015182495\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e448503389471699717bed085d7282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc28b3c8af2490e968ee1ff72181efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.5194\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.836094856262207\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "097879de61704dbc8e4067b5528f1c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52fcd9e17d704ee995ef550ccef58084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.5893\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7973949909210205\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "430b9f7d8aa04a7ab0fb3bf2f1b0f33b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db94ea1dd6e740ae8b0f86ff9993226d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.6728\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7542611360549927\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51dd691ad8a42f697293b0fb933f662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367d8eeb5146415d9d70cd7fb641a247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.7394\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7173950672149658\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2882015e9c6b4ed19eeaa2ac1454111f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d20f78e01a9476a8d3d1dcf2a7474f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.8237\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6837164163589478\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1df6b73f665453f939a55a51514e1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ba797c8807477593768f17ac9f4fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.8870\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6588457226753235\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0028208132402f8c7983672fc3bb7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4774b80d444e9797f3b9bcc0329a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.9295\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.635445237159729\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c64366747be46bdad7404649a527822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f6fee359d249c3bcc8a987c0281889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5960\n",
      "AUC: 0.9669\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss             0.6011922955513\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ee269f3dd543f897ae11b60b74404b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9580268015694cccab3d4a0f75655761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6080\n",
      "AUC: 0.9783\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5804463028907776\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7666d2b62f542c7adcfbc5f21f149d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c030fc8a49d40bab4cd6cb1801bd18d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6640\n",
      "AUC: 0.9850\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5563154816627502\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ef3b38607e45da8086a01a58a507d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4c2d64a4c84e8683615446f3d77ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.9877\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.536345362663269\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ff4711644e48ba8f346642eba8fd7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76e1e52fa2641feb91609e123487752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.9896\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5204633474349976\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5481f8d48a6a4ac88a1ef9de3d930247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff5c4c3d9ce422b813174fb52a84ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7960\n",
      "AUC: 0.9908\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5062368512153625\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d3cf39f6494a7db84f0d7a0a4d3e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cdfc1c89f534dee9945bfda23eb775b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8760\n",
      "AUC: 0.9916\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4897274971008301\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce82c1aaba5a4904ab2e34cf3d9beeff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa0005c6ab94367b310b010783b23f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9040\n",
      "AUC: 0.9920\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.47598063945770264\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837ea8bb92fa4bddaa33e8c399e6af80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f236984ef04f5dafccbd36ec2b9e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9400\n",
      "AUC: 0.9920\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46413880586624146\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fed4136d0f6469f833e0b9452b28f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a8954deaf54217a02e930d1b0c77b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9400\n",
      "AUC: 0.9927\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.45240655541419983\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe9980a1d5b4445bb5d12cfb3970134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b35816de8048b1a7486f917d1162e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9440\n",
      "AUC: 0.9927\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.442131370306015\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc904aa8807948fa9fced1fb1495591c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca368c8724c54e93be67729de3f14e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9600\n",
      "AUC: 0.9932\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.43256956338882446\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62af30ded15349408e53c1292e1f4e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b078739d1754d9e8eb1e2b962bf7fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9520\n",
      "AUC: 0.9934\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4233320951461792\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c748aab405414cb16e2c865eaefb4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94445df86d944cf9b99f8d8702d4fdf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9400\n",
      "AUC: 0.9934\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4178410768508911\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0cf19ed5e97475395dd7a3432513917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "280bfa651ca04ef7b215aa5bf28c665d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9240\n",
      "AUC: 0.9945\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.40832072496414185\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1f472d106b41c980b8e80c61289af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d94599c39545ef8db570c8cf9205f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9000\n",
      "AUC: 0.9945\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.40333452820777893\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0918ac93760e4d49b7d92d1ec2f024ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00215e5cf8a4b70b4e1b6b6240e15ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8920\n",
      "AUC: 0.9946\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3970092236995697\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70910bbb3ceb49bb947ead6ed3c34ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e48dab44a54248950aef90f57fff64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8600\n",
      "AUC: 0.9947\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.39271825551986694\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7706198abe16446e9877ca23cdbea486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73cdf2dd7114fd7bc0e63a18ad7cdf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8440\n",
      "AUC: 0.9955\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3874354362487793\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55dbcfbf1c674e709b9234538723b681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e4085d38ad4bea94b2273fdcdb4a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8400\n",
      "AUC: 0.9958\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3857465088367462\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04b8ae1b01643dab5b3d85ad75d8191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dadddb0bddbc4dfc81847608f99f322d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8360\n",
      "AUC: 0.9957\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.381960928440094\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d441022d8a4e7085c170e8224a6b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625f2bf174d24d108b3c8db405244229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8200\n",
      "AUC: 0.9958\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.38210180401802063\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9800f49e3245fd8e7a1f7889bd2a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa28552de104112a1d5cdb6fd752253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7920\n",
      "AUC: 0.9959\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3862249255180359\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9e253d390541fcb27ab752b1d1c1dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae33d294406649cb904364f0410a5ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7680\n",
      "AUC: 0.9959\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3900529444217682\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05e28a987a140e5a127c25c3435285a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97c0884747d4f31972be3501642f703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7560\n",
      "AUC: 0.9962\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.39183753728866577\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd684dd1e435402489195e8407107923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6938ba301d974844a8f65ca21df711b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.9961\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.39715442061424255\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4ff852d4f74552922c9a0a2d05bdf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d97c59a8a74cd7b2594fc234d20378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.9963\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4049445688724518\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405ca5ffc71143678e7649bdbbabb0a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc14aa70358049ca85cd11f7988f2a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7040\n",
      "AUC: 0.9961\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.42448049783706665\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb3473e7fb0472cb751ce4fe8ee94b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75feead7f9464f77ba15de3227ff0ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7000\n",
      "AUC: 0.9962\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4376722276210785\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e97eb72f4534d7ab8e50a20d172b089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9189dc2d5b754000a4b12d35c484c15f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.9961\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.45417970418930054\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f3bae4c03a4aa29653f8dd7e8ba6a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91777fe7c3504625ba4c962c13c440bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6680\n",
      "AUC: 0.9957\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4867097735404968\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90a00a2880a42faa0a194eb6bdb65aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c4029da5be44d9c86095e53f77e780d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6640\n",
      "AUC: 0.9954\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5291454195976257\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03781bc93e540e9b1dc23ff0cccfc3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e7065e387c4f9baa25175c2cda1bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6520\n",
      "AUC: 0.9949\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5835147500038147\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ff9e72022a4718b45d258070378c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed599b2bd4f4d73bc3cba1cd8899966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6440\n",
      "AUC: 0.9931\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6562725305557251\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1e02f10837432db716833c6de79052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56fa9fb3fa0f4a248d5ad8f071726c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6360\n",
      "AUC: 0.9911\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7162198424339294\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "import numpy as np\n",
    "\n",
    "# --- Place any constants or unchanging objects outside the loop ---\n",
    "pl.seed_everything(42, workers=True)\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "#store the weighted classifiers of all the folds\n",
    "list_folds_weighted_clfs = []  # List to store classifiers from all folds\n",
    "#store the best classfiers of all the folds\n",
    "list_folds_best_models = []  # List to store best models from all folds\n",
    "\n",
    "# Dictionary to store the history of each fold\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "\n",
    "# 3. K-fold cross-validation loop\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(train_data_tensor)):\n",
    "    list_weighted_clfs = [] # List to store the models trained at each stage\n",
    "    best_clfs = [] # List to store the best models from each stage\n",
    "    best_model_paths = [] # List to store the path of the best model from each stage\n",
    "    # 1. Instantiate the LightningModule\n",
    "    model = LitClassifier(input_features=2, hidden_units=32, learning_rate=LEARNING_RATE)\n",
    "    print(f\"--- Starting Fold {fold + 1}/{K_FOLDS} ---\")\n",
    "\n",
    "    # 4. Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "\n",
    "    train_loader = data.DataLoader(\n",
    "                      train_data_tensor,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      sampler=train_subsampler,\n",
    "                      num_workers=NUM_WORKERS)\n",
    "    fold_loader = data.DataLoader(\n",
    "                    train_data_tensor,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    sampler=val_subsampler,\n",
    "                    num_workers=NUM_WORKERS)\n",
    "\n",
    "\n",
    "    for i, pos_weight in enumerate(pos_weights):\n",
    "        \n",
    "        model.criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight))  # Set the pos_weight for this stage\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            every_n_epochs=1,                # Save model every epoch\n",
    "            dirpath=f'checkpoints/stage_{i+1}/fold_{fold+1}/',\n",
    "            filename=f'best-model-fold{fold+1}-{{epoch:02d}}',\n",
    "            save_top_k=1,\n",
    "            mode='max',\n",
    "        )\n",
    "        \n",
    "        # 3. Instantiate a NEW Trainer for this specific stage\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator='gpu',\n",
    "            devices=1,\n",
    "            #strategy='ddp_notebook',\n",
    "            max_epochs=NUM_EPOCHS, # Number of epochs for THIS stage\n",
    "            callbacks=[checkpoint_callback, progress_bar],\n",
    "            logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=f\"stage_{i+1}_fold_{fold+1}_ratio_{pos_weight}\"),\n",
    "            precision='16-mixed'\n",
    "            )\n",
    "        \n",
    "        # 4. Train the model. It will start with weights from the previous stage.\n",
    "        trainer.fit(model, train_dataloaders=train_loader)\n",
    "        \n",
    "        # 5. Get the path to the best model from THIS stage and store it\n",
    "        if checkpoint_callback.best_model_path:\n",
    "            best_path_this_stage = checkpoint_callback.best_model_path\n",
    "            print(f\"--- Fold {fold+1} Stage {i+1} complete. Best model path: {best_path_this_stage} ---\")\n",
    "            best_model_paths.append(best_path_this_stage)\n",
    "            \n",
    "            # 6. CRITICAL: Load the best weights back into the model object\n",
    "            # This ensures we carry forward the BEST model to the next stage, not the last.\n",
    "            print(f\"Loading best weights from {best_path_this_stage} to continue...\")\n",
    "            model = LitClassifier.load_from_checkpoint(best_path_this_stage, strict=False)  # Use strict=False to ignore missing keys if any\n",
    "        else:\n",
    "            print(f\"--- Fold {fold+1} Stage {i+1} complete. No checkpoint was saved. ---\")\n",
    "            # If no checkpoint was saved, the model object will just have the weights from the last epoch.\n",
    "\n",
    "        # 7. Test the model after each stage\n",
    "        print(f\"\\n--- Testing model after Fold {fold+1} Stage {i+1} ---\")\n",
    "        trainer.test(model, dataloaders=fold_loader, ckpt_path=best_path_this_stage)\n",
    "        results_classifier = model.last_test_results.copy()\n",
    "        current_model = {\n",
    "            \"model\": model,\n",
    "            \"fpr\": results_classifier[\"fpr\"],\n",
    "            \"tpr\": results_classifier[\"tpr\"],\n",
    "            \"threshold\": results_classifier[\"threshold\"],\n",
    "            \"full_roc\": results_classifier[\"full_roc\"]\n",
    "        }\n",
    "        list_weighted_clfs.append(current_model)\n",
    "        best_clfs = get_best_roc_envelope(list_weighted_clfs, results_original_roc)\n",
    "    list_folds_weighted_clfs.append(list_weighted_clfs)\n",
    "    list_folds_best_models.append(best_clfs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6b93abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to pickle/NN_data1_weighted.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_models': [[{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.8360656),\n",
       "    'threshold': np.float16(0.899)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0078125),\n",
       "    'tpr': np.float32(0.8442623),\n",
       "    'threshold': np.float16(0.9165)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.015625),\n",
       "    'tpr': np.float32(0.8606557),\n",
       "    'threshold': np.float16(0.8125)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0234375),\n",
       "    'tpr': np.float32(0.8852459),\n",
       "    'threshold': np.float16(0.7646)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.03125),\n",
       "    'tpr': np.float32(0.90163934),\n",
       "    'threshold': np.float16(0.8286)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.046875),\n",
       "    'tpr': np.float32(0.90983605),\n",
       "    'threshold': np.float16(0.758)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0546875),\n",
       "    'tpr': np.float32(0.91803277),\n",
       "    'threshold': np.float16(0.7646)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0625),\n",
       "    'tpr': np.float32(0.93442625),\n",
       "    'threshold': np.float16(0.683)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.078125),\n",
       "    'tpr': np.float32(0.94262296),\n",
       "    'threshold': np.float16(0.6865)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0859375),\n",
       "    'tpr': np.float32(0.9590164),\n",
       "    'threshold': np.float16(0.5513)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.09375),\n",
       "    'tpr': np.float32(0.9672131),\n",
       "    'threshold': np.float16(0.542)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1171875),\n",
       "    'tpr': np.float32(0.9836066),\n",
       "    'threshold': np.float16(0.529)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1328125),\n",
       "    'tpr': np.float32(0.9918033),\n",
       "    'threshold': np.float16(0.4846)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1875),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.4663)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.4090909),\n",
       "    'threshold': np.float16(0.4478)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.008474576),\n",
       "    'tpr': np.float32(0.5530303),\n",
       "    'threshold': np.float16(0.7744)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.016949153),\n",
       "    'tpr': np.float32(0.75),\n",
       "    'threshold': np.float16(0.802)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.025423728),\n",
       "    'tpr': np.float32(0.7878788),\n",
       "    'threshold': np.float16(0.7056)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.033898305),\n",
       "    'tpr': np.float32(0.79545456),\n",
       "    'threshold': np.float16(0.6978)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.042372882),\n",
       "    'tpr': np.float32(0.8712121),\n",
       "    'threshold': np.float16(0.7983)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.050847456),\n",
       "    'tpr': np.float32(0.9469697),\n",
       "    'threshold': np.float16(0.603)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.06779661),\n",
       "    'tpr': np.float32(0.9621212),\n",
       "    'threshold': np.float16(0.6304)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.076271184),\n",
       "    'tpr': np.float32(0.97727275),\n",
       "    'threshold': np.float16(0.689)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.10169491),\n",
       "    'tpr': np.float32(0.9848485),\n",
       "    'threshold': np.float16(0.6123)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.13559322),\n",
       "    'tpr': np.float32(0.99242425),\n",
       "    'threshold': np.float16(0.527)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.19491525),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.4407)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.7076923),\n",
       "    'threshold': np.float16(0.5986)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.008333334),\n",
       "    'tpr': np.float32(0.84615386),\n",
       "    'threshold': np.float16(0.3958)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.016666668),\n",
       "    'tpr': np.float32(0.88461536),\n",
       "    'threshold': np.float16(0.4116)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.025),\n",
       "    'tpr': np.float32(0.9),\n",
       "    'threshold': np.float16(0.4023)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.033333335),\n",
       "    'tpr': np.float32(0.93846154),\n",
       "    'threshold': np.float16(0.7163)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.041666668),\n",
       "    'tpr': np.float32(0.9461538),\n",
       "    'threshold': np.float16(0.7476)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.05),\n",
       "    'tpr': np.float32(0.95384616),\n",
       "    'threshold': np.float16(0.688)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.06666667),\n",
       "    'tpr': np.float32(0.96153843),\n",
       "    'threshold': np.float16(0.414)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.075),\n",
       "    'tpr': np.float32(0.9692308),\n",
       "    'threshold': np.float16(0.616)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1),\n",
       "    'tpr': np.float32(0.97692305),\n",
       "    'threshold': np.float16(0.617)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.125),\n",
       "    'tpr': np.float32(0.9846154),\n",
       "    'threshold': np.float16(0.7036)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.34166667),\n",
       "    'tpr': np.float32(0.99230766),\n",
       "    'threshold': np.float16(0.355)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.39166668),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.4734)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.8189655),\n",
       "    'threshold': np.float16(0.815)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0074626864),\n",
       "    'tpr': np.float32(0.92241377),\n",
       "    'threshold': np.float16(0.7886)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.014925373),\n",
       "    'tpr': np.float32(0.94827586),\n",
       "    'threshold': np.float16(0.8984)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.029850746),\n",
       "    'tpr': np.float32(0.95689654),\n",
       "    'threshold': np.float16(0.627)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.03731343),\n",
       "    'tpr': np.float32(0.98275864),\n",
       "    'threshold': np.float16(0.708)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.04477612),\n",
       "    'tpr': np.float32(0.9913793),\n",
       "    'threshold': np.float16(0.8516)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.05970149),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.672)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}]],\n",
       " 'weighted_clfs': [[{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.1640625, 0.1953125, 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.296875 , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.4921875,\n",
       "            0.5      , 0.5      , 0.5      , 0.5      , 0.5      , 0.5      ,\n",
       "            0.5      , 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.6171875, 0.6328125, 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.65625  , 0.6640625, 0.6640625,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.7109375, 0.7109375, 0.7109375, 0.71875  ,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.765625 , 0.78125  , 0.78125  , 0.78125  ,\n",
       "            0.7890625, 0.7890625, 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.8671875, 0.8671875, 0.875    , 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.921875 , 0.9296875, 0.9375   , 0.9375   , 0.9453125,\n",
       "            0.9453125, 0.9453125, 0.9453125, 0.953125 , 0.953125 , 0.953125 ,\n",
       "            0.953125 , 0.953125 , 0.9609375, 0.9609375, 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.984375 , 0.984375 , 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.01639344, 0.01639344, 0.02459016,\n",
       "            0.03278688, 0.04098361, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.07377049, 0.08196721, 0.09016393, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.36885247, 0.37704918, 0.37704918,\n",
       "            0.3852459 , 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.46721312, 0.46721312, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.56557375, 0.57377046,\n",
       "            0.57377046, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6803279 ,\n",
       "            0.6885246 , 0.6885246 , 0.704918  , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.7295082 , 0.73770493, 0.73770493,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.795082  , 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8278689 , 0.8278689 , 0.8278689 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4766, 0.474 , 0.4734, 0.4724, 0.472 , 0.4714, 0.4712,\n",
       "            0.471 , 0.4692, 0.469 , 0.468 , 0.4675, 0.4668, 0.4663, 0.466 ,\n",
       "            0.4658, 0.4656, 0.4653, 0.465 , 0.4648, 0.4646, 0.464 , 0.4639,\n",
       "            0.463 , 0.4626, 0.4624, 0.4612, 0.4607, 0.4595, 0.4568, 0.4558,\n",
       "            0.4556, 0.4548, 0.4546, 0.454 , 0.4487, 0.446 , 0.4446, 0.443 ,\n",
       "            0.4424, 0.4414, 0.4404, 0.438 , 0.4373, 0.4346, 0.4324, 0.43  ,\n",
       "            0.4282, 0.426 , 0.4248, 0.4216, 0.418 , 0.4177, 0.417 , 0.4167,\n",
       "            0.4155, 0.4148, 0.413 , 0.4126, 0.4119, 0.41  , 0.4097, 0.4084,\n",
       "            0.4075, 0.4055, 0.4038, 0.402 , 0.401 , 0.3997, 0.3994, 0.3992,\n",
       "            0.399 , 0.397 , 0.3958, 0.3955, 0.3936, 0.3906, 0.389 , 0.3882,\n",
       "            0.3877, 0.387 , 0.3867, 0.3862, 0.386 , 0.3855, 0.3853, 0.3843,\n",
       "            0.3833, 0.382 , 0.3816, 0.379 , 0.3767, 0.3762, 0.3755, 0.3752,\n",
       "            0.3748, 0.371 , 0.3708, 0.3704, 0.37  , 0.3699, 0.368 , 0.3674,\n",
       "            0.367 , 0.3667, 0.3657, 0.3652, 0.3638, 0.3635, 0.3625, 0.3606,\n",
       "            0.3604, 0.3594, 0.3582, 0.358 , 0.3577, 0.3574, 0.3572, 0.3567,\n",
       "            0.3562, 0.3552, 0.3533, 0.3525, 0.352 , 0.3518, 0.3516, 0.3513,\n",
       "            0.3508, 0.35  , 0.3477, 0.3464, 0.3462, 0.346 , 0.3433, 0.343 ,\n",
       "            0.3423, 0.3418, 0.3406, 0.34  , 0.3396, 0.3394, 0.339 , 0.338 ,\n",
       "            0.3376, 0.3367, 0.3364, 0.3357, 0.3354, 0.3347, 0.3345, 0.3342,\n",
       "            0.334 , 0.3337, 0.3335, 0.3323, 0.3318, 0.3313, 0.3296, 0.3286,\n",
       "            0.3276, 0.327 , 0.326 , 0.325 , 0.3245, 0.324 , 0.3228, 0.322 ,\n",
       "            0.3208, 0.32  , 0.3196, 0.3193, 0.319 , 0.3179, 0.3174, 0.3167,\n",
       "            0.316 , 0.3157, 0.3152, 0.3135, 0.313 , 0.3115, 0.3103, 0.31  ,\n",
       "            0.3098, 0.3086, 0.3083, 0.3076, 0.3052, 0.3037, 0.3035, 0.3032,\n",
       "            0.3022, 0.3015, 0.2996, 0.2993, 0.2964, 0.2952, 0.295 , 0.2942,\n",
       "            0.291 , 0.2908, 0.29  , 0.2876, 0.2842, 0.284 , 0.2832, 0.279 ,\n",
       "            0.273 , 0.2725, 0.264 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.0390625, 0.0546875,\n",
       "            0.0625   , 0.0859375, 0.09375  , 0.109375 , 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.171875 ,\n",
       "            0.1796875, 0.1953125, 0.203125 , 0.2109375, 0.2265625, 0.2421875,\n",
       "            0.25     , 0.265625 , 0.2734375, 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.4296875, 0.4375   , 0.4453125, 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.6171875, 0.625    , 0.625    ,\n",
       "            0.6328125, 0.6328125, 0.6328125, 0.640625 , 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.6953125, 0.703125 , 0.7109375, 0.7109375,\n",
       "            0.71875  , 0.71875  , 0.71875  , 0.7265625, 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.7421875, 0.75     , 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.78125  , 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.796875 , 0.8046875, 0.8125   , 0.8125   , 0.8125   ,\n",
       "            0.8203125, 0.8359375, 0.8359375, 0.84375  , 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.8671875, 0.875    , 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.8984375, 0.9140625, 0.921875 , 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.953125 , 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.01639344, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.22950819, 0.24590164, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.6393443 , 0.6393443 ,\n",
       "            0.647541  , 0.647541  , 0.647541  , 0.6557377 , 0.6557377 ,\n",
       "            0.6639344 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.71311474, 0.71311474, 0.7295082 , 0.7295082 ,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4568, 0.455 , 0.4548, 0.451 , 0.4507, 0.4497, 0.4478,\n",
       "            0.4475, 0.4473, 0.4465, 0.4463, 0.4458, 0.4456, 0.445 , 0.4448,\n",
       "            0.4446, 0.444 , 0.4436, 0.4434, 0.443 , 0.4424, 0.4417, 0.4412,\n",
       "            0.44  , 0.439 , 0.437 , 0.4365, 0.4363, 0.436 , 0.435 , 0.4343,\n",
       "            0.433 , 0.431 , 0.4282, 0.4265, 0.426 , 0.4248, 0.4238, 0.4229,\n",
       "            0.421 , 0.413 , 0.411 , 0.4094, 0.4077, 0.407 , 0.404 , 0.4014,\n",
       "            0.3997, 0.3953, 0.393 , 0.3916, 0.3904, 0.3877, 0.384 , 0.3762,\n",
       "            0.3738, 0.371 , 0.3704, 0.3687, 0.3684, 0.368 , 0.3667, 0.3638,\n",
       "            0.3633, 0.361 , 0.3594, 0.358 , 0.3567, 0.356 , 0.3547, 0.3533,\n",
       "            0.3513, 0.351 , 0.3503, 0.3481, 0.3472, 0.347 , 0.3447, 0.3438,\n",
       "            0.3435, 0.3433, 0.343 , 0.3413, 0.339 , 0.3386, 0.3381, 0.3372,\n",
       "            0.3342, 0.3335, 0.3323, 0.3315, 0.3306, 0.3296, 0.3293, 0.3289,\n",
       "            0.328 , 0.3274, 0.326 , 0.3257, 0.3247, 0.324 , 0.3237, 0.3206,\n",
       "            0.3196, 0.3174, 0.3164, 0.3162, 0.3142, 0.3125, 0.3096, 0.309 ,\n",
       "            0.3086, 0.3066, 0.3062, 0.306 , 0.3057, 0.3054, 0.3047, 0.3044,\n",
       "            0.304 , 0.3037, 0.3015, 0.3013, 0.301 , 0.3005, 0.2998, 0.2993,\n",
       "            0.2966, 0.294 , 0.2937, 0.293 , 0.2927, 0.2908, 0.2903, 0.29  ,\n",
       "            0.2896, 0.2869, 0.2864, 0.286 , 0.2856, 0.2844, 0.284 , 0.2834,\n",
       "            0.2832, 0.2815, 0.2795, 0.2776, 0.2773, 0.2769, 0.2747, 0.273 ,\n",
       "            0.2727, 0.2717, 0.271 , 0.2708, 0.27  , 0.269 , 0.2683, 0.268 ,\n",
       "            0.2673, 0.2668, 0.2664, 0.2651, 0.265 , 0.2644, 0.264 , 0.2627,\n",
       "            0.2622, 0.262 , 0.2617, 0.2612, 0.261 , 0.2595, 0.2588, 0.2573,\n",
       "            0.2556, 0.2554, 0.255 , 0.2522, 0.2512, 0.25  , 0.2496, 0.2485,\n",
       "            0.2473, 0.247 , 0.2458, 0.2456, 0.2455, 0.2452, 0.2448, 0.2444,\n",
       "            0.2433, 0.243 , 0.2417, 0.2413, 0.2394, 0.2372, 0.2363, 0.2362,\n",
       "            0.2334, 0.2332, 0.2311, 0.2302, 0.2277, 0.2274, 0.226 , 0.224 ,\n",
       "            0.2224, 0.22  , 0.2095, 0.2089, 0.2074, 0.2048, 0.2032, 0.1892],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.0234375, 0.03125  , 0.0390625, 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.109375 ,\n",
       "            0.125    , 0.1328125, 0.1484375, 0.15625  , 0.1640625, 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.5859375, 0.59375  , 0.59375  , 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.6328125, 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6875   , 0.6875   , 0.6875   , 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.7734375,\n",
       "            0.78125  , 0.78125  , 0.7890625, 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.875    , 0.8828125,\n",
       "            0.890625 , 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.02459016, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.08196721, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.23770492, 0.25409836, 0.26229507, 0.26229507,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.3114754 , 0.3114754 ,\n",
       "            0.31967214, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.46721312, 0.47540984, 0.47540984, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.60655737,\n",
       "            0.6147541 , 0.6147541 , 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.71311474, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.852459  , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4368, 0.436 , 0.4314, 0.4302, 0.43  , 0.4297, 0.4294,\n",
       "            0.4287, 0.4285, 0.426 , 0.4253, 0.4246, 0.423 , 0.4226, 0.422 ,\n",
       "            0.4214, 0.421 , 0.4204, 0.4202, 0.4192, 0.4185, 0.4182, 0.4175,\n",
       "            0.4172, 0.4155, 0.4143, 0.4136, 0.4133, 0.411 , 0.4102, 0.41  ,\n",
       "            0.4087, 0.4084, 0.4082, 0.4067, 0.4055, 0.4053, 0.402 , 0.3997,\n",
       "            0.397 , 0.3965, 0.3945, 0.393 , 0.391 , 0.38  , 0.379 , 0.3784,\n",
       "            0.3752, 0.3726, 0.3723, 0.3706, 0.3667, 0.3652, 0.3635, 0.3625,\n",
       "            0.36  , 0.3594, 0.3538, 0.35  , 0.3496, 0.3425, 0.3398, 0.3381,\n",
       "            0.3342, 0.3318, 0.3293, 0.328 , 0.3218, 0.3215, 0.3213, 0.321 ,\n",
       "            0.32  , 0.3171, 0.3164, 0.3157, 0.313 , 0.3108, 0.3105, 0.3098,\n",
       "            0.3079, 0.307 , 0.306 , 0.304 , 0.3032, 0.302 , 0.3018, 0.3008,\n",
       "            0.297 , 0.2966, 0.2957, 0.2947, 0.2932, 0.2927, 0.2917, 0.2915,\n",
       "            0.2903, 0.2886, 0.286 , 0.2854, 0.283 , 0.2822, 0.2803, 0.279 ,\n",
       "            0.2776, 0.277 , 0.276 , 0.2754, 0.2744, 0.2742, 0.274 , 0.2715,\n",
       "            0.2695, 0.2693, 0.2683, 0.2664, 0.2656, 0.2646, 0.2642, 0.2637,\n",
       "            0.2634, 0.2625, 0.2583, 0.2563, 0.2556, 0.2551, 0.255 , 0.2532,\n",
       "            0.2502, 0.2496, 0.2477, 0.2474, 0.2467, 0.2466, 0.2463, 0.2452,\n",
       "            0.2444, 0.2428, 0.2424, 0.2418, 0.2415, 0.2405, 0.239 , 0.2383,\n",
       "            0.2363, 0.2335, 0.2334, 0.2332, 0.2328, 0.2306, 0.2302, 0.228 ,\n",
       "            0.2257, 0.2255, 0.2251, 0.224 , 0.2233, 0.2222, 0.2218, 0.2205,\n",
       "            0.2203, 0.2179, 0.2173, 0.2163, 0.2157, 0.2152, 0.2133, 0.2128,\n",
       "            0.2123, 0.2115, 0.211 , 0.2104, 0.2098, 0.2096, 0.2095, 0.208 ,\n",
       "            0.2069, 0.2064, 0.2053, 0.2045, 0.2039, 0.2029, 0.2026, 0.2024,\n",
       "            0.2021, 0.2009, 0.2006, 0.1993, 0.1991, 0.1964, 0.1962, 0.1948,\n",
       "            0.1929, 0.1913, 0.1896, 0.1885, 0.1873, 0.1871, 0.185 , 0.1835,\n",
       "            0.1829, 0.1826, 0.1824, 0.1823, 0.1819, 0.1803, 0.1797, 0.1763,\n",
       "            0.1757, 0.1744, 0.1736, 0.1731, 0.1719, 0.171 , 0.1686, 0.1685,\n",
       "            0.1658, 0.1656, 0.1619, 0.1611, 0.1583, 0.1482, 0.1464, 0.1453,\n",
       "            0.1448, 0.1414, 0.1312], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.6015625, 0.6015625, 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.6015625, 0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.6328125, 0.6328125, 0.6328125, 0.640625 , 0.640625 ,\n",
       "            0.6484375, 0.6484375, 0.6484375, 0.65625  , 0.6640625, 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6875   , 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.02459016,\n",
       "            0.03278688, 0.04098361, 0.04918033, 0.05737705, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.2704918 , 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.30327868, 0.3114754 ,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36065573, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6885246 , 0.6967213 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.72131145,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4177 , 0.4175 , 0.417  , 0.4136 , 0.413  , 0.4116 ,\n",
       "            0.4094 , 0.4087 , 0.4067 , 0.4058 , 0.4038 , 0.4036 , 0.4028 ,\n",
       "            0.4014 , 0.401  , 0.3992 , 0.399  , 0.3984 , 0.3982 , 0.3975 ,\n",
       "            0.3972 , 0.3958 , 0.3948 , 0.394  , 0.3938 , 0.3936 , 0.3926 ,\n",
       "            0.3904 , 0.3892 , 0.3884 , 0.3882 , 0.3853 , 0.3838 , 0.383  ,\n",
       "            0.3823 , 0.3813 , 0.3806 , 0.379  , 0.3782 , 0.3765 , 0.373  ,\n",
       "            0.372  , 0.3691 , 0.3667 , 0.3662 , 0.3645 , 0.3625 , 0.3608 ,\n",
       "            0.3499 , 0.3489 , 0.347  , 0.345  , 0.342  , 0.3386 , 0.3376 ,\n",
       "            0.334  , 0.3325 , 0.33   , 0.3296 , 0.323  , 0.316  , 0.3154 ,\n",
       "            0.3115 , 0.3079 , 0.302  , 0.3    , 0.296  , 0.2927 , 0.2908 ,\n",
       "            0.2864 , 0.2834 , 0.28   , 0.2795 , 0.2793 , 0.2788 , 0.2786 ,\n",
       "            0.2756 , 0.2751 , 0.273  , 0.2712 , 0.2703 , 0.2693 , 0.2664 ,\n",
       "            0.2659 , 0.2656 , 0.2654 , 0.2651 , 0.2646 , 0.2585 , 0.2583 ,\n",
       "            0.2573 , 0.257  , 0.2537 , 0.2534 , 0.253  , 0.251  , 0.2505 ,\n",
       "            0.249  , 0.2489 , 0.2487 , 0.2483 , 0.248  , 0.2463 , 0.2462 ,\n",
       "            0.2445 , 0.2411 , 0.2397 , 0.2372 , 0.2358 , 0.2352 , 0.235  ,\n",
       "            0.233  , 0.2328 , 0.2313 , 0.2306 , 0.2281 , 0.2278 , 0.2272 ,\n",
       "            0.2261 , 0.2251 , 0.2212 , 0.2205 , 0.219  , 0.2186 , 0.2166 ,\n",
       "            0.2148 , 0.214  , 0.212  , 0.2096 , 0.2094 , 0.2091 , 0.2086 ,\n",
       "            0.2081 , 0.2056 , 0.2048 , 0.2047 , 0.2034 , 0.202  , 0.2004 ,\n",
       "            0.2001 , 0.1998 , 0.1971 , 0.1964 , 0.1958 , 0.1953 , 0.1946 ,\n",
       "            0.1917 , 0.1915 , 0.1893 , 0.187  , 0.1869 , 0.1852 , 0.1849 ,\n",
       "            0.1848 , 0.1841 , 0.1821 , 0.1815 , 0.1812 , 0.181  , 0.1805 ,\n",
       "            0.1791 , 0.1787 , 0.1782 , 0.1771 , 0.1757 , 0.1749 , 0.1744 ,\n",
       "            0.1738 , 0.1721 , 0.1711 , 0.1709 , 0.1703 , 0.1697 , 0.169  ,\n",
       "            0.1677 , 0.1675 , 0.1666 , 0.1656 , 0.1652 , 0.1648 , 0.1644 ,\n",
       "            0.1641 , 0.1622 , 0.1615 , 0.161  , 0.1609 , 0.1603 , 0.1594 ,\n",
       "            0.1577 , 0.1572 , 0.1554 , 0.1545 , 0.1542 , 0.1538 , 0.1528 ,\n",
       "            0.1526 , 0.15   , 0.1488 , 0.1476 , 0.1469 , 0.1455 , 0.1439 ,\n",
       "            0.141  , 0.1406 , 0.1388 , 0.1376 , 0.1351 , 0.1349 , 0.1348 ,\n",
       "            0.1337 , 0.1335 , 0.1334 , 0.1318 , 0.1317 , 0.1305 , 0.129  ,\n",
       "            0.1263 , 0.12463, 0.1245 , 0.1235 , 0.12335, 0.1226 , 0.1214 ,\n",
       "            0.1178 , 0.1158 , 0.1124 , 0.11127, 0.1086 , 0.1063 , 0.10126,\n",
       "            0.0977 , 0.0967 , 0.0945 , 0.0898 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0703125, 0.078125 , 0.09375  , 0.1015625,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.578125 , 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.6171875, 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.640625 , 0.6484375, 0.6640625, 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.7109375, 0.7109375, 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.71311474, 0.72131145, 0.72131145,\n",
       "            0.73770493, 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.795082  , 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8770492 , 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3987 , 0.398  , 0.3962 , 0.3948 , 0.3945 , 0.393  ,\n",
       "            0.3892 , 0.3882 , 0.387  , 0.3845 , 0.382  , 0.381  , 0.3806 ,\n",
       "            0.3787 , 0.3784 , 0.3755 , 0.3752 , 0.374  , 0.3735 , 0.3733 ,\n",
       "            0.3718 , 0.3706 , 0.3696 , 0.369  , 0.3687 , 0.3667 , 0.3652 ,\n",
       "            0.363  , 0.3628 , 0.3623 , 0.3582 , 0.356  , 0.355  , 0.353  ,\n",
       "            0.3518 , 0.351  , 0.3496 , 0.3472 , 0.345  , 0.3433 , 0.3423 ,\n",
       "            0.3389 , 0.3357 , 0.3335 , 0.3313 , 0.3245 , 0.323  , 0.32   ,\n",
       "            0.3137 , 0.308  , 0.3074 , 0.3066 , 0.3044 , 0.3042 , 0.303  ,\n",
       "            0.3003 , 0.295  , 0.2878 , 0.2834 , 0.2793 , 0.2788 , 0.2747 ,\n",
       "            0.2634 , 0.263  , 0.2627 , 0.2605 , 0.258  , 0.2559 , 0.255  ,\n",
       "            0.2498 , 0.2462 , 0.2444 , 0.2426 , 0.2406 , 0.2405 , 0.2401 ,\n",
       "            0.2378 , 0.237  , 0.2332 , 0.2328 , 0.2322 , 0.2316 , 0.2302 ,\n",
       "            0.2285 , 0.2274 , 0.2234 , 0.2216 , 0.2191 , 0.2189 , 0.2177 ,\n",
       "            0.2175 , 0.2167 , 0.2166 , 0.2161 , 0.215  , 0.2134 , 0.2115 ,\n",
       "            0.2108 , 0.209  , 0.2089 , 0.2085 , 0.2084 , 0.208  , 0.2069 ,\n",
       "            0.2064 , 0.206  , 0.2053 , 0.2051 , 0.2042 , 0.2026 , 0.2018 ,\n",
       "            0.2017 , 0.1959 , 0.1952 , 0.1942 , 0.1937 , 0.1927 , 0.1923 ,\n",
       "            0.1913 , 0.1863 , 0.1855 , 0.1853 , 0.1838 , 0.1837 , 0.181  ,\n",
       "            0.1808 , 0.1798 , 0.1796 , 0.1791 , 0.1788 , 0.1787 , 0.1766 ,\n",
       "            0.1764 , 0.1757 , 0.1748 , 0.1716 , 0.1709 , 0.1705 , 0.1699 ,\n",
       "            0.1676 , 0.1672 , 0.1643 , 0.1627 , 0.1616 , 0.1615 , 0.1614 ,\n",
       "            0.1598 , 0.1569 , 0.153  , 0.152  , 0.1511 , 0.1504 , 0.1501 ,\n",
       "            0.1498 , 0.1494 , 0.1477 , 0.1473 , 0.1461 , 0.1456 , 0.1453 ,\n",
       "            0.145  , 0.1427 , 0.1411 , 0.1409 , 0.1395 , 0.1394 , 0.1393 ,\n",
       "            0.139  , 0.1389 , 0.1377 , 0.1376 , 0.135  , 0.1349 , 0.1318 ,\n",
       "            0.1312 , 0.1309 , 0.1298 , 0.1278 , 0.1277 , 0.1274 , 0.1238 ,\n",
       "            0.12317, 0.12305, 0.1226 , 0.1214 , 0.12024, 0.119  , 0.1172 ,\n",
       "            0.11536, 0.1152 , 0.1142 , 0.1128 , 0.1122 , 0.1118 , 0.111  ,\n",
       "            0.1095 , 0.10895, 0.1076 , 0.1054 , 0.10486, 0.1032 , 0.1021 ,\n",
       "            0.1011 , 0.09875, 0.09753, 0.09686, 0.09656, 0.0964 , 0.096  ,\n",
       "            0.0955 , 0.09515, 0.09485, 0.0927 , 0.0914 , 0.0901 , 0.0899 ,\n",
       "            0.088  , 0.0873 , 0.0868 , 0.0862 , 0.0836 , 0.0804 , 0.0786 ,\n",
       "            0.0761 , 0.07544, 0.075  , 0.0729 , 0.0689 , 0.0643 , 0.06323,\n",
       "            0.06165, 0.06064], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.421875 , 0.4296875,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.6171875,\n",
       "            0.6171875, 0.625    , 0.640625 , 0.640625 , 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.671875 , 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.02459016, 0.02459016, 0.02459016, 0.03278688,\n",
       "            0.03278688, 0.03278688, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5081967 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59836066, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.63114756, 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.377  , 0.3765 , 0.376  , 0.3743 , 0.3735 , 0.3706 ,\n",
       "            0.3665 , 0.3662 , 0.3643 , 0.3638 , 0.361  , 0.3606 , 0.3584 ,\n",
       "            0.3582 , 0.358  , 0.3564 , 0.3542 , 0.353  , 0.352  , 0.3513 ,\n",
       "            0.351  , 0.3508 , 0.3481 , 0.348  , 0.3474 , 0.3464 , 0.3462 ,\n",
       "            0.34   , 0.3398 , 0.3396 , 0.3386 , 0.3384 , 0.3337 , 0.333  ,\n",
       "            0.3313 , 0.3308 , 0.3267 , 0.3254 , 0.325  , 0.3228 , 0.322  ,\n",
       "            0.3208 , 0.3193 , 0.3154 , 0.3135 , 0.313  , 0.311  , 0.3076 ,\n",
       "            0.306  , 0.2964 , 0.2944 , 0.2905 , 0.29   , 0.2852 , 0.2847 ,\n",
       "            0.2832 , 0.2808 , 0.2805 , 0.2793 , 0.2703 , 0.2664 , 0.2617 ,\n",
       "            0.258  , 0.2566 , 0.2527 , 0.2487 , 0.241  , 0.2402 , 0.2372 ,\n",
       "            0.2368 , 0.2351 , 0.2338 , 0.2319 , 0.2307 , 0.2306 , 0.228  ,\n",
       "            0.2261 , 0.2195 , 0.2186 , 0.2152 , 0.2148 , 0.2147 , 0.2128 ,\n",
       "            0.2124 , 0.2073 , 0.2069 , 0.2064 , 0.206  , 0.2054 , 0.2045 ,\n",
       "            0.2034 , 0.2024 , 0.1991 , 0.1974 , 0.1973 , 0.1971 , 0.1956 ,\n",
       "            0.1948 , 0.1941 , 0.1927 , 0.1917 , 0.1915 , 0.1907 , 0.1898 ,\n",
       "            0.1891 , 0.1882 , 0.1869 , 0.1843 , 0.1842 , 0.183  , 0.1829 ,\n",
       "            0.182  , 0.1807 , 0.1798 , 0.1779 , 0.1774 , 0.1746 , 0.1716 ,\n",
       "            0.1705 , 0.1703 , 0.17   , 0.1693 , 0.1688 , 0.1685 , 0.1678 ,\n",
       "            0.1674 , 0.1659 , 0.1658 , 0.1649 , 0.1611 , 0.1606 , 0.1593 ,\n",
       "            0.1575 , 0.1564 , 0.1559 , 0.1545 , 0.1534 , 0.1476 , 0.1471 ,\n",
       "            0.1453 , 0.1434 , 0.1422 , 0.1417 , 0.1416 , 0.1415 , 0.1409 ,\n",
       "            0.1389 , 0.1388 , 0.1384 , 0.138  , 0.1372 , 0.1348 , 0.1344 ,\n",
       "            0.1328 , 0.1317 , 0.13   , 0.1299 , 0.1282 , 0.1271 , 0.126  ,\n",
       "            0.1259 , 0.1245 , 0.1238 , 0.12366, 0.12317, 0.12115, 0.121  ,\n",
       "            0.1198 , 0.1194 , 0.1178 , 0.11755, 0.11615, 0.1158 , 0.11456,\n",
       "            0.1142 , 0.1122 , 0.11127, 0.111  , 0.1084 , 0.108  , 0.1069 ,\n",
       "            0.1063 , 0.1041 , 0.1032 , 0.103  , 0.1025 , 0.1023 , 0.1019 ,\n",
       "            0.10156, 0.0986 , 0.09845, 0.09753, 0.09485, 0.09436, 0.09283,\n",
       "            0.0927 , 0.0925 , 0.0901 , 0.0899 , 0.0883 , 0.0876 , 0.0869 ,\n",
       "            0.08466, 0.08386, 0.08374, 0.08124, 0.08093, 0.0806 , 0.0802 ,\n",
       "            0.0801 , 0.0789 , 0.07837, 0.07764, 0.0774 , 0.07544, 0.075  ,\n",
       "            0.07477, 0.0729 , 0.07056, 0.06995, 0.06964, 0.0672 , 0.065  ,\n",
       "            0.0643 , 0.06305, 0.06064, 0.0602 , 0.05823, 0.05676, 0.0504 ,\n",
       "            0.05032, 0.04977, 0.04822], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.40625  , 0.4140625, 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.46875  ,\n",
       "            0.4765625, 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   , 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.640625 , 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.78125  , 0.7890625, 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.03278688, 0.03278688, 0.03278688,\n",
       "            0.03278688, 0.04098361, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.37704918, 0.3852459 ,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.4262295 , 0.43442622, 0.44262296, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.72131145, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.36   , 0.3586 , 0.3567 , 0.3562 , 0.355  , 0.3547 ,\n",
       "            0.3533 , 0.3484 , 0.348  , 0.3472 , 0.3457 , 0.3433 , 0.3423 ,\n",
       "            0.342  , 0.34   , 0.3389 , 0.3386 , 0.3381 , 0.3362 , 0.3354 ,\n",
       "            0.3335 , 0.333  , 0.3323 , 0.3298 , 0.329  , 0.3271 , 0.3257 ,\n",
       "            0.3237 , 0.3218 , 0.3215 , 0.3198 , 0.3193 , 0.3184 , 0.3179 ,\n",
       "            0.3137 , 0.3132 , 0.3115 , 0.3108 , 0.308  , 0.3079 , 0.3074 ,\n",
       "            0.3054 , 0.304  , 0.3025 , 0.2988 , 0.2952 , 0.2915 , 0.2905 ,\n",
       "            0.2825 , 0.2795 , 0.2786 , 0.2783 , 0.278  , 0.2734 , 0.2732 ,\n",
       "            0.269  , 0.2646 , 0.2642 , 0.2617 , 0.2588 , 0.2534 , 0.2507 ,\n",
       "            0.2458 , 0.2415 , 0.2391 , 0.2355 , 0.2343 , 0.231  , 0.2301 ,\n",
       "            0.2283 , 0.2264 , 0.2257 , 0.2234 , 0.2217 , 0.2166 , 0.2144 ,\n",
       "            0.2118 , 0.2103 , 0.2074 , 0.2069 , 0.205  , 0.2048 , 0.2035 ,\n",
       "            0.2007 , 0.2004 , 0.1996 , 0.1993 , 0.1989 , 0.1981 , 0.1965 ,\n",
       "            0.1964 , 0.1956 , 0.1943 , 0.1923 , 0.1919 , 0.1904 , 0.1887 ,\n",
       "            0.1886 , 0.1885 , 0.1865 , 0.1859 , 0.1853 , 0.1838 , 0.1823 ,\n",
       "            0.1819 , 0.1807 , 0.18   , 0.1792 , 0.1781 , 0.1774 , 0.1755 ,\n",
       "            0.1747 , 0.1744 , 0.174  , 0.1737 , 0.1724 , 0.1716 , 0.1707 ,\n",
       "            0.1687 , 0.1675 , 0.1671 , 0.1664 , 0.1659 , 0.165  , 0.1648 ,\n",
       "            0.1643 , 0.1641 , 0.162  , 0.1617 , 0.1616 , 0.1586 , 0.1569 ,\n",
       "            0.155  , 0.1536 , 0.153  , 0.1525 , 0.1523 , 0.1516 , 0.1478 ,\n",
       "            0.1431 , 0.1425 , 0.1422 , 0.1416 , 0.1415 , 0.1411 , 0.1409 ,\n",
       "            0.1375 , 0.1371 , 0.1367 , 0.1349 , 0.1348 , 0.1346 , 0.1338 ,\n",
       "            0.1324 , 0.1323 , 0.1309 , 0.1295 , 0.1277 , 0.1263 , 0.1254 ,\n",
       "            0.1242 , 0.1239 , 0.12274, 0.1225 , 0.1216 , 0.12085, 0.1197 ,\n",
       "            0.119  , 0.1188 , 0.118  , 0.1172 , 0.11633, 0.11395, 0.1126 ,\n",
       "            0.11066, 0.1105 , 0.1099 , 0.10913, 0.108  , 0.1052 , 0.10394,\n",
       "            0.1034 , 0.103  , 0.10175, 0.10156, 0.1    , 0.0995 , 0.09875,\n",
       "            0.0986 , 0.09845, 0.0981 , 0.09753, 0.09534, 0.09503, 0.0932 ,\n",
       "            0.093  , 0.09155, 0.0888 , 0.0887 , 0.0883 , 0.0866 , 0.086  ,\n",
       "            0.0859 , 0.08435, 0.0831 , 0.0806 , 0.0804 , 0.0798 , 0.0786 ,\n",
       "            0.07764, 0.0774 , 0.07654, 0.07574, 0.0753 , 0.07465, 0.0745 ,\n",
       "            0.0742 , 0.0732 , 0.0729 , 0.0716 , 0.06964, 0.06805, 0.06696,\n",
       "            0.0666 , 0.0643 , 0.0631 , 0.06232, 0.0603 , 0.058  , 0.0577 ,\n",
       "            0.05582, 0.0551 , 0.04932, 0.04822, 0.0477 , 0.0461 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.140625 , 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125,\n",
       "            0.265625 , 0.28125  , 0.2890625, 0.296875 , 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.3515625, 0.359375 , 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.3984375, 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5703125, 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.03278688, 0.03278688, 0.03278688, 0.03278688, 0.04098361,\n",
       "            0.04098361, 0.04098361, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.44262296, 0.45081967, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.347  , 0.344  , 0.3438 , 0.341  , 0.3367 , 0.3357 ,\n",
       "            0.3352 , 0.3347 , 0.3342 , 0.3337 , 0.3335 , 0.3318 , 0.3313 ,\n",
       "            0.3289 , 0.328  , 0.3274 , 0.3271 , 0.3264 , 0.3257 , 0.325  ,\n",
       "            0.3215 , 0.3213 , 0.3196 , 0.3188 , 0.3186 , 0.317  , 0.3164 ,\n",
       "            0.3162 , 0.3157 , 0.3154 , 0.313  , 0.31   , 0.3093 , 0.3074 ,\n",
       "            0.307  , 0.3064 , 0.3057 , 0.304  , 0.3032 , 0.2998 , 0.2954 ,\n",
       "            0.2947 , 0.2888 , 0.2886 , 0.2861 , 0.2805 , 0.279  , 0.2761 ,\n",
       "            0.2744 , 0.2725 , 0.2715 , 0.2693 , 0.2627 , 0.2625 , 0.261  ,\n",
       "            0.2593 , 0.2556 , 0.2483 , 0.247  , 0.2466 , 0.2455 , 0.244  ,\n",
       "            0.2433 , 0.2421 , 0.2375 , 0.2366 , 0.2356 , 0.2334 , 0.2332 ,\n",
       "            0.2286 , 0.2272 , 0.2251 , 0.223  , 0.2218 , 0.2194 , 0.2191 ,\n",
       "            0.2175 , 0.2173 , 0.2157 , 0.2139 , 0.2134 , 0.2129 , 0.2125 ,\n",
       "            0.2118 , 0.2109 , 0.2106 , 0.2096 , 0.2084 , 0.2079 , 0.207  ,\n",
       "            0.2069 , 0.2048 , 0.2034 , 0.2031 , 0.2018 , 0.2002 , 0.1996 ,\n",
       "            0.1982 , 0.1978 , 0.1976 , 0.1962 , 0.195  , 0.1946 , 0.1943 ,\n",
       "            0.1941 , 0.1934 , 0.1931 , 0.1904 , 0.1898 , 0.189  , 0.1873 ,\n",
       "            0.1871 , 0.1866 , 0.1859 , 0.1858 , 0.185  , 0.1846 , 0.1835 ,\n",
       "            0.183  , 0.1824 , 0.1813 , 0.1798 , 0.1785 , 0.1783 , 0.1774 ,\n",
       "            0.1764 , 0.1757 , 0.1737 , 0.1736 , 0.1735 , 0.1703 , 0.1694 ,\n",
       "            0.1687 , 0.1661 , 0.1659 , 0.1649 , 0.1638 , 0.1608 , 0.1597 ,\n",
       "            0.159  , 0.1584 , 0.158  , 0.1573 , 0.1566 , 0.1559 , 0.1536 ,\n",
       "            0.1525 , 0.1516 , 0.1515 , 0.1499 , 0.1494 , 0.1493 , 0.1492 ,\n",
       "            0.147  , 0.146  , 0.1455 , 0.1453 , 0.1418 , 0.1409 , 0.14   ,\n",
       "            0.139  , 0.1375 , 0.1372 , 0.1371 , 0.1362 , 0.1354 , 0.1338 ,\n",
       "            0.1337 , 0.1335 , 0.1322 , 0.131  , 0.1305 , 0.1278 , 0.1259 ,\n",
       "            0.1254 , 0.1249 , 0.1242 , 0.12335, 0.12305, 0.12274, 0.12244,\n",
       "            0.1201 , 0.1198 , 0.11676, 0.11597, 0.11456, 0.1142 , 0.1138 ,\n",
       "            0.1122 , 0.11163, 0.11145, 0.111  , 0.1101 , 0.10895, 0.10876,\n",
       "            0.1084 , 0.10596, 0.1047 , 0.10175, 0.10144, 0.1011 , 0.1009 ,\n",
       "            0.0997 , 0.09827, 0.09656, 0.0957 , 0.09467, 0.0933 , 0.093  ,\n",
       "            0.09283, 0.09174, 0.0904 , 0.0901 , 0.0891 , 0.0888 , 0.088  ,\n",
       "            0.0876 , 0.0873 , 0.0865 , 0.0859 , 0.0836 , 0.08167, 0.0802 ,\n",
       "            0.0788 , 0.07837, 0.07587, 0.0741 , 0.0717 , 0.06915, 0.06903,\n",
       "            0.06696, 0.0667 , 0.06064, 0.05878, 0.05814, 0.05646],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.015625 , 0.0234375, 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.1640625, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.3515625, 0.359375 , 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.46875  , 0.4765625, 0.4765625, 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5703125, 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.59375  , 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.6171875, 0.625    , 0.625    , 0.6328125,\n",
       "            0.640625 , 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.7890625, 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.03278688, 0.03278688, 0.03278688,\n",
       "            0.03278688, 0.04098361, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.05737705, 0.06557377, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.46721312, 0.48360655, 0.4918033 , 0.4918033 ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3372 , 0.3328 , 0.332  , 0.3298 , 0.3286 , 0.3274 ,\n",
       "            0.3252 , 0.3245 , 0.3242 , 0.3237 , 0.3225 , 0.3223 , 0.3213 ,\n",
       "            0.3206 , 0.32   , 0.3198 , 0.319  , 0.3186 , 0.3184 , 0.3179 ,\n",
       "            0.3174 , 0.315  , 0.3147 , 0.3135 , 0.3125 , 0.3115 , 0.3113 ,\n",
       "            0.3108 , 0.3096 , 0.3093 , 0.309  , 0.3083 , 0.3064 , 0.3062 ,\n",
       "            0.304  , 0.301  , 0.3    , 0.2996 , 0.2983 , 0.2974 , 0.2969 ,\n",
       "            0.2927 , 0.2925 , 0.292  , 0.2903 , 0.2888 , 0.2856 , 0.2852 ,\n",
       "            0.2817 , 0.2786 , 0.2722 , 0.2715 , 0.2664 , 0.266  , 0.265  ,\n",
       "            0.2637 , 0.263  , 0.2605 , 0.2595 , 0.259  , 0.258  , 0.2573 ,\n",
       "            0.255  , 0.2534 , 0.2505 , 0.2462 , 0.246  , 0.2452 , 0.2417 ,\n",
       "            0.2413 , 0.2399 , 0.239  , 0.2388 , 0.2382 , 0.2343 , 0.234  ,\n",
       "            0.2338 , 0.233  , 0.2328 , 0.2323 , 0.231  , 0.2301 , 0.2289 ,\n",
       "            0.2283 , 0.2278 , 0.2273 , 0.2263 , 0.2255 , 0.2244 , 0.2234 ,\n",
       "            0.2233 , 0.2222 , 0.22   , 0.2194 , 0.2173 , 0.2161 , 0.2153 ,\n",
       "            0.2145 , 0.2139 , 0.213  , 0.2128 , 0.2114 , 0.2113 , 0.211  ,\n",
       "            0.2098 , 0.2073 , 0.207  , 0.2069 , 0.2065 , 0.2051 , 0.205  ,\n",
       "            0.2047 , 0.2045 , 0.2042 , 0.2031 , 0.2018 , 0.2012 , 0.1998 ,\n",
       "            0.1995 , 0.1974 , 0.197  , 0.1964 , 0.1952 , 0.195  , 0.1921 ,\n",
       "            0.1917 , 0.189  , 0.1873 , 0.1869 , 0.1827 , 0.1819 , 0.1815 ,\n",
       "            0.181  , 0.1805 , 0.1803 , 0.1798 , 0.179  , 0.1781 , 0.1776 ,\n",
       "            0.1758 , 0.1743 , 0.173  , 0.1725 , 0.1721 , 0.1707 , 0.1683 ,\n",
       "            0.1678 , 0.167  , 0.1666 , 0.1653 , 0.1637 , 0.1622 , 0.1608 ,\n",
       "            0.1598 , 0.1597 , 0.1594 , 0.158  , 0.1565 , 0.1564 , 0.1561 ,\n",
       "            0.1549 , 0.1543 , 0.1527 , 0.1525 , 0.1495 , 0.1493 , 0.1484 ,\n",
       "            0.145  , 0.1447 , 0.1439 , 0.1426 , 0.1423 , 0.1422 , 0.142  ,\n",
       "            0.1371 , 0.1361 , 0.1351 , 0.1344 , 0.1338 , 0.1333 , 0.1329 ,\n",
       "            0.1322 , 0.1315 , 0.1313 , 0.13   , 0.1292 , 0.1289 , 0.1284 ,\n",
       "            0.1251 , 0.12445, 0.1235 , 0.12103, 0.12054, 0.1198 , 0.1192 ,\n",
       "            0.1172 , 0.11554, 0.11475, 0.1126 , 0.1118 , 0.11145, 0.11127,\n",
       "            0.1097 , 0.1095 , 0.1076 , 0.1069 , 0.1065 , 0.1063 , 0.1054 ,\n",
       "            0.10504, 0.1019 , 0.1    , 0.09894, 0.09686, 0.0967 , 0.09515,\n",
       "            0.0939 , 0.0922 , 0.0893 , 0.0866 , 0.0845 , 0.08435, 0.07806,\n",
       "            0.07544, 0.07465, 0.0729 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.015625 , 0.0234375, 0.03125  , 0.046875 , 0.0546875,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.15625  , 0.1640625, 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.2109375, 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.2734375, 0.28125  , 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.296875 , 0.3046875, 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.375    , 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.453125 , 0.453125 , 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.46875  , 0.46875  , 0.4765625, 0.4765625,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5      ,\n",
       "            0.5      , 0.5      , 0.5      , 0.5      , 0.5      , 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.703125 , 0.7109375, 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.04098361, 0.04918033, 0.04918033,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.06557377, 0.07377049,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09016393, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.14754099, 0.1557377 , 0.18032786, 0.18852459, 0.20491803,\n",
       "            0.21311475, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.56557375, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.795082  , 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.93442625, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3333 , 0.331  , 0.329  , 0.3289 , 0.3286 , 0.3235 ,\n",
       "            0.3232 , 0.323  , 0.322  , 0.3213 , 0.3206 , 0.32   , 0.319  ,\n",
       "            0.3186 , 0.3184 , 0.318  , 0.3179 , 0.3171 , 0.317  , 0.3162 ,\n",
       "            0.3154 , 0.3152 , 0.315  , 0.3147 , 0.3137 , 0.3132 , 0.3127 ,\n",
       "            0.3125 , 0.312  , 0.3115 , 0.311  , 0.3108 , 0.31   , 0.3096 ,\n",
       "            0.3088 , 0.3076 , 0.3057 , 0.303  , 0.3022 , 0.3008 , 0.3005 ,\n",
       "            0.2996 , 0.2993 , 0.2966 , 0.2957 , 0.2935 , 0.2903 , 0.2874 ,\n",
       "            0.2847 , 0.2817 , 0.2808 , 0.2803 , 0.2773 , 0.276  , 0.2751 ,\n",
       "            0.275  , 0.2737 , 0.2732 , 0.2717 , 0.2712 , 0.2705 , 0.27   ,\n",
       "            0.2668 , 0.2656 , 0.2654 , 0.2632 , 0.2617 , 0.2615 , 0.259  ,\n",
       "            0.258  , 0.2566 , 0.2556 , 0.255  , 0.2534 , 0.2522 , 0.2517 ,\n",
       "            0.2512 , 0.25   , 0.2498 , 0.2485 , 0.2473 , 0.2444 , 0.2437 ,\n",
       "            0.2434 , 0.2428 , 0.2415 , 0.2405 , 0.2388 , 0.2384 , 0.2378 ,\n",
       "            0.237  , 0.2355 , 0.2352 , 0.2346 , 0.2344 , 0.2339 , 0.2338 ,\n",
       "            0.2328 , 0.2323 , 0.2318 , 0.2314 , 0.2313 , 0.2299 , 0.2294 ,\n",
       "            0.2286 , 0.2278 , 0.2273 , 0.2264 , 0.2261 , 0.226  , 0.2247 ,\n",
       "            0.2246 , 0.223  , 0.2229 , 0.2224 , 0.2202 , 0.2179 , 0.2162 ,\n",
       "            0.2161 , 0.2158 , 0.2142 , 0.214  , 0.2135 , 0.2125 , 0.2124 ,\n",
       "            0.2063 , 0.2056 , 0.2042 , 0.2037 , 0.2035 , 0.2031 , 0.2029 ,\n",
       "            0.2023 , 0.202  , 0.2015 , 0.1991 , 0.1984 , 0.1973 , 0.197  ,\n",
       "            0.1967 , 0.1958 , 0.1946 , 0.1936 , 0.1906 , 0.1898 , 0.1887 ,\n",
       "            0.1886 , 0.1874 , 0.185  , 0.1842 , 0.1838 , 0.182  , 0.181  ,\n",
       "            0.1807 , 0.1792 , 0.1791 , 0.179  , 0.1785 , 0.1768 , 0.1766 ,\n",
       "            0.1759 , 0.1758 , 0.173  , 0.17   , 0.1699 , 0.1698 , 0.1661 ,\n",
       "            0.1646 , 0.1641 , 0.1635 , 0.1631 , 0.163  , 0.1626 , 0.1589 ,\n",
       "            0.1578 , 0.1559 , 0.1544 , 0.1539 , 0.153  , 0.1521 , 0.152  ,\n",
       "            0.1508 , 0.15   , 0.1495 , 0.149  , 0.1473 , 0.146  , 0.1458 ,\n",
       "            0.1414 , 0.141  , 0.1404 , 0.1403 , 0.1381 , 0.136  , 0.1351 ,\n",
       "            0.1334 , 0.1329 , 0.1322 , 0.1315 , 0.13   , 0.1299 , 0.1287 ,\n",
       "            0.1283 , 0.1279 , 0.1256 , 0.1251 , 0.1222 , 0.1201 , 0.12   ,\n",
       "            0.1172 , 0.11676, 0.115  , 0.1136 , 0.11163, 0.10895, 0.1063 ,\n",
       "            0.10596, 0.10376, 0.1034 , 0.09686, 0.09436, 0.093  , 0.09174],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.0234375, 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875,\n",
       "            0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.2578125, 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.3359375, 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.3828125, 0.390625 , 0.3984375, 0.3984375, 0.40625  ,\n",
       "            0.421875 , 0.4375   , 0.4375   , 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.4765625, 0.484375 , 0.484375 , 0.484375 , 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 ,\n",
       "            0.4921875, 0.4921875, 0.4921875, 0.5      , 0.5      , 0.5      ,\n",
       "            0.5      , 0.5      , 0.5      , 0.5      , 0.5      , 0.5      ,\n",
       "            0.5      , 0.5      , 0.5      , 0.5      , 0.5      , 0.5      ,\n",
       "            0.5      , 0.5      , 0.5      , 0.5      , 0.5      , 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.609375 , 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.03278688, 0.04098361, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09016393, 0.09016393, 0.09016393,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.24590164, 0.25409836, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.45901638, 0.47540984, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.852459  , 0.8606557 , 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3323 , 0.331  , 0.3276 , 0.3264 , 0.325  , 0.3245 ,\n",
       "            0.3242 , 0.3235 , 0.3215 , 0.3213 , 0.3203 , 0.3196 , 0.3188 ,\n",
       "            0.3179 , 0.3176 , 0.317  , 0.3167 , 0.3164 , 0.315  , 0.3147 ,\n",
       "            0.3142 , 0.314  , 0.3137 , 0.313  , 0.3108 , 0.31   , 0.3098 ,\n",
       "            0.3096 , 0.309  , 0.3083 , 0.3079 , 0.3076 , 0.3066 , 0.3064 ,\n",
       "            0.306  , 0.3057 , 0.3054 , 0.304  , 0.3037 , 0.302  , 0.3008 ,\n",
       "            0.3005 , 0.2974 , 0.297  , 0.2942 , 0.2937 , 0.2925 , 0.292  ,\n",
       "            0.2903 , 0.2888 , 0.2876 , 0.287  , 0.2869 , 0.2852 , 0.285  ,\n",
       "            0.2837 , 0.2832 , 0.2808 , 0.2803 , 0.2795 , 0.279  , 0.2783 ,\n",
       "            0.2761 , 0.2751 , 0.2747 , 0.2734 , 0.2727 , 0.2722 , 0.272  ,\n",
       "            0.2717 , 0.271  , 0.2708 , 0.27   , 0.2695 , 0.269  , 0.2678 ,\n",
       "            0.2673 , 0.2668 , 0.2651 , 0.2644 , 0.2637 , 0.26   , 0.258  ,\n",
       "            0.2578 , 0.257  , 0.2568 , 0.2563 , 0.256  , 0.2559 , 0.2544 ,\n",
       "            0.2534 , 0.2532 , 0.2527 , 0.252  , 0.2515 , 0.251  , 0.2502 ,\n",
       "            0.2496 , 0.248  , 0.2478 , 0.2471 , 0.2467 , 0.2466 , 0.246  ,\n",
       "            0.2455 , 0.2452 , 0.2444 , 0.2438 , 0.2437 , 0.243  , 0.2424 ,\n",
       "            0.2417 , 0.2382 , 0.2378 , 0.2368 , 0.2366 , 0.2356 , 0.2346 ,\n",
       "            0.2344 , 0.2343 , 0.2335 , 0.2327 , 0.2318 , 0.2314 , 0.2302 ,\n",
       "            0.2283 , 0.2268 , 0.2252 , 0.2246 , 0.2238 , 0.223  , 0.2229 ,\n",
       "            0.2213 , 0.2194 , 0.219  , 0.2185 , 0.2184 , 0.2181 , 0.2175 ,\n",
       "            0.2167 , 0.2163 , 0.2157 , 0.2148 , 0.2119 , 0.2118 , 0.2091 ,\n",
       "            0.2081 , 0.206  , 0.2059 , 0.2054 , 0.205  , 0.2047 , 0.2035 ,\n",
       "            0.2018 , 0.2007 , 0.1987 , 0.196  , 0.195  , 0.1946 , 0.1943 ,\n",
       "            0.194  , 0.1936 , 0.1925 , 0.1915 , 0.1877 , 0.1874 , 0.1858 ,\n",
       "            0.1846 , 0.1808 , 0.1807 , 0.1805 , 0.1785 , 0.1766 , 0.1738 ,\n",
       "            0.1736 , 0.1731 , 0.1724 , 0.172  , 0.1715 , 0.1709 , 0.1693 ,\n",
       "            0.1685 , 0.1683 , 0.1678 , 0.1677 , 0.1675 , 0.1638 , 0.1611 ,\n",
       "            0.1599 , 0.1593 , 0.1587 , 0.1569 , 0.1548 , 0.1536 , 0.153  ,\n",
       "            0.1516 , 0.1508 , 0.1506 , 0.149  , 0.1489 , 0.1486 , 0.1478 ,\n",
       "            0.1475 , 0.145  , 0.1444 , 0.1438 , 0.1411 , 0.14   , 0.1385 ,\n",
       "            0.1362 , 0.1354 , 0.135  , 0.1321 , 0.1302 , 0.1273 , 0.1251 ,\n",
       "            0.1243 , 0.1226 , 0.12177, 0.1158 , 0.113  , 0.11127, 0.1103 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.0390625, 0.046875 , 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.2109375, 0.21875  , 0.21875  , 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.265625 , 0.2734375, 0.2890625, 0.296875 , 0.296875 , 0.296875 ,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.359375 , 0.359375 , 0.3828125, 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.3984375, 0.3984375, 0.3984375, 0.40625  , 0.4296875, 0.4296875,\n",
       "            0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.453125 , 0.453125 ,\n",
       "            0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.453125 ,\n",
       "            0.453125 , 0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.46875  , 0.46875  , 0.46875  , 0.46875  , 0.46875  ,\n",
       "            0.46875  , 0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.4921875,\n",
       "            0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.4921875,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.59375  , 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.03278688, 0.03278688, 0.04098361, 0.04098361, 0.04098361,\n",
       "            0.04098361, 0.04098361, 0.04098361, 0.04098361, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.07377049,\n",
       "            0.08196721, 0.08196721, 0.08196721, 0.08196721, 0.09836066,\n",
       "            0.09836066, 0.10655738, 0.12295082, 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.17213115, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22131148, 0.22950819, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.30327868, 0.3114754 , 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.44262296, 0.44262296,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6639344 , 0.6721311 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90983605, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.341 , 0.338 , 0.337 , 0.3367, 0.336 , 0.3354, 0.333 ,\n",
       "            0.3325, 0.3318, 0.3315, 0.3313, 0.3289, 0.3286, 0.3264, 0.3262,\n",
       "            0.3257, 0.3254, 0.3242, 0.323 , 0.322 , 0.321 , 0.3206, 0.32  ,\n",
       "            0.3196, 0.3186, 0.3179, 0.3162, 0.3154, 0.3152, 0.3147, 0.3142,\n",
       "            0.3132, 0.3123, 0.3115, 0.3108, 0.31  , 0.3093, 0.3083, 0.3076,\n",
       "            0.3074, 0.3071, 0.307 , 0.3066, 0.3062, 0.306 , 0.3047, 0.3042,\n",
       "            0.3022, 0.302 , 0.3018, 0.3015, 0.301 , 0.3008, 0.3003, 0.2998,\n",
       "            0.2996, 0.2993, 0.2986, 0.2983, 0.298 , 0.2976, 0.2974, 0.2961,\n",
       "            0.296 , 0.2957, 0.2952, 0.2937, 0.2932, 0.2915, 0.291 , 0.2908,\n",
       "            0.2898, 0.2888, 0.2886, 0.2878, 0.2874, 0.2864, 0.2852, 0.2844,\n",
       "            0.2825, 0.282 , 0.2815, 0.2808, 0.2805, 0.2803, 0.2795, 0.279 ,\n",
       "            0.2788, 0.2783, 0.278 , 0.2766, 0.2756, 0.2747, 0.2744, 0.2742,\n",
       "            0.274 , 0.2734, 0.2727, 0.2725, 0.2722, 0.272 , 0.2717, 0.271 ,\n",
       "            0.2703, 0.2698, 0.269 , 0.2686, 0.2676, 0.2664, 0.266 , 0.2654,\n",
       "            0.265 , 0.2642, 0.2632, 0.263 , 0.2615, 0.2612, 0.261 , 0.2607,\n",
       "            0.2595, 0.2588, 0.2583, 0.2573, 0.255 , 0.2542, 0.2532, 0.2524,\n",
       "            0.252 , 0.25  , 0.248 , 0.2473, 0.2466, 0.2455, 0.2451, 0.2448,\n",
       "            0.2441, 0.2438, 0.2437, 0.2417, 0.2413, 0.2406, 0.2383, 0.2375,\n",
       "            0.2362, 0.2355, 0.2351, 0.2335, 0.2334, 0.2332, 0.2327, 0.2322,\n",
       "            0.2306, 0.2263, 0.2261, 0.2247, 0.2238, 0.2235, 0.2224, 0.2216,\n",
       "            0.2198, 0.2173, 0.2161, 0.2137, 0.213 , 0.2129, 0.2124, 0.2076,\n",
       "            0.2074, 0.2073, 0.2042, 0.2029, 0.2009, 0.1993, 0.199 , 0.1987,\n",
       "            0.1985, 0.197 , 0.196 , 0.1956, 0.191 , 0.1906, 0.1873, 0.1866,\n",
       "            0.186 , 0.185 , 0.1829, 0.182 , 0.1812, 0.1796, 0.1788, 0.1783,\n",
       "            0.1782, 0.177 , 0.1766, 0.1764, 0.1735, 0.1726, 0.1714, 0.1696,\n",
       "            0.1694, 0.1663, 0.1649, 0.1637, 0.1631, 0.1599, 0.158 , 0.1549,\n",
       "            0.1533, 0.1519, 0.1506, 0.1494, 0.1438, 0.1411, 0.1385, 0.1382],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.0390625, 0.046875 , 0.0546875, 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.09375  , 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1484375, 0.1640625, 0.1640625, 0.171875 , 0.171875 , 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1875   , 0.1953125, 0.1953125, 0.203125 ,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.21875  , 0.21875  , 0.21875  ,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.234375 , 0.234375 , 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.265625 , 0.265625 , 0.2734375, 0.2734375, 0.28125  , 0.28125  ,\n",
       "            0.28125  , 0.296875 , 0.3046875, 0.3046875, 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.328125 , 0.3359375, 0.3359375, 0.3515625,\n",
       "            0.359375 , 0.359375 , 0.375    , 0.375    , 0.390625 , 0.390625 ,\n",
       "            0.390625 , 0.40625  , 0.40625  , 0.40625  , 0.40625  , 0.4140625,\n",
       "            0.4140625, 0.4140625, 0.421875 , 0.421875 , 0.421875 , 0.421875 ,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.4765625, 0.4765625, 0.484375 ,\n",
       "            0.484375 , 0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.4921875,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   , 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.04098361, 0.04098361, 0.04098361,\n",
       "            0.04098361, 0.04098361, 0.04098361, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.12295082, 0.12295082, 0.13934426, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.16393442, 0.16393442, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.26229507, 0.26229507, 0.26229507, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.32786885, 0.33606556, 0.3442623 , 0.36065573,\n",
       "            0.36885247, 0.36885247, 0.36885247, 0.37704918, 0.37704918,\n",
       "            0.3852459 , 0.3852459 , 0.3852459 , 0.40163934, 0.40163934,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.58196723, 0.59016395, 0.60655737, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.7295082 , 0.73770493,\n",
       "            0.73770493, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8606557 , 0.8606557 , 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90983605, 0.91803277, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.349 , 0.3484, 0.3472, 0.346 , 0.3438, 0.3418, 0.341 ,\n",
       "            0.3384, 0.338 , 0.3376, 0.3374, 0.336 , 0.3357, 0.3345, 0.3333,\n",
       "            0.3325, 0.332 , 0.3315, 0.3306, 0.3303, 0.3286, 0.3284, 0.327 ,\n",
       "            0.3264, 0.3262, 0.3254, 0.3252, 0.324 , 0.3237, 0.3235, 0.3228,\n",
       "            0.3225, 0.3223, 0.3215, 0.321 , 0.3208, 0.3206, 0.3203, 0.32  ,\n",
       "            0.3198, 0.3196, 0.3193, 0.3186, 0.318 , 0.3179, 0.3167, 0.3162,\n",
       "            0.3154, 0.3147, 0.3135, 0.313 , 0.3127, 0.3123, 0.312 , 0.3115,\n",
       "            0.311 , 0.3108, 0.3093, 0.309 , 0.3088, 0.3086, 0.3074, 0.3064,\n",
       "            0.3062, 0.3052, 0.3047, 0.3044, 0.3042, 0.304 , 0.3037, 0.3032,\n",
       "            0.3022, 0.302 , 0.3018, 0.3013, 0.3005, 0.2998, 0.2996, 0.299 ,\n",
       "            0.2986, 0.298 , 0.2976, 0.2974, 0.297 , 0.2966, 0.2964, 0.296 ,\n",
       "            0.294 , 0.2937, 0.2935, 0.2932, 0.293 , 0.2925, 0.2922, 0.291 ,\n",
       "            0.2908, 0.2898, 0.2876, 0.287 , 0.2869, 0.286 , 0.2852, 0.2847,\n",
       "            0.2837, 0.2832, 0.283 , 0.2827, 0.2825, 0.2822, 0.2815, 0.2808,\n",
       "            0.28  , 0.2798, 0.279 , 0.2788, 0.2786, 0.2773, 0.276 , 0.2751,\n",
       "            0.2715, 0.2703, 0.2695, 0.2693, 0.269 , 0.2688, 0.2673, 0.2668,\n",
       "            0.2664, 0.266 , 0.2651, 0.265 , 0.2644, 0.2632, 0.2627, 0.262 ,\n",
       "            0.2605, 0.2583, 0.258 , 0.2556, 0.254 , 0.2537, 0.2527, 0.2482,\n",
       "            0.248 , 0.2474, 0.2455, 0.2449, 0.2438, 0.2433, 0.2375, 0.2374,\n",
       "            0.2358, 0.2316, 0.2314, 0.2306, 0.2297, 0.228 , 0.2257, 0.2244,\n",
       "            0.224 , 0.2239, 0.2224, 0.2218, 0.2216, 0.2212, 0.2181, 0.2162,\n",
       "            0.2129, 0.212 , 0.2114, 0.2095, 0.2091, 0.2069, 0.2068, 0.2054,\n",
       "            0.2047, 0.2045, 0.2042, 0.2035, 0.2034, 0.2006, 0.1995, 0.1979,\n",
       "            0.1976, 0.1962, 0.1925, 0.1917, 0.1896, 0.1866, 0.1846, 0.182 ,\n",
       "            0.1808, 0.1788, 0.1782, 0.1764, 0.1718, 0.169 , 0.1664, 0.1659],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0625   , 0.078125 , 0.078125 , 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.1015625, 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.1171875, 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.140625 ,\n",
       "            0.140625 , 0.140625 , 0.15625  , 0.15625  , 0.1640625, 0.1640625,\n",
       "            0.1796875, 0.1796875, 0.1796875, 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.2109375, 0.2109375,\n",
       "            0.2109375, 0.2109375, 0.2109375, 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.2421875, 0.2421875, 0.2421875,\n",
       "            0.2421875, 0.2421875, 0.2421875, 0.25     , 0.25     , 0.25     ,\n",
       "            0.2578125, 0.2578125, 0.2578125, 0.2578125, 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.2734375, 0.2734375, 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.296875 , 0.296875 , 0.296875 , 0.296875 , 0.3125   ,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.328125 , 0.328125 , 0.328125 ,\n",
       "            0.34375  , 0.359375 , 0.359375 , 0.3671875, 0.3828125, 0.390625 ,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4375   , 0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.453125 ,\n",
       "            0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.02459016,\n",
       "            0.03278688, 0.03278688, 0.04098361, 0.05737705, 0.08196721,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.18032786, 0.18852459, 0.19672132, 0.19672132,\n",
       "            0.19672132, 0.19672132, 0.20491803, 0.21311475, 0.22950819,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.26229507, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.36885247,\n",
       "            0.37704918, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4180328 , 0.4180328 , 0.44262296,\n",
       "            0.45081967, 0.47540984, 0.47540984, 0.4918033 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.704918  , 0.71311474, 0.7295082 ,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.75409836, 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8278689 , 0.8278689 , 0.8442623 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3613, 0.3599, 0.3582, 0.3547, 0.3533, 0.3525, 0.352 ,\n",
       "            0.3503, 0.35  , 0.3499, 0.3486, 0.3474, 0.3464, 0.3457, 0.3455,\n",
       "            0.3452, 0.3435, 0.343 , 0.3428, 0.3425, 0.3423, 0.342 , 0.3418,\n",
       "            0.3416, 0.3413, 0.341 , 0.3408, 0.3403, 0.3398, 0.3394, 0.339 ,\n",
       "            0.3389, 0.3384, 0.3381, 0.3376, 0.3374, 0.3357, 0.335 , 0.3345,\n",
       "            0.3335, 0.333 , 0.3328, 0.3323, 0.3315, 0.331 , 0.3303, 0.3296,\n",
       "            0.3281, 0.328 , 0.327 , 0.3257, 0.3245, 0.3235, 0.3228, 0.3225,\n",
       "            0.3223, 0.322 , 0.3218, 0.3215, 0.3213, 0.321 , 0.3203, 0.32  ,\n",
       "            0.3198, 0.3193, 0.3188, 0.3186, 0.3179, 0.3174, 0.3162, 0.3154,\n",
       "            0.315 , 0.3142, 0.3137, 0.3135, 0.3132, 0.313 , 0.3127, 0.3125,\n",
       "            0.3123, 0.3115, 0.3105, 0.3103, 0.309 , 0.3086, 0.308 , 0.3079,\n",
       "            0.3076, 0.3074, 0.3071, 0.306 , 0.3054, 0.3052, 0.3047, 0.304 ,\n",
       "            0.3037, 0.3032, 0.3025, 0.3018, 0.3   , 0.2993, 0.2986, 0.298 ,\n",
       "            0.2976, 0.2969, 0.2966, 0.296 , 0.2954, 0.295 , 0.2947, 0.2944,\n",
       "            0.2927, 0.292 , 0.2913, 0.2905, 0.2903, 0.2898, 0.2893, 0.2888,\n",
       "            0.288 , 0.2874, 0.2869, 0.2861, 0.2852, 0.2842, 0.2837, 0.282 ,\n",
       "            0.281 , 0.2795, 0.279 , 0.278 , 0.2766, 0.2725, 0.2715, 0.2695,\n",
       "            0.2683, 0.268 , 0.2664, 0.2651, 0.2637, 0.2615, 0.2605, 0.2603,\n",
       "            0.2588, 0.258 , 0.2563, 0.2551, 0.2527, 0.2524, 0.252 , 0.2478,\n",
       "            0.2466, 0.246 , 0.2455, 0.2448, 0.2444, 0.244 , 0.2437, 0.243 ,\n",
       "            0.2382, 0.235 , 0.2347, 0.234 , 0.2335, 0.2327, 0.2323, 0.2303,\n",
       "            0.2295, 0.2294, 0.229 , 0.2289, 0.228 , 0.2274, 0.2268, 0.2266,\n",
       "            0.2244, 0.2238, 0.223 , 0.2203, 0.22  , 0.217 , 0.2167, 0.2157,\n",
       "            0.2128, 0.2104, 0.208 , 0.2059, 0.2053, 0.2024, 0.2023, 0.2   ,\n",
       "            0.1967, 0.1942, 0.1917, 0.1903], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.046875 , 0.046875 , 0.0625   , 0.0703125,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.0859375, 0.1015625, 0.109375 ,\n",
       "            0.109375 , 0.109375 , 0.1171875, 0.125    , 0.125    , 0.125    ,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.15625  , 0.1640625, 0.1640625,\n",
       "            0.171875 , 0.171875 , 0.1875   , 0.1875   , 0.1875   , 0.1953125,\n",
       "            0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.1953125,\n",
       "            0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.1953125,\n",
       "            0.1953125, 0.203125 , 0.203125 , 0.2109375, 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.2421875,\n",
       "            0.25     , 0.2578125, 0.2578125, 0.2578125, 0.2578125, 0.2578125,\n",
       "            0.2578125, 0.2578125, 0.2578125, 0.2578125, 0.2578125, 0.265625 ,\n",
       "            0.265625 , 0.265625 , 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.2890625, 0.296875 , 0.296875 , 0.296875 , 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3359375, 0.34375  , 0.34375  , 0.34375  , 0.359375 ,\n",
       "            0.359375 , 0.3671875, 0.3671875, 0.375    , 0.375    , 0.375    ,\n",
       "            0.390625 , 0.390625 , 0.390625 , 0.3984375, 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4375   , 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.4765625, 0.484375 , 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.515625 , 0.5234375, 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.16393442, 0.17213115,\n",
       "            0.17213115, 0.19672132, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22131148, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.26229507, 0.27868852, 0.28688523, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36065573, 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40163934,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4180328 , 0.4262295 ,\n",
       "            0.4262295 , 0.43442622, 0.43442622, 0.44262296, 0.46721312,\n",
       "            0.46721312, 0.47540984, 0.5081967 , 0.5163934 , 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6147541 ,\n",
       "            0.6229508 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6639344 , 0.6639344 , 0.6639344 , 0.6885246 , 0.6967213 ,\n",
       "            0.6967213 , 0.6967213 , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.7704918 , 0.77868855,\n",
       "            0.795082  , 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8196721 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3735, 0.371 , 0.3706, 0.3696, 0.3694, 0.3674, 0.3667,\n",
       "            0.3665, 0.366 , 0.3652, 0.3643, 0.3633, 0.3623, 0.3599, 0.3582,\n",
       "            0.358 , 0.3574, 0.3564, 0.3562, 0.3557, 0.3538, 0.3528, 0.3523,\n",
       "            0.352 , 0.3518, 0.3516, 0.351 , 0.3508, 0.3506, 0.3499, 0.3496,\n",
       "            0.349 , 0.3489, 0.3481, 0.348 , 0.3474, 0.3472, 0.346 , 0.3455,\n",
       "            0.3452, 0.345 , 0.3445, 0.3442, 0.344 , 0.3435, 0.3433, 0.3423,\n",
       "            0.3416, 0.3403, 0.34  , 0.3381, 0.3376, 0.3374, 0.337 , 0.3367,\n",
       "            0.3364, 0.336 , 0.335 , 0.3335, 0.3333, 0.333 , 0.3323, 0.3318,\n",
       "            0.3315, 0.331 , 0.3306, 0.3303, 0.33  , 0.3298, 0.3296, 0.329 ,\n",
       "            0.3267, 0.3252, 0.325 , 0.3247, 0.3242, 0.324 , 0.3237, 0.3232,\n",
       "            0.3228, 0.3225, 0.3223, 0.3206, 0.3196, 0.318 , 0.3176, 0.317 ,\n",
       "            0.3167, 0.3164, 0.3162, 0.3154, 0.3152, 0.315 , 0.3147, 0.3145,\n",
       "            0.314 , 0.3137, 0.3132, 0.313 , 0.3127, 0.312 , 0.3115, 0.3113,\n",
       "            0.31  , 0.3098, 0.308 , 0.3079, 0.3062, 0.306 , 0.3057, 0.3054,\n",
       "            0.3052, 0.3047, 0.3044, 0.3042, 0.3035, 0.3025, 0.3015, 0.3013,\n",
       "            0.3005, 0.3003, 0.3   , 0.2983, 0.298 , 0.2969, 0.2966, 0.2957,\n",
       "            0.2954, 0.2937, 0.2927, 0.2922, 0.2898, 0.289 , 0.2888, 0.2876,\n",
       "            0.2874, 0.2861, 0.2847, 0.2837, 0.2834, 0.2805, 0.2773, 0.2744,\n",
       "            0.2742, 0.2727, 0.2695, 0.269 , 0.268 , 0.2678, 0.2676, 0.265 ,\n",
       "            0.2646, 0.2588, 0.2573, 0.255 , 0.2544, 0.2534, 0.253 , 0.2527,\n",
       "            0.2522, 0.252 , 0.2517, 0.2512, 0.2505, 0.2478, 0.2466, 0.2448,\n",
       "            0.244 , 0.2437, 0.243 , 0.2418, 0.2407, 0.2406, 0.2405, 0.2394,\n",
       "            0.239 , 0.2366, 0.2363, 0.236 , 0.2351, 0.2343, 0.234 , 0.2339,\n",
       "            0.2325, 0.2307, 0.2285, 0.2277, 0.2261, 0.2256, 0.2233, 0.222 ,\n",
       "            0.2202, 0.2186, 0.2156, 0.2142, 0.2108, 0.2101, 0.2079, 0.2054,\n",
       "            0.2039, 0.2012, 0.199 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.078125 , 0.078125 , 0.078125 , 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.109375 , 0.109375 , 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.125    , 0.125    , 0.1328125, 0.140625 , 0.140625 , 0.140625 ,\n",
       "            0.140625 , 0.1484375, 0.1484375, 0.15625  , 0.1640625, 0.1640625,\n",
       "            0.1640625, 0.1640625, 0.1640625, 0.1640625, 0.171875 , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.1953125,\n",
       "            0.203125 , 0.203125 , 0.203125 , 0.21875  , 0.21875  , 0.2265625,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.2578125,\n",
       "            0.2578125, 0.2578125, 0.265625 , 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4921875, 0.5      , 0.5078125, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.609375 , 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.36065573, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.39344263, 0.40163934, 0.40163934, 0.40983605, 0.40983605,\n",
       "            0.4180328 , 0.4180328 , 0.4262295 , 0.44262296, 0.45081967,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.4918033 , 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5081967 , 0.52459013, 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59836066, 0.59836066, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.647541  , 0.647541  , 0.6557377 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.77868855, 0.8032787 ,\n",
       "            0.8114754 , 0.8278689 , 0.8360656 , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.91803277, 0.91803277,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4282, 0.424 , 0.4211, 0.419 , 0.4172, 0.4163, 0.415 ,\n",
       "            0.4138, 0.4072, 0.4065, 0.4055, 0.4048, 0.4038, 0.403 , 0.4023,\n",
       "            0.4016, 0.401 , 0.398 , 0.3972, 0.396 , 0.3953, 0.3923, 0.391 ,\n",
       "            0.3901, 0.3894, 0.3892, 0.388 , 0.387 , 0.3853, 0.3845, 0.3843,\n",
       "            0.3835, 0.3823, 0.3816, 0.3806, 0.3801, 0.3787, 0.3782, 0.378 ,\n",
       "            0.3777, 0.3772, 0.3767, 0.3765, 0.3762, 0.3752, 0.3748, 0.3745,\n",
       "            0.374 , 0.3735, 0.373 , 0.3728, 0.3708, 0.37  , 0.3694, 0.3691,\n",
       "            0.3684, 0.3677, 0.3674, 0.3657, 0.3652, 0.365 , 0.3647, 0.3645,\n",
       "            0.3643, 0.3635, 0.3633, 0.363 , 0.3628, 0.3623, 0.362 , 0.3618,\n",
       "            0.361 , 0.3608, 0.3604, 0.36  , 0.3591, 0.359 , 0.3577, 0.3572,\n",
       "            0.357 , 0.3564, 0.3562, 0.356 , 0.355 , 0.3538, 0.3535, 0.3533,\n",
       "            0.353 , 0.352 , 0.3518, 0.3513, 0.351 , 0.3506, 0.3499, 0.3496,\n",
       "            0.349 , 0.3486, 0.3481, 0.348 , 0.3472, 0.3467, 0.3457, 0.3447,\n",
       "            0.343 , 0.3428, 0.342 , 0.3418, 0.3413, 0.341 , 0.3406, 0.3403,\n",
       "            0.34  , 0.3396, 0.339 , 0.3381, 0.3354, 0.3352, 0.335 , 0.3345,\n",
       "            0.334 , 0.3328, 0.3318, 0.3313, 0.3303, 0.3298, 0.3293, 0.3289,\n",
       "            0.3276, 0.3264, 0.3245, 0.322 , 0.3215, 0.321 , 0.3203, 0.3196,\n",
       "            0.319 , 0.3174, 0.3162, 0.3154, 0.3125, 0.312 , 0.311 , 0.3093,\n",
       "            0.309 , 0.3064, 0.3062, 0.306 , 0.3052, 0.3047, 0.304 , 0.3032,\n",
       "            0.3025, 0.3015, 0.3013, 0.3005, 0.2983, 0.2964, 0.2942, 0.2925,\n",
       "            0.2917, 0.29  , 0.2898, 0.2888, 0.2883, 0.288 , 0.2878, 0.2874,\n",
       "            0.2869, 0.2864, 0.286 , 0.285 , 0.2842, 0.2832, 0.283 , 0.2803,\n",
       "            0.2795, 0.279 , 0.2773, 0.2761, 0.2756, 0.2754, 0.2751, 0.2737,\n",
       "            0.2722, 0.2712, 0.2708, 0.2705, 0.27  , 0.2693, 0.269 , 0.2678,\n",
       "            0.2668, 0.2664, 0.266 , 0.2654, 0.2646, 0.2634, 0.2622, 0.26  ,\n",
       "            0.2593, 0.2566, 0.2534, 0.2524, 0.2522, 0.2477, 0.2473, 0.2452,\n",
       "            0.2444, 0.2434, 0.2429, 0.2424, 0.2422, 0.2383, 0.2225],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.046875 ,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.078125 , 0.078125 , 0.09375  , 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.109375 , 0.109375 , 0.109375 , 0.109375 , 0.109375 ,\n",
       "            0.109375 , 0.109375 , 0.109375 , 0.109375 , 0.1171875, 0.1171875,\n",
       "            0.1328125, 0.1328125, 0.140625 , 0.140625 , 0.1484375, 0.1484375,\n",
       "            0.15625  , 0.15625  , 0.15625  , 0.15625  , 0.1640625, 0.1640625,\n",
       "            0.1640625, 0.171875 , 0.171875 , 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.1953125, 0.203125 , 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.2265625, 0.234375 , 0.2421875, 0.25     , 0.25     ,\n",
       "            0.265625 , 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3125   , 0.3203125, 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.7421875, 0.75     , 0.7578125, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.828125 , 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.9140625, 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.37704918, 0.3852459 , 0.40163934, 0.40983605,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6393443 , 0.647541  ,\n",
       "            0.6639344 , 0.6639344 , 0.6721311 , 0.6721311 , 0.6803279 ,\n",
       "            0.6967213 , 0.6967213 , 0.704918  , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.795082  , 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.852459  , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4688, 0.4578, 0.4565, 0.4563, 0.4502, 0.4468, 0.4465,\n",
       "            0.4412, 0.441 , 0.44  , 0.4333, 0.433 , 0.4329, 0.4312, 0.4304,\n",
       "            0.4265, 0.4263, 0.4255, 0.4233, 0.421 , 0.4202, 0.4175, 0.417 ,\n",
       "            0.4163, 0.4155, 0.4148, 0.4143, 0.413 , 0.4124, 0.409 , 0.4084,\n",
       "            0.4075, 0.4065, 0.4053, 0.404 , 0.4036, 0.4033, 0.4023, 0.3958,\n",
       "            0.3955, 0.395 , 0.3948, 0.394 , 0.393 , 0.3928, 0.392 , 0.391 ,\n",
       "            0.3906, 0.3901, 0.3892, 0.3884, 0.3882, 0.3875, 0.3865, 0.3845,\n",
       "            0.3843, 0.383 , 0.3828, 0.382 , 0.3818, 0.3813, 0.381 , 0.3809,\n",
       "            0.38  , 0.3792, 0.3784, 0.3777, 0.3762, 0.3757, 0.3752, 0.374 ,\n",
       "            0.3735, 0.3733, 0.373 , 0.3723, 0.3708, 0.3706, 0.3691, 0.3687,\n",
       "            0.3682, 0.368 , 0.3677, 0.3674, 0.3657, 0.3647, 0.364 , 0.3638,\n",
       "            0.3635, 0.363 , 0.3628, 0.3623, 0.362 , 0.3616, 0.3599, 0.3594,\n",
       "            0.3591, 0.3582, 0.358 , 0.3572, 0.357 , 0.3567, 0.3562, 0.356 ,\n",
       "            0.3538, 0.3535, 0.3533, 0.3523, 0.3516, 0.3513, 0.3499, 0.3494,\n",
       "            0.349 , 0.3484, 0.3481, 0.3462, 0.346 , 0.3457, 0.3455, 0.3447,\n",
       "            0.344 , 0.3435, 0.3433, 0.3423, 0.3418, 0.3406, 0.337 , 0.3352,\n",
       "            0.3347, 0.3306, 0.3303, 0.3274, 0.327 , 0.3245, 0.3237, 0.3235,\n",
       "            0.3228, 0.321 , 0.3206, 0.3198, 0.3171, 0.317 , 0.3162, 0.315 ,\n",
       "            0.3135, 0.313 , 0.3127, 0.3123, 0.3093, 0.3083, 0.3074, 0.3057,\n",
       "            0.3044, 0.3042, 0.3037, 0.3035, 0.3025, 0.3022, 0.3018, 0.301 ,\n",
       "            0.3008, 0.2993, 0.299 , 0.298 , 0.2976, 0.297 , 0.2966, 0.2961,\n",
       "            0.2954, 0.2932, 0.293 , 0.2927, 0.292 , 0.2917, 0.2915, 0.2896,\n",
       "            0.289 , 0.2886, 0.2854, 0.2852, 0.285 , 0.2844, 0.2837, 0.2832,\n",
       "            0.283 , 0.2825, 0.282 , 0.2815, 0.28  , 0.2788, 0.2776, 0.2751,\n",
       "            0.2722, 0.271 , 0.27  , 0.268 , 0.2666, 0.2654, 0.2625, 0.2622,\n",
       "            0.2605, 0.26  , 0.2583, 0.257 , 0.2554, 0.2546, 0.2471, 0.235 ,\n",
       "            0.2339, 0.218 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.01639344, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.0859375, 0.0859375,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.09375  , 0.1015625,\n",
       "            0.1015625, 0.109375 , 0.109375 , 0.109375 , 0.1171875, 0.1171875,\n",
       "            0.1171875, 0.1171875, 0.1171875, 0.125    , 0.1328125, 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.1640625, 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.25     , 0.2578125,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.4140625, 0.421875 , 0.4296875, 0.4453125,\n",
       "            0.453125 , 0.46875  , 0.4765625, 0.4921875, 0.5078125, 0.515625 ,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8203125, 0.828125 ,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.875    , 0.890625 , 0.8984375,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.352459  , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.4918033 , 0.5       , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.57377046, 0.58196723,\n",
       "            0.59836066, 0.6147541 , 0.6229508 , 0.63114756, 0.63114756,\n",
       "            0.6393443 , 0.6557377 , 0.6721311 , 0.6967213 , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.7295082 , 0.73770493, 0.73770493,\n",
       "            0.73770493, 0.74590164, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5117, 0.5034, 0.4937, 0.4885, 0.483 , 0.4817, 0.4802,\n",
       "            0.4792, 0.4768, 0.4766, 0.469 , 0.4668, 0.4636, 0.4614, 0.4607,\n",
       "            0.4592, 0.4573, 0.4563, 0.456 , 0.454 , 0.4531, 0.4524, 0.4495,\n",
       "            0.4485, 0.447 , 0.4434, 0.4397, 0.4377, 0.4373, 0.436 , 0.4353,\n",
       "            0.4343, 0.4338, 0.433 , 0.432 , 0.43  , 0.4294, 0.4287, 0.427 ,\n",
       "            0.4268, 0.421 , 0.4143, 0.4114, 0.4097, 0.4094, 0.4087, 0.4072,\n",
       "            0.4062, 0.4058, 0.405 , 0.404 , 0.4033, 0.4028, 0.4011, 0.401 ,\n",
       "            0.4004, 0.4001, 0.3997, 0.3987, 0.3982, 0.398 , 0.3977, 0.3972,\n",
       "            0.3962, 0.3958, 0.3953, 0.3948, 0.3943, 0.3933, 0.3918, 0.3914,\n",
       "            0.3909, 0.39  , 0.3894, 0.3887, 0.388 , 0.387 , 0.3867, 0.386 ,\n",
       "            0.3853, 0.3835, 0.3828, 0.381 , 0.3809, 0.3806, 0.3804, 0.3801,\n",
       "            0.38  , 0.3782, 0.3772, 0.377 , 0.376 , 0.3752, 0.375 , 0.3743,\n",
       "            0.3735, 0.373 , 0.3718, 0.3713, 0.371 , 0.3706, 0.37  , 0.3696,\n",
       "            0.3687, 0.3667, 0.3662, 0.3643, 0.364 , 0.3638, 0.363 , 0.3623,\n",
       "            0.362 , 0.3618, 0.3616, 0.361 , 0.3608, 0.3606, 0.3596, 0.3594,\n",
       "            0.357 , 0.3564, 0.3562, 0.356 , 0.3555, 0.3552, 0.355 , 0.354 ,\n",
       "            0.3528, 0.3525, 0.3516, 0.35  , 0.3496, 0.3486, 0.3447, 0.3438,\n",
       "            0.3408, 0.3381, 0.3367, 0.3345, 0.3298, 0.329 , 0.3286, 0.3276,\n",
       "            0.3274, 0.3264, 0.3262, 0.324 , 0.3232, 0.3228, 0.3225, 0.3213,\n",
       "            0.3208, 0.3206, 0.32  , 0.3196, 0.3186, 0.318 , 0.3176, 0.3167,\n",
       "            0.314 , 0.3137, 0.3132, 0.313 , 0.3125, 0.312 , 0.3115, 0.3113,\n",
       "            0.311 , 0.3105, 0.307 , 0.3044, 0.3042, 0.3037, 0.3032, 0.3025,\n",
       "            0.3022, 0.3015, 0.3013, 0.301 , 0.3003, 0.3   , 0.2998, 0.2986,\n",
       "            0.298 , 0.2976, 0.2974, 0.2954, 0.2944, 0.2937, 0.2932, 0.2925,\n",
       "            0.2903, 0.2896, 0.2886, 0.2883, 0.2874, 0.2864, 0.283 , 0.281 ,\n",
       "            0.2795, 0.279 , 0.278 , 0.2764, 0.2756, 0.2754, 0.274 , 0.2732,\n",
       "            0.2573, 0.2527, 0.25  , 0.2483, 0.2405, 0.2249, 0.2239, 0.2119],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.13114753, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.078125 , 0.078125 , 0.0859375, 0.0859375, 0.09375  ,\n",
       "            0.09375  , 0.09375  , 0.09375  , 0.1015625, 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.1171875, 0.1171875, 0.125    , 0.125    , 0.125    ,\n",
       "            0.140625 , 0.140625 , 0.1484375, 0.1484375, 0.15625  , 0.15625  ,\n",
       "            0.1640625, 0.1640625, 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.203125 , 0.2109375, 0.2109375, 0.2109375, 0.21875  , 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.3984375, 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.453125 , 0.4609375, 0.46875  , 0.484375 ,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.5859375, 0.59375  , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.65625  , 0.6640625, 0.6796875,\n",
       "            0.6875   , 0.703125 , 0.7109375, 0.71875  , 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.26229507, 0.2704918 , 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.37704918, 0.37704918,\n",
       "            0.3852459 , 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6557377 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.72131145, 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.76229507, 0.76229507, 0.76229507, 0.76229507,\n",
       "            0.76229507, 0.77868855, 0.78688526, 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.8852459 , 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5674, 0.5615, 0.544 , 0.5337, 0.533 , 0.532 , 0.529 ,\n",
       "            0.5244, 0.523 , 0.518 , 0.5166, 0.515 , 0.5117, 0.5093, 0.5063,\n",
       "            0.505 , 0.499 , 0.4973, 0.494 , 0.4934, 0.4932, 0.492 , 0.4897,\n",
       "            0.488 , 0.4858, 0.4846, 0.4824, 0.4768, 0.4766, 0.475 , 0.4736,\n",
       "            0.4727, 0.4722, 0.4702, 0.4673, 0.4622, 0.4612, 0.4602, 0.4565,\n",
       "            0.4563, 0.4548, 0.441 , 0.4387, 0.4382, 0.4365, 0.4363, 0.4333,\n",
       "            0.4329, 0.4312, 0.426 , 0.4258, 0.4248, 0.4238, 0.423 , 0.4214,\n",
       "            0.4211, 0.4204, 0.42  , 0.4197, 0.4185, 0.4177, 0.4172, 0.417 ,\n",
       "            0.4167, 0.4158, 0.4143, 0.413 , 0.4124, 0.412 , 0.4111, 0.4106,\n",
       "            0.4102, 0.41  , 0.4087, 0.4082, 0.4065, 0.4062, 0.4053, 0.402 ,\n",
       "            0.4019, 0.4014, 0.4006, 0.399 , 0.3958, 0.3945, 0.3943, 0.394 ,\n",
       "            0.3938, 0.3926, 0.3923, 0.392 , 0.3916, 0.3909, 0.3901, 0.39  ,\n",
       "            0.3894, 0.388 , 0.3875, 0.3862, 0.3853, 0.385 , 0.3843, 0.3835,\n",
       "            0.382 , 0.3818, 0.3806, 0.3796, 0.3794, 0.3792, 0.3777, 0.3767,\n",
       "            0.3762, 0.376 , 0.3745, 0.3738, 0.3735, 0.373 , 0.372 , 0.3713,\n",
       "            0.3706, 0.37  , 0.3696, 0.3694, 0.3682, 0.3674, 0.3672, 0.3662,\n",
       "            0.3657, 0.3638, 0.36  , 0.3562, 0.354 , 0.3525, 0.3503, 0.3496,\n",
       "            0.3489, 0.3477, 0.346 , 0.3457, 0.3447, 0.344 , 0.343 , 0.342 ,\n",
       "            0.3416, 0.3408, 0.34  , 0.3367, 0.3364, 0.3352, 0.3345, 0.3337,\n",
       "            0.3335, 0.333 , 0.3325, 0.3323, 0.3313, 0.3298, 0.3296, 0.3281,\n",
       "            0.328 , 0.3276, 0.3264, 0.3252, 0.325 , 0.3235, 0.3228, 0.322 ,\n",
       "            0.3184, 0.318 , 0.3176, 0.317 , 0.3164, 0.3152, 0.3145, 0.3132,\n",
       "            0.3127, 0.3125, 0.3118, 0.3079, 0.3074, 0.3071, 0.3057, 0.305 ,\n",
       "            0.3044, 0.3037, 0.3035, 0.3022, 0.3015, 0.2988, 0.2986, 0.2966,\n",
       "            0.2961, 0.2944, 0.2937, 0.2898, 0.2896, 0.2893, 0.283 , 0.2795,\n",
       "            0.2778, 0.2756, 0.2742, 0.2734, 0.2537, 0.2505, 0.2498, 0.2441,\n",
       "            0.2395, 0.2197, 0.219 , 0.2115], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.28688523, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.0546875, 0.0703125,\n",
       "            0.0703125, 0.0703125, 0.078125 , 0.0859375, 0.0859375, 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.109375 , 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.125    , 0.125    , 0.1328125, 0.1328125, 0.1328125, 0.140625 ,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.15625  , 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.3359375,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.59375  , 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.6484375, 0.65625  , 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.796875 , 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.40983605,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.56557375, 0.57377046,\n",
       "            0.59016395, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.7704918 , 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8442623 ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.609 , 0.6055, 0.583 , 0.574 , 0.5723, 0.568 , 0.564 ,\n",
       "            0.5615, 0.56  , 0.558 , 0.5566, 0.5503, 0.5474, 0.547 , 0.541 ,\n",
       "            0.5376, 0.532 , 0.53  , 0.528 , 0.524 , 0.5234, 0.5225, 0.5215,\n",
       "            0.5195, 0.5166, 0.5127, 0.5107, 0.5103, 0.507 , 0.505 , 0.5044,\n",
       "            0.504 , 0.502 , 0.4995, 0.495 , 0.4937, 0.4895, 0.489 , 0.4858,\n",
       "            0.4817, 0.4802, 0.473 , 0.4678, 0.4675, 0.465 , 0.4648, 0.4639,\n",
       "            0.4626, 0.461 , 0.4578, 0.4575, 0.453 , 0.4524, 0.452 , 0.4517,\n",
       "            0.4504, 0.4495, 0.4492, 0.4468, 0.4465, 0.4463, 0.4456, 0.4448,\n",
       "            0.443 , 0.4426, 0.4421, 0.4417, 0.441 , 0.4404, 0.439 , 0.4377,\n",
       "            0.4365, 0.4363, 0.4348, 0.434 , 0.4324, 0.4316, 0.4297, 0.4294,\n",
       "            0.4275, 0.427 , 0.4268, 0.426 , 0.4258, 0.4253, 0.4246, 0.4243,\n",
       "            0.4236, 0.4219, 0.4214, 0.419 , 0.4172, 0.4167, 0.415 , 0.4143,\n",
       "            0.4138, 0.4133, 0.413 , 0.4126, 0.4111, 0.4094, 0.4092, 0.409 ,\n",
       "            0.4087, 0.4084, 0.4072, 0.4065, 0.406 , 0.4045, 0.4038, 0.4033,\n",
       "            0.402 , 0.3997, 0.3994, 0.3984, 0.398 , 0.3972, 0.396 , 0.3958,\n",
       "            0.3948, 0.3945, 0.3943, 0.3936, 0.393 , 0.3909, 0.3906, 0.3901,\n",
       "            0.3892, 0.3882, 0.388 , 0.3867, 0.3865, 0.3833, 0.3818, 0.381 ,\n",
       "            0.379 , 0.3787, 0.3782, 0.3777, 0.3774, 0.3772, 0.3757, 0.3755,\n",
       "            0.3733, 0.3723, 0.3691, 0.3667, 0.3657, 0.365 , 0.3638, 0.363 ,\n",
       "            0.3618, 0.3606, 0.36  , 0.3594, 0.359 , 0.3572, 0.3564, 0.356 ,\n",
       "            0.354 , 0.353 , 0.3523, 0.352 , 0.3518, 0.351 , 0.3503, 0.3477,\n",
       "            0.3467, 0.346 , 0.3455, 0.3442, 0.344 , 0.3408, 0.3406, 0.34  ,\n",
       "            0.3398, 0.3396, 0.3394, 0.3386, 0.3384, 0.3381, 0.3372, 0.337 ,\n",
       "            0.3364, 0.3362, 0.334 , 0.3337, 0.3333, 0.3328, 0.3325, 0.3303,\n",
       "            0.3284, 0.326 , 0.3235, 0.323 , 0.3223, 0.322 , 0.3218, 0.3213,\n",
       "            0.3074, 0.307 , 0.3066, 0.3054, 0.3052, 0.3035, 0.2957, 0.2903,\n",
       "            0.29  , 0.2869, 0.2793, 0.2776, 0.2751, 0.2742, 0.2727, 0.252 ,\n",
       "            0.249 , 0.2474, 0.2418, 0.2368, 0.2153, 0.2145, 0.209 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.36065573, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.0703125, 0.0703125, 0.078125 , 0.0859375, 0.0859375,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.1015625, 0.109375 , 0.109375 ,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.1328125, 0.1328125,\n",
       "            0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.15625  , 0.1640625,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.2734375, 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.34375  , 0.3515625, 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.578125 , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.7421875, 0.7578125, 0.765625 , 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4180328 , 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.795082  , 0.795082  ,\n",
       "            0.8114754 , 0.8278689 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6553, 0.654 , 0.627 , 0.6187, 0.6167, 0.6074, 0.606 ,\n",
       "            0.604 , 0.602 , 0.594 , 0.5923, 0.5864, 0.586 , 0.5767, 0.573 ,\n",
       "            0.569 , 0.5684, 0.562 , 0.559 , 0.558 , 0.557 , 0.5566, 0.555 ,\n",
       "            0.552 , 0.55  , 0.5493, 0.546 , 0.5444, 0.5415, 0.539 , 0.5366,\n",
       "            0.5356, 0.535 , 0.533 , 0.531 , 0.525 , 0.5234, 0.517 , 0.512 ,\n",
       "            0.5073, 0.506 , 0.505 , 0.499 , 0.4973, 0.496 , 0.4944, 0.494 ,\n",
       "            0.4907, 0.49  , 0.4866, 0.4795, 0.474 , 0.4739, 0.4717, 0.4697,\n",
       "            0.4695, 0.4692, 0.4683, 0.467 , 0.4666, 0.4658, 0.4653, 0.4644,\n",
       "            0.4636, 0.463 , 0.4617, 0.4595, 0.4587, 0.4556, 0.4548, 0.454 ,\n",
       "            0.4534, 0.4531, 0.451 , 0.4507, 0.4497, 0.448 , 0.4468, 0.4458,\n",
       "            0.445 , 0.4446, 0.4436, 0.4417, 0.4404, 0.4397, 0.4392, 0.4387,\n",
       "            0.4385, 0.4373, 0.4365, 0.4355, 0.4336, 0.4326, 0.4314, 0.431 ,\n",
       "            0.4302, 0.43  , 0.4297, 0.429 , 0.4287, 0.4265, 0.4255, 0.4253,\n",
       "            0.4246, 0.4233, 0.423 , 0.422 , 0.4219, 0.4202, 0.4197, 0.4192,\n",
       "            0.4182, 0.416 , 0.4153, 0.4133, 0.4128, 0.4114, 0.411 , 0.41  ,\n",
       "            0.4084, 0.408 , 0.4072, 0.407 , 0.4067, 0.4062, 0.4043, 0.4036,\n",
       "            0.403 , 0.4011, 0.4006, 0.3997, 0.3987, 0.3975, 0.3972, 0.3953,\n",
       "            0.395 , 0.392 , 0.391 , 0.389 , 0.3865, 0.3848, 0.3843, 0.3838,\n",
       "            0.3833, 0.3828, 0.382 , 0.3806, 0.38  , 0.3787, 0.3782, 0.378 ,\n",
       "            0.3767, 0.376 , 0.3743, 0.3733, 0.371 , 0.37  , 0.369 , 0.3687,\n",
       "            0.3684, 0.3665, 0.3652, 0.364 , 0.3638, 0.3625, 0.362 , 0.3618,\n",
       "            0.36  , 0.358 , 0.3574, 0.357 , 0.3564, 0.3542, 0.3535, 0.3528,\n",
       "            0.3525, 0.3523, 0.352 , 0.351 , 0.3508, 0.3506, 0.349 , 0.3486,\n",
       "            0.3464, 0.3447, 0.3433, 0.3428, 0.3413, 0.341 , 0.3398, 0.3394,\n",
       "            0.3389, 0.3376, 0.3347, 0.3345, 0.334 , 0.324 , 0.3237, 0.321 ,\n",
       "            0.3093, 0.307 , 0.3057, 0.3054, 0.3044, 0.3025, 0.2944, 0.2915,\n",
       "            0.2893, 0.2888, 0.2766, 0.275 , 0.2727, 0.2705, 0.27  , 0.2473,\n",
       "            0.2467, 0.2426, 0.2358, 0.2335, 0.2084, 0.2076, 0.2065],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.0078125, dtype=float32),\n",
       "    'tpr': array(0.4180328, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0703125, 0.0703125, 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.0859375, 0.0859375, 0.0859375, 0.09375  , 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.109375 , 0.109375 , 0.109375 , 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.140625 , 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.171875 , 0.171875 , 0.1875   , 0.1953125, 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.3671875, 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.4921875, 0.5      ,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.01639344, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.687 , 0.6562, 0.6494, 0.647 , 0.64  , 0.636 , 0.6323,\n",
       "            0.6313, 0.631 , 0.6235, 0.62  , 0.6133, 0.612 , 0.6006, 0.5986,\n",
       "            0.5957, 0.594 , 0.587 , 0.585 , 0.583 , 0.5825, 0.579 , 0.5776,\n",
       "            0.577 , 0.5747, 0.5728, 0.5713, 0.5664, 0.5654, 0.564 , 0.56  ,\n",
       "            0.5596, 0.557 , 0.556 , 0.5537, 0.5513, 0.551 , 0.543 , 0.5376,\n",
       "            0.531 , 0.529 , 0.526 , 0.524 , 0.522 , 0.521 , 0.5176, 0.517 ,\n",
       "            0.5166, 0.514 , 0.51  , 0.5034, 0.4966, 0.4963, 0.4956, 0.4944,\n",
       "            0.4927, 0.492 , 0.4905, 0.489 , 0.4885, 0.486 , 0.4854, 0.484 ,\n",
       "            0.4817, 0.4802, 0.48  , 0.4795, 0.4788, 0.478 , 0.4775, 0.4753,\n",
       "            0.475 , 0.4749, 0.4746, 0.4695, 0.4688, 0.4646, 0.4639, 0.463 ,\n",
       "            0.4626, 0.462 , 0.4612, 0.4597, 0.4592, 0.4583, 0.4568, 0.456 ,\n",
       "            0.4539, 0.4507, 0.4492, 0.4478, 0.4475, 0.447 , 0.4465, 0.4463,\n",
       "            0.4458, 0.4456, 0.4453, 0.4443, 0.444 , 0.4438, 0.4436, 0.4429,\n",
       "            0.4424, 0.4414, 0.4404, 0.4392, 0.4385, 0.4348, 0.4329, 0.43  ,\n",
       "            0.4287, 0.4285, 0.4272, 0.4268, 0.4263, 0.4253, 0.425 , 0.4236,\n",
       "            0.4229, 0.422 , 0.4214, 0.4207, 0.4197, 0.4192, 0.419 , 0.4177,\n",
       "            0.4172, 0.4143, 0.4128, 0.4126, 0.4124, 0.4114, 0.4102, 0.41  ,\n",
       "            0.4092, 0.4043, 0.4038, 0.3987, 0.3982, 0.3972, 0.3962, 0.3953,\n",
       "            0.395 , 0.3938, 0.3936, 0.3928, 0.3923, 0.391 , 0.3901, 0.3896,\n",
       "            0.3887, 0.3882, 0.3877, 0.387 , 0.384 , 0.3826, 0.3823, 0.3816,\n",
       "            0.3804, 0.3777, 0.3774, 0.3767, 0.376 , 0.3757, 0.3733, 0.3723,\n",
       "            0.3718, 0.3713, 0.371 , 0.3706, 0.3704, 0.3699, 0.3694, 0.369 ,\n",
       "            0.3677, 0.3674, 0.3672, 0.367 , 0.3657, 0.3652, 0.3647, 0.364 ,\n",
       "            0.3633, 0.3604, 0.3586, 0.3542, 0.354 , 0.3533, 0.3525, 0.3518,\n",
       "            0.35  , 0.3489, 0.347 , 0.3442, 0.343 , 0.3425, 0.3408, 0.3386,\n",
       "            0.3362, 0.3354, 0.3242, 0.324 , 0.3215, 0.3076, 0.3044, 0.304 ,\n",
       "            0.3032, 0.3025, 0.3005, 0.2915, 0.2913, 0.286 , 0.2856, 0.273 ,\n",
       "            0.271 , 0.2688, 0.2673, 0.2664, 0.2426, 0.2424, 0.2374, 0.2314,\n",
       "            0.2278, 0.202 , 0.2012], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.015625, dtype=float32),\n",
       "    'tpr': array(0.57377046, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.0546875,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.0859375,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.140625 ,\n",
       "            0.140625 , 0.1484375, 0.1640625, 0.1640625, 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.2890625, 0.3046875, 0.3125   , 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.43442622, 0.44262296, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.47540984, 0.4918033 , 0.5       , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.89344263, 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.719 , 0.718 , 0.6865, 0.68  , 0.6777, 0.673 , 0.6685,\n",
       "            0.6597, 0.659 , 0.655 , 0.647 , 0.641 , 0.638 , 0.6265, 0.625 ,\n",
       "            0.624 , 0.621 , 0.6157, 0.6094, 0.609 , 0.6084, 0.6064, 0.6035,\n",
       "            0.601 , 0.599 , 0.598 , 0.5977, 0.593 , 0.59  , 0.589 , 0.5854,\n",
       "            0.585 , 0.583 , 0.5806, 0.578 , 0.5757, 0.574 , 0.5654, 0.5596,\n",
       "            0.5537, 0.5513, 0.5464, 0.546 , 0.5435, 0.542 , 0.5405, 0.54  ,\n",
       "            0.5396, 0.531 , 0.5264, 0.525 , 0.523 , 0.516 , 0.514 , 0.5137,\n",
       "            0.513 , 0.5127, 0.5117, 0.511 , 0.5107, 0.506 , 0.503 , 0.5024,\n",
       "            0.5005, 0.4995, 0.4985, 0.4983, 0.498 , 0.4978, 0.495 , 0.4946,\n",
       "            0.4934, 0.4907, 0.4905, 0.49  , 0.4893, 0.4866, 0.4824, 0.4814,\n",
       "            0.4812, 0.4805, 0.4802, 0.4792, 0.4773, 0.4756, 0.4753, 0.475 ,\n",
       "            0.474 , 0.4712, 0.471 , 0.4688, 0.4683, 0.4675, 0.4673, 0.4666,\n",
       "            0.4658, 0.4646, 0.464 , 0.4636, 0.4626, 0.4622, 0.462 , 0.4617,\n",
       "            0.461 , 0.4597, 0.4592, 0.4573, 0.4563, 0.4558, 0.454 , 0.4517,\n",
       "            0.4495, 0.4485, 0.445 , 0.4448, 0.4443, 0.4434, 0.4421, 0.4417,\n",
       "            0.4397, 0.4392, 0.4387, 0.4385, 0.4375, 0.4333, 0.4329, 0.4326,\n",
       "            0.4324, 0.431 , 0.4297, 0.429 , 0.4277, 0.426 , 0.4255, 0.4238,\n",
       "            0.423 , 0.422 , 0.416 , 0.4153, 0.4128, 0.4126, 0.4124, 0.4119,\n",
       "            0.4104, 0.4087, 0.4062, 0.4043, 0.404 , 0.4033, 0.403 , 0.4023,\n",
       "            0.4016, 0.4001, 0.399 , 0.3965, 0.3962, 0.396 , 0.3958, 0.3955,\n",
       "            0.3945, 0.393 , 0.3923, 0.392 , 0.3906, 0.3884, 0.3882, 0.388 ,\n",
       "            0.3877, 0.3875, 0.3867, 0.386 , 0.3853, 0.3838, 0.3833, 0.382 ,\n",
       "            0.3818, 0.3813, 0.3809, 0.3806, 0.38  , 0.3796, 0.3782, 0.3777,\n",
       "            0.3738, 0.3723, 0.3704, 0.3691, 0.3687, 0.3677, 0.367 , 0.3645,\n",
       "            0.358 , 0.3538, 0.3533, 0.3477, 0.347 , 0.3457, 0.344 , 0.3418,\n",
       "            0.3394, 0.339 , 0.3264, 0.3262, 0.3235, 0.3079, 0.3042, 0.304 ,\n",
       "            0.3025, 0.3003, 0.293 , 0.2903, 0.2844, 0.2842, 0.271 , 0.2688,\n",
       "            0.2664, 0.2656, 0.2637, 0.2399, 0.2394, 0.2338, 0.2281, 0.2239,\n",
       "            0.1976, 0.197 , 0.1959], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.0390625, dtype=float32),\n",
       "    'tpr': array(0.7295082, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0546875, 0.0546875,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.1484375, 0.1484375,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.21875  , 0.2265625, 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.9296875, 0.9375   , 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13934426, 0.14754099, 0.1557377 , 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.36065573,\n",
       "            0.37704918, 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.44262296, 0.44262296, 0.45081967, 0.47540984,\n",
       "            0.48360655, 0.5       , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.5491803 , 0.55737704, 0.56557375, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.647541  , 0.6557377 , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6803279 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.795082  , 0.8032787 ,\n",
       "            0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7524, 0.75  , 0.719 , 0.7124, 0.71  , 0.7065, 0.7017,\n",
       "            0.6904, 0.69  , 0.6895, 0.6875, 0.6763, 0.671 , 0.6665, 0.655 ,\n",
       "            0.654 , 0.65  , 0.6465, 0.6377, 0.636 , 0.631 , 0.628 , 0.627 ,\n",
       "            0.626 , 0.625 , 0.621 , 0.6177, 0.6147, 0.613 , 0.6123, 0.612 ,\n",
       "            0.6074, 0.6064, 0.6006, 0.5903, 0.584 , 0.581 , 0.5747, 0.573 ,\n",
       "            0.569 , 0.567 , 0.566 , 0.565 , 0.557 , 0.5566, 0.554 , 0.5454,\n",
       "            0.541 , 0.5405, 0.54  , 0.5396, 0.5376, 0.536 , 0.534 , 0.532 ,\n",
       "            0.5317, 0.53  , 0.5283, 0.526 , 0.524 , 0.5234, 0.5225, 0.52  ,\n",
       "            0.5195, 0.519 , 0.5186, 0.5166, 0.513 , 0.512 , 0.5107, 0.506 ,\n",
       "            0.5054, 0.5044, 0.5034, 0.503 , 0.502 , 0.5   , 0.498 , 0.4978,\n",
       "            0.4973, 0.4963, 0.4954, 0.4934, 0.493 , 0.491 , 0.4907, 0.4866,\n",
       "            0.4863, 0.486 , 0.484 , 0.4834, 0.4832, 0.4827, 0.4824, 0.4783,\n",
       "            0.4773, 0.4768, 0.4763, 0.4758, 0.4746, 0.4724, 0.4707, 0.4702,\n",
       "            0.4678, 0.4646, 0.464 , 0.4636, 0.4634, 0.4602, 0.4595, 0.4563,\n",
       "            0.4553, 0.455 , 0.454 , 0.4536, 0.4526, 0.4512, 0.4507, 0.449 ,\n",
       "            0.445 , 0.4448, 0.4446, 0.4426, 0.4414, 0.4402, 0.44  , 0.4363,\n",
       "            0.4336, 0.433 , 0.432 , 0.4294, 0.4292, 0.4275, 0.4268, 0.4255,\n",
       "            0.424 , 0.4233, 0.4226, 0.4224, 0.421 , 0.4207, 0.4202, 0.4192,\n",
       "            0.4187, 0.4143, 0.4136, 0.413 , 0.4124, 0.412 , 0.4116, 0.4114,\n",
       "            0.4104, 0.4102, 0.4094, 0.4092, 0.4087, 0.4084, 0.407 , 0.4058,\n",
       "            0.4053, 0.4043, 0.4038, 0.4036, 0.403 , 0.4023, 0.4014, 0.401 ,\n",
       "            0.4001, 0.3987, 0.3984, 0.398 , 0.3975, 0.3972, 0.3967, 0.3962,\n",
       "            0.3958, 0.3933, 0.3923, 0.39  , 0.3877, 0.387 , 0.3855, 0.3853,\n",
       "            0.3835, 0.3706, 0.3662, 0.362 , 0.361 , 0.3525, 0.3518, 0.3508,\n",
       "            0.3489, 0.3464, 0.3452, 0.3438, 0.33  , 0.3298, 0.3262, 0.31  ,\n",
       "            0.3054, 0.305 , 0.3035, 0.3032, 0.301 , 0.2969, 0.2903, 0.2844,\n",
       "            0.284 , 0.2837, 0.2698, 0.2676, 0.265 , 0.2622, 0.2375, 0.2306,\n",
       "            0.2252, 0.2211, 0.1953, 0.1925, 0.1913], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.0546875, dtype=float32),\n",
       "    'tpr': array(0.852459, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.0546875, 0.0546875,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0546875, 0.0546875, 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.1015625, 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.1171875, 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.125    , 0.1328125, 0.1328125, 0.140625 , 0.1484375, 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.265625 , 0.2734375, 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.515625 , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6803279 , 0.6885246 , 0.704918  , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.73770493, 0.74590164, 0.76229507, 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.90163934, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.779 , 0.775 , 0.7446, 0.738 , 0.7354, 0.734 , 0.7285,\n",
       "            0.715 , 0.714 , 0.713 , 0.6997, 0.6953, 0.6895, 0.678 , 0.6777,\n",
       "            0.677 , 0.6733, 0.6714, 0.662 , 0.6606, 0.6597, 0.659 , 0.653 ,\n",
       "            0.65  , 0.6494, 0.6475, 0.6465, 0.6436, 0.6406, 0.636 , 0.6353,\n",
       "            0.635 , 0.6343, 0.631 , 0.627 , 0.6216, 0.6206, 0.611 , 0.604 ,\n",
       "            0.603 , 0.595 , 0.5947, 0.5933, 0.5903, 0.589 , 0.588 , 0.5874,\n",
       "            0.586 , 0.5854, 0.5845, 0.584 , 0.582 , 0.5728, 0.569 , 0.5684,\n",
       "            0.565 , 0.564 , 0.5635, 0.562 , 0.561 , 0.56  , 0.5586, 0.5576,\n",
       "            0.5566, 0.554 , 0.5537, 0.5503, 0.549 , 0.5483, 0.5474, 0.547 ,\n",
       "            0.5464, 0.5444, 0.543 , 0.5415, 0.535 , 0.5347, 0.532 , 0.5312,\n",
       "            0.528 , 0.5273, 0.526 , 0.524 , 0.5234, 0.523 , 0.5225, 0.5195,\n",
       "            0.5166, 0.516 , 0.5156, 0.515 , 0.5146, 0.51  , 0.5093, 0.506 ,\n",
       "            0.505 , 0.5034, 0.503 , 0.501 , 0.4988, 0.498 , 0.4963, 0.4941,\n",
       "            0.4917, 0.4915, 0.4902, 0.4885, 0.4856, 0.4834, 0.482 , 0.4814,\n",
       "            0.4805, 0.478 , 0.4768, 0.4763, 0.4756, 0.474 , 0.4712, 0.4702,\n",
       "            0.4675, 0.4653, 0.465 , 0.4626, 0.461 , 0.4607, 0.4575, 0.4556,\n",
       "            0.455 , 0.4548, 0.4543, 0.4524, 0.4521, 0.452 , 0.449 , 0.4463,\n",
       "            0.4456, 0.4448, 0.4426, 0.4414, 0.4407, 0.4404, 0.4392, 0.4377,\n",
       "            0.437 , 0.4355, 0.434 , 0.4324, 0.4321, 0.4314, 0.43  , 0.4297,\n",
       "            0.4255, 0.425 , 0.4238, 0.423 , 0.4226, 0.4224, 0.422 , 0.4216,\n",
       "            0.419 , 0.4182, 0.4177, 0.4175, 0.417 , 0.4163, 0.416 , 0.4143,\n",
       "            0.4138, 0.4119, 0.4114, 0.4106, 0.4102, 0.41  , 0.4094, 0.4092,\n",
       "            0.4087, 0.4084, 0.4082, 0.408 , 0.407 , 0.4028, 0.4016, 0.401 ,\n",
       "            0.4006, 0.3992, 0.3965, 0.396 , 0.394 , 0.3918, 0.3914, 0.374 ,\n",
       "            0.3708, 0.3662, 0.3652, 0.3552, 0.353 , 0.3513, 0.3486, 0.348 ,\n",
       "            0.3464, 0.3315, 0.331 , 0.3281, 0.3093, 0.3052, 0.3037, 0.3025,\n",
       "            0.3018, 0.3003, 0.2969, 0.2883, 0.282 , 0.2815, 0.2812, 0.267 ,\n",
       "            0.2646, 0.2634, 0.2617, 0.2588, 0.2347, 0.233 , 0.2263, 0.222 ,\n",
       "            0.2158, 0.1903, 0.1876, 0.1858], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.0859375, dtype=float32),\n",
       "    'tpr': array(0.91803277, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0546875, 0.0546875, 0.0546875, 0.0546875,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.078125 , 0.078125 , 0.078125 , 0.078125 , 0.0859375,\n",
       "            0.0859375, 0.1015625, 0.109375 , 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.125    , 0.125    , 0.125    , 0.1328125, 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.234375 , 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4453125,\n",
       "            0.453125 , 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.5390625, 0.546875 , 0.5546875, 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.71311474, 0.71311474, 0.71311474, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.795082  , 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.809 , 0.804 , 0.775 , 0.7686, 0.7666, 0.766 , 0.7607,\n",
       "            0.746 , 0.7446, 0.743 , 0.741 , 0.7275, 0.724 , 0.7173, 0.708 ,\n",
       "            0.705 , 0.7046, 0.702 , 0.7017, 0.6934, 0.689 , 0.6865, 0.6797,\n",
       "            0.6787, 0.6753, 0.674 , 0.6733, 0.6724, 0.669 , 0.664 , 0.663 ,\n",
       "            0.6616, 0.66  , 0.653 , 0.6475, 0.645 , 0.6357, 0.631 , 0.628 ,\n",
       "            0.6235, 0.622 , 0.618 , 0.6177, 0.616 , 0.6147, 0.6143, 0.613 ,\n",
       "            0.611 , 0.61  , 0.6094, 0.6064, 0.5986, 0.597 , 0.596 , 0.591 ,\n",
       "            0.59  , 0.589 , 0.5884, 0.5874, 0.587 , 0.586 , 0.585 , 0.583 ,\n",
       "            0.5815, 0.5806, 0.577 , 0.5767, 0.576 , 0.5757, 0.5728, 0.5713,\n",
       "            0.571 , 0.5703, 0.569 , 0.5684, 0.568 , 0.567 , 0.5605, 0.556 ,\n",
       "            0.5557, 0.555 , 0.5547, 0.5522, 0.5513, 0.55  , 0.5493, 0.5454,\n",
       "            0.544 , 0.543 , 0.5425, 0.542 , 0.5405, 0.539 , 0.5366, 0.536 ,\n",
       "            0.5356, 0.534 , 0.5337, 0.528 , 0.527 , 0.526 , 0.5244, 0.522 ,\n",
       "            0.5215, 0.519 , 0.518 , 0.512 , 0.5107, 0.5103, 0.51  , 0.5073,\n",
       "            0.5063, 0.5024, 0.5015, 0.5   , 0.498 , 0.4958, 0.4956, 0.4934,\n",
       "            0.49  , 0.4897, 0.4824, 0.4773, 0.4753, 0.474 , 0.4734, 0.4727,\n",
       "            0.4722, 0.4707, 0.4695, 0.468 , 0.4668, 0.4663, 0.4656, 0.4653,\n",
       "            0.4612, 0.4597, 0.459 , 0.4585, 0.4573, 0.4565, 0.4556, 0.455 ,\n",
       "            0.4546, 0.454 , 0.451 , 0.4504, 0.4497, 0.4475, 0.4465, 0.4453,\n",
       "            0.4446, 0.4438, 0.4436, 0.44  , 0.4397, 0.439 , 0.4385, 0.438 ,\n",
       "            0.4377, 0.4375, 0.4368, 0.4353, 0.4316, 0.4312, 0.431 , 0.4297,\n",
       "            0.4282, 0.428 , 0.4275, 0.4272, 0.4265, 0.4263, 0.4248, 0.4246,\n",
       "            0.4236, 0.4233, 0.4211, 0.4207, 0.418 , 0.4175, 0.4165, 0.4155,\n",
       "            0.414 , 0.4128, 0.4116, 0.4111, 0.4077, 0.398 , 0.3975, 0.3787,\n",
       "            0.3784, 0.3748, 0.3718, 0.359 , 0.3586, 0.3564, 0.3545, 0.3528,\n",
       "            0.352 , 0.3496, 0.3337, 0.3335, 0.3296, 0.3103, 0.305 , 0.3032,\n",
       "            0.3018, 0.301 , 0.3003, 0.2993, 0.2869, 0.281 , 0.2798, 0.2795,\n",
       "            0.2644, 0.2622, 0.2612, 0.259 , 0.2563, 0.2314, 0.2302, 0.222 ,\n",
       "            0.2184, 0.2119, 0.1873, 0.1824, 0.1804], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.125, dtype=float32),\n",
       "    'tpr': array(0.9508197, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0546875,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0546875, 0.0546875, 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.078125 , 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.0859375, 0.0859375, 0.0859375, 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.125    , 0.125    , 0.125    , 0.125    ,\n",
       "            0.125    , 0.125    , 0.1328125, 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.25     , 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.515625 , 0.5234375, 0.53125  , 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5327869 , 0.5409836 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.71311474, 0.72131145,\n",
       "            0.73770493, 0.75409836, 0.76229507, 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8296, 0.8247, 0.797 , 0.789 , 0.788 , 0.7866, 0.782 ,\n",
       "            0.767 , 0.765 , 0.7646, 0.7617, 0.7476, 0.7446, 0.7373, 0.728 ,\n",
       "            0.725 , 0.724 , 0.7227, 0.721 , 0.7134, 0.7085, 0.706 , 0.7056,\n",
       "            0.699 , 0.698 , 0.6943, 0.6924, 0.6914, 0.688 , 0.6836, 0.6816,\n",
       "            0.68  , 0.6797, 0.671 , 0.6665, 0.663 , 0.654 , 0.649 , 0.645 ,\n",
       "            0.6416, 0.64  , 0.6377, 0.6357, 0.6353, 0.634 , 0.6323, 0.628 ,\n",
       "            0.626 , 0.6235, 0.6226, 0.6216, 0.613 , 0.6123, 0.612 , 0.6113,\n",
       "            0.61  , 0.6084, 0.6074, 0.603 , 0.6025, 0.6016, 0.601 , 0.5996,\n",
       "            0.599 , 0.5977, 0.597 , 0.5957, 0.5923, 0.591 , 0.59  , 0.5894,\n",
       "            0.5874, 0.584 , 0.5806, 0.575 , 0.5747, 0.573 , 0.5713, 0.5703,\n",
       "            0.57  , 0.569 , 0.568 , 0.564 , 0.5625, 0.5615, 0.5596, 0.559 ,\n",
       "            0.5586, 0.5576, 0.553 , 0.5527, 0.55  , 0.5493, 0.548 , 0.545 ,\n",
       "            0.542 , 0.541 , 0.5405, 0.5386, 0.537 , 0.531 , 0.5303, 0.524 ,\n",
       "            0.5234, 0.5225, 0.521 , 0.5186, 0.518 , 0.5176, 0.516 , 0.5156,\n",
       "            0.515 , 0.512 , 0.5117, 0.509 , 0.505 , 0.503 , 0.4988, 0.495 ,\n",
       "            0.4927, 0.4863, 0.4854, 0.4846, 0.4844, 0.4841, 0.482 , 0.4812,\n",
       "            0.48  , 0.478 , 0.476 , 0.4744, 0.4739, 0.4727, 0.47  , 0.4697,\n",
       "            0.4683, 0.4678, 0.4673, 0.4666, 0.4653, 0.465 , 0.4639, 0.4622,\n",
       "            0.461 , 0.4585, 0.457 , 0.456 , 0.4548, 0.4543, 0.4539, 0.4534,\n",
       "            0.4512, 0.4502, 0.45  , 0.4485, 0.4465, 0.4458, 0.4453, 0.445 ,\n",
       "            0.4446, 0.4443, 0.444 , 0.4438, 0.4436, 0.4421, 0.4417, 0.438 ,\n",
       "            0.4375, 0.4365, 0.4353, 0.4346, 0.434 , 0.4338, 0.4329, 0.432 ,\n",
       "            0.4316, 0.4314, 0.4302, 0.428 , 0.4246, 0.4243, 0.4236, 0.4207,\n",
       "            0.4204, 0.4202, 0.4194, 0.4192, 0.4175, 0.4114, 0.4028, 0.4016,\n",
       "            0.3828, 0.3809, 0.3792, 0.3752, 0.3606, 0.36  , 0.3577, 0.3557,\n",
       "            0.3552, 0.3535, 0.3508, 0.334 , 0.3337, 0.3298, 0.3088, 0.3032,\n",
       "            0.3013, 0.3003, 0.2998, 0.2983, 0.2974, 0.2837, 0.2783, 0.2766,\n",
       "            0.2764, 0.2607, 0.2585, 0.2583, 0.2551, 0.252 , 0.2277, 0.2256,\n",
       "            0.2172, 0.214 , 0.2065, 0.1824, 0.177 , 0.1744], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.125, dtype=float32),\n",
       "    'tpr': array(0.9836066, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.0546875,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.078125 , 0.0859375,\n",
       "            0.0859375, 0.0859375, 0.0859375, 0.0859375, 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.109375 , 0.1171875, 0.125    , 0.125    ,\n",
       "            0.125    , 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.1484375,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.546875 , 0.5546875, 0.5625   , 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.73770493, 0.76229507, 0.77868855,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.848 , 0.843 , 0.818 , 0.808 , 0.8066, 0.8057, 0.8013,\n",
       "            0.786 , 0.785 , 0.784 , 0.7817, 0.7676, 0.7637, 0.757 , 0.747 ,\n",
       "            0.745 , 0.743 , 0.7407, 0.74  , 0.732 , 0.7275, 0.7266, 0.7246,\n",
       "            0.7188, 0.7163, 0.7134, 0.7114, 0.7104, 0.7095, 0.7056, 0.701 ,\n",
       "            0.6997, 0.699 , 0.698 , 0.6973, 0.689 , 0.686 , 0.681 , 0.673 ,\n",
       "            0.669 , 0.6655, 0.6626, 0.6616, 0.6577, 0.6562, 0.652 , 0.6514,\n",
       "            0.651 , 0.6494, 0.648 , 0.6436, 0.6426, 0.6396, 0.6377, 0.6367,\n",
       "            0.6357, 0.6343, 0.6333, 0.632 , 0.6274, 0.627 , 0.6265, 0.6245,\n",
       "            0.624 , 0.621 , 0.6206, 0.6167, 0.6157, 0.6147, 0.6143, 0.614 ,\n",
       "            0.6133, 0.6123, 0.612 , 0.6104, 0.6084, 0.607 , 0.601 , 0.599 ,\n",
       "            0.5967, 0.5957, 0.594 , 0.5913, 0.5903, 0.5845, 0.5835, 0.582 ,\n",
       "            0.5796, 0.579 , 0.576 , 0.573 , 0.5728, 0.5713, 0.5693, 0.5645,\n",
       "            0.564 , 0.5605, 0.5596, 0.559 , 0.5566, 0.5557, 0.542 , 0.5415,\n",
       "            0.535 , 0.5347, 0.533 , 0.5327, 0.532 , 0.5317, 0.531 , 0.528 ,\n",
       "            0.5234, 0.523 , 0.521 , 0.5205, 0.5176, 0.515 , 0.513 , 0.5093,\n",
       "            0.509 , 0.504 , 0.497 , 0.4966, 0.4954, 0.4946, 0.4922, 0.4902,\n",
       "            0.4883, 0.486 , 0.4822, 0.482 , 0.4775, 0.4773, 0.4758, 0.4756,\n",
       "            0.4744, 0.474 , 0.4731, 0.4724, 0.4717, 0.468 , 0.4668, 0.4663,\n",
       "            0.464 , 0.4636, 0.4634, 0.4597, 0.4595, 0.4585, 0.4583, 0.4565,\n",
       "            0.4543, 0.454 , 0.4534, 0.4524, 0.4517, 0.4495, 0.4492, 0.449 ,\n",
       "            0.4475, 0.4473, 0.446 , 0.4453, 0.444 , 0.441 , 0.4404, 0.4402,\n",
       "            0.4397, 0.4387, 0.438 , 0.4377, 0.4365, 0.4353, 0.435 , 0.4348,\n",
       "            0.4338, 0.4326, 0.4302, 0.4275, 0.426 , 0.4253, 0.4248, 0.4216,\n",
       "            0.4214, 0.4192, 0.4172, 0.4116, 0.4087, 0.3882, 0.3845, 0.3843,\n",
       "            0.38  , 0.3647, 0.363 , 0.3604, 0.3591, 0.3584, 0.356 , 0.3542,\n",
       "            0.3347, 0.3345, 0.3328, 0.3083, 0.3037, 0.3005, 0.3003, 0.299 ,\n",
       "            0.2969, 0.2966, 0.282 , 0.2764, 0.2744, 0.2742, 0.2583, 0.258 ,\n",
       "            0.2556, 0.2524, 0.249 , 0.2257, 0.2213, 0.2133, 0.2118, 0.2017,\n",
       "            0.178 , 0.1729, 0.1698], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1875, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0546875,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.0859375, 0.0859375,\n",
       "            0.09375  , 0.109375 , 0.109375 , 0.109375 , 0.1171875, 0.125    ,\n",
       "            0.125    , 0.125    , 0.125    , 0.1328125, 0.140625 , 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.2704918 , 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8696, 0.8643, 0.842 , 0.831 , 0.8306, 0.8286, 0.8247,\n",
       "            0.809 , 0.807 , 0.8047, 0.7905, 0.7866, 0.78  , 0.7705, 0.7686,\n",
       "            0.766 , 0.764 , 0.763 , 0.7554, 0.75  , 0.747 , 0.742 , 0.7393,\n",
       "            0.7363, 0.734 , 0.733 , 0.7324, 0.7285, 0.724 , 0.722 , 0.72  ,\n",
       "            0.711 , 0.7095, 0.7026, 0.701 , 0.6963, 0.696 , 0.6914, 0.6875,\n",
       "            0.6836, 0.6816, 0.6797, 0.678 , 0.6777, 0.674 , 0.67  , 0.6694,\n",
       "            0.667 , 0.6665, 0.6655, 0.6646, 0.663 , 0.6626, 0.6616, 0.6606,\n",
       "            0.66  , 0.6587, 0.656 , 0.654 , 0.652 , 0.649 , 0.6484, 0.647 ,\n",
       "            0.642 , 0.6406, 0.639 , 0.6387, 0.637 , 0.6367, 0.6357, 0.6343,\n",
       "            0.632 , 0.626 , 0.622 , 0.621 , 0.6206, 0.616 , 0.6147, 0.6133,\n",
       "            0.61  , 0.606 , 0.605 , 0.604 , 0.6035, 0.6025, 0.602 , 0.601 ,\n",
       "            0.5996, 0.596 , 0.5947, 0.592 , 0.588 , 0.5874, 0.586 , 0.5845,\n",
       "            0.582 , 0.581 , 0.5786, 0.578 , 0.5767, 0.5757, 0.5615, 0.558 ,\n",
       "            0.5576, 0.555 , 0.553 , 0.5513, 0.5503, 0.5493, 0.548 , 0.547 ,\n",
       "            0.542 , 0.5415, 0.54  , 0.536 , 0.535 , 0.5347, 0.5283, 0.528 ,\n",
       "            0.526 , 0.5205, 0.518 , 0.513 , 0.512 , 0.5073, 0.507 , 0.506 ,\n",
       "            0.504 , 0.5015, 0.501 , 0.4998, 0.4946, 0.4932, 0.493 , 0.4927,\n",
       "            0.4917, 0.4893, 0.4875, 0.4858, 0.4846, 0.4844, 0.483 , 0.4827,\n",
       "            0.4812, 0.4792, 0.4778, 0.4763, 0.4746, 0.4727, 0.471 , 0.4707,\n",
       "            0.4697, 0.4695, 0.4685, 0.4683, 0.4678, 0.4666, 0.4648, 0.462 ,\n",
       "            0.4617, 0.46  , 0.4585, 0.4583, 0.4568, 0.4563, 0.4558, 0.4546,\n",
       "            0.451 , 0.4507, 0.4502, 0.4492, 0.4485, 0.448 , 0.4465, 0.4458,\n",
       "            0.4453, 0.444 , 0.4434, 0.443 , 0.4414, 0.4363, 0.435 , 0.434 ,\n",
       "            0.4338, 0.4312, 0.4297, 0.4292, 0.427 , 0.424 , 0.4214, 0.4165,\n",
       "            0.395 , 0.3916, 0.3887, 0.3855, 0.3696, 0.3662, 0.3638, 0.363 ,\n",
       "            0.3616, 0.3591, 0.358 , 0.3364, 0.3354, 0.335 , 0.3083, 0.3042,\n",
       "            0.3025, 0.2993, 0.2983, 0.2961, 0.2957, 0.2805, 0.2747, 0.2722,\n",
       "            0.2576, 0.2556, 0.253 , 0.2494, 0.246 , 0.2239, 0.2177, 0.2095,\n",
       "            0.2094, 0.1973, 0.1744, 0.1686, 0.1653], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.234375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.0546875,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.0859375, 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.09375  , 0.109375 , 0.109375 , 0.1171875,\n",
       "            0.125    , 0.125    , 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1484375, 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.765625 , 0.7734375,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.2704918 , 0.28688523, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.43442622, 0.44262296,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.63114756,\n",
       "            0.6393443 , 0.6393443 , 0.647541  , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.90163934, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8867, 0.8813, 0.86  , 0.8496, 0.847 , 0.844 , 0.8286,\n",
       "            0.828 , 0.8267, 0.824 , 0.81  , 0.806 , 0.8003, 0.79  , 0.788 ,\n",
       "            0.7856, 0.784 , 0.7827, 0.7754, 0.7695, 0.769 , 0.7666, 0.7617,\n",
       "            0.759 , 0.755 , 0.754 , 0.7524, 0.752 , 0.748 , 0.744 , 0.741 ,\n",
       "            0.7397, 0.73  , 0.7285, 0.725 , 0.722 , 0.7207, 0.715 , 0.7124,\n",
       "            0.708 , 0.7065, 0.702 , 0.6987, 0.6973, 0.697 , 0.696 , 0.6934,\n",
       "            0.693 , 0.69  , 0.6885, 0.688 , 0.687 , 0.685 , 0.684 , 0.6836,\n",
       "            0.6826, 0.6816, 0.681 , 0.6807, 0.6777, 0.6772, 0.676 , 0.6704,\n",
       "            0.667 , 0.666 , 0.664 , 0.6636, 0.6616, 0.6533, 0.652 , 0.6504,\n",
       "            0.6494, 0.649 , 0.6465, 0.6426, 0.6416, 0.64  , 0.6377, 0.636 ,\n",
       "            0.6294, 0.629 , 0.6284, 0.6274, 0.626 , 0.624 , 0.619 , 0.6167,\n",
       "            0.616 , 0.615 , 0.6147, 0.611 , 0.6104, 0.61  , 0.609 , 0.604 ,\n",
       "            0.6035, 0.6016, 0.6   , 0.5957, 0.5938, 0.592 , 0.5815, 0.578 ,\n",
       "            0.576 , 0.572 , 0.5713, 0.57  , 0.5645, 0.563 , 0.5615, 0.561 ,\n",
       "            0.5605, 0.559 , 0.556 , 0.5547, 0.553 , 0.5493, 0.543 , 0.541 ,\n",
       "            0.539 , 0.5317, 0.5312, 0.5293, 0.5283, 0.522 , 0.5195, 0.5166,\n",
       "            0.5146, 0.514 , 0.513 , 0.5117, 0.51  , 0.5083, 0.5054, 0.502 ,\n",
       "            0.498 , 0.497 , 0.4963, 0.4954, 0.4944, 0.4941, 0.494 , 0.492 ,\n",
       "            0.491 , 0.4902, 0.4895, 0.4883, 0.4836, 0.4834, 0.4832, 0.4805,\n",
       "            0.4795, 0.4792, 0.4788, 0.4778, 0.4766, 0.4744, 0.4731, 0.4707,\n",
       "            0.4688, 0.4685, 0.4673, 0.4666, 0.4663, 0.4634, 0.4631, 0.4624,\n",
       "            0.462 , 0.4578, 0.4568, 0.4565, 0.4556, 0.4543, 0.454 , 0.4531,\n",
       "            0.4512, 0.4507, 0.4504, 0.4487, 0.4417, 0.4412, 0.441 , 0.4404,\n",
       "            0.4365, 0.436 , 0.4333, 0.4321, 0.43  , 0.424 , 0.3992, 0.396 ,\n",
       "            0.3914, 0.39  , 0.3735, 0.3684, 0.366 , 0.363 , 0.361 , 0.34  ,\n",
       "            0.3352, 0.3342, 0.3071, 0.3042, 0.3022, 0.2974, 0.2969, 0.2947,\n",
       "            0.2932, 0.2783, 0.2722, 0.2693, 0.2576, 0.2527, 0.2496, 0.246 ,\n",
       "            0.2422, 0.222 , 0.213 , 0.2074, 0.2053, 0.1923, 0.1698, 0.1646,\n",
       "            0.161 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.234375, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.0859375, 0.0859375, 0.0859375, 0.09375  , 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.1171875, 0.1171875, 0.125    , 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.234375 , 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6229508 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.89344263, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8955, 0.891 , 0.8735, 0.859 , 0.8574, 0.8564, 0.852 ,\n",
       "            0.842 , 0.8364, 0.836 , 0.821 , 0.8154, 0.811 , 0.8   , 0.7983,\n",
       "            0.7954, 0.7915, 0.791 , 0.7817, 0.781 , 0.778 , 0.7754, 0.7734,\n",
       "            0.766 , 0.7656, 0.763 , 0.7607, 0.7583, 0.755 , 0.752 , 0.7495,\n",
       "            0.748 , 0.7466, 0.746 , 0.7446, 0.741 , 0.738 , 0.7363, 0.731 ,\n",
       "            0.726 , 0.721 , 0.71  , 0.709 , 0.7085, 0.708 , 0.7056, 0.7036,\n",
       "            0.7017, 0.701 , 0.7   , 0.6997, 0.6987, 0.696 , 0.695 , 0.6943,\n",
       "            0.694 , 0.692 , 0.691 , 0.6904, 0.688 , 0.687 , 0.6865, 0.686 ,\n",
       "            0.6855, 0.679 , 0.6772, 0.6763, 0.6753, 0.675 , 0.6724, 0.668 ,\n",
       "            0.6597, 0.6562, 0.6553, 0.655 , 0.6543, 0.6514, 0.6494, 0.649 ,\n",
       "            0.6475, 0.644 , 0.642 , 0.6377, 0.636 , 0.635 , 0.6343, 0.6333,\n",
       "            0.633 , 0.626 , 0.6245, 0.617 , 0.6167, 0.615 , 0.614 , 0.6123,\n",
       "            0.609 , 0.608 , 0.6064, 0.6045, 0.602 , 0.5894, 0.5845, 0.5835,\n",
       "            0.578 , 0.5776, 0.577 , 0.5728, 0.5713, 0.568 , 0.5674, 0.561 ,\n",
       "            0.5596, 0.5586, 0.5557, 0.553 , 0.5513, 0.551 , 0.542 , 0.538 ,\n",
       "            0.537 , 0.5366, 0.5293, 0.529 , 0.528 , 0.527 , 0.526 , 0.5244,\n",
       "            0.5156, 0.5146, 0.514 , 0.512 , 0.511 , 0.5103, 0.503 , 0.502 ,\n",
       "            0.501 , 0.5005, 0.4934, 0.4924, 0.49  , 0.4846, 0.4822, 0.4814,\n",
       "            0.479 , 0.4785, 0.4775, 0.4768, 0.4763, 0.474 , 0.4734, 0.4714,\n",
       "            0.4702, 0.4673, 0.4663, 0.4653, 0.465 , 0.4648, 0.4646, 0.4624,\n",
       "            0.46  , 0.4585, 0.455 , 0.4539, 0.4524, 0.4504, 0.4495, 0.4485,\n",
       "            0.4482, 0.4453, 0.4443, 0.443 , 0.4426, 0.4407, 0.4395, 0.4392,\n",
       "            0.439 , 0.4387, 0.4375, 0.4355, 0.4353, 0.4343, 0.4336, 0.432 ,\n",
       "            0.4312, 0.4287, 0.4282, 0.427 , 0.4233, 0.419 , 0.4153, 0.4136,\n",
       "            0.4126, 0.4097, 0.3987, 0.3977, 0.3892, 0.3875, 0.371 , 0.3643,\n",
       "            0.3625, 0.3623, 0.3599, 0.358 , 0.3574, 0.3374, 0.3298, 0.3286,\n",
       "            0.3018, 0.301 , 0.2993, 0.2915, 0.291 , 0.289 , 0.2876, 0.2722,\n",
       "            0.2664, 0.263 , 0.2627, 0.254 , 0.2462, 0.243 , 0.2395, 0.2355,\n",
       "            0.2173, 0.207 , 0.2024, 0.1987, 0.1857, 0.1649, 0.1586, 0.155 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3203125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0546875, 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0703125, 0.078125 ,\n",
       "            0.0859375, 0.0859375, 0.0859375, 0.09375  , 0.09375  , 0.09375  ,\n",
       "            0.109375 , 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.1328125,\n",
       "            0.140625 , 0.140625 , 0.1484375, 0.15625  , 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     , 0.25     ,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.765625 , 0.7734375, 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8278689 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9165, 0.9116, 0.895 , 0.8833, 0.881 , 0.878 , 0.865 ,\n",
       "            0.864 , 0.8613, 0.8594, 0.846 , 0.8423, 0.836 , 0.8267, 0.825 ,\n",
       "            0.8223, 0.821 , 0.8193, 0.812 , 0.8066, 0.803 , 0.7993, 0.7954,\n",
       "            0.792 , 0.79  , 0.7886, 0.788 , 0.784 , 0.7803, 0.7783, 0.7773,\n",
       "            0.7764, 0.776 , 0.775 , 0.7695, 0.768 , 0.766 , 0.7646, 0.7573,\n",
       "            0.757 , 0.753 , 0.752 , 0.7417, 0.7397, 0.7393, 0.737 , 0.735 ,\n",
       "            0.734 , 0.732 , 0.7314, 0.7295, 0.7275, 0.727 , 0.7266, 0.726 ,\n",
       "            0.7256, 0.7227, 0.722 , 0.7197, 0.717 , 0.7163, 0.7144, 0.712 ,\n",
       "            0.7114, 0.709 , 0.7065, 0.706 , 0.7026, 0.7007, 0.697 , 0.695 ,\n",
       "            0.6885, 0.685 , 0.684 , 0.6836, 0.683 , 0.6807, 0.679 , 0.6772,\n",
       "            0.6743, 0.6733, 0.6665, 0.666 , 0.6655, 0.665 , 0.663 , 0.6616,\n",
       "            0.6597, 0.6587, 0.654 , 0.651 , 0.6494, 0.646 , 0.6455, 0.6445,\n",
       "            0.643 , 0.637 , 0.6367, 0.6333, 0.6294, 0.6274, 0.6187, 0.616 ,\n",
       "            0.6133, 0.6104, 0.607 , 0.6016, 0.6006, 0.5996, 0.599 , 0.5957,\n",
       "            0.595 , 0.5864, 0.5845, 0.583 , 0.5825, 0.5815, 0.58  , 0.576 ,\n",
       "            0.569 , 0.5684, 0.5596, 0.5586, 0.553 , 0.552 , 0.5513, 0.5493,\n",
       "            0.547 , 0.544 , 0.538 , 0.536 , 0.5347, 0.533 , 0.5327, 0.5312,\n",
       "            0.53  , 0.529 , 0.5273, 0.5205, 0.5195, 0.517 , 0.516 , 0.5146,\n",
       "            0.509 , 0.508 , 0.5073, 0.507 , 0.5063, 0.5054, 0.5034, 0.499 ,\n",
       "            0.4978, 0.4973, 0.497 , 0.494 , 0.4934, 0.493 , 0.4912, 0.49  ,\n",
       "            0.488 , 0.4875, 0.487 , 0.486 , 0.4841, 0.4814, 0.4802, 0.479 ,\n",
       "            0.4778, 0.474 , 0.4736, 0.4731, 0.4724, 0.469 , 0.468 , 0.4636,\n",
       "            0.4634, 0.4624, 0.461 , 0.4607, 0.46  , 0.4597, 0.459 , 0.4573,\n",
       "            0.4548, 0.4546, 0.453 , 0.4504, 0.4487, 0.448 , 0.445 , 0.4438,\n",
       "            0.4421, 0.4387, 0.438 , 0.4375, 0.4348, 0.4346, 0.4102, 0.4062,\n",
       "            0.3994, 0.3955, 0.3784, 0.371 , 0.3694, 0.3667, 0.3643, 0.343 ,\n",
       "            0.333 , 0.3318, 0.3054, 0.304 , 0.3015, 0.293 , 0.2925, 0.2903,\n",
       "            0.2893, 0.273 , 0.2668, 0.2627, 0.2625, 0.2546, 0.2451, 0.2421,\n",
       "            0.2382, 0.234 , 0.2157, 0.2051, 0.2002, 0.1958, 0.1823, 0.1621,\n",
       "            0.1545, 0.151 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.09375  ,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.140625 ,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.171875 , 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.203125 , 0.2109375, 0.21875  , 0.234375 , 0.2421875,\n",
       "            0.25     , 0.25     , 0.265625 , 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4375   , 0.4453125, 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9272, 0.923 , 0.907 , 0.8965, 0.896 , 0.894 , 0.891 ,\n",
       "            0.8784, 0.8774, 0.8755, 0.8726, 0.861 , 0.857 , 0.851 , 0.8413,\n",
       "            0.84  , 0.837 , 0.8354, 0.834 , 0.8267, 0.822 , 0.8213, 0.8184,\n",
       "            0.8145, 0.81  , 0.8066, 0.8057, 0.8037, 0.8027, 0.7993, 0.795 ,\n",
       "            0.7944, 0.7935, 0.7925, 0.791 , 0.789 , 0.7837, 0.7812, 0.776 ,\n",
       "            0.7715, 0.7686, 0.7637, 0.759 , 0.7563, 0.755 , 0.753 , 0.7515,\n",
       "            0.751 , 0.7505, 0.75  , 0.7495, 0.748 , 0.7466, 0.746 , 0.744 ,\n",
       "            0.7417, 0.74  , 0.7397, 0.737 , 0.7354, 0.734 , 0.731 , 0.7295,\n",
       "            0.729 , 0.726 , 0.7256, 0.723 , 0.7197, 0.712 , 0.7104, 0.7065,\n",
       "            0.7007, 0.699 , 0.6987, 0.6973, 0.6963, 0.694 , 0.688 , 0.6875,\n",
       "            0.687 , 0.6865, 0.686 , 0.684 , 0.6826, 0.68  , 0.678 , 0.6743,\n",
       "            0.6714, 0.671 , 0.667 , 0.6665, 0.663 , 0.657 , 0.6567, 0.6562,\n",
       "            0.656 , 0.6523, 0.6475, 0.6465, 0.641 , 0.633 , 0.63  , 0.628 ,\n",
       "            0.6255, 0.625 , 0.618 , 0.617 , 0.6167, 0.606 , 0.605 , 0.6025,\n",
       "            0.597 , 0.5957, 0.595 , 0.593 , 0.5923, 0.5913, 0.586 , 0.583 ,\n",
       "            0.576 , 0.5684, 0.5674, 0.5664, 0.565 , 0.5635, 0.5625, 0.5586,\n",
       "            0.5537, 0.549 , 0.5483, 0.548 , 0.544 , 0.541 , 0.5386, 0.536 ,\n",
       "            0.529 , 0.525 , 0.5244, 0.521 , 0.5176, 0.5156, 0.513 , 0.5107,\n",
       "            0.5103, 0.5093, 0.5083, 0.508 , 0.5073, 0.507 , 0.503 , 0.501 ,\n",
       "            0.5   , 0.4963, 0.4954, 0.4949, 0.4934, 0.4893, 0.487 , 0.484 ,\n",
       "            0.4836, 0.481 , 0.4788, 0.4766, 0.4756, 0.475 , 0.4746, 0.47  ,\n",
       "            0.4697, 0.4668, 0.4666, 0.465 , 0.4646, 0.464 , 0.461 , 0.46  ,\n",
       "            0.459 , 0.458 , 0.4565, 0.4563, 0.4548, 0.4536, 0.4524, 0.4485,\n",
       "            0.4438, 0.443 , 0.4424, 0.441 , 0.4392, 0.4373, 0.4343, 0.4138,\n",
       "            0.4072, 0.4026, 0.3977, 0.3828, 0.3726, 0.3718, 0.3706, 0.3667,\n",
       "            0.3652, 0.3477, 0.332 , 0.3303, 0.3044, 0.301 , 0.3008, 0.2903,\n",
       "            0.288 , 0.2866, 0.27  , 0.263 , 0.259 , 0.2588, 0.2563, 0.2413,\n",
       "            0.2382, 0.234 , 0.2297, 0.2137, 0.1998, 0.1979, 0.1912, 0.1763,\n",
       "            0.1569, 0.1503, 0.1466], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.4140625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.09375  ,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.25     , 0.2578125,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.34375  , 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9404, 0.9365, 0.923 , 0.913 , 0.9126, 0.91  , 0.908 ,\n",
       "            0.8965, 0.8955, 0.893 , 0.89  , 0.879 , 0.8755, 0.8696, 0.861 ,\n",
       "            0.859 , 0.8564, 0.8555, 0.854 , 0.847 , 0.842 , 0.8384, 0.835 ,\n",
       "            0.831 , 0.827 , 0.8257, 0.824 , 0.8237, 0.82  , 0.8193, 0.8164,\n",
       "            0.8145, 0.814 , 0.8135, 0.8125, 0.8115, 0.809 , 0.805 , 0.802 ,\n",
       "            0.8013, 0.7964, 0.792 , 0.79  , 0.784 , 0.7837, 0.7783, 0.778 ,\n",
       "            0.775 , 0.7725, 0.771 , 0.7705, 0.7695, 0.769 , 0.7676, 0.7666,\n",
       "            0.766 , 0.764 , 0.762 , 0.761 , 0.76  , 0.7583, 0.7573, 0.7554,\n",
       "            0.7544, 0.7515, 0.7495, 0.749 , 0.747 , 0.7446, 0.742 , 0.74  ,\n",
       "            0.732 , 0.731 , 0.7256, 0.72  , 0.719 , 0.7188, 0.717 , 0.7163,\n",
       "            0.7144, 0.707 , 0.7065, 0.706 , 0.7046, 0.702 , 0.701 , 0.6987,\n",
       "            0.698 , 0.693 , 0.69  , 0.6895, 0.689 , 0.686 , 0.6855, 0.681 ,\n",
       "            0.676 , 0.675 , 0.674 , 0.6704, 0.6665, 0.6636, 0.659 , 0.65  ,\n",
       "            0.648 , 0.647 , 0.646 , 0.644 , 0.642 , 0.6353, 0.6333, 0.623 ,\n",
       "            0.6216, 0.6187, 0.6123, 0.612 , 0.6094, 0.6084, 0.6074, 0.601 ,\n",
       "            0.598 , 0.593 , 0.5923, 0.582 , 0.5796, 0.5776, 0.5767, 0.572 ,\n",
       "            0.5713, 0.563 , 0.5625, 0.5615, 0.5605, 0.558 , 0.5547, 0.5522,\n",
       "            0.549 , 0.547 , 0.5444, 0.542 , 0.5376, 0.5356, 0.531 , 0.53  ,\n",
       "            0.5293, 0.525 , 0.5244, 0.524 , 0.523 , 0.522 , 0.521 , 0.5205,\n",
       "            0.519 , 0.5186, 0.514 , 0.5137, 0.5127, 0.5117, 0.5073, 0.5044,\n",
       "            0.5034, 0.502 , 0.4978, 0.4963, 0.4956, 0.4937, 0.492 , 0.4912,\n",
       "            0.4902, 0.4875, 0.4863, 0.4858, 0.484 , 0.4795, 0.4775, 0.4744,\n",
       "            0.4739, 0.4727, 0.4722, 0.4712, 0.4695, 0.4673, 0.4648, 0.463 ,\n",
       "            0.4626, 0.4617, 0.46  , 0.459 , 0.4563, 0.4521, 0.4497, 0.4485,\n",
       "            0.4468, 0.445 , 0.4429, 0.44  , 0.424 , 0.4138, 0.4097, 0.4023,\n",
       "            0.3875, 0.3762, 0.3752, 0.3716, 0.37  , 0.3699, 0.3525, 0.3328,\n",
       "            0.3313, 0.3088, 0.3018, 0.3008, 0.29  , 0.2898, 0.2876, 0.2869,\n",
       "            0.269 , 0.2622, 0.2578, 0.2576, 0.2573, 0.239 , 0.2358, 0.2316,\n",
       "            0.2272, 0.2119, 0.1973, 0.196 , 0.1877, 0.1725, 0.1542, 0.1462,\n",
       "            0.1426], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.4765625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.09375  , 0.09375  ,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.1484375, 0.1484375,\n",
       "            0.15625  , 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.265625 ,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.23770492, 0.24590164,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.4180328 , 0.4262295 , 0.44262296,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8032787 , 0.8114754 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9507, 0.9473, 0.9355, 0.926 , 0.9253, 0.924 , 0.922 ,\n",
       "            0.911 , 0.91  , 0.9077, 0.905 , 0.8945, 0.891 , 0.8857, 0.8774,\n",
       "            0.876 , 0.873 , 0.8726, 0.8706, 0.8643, 0.86  , 0.859 , 0.856 ,\n",
       "            0.853 , 0.8486, 0.845 , 0.8438, 0.8423, 0.842 , 0.838 , 0.8345,\n",
       "            0.833 , 0.8325, 0.8315, 0.8306, 0.83  , 0.8257, 0.8247, 0.8203,\n",
       "            0.8105, 0.81  , 0.8086, 0.808 , 0.8022, 0.7983, 0.797 , 0.796 ,\n",
       "            0.7944, 0.7935, 0.7915, 0.791 , 0.7896, 0.7876, 0.7866, 0.784 ,\n",
       "            0.7812, 0.7803, 0.78  , 0.7773, 0.7764, 0.7734, 0.7705, 0.7686,\n",
       "            0.7676, 0.7666, 0.766 , 0.7646, 0.7573, 0.757 , 0.75  , 0.7495,\n",
       "            0.7446, 0.743 , 0.7417, 0.7383, 0.735 , 0.7344, 0.7334, 0.732 ,\n",
       "            0.731 , 0.7305, 0.7275, 0.7256, 0.725 , 0.7246, 0.7217, 0.717 ,\n",
       "            0.7163, 0.7124, 0.712 , 0.711 , 0.7095, 0.7085, 0.7046, 0.6978,\n",
       "            0.694 , 0.6934, 0.692 , 0.6855, 0.684 , 0.677 , 0.672 , 0.6704,\n",
       "            0.665 , 0.6646, 0.6616, 0.6567, 0.6553, 0.654 , 0.639 , 0.6377,\n",
       "            0.6323, 0.6313, 0.6274, 0.626 , 0.624 , 0.6235, 0.618 , 0.6167,\n",
       "            0.608 , 0.601 , 0.6006, 0.598 , 0.597 , 0.5947, 0.5874, 0.5864,\n",
       "            0.5815, 0.5806, 0.5786, 0.578 , 0.576 , 0.5737, 0.5654, 0.5625,\n",
       "            0.5605, 0.56  , 0.5586, 0.551 , 0.5483, 0.547 , 0.546 , 0.5425,\n",
       "            0.5415, 0.539 , 0.5366, 0.536 , 0.5356, 0.5347, 0.534 , 0.5327,\n",
       "            0.5303, 0.53  , 0.5293, 0.5273, 0.525 , 0.52  , 0.518 , 0.514 ,\n",
       "            0.5127, 0.5103, 0.508 , 0.5063, 0.5044, 0.504 , 0.503 , 0.501 ,\n",
       "            0.5005, 0.497 , 0.4966, 0.4937, 0.4934, 0.4893, 0.4866, 0.4846,\n",
       "            0.4841, 0.484 , 0.4834, 0.483 , 0.4817, 0.4805, 0.4763, 0.4758,\n",
       "            0.4734, 0.4717, 0.4714, 0.4697, 0.4683, 0.4666, 0.4644, 0.4639,\n",
       "            0.4575, 0.4563, 0.454 , 0.4534, 0.45  , 0.4478, 0.4333, 0.4194,\n",
       "            0.4155, 0.4075, 0.394 , 0.3806, 0.3801, 0.3796, 0.3757, 0.374 ,\n",
       "            0.3738, 0.3594, 0.334 , 0.3323, 0.3123, 0.302 , 0.3018, 0.2898,\n",
       "            0.2893, 0.287 , 0.2866, 0.268 , 0.2607, 0.2605, 0.256 , 0.2559,\n",
       "            0.2366, 0.2334, 0.229 , 0.2244, 0.2119, 0.1958, 0.194 , 0.1841,\n",
       "            0.1677, 0.1506, 0.1423, 0.1383], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.4765625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.0625   , 0.0625   , 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.1953125, 0.203125 , 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.328125 , 0.3359375,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.8515625,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.36065573,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40983605, 0.4180328 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8114754 , 0.8278689 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9585, 0.9556, 0.9453, 0.9355, 0.9336, 0.9316, 0.9233,\n",
       "            0.921 , 0.919 , 0.917 , 0.907 , 0.9033, 0.899 , 0.89  , 0.886 ,\n",
       "            0.8853, 0.884 , 0.877 , 0.875 , 0.8726, 0.8696, 0.8687, 0.863 ,\n",
       "            0.8604, 0.859 , 0.858 , 0.8564, 0.856 , 0.853 , 0.852 , 0.8486,\n",
       "            0.848 , 0.8467, 0.8457, 0.844 , 0.842 , 0.8413, 0.835 , 0.8296,\n",
       "            0.8267, 0.823 , 0.8193, 0.8174, 0.815 , 0.8145, 0.8125, 0.812 ,\n",
       "            0.8105, 0.8066, 0.805 , 0.8022, 0.802 , 0.8013, 0.8003, 0.795 ,\n",
       "            0.7944, 0.7935, 0.792 , 0.791 , 0.7886, 0.7876, 0.787 , 0.785 ,\n",
       "            0.784 , 0.783 , 0.779 , 0.7783, 0.7705, 0.7656, 0.764 , 0.7637,\n",
       "            0.763 , 0.753 , 0.752 , 0.7515, 0.751 , 0.7485, 0.748 , 0.7466,\n",
       "            0.746 , 0.745 , 0.7417, 0.7393, 0.7363, 0.734 , 0.732 , 0.7314,\n",
       "            0.7295, 0.7246, 0.724 , 0.7173, 0.713 , 0.7075, 0.7056, 0.705 ,\n",
       "            0.6963, 0.6943, 0.6924, 0.692 , 0.6914, 0.6836, 0.675 , 0.6733,\n",
       "            0.6724, 0.656 , 0.6504, 0.649 , 0.638 , 0.635 , 0.6343, 0.6333,\n",
       "            0.6284, 0.6177, 0.6167, 0.616 , 0.6133, 0.6094, 0.605 , 0.602 ,\n",
       "            0.5986, 0.598 , 0.594 , 0.5938, 0.593 , 0.588 , 0.5874, 0.576 ,\n",
       "            0.573 , 0.572 , 0.571 , 0.56  , 0.5586, 0.558 , 0.557 , 0.5566,\n",
       "            0.5527, 0.551 , 0.5503, 0.5464, 0.5454, 0.5444, 0.542 , 0.541 ,\n",
       "            0.54  , 0.5396, 0.5376, 0.536 , 0.5303, 0.5225, 0.5215, 0.5205,\n",
       "            0.518 , 0.512 , 0.5107, 0.5103, 0.509 , 0.5083, 0.5073, 0.507 ,\n",
       "            0.499 , 0.4985, 0.497 , 0.4968, 0.4963, 0.494 , 0.491 , 0.4905,\n",
       "            0.4888, 0.4875, 0.4841, 0.4824, 0.4788, 0.4783, 0.4768, 0.4753,\n",
       "            0.4744, 0.4736, 0.4722, 0.4702, 0.4697, 0.4626, 0.458 , 0.4539,\n",
       "            0.4531, 0.4497, 0.4475, 0.4414, 0.4238, 0.4202, 0.4114, 0.3992,\n",
       "            0.3835, 0.383 , 0.3784, 0.3772, 0.376 , 0.366 , 0.334 , 0.3318,\n",
       "            0.3145, 0.3018, 0.3013, 0.288 , 0.286 , 0.266 , 0.2637, 0.2573,\n",
       "            0.2537, 0.2534, 0.2339, 0.2301, 0.2256, 0.2203, 0.2119, 0.1954,\n",
       "            0.19  , 0.1799, 0.163 , 0.1467, 0.1384, 0.1335], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5390625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.09375  ,\n",
       "            0.09375  , 0.09375  , 0.09375  , 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.1953125,\n",
       "            0.203125 , 0.21875  , 0.2265625, 0.234375 , 0.25     , 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.34375  , 0.3515625,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6803279 ,\n",
       "            0.6885246 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8278689 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.86885244, 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.968 , 0.965 , 0.956 , 0.9478, 0.9463, 0.9443, 0.9365,\n",
       "            0.935 , 0.933 , 0.931 , 0.9224, 0.9194, 0.9146, 0.9077, 0.9062,\n",
       "            0.9033, 0.903 , 0.9014, 0.895 , 0.8926, 0.891 , 0.888 , 0.886 ,\n",
       "            0.882 , 0.8794, 0.879 , 0.8774, 0.8755, 0.875 , 0.872 , 0.87  ,\n",
       "            0.868 , 0.8677, 0.8657, 0.8643, 0.864 , 0.861 , 0.8584, 0.855 ,\n",
       "            0.847 , 0.8467, 0.846 , 0.8403, 0.837 , 0.835 , 0.833 , 0.8325,\n",
       "            0.832 , 0.83  , 0.829 , 0.8286, 0.8276, 0.823 , 0.8228, 0.822 ,\n",
       "            0.82  , 0.8193, 0.8164, 0.8154, 0.8125, 0.807 , 0.8066, 0.806 ,\n",
       "            0.805 , 0.804 , 0.7974, 0.7964, 0.7886, 0.786 , 0.7837, 0.782 ,\n",
       "            0.7817, 0.7734, 0.7715, 0.771 , 0.7705, 0.7695, 0.7686, 0.7666,\n",
       "            0.764 , 0.763 , 0.7617, 0.7603, 0.755 , 0.752 , 0.7505, 0.75  ,\n",
       "            0.748 , 0.7446, 0.743 , 0.736 , 0.7314, 0.729 , 0.727 , 0.723 ,\n",
       "            0.7183, 0.714 , 0.7124, 0.71  , 0.7017, 0.6973, 0.6943, 0.693 ,\n",
       "            0.6914, 0.69  , 0.6733, 0.6704, 0.6694, 0.6665, 0.6655, 0.658 ,\n",
       "            0.6562, 0.655 , 0.654 , 0.6514, 0.6475, 0.6377, 0.637 , 0.6353,\n",
       "            0.633 , 0.63  , 0.627 , 0.626 , 0.622 , 0.615 , 0.614 , 0.6104,\n",
       "            0.6094, 0.6084, 0.604 , 0.602 , 0.59  , 0.5894, 0.586 , 0.5835,\n",
       "            0.5747, 0.5728, 0.5723, 0.5713, 0.569 , 0.565 , 0.5645, 0.56  ,\n",
       "            0.5596, 0.5586, 0.558 , 0.5566, 0.555 , 0.554 , 0.5537, 0.5513,\n",
       "            0.545 , 0.5435, 0.5376, 0.534 , 0.5312, 0.5303, 0.526 , 0.5244,\n",
       "            0.5225, 0.5215, 0.52  , 0.518 , 0.5176, 0.515 , 0.5146, 0.5083,\n",
       "            0.508 , 0.505 , 0.504 , 0.502 , 0.5   , 0.4998, 0.4978, 0.495 ,\n",
       "            0.4924, 0.4878, 0.4875, 0.4873, 0.4856, 0.485 , 0.4832, 0.4807,\n",
       "            0.48  , 0.4797, 0.47  , 0.4675, 0.4626, 0.4617, 0.4587, 0.4556,\n",
       "            0.4546, 0.4316, 0.428 , 0.417 , 0.4028, 0.3887, 0.388 , 0.3877,\n",
       "            0.3833, 0.3818, 0.3782, 0.3706, 0.335 , 0.3328, 0.3198, 0.3025,\n",
       "            0.3013, 0.2876, 0.287 , 0.286 , 0.2847, 0.2644, 0.2556, 0.252 ,\n",
       "            0.2517, 0.2313, 0.2268, 0.2224, 0.2166, 0.2101, 0.1931, 0.1869,\n",
       "            0.1754, 0.1583, 0.1434, 0.1335, 0.128 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5703125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.09375  , 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.1953125, 0.203125 , 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.72131145, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.8032787 , 0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9727, 0.97  , 0.9624, 0.955 , 0.9536, 0.9517, 0.9443,\n",
       "            0.9434, 0.9414, 0.9395, 0.931 , 0.9287, 0.924 , 0.918 , 0.9165,\n",
       "            0.9136, 0.913 , 0.9116, 0.9053, 0.9033, 0.902 , 0.899 , 0.8975,\n",
       "            0.8945, 0.893 , 0.8906, 0.89  , 0.8887, 0.887 , 0.8857, 0.884 ,\n",
       "            0.8804, 0.88  , 0.8794, 0.878 , 0.8765, 0.876 , 0.8755, 0.8716,\n",
       "            0.867 , 0.8643, 0.86  , 0.8584, 0.8574, 0.8535, 0.853 , 0.8516,\n",
       "            0.85  , 0.8496, 0.8486, 0.847 , 0.8467, 0.8447, 0.841 , 0.8403,\n",
       "            0.8394, 0.8384, 0.836 , 0.835 , 0.831 , 0.8296, 0.8286, 0.8257,\n",
       "            0.825 , 0.823 , 0.8228, 0.821 , 0.8184, 0.817 , 0.816 , 0.807 ,\n",
       "            0.8022, 0.8013, 0.801 , 0.8   , 0.7905, 0.7896, 0.7886, 0.787 ,\n",
       "            0.784 , 0.7837, 0.782 , 0.7817, 0.7812, 0.7773, 0.7754, 0.7725,\n",
       "            0.77  , 0.768 , 0.7676, 0.766 , 0.7617, 0.7573, 0.7544, 0.754 ,\n",
       "            0.75  , 0.742 , 0.7397, 0.7324, 0.7314, 0.73  , 0.726 , 0.7246,\n",
       "            0.72  , 0.711 , 0.709 , 0.708 , 0.7046, 0.69  , 0.683 , 0.6816,\n",
       "            0.6797, 0.6704, 0.6694, 0.6675, 0.6665, 0.6597, 0.656 , 0.65  ,\n",
       "            0.6494, 0.649 , 0.6455, 0.6406, 0.6377, 0.637 , 0.633 , 0.6274,\n",
       "            0.6265, 0.6255, 0.625 , 0.62  , 0.6196, 0.6147, 0.607 , 0.5986,\n",
       "            0.5947, 0.5923, 0.5884, 0.588 , 0.5864, 0.5854, 0.582 , 0.579 ,\n",
       "            0.577 , 0.574 , 0.573 , 0.569 , 0.5684, 0.568 , 0.5674, 0.5664,\n",
       "            0.563 , 0.5625, 0.56  , 0.558 , 0.5537, 0.546 , 0.5454, 0.5444,\n",
       "            0.5366, 0.5356, 0.5337, 0.532 , 0.5303, 0.53  , 0.5244, 0.5234,\n",
       "            0.523 , 0.5176, 0.5156, 0.515 , 0.5127, 0.5117, 0.5093, 0.5073,\n",
       "            0.507 , 0.5063, 0.5015, 0.4993, 0.4949, 0.4934, 0.4924, 0.4912,\n",
       "            0.4897, 0.4863, 0.4854, 0.484 , 0.4834, 0.4736, 0.4731, 0.468 ,\n",
       "            0.4675, 0.4639, 0.4612, 0.4597, 0.4329, 0.4287, 0.4185, 0.404 ,\n",
       "            0.3892, 0.3887, 0.3884, 0.3826, 0.3806, 0.3772, 0.3735, 0.3323,\n",
       "            0.3298, 0.3193, 0.299 , 0.2983, 0.2834, 0.2832, 0.282 , 0.2808,\n",
       "            0.264 , 0.26  , 0.2505, 0.2473, 0.2471, 0.2263, 0.2218, 0.217 ,\n",
       "            0.2104, 0.2076, 0.1906, 0.1813, 0.1696, 0.152 , 0.1381, 0.1279,\n",
       "            0.1222], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.609375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.1015625, 0.1015625,\n",
       "            0.109375 , 0.125    , 0.1328125, 0.1328125, 0.1484375, 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1796875, 0.1875   , 0.1953125, 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.484375 , 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.5859375, 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.26229507, 0.2704918 , 0.27868852, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5409836 , 0.55737704,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.978  , 0.9756 , 0.9688 , 0.9624 , 0.962  , 0.961  ,\n",
       "            0.959  , 0.9526 , 0.951  , 0.95   , 0.948  , 0.941  , 0.9385 ,\n",
       "            0.934  , 0.928  , 0.9272 , 0.925  , 0.924  , 0.923  , 0.9165 ,\n",
       "            0.915  , 0.9136 , 0.9106 , 0.91   , 0.9097 , 0.9062 , 0.9053 ,\n",
       "            0.9023 , 0.902  , 0.9014 , 0.8994 , 0.8975 , 0.8965 , 0.8926 ,\n",
       "            0.892  , 0.8906 , 0.8896 , 0.888  , 0.884  , 0.882  , 0.881  ,\n",
       "            0.875  , 0.8726 , 0.872  , 0.8716 , 0.871  , 0.869  , 0.868  ,\n",
       "            0.867  , 0.8667 , 0.866  , 0.8657 , 0.865  , 0.86   , 0.859  ,\n",
       "            0.8584 , 0.8574 , 0.855  , 0.8506 , 0.85   , 0.849  , 0.848  ,\n",
       "            0.8438 , 0.843  , 0.842  , 0.8403 , 0.84   , 0.8374 , 0.836  ,\n",
       "            0.833  , 0.832  , 0.827  , 0.8223 , 0.822  , 0.821  , 0.8145 ,\n",
       "            0.811  , 0.81   , 0.8086 , 0.8037 , 0.8022 , 0.802  , 0.801  ,\n",
       "            0.7993 , 0.798  , 0.7974 , 0.797  , 0.7925 , 0.7915 , 0.791  ,\n",
       "            0.7886 , 0.788  , 0.787  , 0.782  , 0.7812 , 0.775  , 0.774  ,\n",
       "            0.773  , 0.7705 , 0.7593 , 0.758  , 0.7554 , 0.755  , 0.7515 ,\n",
       "            0.747  , 0.7466 , 0.7407 , 0.7397 , 0.7305 , 0.729  , 0.726  ,\n",
       "            0.724  , 0.7227 , 0.709  , 0.7026 , 0.698  , 0.6973 , 0.6963 ,\n",
       "            0.6865 , 0.6846 , 0.6836 , 0.6807 , 0.68   , 0.6772 , 0.674  ,\n",
       "            0.6675 , 0.6636 , 0.663  , 0.6577 , 0.651  , 0.6465 , 0.6455 ,\n",
       "            0.6426 , 0.6396 , 0.638  , 0.636  , 0.63   , 0.626  , 0.611  ,\n",
       "            0.6104 , 0.608  , 0.6074 , 0.606  , 0.6045 , 0.603  , 0.5986 ,\n",
       "            0.5967 , 0.5903 , 0.59   , 0.5894 , 0.589  , 0.5854 , 0.5835 ,\n",
       "            0.583  , 0.5825 , 0.5796 , 0.5776 , 0.577  , 0.576  , 0.5728 ,\n",
       "            0.5703 , 0.564  , 0.5586 , 0.558  , 0.5557 , 0.551  , 0.544  ,\n",
       "            0.543  , 0.5425 , 0.5415 , 0.5386 , 0.5327 , 0.532  , 0.5244 ,\n",
       "            0.524  , 0.5234 , 0.5205 , 0.5195 , 0.517  , 0.5146 , 0.514  ,\n",
       "            0.5093 , 0.507  , 0.503  , 0.5005 , 0.4978 , 0.4973 , 0.493  ,\n",
       "            0.4924 , 0.4905 , 0.49   , 0.4812 , 0.4797 , 0.4744 , 0.4727 ,\n",
       "            0.47   , 0.4668 , 0.4358 , 0.432  , 0.4229 , 0.4114 , 0.3926 ,\n",
       "            0.3923 , 0.3918 , 0.384  , 0.382  , 0.3813 , 0.3801 , 0.3325 ,\n",
       "            0.3296 , 0.32   , 0.2986 , 0.297  , 0.2817 , 0.2815 , 0.2808 ,\n",
       "            0.2798 , 0.2676 , 0.2578 , 0.2467 , 0.2448 , 0.2445 , 0.2234 ,\n",
       "            0.2189 , 0.2134 , 0.2085 , 0.2058 , 0.1906 , 0.1763 , 0.1658 ,\n",
       "            0.1462 , 0.133  , 0.1238 , 0.11755], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.640625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0703125, 0.0703125, 0.078125 , 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.1015625, 0.1015625, 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.1328125, 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.328125 , 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4262295 , 0.43442622,\n",
       "            0.45081967, 0.45901638, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.982 , 0.98  , 0.974 , 0.9683, 0.9673, 0.966 , 0.9595,\n",
       "            0.9585, 0.9575, 0.955 , 0.949 , 0.947 , 0.9424, 0.938 , 0.936 ,\n",
       "            0.934 , 0.9336, 0.9326, 0.927 , 0.925 , 0.9243, 0.924 , 0.9214,\n",
       "            0.9204, 0.92  , 0.9165, 0.916 , 0.913 , 0.912 , 0.911 , 0.9106,\n",
       "            0.908 , 0.904 , 0.9033, 0.903 , 0.9014, 0.9004, 0.899 , 0.8984,\n",
       "            0.894 , 0.893 , 0.891 , 0.889 , 0.8867, 0.8853, 0.885 , 0.8843,\n",
       "            0.884 , 0.8833, 0.883 , 0.882 , 0.878 , 0.876 , 0.8716, 0.8687,\n",
       "            0.868 , 0.865 , 0.864 , 0.863 , 0.861 , 0.859 , 0.8584, 0.858 ,\n",
       "            0.8574, 0.857 , 0.856 , 0.8545, 0.8525, 0.8496, 0.846 , 0.8457,\n",
       "            0.845 , 0.8423, 0.842 , 0.8403, 0.8315, 0.8306, 0.829 , 0.8286,\n",
       "            0.822 , 0.8213, 0.8184, 0.817 , 0.8145, 0.814 , 0.813 , 0.812 ,\n",
       "            0.8105, 0.8086, 0.807 , 0.8057, 0.8047, 0.8022, 0.797 , 0.795 ,\n",
       "            0.794 , 0.7905, 0.7856, 0.7773, 0.777 , 0.774 , 0.7725, 0.7695,\n",
       "            0.7646, 0.763 , 0.7617, 0.753 , 0.751 , 0.7495, 0.7427, 0.7417,\n",
       "            0.7393, 0.728 , 0.722 , 0.715 , 0.712 , 0.711 , 0.7056, 0.7026,\n",
       "            0.7   , 0.699 , 0.696 , 0.695 , 0.6875, 0.686 , 0.682 , 0.6797,\n",
       "            0.679 , 0.675 , 0.667 , 0.6636, 0.662 , 0.6606, 0.6587, 0.658 ,\n",
       "            0.6514, 0.6504, 0.6494, 0.646 , 0.627 , 0.6265, 0.623 , 0.6216,\n",
       "            0.6206, 0.6177, 0.6147, 0.6113, 0.611 , 0.609 , 0.604 , 0.602 ,\n",
       "            0.598 , 0.5977, 0.597 , 0.594 , 0.5923, 0.5913, 0.591 , 0.5874,\n",
       "            0.5854, 0.5825, 0.5767, 0.576 , 0.574 , 0.5713, 0.5684, 0.561 ,\n",
       "            0.558 , 0.5547, 0.553 , 0.551 , 0.5503, 0.5474, 0.5464, 0.546 ,\n",
       "            0.539 , 0.535 , 0.5347, 0.5337, 0.5317, 0.526 , 0.52  , 0.5195,\n",
       "            0.518 , 0.5176, 0.514 , 0.5127, 0.511 , 0.509 , 0.504 , 0.503 ,\n",
       "            0.4944, 0.4907, 0.4863, 0.4856, 0.4834, 0.4807, 0.478 , 0.4717,\n",
       "            0.436 , 0.4326, 0.4246, 0.417 , 0.393 , 0.3928, 0.3923, 0.3877,\n",
       "            0.3828, 0.381 , 0.3809, 0.3303, 0.3267, 0.3186, 0.2979, 0.2925,\n",
       "            0.2778, 0.277 , 0.2766, 0.2703, 0.2537, 0.2411, 0.2402, 0.2401,\n",
       "            0.2189, 0.2142, 0.2085, 0.2081, 0.1995, 0.1898, 0.1699, 0.1609,\n",
       "            0.1395, 0.1272, 0.1186, 0.1122], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.640625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.1015625, 0.1015625, 0.109375 , 0.1171875, 0.1171875, 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.203125 , 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.19672132, 0.20491803,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.3114754 , 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.985  , 0.9834 , 0.978  , 0.973  , 0.9727 , 0.972  ,\n",
       "            0.97   , 0.965  , 0.964  , 0.9634 , 0.961  , 0.9556 , 0.9536 ,\n",
       "            0.949  , 0.9453 , 0.9434 , 0.9414 , 0.941  , 0.94   , 0.935  ,\n",
       "            0.9346 , 0.933  , 0.932  , 0.9297 , 0.928  , 0.926  , 0.9253 ,\n",
       "            0.9214 , 0.921  , 0.92   , 0.9194 , 0.917  , 0.9126 , 0.912  ,\n",
       "            0.9106 , 0.909  , 0.9043 , 0.904  , 0.903  , 0.9023 , 0.9004 ,\n",
       "            0.8994 , 0.899  , 0.8984 , 0.898  , 0.897  , 0.8955 , 0.8936 ,\n",
       "            0.893  , 0.8926 , 0.891  , 0.8843 , 0.8813 , 0.88   , 0.8784 ,\n",
       "            0.8765 , 0.8735 , 0.873  , 0.8726 , 0.872  , 0.8677 , 0.867  ,\n",
       "            0.8643 , 0.863  , 0.8623 , 0.8604 , 0.859  , 0.858  , 0.857  ,\n",
       "            0.8564 , 0.856  , 0.848  , 0.847  , 0.8457 , 0.84   , 0.838  ,\n",
       "            0.8374 , 0.8345 , 0.831  , 0.8306 , 0.8276 , 0.8267 , 0.826  ,\n",
       "            0.8247 , 0.8237 , 0.8228 , 0.821  , 0.8193 , 0.817  , 0.812  ,\n",
       "            0.811  , 0.8076 , 0.807  , 0.797  , 0.793  , 0.792  , 0.783  ,\n",
       "            0.781  , 0.779  , 0.7734 , 0.768  , 0.766  , 0.7637 , 0.758  ,\n",
       "            0.7524 , 0.749  , 0.744  , 0.7383 , 0.7305 , 0.7217 , 0.72   ,\n",
       "            0.709  , 0.7085 , 0.7046 , 0.704  , 0.702  , 0.6978 , 0.697  ,\n",
       "            0.6895 , 0.688  , 0.6875 , 0.684  , 0.6797 , 0.6753 , 0.675  ,\n",
       "            0.671  , 0.6665 , 0.666  , 0.664  , 0.66   , 0.659  , 0.6455 ,\n",
       "            0.642  , 0.64   , 0.6357 , 0.6294 , 0.6284 , 0.627  , 0.625  ,\n",
       "            0.624  , 0.6235 , 0.6187 , 0.6177 , 0.616  , 0.6113 , 0.6064 ,\n",
       "            0.606  , 0.605  , 0.5996 , 0.598  , 0.5967 , 0.596  , 0.591  ,\n",
       "            0.5894 , 0.588  , 0.5854 , 0.584  , 0.581  , 0.5728 , 0.5723 ,\n",
       "            0.5684 , 0.559  , 0.557  , 0.5557 , 0.5547 , 0.5503 , 0.55   ,\n",
       "            0.545  , 0.5444 , 0.543  , 0.54   , 0.5396 , 0.539  , 0.536  ,\n",
       "            0.529  , 0.5283 , 0.5234 , 0.523  , 0.5225 , 0.5215 , 0.5186 ,\n",
       "            0.513  , 0.5127 , 0.5107 , 0.505  , 0.4976 , 0.4973 , 0.4924 ,\n",
       "            0.491  , 0.4897 , 0.4832 , 0.4812 , 0.48   , 0.475  , 0.4353 ,\n",
       "            0.432  , 0.426  , 0.4224 , 0.394  , 0.3938 , 0.3936 , 0.3909 ,\n",
       "            0.3809 , 0.3794 , 0.3281 , 0.3237 , 0.317  , 0.2966 , 0.2876 ,\n",
       "            0.2742 , 0.274  , 0.2734 , 0.2727 , 0.2725 , 0.2494 , 0.2358 ,\n",
       "            0.2356 , 0.2351 , 0.2144 , 0.2096 , 0.2086 , 0.2028 , 0.1935 ,\n",
       "            0.1892 , 0.1637 , 0.1555 , 0.1329 , 0.1217 , 0.11395, 0.10724],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6796875, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.109375 , 0.1171875, 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.203125 , 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.37704918, 0.3852459 , 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8032787 , 0.8114754 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.988  , 0.9863 , 0.982  , 0.9775 , 0.977  , 0.975  ,\n",
       "            0.9707 , 0.9697 , 0.9688 , 0.967  , 0.9624 , 0.9604 , 0.9565 ,\n",
       "            0.9526 , 0.951  , 0.9497 , 0.9487 , 0.948  , 0.947  , 0.944  ,\n",
       "            0.943  , 0.942  , 0.941  , 0.94   , 0.939  , 0.9385 , 0.9375 ,\n",
       "            0.9346 , 0.931  , 0.9307 , 0.9297 , 0.929  , 0.9272 , 0.927  ,\n",
       "            0.9263 , 0.923  , 0.9224 , 0.921  , 0.9194 , 0.919  , 0.9185 ,\n",
       "            0.9146 , 0.914  , 0.9136 , 0.913  , 0.9126 , 0.912  , 0.911  ,\n",
       "            0.91   , 0.9097 , 0.908  , 0.907  , 0.905  , 0.904  , 0.901  ,\n",
       "            0.896  , 0.893  , 0.8926 , 0.8916 , 0.8906 , 0.89   , 0.889  ,\n",
       "            0.886  , 0.885  , 0.8804 , 0.88   , 0.878  , 0.877  , 0.876  ,\n",
       "            0.8755 , 0.875  , 0.873  , 0.869  , 0.867  , 0.866  , 0.8647 ,\n",
       "            0.857  , 0.8555 , 0.8535 , 0.8525 , 0.8516 , 0.8486 , 0.846  ,\n",
       "            0.845  , 0.843  , 0.8413 , 0.84   , 0.8394 , 0.839  , 0.837  ,\n",
       "            0.8345 , 0.832  , 0.831  , 0.8276 , 0.822  , 0.8184 , 0.8145 ,\n",
       "            0.8125 , 0.811  , 0.8003 , 0.8    , 0.799  , 0.796  , 0.789  ,\n",
       "            0.7886 , 0.7876 , 0.7783 , 0.7773 , 0.7676 , 0.7646 , 0.764  ,\n",
       "            0.76   , 0.75   , 0.747  , 0.7427 , 0.737  , 0.736  , 0.7246 ,\n",
       "            0.724  , 0.7236 , 0.7197 , 0.7188 , 0.7124 , 0.7095 , 0.7075 ,\n",
       "            0.703  , 0.7026 , 0.6997 , 0.6973 , 0.6963 , 0.6914 , 0.69   ,\n",
       "            0.6855 , 0.682  , 0.679  , 0.6753 , 0.6665 , 0.665  , 0.657  ,\n",
       "            0.648  , 0.646  , 0.6436 , 0.6426 , 0.642  , 0.6416 , 0.638  ,\n",
       "            0.6377 , 0.6313 , 0.63   , 0.6294 , 0.6216 , 0.619  , 0.6177 ,\n",
       "            0.614  , 0.613  , 0.6104 , 0.61   , 0.6064 , 0.605  , 0.604  ,\n",
       "            0.601  , 0.594  , 0.593  , 0.587  , 0.585  , 0.576  , 0.5713 ,\n",
       "            0.5693 , 0.5664 , 0.5625 , 0.5615 , 0.5605 , 0.5596 , 0.558  ,\n",
       "            0.556  , 0.5537 , 0.5513 , 0.548  , 0.544  , 0.5405 , 0.536  ,\n",
       "            0.535  , 0.5347 , 0.5327 , 0.527  , 0.524  , 0.522  , 0.516  ,\n",
       "            0.5156 , 0.5063 , 0.506  , 0.505  , 0.504  , 0.5005 , 0.4932 ,\n",
       "            0.4922 , 0.4849 , 0.4395 , 0.4363 , 0.432  , 0.4316 , 0.4036 ,\n",
       "            0.3977 , 0.3972 , 0.3938 , 0.3848 , 0.3828 , 0.3818 , 0.3296 ,\n",
       "            0.3245 , 0.32   , 0.2983 , 0.2861 , 0.2773 , 0.2732 , 0.273  ,\n",
       "            0.2708 , 0.2478 , 0.2338 , 0.2313 , 0.2119 , 0.2103 , 0.207  ,\n",
       "            0.199  , 0.1896 , 0.1892 , 0.1597 , 0.1511 , 0.1279 , 0.11755,\n",
       "            0.1097 , 0.1025 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7109375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.046875 , 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0625   , 0.0703125, 0.078125 , 0.078125 ,\n",
       "            0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.109375 ,\n",
       "            0.1171875, 0.1171875, 0.125    , 0.125    , 0.125    , 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.2109375, 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5234375, 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.671875 , 0.6796875, 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.30327868, 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40983605,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8606557 , 0.8606557 ,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9907 , 0.9897 , 0.9863 , 0.9824 , 0.982  , 0.9805 ,\n",
       "            0.9766 , 0.976  , 0.975  , 0.9736 , 0.969  , 0.968  , 0.9644 ,\n",
       "            0.9614 , 0.96   , 0.9585 , 0.958  , 0.9575 , 0.9565 , 0.9536 ,\n",
       "            0.953  , 0.9517 , 0.951  , 0.95   , 0.949  , 0.9478 , 0.9463 ,\n",
       "            0.9453 , 0.942  , 0.9414 , 0.941  , 0.9395 , 0.939  , 0.935  ,\n",
       "            0.9346 , 0.9336 , 0.933  , 0.932  , 0.931  , 0.9287 , 0.928  ,\n",
       "            0.9277 , 0.9272 , 0.9263 , 0.9253 , 0.925  , 0.9243 , 0.923  ,\n",
       "            0.9224 , 0.922  , 0.9185 , 0.917  , 0.916  , 0.911  , 0.9087 ,\n",
       "            0.907  , 0.9062 , 0.9053 , 0.904  , 0.902  , 0.901  , 0.897  ,\n",
       "            0.8965 , 0.896  , 0.894  , 0.8936 , 0.8926 , 0.8916 , 0.8896 ,\n",
       "            0.886  , 0.8853 , 0.884  , 0.8755 , 0.8735 , 0.872  , 0.871  ,\n",
       "            0.8706 , 0.8667 , 0.8643 , 0.8604 , 0.86   , 0.8594 , 0.858  ,\n",
       "            0.856  , 0.8525 , 0.8516 , 0.85   , 0.8486 , 0.8433 , 0.838  ,\n",
       "            0.8364 , 0.832  , 0.8296 , 0.823  , 0.8184 , 0.8154 , 0.812  ,\n",
       "            0.811  , 0.8105 , 0.7974 , 0.7964 , 0.792  , 0.788  , 0.783  ,\n",
       "            0.777  , 0.7705 , 0.7666 , 0.7593 , 0.758  , 0.7505 , 0.748  ,\n",
       "            0.7466 , 0.7437 , 0.743  , 0.7417 , 0.7354 , 0.734  , 0.7324 ,\n",
       "            0.729  , 0.728  , 0.7246 , 0.7217 , 0.721  , 0.7197 , 0.716  ,\n",
       "            0.705  , 0.7026 , 0.7017 , 0.699  , 0.6953 , 0.694  , 0.686  ,\n",
       "            0.684  , 0.6763 , 0.6743 , 0.672  , 0.667  , 0.6626 , 0.662  ,\n",
       "            0.6597 , 0.6587 , 0.657  , 0.655  , 0.6494 , 0.6436 , 0.64   ,\n",
       "            0.6396 , 0.6367 , 0.636  , 0.6353 , 0.635  , 0.6343 , 0.632  ,\n",
       "            0.6313 , 0.6284 , 0.6245 , 0.621  , 0.6177 , 0.6133 , 0.61   ,\n",
       "            0.5947 , 0.594  , 0.593  , 0.592  , 0.59   , 0.589  , 0.588  ,\n",
       "            0.582  , 0.5806 , 0.5767 , 0.5747 , 0.5737 , 0.573  , 0.5635 ,\n",
       "            0.561  , 0.5596 , 0.557  , 0.5566 , 0.552  , 0.551  , 0.548  ,\n",
       "            0.547  , 0.545  , 0.5396 , 0.539  , 0.529  , 0.5283 , 0.519  ,\n",
       "            0.5166 , 0.5156 , 0.5127 , 0.502  , 0.4495 , 0.4448 , 0.4424 ,\n",
       "            0.4417 , 0.4143 , 0.4038 , 0.4033 , 0.4006 , 0.3906 , 0.3892 ,\n",
       "            0.3882 , 0.333  , 0.3289 , 0.3276 , 0.3022 , 0.288  , 0.2822 ,\n",
       "            0.2747 , 0.2744 , 0.272  , 0.2482 , 0.2338 , 0.2335 , 0.2302 ,\n",
       "            0.2123 , 0.2109 , 0.2059 , 0.197  , 0.19   , 0.1863 , 0.1575 ,\n",
       "            0.1478 , 0.12463, 0.11554, 0.1063 , 0.09827], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7109375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0546875,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.078125 , 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.1171875,\n",
       "            0.1171875, 0.125    , 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1953125, 0.2109375, 0.21875  , 0.21875  , 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.328125 ,\n",
       "            0.34375  , 0.3515625, 0.3671875, 0.375    , 0.3828125, 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.453125 ,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.609375 , 0.6171875,\n",
       "            0.625    , 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.27868852, 0.29508197, 0.30327868, 0.3114754 , 0.33606556,\n",
       "            0.3442623 , 0.36065573, 0.36885247, 0.3852459 , 0.40163934,\n",
       "            0.40983605, 0.4262295 , 0.44262296, 0.45081967, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9927 , 0.9917 , 0.9893 , 0.986  , 0.9854 , 0.9844 ,\n",
       "            0.981  , 0.9805 , 0.98   , 0.9785 , 0.9746 , 0.973  , 0.97   ,\n",
       "            0.968  , 0.9663 , 0.965  , 0.9644 , 0.964  , 0.9614 , 0.9604 ,\n",
       "            0.9595 , 0.959  , 0.9585 , 0.9565 , 0.956  , 0.9556 , 0.953  ,\n",
       "            0.9507 , 0.95   , 0.9497 , 0.949  , 0.9478 , 0.9443 , 0.944  ,\n",
       "            0.9424 , 0.9414 , 0.94   , 0.9395 , 0.9375 , 0.937  , 0.936  ,\n",
       "            0.935  , 0.934  , 0.9336 , 0.9287 , 0.928  , 0.9272 , 0.923  ,\n",
       "            0.9224 , 0.9204 , 0.92   , 0.917  , 0.9165 , 0.9155 , 0.914  ,\n",
       "            0.9126 , 0.9106 , 0.909  , 0.9087 , 0.908  , 0.907  , 0.906  ,\n",
       "            0.9033 , 0.9014 , 0.9004 , 0.8984 , 0.898  , 0.8975 , 0.8896 ,\n",
       "            0.888  , 0.887  , 0.8843 , 0.883  , 0.881  , 0.8784 , 0.876  ,\n",
       "            0.8745 , 0.8726 , 0.872  , 0.87   , 0.869  , 0.8677 , 0.8667 ,\n",
       "            0.865  , 0.8643 , 0.8584 , 0.8564 , 0.852  , 0.8477 , 0.844  ,\n",
       "            0.8413 , 0.8335 , 0.8325 , 0.8306 , 0.8296 , 0.8286 , 0.827  ,\n",
       "            0.8115 , 0.811  , 0.8096 , 0.8057 , 0.805  , 0.8013 , 0.799  ,\n",
       "            0.786  , 0.785  , 0.7754 , 0.7744 , 0.769  , 0.7666 , 0.7637 ,\n",
       "            0.7617 , 0.761  , 0.7583 , 0.756  , 0.75   , 0.7476 , 0.7466 ,\n",
       "            0.744  , 0.743  , 0.7393 , 0.736  , 0.7344 , 0.722  , 0.72   ,\n",
       "            0.719  , 0.7163 , 0.714  , 0.7104 , 0.703  , 0.697  , 0.6943 ,\n",
       "            0.693  , 0.6865 , 0.6807 , 0.679  , 0.6753 , 0.674  , 0.67   ,\n",
       "            0.666  , 0.6646 , 0.66   , 0.658  , 0.6577 , 0.652  , 0.6514 ,\n",
       "            0.649  , 0.645  , 0.6445 , 0.64   , 0.639  , 0.634  , 0.6304 ,\n",
       "            0.6265 , 0.6094 , 0.6084 , 0.608  , 0.6064 , 0.6045 , 0.5977 ,\n",
       "            0.591  , 0.5894 , 0.589  , 0.588  , 0.5864 , 0.5786 , 0.574  ,\n",
       "            0.5728 , 0.5713 , 0.5693 , 0.5635 , 0.563  , 0.5586 , 0.5566 ,\n",
       "            0.5527 , 0.543  , 0.541  , 0.53   , 0.529  , 0.5283 , 0.528  ,\n",
       "            0.5264 , 0.5205 , 0.517  , 0.457  , 0.4502 , 0.45   , 0.4468 ,\n",
       "            0.4224 , 0.4062 , 0.4055 , 0.4036 , 0.393  , 0.3923 , 0.3909 ,\n",
       "            0.3364 , 0.333  , 0.3276 , 0.304  , 0.2874 , 0.2864 , 0.2737 ,\n",
       "            0.2732 , 0.273  , 0.2705 , 0.2462 , 0.2311 , 0.2269 , 0.2137 ,\n",
       "            0.208  , 0.2032 , 0.1935 , 0.1903 , 0.1819 , 0.1545 , 0.1436 ,\n",
       "            0.12085, 0.113  , 0.10266, 0.094  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7109375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.1171875, 0.125    , 0.125    , 0.125    ,\n",
       "            0.1328125, 0.140625 , 0.15625  , 0.1640625, 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.8671875, 0.875    , 0.8828125, 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.21311475, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.2704918 , 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.36065573, 0.36885247, 0.3852459 , 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.44262296, 0.46721312, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.59016395, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.8770492 , 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9946 , 0.994  , 0.9917 , 0.9893 , 0.989  , 0.988  ,\n",
       "            0.9854 , 0.9844 , 0.984  , 0.983  , 0.98   , 0.9785 , 0.976  ,\n",
       "            0.9736 , 0.973  , 0.9717 , 0.971  , 0.9707 , 0.969  , 0.968  ,\n",
       "            0.9673 , 0.967  , 0.9663 , 0.9644 , 0.964  , 0.9614 , 0.9595 ,\n",
       "            0.959  , 0.9585 , 0.958  , 0.9565 , 0.954  , 0.9536 , 0.953  ,\n",
       "            0.952  , 0.951  , 0.95   , 0.9497 , 0.9478 , 0.947  , 0.9463 ,\n",
       "            0.946  , 0.945  , 0.94   , 0.9385 , 0.935  , 0.9346 , 0.933  ,\n",
       "            0.9316 , 0.9297 , 0.929  , 0.9287 , 0.928  , 0.9263 , 0.9253 ,\n",
       "            0.9243 , 0.922  , 0.9214 , 0.9204 , 0.919  , 0.917  , 0.9155 ,\n",
       "            0.915  , 0.9146 , 0.913  , 0.912  , 0.9116 , 0.905  , 0.9043 ,\n",
       "            0.903  , 0.9    , 0.899  , 0.8984 , 0.8965 , 0.8945 , 0.892  ,\n",
       "            0.89   , 0.889  , 0.888  , 0.8877 , 0.886  , 0.8857 , 0.8843 ,\n",
       "            0.882  , 0.8804 , 0.8755 , 0.8745 , 0.8706 , 0.8657 , 0.862  ,\n",
       "            0.86   , 0.8516 , 0.85   , 0.8486 , 0.8477 , 0.8457 , 0.83   ,\n",
       "            0.8296 , 0.829  , 0.825  , 0.8213 , 0.821  , 0.8057 , 0.7954 ,\n",
       "            0.7944 , 0.79   , 0.788  , 0.7837 , 0.7827 , 0.7817 , 0.779  ,\n",
       "            0.771  , 0.7705 , 0.769  , 0.7676 , 0.7666 , 0.761  , 0.757  ,\n",
       "            0.756  , 0.747  , 0.7417 , 0.7407 , 0.7393 , 0.7373 , 0.737  ,\n",
       "            0.731  , 0.7256 , 0.72   , 0.718  , 0.717  , 0.71   , 0.7046 ,\n",
       "            0.7036 , 0.6973 , 0.6924 , 0.6875 , 0.686  , 0.6846 , 0.684  ,\n",
       "            0.682  , 0.6797 , 0.6777 , 0.6733 , 0.673  , 0.6724 , 0.6714 ,\n",
       "            0.666  , 0.6646 , 0.663  , 0.662  , 0.6606 , 0.655  , 0.653  ,\n",
       "            0.6475 , 0.6304 , 0.63   , 0.6294 , 0.6284 , 0.628  , 0.6265 ,\n",
       "            0.6196 , 0.6113 , 0.609  , 0.6074 , 0.606  , 0.6055 , 0.599  ,\n",
       "            0.594  , 0.592  , 0.5903 , 0.5884 , 0.583  , 0.5825 , 0.5776 ,\n",
       "            0.5747 , 0.5723 , 0.572  , 0.563  , 0.5596 , 0.5483 , 0.5474 ,\n",
       "            0.547  , 0.545  , 0.543  , 0.5425 , 0.537  , 0.4731 , 0.4644 ,\n",
       "            0.4639 , 0.4592 , 0.437  , 0.4155 , 0.4146 , 0.4136 , 0.4036 ,\n",
       "            0.4028 , 0.4004 , 0.3535 , 0.3394 , 0.3335 , 0.312  , 0.295  ,\n",
       "            0.2937 , 0.2776 , 0.2769 , 0.275  , 0.2487 , 0.2328 , 0.229  ,\n",
       "            0.2185 , 0.209  , 0.204  , 0.1941 , 0.1937 , 0.1815 , 0.1559 ,\n",
       "            0.142  , 0.12054, 0.1142 , 0.1009 , 0.09186], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7109375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.03125  , 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.0703125, 0.0703125, 0.078125 , 0.0859375, 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.109375 , 0.1171875, 0.125    ,\n",
       "            0.125    , 0.1328125, 0.1484375, 0.15625  , 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5078125, 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5625   , 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04918033, 0.05737705, 0.07377049, 0.08196721, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.20491803, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4262295 , 0.44262296, 0.45081967,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.996 , 0.9956, 0.9937, 0.992 , 0.9917, 0.991 , 0.989 ,\n",
       "            0.988 , 0.987 , 0.9844, 0.984 , 0.981 , 0.98  , 0.9785, 0.978 ,\n",
       "            0.9775, 0.977 , 0.9756, 0.975 , 0.9746, 0.9736, 0.973 , 0.972 ,\n",
       "            0.9717, 0.9707, 0.9697, 0.968 , 0.9673, 0.967 , 0.9663, 0.9653,\n",
       "            0.964 , 0.9634, 0.9624, 0.962 , 0.9614, 0.961 , 0.96  , 0.959 ,\n",
       "            0.958 , 0.9575, 0.9565, 0.9556, 0.955 , 0.9546, 0.951 , 0.95  ,\n",
       "            0.948 , 0.9478, 0.9463, 0.945 , 0.9414, 0.941 , 0.9404, 0.9395,\n",
       "            0.939 , 0.9385, 0.9375, 0.9365, 0.9355, 0.9346, 0.9336, 0.9307,\n",
       "            0.93  , 0.9297, 0.928 , 0.9253, 0.9214, 0.92  , 0.9175, 0.916 ,\n",
       "            0.9155, 0.915 , 0.912 , 0.91  , 0.9097, 0.908 , 0.907 , 0.9053,\n",
       "            0.905 , 0.904 , 0.903 , 0.9023, 0.9004, 0.899 , 0.8984, 0.897 ,\n",
       "            0.8955, 0.888 , 0.8843, 0.8813, 0.879 , 0.8726, 0.8706, 0.869 ,\n",
       "            0.8687, 0.868 , 0.8574, 0.8525, 0.851 , 0.849 , 0.848 , 0.845 ,\n",
       "            0.8306, 0.826 , 0.8223, 0.822 , 0.8213, 0.8145, 0.812 , 0.8115,\n",
       "            0.8096, 0.809 , 0.806 , 0.8022, 0.801 , 0.797 , 0.7964, 0.7905,\n",
       "            0.789 , 0.785 , 0.7793, 0.771 , 0.7686, 0.7627, 0.7603, 0.7593,\n",
       "            0.758 , 0.756 , 0.755 , 0.753 , 0.752 , 0.749 , 0.7446, 0.742 ,\n",
       "            0.735 , 0.725 , 0.723 , 0.7217, 0.719 , 0.7144, 0.711 , 0.7095,\n",
       "            0.709 , 0.7085, 0.707 , 0.705 , 0.7026, 0.7007, 0.696 , 0.695 ,\n",
       "            0.691 , 0.6875, 0.687 , 0.686 , 0.6826, 0.674 , 0.672 , 0.6694,\n",
       "            0.6665, 0.6655, 0.6646, 0.6562, 0.654 , 0.6436, 0.643 , 0.639 ,\n",
       "            0.631 , 0.6284, 0.6274, 0.6255, 0.6245, 0.62  , 0.6167, 0.616 ,\n",
       "            0.6143, 0.6113, 0.6035, 0.6025, 0.599 , 0.5938, 0.59  , 0.5884,\n",
       "            0.587 , 0.563 , 0.562 , 0.561 , 0.5566, 0.4868, 0.4807, 0.4758,\n",
       "            0.4734, 0.4531, 0.426 , 0.425 , 0.4238, 0.4146, 0.413 , 0.4104,\n",
       "            0.3645, 0.3467, 0.3398, 0.3208, 0.3042, 0.2979, 0.282 , 0.281 ,\n",
       "            0.2805, 0.2783, 0.2515, 0.2343, 0.2299, 0.2238, 0.2104, 0.2048,\n",
       "            0.1981, 0.1936, 0.1805, 0.1548, 0.1399, 0.1184, 0.1124, 0.0991,\n",
       "            0.0896], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.71875, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0703125, 0.0703125, 0.078125 , 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.1015625, 0.1171875, 0.125    , 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.1640625, 0.171875 , 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.1953125, 0.1953125, 0.203125 , 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.08196721, 0.09016393,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.16393442, 0.17213115, 0.18852459, 0.19672132,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.24590164, 0.25409836,\n",
       "            0.2704918 , 0.27868852, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36885247,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5491803 , 0.55737704, 0.57377046,\n",
       "            0.59016395, 0.60655737, 0.6229508 , 0.63114756, 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9976 , 0.997  , 0.9956 , 0.9946 , 0.994  , 0.992  ,\n",
       "            0.9917 , 0.991  , 0.99   , 0.9883 , 0.986  , 0.9854 , 0.9844 ,\n",
       "            0.984  , 0.9834 , 0.983  , 0.982  , 0.981  , 0.9805 , 0.9795 ,\n",
       "            0.979  , 0.9785 , 0.9775 , 0.9756 , 0.975  , 0.9746 , 0.974  ,\n",
       "            0.9727 , 0.972  , 0.9717 , 0.971  , 0.9707 , 0.97   , 0.969  ,\n",
       "            0.9688 , 0.9673 , 0.9663 , 0.966  , 0.9653 , 0.965  , 0.9644 ,\n",
       "            0.964  , 0.9634 , 0.9614 , 0.9604 , 0.9595 , 0.959  , 0.958  ,\n",
       "            0.9575 , 0.956  , 0.9546 , 0.953  , 0.952  , 0.9517 , 0.951  ,\n",
       "            0.9497 , 0.9487 , 0.9478 , 0.9453 , 0.9443 , 0.9434 , 0.943  ,\n",
       "            0.9395 , 0.939  , 0.938  , 0.934  , 0.932  , 0.9316 , 0.929  ,\n",
       "            0.9277 , 0.927  , 0.9263 , 0.9253 , 0.9243 , 0.9214 , 0.9204 ,\n",
       "            0.92   , 0.9185 , 0.9175 , 0.9165 , 0.9155 , 0.905  , 0.903  ,\n",
       "            0.9014 , 0.898  , 0.897  , 0.8945 , 0.8926 , 0.8916 , 0.89   ,\n",
       "            0.8877 , 0.886  , 0.883  , 0.882  , 0.8706 , 0.8696 , 0.869  ,\n",
       "            0.868  , 0.8584 , 0.8564 , 0.851  , 0.847  , 0.8447 , 0.8433 ,\n",
       "            0.8423 , 0.8403 , 0.8384 , 0.8374 , 0.837  , 0.8296 , 0.826  ,\n",
       "            0.822  , 0.819  , 0.808  , 0.8022 , 0.798  , 0.7935 , 0.793  ,\n",
       "            0.79   , 0.7896 , 0.786  , 0.7837 , 0.783  , 0.7827 , 0.779  ,\n",
       "            0.772  , 0.769  , 0.766  , 0.764  , 0.756  , 0.7524 , 0.752  ,\n",
       "            0.746  , 0.7446 , 0.7437 , 0.741  , 0.7393 , 0.738  , 0.735  ,\n",
       "            0.734  , 0.7324 , 0.732  , 0.7285 , 0.728  , 0.726  , 0.722  ,\n",
       "            0.7188 , 0.7124 , 0.711  , 0.7095 , 0.707  , 0.7065 , 0.7007 ,\n",
       "            0.6895 , 0.689  , 0.6855 , 0.6787 , 0.678  , 0.675  , 0.6733 ,\n",
       "            0.6704 , 0.6685 , 0.6675 , 0.6665 , 0.661  , 0.656  , 0.6533 ,\n",
       "            0.6523 , 0.6504 , 0.649  , 0.6455 , 0.642  , 0.6406 , 0.639  ,\n",
       "            0.6284 , 0.618  , 0.591  , 0.5874 , 0.5845 , 0.58   , 0.508  ,\n",
       "            0.4995 , 0.494  , 0.492  , 0.4712 , 0.44   , 0.4395 , 0.4392 ,\n",
       "            0.4302 , 0.4282 , 0.4248 , 0.3838 , 0.357  , 0.3494 , 0.3315 ,\n",
       "            0.3147 , 0.3064 , 0.2883 , 0.2878 , 0.2869 , 0.2847 , 0.2563 ,\n",
       "            0.2375 , 0.2374 , 0.2335 , 0.2294 , 0.2134 , 0.2064 , 0.2024 ,\n",
       "            0.1946 , 0.181  , 0.1561 , 0.138  , 0.118  , 0.113  , 0.09753,\n",
       "            0.0871 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7421875, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.0234375, 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0546875, 0.0625   , 0.0625   , 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.234375 , 0.234375 , 0.2421875, 0.25     , 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5234375, 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.05737705, 0.06557377, 0.08196721, 0.09016393, 0.10655738,\n",
       "            0.12295082, 0.13114753, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.21311475, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.28688523,\n",
       "            0.3114754 , 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36885247, 0.3852459 , 0.39344263, 0.40983605, 0.4180328 ,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.60655737, 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.8032787 , 0.8114754 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.8442623 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9985 , 0.998  , 0.997  , 0.9966 , 0.996  , 0.995  ,\n",
       "            0.994  , 0.993  , 0.9917 , 0.9897 , 0.9893 , 0.9883 , 0.988  ,\n",
       "            0.987  , 0.9863 , 0.986  , 0.9854 , 0.985  , 0.9844 , 0.984  ,\n",
       "            0.9834 , 0.9824 , 0.982  , 0.9814 , 0.981  , 0.98   , 0.9795 ,\n",
       "            0.979  , 0.9775 , 0.977  , 0.9766 , 0.9756 , 0.9746 , 0.974  ,\n",
       "            0.9727 , 0.9717 , 0.971  , 0.9707 , 0.97   , 0.9697 , 0.969  ,\n",
       "            0.9683 , 0.968  , 0.9663 , 0.966  , 0.965  , 0.964  , 0.9634 ,\n",
       "            0.963  , 0.961  , 0.96   , 0.9595 , 0.959  , 0.958  , 0.9575 ,\n",
       "            0.957  , 0.956  , 0.9556 , 0.9526 , 0.9517 , 0.9478 , 0.9473 ,\n",
       "            0.9463 , 0.946  , 0.944  , 0.9434 , 0.942  , 0.939  , 0.9385 ,\n",
       "            0.9375 , 0.936  , 0.935  , 0.934  , 0.932  , 0.93   , 0.924  ,\n",
       "            0.923  , 0.9194 , 0.918  , 0.9175 , 0.916  , 0.9136 , 0.913  ,\n",
       "            0.9126 , 0.9116 , 0.91   , 0.902  , 0.896  , 0.893  , 0.8906 ,\n",
       "            0.89   , 0.886  , 0.882  , 0.88   , 0.8794 , 0.878  , 0.876  ,\n",
       "            0.8755 , 0.874  , 0.871  , 0.87   , 0.869  , 0.8687 , 0.8667 ,\n",
       "            0.865  , 0.863  , 0.8564 , 0.849  , 0.8467 , 0.846  , 0.836  ,\n",
       "            0.8335 , 0.831  , 0.83   , 0.8286 , 0.8276 , 0.8247 , 0.8237 ,\n",
       "            0.8193 , 0.819  , 0.8164 , 0.814  , 0.811  , 0.806  , 0.8057 ,\n",
       "            0.801  , 0.7964 , 0.795  , 0.794  , 0.792  , 0.789  , 0.786  ,\n",
       "            0.7856 , 0.785  , 0.7827 , 0.7793 , 0.7764 , 0.774  , 0.769  ,\n",
       "            0.765  , 0.7646 , 0.7627 , 0.7617 , 0.761  , 0.759  , 0.758  ,\n",
       "            0.7524 , 0.752  , 0.748  , 0.7446 , 0.7427 , 0.7373 , 0.735  ,\n",
       "            0.7324 , 0.732  , 0.7314 , 0.7285 , 0.7266 , 0.7236 , 0.723  ,\n",
       "            0.7183 , 0.716  , 0.715  , 0.7104 , 0.706  , 0.703  , 0.681  ,\n",
       "            0.6777 , 0.6743 , 0.6655 , 0.6533 , 0.6465 , 0.6245 , 0.6143 ,\n",
       "            0.611  , 0.605  , 0.5337 , 0.52   , 0.5166 , 0.513  , 0.4907 ,\n",
       "            0.4578 , 0.457  , 0.4565 , 0.4482 , 0.4473 , 0.4429 , 0.409  ,\n",
       "            0.3699 , 0.362  , 0.3445 , 0.3264 , 0.3186 , 0.2969 , 0.2964 ,\n",
       "            0.2954 , 0.294  , 0.263  , 0.2426 , 0.2397 , 0.2363 , 0.218  ,\n",
       "            0.2098 , 0.2079 , 0.197  , 0.183  , 0.1597 , 0.1373 , 0.119  ,\n",
       "            0.11615, 0.0967 , 0.0854 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.75, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.0234375, 0.0234375, 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.078125 ,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.09375  , 0.1015625, 0.1015625,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.1328125, 0.140625 , 0.140625 ,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.234375 , 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.4140625, 0.421875 , 0.4375   , 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.546875 , 0.5546875, 0.5625   , 0.578125 ,\n",
       "            0.5859375, 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01639344, 0.03278688, 0.05737705, 0.06557377,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.16393442, 0.17213115, 0.18852459,\n",
       "            0.20491803, 0.22131148, 0.22950819, 0.24590164, 0.2704918 ,\n",
       "            0.29508197, 0.32786885, 0.3442623 , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.46721312,\n",
       "            0.5       , 0.5163934 , 0.52459013, 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.60655737,\n",
       "            0.6147541 , 0.6393443 , 0.647541  , 0.6557377 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.8606557 , 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.999  , 0.998  , 0.9976 , 0.997  , 0.996  , 0.995  ,\n",
       "            0.9946 , 0.994  , 0.993  , 0.9927 , 0.992  , 0.9917 , 0.99   ,\n",
       "            0.9897 , 0.9893 , 0.989  , 0.9883 , 0.988  , 0.9873 , 0.9863 ,\n",
       "            0.986  , 0.985  , 0.9834 , 0.983  , 0.9824 , 0.982  , 0.981  ,\n",
       "            0.9805 , 0.98   , 0.9795 , 0.979  , 0.9785 , 0.978  , 0.9775 ,\n",
       "            0.977  , 0.9766 , 0.976  , 0.9756 , 0.9736 , 0.9727 , 0.972  ,\n",
       "            0.9717 , 0.9707 , 0.9683 , 0.968  , 0.9673 , 0.967  , 0.966  ,\n",
       "            0.9653 , 0.9644 , 0.963  , 0.962  , 0.9614 , 0.961  , 0.9604 ,\n",
       "            0.9595 , 0.959  , 0.956  , 0.954  , 0.9536 , 0.953  , 0.9517 ,\n",
       "            0.95   , 0.9497 , 0.9487 , 0.948  , 0.947  , 0.9463 , 0.946  ,\n",
       "            0.9453 , 0.9434 , 0.941  , 0.9395 , 0.9385 , 0.9365 , 0.935  ,\n",
       "            0.932  , 0.9316 , 0.9307 , 0.93   , 0.9277 , 0.916  , 0.9146 ,\n",
       "            0.9136 , 0.912  , 0.91   , 0.9097 , 0.909  , 0.9087 , 0.908  ,\n",
       "            0.9077 , 0.9062 , 0.9053 , 0.9043 , 0.902  , 0.8984 , 0.895  ,\n",
       "            0.892  , 0.8906 , 0.885  , 0.884  , 0.882  , 0.877  , 0.875  ,\n",
       "            0.8735 , 0.8706 , 0.8696 , 0.868  , 0.8677 , 0.865  , 0.8643 ,\n",
       "            0.863  , 0.855  , 0.8545 , 0.854  , 0.8516 , 0.8486 , 0.8477 ,\n",
       "            0.844  , 0.8438 , 0.843  , 0.8423 , 0.8403 , 0.838  , 0.8374 ,\n",
       "            0.8335 , 0.8325 , 0.832  , 0.829  , 0.8276 , 0.8267 , 0.8184 ,\n",
       "            0.817  , 0.814  , 0.8125 , 0.8066 , 0.803  , 0.801  , 0.7993 ,\n",
       "            0.796  , 0.792  , 0.7905 , 0.789  , 0.7866 , 0.7856 , 0.784  ,\n",
       "            0.783  , 0.7827 , 0.7817 , 0.78   , 0.7793 , 0.775  , 0.763  ,\n",
       "            0.7583 , 0.728  , 0.7075 , 0.705  , 0.702  , 0.692  , 0.6807 ,\n",
       "            0.677  , 0.665  , 0.645  , 0.64   , 0.633  , 0.5654 , 0.5464 ,\n",
       "            0.5444 , 0.539  , 0.514  , 0.4814 , 0.4783 , 0.4734 , 0.4707 ,\n",
       "            0.466  , 0.4443 , 0.3872 , 0.3792 , 0.3613 , 0.342  , 0.3376 ,\n",
       "            0.31   , 0.3096 , 0.3093 , 0.309  , 0.2742 , 0.2527 , 0.252  ,\n",
       "            0.2467 , 0.2263 , 0.2177 , 0.2166 , 0.2042 , 0.1897 , 0.1683 ,\n",
       "            0.1407 , 0.1241 , 0.09875, 0.0863 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.75, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.0703125, 0.0703125, 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.109375 , 0.1171875, 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.140625 , 0.140625 , 0.140625 ,\n",
       "            0.140625 , 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1796875,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.875    , 0.8828125, 0.890625 , 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.04098361, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.12295082, 0.13934426, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.2704918 , 0.29508197, 0.31967214, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40983605, 0.4262295 , 0.44262296, 0.45081967, 0.46721312,\n",
       "            0.48360655, 0.5       , 0.5163934 , 0.5327869 , 0.5491803 ,\n",
       "            0.55737704, 0.57377046, 0.58196723, 0.59016395, 0.6147541 ,\n",
       "            0.63114756, 0.6557377 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.704918  , 0.7295082 , 0.73770493, 0.75409836, 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.89344263, 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9995, 0.999 , 0.9985, 0.998 , 0.9976, 0.997 , 0.9966,\n",
       "            0.996 , 0.9956, 0.995 , 0.9946, 0.994 , 0.993 , 0.9927, 0.992 ,\n",
       "            0.9917, 0.991 , 0.9907, 0.99  , 0.9897, 0.989 , 0.9883, 0.988 ,\n",
       "            0.9873, 0.9863, 0.986 , 0.9854, 0.985 , 0.984 , 0.9834, 0.983 ,\n",
       "            0.9824, 0.982 , 0.9814, 0.981 , 0.9805, 0.98  , 0.9795, 0.979 ,\n",
       "            0.9785, 0.9766, 0.976 , 0.9746, 0.972 , 0.9717, 0.9707, 0.97  ,\n",
       "            0.969 , 0.9688, 0.9683, 0.967 , 0.9653, 0.961 , 0.96  , 0.9585,\n",
       "            0.9575, 0.957 , 0.9565, 0.955 , 0.9546, 0.9536, 0.953 , 0.9526,\n",
       "            0.9507, 0.95  , 0.948 , 0.9463, 0.9453, 0.9443, 0.94  , 0.9395,\n",
       "            0.9385, 0.9375, 0.9365, 0.9346, 0.932 , 0.929 , 0.9277, 0.927 ,\n",
       "            0.9253, 0.925 , 0.9243, 0.924 , 0.922 , 0.921 , 0.9194, 0.9175,\n",
       "            0.916 , 0.915 , 0.91  , 0.909 , 0.9043, 0.9023, 0.902 , 0.8994,\n",
       "            0.8984, 0.8945, 0.894 , 0.8936, 0.893 , 0.8926, 0.8906, 0.889 ,\n",
       "            0.886 , 0.885 , 0.8843, 0.8813, 0.88  , 0.878 , 0.8755, 0.872 ,\n",
       "            0.871 , 0.87  , 0.869 , 0.8657, 0.8623, 0.858 , 0.857 , 0.856 ,\n",
       "            0.853 , 0.852 , 0.8516, 0.849 , 0.848 , 0.846 , 0.8457, 0.845 ,\n",
       "            0.8423, 0.842 , 0.841 , 0.839 , 0.8374, 0.8354, 0.8315, 0.8306,\n",
       "            0.83  , 0.8286, 0.8276, 0.8267, 0.826 , 0.825 , 0.824 , 0.8237,\n",
       "            0.823 , 0.806 , 0.8022, 0.8003, 0.8   , 0.7964, 0.7793, 0.7754,\n",
       "            0.7446, 0.725 , 0.7227, 0.72  , 0.709 , 0.698 , 0.6963, 0.6865,\n",
       "            0.6655, 0.66  , 0.652 , 0.5864, 0.567 , 0.5625, 0.5576, 0.5317,\n",
       "            0.5   , 0.496 , 0.4922, 0.4885, 0.4841, 0.4648, 0.4028, 0.3945,\n",
       "            0.3762, 0.3562, 0.3528, 0.3235, 0.323 , 0.3228, 0.286 , 0.2634,\n",
       "            0.2632, 0.2573, 0.2358, 0.2268, 0.2257, 0.2128, 0.1978, 0.1764,\n",
       "            0.1462, 0.1304, 0.1296, 0.1025, 0.0895], dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.08474576, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.18644068, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.22033899, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.31355932, 0.31355932, 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.37288135, 0.38135594,\n",
       "            0.3983051 , 0.40677965, 0.43220338, 0.44067797, 0.4661017 ,\n",
       "            0.47457626, 0.4915254 , 0.5084746 , 0.5338983 , 0.5423729 ,\n",
       "            0.55932206, 0.5762712 , 0.6101695 , 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6779661 , 0.69491524, 0.7118644 , 0.720339  ,\n",
       "            0.7372881 , 0.7542373 , 0.7627119 , 0.779661  , 0.7966102 ,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.84745765, 0.8559322 , 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.90677965, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 ,\n",
       "            0.9576271 , 0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.06818182,\n",
       "            0.09848485, 0.11363637, 0.12878788, 0.14393939, 0.15151516,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.20454545, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.42424244, 0.43939394, 0.43939394,\n",
       "            0.45454547, 0.45454547, 0.46212122, 0.46212122, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.50757575, 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.52272725, 0.52272725,\n",
       "            0.52272725, 0.52272725, 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.56060606, 0.56060606, 0.56060606, 0.56060606,\n",
       "            0.56060606, 0.56060606, 0.56060606, 0.56060606, 0.56060606,\n",
       "            0.56060606, 0.56060606, 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.57575756, 0.57575756, 0.57575756,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.59090906, 0.5984849 , 0.5984849 , 0.5984849 , 0.5984849 ,\n",
       "            0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.99242425, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4634, 0.4631, 0.463 , 0.4622, 0.462 , 0.4617, 0.4612,\n",
       "            0.461 , 0.4607, 0.4604, 0.4597, 0.4595, 0.459 , 0.4587, 0.4585,\n",
       "            0.458 , 0.4575, 0.4573, 0.4568, 0.456 , 0.455 , 0.4548, 0.4546,\n",
       "            0.4534, 0.453 , 0.4526, 0.4524, 0.452 , 0.4514, 0.4512, 0.4492,\n",
       "            0.449 , 0.4478, 0.4463, 0.4458, 0.4456, 0.445 , 0.4446, 0.444 ,\n",
       "            0.4436, 0.443 , 0.4424, 0.4421, 0.4417, 0.4412, 0.4407, 0.4404,\n",
       "            0.44  , 0.4392, 0.439 , 0.437 , 0.4368, 0.4365, 0.4346, 0.4343,\n",
       "            0.434 , 0.433 , 0.4324, 0.4316, 0.431 , 0.4307, 0.4304, 0.43  ,\n",
       "            0.4277, 0.427 , 0.4268, 0.4263, 0.426 , 0.4258, 0.4248, 0.4229,\n",
       "            0.4226, 0.4219, 0.4216, 0.4214, 0.421 , 0.4204, 0.4202, 0.4197,\n",
       "            0.4192, 0.4187, 0.4185, 0.4182, 0.418 , 0.4172, 0.417 , 0.4167,\n",
       "            0.4165, 0.4163, 0.416 , 0.4155, 0.4153, 0.415 , 0.4148, 0.4146,\n",
       "            0.4143, 0.414 , 0.4138, 0.4133, 0.4128, 0.4124, 0.4114, 0.4111,\n",
       "            0.411 , 0.4104, 0.41  , 0.409 , 0.4087, 0.4084, 0.4082, 0.408 ,\n",
       "            0.4075, 0.4072, 0.4067, 0.4065, 0.4058, 0.405 , 0.4045, 0.4033,\n",
       "            0.403 , 0.4026, 0.4019, 0.4016, 0.4006, 0.4   , 0.3982, 0.398 ,\n",
       "            0.3977, 0.3965, 0.396 , 0.3958, 0.392 , 0.3896, 0.3877, 0.3872,\n",
       "            0.3867, 0.3865, 0.3855, 0.3853, 0.3845, 0.382 , 0.3818, 0.3816,\n",
       "            0.3809, 0.3806, 0.3801, 0.3784, 0.3782, 0.3777, 0.3774, 0.3765,\n",
       "            0.376 , 0.3745, 0.374 , 0.3713, 0.37  , 0.3694, 0.3687, 0.3662,\n",
       "            0.3643, 0.362 , 0.3616, 0.3604, 0.36  , 0.3555, 0.3547, 0.3542,\n",
       "            0.3528, 0.3516, 0.3503, 0.3489, 0.347 , 0.3452, 0.3286],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.29661018, 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5423729 , 0.5508475 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.59322035, 0.6101695 ,\n",
       "            0.61864406, 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.6694915 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7372881 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.8135593 , 0.8305085 , 0.83898306, 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.88135594, 0.88135594, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.90677965, 0.91525424, 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9661017 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03787879, 0.04545455,\n",
       "            0.0530303 , 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.11363637, 0.12121212, 0.16666667, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.34848484,\n",
       "            0.36363637, 0.36363637, 0.37121212, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.42424244, 0.42424244,\n",
       "            0.42424244, 0.42424244, 0.4318182 , 0.4318182 , 0.4318182 ,\n",
       "            0.4318182 , 0.4469697 , 0.4469697 , 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.46212122, 0.46969697, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.49242425, 0.49242425, 0.49242425, 0.49242425,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.50757575, 0.50757575, 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.52272725, 0.52272725,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.54545456, 0.54545456,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.54545456, 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.56060606, 0.56060606, 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.57575756, 0.57575756, 0.57575756,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.5833333 , 0.59090906,\n",
       "            0.59090906, 0.59090906, 0.59090906, 0.59090906, 0.5984849 ,\n",
       "            0.5984849 , 0.5984849 , 0.5984849 , 0.5984849 , 0.6060606 ,\n",
       "            0.6060606 , 0.6060606 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6363636 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6439394 ,\n",
       "            0.6439394 , 0.6439394 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.68939394, 0.68939394, 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.79545456, 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4475, 0.4473, 0.4463, 0.446 , 0.4458, 0.4443, 0.4436,\n",
       "            0.4434, 0.4429, 0.4426, 0.4421, 0.4414, 0.4412, 0.441 , 0.4407,\n",
       "            0.4404, 0.4397, 0.4387, 0.4385, 0.4382, 0.438 , 0.4373, 0.437 ,\n",
       "            0.4363, 0.4358, 0.4355, 0.4353, 0.435 , 0.434 , 0.4336, 0.4321,\n",
       "            0.432 , 0.4314, 0.4312, 0.431 , 0.43  , 0.4272, 0.427 , 0.4265,\n",
       "            0.426 , 0.4248, 0.4243, 0.4238, 0.4229, 0.4216, 0.4214, 0.421 ,\n",
       "            0.4207, 0.4204, 0.42  , 0.4194, 0.419 , 0.4177, 0.4175, 0.4172,\n",
       "            0.417 , 0.4167, 0.4158, 0.4155, 0.4143, 0.4133, 0.4128, 0.4124,\n",
       "            0.4104, 0.4092, 0.409 , 0.4087, 0.4075, 0.4065, 0.4062, 0.4058,\n",
       "            0.4055, 0.4053, 0.4048, 0.4028, 0.402 , 0.401 , 0.4006, 0.3992,\n",
       "            0.399 , 0.3987, 0.398 , 0.3972, 0.3965, 0.396 , 0.3953, 0.3936,\n",
       "            0.3916, 0.3906, 0.3904, 0.3882, 0.3875, 0.3867, 0.386 , 0.3853,\n",
       "            0.384 , 0.3828, 0.3823, 0.38  , 0.3782, 0.3777, 0.3772, 0.3767,\n",
       "            0.376 , 0.3757, 0.3755, 0.3748, 0.3745, 0.3733, 0.3716, 0.3713,\n",
       "            0.371 , 0.3704, 0.3687, 0.3684, 0.3677, 0.3672, 0.367 , 0.3665,\n",
       "            0.3662, 0.366 , 0.3643, 0.3635, 0.3633, 0.362 , 0.3618, 0.3608,\n",
       "            0.3606, 0.3604, 0.3596, 0.3567, 0.3562, 0.356 , 0.3555, 0.3552,\n",
       "            0.355 , 0.3542, 0.353 , 0.3528, 0.3518, 0.3516, 0.3513, 0.351 ,\n",
       "            0.3506, 0.35  , 0.3499, 0.3496, 0.349 , 0.3489, 0.3484, 0.3477,\n",
       "            0.347 , 0.346 , 0.3455, 0.3452, 0.344 , 0.3435, 0.343 , 0.3423,\n",
       "            0.3408, 0.3403, 0.3389, 0.3386, 0.3367, 0.3364, 0.336 , 0.3357,\n",
       "            0.3323, 0.3318, 0.3315, 0.3313, 0.3308, 0.3254, 0.3252, 0.324 ,\n",
       "            0.3208, 0.32  , 0.3179, 0.317 , 0.3167, 0.3164, 0.3145, 0.3105,\n",
       "            0.31  , 0.3093, 0.308 , 0.3071, 0.3064, 0.3052, 0.305 , 0.304 ,\n",
       "            0.3018, 0.3015, 0.2996, 0.2979, 0.2954, 0.2869, 0.286 , 0.2842,\n",
       "            0.284 , 0.2815, 0.278 , 0.2764, 0.2737, 0.2708, 0.269 , 0.268 ,\n",
       "            0.2445], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.10169491, 0.11016949, 0.11016949, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3559322 , 0.3644068 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.62711865, 0.63559324,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8220339 , 0.8305085 , 0.8305085 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.89830506, 0.89830506, 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9661017 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 ,\n",
       "            0.9915254 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.09090909, 0.09848485, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.1969697 , 0.20454545, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.27272728, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.37878788, 0.37878788,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.40151516,\n",
       "            0.40151516, 0.40151516, 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.41666666, 0.42424244, 0.42424244, 0.42424244, 0.42424244,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.45454547, 0.45454547, 0.45454547, 0.46212122, 0.46212122,\n",
       "            0.46212122, 0.46212122, 0.46969697, 0.46969697, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.4848485 , 0.49242425, 0.49242425, 0.49242425,\n",
       "            0.49242425, 0.49242425, 0.49242425, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5151515 , 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.52272725, 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.54545456, 0.54545456,\n",
       "            0.54545456, 0.54545456, 0.5530303 , 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.5984849 , 0.6060606 , 0.6060606 ,\n",
       "            0.6060606 , 0.6060606 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6287879 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6439394 , 0.6515151 , 0.6515151 ,\n",
       "            0.6515151 , 0.6515151 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.6666667 , 0.67424244, 0.68939394,\n",
       "            0.68939394, 0.68939394, 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.719697  , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.7651515 ,\n",
       "            0.77272725, 0.77272725, 0.780303  , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.432 , 0.4316, 0.431 , 0.4307, 0.4304, 0.4292, 0.4287,\n",
       "            0.4285, 0.4272, 0.424 , 0.4236, 0.423 , 0.422 , 0.4219, 0.4216,\n",
       "            0.4214, 0.4211, 0.421 , 0.4202, 0.42  , 0.419 , 0.4185, 0.4182,\n",
       "            0.4177, 0.4175, 0.417 , 0.4165, 0.4153, 0.4143, 0.4138, 0.4128,\n",
       "            0.412 , 0.4119, 0.4116, 0.4114, 0.4111, 0.4097, 0.4094, 0.4082,\n",
       "            0.408 , 0.4077, 0.4072, 0.4062, 0.404 , 0.4038, 0.402 , 0.4019,\n",
       "            0.4014, 0.3972, 0.3967, 0.396 , 0.3955, 0.3953, 0.395 , 0.3948,\n",
       "            0.3933, 0.3928, 0.3926, 0.3923, 0.3916, 0.3914, 0.391 , 0.39  ,\n",
       "            0.3894, 0.3892, 0.3882, 0.387 , 0.3865, 0.3857, 0.385 , 0.3843,\n",
       "            0.3838, 0.3826, 0.3816, 0.38  , 0.3796, 0.379 , 0.3784, 0.3777,\n",
       "            0.377 , 0.3762, 0.3755, 0.3735, 0.3733, 0.3728, 0.372 , 0.3718,\n",
       "            0.3713, 0.3704, 0.37  , 0.3694, 0.3677, 0.3674, 0.3672, 0.3667,\n",
       "            0.365 , 0.3643, 0.362 , 0.3582, 0.3555, 0.3552, 0.3528, 0.3494,\n",
       "            0.3486, 0.3477, 0.3474, 0.3452, 0.3435, 0.343 , 0.3418, 0.3408,\n",
       "            0.3381, 0.3374, 0.3372, 0.3345, 0.333 , 0.3303, 0.3298, 0.3289,\n",
       "            0.3286, 0.3267, 0.325 , 0.3245, 0.3237, 0.3235, 0.3232, 0.3228,\n",
       "            0.3208, 0.3198, 0.319 , 0.318 , 0.3176, 0.317 , 0.3157, 0.3147,\n",
       "            0.3132, 0.3125, 0.3115, 0.3103, 0.3093, 0.3079, 0.3076, 0.3074,\n",
       "            0.307 , 0.3066, 0.3042, 0.3027, 0.2996, 0.2988, 0.2983, 0.298 ,\n",
       "            0.2974, 0.297 , 0.2969, 0.2966, 0.2957, 0.295 , 0.2937, 0.2935,\n",
       "            0.2925, 0.2908, 0.29  , 0.2893, 0.2886, 0.288 , 0.2876, 0.2869,\n",
       "            0.2866, 0.2864, 0.2837, 0.281 , 0.2805, 0.2793, 0.279 , 0.2773,\n",
       "            0.2766, 0.2754, 0.2747, 0.2744, 0.2742, 0.2732, 0.2722, 0.27  ,\n",
       "            0.269 , 0.2678, 0.266 , 0.2646, 0.264 , 0.263 , 0.2622, 0.2615,\n",
       "            0.26  , 0.2598, 0.2595, 0.259 , 0.258 , 0.2551, 0.2546, 0.252 ,\n",
       "            0.2505, 0.2494, 0.2487, 0.2467, 0.2449, 0.2434, 0.2428, 0.2426,\n",
       "            0.2421, 0.2383, 0.2343, 0.2235, 0.2233, 0.2218, 0.2202, 0.2197,\n",
       "            0.2185, 0.2157, 0.214 , 0.2104, 0.2063, 0.2051, 0.205 , 0.1785],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.11016949, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.23728813, 0.2542373 ,\n",
       "            0.26271185, 0.27966103, 0.2881356 , 0.29661018, 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.3644068 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6779661 , 0.6864407 , 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.80508476, 0.8220339 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.83898306, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.88135594, 0.88135594, 0.88135594, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.90677965, 0.90677965,\n",
       "            0.91525424, 0.91525424, 0.9237288 , 0.9322034 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.07575758, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.12121212, 0.12878788, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.1590909 , 0.16666667,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.21212122,\n",
       "            0.22727273, 0.25      , 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.31060606,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.32575756, 0.33333334,\n",
       "            0.34848484, 0.34848484, 0.3560606 , 0.36363637, 0.36363637,\n",
       "            0.36363637, 0.37121212, 0.37121212, 0.37878788, 0.37878788,\n",
       "            0.37878788, 0.37878788, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.42424244, 0.42424244, 0.4318182 , 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.43939394, 0.43939394,\n",
       "            0.4469697 , 0.4469697 , 0.45454547, 0.46212122, 0.46212122,\n",
       "            0.46212122, 0.46212122, 0.46212122, 0.46212122, 0.46969697,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.49242425, 0.5       ,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.52272725, 0.52272725, 0.52272725,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.5530303 , 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.57575756, 0.57575756, 0.57575756, 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.59090906, 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.5984849 , 0.5984849 , 0.5984849 ,\n",
       "            0.5984849 , 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6439394 , 0.6439394 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.6666667 , 0.6666667 , 0.6666667 , 0.6666667 ,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.6969697 , 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.7121212 , 0.719697  , 0.719697  , 0.719697  , 0.72727275,\n",
       "            0.72727275, 0.72727275, 0.7348485 , 0.75      , 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4182, 0.4158, 0.4155, 0.415 , 0.4138, 0.413 , 0.4106,\n",
       "            0.4104, 0.4058, 0.4053, 0.4036, 0.4033, 0.401 , 0.4006, 0.4001,\n",
       "            0.3992, 0.3987, 0.3982, 0.3975, 0.3967, 0.3965, 0.3962, 0.396 ,\n",
       "            0.395 , 0.3936, 0.393 , 0.3926, 0.3923, 0.3916, 0.391 , 0.3904,\n",
       "            0.3894, 0.3872, 0.3843, 0.3838, 0.3833, 0.383 , 0.3826, 0.3813,\n",
       "            0.381 , 0.38  , 0.3792, 0.3767, 0.375 , 0.3745, 0.3735, 0.3728,\n",
       "            0.3718, 0.3704, 0.37  , 0.3694, 0.3687, 0.3682, 0.3672, 0.3665,\n",
       "            0.3652, 0.3643, 0.3638, 0.3635, 0.3628, 0.3625, 0.3606, 0.36  ,\n",
       "            0.3594, 0.3582, 0.358 , 0.357 , 0.355 , 0.3547, 0.3535, 0.353 ,\n",
       "            0.3525, 0.3518, 0.35  , 0.3499, 0.3489, 0.348 , 0.3464, 0.3462,\n",
       "            0.3452, 0.3442, 0.344 , 0.3433, 0.34  , 0.3394, 0.3386, 0.338 ,\n",
       "            0.3354, 0.3333, 0.3308, 0.3281, 0.3264, 0.3228, 0.3218, 0.319 ,\n",
       "            0.3186, 0.3184, 0.3174, 0.3154, 0.3147, 0.312 , 0.311 , 0.3103,\n",
       "            0.307 , 0.3037, 0.2983, 0.298 , 0.2966, 0.2961, 0.294 , 0.2922,\n",
       "            0.2898, 0.2886, 0.288 , 0.287 , 0.2856, 0.283 , 0.2827, 0.282 ,\n",
       "            0.2815, 0.281 , 0.279 , 0.278 , 0.2756, 0.2747, 0.273 , 0.2717,\n",
       "            0.271 , 0.2708, 0.2703, 0.268 , 0.2676, 0.2654, 0.2637, 0.263 ,\n",
       "            0.2622, 0.2583, 0.2573, 0.2556, 0.2546, 0.2537, 0.2532, 0.2527,\n",
       "            0.2524, 0.2493, 0.249 , 0.2489, 0.2483, 0.2473, 0.2466, 0.246 ,\n",
       "            0.2445, 0.243 , 0.2426, 0.2421, 0.2411, 0.241 , 0.2407, 0.2363,\n",
       "            0.2358, 0.2346, 0.2335, 0.233 , 0.2327, 0.2318, 0.231 , 0.2306,\n",
       "            0.2303, 0.2302, 0.229 , 0.2268, 0.2246, 0.2225, 0.2222, 0.2198,\n",
       "            0.2195, 0.2186, 0.2181, 0.2177, 0.2175, 0.217 , 0.2166, 0.2156,\n",
       "            0.2134, 0.2125, 0.2114, 0.2104, 0.2085, 0.2064, 0.2056, 0.2042,\n",
       "            0.2039, 0.2032, 0.2031, 0.2029, 0.2026, 0.1989, 0.1967, 0.1962,\n",
       "            0.1959, 0.1958, 0.1952, 0.1947, 0.1946, 0.1934, 0.1925, 0.1923,\n",
       "            0.1833, 0.1757, 0.1735, 0.1716, 0.1708, 0.1693, 0.1676, 0.1666,\n",
       "            0.165 , 0.1616, 0.1572, 0.157 , 0.1566, 0.1307], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22033899, 0.22033899,\n",
       "            0.22033899, 0.23728813, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.2881356 ,\n",
       "            0.30508474, 0.3220339 , 0.3220339 , 0.3220339 , 0.33050847,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.3644068 , 0.3644068 , 0.3644068 , 0.37288135,\n",
       "            0.3898305 , 0.3898305 , 0.3983051 , 0.40677965, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 ,\n",
       "            0.7033898 , 0.7118644 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7288136 , 0.7372881 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.7711864 , 0.779661  , 0.779661  ,\n",
       "            0.7881356 , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.83898306, 0.83898306, 0.83898306, 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.88135594, 0.88135594, 0.88135594, 0.8898305 ,\n",
       "            0.8898305 , 0.8898305 , 0.89830506, 0.89830506, 0.90677965,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.9322034 ,\n",
       "            0.94067794, 0.94067794, 0.94067794, 0.94067794, 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 ,\n",
       "            0.9915254 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.24242425,\n",
       "            0.25757575, 0.27272728, 0.28030303, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.29545453, 0.3030303 , 0.31060606, 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.34848484, 0.34848484,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.36363637, 0.36363637,\n",
       "            0.36363637, 0.36363637, 0.36363637, 0.37121212, 0.37121212,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.40151516, 0.40151516, 0.40151516,\n",
       "            0.4090909 , 0.4090909 , 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.43939394, 0.43939394,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.46212122, 0.46969697, 0.46969697,\n",
       "            0.47727272, 0.47727272, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.5530303 , 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.57575756, 0.57575756, 0.57575756, 0.57575756, 0.57575756,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.59090906, 0.59090906,\n",
       "            0.59090906, 0.59090906, 0.5984849 , 0.5984849 , 0.5984849 ,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6439394 , 0.6515151 , 0.6515151 , 0.6515151 ,\n",
       "            0.6515151 , 0.6515151 , 0.65909094, 0.65909094, 0.6666667 ,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.67424244, 0.67424244,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.70454544, 0.70454544,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.72727275,\n",
       "            0.7348485 , 0.75      , 0.75      , 0.75757575, 0.75757575,\n",
       "            0.7651515 , 0.7651515 , 0.77272725, 0.77272725, 0.780303  ,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.81060606, 0.8181818 ,\n",
       "            0.8181818 , 0.8181818 , 0.8181818 , 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.9848485 , 0.99242425,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4036 , 0.4014 , 0.4004 , 0.3987 , 0.3972 , 0.396  ,\n",
       "            0.3958 , 0.3953 , 0.393  , 0.3923 , 0.3909 , 0.3892 , 0.3835 ,\n",
       "            0.383  , 0.3818 , 0.381  , 0.3809 , 0.3806 , 0.3804 , 0.3765 ,\n",
       "            0.3762 , 0.376  , 0.3755 , 0.3752 , 0.3743 , 0.374  , 0.3735 ,\n",
       "            0.3728 , 0.3723 , 0.3706 , 0.3704 , 0.3687 , 0.3672 , 0.3665 ,\n",
       "            0.366  , 0.365  , 0.3635 , 0.363  , 0.3623 , 0.3613 , 0.3574 ,\n",
       "            0.3572 , 0.3555 , 0.3552 , 0.355  , 0.353  , 0.3525 , 0.3523 ,\n",
       "            0.3516 , 0.3503 , 0.3489 , 0.348  , 0.3467 , 0.3455 , 0.3452 ,\n",
       "            0.3445 , 0.3438 , 0.3435 , 0.3433 , 0.3408 , 0.34   , 0.3394 ,\n",
       "            0.3386 , 0.3381 , 0.3376 , 0.3374 , 0.3367 , 0.3357 , 0.3354 ,\n",
       "            0.3337 , 0.333  , 0.3328 , 0.3315 , 0.3313 , 0.3306 , 0.3298 ,\n",
       "            0.329  , 0.3281 , 0.327  , 0.3267 , 0.322  , 0.3215 , 0.321  ,\n",
       "            0.3208 , 0.32   , 0.3164 , 0.3157 , 0.3127 , 0.3123 , 0.3103 ,\n",
       "            0.3096 , 0.3088 , 0.3066 , 0.306  , 0.3047 , 0.304  , 0.2974 ,\n",
       "            0.2942 , 0.294  , 0.2908 , 0.2898 , 0.2886 , 0.288  , 0.2874 ,\n",
       "            0.2827 , 0.2825 , 0.2754 , 0.2732 , 0.2727 , 0.267  , 0.2646 ,\n",
       "            0.2612 , 0.2605 , 0.2585 , 0.2573 , 0.255  , 0.2542 , 0.2524 ,\n",
       "            0.2498 , 0.2463 , 0.246  , 0.2455 , 0.2448 , 0.2441 , 0.2428 ,\n",
       "            0.2407 , 0.2405 , 0.2375 , 0.2351 , 0.2343 , 0.2332 , 0.2327 ,\n",
       "            0.2319 , 0.2281 , 0.228  , 0.2269 , 0.2268 , 0.2264 , 0.226  ,\n",
       "            0.2256 , 0.2252 , 0.2251 , 0.2211 , 0.22   , 0.2184 , 0.2172 ,\n",
       "            0.2162 , 0.2158 , 0.2129 , 0.2119 , 0.211  , 0.2098 , 0.2096 ,\n",
       "            0.2091 , 0.2073 , 0.207  , 0.2042 , 0.2035 , 0.2026 , 0.2006 ,\n",
       "            0.2001 , 0.1995 , 0.1991 , 0.199  , 0.1971 , 0.1964 , 0.1956 ,\n",
       "            0.1947 , 0.1946 , 0.1935 , 0.1931 , 0.1912 , 0.1906 , 0.1896 ,\n",
       "            0.1885 , 0.1879 , 0.1859 , 0.185  , 0.1846 , 0.1836 , 0.1826 ,\n",
       "            0.182  , 0.1814 , 0.1807 , 0.1799 , 0.1792 , 0.1779 , 0.1759 ,\n",
       "            0.1752 , 0.1743 , 0.1725 , 0.1718 , 0.1707 , 0.1688 , 0.1685 ,\n",
       "            0.1678 , 0.1677 , 0.1676 , 0.1674 , 0.1671 , 0.1661 , 0.1649 ,\n",
       "            0.1641 , 0.1635 , 0.1609 , 0.1604 , 0.1589 , 0.1587 , 0.1582 ,\n",
       "            0.1575 , 0.1567 , 0.1561 , 0.1556 , 0.1548 , 0.1492 , 0.1462 ,\n",
       "            0.1459 , 0.1415 , 0.1377 , 0.1371 , 0.1337 , 0.1329 , 0.1318 ,\n",
       "            0.1306 , 0.1304 , 0.127  , 0.12317, 0.12274, 0.1225 , 0.0995 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22033899, 0.22033899, 0.22033899, 0.22881356,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.34745762, 0.34745762, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.3644068 , 0.3644068 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.3983051 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.43220338, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 ,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.60169494, 0.60169494, 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.65254235, 0.66101694, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.6864407 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7288136 , 0.7372881 , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7881356 , 0.7966102 ,\n",
       "            0.7966102 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.83898306, 0.84745765, 0.84745765, 0.84745765, 0.84745765,\n",
       "            0.84745765, 0.8559322 , 0.8559322 , 0.86440676, 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.8898305 , 0.8898305 ,\n",
       "            0.8898305 , 0.8898305 , 0.89830506, 0.89830506, 0.89830506,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.9322034 , 0.9322034 ,\n",
       "            0.94067794, 0.94067794, 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.09848485, 0.09848485,\n",
       "            0.10606061, 0.11363637, 0.12121212, 0.12878788, 0.14393939,\n",
       "            0.15151516, 0.16666667, 0.17424242, 0.18939394, 0.1969697 ,\n",
       "            0.21212122, 0.21212122, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28787878, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.3030303 , 0.3030303 , 0.31060606, 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.3409091 , 0.3409091 ,\n",
       "            0.34848484, 0.34848484, 0.34848484, 0.3560606 , 0.3560606 ,\n",
       "            0.36363637, 0.36363637, 0.36363637, 0.36363637, 0.36363637,\n",
       "            0.36363637, 0.37121212, 0.37121212, 0.37121212, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.41666666, 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.43939394, 0.43939394,\n",
       "            0.43939394, 0.4469697 , 0.4469697 , 0.45454547, 0.45454547,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.46969697, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.49242425, 0.49242425,\n",
       "            0.49242425, 0.5       , 0.5       , 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.50757575, 0.5151515 , 0.5151515 , 0.52272725,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.54545456, 0.54545456,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.57575756, 0.57575756, 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.5984849 , 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6136364 , 0.6136364 , 0.6212121 ,\n",
       "            0.6212121 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.6515151 , 0.6515151 ,\n",
       "            0.6515151 , 0.6515151 , 0.65909094, 0.65909094, 0.6666667 ,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.67424244, 0.67424244,\n",
       "            0.6818182 , 0.6818182 , 0.6818182 , 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.70454544, 0.70454544, 0.7121212 ,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75      , 0.75757575, 0.75757575, 0.7651515 ,\n",
       "            0.7651515 , 0.7651515 , 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.79545456, 0.81060606, 0.8181818 ,\n",
       "            0.8181818 , 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8636364 ,\n",
       "            0.8712121 , 0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3887 , 0.387  , 0.3843 , 0.3816 , 0.3809 , 0.379  ,\n",
       "            0.3767 , 0.3762 , 0.373  , 0.3716 , 0.3704 , 0.3684 , 0.3652 ,\n",
       "            0.365  , 0.3596 , 0.3574 , 0.357  , 0.3555 , 0.3552 , 0.3516 ,\n",
       "            0.3506 , 0.3494 , 0.3489 , 0.3481 , 0.3442 , 0.3433 , 0.3425 ,\n",
       "            0.3418 , 0.3403 , 0.34   , 0.339  , 0.3389 , 0.3386 , 0.3384 ,\n",
       "            0.337  , 0.3354 , 0.3347 , 0.3335 , 0.3308 , 0.3303 , 0.3296 ,\n",
       "            0.3284 , 0.3281 , 0.3276 , 0.3262 , 0.3252 , 0.3247 , 0.3245 ,\n",
       "            0.3232 , 0.3218 , 0.32   , 0.3196 , 0.319  , 0.3184 , 0.317  ,\n",
       "            0.3164 , 0.3154 , 0.315  , 0.3147 , 0.3137 , 0.3135 , 0.3127 ,\n",
       "            0.3125 , 0.3115 , 0.31   , 0.3093 , 0.3088 , 0.3086 , 0.3064 ,\n",
       "            0.304  , 0.303  , 0.3025 , 0.3022 , 0.3008 , 0.298  , 0.2976 ,\n",
       "            0.2969 , 0.2947 , 0.2932 , 0.292  , 0.2903 , 0.29   , 0.289  ,\n",
       "            0.2874 , 0.281  , 0.28   , 0.2798 , 0.279  , 0.2788 , 0.2776 ,\n",
       "            0.2727 , 0.27   , 0.2664 , 0.264  , 0.2634 , 0.263  , 0.2617 ,\n",
       "            0.2612 , 0.2595 , 0.2585 , 0.2573 , 0.2546 , 0.2544 , 0.2478 ,\n",
       "            0.2463 , 0.2386 , 0.2372 , 0.2334 , 0.2283 , 0.2256 , 0.2213 ,\n",
       "            0.2207 , 0.2177 , 0.2172 , 0.2167 , 0.2161 , 0.2142 , 0.2137 ,\n",
       "            0.2118 , 0.2084 , 0.2076 , 0.2065 , 0.2054 , 0.2028 , 0.2024 ,\n",
       "            0.2001 , 0.1959 , 0.1948 , 0.1936 , 0.1934 , 0.1923 , 0.1887 ,\n",
       "            0.1884 , 0.1879 , 0.1874 , 0.1871 , 0.1863 , 0.1857 , 0.1852 ,\n",
       "            0.1831 , 0.1816 , 0.1812 , 0.1798 , 0.1772 , 0.1753 , 0.1737 ,\n",
       "            0.1718 , 0.1716 , 0.1709 , 0.1708 , 0.17   , 0.1697 , 0.1694 ,\n",
       "            0.1682 , 0.1671 , 0.1656 , 0.1636 , 0.1625 , 0.16   , 0.1593 ,\n",
       "            0.1592 , 0.1589 , 0.1587 , 0.1569 , 0.1566 , 0.1565 , 0.1564 ,\n",
       "            0.1545 , 0.1543 , 0.1528 , 0.1514 , 0.1508 , 0.1504 , 0.15   ,\n",
       "            0.1497 , 0.1481 , 0.147  , 0.1453 , 0.1451 , 0.1448 , 0.1437 ,\n",
       "            0.1425 , 0.141  , 0.1403 , 0.1399 , 0.1395 , 0.1394 , 0.1392 ,\n",
       "            0.1383 , 0.1355 , 0.135  , 0.1333 , 0.1332 , 0.1327 , 0.1318 ,\n",
       "            0.1317 , 0.1309 , 0.1299 , 0.129  , 0.1278 , 0.1277 , 0.1276 ,\n",
       "            0.126  , 0.119  , 0.1174 , 0.11554, 0.11127, 0.111  , 0.11084,\n",
       "            0.1093 , 0.10614, 0.10596, 0.1047 , 0.1032 , 0.10126, 0.09827,\n",
       "            0.0974 , 0.0775 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.1440678 , 0.15254237, 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22033899, 0.22033899, 0.22881356, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.3644068 , 0.3644068 , 0.3644068 , 0.3644068 , 0.37288135,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.41525424, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.5       , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.58474576, 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6694915 , 0.6694915 , 0.6779661 ,\n",
       "            0.6779661 , 0.6864407 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7288136 ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7457627 , 0.7542373 ,\n",
       "            0.7542373 , 0.7542373 , 0.7542373 , 0.7627119 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.8305085 , 0.84745765, 0.84745765, 0.84745765, 0.84745765,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.86440676, 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.8898305 , 0.8898305 ,\n",
       "            0.89830506, 0.89830506, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.09848485,\n",
       "            0.09848485, 0.09848485, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.1969697 ,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.28787878, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.31060606, 0.3181818 , 0.3181818 ,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.33333334, 0.3409091 ,\n",
       "            0.3409091 , 0.3409091 , 0.3409091 , 0.34848484, 0.34848484,\n",
       "            0.3560606 , 0.3560606 , 0.3560606 , 0.3560606 , 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.40151516, 0.40151516, 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.42424244, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.43939394, 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.45454547, 0.45454547, 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.4848485 ,\n",
       "            0.49242425, 0.49242425, 0.49242425, 0.49242425, 0.49242425,\n",
       "            0.49242425, 0.5       , 0.5       , 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.5378788 , 0.54545456, 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.57575756, 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.59090906,\n",
       "            0.59090906, 0.59090906, 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6212121 , 0.6212121 ,\n",
       "            0.6212121 , 0.6212121 , 0.6287879 , 0.6287879 , 0.6287879 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.6515151 ,\n",
       "            0.65909094, 0.65909094, 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.67424244, 0.67424244, 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.72727275, 0.74242425,\n",
       "            0.74242425, 0.74242425, 0.75      , 0.75757575, 0.75757575,\n",
       "            0.75757575, 0.7651515 , 0.7651515 , 0.7651515 , 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.84090906, 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.99242425, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.374  , 0.373  , 0.3682 , 0.3667 , 0.3652 , 0.3635 ,\n",
       "            0.3613 , 0.3591 , 0.3582 , 0.355  , 0.3542 , 0.3538 , 0.3506 ,\n",
       "            0.3489 , 0.3484 , 0.3396 , 0.3394 , 0.3376 , 0.337  , 0.333  ,\n",
       "            0.3325 , 0.3315 , 0.33   , 0.328  , 0.3276 , 0.3271 , 0.3267 ,\n",
       "            0.3257 , 0.325  , 0.3218 , 0.3186 , 0.3184 , 0.3174 , 0.3162 ,\n",
       "            0.3157 , 0.315  , 0.3147 , 0.314  , 0.3137 , 0.313  , 0.3115 ,\n",
       "            0.311  , 0.3098 , 0.309  , 0.3088 , 0.3064 , 0.3054 , 0.3044 ,\n",
       "            0.3032 , 0.3025 , 0.3018 , 0.3013 , 0.2998 , 0.299  , 0.2974 ,\n",
       "            0.297  , 0.2964 , 0.2961 , 0.2957 , 0.2954 , 0.2944 , 0.294  ,\n",
       "            0.2937 , 0.2927 , 0.29   , 0.289  , 0.2888 , 0.2866 , 0.2852 ,\n",
       "            0.2837 , 0.2834 , 0.2832 , 0.2827 , 0.2815 , 0.2803 , 0.2795 ,\n",
       "            0.2778 , 0.277  , 0.2761 , 0.2747 , 0.2734 , 0.2717 , 0.2708 ,\n",
       "            0.2703 , 0.2673 , 0.2637 , 0.263  , 0.2605 , 0.2588 , 0.254  ,\n",
       "            0.253  , 0.252  , 0.248  , 0.2474 , 0.2448 , 0.2441 , 0.2428 ,\n",
       "            0.2402 , 0.2394 , 0.2391 , 0.2378 , 0.2375 , 0.2374 , 0.2355 ,\n",
       "            0.2295 , 0.229  , 0.2233 , 0.218  , 0.2124 , 0.2119 , 0.2115 ,\n",
       "            0.2106 , 0.2045 , 0.2037 , 0.2032 , 0.2002 , 0.1971 , 0.1959 ,\n",
       "            0.1941 , 0.193  , 0.1924 , 0.1921 , 0.1901 , 0.188  , 0.1838 ,\n",
       "            0.1821 , 0.1815 , 0.1783 , 0.1776 , 0.1774 , 0.1772 , 0.1761 ,\n",
       "            0.1743 , 0.1738 , 0.1724 , 0.171  , 0.1694 , 0.1682 , 0.1647 ,\n",
       "            0.1643 , 0.164  , 0.1636 , 0.163  , 0.1627 , 0.1625 , 0.1617 ,\n",
       "            0.1604 , 0.1603 , 0.1598 , 0.1575 , 0.1572 , 0.157  , 0.1512 ,\n",
       "            0.1493 , 0.1483 , 0.1481 , 0.148  , 0.1477 , 0.1453 , 0.1447 ,\n",
       "            0.1445 , 0.144  , 0.1438 , 0.143  , 0.1415 , 0.1406 , 0.1392 ,\n",
       "            0.1387 , 0.138  , 0.1377 , 0.1373 , 0.1359 , 0.1357 , 0.1351 ,\n",
       "            0.134  , 0.1338 , 0.1327 , 0.1326 , 0.1313 , 0.1306 , 0.13   ,\n",
       "            0.1289 , 0.1285 , 0.1282 , 0.127  , 0.1262 , 0.1241 , 0.1239 ,\n",
       "            0.1238 , 0.12305, 0.1229 , 0.12146, 0.12103, 0.12024, 0.1194 ,\n",
       "            0.1186 , 0.1174 , 0.1172 , 0.11633, 0.11597, 0.11554, 0.115  ,\n",
       "            0.1144 , 0.1134 , 0.1093 , 0.10895, 0.10724, 0.10706, 0.1067 ,\n",
       "            0.103  , 0.1019 , 0.10156, 0.0979 , 0.09705, 0.0967 , 0.0959 ,\n",
       "            0.0935 , 0.0933 , 0.09235, 0.09106, 0.0909 , 0.0898 , 0.0895 ,\n",
       "            0.0715 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.09322034, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.16949153, 0.1779661 ,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22033899, 0.22033899, 0.22881356,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.2542373 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.29661018, 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.3644068 , 0.37288135, 0.37288135,\n",
       "            0.37288135, 0.38135594, 0.38135594, 0.3898305 , 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.58474576, 0.58474576, 0.58474576,\n",
       "            0.58474576, 0.59322035, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6779661 , 0.6864407 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7033898 , 0.7118644 , 0.720339  , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 ,\n",
       "            0.7542373 , 0.7542373 , 0.7542373 , 0.7542373 , 0.7542373 ,\n",
       "            0.7627119 , 0.779661  , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8220339 , 0.8220339 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.84745765,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.9322034 , 0.94067794, 0.94067794, 0.94067794, 0.9491525 ,\n",
       "            0.9491525 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9661017 ,\n",
       "            0.9661017 , 0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01515152, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09090909, 0.09848485, 0.09848485,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.1590909 , 0.1590909 , 0.16666667,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.22727273, 0.22727273, 0.23484848, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25      , 0.25757575, 0.25757575, 0.27272728,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.29545453,\n",
       "            0.29545453, 0.29545453, 0.3030303 , 0.3030303 , 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.3181818 , 0.3181818 , 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.33333334, 0.33333334, 0.34848484, 0.3560606 , 0.3560606 ,\n",
       "            0.36363637, 0.36363637, 0.36363637, 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.37878788, 0.38636363, 0.3939394 , 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.4090909 , 0.4090909 , 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.42424244, 0.42424244, 0.42424244,\n",
       "            0.4318182 , 0.4318182 , 0.4318182 , 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.4469697 , 0.45454547, 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.4848485 , 0.49242425, 0.49242425, 0.49242425,\n",
       "            0.49242425, 0.5       , 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.5681818 , 0.5681818 , 0.57575756, 0.57575756, 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6212121 , 0.6212121 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.6666667 , 0.6666667 , 0.6666667 ,\n",
       "            0.6666667 , 0.6666667 , 0.6666667 , 0.6666667 , 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75      , 0.75      , 0.75757575,\n",
       "            0.75757575, 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8712121 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3606 , 0.3535 , 0.3528 , 0.3525 , 0.348  , 0.3455 ,\n",
       "            0.3423 , 0.3413 , 0.3408 , 0.3396 , 0.3362 , 0.3342 , 0.333  ,\n",
       "            0.3328 , 0.3257 , 0.3242 , 0.3206 , 0.32   , 0.3184 , 0.3176 ,\n",
       "            0.3137 , 0.3127 , 0.3118 , 0.3108 , 0.31   , 0.3096 , 0.3083 ,\n",
       "            0.3071 , 0.3057 , 0.304  , 0.3037 , 0.3035 , 0.3018 , 0.2988 ,\n",
       "            0.2986 , 0.298  , 0.2974 , 0.2969 , 0.2966 , 0.2964 , 0.2961 ,\n",
       "            0.2954 , 0.294  , 0.2937 , 0.2927 , 0.2922 , 0.292  , 0.2917 ,\n",
       "            0.2915 , 0.2903 , 0.2898 , 0.2893 , 0.289  , 0.2886 , 0.288  ,\n",
       "            0.2864 , 0.285  , 0.2847 , 0.2837 , 0.283  , 0.2825 , 0.2822 ,\n",
       "            0.2805 , 0.2803 , 0.2798 , 0.2778 , 0.2773 , 0.2761 , 0.274  ,\n",
       "            0.2737 , 0.272  , 0.2717 , 0.2705 , 0.2703 , 0.2693 , 0.2686 ,\n",
       "            0.268  , 0.2676 , 0.267  , 0.2668 , 0.2664 , 0.266  , 0.2654 ,\n",
       "            0.2637 , 0.2634 , 0.2632 , 0.2627 , 0.2605 , 0.2595 , 0.2576 ,\n",
       "            0.256  , 0.2556 , 0.2537 , 0.252  , 0.2517 , 0.2456 , 0.2451 ,\n",
       "            0.2375 , 0.236  , 0.2352 , 0.2325 , 0.2313 , 0.2311 , 0.2307 ,\n",
       "            0.2301 , 0.2292 , 0.2273 , 0.2257 , 0.2256 , 0.2246 , 0.2244 ,\n",
       "            0.2216 , 0.22   , 0.2118 , 0.2079 , 0.2069 , 0.2048 , 0.2026 ,\n",
       "            0.1998 , 0.1976 , 0.196  , 0.1959 , 0.1943 , 0.1931 , 0.193  ,\n",
       "            0.1919 , 0.19   , 0.1879 , 0.1823 , 0.18   , 0.1783 , 0.178  ,\n",
       "            0.1764 , 0.1757 , 0.1731 , 0.171  , 0.1704 , 0.1696 , 0.1686 ,\n",
       "            0.1674 , 0.1653 , 0.1652 , 0.163  , 0.1617 , 0.1616 , 0.1615 ,\n",
       "            0.1608 , 0.1605 , 0.1604 , 0.1599 , 0.1548 , 0.1547 , 0.1542 ,\n",
       "            0.1536 , 0.1532 , 0.1517 , 0.1514 , 0.1503 , 0.1499 , 0.1481 ,\n",
       "            0.1477 , 0.1473 , 0.1456 , 0.1448 , 0.1447 , 0.1444 , 0.1428 ,\n",
       "            0.1409 , 0.1406 , 0.1395 , 0.1392 , 0.1385 , 0.1372 , 0.1371 ,\n",
       "            0.1367 , 0.1366 , 0.136  , 0.1359 , 0.1348 , 0.1335 , 0.1332 ,\n",
       "            0.1324 , 0.131  , 0.1306 , 0.1302 , 0.1294 , 0.1292 , 0.1289 ,\n",
       "            0.1288 , 0.1277 , 0.127  , 0.1257 , 0.1252 , 0.1251 , 0.12445,\n",
       "            0.12335, 0.12274, 0.1219 , 0.12146, 0.12103, 0.12054, 0.1193 ,\n",
       "            0.1192 , 0.1184 , 0.118  , 0.1166 , 0.11615, 0.11554, 0.11316,\n",
       "            0.113  , 0.1126 , 0.1122 , 0.11127, 0.1105 , 0.1099 , 0.1097 ,\n",
       "            0.10876, 0.1069 , 0.1058 , 0.1036 , 0.1034 , 0.1023 , 0.10126,\n",
       "            0.1009 , 0.0993 , 0.09894, 0.09827, 0.09705, 0.09686, 0.09656,\n",
       "            0.09534, 0.09485, 0.08527, 0.08466, 0.0772 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.09322034, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33050847, 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.34745762, 0.34745762, 0.3559322 ,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.3898305 , 0.3983051 , 0.3983051 ,\n",
       "            0.3983051 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44067797, 0.44915253, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.5762712 , 0.58474576,\n",
       "            0.58474576, 0.58474576, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.66101694, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6779661 , 0.6864407 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 , 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.69491524, 0.7033898 , 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7288136 , 0.7372881 ,\n",
       "            0.7372881 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8220339 , 0.8220339 , 0.8305085 , 0.83898306, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.9322034 , 0.9322034 , 0.9322034 , 0.94067794,\n",
       "            0.94067794, 0.94067794, 0.94067794, 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.09848485,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.12121212, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.18939394,\n",
       "            0.1969697 , 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.22727273, 0.24242425, 0.25      , 0.25      ,\n",
       "            0.25757575, 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.29545453, 0.3030303 ,\n",
       "            0.3030303 , 0.3030303 , 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.33333334, 0.33333334, 0.3409091 ,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.3560606 , 0.36363637,\n",
       "            0.36363637, 0.36363637, 0.36363637, 0.36363637, 0.36363637,\n",
       "            0.37121212, 0.37121212, 0.37878788, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.4090909 , 0.41666666, 0.42424244, 0.42424244,\n",
       "            0.42424244, 0.42424244, 0.42424244, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.45454547, 0.45454547, 0.45454547, 0.46212122, 0.46212122,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.50757575, 0.50757575, 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.5681818 , 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.6060606 , 0.6060606 , 0.6060606 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.6666667 , 0.6666667 , 0.6666667 , 0.6666667 ,\n",
       "            0.6666667 , 0.6666667 , 0.6666667 , 0.67424244, 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.68939394, 0.68939394, 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.719697  , 0.719697  , 0.72727275,\n",
       "            0.72727275, 0.72727275, 0.7348485 , 0.7348485 , 0.7348485 ,\n",
       "            0.74242425, 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.7651515 , 0.7651515 , 0.77272725, 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.84090906, 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.92424244, 0.92424244,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.9318182 ,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3533 , 0.3513 , 0.3442 , 0.3433 , 0.343  , 0.3396 ,\n",
       "            0.337  , 0.334  , 0.3328 , 0.3325 , 0.331  , 0.3276 , 0.3247 ,\n",
       "            0.3223 , 0.321  , 0.32   , 0.313  , 0.312  , 0.3115 , 0.31   ,\n",
       "            0.3098 , 0.3057 , 0.3047 , 0.3044 , 0.3025 , 0.3018 , 0.3005 ,\n",
       "            0.2988 , 0.2986 , 0.297  , 0.2966 , 0.2957 , 0.2954 , 0.294  ,\n",
       "            0.291  , 0.2908 , 0.2888 , 0.2886 , 0.288  , 0.2874 , 0.286  ,\n",
       "            0.2856 , 0.2854 , 0.2847 , 0.2844 , 0.2837 , 0.2832 , 0.2825 ,\n",
       "            0.282  , 0.2812 , 0.2805 , 0.2798 , 0.2795 , 0.279  , 0.2756 ,\n",
       "            0.275  , 0.2747 , 0.2712 , 0.2708 , 0.2703 , 0.27   , 0.2693 ,\n",
       "            0.2686 , 0.2654 , 0.2646 , 0.2644 , 0.2642 , 0.264  , 0.2637 ,\n",
       "            0.2634 , 0.2632 , 0.2627 , 0.2615 , 0.2612 , 0.2605 , 0.2595 ,\n",
       "            0.2568 , 0.2563 , 0.2559 , 0.2556 , 0.2534 , 0.2527 , 0.2524 ,\n",
       "            0.251  , 0.2507 , 0.2477 , 0.2467 , 0.2451 , 0.2429 , 0.239  ,\n",
       "            0.235  , 0.2314 , 0.2307 , 0.2303 , 0.2299 , 0.2297 , 0.2261 ,\n",
       "            0.2255 , 0.2246 , 0.2224 , 0.2213 , 0.2207 , 0.2202 , 0.2181 ,\n",
       "            0.2152 , 0.2147 , 0.2084 , 0.2079 , 0.2074 , 0.2068 , 0.2051 ,\n",
       "            0.2043 , 0.2017 , 0.2006 , 0.197  , 0.1965 , 0.1953 , 0.1947 ,\n",
       "            0.1942 , 0.1929 , 0.1924 , 0.1903 , 0.1887 , 0.1859 , 0.1844 ,\n",
       "            0.1823 , 0.1804 , 0.1771 , 0.177  , 0.1758 , 0.1752 , 0.1736 ,\n",
       "            0.1724 , 0.17   , 0.1694 , 0.1693 , 0.1688 , 0.1685 , 0.167  ,\n",
       "            0.1638 , 0.1626 , 0.1619 , 0.1616 , 0.161  , 0.1602 , 0.1581 ,\n",
       "            0.1577 , 0.1564 , 0.156  , 0.1555 , 0.1554 , 0.155  , 0.1547 ,\n",
       "            0.1534 , 0.1533 , 0.1528 , 0.1525 , 0.1523 , 0.1517 , 0.1511 ,\n",
       "            0.1505 , 0.1504 , 0.1501 , 0.1498 , 0.1497 , 0.1495 , 0.1492 ,\n",
       "            0.1489 , 0.1472 , 0.1464 , 0.1462 , 0.1444 , 0.1442 , 0.1437 ,\n",
       "            0.1434 , 0.1422 , 0.1421 , 0.1406 , 0.1403 , 0.1377 , 0.1373 ,\n",
       "            0.1371 , 0.1345 , 0.1344 , 0.1338 , 0.1334 , 0.1322 , 0.1312 ,\n",
       "            0.131  , 0.1301 , 0.13   , 0.1295 , 0.129  , 0.1279 , 0.126  ,\n",
       "            0.1245 , 0.1243 , 0.1242 , 0.1238 , 0.12335, 0.1219 , 0.1213 ,\n",
       "            0.12054, 0.12024, 0.1201 , 0.1193 , 0.1192 , 0.1186 , 0.1184 ,\n",
       "            0.11816, 0.118  , 0.11597, 0.11536, 0.115  , 0.11475, 0.11456,\n",
       "            0.113  , 0.1128 , 0.1126 , 0.111  , 0.11066, 0.1103 , 0.1082 ,\n",
       "            0.1041 , 0.10175, 0.1005 , 0.0927 , 0.0888 , 0.0887 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.09322034, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.1779661 , 0.18644068, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.21186441, 0.21186441, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2457627 , 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.3644068 , 0.37288135, 0.38135594, 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.3898305 , 0.3898305 , 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.40677965, 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5423729 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.55932206, 0.55932206, 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.6101695 , 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7033898 , 0.7118644 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7542373 , 0.7542373 , 0.7542373 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.8898305 , 0.89830506, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.11363637, 0.12121212, 0.12878788, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.22727273, 0.24242425, 0.25      , 0.25      ,\n",
       "            0.25757575, 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.28787878, 0.29545453, 0.29545453, 0.29545453,\n",
       "            0.3030303 , 0.3030303 , 0.31060606, 0.3181818 , 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.33333334, 0.3409091 , 0.3409091 ,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.3560606 , 0.3560606 ,\n",
       "            0.36363637, 0.36363637, 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.4090909 ,\n",
       "            0.4090909 , 0.4090909 , 0.41666666, 0.42424244, 0.42424244,\n",
       "            0.42424244, 0.42424244, 0.4318182 , 0.4318182 , 0.43939394,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.43939394, 0.4469697 ,\n",
       "            0.4469697 , 0.4469697 , 0.45454547, 0.45454547, 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.46969697, 0.46969697, 0.47727272,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.5       ,\n",
       "            0.50757575, 0.50757575, 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.6666667 , 0.67424244, 0.67424244,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.68939394, 0.6969697 ,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.77272725, 0.77272725, 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.81060606, 0.8181818 , 0.8181818 ,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8636364 , 0.8636364 ,\n",
       "            0.8712121 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3508 , 0.3474 , 0.3425 , 0.3386 , 0.3362 , 0.336  ,\n",
       "            0.3352 , 0.333  , 0.3325 , 0.3323 , 0.3276 , 0.324  , 0.3237 ,\n",
       "            0.3228 , 0.315  , 0.3123 , 0.312  , 0.3113 , 0.311  , 0.3096 ,\n",
       "            0.3074 , 0.3064 , 0.3054 , 0.3032 , 0.3027 , 0.3018 , 0.3015 ,\n",
       "            0.3    , 0.2986 , 0.298  , 0.2974 , 0.297  , 0.2957 , 0.2952 ,\n",
       "            0.293  , 0.291  , 0.2908 , 0.2905 , 0.29   , 0.2898 , 0.289  ,\n",
       "            0.2878 , 0.2876 , 0.2869 , 0.2864 , 0.286  , 0.2856 , 0.285  ,\n",
       "            0.2847 , 0.2842 , 0.2837 , 0.282  , 0.2815 , 0.281  , 0.2786 ,\n",
       "            0.278  , 0.2766 , 0.2747 , 0.2742 , 0.2737 , 0.2732 , 0.2727 ,\n",
       "            0.272  , 0.2717 , 0.269  , 0.2683 , 0.268  , 0.267  , 0.2664 ,\n",
       "            0.266  , 0.2659 , 0.265  , 0.2646 , 0.264  , 0.2632 , 0.2627 ,\n",
       "            0.261  , 0.2607 , 0.2595 , 0.2585 , 0.2568 , 0.2556 , 0.2542 ,\n",
       "            0.2522 , 0.252  , 0.2515 , 0.2512 , 0.251  , 0.2502 , 0.2483 ,\n",
       "            0.2458 , 0.2444 , 0.243  , 0.2411 , 0.2366 , 0.2356 , 0.2355 ,\n",
       "            0.2347 , 0.2322 , 0.2316 , 0.231  , 0.2294 , 0.2289 , 0.2286 ,\n",
       "            0.2249 , 0.2239 , 0.2222 , 0.2213 , 0.2207 , 0.2184 , 0.2168 ,\n",
       "            0.2166 , 0.2148 , 0.2123 , 0.212  , 0.2114 , 0.2108 , 0.2095 ,\n",
       "            0.2086 , 0.208  , 0.205  , 0.2032 , 0.2023 , 0.2007 , 0.2004 ,\n",
       "            0.199  , 0.1971 , 0.197  , 0.1959 , 0.1942 , 0.1929 , 0.1917 ,\n",
       "            0.1913 , 0.1904 , 0.19   , 0.1885 , 0.188  , 0.1864 , 0.1859 ,\n",
       "            0.1855 , 0.1852 , 0.1831 , 0.1819 , 0.1798 , 0.1797 , 0.1792 ,\n",
       "            0.179  , 0.1785 , 0.1776 , 0.1774 , 0.177  , 0.1766 , 0.1765 ,\n",
       "            0.1755 , 0.1746 , 0.1744 , 0.1743 , 0.1741 , 0.1735 , 0.1725 ,\n",
       "            0.1724 , 0.1711 , 0.1707 , 0.1704 , 0.1703 , 0.17   , 0.1692 ,\n",
       "            0.1688 , 0.1687 , 0.1682 , 0.1654 , 0.1648 , 0.1636 , 0.1631 ,\n",
       "            0.1626 , 0.162  , 0.1619 , 0.1616 , 0.1608 , 0.1599 , 0.1598 ,\n",
       "            0.1588 , 0.1581 , 0.1555 , 0.155  , 0.1549 , 0.1521 , 0.1517 ,\n",
       "            0.1514 , 0.1501 , 0.15   , 0.1494 , 0.1492 , 0.1475 , 0.1458 ,\n",
       "            0.1456 , 0.1447 , 0.1445 , 0.1425 , 0.1415 , 0.1412 , 0.141  ,\n",
       "            0.1405 , 0.1394 , 0.139  , 0.1388 , 0.1385 , 0.138  , 0.1375 ,\n",
       "            0.1372 , 0.137  , 0.1359 , 0.1351 , 0.134  , 0.133  , 0.1329 ,\n",
       "            0.1328 , 0.1322 , 0.1283 , 0.1257 , 0.1255 , 0.1238 , 0.12366,\n",
       "            0.1223 , 0.1195 , 0.119  , 0.11456, 0.1045 , 0.10376],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.15254237, 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.19491525, 0.19491525, 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.19491525, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.38135594, 0.38135594, 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.3898305 , 0.3898305 , 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.40677965, 0.40677965, 0.40677965,\n",
       "            0.40677965, 0.40677965, 0.40677965, 0.41525424, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.42372882, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.58474576, 0.58474576,\n",
       "            0.59322035, 0.59322035, 0.60169494, 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.61864406, 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.63559324, 0.6440678 , 0.6440678 , 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.7288136 , 0.7372881 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12878788, 0.13636364, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.21212122, 0.21969697, 0.21969697, 0.21969697, 0.22727273,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.25757575, 0.25757575, 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.3030303 ,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.3560606 , 0.3560606 , 0.3560606 , 0.3560606 ,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.4090909 , 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.43939394, 0.4469697 ,\n",
       "            0.4469697 , 0.4469697 , 0.4469697 , 0.45454547, 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.45454547, 0.46212122, 0.47727272,\n",
       "            0.47727272, 0.4848485 , 0.4848485 , 0.4848485 , 0.4848485 ,\n",
       "            0.4848485 , 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.54545456, 0.5530303 , 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.68939394, 0.68939394, 0.6969697 ,\n",
       "            0.70454544, 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.7878788 , 0.79545456, 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8484849 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.9318182 , 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.35   , 0.3455 , 0.343  , 0.339  , 0.3364 , 0.335  ,\n",
       "            0.3335 , 0.3333 , 0.3318 , 0.33   , 0.3289 , 0.3257 , 0.3252 ,\n",
       "            0.3184 , 0.3174 , 0.3137 , 0.3118 , 0.309  , 0.3076 , 0.3057 ,\n",
       "            0.3052 , 0.304  , 0.3025 , 0.3013 , 0.3    , 0.2986 , 0.297  ,\n",
       "            0.2964 , 0.2961 , 0.2954 , 0.2944 , 0.294  , 0.2937 , 0.293  ,\n",
       "            0.2927 , 0.2922 , 0.2915 , 0.2913 , 0.291  , 0.2908 , 0.2898 ,\n",
       "            0.289  , 0.288  , 0.2874 , 0.2864 , 0.2856 , 0.2854 , 0.2837 ,\n",
       "            0.2825 , 0.282  , 0.2817 , 0.2815 , 0.2803 , 0.2776 , 0.2769 ,\n",
       "            0.2764 , 0.2761 , 0.2756 , 0.2751 , 0.2747 , 0.2732 , 0.2722 ,\n",
       "            0.272  , 0.2717 , 0.2712 , 0.27   , 0.2693 , 0.268  , 0.2673 ,\n",
       "            0.2668 , 0.2664 , 0.2659 , 0.2634 , 0.261  , 0.2588 , 0.2578 ,\n",
       "            0.2568 , 0.2563 , 0.2556 , 0.2546 , 0.254  , 0.2527 , 0.2505 ,\n",
       "            0.2473 , 0.247  , 0.2467 , 0.2456 , 0.2451 , 0.2433 , 0.2428 ,\n",
       "            0.2424 , 0.2415 , 0.2413 , 0.241  , 0.2405 , 0.2399 , 0.2391 ,\n",
       "            0.2386 , 0.2384 , 0.2378 , 0.2375 , 0.2362 , 0.2355 , 0.234  ,\n",
       "            0.2334 , 0.2325 , 0.231  , 0.2299 , 0.2278 , 0.2269 , 0.2263 ,\n",
       "            0.2255 , 0.2247 , 0.2233 , 0.2229 , 0.2222 , 0.2211 , 0.2191 ,\n",
       "            0.2167 , 0.2162 , 0.2144 , 0.2139 , 0.213  , 0.2128 , 0.2124 ,\n",
       "            0.2119 , 0.2114 , 0.2113 , 0.2109 , 0.2104 , 0.2096 , 0.2086 ,\n",
       "            0.2081 , 0.2076 , 0.2074 , 0.2073 , 0.2068 , 0.2064 , 0.206  ,\n",
       "            0.2054 , 0.2051 , 0.2034 , 0.2029 , 0.2021 , 0.2017 , 0.2006 ,\n",
       "            0.1998 , 0.1981 , 0.1979 , 0.1973 , 0.1964 , 0.1958 , 0.1954 ,\n",
       "            0.1953 , 0.1942 , 0.1937 , 0.1923 , 0.1917 , 0.1912 , 0.1906 ,\n",
       "            0.1903 , 0.1896 , 0.1893 , 0.1887 , 0.1884 , 0.1879 , 0.1874 ,\n",
       "            0.1873 , 0.1865 , 0.1863 , 0.1858 , 0.1846 , 0.1833 , 0.1831 ,\n",
       "            0.183  , 0.1827 , 0.182  , 0.1819 , 0.1807 , 0.18   , 0.1797 ,\n",
       "            0.1785 , 0.1783 , 0.1782 , 0.1757 , 0.1741 , 0.1738 , 0.1736 ,\n",
       "            0.1727 , 0.1726 , 0.1721 , 0.1707 , 0.167  , 0.1653 , 0.1635 ,\n",
       "            0.1631 , 0.1627 , 0.1626 , 0.1624 , 0.1611 , 0.16   , 0.1578 ,\n",
       "            0.1559 , 0.1549 , 0.1527 , 0.1526 , 0.1525 , 0.1523 , 0.1515 ,\n",
       "            0.1506 , 0.15   , 0.149  , 0.1473 , 0.1472 , 0.147  , 0.1467 ,\n",
       "            0.1465 , 0.1464 , 0.1448 , 0.1425 , 0.1396 , 0.1393 , 0.1377 ,\n",
       "            0.1355 , 0.1295 , 0.12177, 0.12036, 0.1186 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.18644068, 0.18644068, 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.20338982, 0.20338982,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.27966103, 0.29661018,\n",
       "            0.29661018, 0.29661018, 0.29661018, 0.29661018, 0.29661018,\n",
       "            0.30508474, 0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.33898306, 0.33898306, 0.33898306, 0.33898306,\n",
       "            0.33898306, 0.34745762, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.3644068 , 0.3644068 , 0.3644068 , 0.3644068 , 0.3644068 ,\n",
       "            0.3644068 , 0.37288135, 0.37288135, 0.38135594, 0.38135594,\n",
       "            0.38135594, 0.38135594, 0.3898305 , 0.3898305 , 0.3983051 ,\n",
       "            0.3983051 , 0.3983051 , 0.40677965, 0.40677965, 0.40677965,\n",
       "            0.40677965, 0.40677965, 0.41525424, 0.41525424, 0.41525424,\n",
       "            0.41525424, 0.41525424, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.21212122, 0.21969697, 0.21969697, 0.22727273,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25      ,\n",
       "            0.25757575, 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.29545453, 0.3030303 , 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.3181818 , 0.3181818 , 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.33333334, 0.3409091 , 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.3560606 , 0.3560606 , 0.3560606 ,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.42424244, 0.4318182 , 0.4318182 , 0.43939394,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46212122,\n",
       "            0.46212122, 0.46212122, 0.46969697, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.4848485 , 0.49242425, 0.5       , 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.54545456,\n",
       "            0.54545456, 0.54545456, 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.59090906, 0.5984849 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6818182 , 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.7348485 , 0.7348485 , 0.74242425, 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.7651515 , 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8712121 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.9166667 , 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.353 , 0.3477, 0.3474, 0.3438, 0.3408, 0.3406, 0.3384,\n",
       "            0.338 , 0.3342, 0.3323, 0.3303, 0.3289, 0.324 , 0.3196, 0.319 ,\n",
       "            0.3167, 0.3152, 0.315 , 0.3147, 0.3135, 0.3115, 0.3113, 0.31  ,\n",
       "            0.3088, 0.3079, 0.3062, 0.305 , 0.304 , 0.3025, 0.3013, 0.3008,\n",
       "            0.3005, 0.3003, 0.3   , 0.2998, 0.299 , 0.2983, 0.298 , 0.2974,\n",
       "            0.2969, 0.2961, 0.2952, 0.295 , 0.2935, 0.2927, 0.2925, 0.292 ,\n",
       "            0.2917, 0.2903, 0.2896, 0.289 , 0.2886, 0.2874, 0.2861, 0.2852,\n",
       "            0.2847, 0.2844, 0.2837, 0.282 , 0.2815, 0.281 , 0.28  , 0.2798,\n",
       "            0.2793, 0.2788, 0.2776, 0.277 , 0.2766, 0.2742, 0.2737, 0.2698,\n",
       "            0.269 , 0.268 , 0.267 , 0.2664, 0.2654, 0.2651, 0.264 , 0.2625,\n",
       "            0.2622, 0.262 , 0.2603, 0.2593, 0.259 , 0.2588, 0.2585, 0.2573,\n",
       "            0.2563, 0.2551, 0.253 , 0.2522, 0.2515, 0.2505, 0.2496, 0.2493,\n",
       "            0.2489, 0.2485, 0.2482, 0.2477, 0.2467, 0.2451, 0.2448, 0.2444,\n",
       "            0.2433, 0.243 , 0.2422, 0.2411, 0.2407, 0.2405, 0.2402, 0.2395,\n",
       "            0.2391, 0.239 , 0.2388, 0.2386, 0.2379, 0.2375, 0.2372, 0.2367,\n",
       "            0.2366, 0.236 , 0.235 , 0.2347, 0.2335, 0.2332, 0.2323, 0.2319,\n",
       "            0.2318, 0.2311, 0.2307, 0.2306, 0.2303, 0.2299, 0.2295, 0.2273,\n",
       "            0.2268, 0.226 , 0.2252, 0.2249, 0.2246, 0.2233, 0.223 , 0.2229,\n",
       "            0.2227, 0.2225, 0.222 , 0.2218, 0.2211, 0.2202, 0.22  , 0.2197,\n",
       "            0.2186, 0.2181, 0.2173, 0.217 , 0.2157, 0.2148, 0.2103, 0.2098,\n",
       "            0.2091, 0.2084, 0.2079, 0.207 , 0.2065, 0.2058, 0.2039, 0.2037,\n",
       "            0.2035, 0.2015, 0.2013, 0.2009, 0.2006, 0.1996, 0.1995, 0.1971,\n",
       "            0.197 , 0.1929, 0.1917, 0.1913, 0.191 , 0.1884, 0.1865, 0.186 ,\n",
       "            0.1855, 0.1853, 0.1846, 0.1844, 0.1835, 0.1804, 0.179 , 0.1788,\n",
       "            0.1776, 0.1765, 0.1764, 0.1753, 0.1746, 0.1735, 0.1718, 0.1716,\n",
       "            0.1683, 0.1671, 0.1665, 0.1656, 0.1646, 0.164 , 0.1632, 0.1626,\n",
       "            0.1611, 0.1604, 0.1597, 0.1594, 0.1587, 0.1584, 0.1583, 0.1562,\n",
       "            0.1531, 0.1523, 0.1511, 0.144 , 0.1384, 0.1364, 0.1152],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.15254237, 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.19491525,\n",
       "            0.19491525, 0.19491525, 0.19491525, 0.19491525, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.21186441, 0.21186441, 0.21186441,\n",
       "            0.21186441, 0.21186441, 0.21186441, 0.21186441, 0.22881356,\n",
       "            0.22881356, 0.22881356, 0.22881356, 0.22881356, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.2542373 , 0.2542373 , 0.2542373 , 0.2542373 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.2881356 , 0.29661018,\n",
       "            0.29661018, 0.29661018, 0.29661018, 0.29661018, 0.29661018,\n",
       "            0.30508474, 0.30508474, 0.30508474, 0.30508474, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.20454545, 0.21212122, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.3181818 ,\n",
       "            0.3181818 , 0.3181818 , 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.33333334, 0.33333334, 0.3409091 , 0.3560606 , 0.3560606 ,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.4318182 , 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.49242425, 0.5       ,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.530303  , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.57575756, 0.5833333 , 0.5833333 ,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6287879 , 0.6363636 , 0.6515151 , 0.6515151 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.68939394, 0.70454544, 0.7121212 , 0.719697  , 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.81060606, 0.8181818 ,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.358  , 0.3535 , 0.3518 , 0.3503 , 0.3481 , 0.348  ,\n",
       "            0.3457 , 0.3452 , 0.3418 , 0.34   , 0.3381 , 0.3335 , 0.3306 ,\n",
       "            0.3296 , 0.3284 , 0.3271 , 0.3242 , 0.324  , 0.3223 , 0.3203 ,\n",
       "            0.32   , 0.3196 , 0.3184 , 0.3171 , 0.3154 , 0.314  , 0.3137 ,\n",
       "            0.3132 , 0.312  , 0.3105 , 0.3103 , 0.3098 , 0.3096 , 0.3093 ,\n",
       "            0.3083 , 0.3079 , 0.3071 , 0.3066 , 0.3064 , 0.3052 , 0.305  ,\n",
       "            0.3032 , 0.3025 , 0.302  , 0.3018 , 0.3015 , 0.3003 , 0.2998 ,\n",
       "            0.2996 , 0.2993 , 0.2988 , 0.2974 , 0.2957 , 0.294  , 0.2937 ,\n",
       "            0.2922 , 0.2913 , 0.291  , 0.2908 , 0.2905 , 0.2903 , 0.29   ,\n",
       "            0.2898 , 0.2896 , 0.2893 , 0.289  , 0.2888 , 0.2886 , 0.287  ,\n",
       "            0.2869 , 0.2866 , 0.2856 , 0.2852 , 0.2847 , 0.2837 , 0.2822 ,\n",
       "            0.282  , 0.2817 , 0.281  , 0.2808 , 0.2805 , 0.28   , 0.2795 ,\n",
       "            0.279  , 0.2786 , 0.2783 , 0.2776 , 0.277  , 0.2766 , 0.2761 ,\n",
       "            0.276  , 0.2751 , 0.2747 , 0.2737 , 0.2734 , 0.2732 , 0.272  ,\n",
       "            0.2712 , 0.2708 , 0.2703 , 0.27   , 0.269  , 0.2688 , 0.2686 ,\n",
       "            0.268  , 0.2673 , 0.2659 , 0.265  , 0.2646 , 0.2642 , 0.264  ,\n",
       "            0.2637 , 0.2634 , 0.263  , 0.2627 , 0.262  , 0.261  , 0.2605 ,\n",
       "            0.2595 , 0.2593 , 0.2585 , 0.2583 , 0.258  , 0.2576 , 0.257  ,\n",
       "            0.2563 , 0.2556 , 0.2542 , 0.254  , 0.2534 , 0.253  , 0.2524 ,\n",
       "            0.2522 , 0.2483 , 0.2463 , 0.2456 , 0.2441 , 0.2437 , 0.2417 ,\n",
       "            0.2395 , 0.2394 , 0.2378 , 0.2374 , 0.2372 , 0.2368 , 0.2367 ,\n",
       "            0.2335 , 0.2322 , 0.2313 , 0.2295 , 0.2289 , 0.2286 , 0.2255 ,\n",
       "            0.2238 , 0.2218 , 0.2213 , 0.22   , 0.2197 , 0.2186 , 0.2184 ,\n",
       "            0.2173 , 0.2168 , 0.2163 , 0.2153 , 0.215  , 0.2144 , 0.2142 ,\n",
       "            0.2128 , 0.2089 , 0.208  , 0.2079 , 0.2076 , 0.2073 , 0.2056 ,\n",
       "            0.2042 , 0.2032 , 0.2015 , 0.201  , 0.2007 , 0.1996 , 0.1985 ,\n",
       "            0.1979 , 0.1973 , 0.195  , 0.1941 , 0.1937 , 0.1929 , 0.1925 ,\n",
       "            0.1901 , 0.1882 , 0.1865 , 0.1858 , 0.1853 , 0.1843 , 0.1836 ,\n",
       "            0.182  , 0.1805 , 0.1783 , 0.1781 , 0.1776 , 0.1775 , 0.1772 ,\n",
       "            0.1752 , 0.1746 , 0.1744 , 0.1726 , 0.1725 , 0.1716 , 0.1638 ,\n",
       "            0.163  , 0.1619 , 0.1587 , 0.1355 , 0.11127], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.18644068, 0.18644068, 0.19491525,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22033899, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.2457627 , 0.2457627 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.2881356 , 0.29661018,\n",
       "            0.29661018, 0.29661018, 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5508475 , 0.55932206, 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.69491524, 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7457627 , 0.7542373 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.15151516, 0.1590909 ,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.3030303 , 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3560606 , 0.37121212, 0.37878788,\n",
       "            0.37878788, 0.38636363, 0.4090909 , 0.42424244, 0.42424244,\n",
       "            0.4469697 , 0.45454547, 0.45454547, 0.46212122, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.5378788 , 0.5530303 , 0.5530303 , 0.56060606, 0.59090906,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6515151 , 0.6666667 , 0.67424244, 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.70454544, 0.719697  ,\n",
       "            0.719697  , 0.72727275, 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75      , 0.75757575, 0.7651515 , 0.7651515 ,\n",
       "            0.77272725, 0.77272725, 0.780303  , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.92424244, 0.92424244, 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3596, 0.3567, 0.353 , 0.3525, 0.3503, 0.3481, 0.3477,\n",
       "            0.3455, 0.345 , 0.3408, 0.338 , 0.3313, 0.331 , 0.3306, 0.3284,\n",
       "            0.3281, 0.328 , 0.3274, 0.3271, 0.3267, 0.326 , 0.325 , 0.3247,\n",
       "            0.3245, 0.3242, 0.324 , 0.323 , 0.322 , 0.3218, 0.3213, 0.3208,\n",
       "            0.3206, 0.32  , 0.3196, 0.3193, 0.319 , 0.3188, 0.3176, 0.3167,\n",
       "            0.3164, 0.3162, 0.3154, 0.3152, 0.3147, 0.3145, 0.3142, 0.3137,\n",
       "            0.3135, 0.3123, 0.312 , 0.3115, 0.311 , 0.3108, 0.3103, 0.31  ,\n",
       "            0.3096, 0.3093, 0.3079, 0.3074, 0.3071, 0.306 , 0.3047, 0.3042,\n",
       "            0.304 , 0.3032, 0.3027, 0.3018, 0.3013, 0.301 , 0.3008, 0.3   ,\n",
       "            0.299 , 0.2988, 0.2983, 0.298 , 0.2979, 0.2976, 0.2974, 0.2969,\n",
       "            0.2966, 0.2964, 0.2957, 0.2954, 0.2952, 0.295 , 0.2947, 0.2944,\n",
       "            0.2935, 0.2927, 0.292 , 0.2913, 0.2905, 0.2903, 0.289 , 0.2886,\n",
       "            0.288 , 0.2866, 0.286 , 0.2856, 0.2832, 0.2815, 0.2805, 0.2798,\n",
       "            0.2793, 0.2783, 0.2776, 0.2766, 0.2751, 0.275 , 0.2734, 0.2715,\n",
       "            0.2705, 0.2695, 0.268 , 0.2654, 0.265 , 0.2637, 0.2595, 0.2593,\n",
       "            0.258 , 0.2534, 0.2524, 0.252 , 0.2502, 0.2487, 0.248 , 0.247 ,\n",
       "            0.2462, 0.2452, 0.244 , 0.2433, 0.243 , 0.2418, 0.2405, 0.2397,\n",
       "            0.2374, 0.2362, 0.2339, 0.233 , 0.2328, 0.2318, 0.2314, 0.2313,\n",
       "            0.2311, 0.2303, 0.2295, 0.2289, 0.2273, 0.2269, 0.2268, 0.2249,\n",
       "            0.223 , 0.2229, 0.2217, 0.2216, 0.2212, 0.2202, 0.2194, 0.2185,\n",
       "            0.2181, 0.2172, 0.2166, 0.2152, 0.2147, 0.2134, 0.2123, 0.2115,\n",
       "            0.2094, 0.2089, 0.2076, 0.2069, 0.2065, 0.2058, 0.2053, 0.2031,\n",
       "            0.202 , 0.2006, 0.1998, 0.1968, 0.1959, 0.1954, 0.1953, 0.1929,\n",
       "            0.191 , 0.1906, 0.1904, 0.19  , 0.1896, 0.1882, 0.1877, 0.1852,\n",
       "            0.1848, 0.1813, 0.1794, 0.1768, 0.172 , 0.1528, 0.1257, 0.1063],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.1779661 , 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.18644068, 0.18644068, 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.20338982, 0.21186441,\n",
       "            0.22881356, 0.22881356, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.2881356 , 0.29661018,\n",
       "            0.29661018, 0.30508474, 0.30508474, 0.30508474, 0.31355932,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.34745762, 0.34745762, 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28787878, 0.29545453, 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.38636363,\n",
       "            0.3939394 , 0.4090909 , 0.41666666, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.49242425, 0.50757575, 0.5151515 , 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6212121 , 0.6212121 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6666667 ,\n",
       "            0.6818182 , 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.780303  , 0.780303  , 0.79545456,\n",
       "            0.8030303 , 0.8030303 , 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3887, 0.3882, 0.3877, 0.3867, 0.3862, 0.3835, 0.3833,\n",
       "            0.3816, 0.3804, 0.3801, 0.3782, 0.3772, 0.376 , 0.3755, 0.3728,\n",
       "            0.3726, 0.371 , 0.3708, 0.3691, 0.3687, 0.3652, 0.3645, 0.3633,\n",
       "            0.3625, 0.3616, 0.3613, 0.361 , 0.3599, 0.3584, 0.358 , 0.357 ,\n",
       "            0.3567, 0.3562, 0.3552, 0.355 , 0.3545, 0.3538, 0.3535, 0.3533,\n",
       "            0.353 , 0.3525, 0.3518, 0.3516, 0.3513, 0.351 , 0.3494, 0.3481,\n",
       "            0.3474, 0.346 , 0.3457, 0.3445, 0.3425, 0.3418, 0.3416, 0.3367,\n",
       "            0.3364, 0.3354, 0.3347, 0.333 , 0.3325, 0.331 , 0.3308, 0.3306,\n",
       "            0.3298, 0.329 , 0.3286, 0.328 , 0.3274, 0.3262, 0.326 , 0.3257,\n",
       "            0.3252, 0.3245, 0.3242, 0.3213, 0.321 , 0.3208, 0.3196, 0.3193,\n",
       "            0.3179, 0.3176, 0.3171, 0.3162, 0.316 , 0.3157, 0.3152, 0.3137,\n",
       "            0.3132, 0.313 , 0.3125, 0.3118, 0.3105, 0.3103, 0.3088, 0.3086,\n",
       "            0.3079, 0.3076, 0.3074, 0.3066, 0.3064, 0.306 , 0.3044, 0.3037,\n",
       "            0.3027, 0.3025, 0.3015, 0.3013, 0.301 , 0.3005, 0.3003, 0.3   ,\n",
       "            0.2986, 0.2976, 0.297 , 0.2952, 0.2944, 0.294 , 0.293 , 0.2927,\n",
       "            0.29  , 0.2866, 0.2861, 0.2854, 0.2852, 0.2842, 0.2832, 0.2815,\n",
       "            0.2798, 0.2795, 0.2788, 0.2776, 0.2766, 0.2761, 0.2754, 0.274 ,\n",
       "            0.2732, 0.2727, 0.2703, 0.2683, 0.2673, 0.2659, 0.2656, 0.265 ,\n",
       "            0.2646, 0.2617, 0.2612, 0.2603, 0.2598, 0.2563, 0.255 , 0.2542,\n",
       "            0.2512, 0.2487, 0.2482, 0.2463, 0.246 , 0.2448, 0.2406, 0.2402,\n",
       "            0.2399, 0.239 , 0.2383, 0.2382, 0.2367, 0.2363, 0.236 , 0.2346,\n",
       "            0.234 , 0.2335, 0.2328, 0.2327, 0.2323, 0.2316, 0.2313, 0.2311,\n",
       "            0.2299, 0.2286, 0.2277, 0.2272, 0.2269, 0.2257, 0.2255, 0.2246,\n",
       "            0.224 , 0.2235, 0.2212, 0.2207, 0.2205, 0.2191, 0.2185, 0.2175,\n",
       "            0.217 , 0.2147, 0.2142, 0.2135, 0.2119, 0.211 , 0.2096, 0.2091,\n",
       "            0.2054, 0.2051, 0.2048, 0.2045, 0.2043, 0.2032, 0.2028, 0.1998,\n",
       "            0.1974, 0.1968, 0.1964, 0.1953, 0.1952, 0.1947, 0.1923, 0.1711,\n",
       "            0.146 , 0.1192, 0.1052], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.22881356, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.2881356 , 0.2881356 ,\n",
       "            0.29661018, 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.33898306, 0.34745762, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.6440678 ,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.41666666, 0.42424244,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.5833333 , 0.59090906, 0.59090906, 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6363636 ,\n",
       "            0.6363636 , 0.6515151 , 0.65909094, 0.6666667 , 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.8333333 , 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4526 , 0.4458 , 0.4426 , 0.4414 , 0.4387 , 0.4385 ,\n",
       "            0.4375 , 0.4358 , 0.435  , 0.4326 , 0.428  , 0.4248 , 0.4243 ,\n",
       "            0.4238 , 0.421  , 0.419  , 0.4146 , 0.412  , 0.4106 , 0.4084 ,\n",
       "            0.4062 , 0.4053 , 0.405  , 0.4043 , 0.403  , 0.4023 , 0.4011 ,\n",
       "            0.399  , 0.3982 , 0.3975 , 0.3967 , 0.3962 , 0.3958 , 0.3955 ,\n",
       "            0.3945 , 0.3933 , 0.3894 , 0.3865 , 0.3862 , 0.3823 , 0.3804 ,\n",
       "            0.3777 , 0.3752 , 0.3733 , 0.3718 , 0.3691 , 0.3672 , 0.3667 ,\n",
       "            0.3662 , 0.366  , 0.3655 , 0.3645 , 0.3633 , 0.3613 , 0.3606 ,\n",
       "            0.36   , 0.3599 , 0.3584 , 0.358  , 0.3555 , 0.3525 , 0.3518 ,\n",
       "            0.3516 , 0.3477 , 0.345  , 0.3447 , 0.344  , 0.343  , 0.3418 ,\n",
       "            0.3408 , 0.34   , 0.3398 , 0.3396 , 0.3394 , 0.3384 , 0.3381 ,\n",
       "            0.3374 , 0.337  , 0.3354 , 0.335  , 0.3347 , 0.3335 , 0.333  ,\n",
       "            0.3328 , 0.3315 , 0.3298 , 0.329  , 0.3289 , 0.3284 , 0.3281 ,\n",
       "            0.328  , 0.3267 , 0.3264 , 0.3252 , 0.325  , 0.3245 , 0.324  ,\n",
       "            0.3225 , 0.322  , 0.3218 , 0.3215 , 0.3196 , 0.3193 , 0.3184 ,\n",
       "            0.318  , 0.3176 , 0.3164 , 0.3162 , 0.316  , 0.3154 , 0.3127 ,\n",
       "            0.3125 , 0.3115 , 0.311  , 0.3108 , 0.3105 , 0.3093 , 0.3088 ,\n",
       "            0.3086 , 0.3066 , 0.3052 , 0.305  , 0.3047 , 0.3042 , 0.303  ,\n",
       "            0.3027 , 0.3015 , 0.2969 , 0.2966 , 0.2964 , 0.2961 , 0.2947 ,\n",
       "            0.2932 , 0.2922 , 0.2917 , 0.291  , 0.2908 , 0.2905 , 0.2893 ,\n",
       "            0.288  , 0.2878 , 0.2874 , 0.2866 , 0.2854 , 0.2852 , 0.284  ,\n",
       "            0.2837 , 0.2832 , 0.2827 , 0.2812 , 0.281  , 0.2808 , 0.2788 ,\n",
       "            0.2786 , 0.277  , 0.275  , 0.2744 , 0.2737 , 0.273  , 0.2705 ,\n",
       "            0.2673 , 0.2668 , 0.2637 , 0.2634 , 0.2627 , 0.2617 , 0.2595 ,\n",
       "            0.2593 , 0.2585 , 0.2537 , 0.2527 , 0.2517 , 0.251  , 0.2507 ,\n",
       "            0.249  , 0.2487 , 0.2477 , 0.2456 , 0.2445 , 0.2434 , 0.2433 ,\n",
       "            0.2401 , 0.2395 , 0.2394 , 0.2379 , 0.2375 , 0.2372 , 0.2368 ,\n",
       "            0.2363 , 0.2344 , 0.2328 , 0.2316 , 0.2311 , 0.2306 , 0.2302 ,\n",
       "            0.2297 , 0.2295 , 0.2286 , 0.2272 , 0.2264 , 0.2261 , 0.2256 ,\n",
       "            0.224  , 0.223  , 0.2229 , 0.2222 , 0.2216 , 0.2207 , 0.2205 ,\n",
       "            0.2203 , 0.2202 , 0.2186 , 0.2163 , 0.2152 , 0.2109 , 0.2106 ,\n",
       "            0.2081 , 0.2079 , 0.2056 , 0.2006 , 0.1968 , 0.195  , 0.1917 ,\n",
       "            0.1886 , 0.1674 , 0.138  , 0.11145, 0.10156], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.01515152, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.15254237, 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.18644068, 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.2542373 , 0.2542373 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33898306, 0.34745762, 0.34745762, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.38135594, 0.3898305 ,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.4915254 , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6864407 , 0.69491524, 0.7118644 , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.530303  , 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.77272725, 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.8030303 , 0.81060606, 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8636364 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.9318182 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.521  , 0.5063 , 0.4988 , 0.4985 , 0.4973 , 0.4958 ,\n",
       "            0.4944 , 0.494  , 0.491  , 0.4866 , 0.4783 , 0.4778 , 0.4731 ,\n",
       "            0.472  , 0.4685 , 0.4678 , 0.4673 , 0.461  , 0.4565 , 0.4556 ,\n",
       "            0.4546 , 0.454  , 0.4536 , 0.452  , 0.4495 , 0.4475 , 0.446  ,\n",
       "            0.4453 , 0.4443 , 0.4414 , 0.4412 , 0.441  , 0.4382 , 0.437  ,\n",
       "            0.4363 , 0.4355 , 0.4353 , 0.4336 , 0.4229 , 0.421  , 0.4202 ,\n",
       "            0.42   , 0.4192 , 0.415  , 0.4043 , 0.4033 , 0.4026 , 0.402  ,\n",
       "            0.4001 , 0.3992 , 0.395  , 0.393  , 0.3882 , 0.3855 , 0.3853 ,\n",
       "            0.3762 , 0.375  , 0.3723 , 0.3718 , 0.3713 , 0.3704 , 0.3677 ,\n",
       "            0.3667 , 0.3665 , 0.3662 , 0.3657 , 0.364  , 0.3638 , 0.3635 ,\n",
       "            0.361  , 0.3574 , 0.3552 , 0.355  , 0.3506 , 0.3503 , 0.3496 ,\n",
       "            0.3494 , 0.3477 , 0.3464 , 0.346  , 0.3455 , 0.3452 , 0.345  ,\n",
       "            0.344  , 0.343  , 0.3418 , 0.3416 , 0.3403 , 0.3398 , 0.3389 ,\n",
       "            0.3384 , 0.3381 , 0.338  , 0.3374 , 0.3362 , 0.3357 , 0.3347 ,\n",
       "            0.3335 , 0.333  , 0.3315 , 0.3313 , 0.331  , 0.3306 , 0.3303 ,\n",
       "            0.3298 , 0.3296 , 0.3289 , 0.3286 , 0.3276 , 0.327  , 0.3252 ,\n",
       "            0.3245 , 0.3242 , 0.324  , 0.323  , 0.3218 , 0.3198 , 0.3193 ,\n",
       "            0.318  , 0.317  , 0.3162 , 0.3157 , 0.3154 , 0.3145 , 0.3135 ,\n",
       "            0.3132 , 0.3125 , 0.3105 , 0.31   , 0.3086 , 0.308  , 0.3076 ,\n",
       "            0.3047 , 0.3035 , 0.3032 , 0.303  , 0.3025 , 0.3015 , 0.3005 ,\n",
       "            0.2996 , 0.2993 , 0.2976 , 0.2974 , 0.2944 , 0.2935 , 0.2927 ,\n",
       "            0.2925 , 0.292  , 0.2917 , 0.2908 , 0.2903 , 0.2854 , 0.2852 ,\n",
       "            0.2844 , 0.2837 , 0.2832 , 0.2825 , 0.282  , 0.2815 , 0.2798 ,\n",
       "            0.2795 , 0.278  , 0.2766 , 0.2761 , 0.276  , 0.2751 , 0.2737 ,\n",
       "            0.2734 , 0.272  , 0.2712 , 0.2705 , 0.263  , 0.2605 , 0.2593 ,\n",
       "            0.258  , 0.257  , 0.256  , 0.2551 , 0.2537 , 0.252  , 0.2502 ,\n",
       "            0.248  , 0.2478 , 0.2477 , 0.2473 , 0.2471 , 0.2462 , 0.246  ,\n",
       "            0.2455 , 0.2451 , 0.2449 , 0.2444 , 0.2438 , 0.2428 , 0.2424 ,\n",
       "            0.2413 , 0.2395 , 0.2384 , 0.2382 , 0.2378 , 0.2367 , 0.2356 ,\n",
       "            0.2351 , 0.231  , 0.2307 , 0.2286 , 0.2283 , 0.2274 , 0.2256 ,\n",
       "            0.2235 , 0.2213 , 0.2189 , 0.2185 , 0.218  , 0.2158 , 0.2157 ,\n",
       "            0.2156 , 0.2081 , 0.1989 , 0.1984 , 0.19   , 0.1887 , 0.1879 ,\n",
       "            0.1857 , 0.1641 , 0.1306 , 0.1045 , 0.09827], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.15151516, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.11016949, 0.11016949, 0.11016949, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.12711865, 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.15254237, 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.16949153, 0.1779661 ,\n",
       "            0.1779661 , 0.18644068, 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.21186441, 0.21186441, 0.22033899, 0.22033899,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.2457627 , 0.2457627 ,\n",
       "            0.2542373 , 0.2542373 , 0.27966103, 0.2881356 , 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.34745762, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.38135594, 0.38135594, 0.3898305 ,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6864407 , 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.4318182 , 0.4318182 , 0.43939394,\n",
       "            0.43939394, 0.4469697 , 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.75      ,\n",
       "            0.75757575, 0.77272725, 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.582 , 0.5605, 0.552 , 0.5483, 0.548 , 0.5474, 0.546 ,\n",
       "            0.544 , 0.533 , 0.5264, 0.524 , 0.517 , 0.5166, 0.5156, 0.511 ,\n",
       "            0.505 , 0.503 , 0.502 , 0.4956, 0.4946, 0.4937, 0.4934, 0.4866,\n",
       "            0.4841, 0.483 , 0.4827, 0.4824, 0.48  , 0.4778, 0.4756, 0.4744,\n",
       "            0.4736, 0.4727, 0.4705, 0.4602, 0.4578, 0.4565, 0.4514, 0.4512,\n",
       "            0.4468, 0.4346, 0.4326, 0.4324, 0.4316, 0.4297, 0.4243, 0.418 ,\n",
       "            0.416 , 0.4146, 0.4136, 0.403 , 0.3992, 0.3914, 0.3877, 0.3872,\n",
       "            0.3857, 0.383 , 0.382 , 0.3818, 0.379 , 0.3784, 0.3767, 0.3765,\n",
       "            0.3752, 0.3718, 0.37  , 0.3699, 0.3687, 0.3677, 0.3667, 0.3628,\n",
       "            0.3623, 0.3606, 0.3594, 0.3591, 0.359 , 0.3584, 0.3577, 0.3572,\n",
       "            0.3564, 0.3547, 0.3538, 0.3533, 0.3528, 0.3523, 0.3499, 0.3496,\n",
       "            0.349 , 0.348 , 0.3477, 0.3464, 0.3452, 0.3447, 0.3438, 0.3433,\n",
       "            0.3416, 0.341 , 0.3408, 0.3406, 0.3403, 0.34  , 0.3394, 0.3376,\n",
       "            0.3372, 0.3367, 0.3364, 0.3354, 0.3352, 0.3347, 0.3337, 0.3335,\n",
       "            0.332 , 0.331 , 0.3298, 0.3286, 0.328 , 0.3274, 0.327 , 0.3267,\n",
       "            0.3254, 0.3247, 0.3225, 0.322 , 0.3218, 0.3206, 0.3203, 0.3157,\n",
       "            0.3152, 0.314 , 0.3132, 0.313 , 0.3125, 0.3113, 0.3093, 0.3088,\n",
       "            0.3083, 0.3074, 0.3064, 0.3062, 0.306 , 0.3044, 0.3037, 0.3027,\n",
       "            0.3025, 0.301 , 0.2998, 0.2996, 0.2974, 0.2969, 0.2952, 0.295 ,\n",
       "            0.2947, 0.2937, 0.2922, 0.2917, 0.2913, 0.2905, 0.2896, 0.287 ,\n",
       "            0.2869, 0.2866, 0.285 , 0.2832, 0.2786, 0.278 , 0.2761, 0.2732,\n",
       "            0.2725, 0.272 , 0.2715, 0.2705, 0.27  , 0.268 , 0.2673, 0.2659,\n",
       "            0.2637, 0.2622, 0.262 , 0.2615, 0.2612, 0.261 , 0.26  , 0.2595,\n",
       "            0.2576, 0.2573, 0.2568, 0.2566, 0.256 , 0.2542, 0.253 , 0.251 ,\n",
       "            0.2505, 0.2502, 0.2498, 0.2496, 0.2444, 0.2438, 0.2437, 0.2434,\n",
       "            0.2433, 0.2422, 0.2418, 0.2407, 0.2388, 0.2292, 0.2272, 0.2268,\n",
       "            0.2264, 0.2229, 0.2203, 0.2173, 0.2158, 0.2148, 0.2144, 0.2113,\n",
       "            0.2048, 0.1953, 0.1931, 0.1849, 0.1842, 0.1819, 0.1816, 0.1598,\n",
       "            0.1232, 0.0972, 0.0939], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.3030303, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.16949153, 0.16949153, 0.1779661 ,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.19491525, 0.19491525, 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2457627 , 0.2542373 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3644068 , 0.37288135,\n",
       "            0.37288135, 0.38135594, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.44915253, 0.45762712, 0.47457626, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.0530303 , 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.43939394, 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.5378788 , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6212121 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.82575756, 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.6484 , 0.621  , 0.6123 , 0.606  , 0.605  , 0.604  ,\n",
       "            0.6035 , 0.5864 , 0.582  , 0.5757 , 0.5723 , 0.568  , 0.566  ,\n",
       "            0.562  , 0.561  , 0.5605 , 0.557  , 0.5513 , 0.5454 , 0.5444 ,\n",
       "            0.5425 , 0.542  , 0.5396 , 0.536  , 0.532  , 0.5312 , 0.53   ,\n",
       "            0.526  , 0.5254 , 0.524  , 0.5225 , 0.522  , 0.517  , 0.5166 ,\n",
       "            0.5117 , 0.5044 , 0.5034 , 0.4993 , 0.488  , 0.485  , 0.4734 ,\n",
       "            0.473  , 0.4712 , 0.4678 , 0.4636 , 0.4624 , 0.4597 , 0.4536 ,\n",
       "            0.4478 , 0.4475 , 0.4465 , 0.4358 , 0.4338 , 0.4272 , 0.425  ,\n",
       "            0.412  , 0.4097 , 0.4045 , 0.4026 , 0.4011 , 0.4    , 0.3975 ,\n",
       "            0.3972 , 0.3965 , 0.3926 , 0.3923 , 0.391  , 0.3901 , 0.387  ,\n",
       "            0.3867 , 0.3853 , 0.3848 , 0.3833 , 0.3782 , 0.378  , 0.3755 ,\n",
       "            0.374  , 0.3735 , 0.3733 , 0.3718 , 0.3713 , 0.37   , 0.3699 ,\n",
       "            0.3687 , 0.3682 , 0.3672 , 0.3667 , 0.3665 , 0.3638 , 0.3633 ,\n",
       "            0.363  , 0.3616 , 0.3599 , 0.3591 , 0.3586 , 0.3584 , 0.358  ,\n",
       "            0.3564 , 0.3557 , 0.3552 , 0.3547 , 0.3542 , 0.354  , 0.3538 ,\n",
       "            0.353  , 0.3528 , 0.3513 , 0.3506 , 0.3503 , 0.3496 , 0.349  ,\n",
       "            0.3484 , 0.3474 , 0.3452 , 0.344  , 0.3438 , 0.3435 , 0.342  ,\n",
       "            0.3418 , 0.3416 , 0.3408 , 0.34   , 0.3364 , 0.3354 , 0.3345 ,\n",
       "            0.3335 , 0.331  , 0.33   , 0.3293 , 0.3286 , 0.3284 , 0.3281 ,\n",
       "            0.3271 , 0.327  , 0.3264 , 0.3262 , 0.3247 , 0.3237 , 0.322  ,\n",
       "            0.3215 , 0.3208 , 0.3203 , 0.3186 , 0.3179 , 0.3174 , 0.317  ,\n",
       "            0.3162 , 0.316  , 0.3147 , 0.3118 , 0.311  , 0.3103 , 0.3098 ,\n",
       "            0.3093 , 0.3088 , 0.3074 , 0.3062 , 0.304  , 0.3032 , 0.3022 ,\n",
       "            0.3008 , 0.2986 , 0.2979 , 0.2957 , 0.2925 , 0.29   , 0.2883 ,\n",
       "            0.2876 , 0.285  , 0.2847 , 0.2842 , 0.2822 , 0.282  , 0.2817 ,\n",
       "            0.2815 , 0.28   , 0.2786 , 0.2778 , 0.2776 , 0.2766 , 0.2764 ,\n",
       "            0.2761 , 0.276  , 0.2747 , 0.274  , 0.2734 , 0.273  , 0.2717 ,\n",
       "            0.2712 , 0.2683 , 0.268  , 0.2664 , 0.266  , 0.2651 , 0.2646 ,\n",
       "            0.2637 , 0.26   , 0.2598 , 0.2595 , 0.2585 , 0.258  , 0.2487 ,\n",
       "            0.2477 , 0.244  , 0.2421 , 0.2415 , 0.2411 , 0.2372 , 0.2252 ,\n",
       "            0.2211 , 0.2179 , 0.2142 , 0.214  , 0.2124 , 0.2106 , 0.2073 ,\n",
       "            0.2029 , 0.1937 , 0.188  , 0.1826 , 0.1796 , 0.1788 , 0.1763 ,\n",
       "            0.157  , 0.11694, 0.0914 , 0.0909 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.33333334, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.1440678 , 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.18644068, 0.18644068, 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.18644068, 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.20338982, 0.20338982, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2457627 , 0.2542373 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.33898306, 0.3559322 ,\n",
       "            0.3644068 , 0.3644068 , 0.3644068 , 0.37288135, 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.43220338, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.60169494, 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.4318182 , 0.4318182 , 0.43939394,\n",
       "            0.43939394, 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.54545456, 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6212121 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.7651515 , 0.77272725, 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.84090906, 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.6934 , 0.6626 , 0.6533 , 0.646  , 0.645  , 0.644  ,\n",
       "            0.6436 , 0.643  , 0.6245 , 0.619  , 0.612  , 0.61   , 0.6035 ,\n",
       "            0.6016 , 0.597  , 0.5967 , 0.595  , 0.593  , 0.585  , 0.579  ,\n",
       "            0.5776 , 0.575  , 0.5747 , 0.5713 , 0.569  , 0.5635 , 0.563  ,\n",
       "            0.561  , 0.5566 , 0.556  , 0.5547 , 0.5537 , 0.5522 , 0.5464 ,\n",
       "            0.546  , 0.54   , 0.533  , 0.5317 , 0.527  , 0.514  , 0.5127 ,\n",
       "            0.5103 , 0.4973 , 0.497  , 0.4949 , 0.4902 , 0.4856 , 0.484  ,\n",
       "            0.4814 , 0.475  , 0.4683 , 0.4675 , 0.4663 , 0.4546 , 0.4517 ,\n",
       "            0.4438 , 0.4421 , 0.4275 , 0.424  , 0.4211 , 0.4192 , 0.4111 ,\n",
       "            0.4065 , 0.406  , 0.4048 , 0.402  , 0.3977 , 0.3975 , 0.3962 ,\n",
       "            0.395  , 0.3928 , 0.3914 , 0.39   , 0.3877 , 0.3828 , 0.381  ,\n",
       "            0.3794 , 0.3787 , 0.3782 , 0.3774 , 0.3772 , 0.3755 , 0.3752 ,\n",
       "            0.3748 , 0.3735 , 0.3733 , 0.3718 , 0.3716 , 0.3713 , 0.371  ,\n",
       "            0.3696 , 0.3682 , 0.3662 , 0.366  , 0.3652 , 0.365  , 0.3628 ,\n",
       "            0.3625 , 0.3618 , 0.3608 , 0.3596 , 0.3591 , 0.359  , 0.3586 ,\n",
       "            0.3582 , 0.3567 , 0.3564 , 0.3557 , 0.3547 , 0.3542 , 0.354  ,\n",
       "            0.3533 , 0.353  , 0.3528 , 0.3518 , 0.3506 , 0.3499 , 0.3481 ,\n",
       "            0.3472 , 0.347  , 0.3455 , 0.3445 , 0.3442 , 0.3438 , 0.3435 ,\n",
       "            0.3428 , 0.3418 , 0.3396 , 0.3374 , 0.3367 , 0.3364 , 0.3337 ,\n",
       "            0.3318 , 0.331  , 0.3308 , 0.3306 , 0.3286 , 0.3284 , 0.3274 ,\n",
       "            0.3262 , 0.325  , 0.3232 , 0.323  , 0.322  , 0.3218 , 0.3188 ,\n",
       "            0.3179 , 0.3174 , 0.3164 , 0.3162 , 0.3142 , 0.314  , 0.3135 ,\n",
       "            0.313  , 0.312  , 0.3115 , 0.3113 , 0.3088 , 0.3079 , 0.3062 ,\n",
       "            0.3054 , 0.3044 , 0.3013 , 0.3    , 0.2996 , 0.2957 , 0.2942 ,\n",
       "            0.293  , 0.29   , 0.2893 , 0.2874 , 0.287  , 0.2861 , 0.2856 ,\n",
       "            0.2842 , 0.2837 , 0.2827 , 0.2825 , 0.282  , 0.2803 , 0.2793 ,\n",
       "            0.2788 , 0.278  , 0.2778 , 0.2769 , 0.276  , 0.2756 , 0.2754 ,\n",
       "            0.2751 , 0.2747 , 0.2717 , 0.2715 , 0.2712 , 0.27   , 0.2688 ,\n",
       "            0.2673 , 0.2668 , 0.2659 , 0.2654 , 0.2644 , 0.2605 , 0.26   ,\n",
       "            0.2598 , 0.2585 , 0.2566 , 0.2487 , 0.2448 , 0.2441 , 0.2415 ,\n",
       "            0.241  , 0.2352 , 0.2311 , 0.2185 , 0.2137 , 0.2106 , 0.2076 ,\n",
       "            0.2069 , 0.2051 , 0.2024 , 0.1993 , 0.1964 , 0.1877 , 0.1799 ,\n",
       "            0.1759 , 0.173  , 0.1707 , 0.1678 , 0.1504 , 0.1086 , 0.0856 ,\n",
       "            0.08374], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00847458, dtype=float32),\n",
       "    'tpr': array(0.3939394, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.15254237, 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.16101696, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.1779661 , 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.21186441, 0.21186441, 0.21186441, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.22881356, 0.22881356, 0.23728813,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.26271185, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.29661018, 0.29661018,\n",
       "            0.30508474, 0.30508474, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.38135594, 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5254237 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.59322035, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.4318182 , 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.5984849 , 0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.72727275, 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.77272725, 0.780303  , 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.8181818 , 0.82575756, 0.82575756, 0.82575756,\n",
       "            0.8333333 , 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.92424244, 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.746  , 0.713  , 0.703  , 0.695  , 0.6943 , 0.6924 ,\n",
       "            0.692  , 0.672  , 0.6675 , 0.6577 , 0.649  , 0.6475 , 0.6436 ,\n",
       "            0.642  , 0.64   , 0.639  , 0.6294 , 0.6255 , 0.6226 , 0.6187 ,\n",
       "            0.6177 , 0.6143 , 0.6133 , 0.608  , 0.607  , 0.605  , 0.603  ,\n",
       "            0.598  , 0.597  , 0.5947 , 0.588  , 0.5864 , 0.579  , 0.574  ,\n",
       "            0.5728 , 0.5664 , 0.5503 , 0.5483 , 0.5464 , 0.5347 , 0.5337 ,\n",
       "            0.5312 , 0.524  , 0.5176 , 0.516  , 0.5156 , 0.509  , 0.5005 ,\n",
       "            0.4976 , 0.4973 , 0.4858 , 0.4827 , 0.4731 , 0.4714 , 0.4531 ,\n",
       "            0.4524 , 0.4512 , 0.4495 , 0.4365 , 0.4224 , 0.422  , 0.4207 ,\n",
       "            0.4177 , 0.4133 , 0.4126 , 0.4124 , 0.4104 , 0.4092 , 0.409  ,\n",
       "            0.4087 , 0.4067 , 0.4055 , 0.4053 , 0.404  , 0.403  , 0.3994 ,\n",
       "            0.3958 , 0.3955 , 0.3948 , 0.3933 , 0.39   , 0.3896 , 0.3887 ,\n",
       "            0.3882 , 0.3877 , 0.3875 , 0.387  , 0.3855 , 0.385  , 0.3843 ,\n",
       "            0.3806 , 0.3801 , 0.38   , 0.3794 , 0.3792 , 0.3777 , 0.377  ,\n",
       "            0.3767 , 0.3757 , 0.3755 , 0.3748 , 0.3745 , 0.3733 , 0.373  ,\n",
       "            0.3728 , 0.3718 , 0.3696 , 0.369  , 0.3684 , 0.368  , 0.367  ,\n",
       "            0.3647 , 0.3645 , 0.3638 , 0.3633 , 0.362  , 0.3608 , 0.3604 ,\n",
       "            0.3596 , 0.3586 , 0.3584 , 0.358  , 0.3577 , 0.3555 , 0.3538 ,\n",
       "            0.352  , 0.351  , 0.3503 , 0.3489 , 0.3484 , 0.3442 , 0.3435 ,\n",
       "            0.3425 , 0.3423 , 0.342  , 0.34   , 0.3389 , 0.337  , 0.3362 ,\n",
       "            0.3357 , 0.3325 , 0.3313 , 0.3306 , 0.33   , 0.3289 , 0.3271 ,\n",
       "            0.3257 , 0.3254 , 0.3252 , 0.3245 , 0.323  , 0.3225 , 0.3215 ,\n",
       "            0.3213 , 0.3203 , 0.3186 , 0.3184 , 0.3132 , 0.313  , 0.3127 ,\n",
       "            0.31   , 0.3079 , 0.3054 , 0.3052 , 0.3047 , 0.3037 , 0.3032 ,\n",
       "            0.2996 , 0.2993 , 0.2986 , 0.298  , 0.2976 , 0.2974 , 0.2957 ,\n",
       "            0.2944 , 0.2935 , 0.293  , 0.2915 , 0.2913 , 0.2903 , 0.29   ,\n",
       "            0.289  , 0.2878 , 0.2861 , 0.2847 , 0.284  , 0.2834 , 0.2822 ,\n",
       "            0.282  , 0.281  , 0.2808 , 0.28   , 0.2793 , 0.279  , 0.277  ,\n",
       "            0.2766 , 0.2734 , 0.273  , 0.2725 , 0.2722 , 0.2605 , 0.2566 ,\n",
       "            0.2546 , 0.2534 , 0.2527 , 0.2473 , 0.234  , 0.2295 , 0.2166 ,\n",
       "            0.2108 , 0.2076 , 0.2054 , 0.2032 , 0.2023 , 0.1984 , 0.1954 ,\n",
       "            0.194  , 0.1857 , 0.1752 , 0.1731 , 0.1703 , 0.1656 , 0.1627 ,\n",
       "            0.1475 , 0.10266, 0.0823 , 0.07806], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00847458, dtype=float32),\n",
       "    'tpr': array(0.4090909, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.18644068, 0.19491525, 0.21186441,\n",
       "            0.21186441, 0.21186441, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.23728813, 0.23728813, 0.23728813,\n",
       "            0.2457627 , 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.37288135, 0.38135594, 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.5508475 , 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.65254235, 0.66101694, 0.6694915 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03787879,\n",
       "            0.04545455, 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.4318182 , 0.4318182 , 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.54545456, 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6363636 , 0.6515151 , 0.6515151 ,\n",
       "            0.65909094, 0.67424244, 0.6818182 , 0.68939394, 0.70454544,\n",
       "            0.7121212 , 0.7348485 , 0.7348485 , 0.74242425, 0.74242425,\n",
       "            0.75      , 0.75757575, 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.774  , 0.7397 , 0.73   , 0.721  , 0.7207 , 0.7188 ,\n",
       "            0.7183 , 0.6987 , 0.6924 , 0.683  , 0.6826 , 0.674  , 0.6724 ,\n",
       "            0.666  , 0.6646 , 0.661  , 0.653  , 0.648  , 0.6455 , 0.6416 ,\n",
       "            0.641  , 0.637  , 0.6353 , 0.6294 , 0.6284 , 0.6274 , 0.6245 ,\n",
       "            0.62   , 0.6196 , 0.6187 , 0.6177 , 0.6157 , 0.6084 , 0.6074 ,\n",
       "            0.6    , 0.5933 , 0.5903 , 0.5854 , 0.57   , 0.5674 , 0.5645 ,\n",
       "            0.5503 , 0.55   , 0.547  , 0.5405 , 0.534  , 0.532  , 0.531  ,\n",
       "            0.522  , 0.514  , 0.512  , 0.5117 , 0.4983 , 0.4941 , 0.4836 ,\n",
       "            0.4624 , 0.4622 , 0.4602 , 0.4592 , 0.4443 , 0.437  , 0.435  ,\n",
       "            0.431  , 0.428  , 0.425  , 0.4243 , 0.4226 , 0.4216 , 0.4207 ,\n",
       "            0.419  , 0.4167 , 0.4146 , 0.4143 , 0.4136 , 0.4124 , 0.4116 ,\n",
       "            0.4106 , 0.4084 , 0.4075 , 0.4067 , 0.4014 , 0.4006 , 0.3997 ,\n",
       "            0.3962 , 0.3958 , 0.395  , 0.3938 , 0.3926 , 0.3918 , 0.3901 ,\n",
       "            0.39   , 0.3896 , 0.3892 , 0.3884 , 0.387  , 0.3867 , 0.3865 ,\n",
       "            0.3855 , 0.385  , 0.3845 , 0.3843 , 0.3828 , 0.3818 , 0.381  ,\n",
       "            0.3787 , 0.3772 , 0.3765 , 0.3748 , 0.3743 , 0.374  , 0.3735 ,\n",
       "            0.3728 , 0.372  , 0.3708 , 0.3706 , 0.369  , 0.3674 , 0.3657 ,\n",
       "            0.3655 , 0.3652 , 0.3647 , 0.3638 , 0.3618 , 0.3604 , 0.3582 ,\n",
       "            0.357  , 0.3567 , 0.3542 , 0.3538 , 0.3506 , 0.349  , 0.3484 ,\n",
       "            0.3481 , 0.3455 , 0.3452 , 0.343  , 0.3423 , 0.3418 , 0.3413 ,\n",
       "            0.3386 , 0.338  , 0.3374 , 0.3352 , 0.332  , 0.3315 , 0.3293 ,\n",
       "            0.3289 , 0.3274 , 0.326  , 0.3252 , 0.324  , 0.3235 , 0.322  ,\n",
       "            0.3208 , 0.3206 , 0.3198 , 0.3171 , 0.3167 , 0.3118 , 0.3115 ,\n",
       "            0.308  , 0.3079 , 0.306  , 0.3054 , 0.304  , 0.3035 , 0.3032 ,\n",
       "            0.3027 , 0.302  , 0.2998 , 0.2986 , 0.2979 , 0.2966 , 0.296  ,\n",
       "            0.295  , 0.2937 , 0.2932 , 0.292  , 0.2915 , 0.2903 , 0.29   ,\n",
       "            0.288  , 0.2874 , 0.2866 , 0.2852 , 0.2844 , 0.2827 , 0.282  ,\n",
       "            0.281  , 0.2793 , 0.279  , 0.2786 , 0.2776 , 0.2764 , 0.2742 ,\n",
       "            0.2715 , 0.271  , 0.2705 , 0.2703 , 0.2578 , 0.2568 , 0.253  ,\n",
       "            0.2527 , 0.2517 , 0.2428 , 0.2289 , 0.2244 , 0.21   , 0.204  ,\n",
       "            0.2009 , 0.199  , 0.1964 , 0.1956 , 0.1912 , 0.1897 , 0.1873 ,\n",
       "            0.1791 , 0.169  , 0.1664 , 0.1635 , 0.16   , 0.1567 , 0.1405 ,\n",
       "            0.0955 , 0.07654, 0.0716 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.01694915, dtype=float32),\n",
       "    'tpr': array(0.4318182, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11016949, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.15254237, 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.19491525, 0.20338982, 0.20338982,\n",
       "            0.21186441, 0.21186441, 0.22033899, 0.22033899, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.34745762, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03787879,\n",
       "            0.04545455, 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.4318182 , 0.4318182 , 0.4318182 , 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.54545456, 0.56060606, 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.6666667 , 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.719697  , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.7348485 , 0.74242425, 0.74242425, 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8636364 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.8086 , 0.7744 , 0.7646 , 0.756  , 0.7554 , 0.753  ,\n",
       "            0.7524 , 0.734  , 0.726  , 0.717  , 0.7163 , 0.707  , 0.7056 ,\n",
       "            0.699  , 0.6978 , 0.693  , 0.6855 , 0.6797 , 0.6772 , 0.674  ,\n",
       "            0.6733 , 0.6694 , 0.667  , 0.6606 , 0.6597 , 0.6587 , 0.6562 ,\n",
       "            0.6523 , 0.651  , 0.6494 , 0.6484 , 0.6465 , 0.6387 , 0.6377 ,\n",
       "            0.6304 , 0.623  , 0.6177 , 0.6143 , 0.599  , 0.595  , 0.592  ,\n",
       "            0.576  , 0.5747 , 0.5728 , 0.566  , 0.5605 , 0.557  , 0.5557 ,\n",
       "            0.545  , 0.537  , 0.5366 , 0.535  , 0.52   , 0.5146 , 0.505  ,\n",
       "            0.504  , 0.4822 , 0.481  , 0.479  , 0.4775 , 0.461  , 0.4578 ,\n",
       "            0.4536 , 0.4468 , 0.4438 , 0.4426 , 0.442  , 0.4397 , 0.4385 ,\n",
       "            0.4365 , 0.434  , 0.433  , 0.4304 , 0.4294 , 0.428  , 0.4265 ,\n",
       "            0.4263 , 0.4253 , 0.423  , 0.4229 , 0.4197 , 0.4177 , 0.4146 ,\n",
       "            0.4136 , 0.4124 , 0.4116 , 0.4092 , 0.409  , 0.4087 , 0.4075 ,\n",
       "            0.4055 , 0.4053 , 0.405  , 0.4048 , 0.4043 , 0.4038 , 0.402  ,\n",
       "            0.4019 , 0.4016 , 0.401  , 0.4006 , 0.3984 , 0.3982 , 0.398  ,\n",
       "            0.3972 , 0.397  , 0.3943 , 0.3936 , 0.391  , 0.3909 , 0.3904 ,\n",
       "            0.3887 , 0.388  , 0.3877 , 0.3872 , 0.3862 , 0.3843 , 0.382  ,\n",
       "            0.3818 , 0.3804 , 0.3782 , 0.3777 , 0.376  , 0.3735 , 0.373  ,\n",
       "            0.3726 , 0.3716 , 0.37   , 0.3696 , 0.3662 , 0.3657 , 0.3633 ,\n",
       "            0.3625 , 0.362  , 0.3606 , 0.3596 , 0.3572 , 0.3538 , 0.3533 ,\n",
       "            0.3518 , 0.3516 , 0.349  , 0.3477 , 0.344  , 0.3438 , 0.343  ,\n",
       "            0.3398 , 0.3394 , 0.3386 , 0.3367 , 0.3357 , 0.3323 , 0.33   ,\n",
       "            0.3298 , 0.3293 , 0.3271 , 0.327  , 0.324  , 0.3228 , 0.3193 ,\n",
       "            0.318  , 0.3174 , 0.3154 , 0.3147 , 0.3145 , 0.3123 , 0.311  ,\n",
       "            0.3103 , 0.3096 , 0.3093 , 0.3088 , 0.3071 , 0.3066 , 0.3025 ,\n",
       "            0.3022 , 0.3018 , 0.3005 , 0.3003 , 0.2993 , 0.2976 , 0.2974 ,\n",
       "            0.2961 , 0.2957 , 0.2954 , 0.2935 , 0.2932 , 0.2925 , 0.2917 ,\n",
       "            0.2903 , 0.2893 , 0.289  , 0.2876 , 0.2864 , 0.2856 , 0.2852 ,\n",
       "            0.2837 , 0.2832 , 0.2803 , 0.278  , 0.2761 , 0.276  , 0.2756 ,\n",
       "            0.2751 , 0.2742 , 0.2646 , 0.2595 , 0.2593 , 0.258  , 0.2544 ,\n",
       "            0.243  , 0.2266 , 0.222  , 0.2065 , 0.2001 , 0.1968 , 0.1954 ,\n",
       "            0.1919 , 0.1915 , 0.1865 , 0.1859 , 0.1836 , 0.1755 , 0.1646 ,\n",
       "            0.1622 , 0.1593 , 0.1555 , 0.1519 , 0.1361 , 0.0898 , 0.07275,\n",
       "            0.06647], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04237288, dtype=float32),\n",
       "    'tpr': array(0.4318182, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.16949153, 0.16949153,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.16949153, 0.16949153,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.21186441, 0.21186441,\n",
       "            0.21186441, 0.22881356, 0.22881356, 0.22881356, 0.23728813,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.55932206, 0.5677966 , 0.58474576, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.8898305 , 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.04545455,\n",
       "            0.0530303 , 0.06818182, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.4318182 ,\n",
       "            0.4318182 , 0.4318182 , 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6136364 , 0.6287879 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.719697  , 0.72727275, 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.74242425, 0.75      , 0.75      ,\n",
       "            0.75      , 0.75757575, 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8636364 , 0.8712121 ,\n",
       "            0.8712121 , 0.8712121 , 0.8712121 , 0.8787879 , 0.8939394 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.9166667 , 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.8423 , 0.8086 , 0.8    , 0.7905 , 0.7876 , 0.787  ,\n",
       "            0.7695 , 0.761  , 0.752  , 0.7505 , 0.7417 , 0.7407 , 0.734  ,\n",
       "            0.7324 , 0.732  , 0.727  , 0.7197 , 0.7134 , 0.712  , 0.7075 ,\n",
       "            0.703  , 0.7017 , 0.695  , 0.6943 , 0.6924 , 0.6895 , 0.686  ,\n",
       "            0.684  , 0.683  , 0.681  , 0.68   , 0.672  , 0.6704 , 0.6626 ,\n",
       "            0.656  , 0.6494 , 0.6465 , 0.63   , 0.6255 , 0.622  , 0.606  ,\n",
       "            0.6025 , 0.5947 , 0.588  , 0.5845 , 0.5835 , 0.571  , 0.564  ,\n",
       "            0.5625 , 0.561  , 0.545  , 0.539  , 0.528  , 0.5273 , 0.505  ,\n",
       "            0.503  , 0.5024 , 0.4983 , 0.4802 , 0.4758 , 0.4697 , 0.4604 ,\n",
       "            0.4575 , 0.457  , 0.4568 , 0.4558 , 0.452  , 0.45   , 0.449  ,\n",
       "            0.4463 , 0.4443 , 0.443  , 0.4429 , 0.4417 , 0.4412 , 0.4385 ,\n",
       "            0.436  , 0.4355 , 0.435  , 0.434  , 0.4329 , 0.428  , 0.4263 ,\n",
       "            0.426  , 0.4233 , 0.4204 , 0.4202 , 0.4197 , 0.4192 , 0.4175 ,\n",
       "            0.4172 , 0.417  , 0.4165 , 0.4163 , 0.416  , 0.4155 , 0.413  ,\n",
       "            0.4124 , 0.411  , 0.4106 , 0.4102 , 0.4087 , 0.406  , 0.4058 ,\n",
       "            0.4048 , 0.404  , 0.4033 , 0.4026 , 0.4016 , 0.4004 , 0.3987 ,\n",
       "            0.3982 , 0.398  , 0.3975 , 0.3965 , 0.3938 , 0.3923 , 0.3904 ,\n",
       "            0.3896 , 0.388  , 0.3877 , 0.386  , 0.3845 , 0.3816 , 0.3806 ,\n",
       "            0.3792 , 0.375  , 0.3748 , 0.3723 , 0.371  , 0.3708 , 0.369  ,\n",
       "            0.3687 , 0.3665 , 0.3652 , 0.365  , 0.3645 , 0.3638 , 0.3633 ,\n",
       "            0.362  , 0.3606 , 0.358  , 0.3555 , 0.3542 , 0.351  , 0.3499 ,\n",
       "            0.348  , 0.3477 , 0.3464 , 0.3457 , 0.343  , 0.3406 , 0.338  ,\n",
       "            0.3362 , 0.3354 , 0.3345 , 0.3342 , 0.334  , 0.3276 , 0.3274 ,\n",
       "            0.326  , 0.3257 , 0.3245 , 0.3232 , 0.3225 , 0.3213 , 0.3203 ,\n",
       "            0.319  , 0.3176 , 0.3167 , 0.3157 , 0.3127 , 0.312  , 0.3115 ,\n",
       "            0.311  , 0.3108 , 0.31   , 0.3093 , 0.3088 , 0.3074 , 0.3062 ,\n",
       "            0.3054 , 0.3042 , 0.3032 , 0.302  , 0.3015 , 0.3    , 0.2998 ,\n",
       "            0.2988 , 0.2974 , 0.2954 , 0.2947 , 0.2935 , 0.2917 , 0.2915 ,\n",
       "            0.289  , 0.2874 , 0.284  , 0.2837 , 0.2832 , 0.2822 , 0.2805 ,\n",
       "            0.2786 , 0.275  , 0.2737 , 0.2683 , 0.268  , 0.258  , 0.2573 ,\n",
       "            0.2433 , 0.2233 , 0.2185 , 0.2021 , 0.195  , 0.1918 , 0.191  ,\n",
       "            0.1865 , 0.181  , 0.1791 , 0.1714 , 0.1589 , 0.1577 , 0.1545 ,\n",
       "            0.15   , 0.1462 , 0.1312 , 0.08386, 0.0689 , 0.0611 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04237288, dtype=float32),\n",
       "    'tpr': array(0.43939394, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.10169491, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.16949153, 0.16949153,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.21186441, 0.21186441, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22033899, 0.22033899, 0.22881356, 0.22881356,\n",
       "            0.22881356, 0.23728813, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.04545455,\n",
       "            0.06060606, 0.06818182, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.4318182 , 0.4318182 , 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75      , 0.7651515 , 0.7651515 ,\n",
       "            0.7651515 , 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.79545456, 0.79545456, 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8560606 , 0.8636364 , 0.8636364 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.868  , 0.837  , 0.8276 , 0.819  , 0.816  , 0.8154 ,\n",
       "            0.799  , 0.79   , 0.7817 , 0.779  , 0.771  , 0.77   , 0.763  ,\n",
       "            0.7617 , 0.7603 , 0.755  , 0.749  , 0.741  , 0.7373 , 0.737  ,\n",
       "            0.7324 , 0.7305 , 0.7236 , 0.7227 , 0.721  , 0.7188 , 0.7153 ,\n",
       "            0.713  , 0.7114 , 0.709  , 0.7085 , 0.7    , 0.6987 , 0.691  ,\n",
       "            0.683  , 0.6763 , 0.674  , 0.6577 , 0.6523 , 0.649  , 0.632  ,\n",
       "            0.628  , 0.6274 , 0.6196 , 0.613  , 0.6094 , 0.608  , 0.5933 ,\n",
       "            0.5874 , 0.586  , 0.5845 , 0.5664 , 0.5596 , 0.549  , 0.5474 ,\n",
       "            0.5234 , 0.522  , 0.5215 , 0.5166 , 0.499  , 0.4973 , 0.4895 ,\n",
       "            0.4778 , 0.477  , 0.476  , 0.4746 , 0.474  , 0.469  , 0.468  ,\n",
       "            0.467  , 0.4668 , 0.4644 , 0.4639 , 0.463  , 0.4587 , 0.4578 ,\n",
       "            0.4575 , 0.4558 , 0.4556 , 0.45   , 0.4485 , 0.4482 , 0.4473 ,\n",
       "            0.4468 , 0.4446 , 0.4436 , 0.4417 , 0.4414 , 0.4412 , 0.4404 ,\n",
       "            0.4395 , 0.439  , 0.438  , 0.4373 , 0.4355 , 0.4348 , 0.4336 ,\n",
       "            0.4329 , 0.432  , 0.4304 , 0.429  , 0.4287 , 0.4263 , 0.426  ,\n",
       "            0.4253 , 0.4243 , 0.4226 , 0.4224 , 0.4216 , 0.421  , 0.4207 ,\n",
       "            0.4202 , 0.4175 , 0.4165 , 0.4158 , 0.4138 , 0.4128 , 0.4124 ,\n",
       "            0.412  , 0.4119 , 0.411  , 0.4094 , 0.4087 , 0.4072 , 0.4065 ,\n",
       "            0.4043 , 0.4019 , 0.399  , 0.397  , 0.395  , 0.393  , 0.388  ,\n",
       "            0.387  , 0.3857 , 0.3845 , 0.3838 , 0.3823 , 0.3809 , 0.3801 ,\n",
       "            0.3794 , 0.3787 , 0.3772 , 0.376  , 0.3752 , 0.374  , 0.3733 ,\n",
       "            0.3723 , 0.3677 , 0.3655 , 0.3635 , 0.3608 , 0.3574 , 0.3562 ,\n",
       "            0.3552 , 0.3538 , 0.3525 , 0.35   , 0.3438 , 0.343  , 0.342  ,\n",
       "            0.3389 , 0.3386 , 0.337  , 0.3364 , 0.334  , 0.3337 , 0.3335 ,\n",
       "            0.332  , 0.3306 , 0.3298 , 0.3284 , 0.3271 , 0.327  , 0.326  ,\n",
       "            0.3247 , 0.322  , 0.3208 , 0.3176 , 0.3171 , 0.3164 , 0.3162 ,\n",
       "            0.3154 , 0.314  , 0.3135 , 0.313  , 0.3123 , 0.312  , 0.3118 ,\n",
       "            0.3105 , 0.3103 , 0.31   , 0.309  , 0.3079 , 0.3071 , 0.307  ,\n",
       "            0.3042 , 0.3005 , 0.3003 , 0.2986 , 0.298  , 0.2961 , 0.2903 ,\n",
       "            0.29   , 0.2898 , 0.2893 , 0.2883 , 0.2827 , 0.2812 , 0.2795 ,\n",
       "            0.277  , 0.2766 , 0.2754 , 0.2603 , 0.258  , 0.2437 , 0.2207 ,\n",
       "            0.2157 , 0.1985 , 0.1907 , 0.1876 , 0.1873 , 0.1824 , 0.182  ,\n",
       "            0.1771 , 0.1763 , 0.1753 , 0.1677 , 0.1545 , 0.1536 , 0.1506 ,\n",
       "            0.1458 , 0.1416 , 0.1271 , 0.0788 , 0.06573, 0.05664],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04237288, dtype=float32),\n",
       "    'tpr': array(0.46212122, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.18644068, 0.18644068, 0.18644068,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.20338982, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22033899, 0.22881356, 0.22881356,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2457627 , 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.33050847,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.04545455,\n",
       "            0.0530303 , 0.06818182, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.4318182 , 0.4318182 , 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6060606 , 0.6212121 ,\n",
       "            0.6287879 , 0.6439394 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.8833 , 0.854  , 0.845  , 0.8364 , 0.834  , 0.8335 ,\n",
       "            0.818  , 0.808  , 0.8003 , 0.7954 , 0.79   , 0.7896 , 0.7817 ,\n",
       "            0.781  , 0.777  , 0.7715 , 0.7676 , 0.759  , 0.758  , 0.7563 ,\n",
       "            0.755  , 0.7515 , 0.747  , 0.74   , 0.7397 , 0.737  , 0.7354 ,\n",
       "            0.731  , 0.729  , 0.726  , 0.724  , 0.718  , 0.717  , 0.709  ,\n",
       "            0.6997 , 0.691  , 0.6904 , 0.676  , 0.67   , 0.6655 , 0.6465 ,\n",
       "            0.6426 , 0.6406 , 0.6353 , 0.629  , 0.6255 , 0.622  , 0.6045 ,\n",
       "            0.601  , 0.6    , 0.598  , 0.578  , 0.5693 , 0.5615 , 0.556  ,\n",
       "            0.532  , 0.53   , 0.5273 , 0.527  , 0.523  , 0.51   , 0.5044 ,\n",
       "            0.497  , 0.496  , 0.4949 , 0.4917 , 0.4915 , 0.4873 , 0.4858 ,\n",
       "            0.4854 , 0.484  , 0.4832 , 0.4785 , 0.4768 , 0.4736 , 0.4688 ,\n",
       "            0.4675 , 0.4656 , 0.465  , 0.4617 , 0.4612 , 0.4607 , 0.459  ,\n",
       "            0.4587 , 0.4578 , 0.4575 , 0.4573 , 0.456  , 0.4553 , 0.455  ,\n",
       "            0.454  , 0.4536 , 0.4521 , 0.4495 , 0.4458 , 0.4456 , 0.445  ,\n",
       "            0.4426 , 0.4421 , 0.442  , 0.441  , 0.4385 , 0.4377 , 0.4373 ,\n",
       "            0.436  , 0.4346 , 0.4333 , 0.4285 , 0.4272 , 0.426  , 0.4255 ,\n",
       "            0.4233 , 0.4229 , 0.4224 , 0.422  , 0.4219 , 0.421  , 0.4204 ,\n",
       "            0.4177 , 0.4172 , 0.4148 , 0.4146 , 0.413  , 0.411  , 0.4104 ,\n",
       "            0.4082 , 0.4004 , 0.398  , 0.3948 , 0.394  , 0.3926 , 0.392  ,\n",
       "            0.3918 , 0.39   , 0.3896 , 0.3892 , 0.3872 , 0.3862 , 0.3857 ,\n",
       "            0.385  , 0.3809 , 0.3792 , 0.3767 , 0.3765 , 0.3755 , 0.3752 ,\n",
       "            0.3733 , 0.3726 , 0.3718 , 0.3713 , 0.371  , 0.3635 , 0.3625 ,\n",
       "            0.3591 , 0.3562 , 0.353  , 0.3525 , 0.3442 , 0.344  , 0.3423 ,\n",
       "            0.3386 , 0.3384 , 0.338  , 0.3362 , 0.3352 , 0.3337 , 0.3333 ,\n",
       "            0.3318 , 0.331  , 0.3289 , 0.3274 , 0.3264 , 0.3262 , 0.3257 ,\n",
       "            0.3228 , 0.3206 , 0.3186 , 0.318  , 0.3176 , 0.3174 , 0.317  ,\n",
       "            0.3154 , 0.3147 , 0.3142 , 0.313  , 0.312  , 0.3115 , 0.311  ,\n",
       "            0.3108 , 0.3093 , 0.309  , 0.3079 , 0.3076 , 0.3066 , 0.3    ,\n",
       "            0.2986 , 0.2983 , 0.296  , 0.2925 , 0.291  , 0.2908 , 0.2903 ,\n",
       "            0.2878 , 0.2876 , 0.2815 , 0.281  , 0.2786 , 0.2769 , 0.274  ,\n",
       "            0.2573 , 0.2537 , 0.2394 , 0.2161 , 0.2114 , 0.1924 , 0.1844 ,\n",
       "            0.1814 , 0.1812 , 0.1761 , 0.1759 , 0.1725 , 0.17   , 0.169  ,\n",
       "            0.1615 , 0.1495 , 0.1472 , 0.1443 , 0.1412 , 0.1367 , 0.1207 ,\n",
       "            0.07306, 0.0612 , 0.05176], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04237288, dtype=float32),\n",
       "    'tpr': array(0.54545456, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.16949153, 0.16949153,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.1779661 , 0.1779661 ,\n",
       "            0.1779661 , 0.18644068, 0.19491525, 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22033899, 0.22033899,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.6515151 , 0.65909094, 0.67424244, 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.70454544, 0.70454544, 0.719697  ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.8030303 , 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8636364 ,\n",
       "            0.8636364 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.8984 , 0.8716 , 0.8633 , 0.855  , 0.8545 , 0.8535 ,\n",
       "            0.8525 , 0.8516 , 0.8374 , 0.8267 , 0.82   , 0.813  , 0.8096 ,\n",
       "            0.801  , 0.8003 , 0.7944 , 0.789  , 0.787  , 0.778  , 0.777  ,\n",
       "            0.775  , 0.7744 , 0.771  , 0.764  , 0.7593 , 0.758  , 0.7573 ,\n",
       "            0.7563 , 0.75   , 0.748  , 0.7446 , 0.741  , 0.737  , 0.7363 ,\n",
       "            0.729  , 0.7163 , 0.7085 , 0.707  , 0.695  , 0.689  , 0.6836 ,\n",
       "            0.663  , 0.6587 , 0.6553 , 0.6523 , 0.6465 , 0.6426 , 0.638  ,\n",
       "            0.6167 , 0.6147 , 0.6133 , 0.5913 , 0.5796 , 0.575  , 0.5654 ,\n",
       "            0.5464 , 0.5425 , 0.538  , 0.5366 , 0.5337 , 0.529  , 0.5176 ,\n",
       "            0.513  , 0.512  , 0.511  , 0.509  , 0.5083 , 0.5063 , 0.503  ,\n",
       "            0.5024 , 0.502  , 0.5005 , 0.497  , 0.4956 , 0.4902 , 0.4873 ,\n",
       "            0.485  , 0.4814 , 0.4805 , 0.4785 , 0.4766 , 0.4746 , 0.474  ,\n",
       "            0.4739 , 0.4734 , 0.4731 , 0.4724 , 0.4714 , 0.4707 , 0.4646 ,\n",
       "            0.4644 , 0.4622 , 0.46   , 0.4585 , 0.4565 , 0.4546 , 0.4543 ,\n",
       "            0.4536 , 0.453  , 0.4517 , 0.4512 , 0.451  , 0.4497 , 0.4492 ,\n",
       "            0.4426 , 0.4395 , 0.439  , 0.438  , 0.435  , 0.4343 , 0.434  ,\n",
       "            0.4336 , 0.4326 , 0.432  , 0.4304 , 0.43   , 0.4287 , 0.4265 ,\n",
       "            0.4246 , 0.4238 , 0.4233 , 0.4207 , 0.4167 , 0.4158 , 0.412  ,\n",
       "            0.4072 , 0.407  , 0.4043 , 0.4033 , 0.4004 , 0.4    , 0.3972 ,\n",
       "            0.3962 , 0.396  , 0.3955 , 0.3938 , 0.3906 , 0.389  , 0.3882 ,\n",
       "            0.388  , 0.3848 , 0.381  , 0.3804 , 0.3787 , 0.3772 , 0.3735 ,\n",
       "            0.3706 , 0.369  , 0.3682 , 0.3665 , 0.3538 , 0.3523 , 0.3518 ,\n",
       "            0.3499 , 0.3489 , 0.3442 , 0.3438 , 0.3433 , 0.3418 , 0.341  ,\n",
       "            0.3408 , 0.338  , 0.3376 , 0.3364 , 0.3337 , 0.3325 , 0.3323 ,\n",
       "            0.331  , 0.3281 , 0.327  , 0.3262 , 0.3242 , 0.3237 , 0.3218 ,\n",
       "            0.3215 , 0.3213 , 0.3206 , 0.3203 , 0.3198 , 0.3186 , 0.318  ,\n",
       "            0.3176 , 0.313  , 0.3123 , 0.3118 , 0.3115 , 0.3105 , 0.31   ,\n",
       "            0.309  , 0.3079 , 0.3062 , 0.306  , 0.3052 , 0.3022 , 0.2993 ,\n",
       "            0.2974 , 0.2961 , 0.2932 , 0.2917 , 0.2908 , 0.2905 , 0.2903 ,\n",
       "            0.288  , 0.2861 , 0.2852 , 0.2842 , 0.2832 , 0.2751 , 0.2734 ,\n",
       "            0.273  , 0.2537 , 0.2485 , 0.2346 , 0.2109 , 0.2073 , 0.186  ,\n",
       "            0.1781 , 0.1748 , 0.1747 , 0.1708 , 0.1696 , 0.1683 , 0.1641 ,\n",
       "            0.1624 , 0.1548 , 0.1454 , 0.1406 , 0.1377 , 0.1326 , 0.1142 ,\n",
       "            0.06757, 0.05664, 0.047  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04237288, dtype=float32),\n",
       "    'tpr': array(0.5984849, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.11864407, 0.11864407, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.16949153, 0.16949153,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.19491525, 0.19491525, 0.21186441,\n",
       "            0.21186441, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21969697, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.4469697 , 0.4469697 , 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6287879 , 0.6363636 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.75757575, 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9165 , 0.8936 , 0.8853 , 0.878  , 0.8774 , 0.876  ,\n",
       "            0.8755 , 0.875  , 0.862  , 0.851  , 0.845  , 0.8374 , 0.8354 ,\n",
       "            0.827  , 0.8267 , 0.82   , 0.8145 , 0.814  , 0.8047 , 0.8037 ,\n",
       "            0.802  , 0.801  , 0.7983 , 0.7905 , 0.7866 , 0.784  , 0.7837 ,\n",
       "            0.7773 , 0.7754 , 0.772  , 0.7676 , 0.764  , 0.7637 , 0.7563 ,\n",
       "            0.7427 , 0.736  , 0.7334 , 0.7227 , 0.7163 , 0.7104 , 0.6895 ,\n",
       "            0.6836 , 0.6807 , 0.6787 , 0.673  , 0.6685 , 0.6636 , 0.6406 ,\n",
       "            0.639  , 0.6377 , 0.6147 , 0.6006 , 0.5977 , 0.586  , 0.571  ,\n",
       "            0.563  , 0.5586 , 0.5557 , 0.5522 , 0.5474 , 0.539  , 0.531  ,\n",
       "            0.5293 , 0.5283 , 0.526  , 0.5225 , 0.522  , 0.52   , 0.5195 ,\n",
       "            0.5176 , 0.517  , 0.515  , 0.5073 , 0.506  , 0.5054 , 0.5024 ,\n",
       "            0.501  , 0.4998 , 0.497  , 0.4932 , 0.4927 , 0.4907 , 0.4905 ,\n",
       "            0.4902 , 0.489  , 0.4883 , 0.4878 , 0.4868 , 0.4858 , 0.4856 ,\n",
       "            0.4849 , 0.4778 , 0.4766 , 0.4746 , 0.4739 , 0.4722 , 0.471  ,\n",
       "            0.4702 , 0.4695 , 0.466  , 0.4653 , 0.465  , 0.4636 , 0.463  ,\n",
       "            0.4626 , 0.4607 , 0.458  , 0.4578 , 0.4512 , 0.449  , 0.4478 ,\n",
       "            0.4475 , 0.4453 , 0.445  , 0.444  , 0.4434 , 0.442  , 0.4382 ,\n",
       "            0.4368 , 0.4358 , 0.4353 , 0.4265 , 0.4255 , 0.4224 , 0.4177 ,\n",
       "            0.4172 , 0.417  , 0.413  , 0.4126 , 0.4094 , 0.4053 , 0.404  ,\n",
       "            0.4036 , 0.4023 , 0.402  , 0.398  , 0.3962 , 0.3938 , 0.3936 ,\n",
       "            0.392  , 0.3901 , 0.3894 , 0.3853 , 0.3818 , 0.3809 , 0.379  ,\n",
       "            0.3782 , 0.3777 , 0.377  , 0.3765 , 0.3604 , 0.36   , 0.3599 ,\n",
       "            0.3584 , 0.3555 , 0.353  , 0.352  , 0.3513 , 0.3506 , 0.3472 ,\n",
       "            0.3464 , 0.343  , 0.3418 , 0.3413 , 0.3396 , 0.338  , 0.3347 ,\n",
       "            0.3345 , 0.334  , 0.3306 , 0.3303 , 0.33   , 0.3293 , 0.329  ,\n",
       "            0.3289 , 0.3271 , 0.3252 , 0.323  , 0.322  , 0.3206 , 0.319  ,\n",
       "            0.3188 , 0.3186 , 0.3176 , 0.3171 , 0.315  , 0.3145 , 0.3118 ,\n",
       "            0.311  , 0.3105 , 0.3098 , 0.309  , 0.3074 , 0.306  , 0.304  ,\n",
       "            0.3013 , 0.299  , 0.2966 , 0.2964 , 0.2961 , 0.293  , 0.2927 ,\n",
       "            0.292  , 0.2917 , 0.2915 , 0.2908 , 0.2844 , 0.274  , 0.2732 ,\n",
       "            0.2725 , 0.2559 , 0.2471 , 0.2339 , 0.2065 , 0.2035 , 0.1812 ,\n",
       "            0.1729 , 0.1698 , 0.1696 , 0.1659 , 0.1644 , 0.1636 , 0.1588 ,\n",
       "            0.1577 , 0.1503 , 0.1404 , 0.1359 , 0.1329 , 0.1328 , 0.1276 ,\n",
       "            0.1093 , 0.0627 , 0.0537 , 0.04297], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04237288, dtype=float32),\n",
       "    'tpr': array(0.68939394, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.1779661 , 0.1779661 , 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.31355932, 0.33050847, 0.33898306, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.69491524, 0.7033898 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37121212, 0.37878788, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46212122, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75      , 0.75757575, 0.75757575, 0.7651515 ,\n",
       "            0.7651515 , 0.77272725, 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.8030303 , 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9263 , 0.9053 , 0.8965 , 0.89   , 0.889  , 0.888  ,\n",
       "            0.8877 , 0.887  , 0.877  , 0.8633 , 0.86   , 0.851  , 0.85   ,\n",
       "            0.849  , 0.8423 , 0.842  , 0.831  , 0.829  , 0.826  , 0.8203 ,\n",
       "            0.818  , 0.8164 , 0.814  , 0.8125 , 0.8027 , 0.802  , 0.7983 ,\n",
       "            0.7964 , 0.796  , 0.792  , 0.7896 , 0.7856 , 0.7793 , 0.779  ,\n",
       "            0.7725 , 0.7544 , 0.7495 , 0.744  , 0.739  , 0.7324 , 0.725  ,\n",
       "            0.7    , 0.6943 , 0.6924 , 0.6904 , 0.6885 , 0.683  , 0.676  ,\n",
       "            0.6504 , 0.65   , 0.6484 , 0.623  , 0.609  , 0.6055 , 0.5933 ,\n",
       "            0.5894 , 0.5737 , 0.567  , 0.5654 , 0.5586 , 0.5537 , 0.5503 ,\n",
       "            0.5474 , 0.543  , 0.5425 , 0.542  , 0.5415 , 0.5396 , 0.5386 ,\n",
       "            0.5356 , 0.535  , 0.534  , 0.533  , 0.532  , 0.5317 , 0.523  ,\n",
       "            0.522  , 0.52   , 0.519  , 0.517  , 0.5166 , 0.5127 , 0.5083 ,\n",
       "            0.508  , 0.507  , 0.506  , 0.505  , 0.5044 , 0.504  , 0.5024 ,\n",
       "            0.501  , 0.4998 , 0.4985 , 0.4944 , 0.492  , 0.4897 , 0.4858 ,\n",
       "            0.485  , 0.4824 , 0.4822 , 0.48   , 0.4756 , 0.4744 , 0.473  ,\n",
       "            0.4722 , 0.4717 , 0.4714 , 0.471  , 0.47   , 0.4678 , 0.4583 ,\n",
       "            0.4575 , 0.456  , 0.455  , 0.4524 , 0.4514 , 0.4504 , 0.449  ,\n",
       "            0.4487 , 0.448  , 0.443  , 0.441  , 0.4373 , 0.434  , 0.431  ,\n",
       "            0.4265 , 0.4263 , 0.424  , 0.4238 , 0.4226 , 0.421  , 0.419  ,\n",
       "            0.4165 , 0.415  , 0.4087 , 0.408  , 0.4072 , 0.4062 , 0.4036 ,\n",
       "            0.3987 , 0.3982 , 0.395  , 0.3945 , 0.3943 , 0.3933 , 0.3867 ,\n",
       "            0.384  , 0.3833 , 0.3823 , 0.3804 , 0.38   , 0.3794 , 0.3774 ,\n",
       "            0.3667 , 0.3657 , 0.3613 , 0.3606 , 0.354  , 0.3538 , 0.3525 ,\n",
       "            0.351  , 0.35   , 0.3467 , 0.3462 , 0.3445 , 0.3438 , 0.3408 ,\n",
       "            0.339  , 0.3376 , 0.3325 , 0.332  , 0.3315 , 0.3298 , 0.3284 ,\n",
       "            0.3281 , 0.3276 , 0.3267 , 0.324  , 0.3235 , 0.3225 , 0.322  ,\n",
       "            0.3179 , 0.3174 , 0.316  , 0.315  , 0.3145 , 0.3127 , 0.3123 ,\n",
       "            0.312  , 0.3096 , 0.3083 , 0.3074 , 0.3066 , 0.305  , 0.3005 ,\n",
       "            0.2988 , 0.2969 , 0.2961 , 0.295  , 0.294  , 0.2922 , 0.2893 ,\n",
       "            0.2888 , 0.2886 , 0.2883 , 0.287  , 0.2837 , 0.2805 , 0.2778 ,\n",
       "            0.2695 , 0.2693 , 0.2542 , 0.2421 , 0.2295 , 0.1998 , 0.1991 ,\n",
       "            0.1746 , 0.166  , 0.1635 , 0.1627 , 0.1602 , 0.1583 , 0.1577 ,\n",
       "            0.1523 , 0.1512 , 0.1443 , 0.1353 , 0.1298 , 0.1279 , 0.127  ,\n",
       "            0.12244, 0.1036 , 0.05792, 0.0504 , 0.03912], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.05084746, dtype=float32),\n",
       "    'tpr': array(0.74242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05932203, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.41525424,\n",
       "            0.42372882, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.47727272,\n",
       "            0.4848485 , 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.65909094, 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.7121212 , 0.719697  , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.8030303 , 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.82575756, 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.938  , 0.9194 , 0.91   , 0.9053 , 0.905  , 0.904  ,\n",
       "            0.903  , 0.9014 , 0.8936 , 0.8794 , 0.8774 , 0.8687 , 0.868  ,\n",
       "            0.8657 , 0.8604 , 0.86   , 0.848  , 0.8477 , 0.8433 , 0.84   ,\n",
       "            0.836  , 0.8354 , 0.8335 , 0.83   , 0.822  , 0.8213 , 0.821  ,\n",
       "            0.818  , 0.815  , 0.814  , 0.8115 , 0.809  , 0.804  , 0.7993 ,\n",
       "            0.799  , 0.7974 , 0.793  , 0.7734 , 0.7695 , 0.763  , 0.7554 ,\n",
       "            0.753  , 0.745  , 0.7188 , 0.7124 , 0.7085 , 0.706  , 0.7036 ,\n",
       "            0.6953 , 0.669  , 0.6685 , 0.6655 , 0.6396 , 0.6265 , 0.621  ,\n",
       "            0.62   , 0.6025 , 0.587  , 0.5864 , 0.583  , 0.5825 , 0.5674 ,\n",
       "            0.565  , 0.5645 , 0.562  , 0.561  , 0.5605 , 0.5596 , 0.556  ,\n",
       "            0.5557 , 0.5547 , 0.5537 , 0.5527 , 0.546  , 0.545  , 0.5435 ,\n",
       "            0.543  , 0.541  , 0.5405 , 0.5386 , 0.5356 , 0.5303 , 0.529  ,\n",
       "            0.5283 , 0.5273 , 0.527  , 0.526  , 0.525  , 0.5225 , 0.521  ,\n",
       "            0.5176 , 0.5146 , 0.5137 , 0.507  , 0.5063 , 0.5034 , 0.503  ,\n",
       "            0.4998 , 0.4937 , 0.4932 , 0.4917 , 0.4912 , 0.4866 , 0.4856 ,\n",
       "            0.4854 , 0.484  , 0.4812 , 0.4797 , 0.479  , 0.474  , 0.4736 ,\n",
       "            0.4727 , 0.4678 , 0.4673 , 0.4656 , 0.4639 , 0.4636 , 0.4634 ,\n",
       "            0.4592 , 0.4585 , 0.4575 , 0.4507 , 0.4487 , 0.44   , 0.439  ,\n",
       "            0.4368 , 0.4336 , 0.4302 , 0.43   , 0.4285 , 0.4268 , 0.4263 ,\n",
       "            0.4219 , 0.417  , 0.4165 , 0.4155 , 0.4124 , 0.4084 , 0.4072 ,\n",
       "            0.402  , 0.401  , 0.3967 , 0.3962 , 0.3958 , 0.3955 , 0.3928 ,\n",
       "            0.3904 , 0.39   , 0.3887 , 0.3872 , 0.381  , 0.3794 , 0.373  ,\n",
       "            0.3708 , 0.3684 , 0.3665 , 0.3662 , 0.362  , 0.3594 , 0.3552 ,\n",
       "            0.355  , 0.3545 , 0.3533 , 0.3523 , 0.3508 , 0.3481 , 0.3455 ,\n",
       "            0.34   , 0.3396 , 0.3384 , 0.3381 , 0.3364 , 0.3352 , 0.3347 ,\n",
       "            0.3318 , 0.3271 , 0.3257 , 0.324  , 0.3235 , 0.3218 , 0.3186 ,\n",
       "            0.318  , 0.3179 , 0.3171 , 0.3167 , 0.3162 , 0.316  , 0.313  ,\n",
       "            0.3108 , 0.309  , 0.3079 , 0.3066 , 0.3057 , 0.3044 , 0.303  ,\n",
       "            0.3027 , 0.3005 , 0.2961 , 0.2954 , 0.295  , 0.2944 , 0.294  ,\n",
       "            0.2927 , 0.2925 , 0.292  , 0.2888 , 0.2864 , 0.279  , 0.278  ,\n",
       "            0.269  , 0.2673 , 0.2542 , 0.2384 , 0.2264 , 0.1968 , 0.1953 ,\n",
       "            0.1694 , 0.1605 , 0.1582 , 0.1573 , 0.1559 , 0.1547 , 0.1523 ,\n",
       "            0.1472 , 0.1461 , 0.1392 , 0.1313 , 0.12476, 0.12463, 0.1219 ,\n",
       "            0.1188 , 0.09845, 0.0537 , 0.04724, 0.03568], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.05084746, dtype=float32),\n",
       "    'tpr': array(0.8030303, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.16101696, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.4915254 , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.65254235,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.43939394,\n",
       "            0.45454547, 0.45454547, 0.46212122, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.82575756, 0.8333333 , 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9478 , 0.931  , 0.923  , 0.9185 , 0.9175 , 0.917  ,\n",
       "            0.9165 , 0.9146 , 0.9087 , 0.894  , 0.8936 , 0.8857 , 0.885  ,\n",
       "            0.8813 , 0.8774 , 0.877  , 0.865  , 0.8643 , 0.8594 , 0.858  ,\n",
       "            0.8535 , 0.853  , 0.852  , 0.847  , 0.841  , 0.8403 , 0.8384 ,\n",
       "            0.837  , 0.8325 , 0.8315 , 0.8306 , 0.827  , 0.8223 , 0.8184 ,\n",
       "            0.818  , 0.816  , 0.8125 , 0.792  , 0.788  , 0.7812 , 0.7734 ,\n",
       "            0.773  , 0.765  , 0.7373 , 0.7324 , 0.7314 , 0.727  , 0.7236 ,\n",
       "            0.723  , 0.7144 , 0.688  , 0.6875 , 0.683  , 0.6816 , 0.6567 ,\n",
       "            0.6445 , 0.6426 , 0.6377 , 0.617  , 0.607  , 0.601  , 0.5986 ,\n",
       "            0.5864 , 0.5835 , 0.582  , 0.58   , 0.578  , 0.5776 , 0.5767 ,\n",
       "            0.576  , 0.575  , 0.574  , 0.571  , 0.5703 , 0.57   , 0.568  ,\n",
       "            0.567  , 0.5654 , 0.564  , 0.563  , 0.5576 , 0.5566 , 0.556  ,\n",
       "            0.552  , 0.5513 , 0.5503 , 0.549  , 0.5474 , 0.547  , 0.5464 ,\n",
       "            0.5454 , 0.5405 , 0.539  , 0.5376 , 0.537  , 0.535  , 0.5303 ,\n",
       "            0.5264 , 0.525  , 0.5195 , 0.5166 , 0.515  , 0.514  , 0.512  ,\n",
       "            0.508  , 0.501  , 0.5005 , 0.4954 , 0.4937 , 0.4905 , 0.489  ,\n",
       "            0.488  , 0.4875 , 0.4873 , 0.484  , 0.4814 , 0.4797 , 0.4792 ,\n",
       "            0.4785 , 0.476  , 0.472  , 0.4717 , 0.4697 , 0.4688 , 0.4678 ,\n",
       "            0.4666 , 0.4573 , 0.4563 , 0.454  , 0.4485 , 0.445  , 0.4434 ,\n",
       "            0.4407 , 0.4368 , 0.4343 , 0.4336 , 0.432  , 0.4294 , 0.427  ,\n",
       "            0.4246 , 0.4243 , 0.423  , 0.42   , 0.4111 , 0.4082 , 0.4075 ,\n",
       "            0.4058 , 0.4006 , 0.3992 , 0.3984 , 0.3982 , 0.3953 , 0.3945 ,\n",
       "            0.3914 , 0.3855 , 0.382  , 0.3818 , 0.3813 , 0.3792 , 0.372  ,\n",
       "            0.3704 , 0.3696 , 0.3674 , 0.367  , 0.365  , 0.3616 , 0.3604 ,\n",
       "            0.3596 , 0.356  , 0.3545 , 0.3503 , 0.3499 , 0.3489 , 0.3484 ,\n",
       "            0.3464 , 0.3457 , 0.3452 , 0.3435 , 0.3396 , 0.3384 , 0.3342 ,\n",
       "            0.332  , 0.3298 , 0.3245 , 0.3237 , 0.3235 , 0.323  , 0.3218 ,\n",
       "            0.3208 , 0.3186 , 0.3157 , 0.3147 , 0.314  , 0.3135 , 0.3123 ,\n",
       "            0.3079 , 0.3076 , 0.3064 , 0.305  , 0.3042 , 0.3027 , 0.2983 ,\n",
       "            0.297  , 0.2964 , 0.2961 , 0.2957 , 0.2944 , 0.292  , 0.2888 ,\n",
       "            0.2874 , 0.2786 , 0.2769 , 0.2678 , 0.265  , 0.264  , 0.2544 ,\n",
       "            0.2346 , 0.2233 , 0.1927 , 0.19   , 0.1636 , 0.1544 , 0.1525 ,\n",
       "            0.1514 , 0.151  , 0.15   , 0.1464 , 0.1414 , 0.1404 , 0.1337 ,\n",
       "            0.1267 , 0.1204 , 0.1192 , 0.11633, 0.1142 , 0.0932 , 0.04932,\n",
       "            0.0441 , 0.0323 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.06779661, dtype=float32),\n",
       "    'tpr': array(0.8484849, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.1440678 , 0.15254237, 0.15254237,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.1779661 , 0.18644068, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.30508474, 0.31355932, 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.959  , 0.945  , 0.9375 , 0.934  , 0.9336 , 0.933  ,\n",
       "            0.932  , 0.9316 , 0.9307 , 0.9253 , 0.912  , 0.9116 , 0.905  ,\n",
       "            0.904  , 0.901  , 0.8975 , 0.897  , 0.886  , 0.8857 , 0.8813 ,\n",
       "            0.8794 , 0.8755 , 0.875  , 0.8735 , 0.8696 , 0.8633 , 0.863  ,\n",
       "            0.8613 , 0.8604 , 0.856  , 0.855  , 0.8545 , 0.8506 , 0.846  ,\n",
       "            0.8423 , 0.84   , 0.837  , 0.8174 , 0.8135 , 0.807  , 0.799  ,\n",
       "            0.796  , 0.7915 , 0.764  , 0.759  , 0.7583 , 0.7544 , 0.7495 ,\n",
       "            0.7456 , 0.7417 , 0.7144 , 0.711  , 0.7046 , 0.6836 , 0.67   ,\n",
       "            0.6655 , 0.664  , 0.6445 , 0.6313 , 0.6274 , 0.623  , 0.6226 ,\n",
       "            0.607  , 0.6064 , 0.6055 , 0.6045 , 0.6    , 0.5996 , 0.5986 ,\n",
       "            0.598  , 0.5957 , 0.5947 , 0.5933 , 0.5903 , 0.59   , 0.589  ,\n",
       "            0.588  , 0.587  , 0.586  , 0.5806 , 0.5786 , 0.576  , 0.5747 ,\n",
       "            0.574  , 0.5737 , 0.5728 , 0.5703 , 0.5674 , 0.567  , 0.566  ,\n",
       "            0.5635 , 0.5615 , 0.56   , 0.5586 , 0.5537 , 0.5483 , 0.5474 ,\n",
       "            0.545  , 0.5396 , 0.538  , 0.5376 , 0.537  , 0.536  , 0.5356 ,\n",
       "            0.526  , 0.525  , 0.5195 , 0.5186 , 0.515  , 0.511  , 0.5107 ,\n",
       "            0.5103 , 0.51   , 0.508  , 0.507  , 0.503  , 0.4983 , 0.4944 ,\n",
       "            0.494  , 0.4917 , 0.49   , 0.4897 , 0.4888 , 0.487  , 0.4802 ,\n",
       "            0.478  , 0.4763 , 0.4739 , 0.4731 , 0.4675 , 0.4644 , 0.4612 ,\n",
       "            0.4575 , 0.4558 , 0.4526 , 0.449  , 0.4458 , 0.4402 , 0.4377 ,\n",
       "            0.4355 , 0.4329 , 0.4314 , 0.4292 , 0.429  , 0.4246 , 0.4236 ,\n",
       "            0.4219 , 0.4165 , 0.4148 , 0.414  , 0.4097 , 0.4092 , 0.4055 ,\n",
       "            0.4045 , 0.4033 , 0.3987 , 0.3977 , 0.3882 , 0.387  , 0.3867 ,\n",
       "            0.3855 , 0.3833 , 0.3809 , 0.3782 , 0.3752 , 0.3733 , 0.368  ,\n",
       "            0.3672 , 0.3655 , 0.3633 , 0.3608 , 0.3606 , 0.3599 , 0.359  ,\n",
       "            0.3584 , 0.3562 , 0.3496 , 0.3477 , 0.343  , 0.3423 , 0.3384 ,\n",
       "            0.3376 , 0.3357 , 0.3347 , 0.3342 , 0.3328 , 0.328  , 0.3267 ,\n",
       "            0.3254 , 0.3247 , 0.3245 , 0.3232 , 0.3223 , 0.3196 , 0.3193 ,\n",
       "            0.319  , 0.3184 , 0.3179 , 0.3171 , 0.3167 , 0.3096 , 0.3088 ,\n",
       "            0.3079 , 0.3076 , 0.306  , 0.3057 , 0.3054 , 0.3035 , 0.2998 ,\n",
       "            0.2974 , 0.2896 , 0.2878 , 0.2761 , 0.2683 , 0.2651 , 0.2634 ,\n",
       "            0.259  , 0.2338 , 0.2229 , 0.1896 , 0.1858 , 0.1592 , 0.1498 ,\n",
       "            0.1482 , 0.147  , 0.1467 , 0.1458 , 0.1417 , 0.1365 , 0.1361 ,\n",
       "            0.1298 , 0.1223 , 0.11615, 0.115  , 0.1122 , 0.1097 , 0.0891 ,\n",
       "            0.0457 , 0.04184, 0.02937], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.07627118, dtype=float32),\n",
       "    'tpr': array(0.8863636, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.36363637, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.6060606 , 0.6212121 , 0.6287879 ,\n",
       "            0.6439394 , 0.6515151 , 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.77272725, 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9653 , 0.9526 , 0.9463 , 0.944  , 0.943  , 0.9424 ,\n",
       "            0.9414 , 0.941  , 0.9395 , 0.936  , 0.924  , 0.923  , 0.917  ,\n",
       "            0.916  , 0.9116 , 0.91   , 0.9097 , 0.9    , 0.8975 , 0.8936 ,\n",
       "            0.893  , 0.8896 , 0.888  , 0.8877 , 0.882  , 0.878  , 0.877  ,\n",
       "            0.875  , 0.8745 , 0.869  , 0.8687 , 0.8647 , 0.861  , 0.8584 ,\n",
       "            0.858  , 0.8535 , 0.853  , 0.832  , 0.829  , 0.822  , 0.8164 ,\n",
       "            0.809  , 0.8086 , 0.78   , 0.7764 , 0.774  , 0.7695 , 0.768  ,\n",
       "            0.759  , 0.732  , 0.7305 , 0.726  , 0.7173 , 0.6987 , 0.6895 ,\n",
       "            0.687  , 0.6787 , 0.657  , 0.6567 , 0.649  , 0.6387 , 0.634  ,\n",
       "            0.63   , 0.6284 , 0.6265 , 0.626  , 0.6235 , 0.622  , 0.6177 ,\n",
       "            0.615  , 0.6143 , 0.614  , 0.613  , 0.6123 , 0.612  , 0.609  ,\n",
       "            0.608  , 0.6064 , 0.606  , 0.6045 , 0.6035 , 0.601  , 0.5986 ,\n",
       "            0.597  , 0.593  , 0.5913 , 0.589  , 0.5884 , 0.587  , 0.585  ,\n",
       "            0.5806 , 0.579  , 0.573  , 0.571  , 0.5703 , 0.563  , 0.5625 ,\n",
       "            0.56   , 0.557  , 0.5557 , 0.552  , 0.5483 , 0.545  , 0.5386 ,\n",
       "            0.537  , 0.533  , 0.5327 , 0.5312 , 0.526  , 0.5215 , 0.5195 ,\n",
       "            0.513  , 0.509  , 0.5083 , 0.5063 , 0.504  , 0.4973 , 0.4968 ,\n",
       "            0.494  , 0.4932 , 0.4917 , 0.4902 , 0.488  , 0.4841 , 0.4834 ,\n",
       "            0.4812 , 0.4727 , 0.4714 , 0.4668 , 0.462  , 0.454  , 0.4539 ,\n",
       "            0.4521 , 0.4478 , 0.4453 , 0.443  , 0.4392 , 0.439  , 0.4382 ,\n",
       "            0.438  , 0.4287 , 0.4282 , 0.4277 , 0.4177 , 0.4175 , 0.4167 ,\n",
       "            0.4148 , 0.4143 , 0.4124 , 0.4119 , 0.4111 , 0.4104 , 0.4075 ,\n",
       "            0.3992 , 0.399  , 0.3965 , 0.3914 , 0.39   , 0.3894 , 0.3892 ,\n",
       "            0.3843 , 0.3828 , 0.3794 , 0.3784 , 0.3782 , 0.3765 , 0.372  ,\n",
       "            0.3699 , 0.3696 , 0.3694 , 0.368  , 0.3672 , 0.3616 , 0.3582 ,\n",
       "            0.3574 , 0.3496 , 0.345  , 0.3442 , 0.344  , 0.3433 , 0.3428 ,\n",
       "            0.339  , 0.3381 , 0.3362 , 0.3357 , 0.335  , 0.3296 , 0.329  ,\n",
       "            0.3281 , 0.326  , 0.3252 , 0.3242 , 0.3232 , 0.3225 , 0.3218 ,\n",
       "            0.3203 , 0.32   , 0.318  , 0.317  , 0.3147 , 0.312  , 0.3115 ,\n",
       "            0.306  , 0.3052 , 0.305  , 0.3015 , 0.301  , 0.2998 , 0.2903 ,\n",
       "            0.288  , 0.2747 , 0.27   , 0.2632 , 0.2615 , 0.258  , 0.2302 ,\n",
       "            0.2194 , 0.1871 , 0.1819 , 0.1545 , 0.1451 , 0.1437 , 0.1434 ,\n",
       "            0.1431 , 0.142  , 0.137  , 0.1321 , 0.1313 , 0.1249 , 0.1196 ,\n",
       "            0.1142 , 0.1103 , 0.1074 , 0.10706, 0.0845 , 0.04248, 0.03897,\n",
       "            0.02681], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.11016949, dtype=float32),\n",
       "    'tpr': array(0.90909094, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.10169491, 0.11016949, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.1440678 , 0.1440678 , 0.1440678 , 0.15254237, 0.15254237,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.27272728, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6515151 , 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9727 , 0.9614 , 0.956  , 0.9546 , 0.9536 , 0.9526 ,\n",
       "            0.9517 , 0.951  , 0.95   , 0.9478 , 0.9365 , 0.9355 , 0.9307 ,\n",
       "            0.93   , 0.926  , 0.925  , 0.9243 , 0.9155 , 0.9126 , 0.9097 ,\n",
       "            0.9087 , 0.9062 , 0.905  , 0.904  , 0.8984 , 0.8955 , 0.8936 ,\n",
       "            0.8926 , 0.8916 , 0.887  , 0.8867 , 0.8857 , 0.8823 , 0.8784 ,\n",
       "            0.877  , 0.872  , 0.8516 , 0.8486 , 0.8413 , 0.8364 , 0.83   ,\n",
       "            0.8276 , 0.802  , 0.799  , 0.796  , 0.791  , 0.79   , 0.7817 ,\n",
       "            0.778  , 0.755  , 0.7524 , 0.7476 , 0.737  , 0.721  , 0.7124 ,\n",
       "            0.71   , 0.7007 , 0.6787 , 0.678  , 0.6685 , 0.6606 , 0.653  ,\n",
       "            0.651  , 0.649  , 0.6475 , 0.646  , 0.645  , 0.644  , 0.636  ,\n",
       "            0.635  , 0.6343 , 0.6333 , 0.633  , 0.6323 , 0.632  , 0.631  ,\n",
       "            0.626  , 0.625  , 0.6245 , 0.6235 , 0.621  , 0.62   , 0.619  ,\n",
       "            0.614  , 0.6113 , 0.6094 , 0.6084 , 0.608  , 0.6064 , 0.6006 ,\n",
       "            0.599  , 0.592  , 0.5913 , 0.5854 , 0.582  , 0.5815 , 0.5767 ,\n",
       "            0.575  , 0.5747 , 0.5703 , 0.5693 , 0.5635 , 0.5576 , 0.556  ,\n",
       "            0.554  , 0.5527 , 0.5513 , 0.542  , 0.5415 , 0.534  , 0.527  ,\n",
       "            0.524  , 0.5225 , 0.521  , 0.5195 , 0.5176 , 0.5137 , 0.5073 ,\n",
       "            0.507  , 0.5063 , 0.505  , 0.5005 , 0.4978 , 0.497  , 0.489  ,\n",
       "            0.4863 , 0.479  , 0.478  , 0.4673 , 0.465  , 0.4592 , 0.453  ,\n",
       "            0.4526 , 0.4521 , 0.4517 , 0.4463 , 0.4448 , 0.4414 , 0.4402 ,\n",
       "            0.4382 , 0.4312 , 0.429  , 0.4265 , 0.4248 , 0.4246 , 0.4238 ,\n",
       "            0.423  , 0.4214 , 0.4207 , 0.413  , 0.412  , 0.4116 , 0.4092 ,\n",
       "            0.4033 , 0.4023 , 0.3958 , 0.3943 , 0.393  , 0.39   , 0.3894 ,\n",
       "            0.388  , 0.3872 , 0.386  , 0.3823 , 0.3804 , 0.3796 , 0.3782 ,\n",
       "            0.377  , 0.3762 , 0.3684 , 0.3652 , 0.3633 , 0.3538 , 0.3533 ,\n",
       "            0.353  , 0.3513 , 0.347  , 0.3467 , 0.3464 , 0.3462 , 0.3423 ,\n",
       "            0.34   , 0.3376 , 0.3364 , 0.3354 , 0.3335 , 0.3315 , 0.328  ,\n",
       "            0.327  , 0.3267 , 0.3262 , 0.3237 , 0.3232 , 0.323  , 0.321  ,\n",
       "            0.3206 , 0.3203 , 0.3196 , 0.3179 , 0.3113 , 0.308  , 0.3066 ,\n",
       "            0.306  , 0.3037 , 0.3032 , 0.2957 , 0.2886 , 0.274  , 0.2712 ,\n",
       "            0.263  , 0.2622 , 0.2605 , 0.2294 , 0.2185 , 0.1844 , 0.1781 ,\n",
       "            0.1505 , 0.1409 , 0.1404 , 0.1398 , 0.1395 , 0.1377 , 0.1327 ,\n",
       "            0.1283 , 0.1273 , 0.12115, 0.11615, 0.111  , 0.1063 , 0.10376,\n",
       "            0.1036 , 0.0808 , 0.0395 , 0.037  , 0.02452], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.11864407, dtype=float32),\n",
       "    'tpr': array(0.9318182, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.18644068, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.61864406, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6287879 , 0.6287879 , 0.6439394 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.780303  , 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8560606 , 0.8712121 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.9166667 , 0.9166667 , 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.977  , 0.968  , 0.963  , 0.9614 , 0.9604 , 0.96   ,\n",
       "            0.959  , 0.9585 , 0.9575 , 0.955  , 0.946  , 0.944  , 0.941  ,\n",
       "            0.94   , 0.935  , 0.9346 , 0.9263 , 0.923  , 0.921  , 0.9194 ,\n",
       "            0.918  , 0.9165 , 0.9146 , 0.9097 , 0.9077 , 0.9053 , 0.905  ,\n",
       "            0.9033 , 0.9    , 0.8984 , 0.898  , 0.895  , 0.8906 , 0.89   ,\n",
       "            0.886  , 0.885  , 0.865  , 0.863  , 0.8555 , 0.851  , 0.8457 ,\n",
       "            0.8384 , 0.817  , 0.8154 , 0.8105 , 0.806  , 0.8057 , 0.798  ,\n",
       "            0.789  , 0.772  , 0.7686 , 0.763  , 0.7476 , 0.737  , 0.734  ,\n",
       "            0.7266 , 0.7153 , 0.701  , 0.6924 , 0.6885 , 0.677  , 0.672  ,\n",
       "            0.67   , 0.6685 , 0.667  , 0.6655 , 0.664  , 0.6626 , 0.6577 ,\n",
       "            0.657  , 0.655  , 0.6533 , 0.6523 , 0.652  , 0.6514 , 0.651  ,\n",
       "            0.648  , 0.6445 , 0.6436 , 0.6426 , 0.6416 , 0.636  , 0.635  ,\n",
       "            0.632  , 0.631  , 0.6304 , 0.6294 , 0.6284 , 0.628  , 0.6255 ,\n",
       "            0.621  , 0.6196 , 0.614  , 0.612  , 0.61   , 0.6084 , 0.605  ,\n",
       "            0.6035 , 0.594  , 0.5938 , 0.593  , 0.5825 , 0.5815 , 0.5786 ,\n",
       "            0.576  , 0.5747 , 0.573  , 0.5723 , 0.562  , 0.557  , 0.5557 ,\n",
       "            0.541  , 0.5386 , 0.535  , 0.5347 , 0.534  , 0.524  , 0.518  ,\n",
       "            0.5176 , 0.5166 , 0.515  , 0.513  , 0.512  , 0.5117 , 0.507  ,\n",
       "            0.5063 , 0.506  , 0.5    , 0.4946 , 0.485  , 0.4822 , 0.4775 ,\n",
       "            0.4705 , 0.4692 , 0.4678 , 0.467  , 0.4658 , 0.4565 , 0.4563 ,\n",
       "            0.4536 , 0.4475 , 0.4453 , 0.4443 , 0.441  , 0.4407 , 0.4385 ,\n",
       "            0.4377 , 0.4272 , 0.4268 , 0.4263 , 0.4253 , 0.4248 , 0.4233 ,\n",
       "            0.421  , 0.415  , 0.4143 , 0.414  , 0.405  , 0.4016 , 0.3994 ,\n",
       "            0.3958 , 0.3945 , 0.393  , 0.391  , 0.3906 , 0.3884 , 0.3882 ,\n",
       "            0.387  , 0.3857 , 0.3794 , 0.3784 , 0.3657 , 0.3635 , 0.362  ,\n",
       "            0.3613 , 0.3608 , 0.3564 , 0.3542 , 0.353  , 0.3481 , 0.3462 ,\n",
       "            0.3455 , 0.3452 , 0.343  , 0.342  , 0.3418 , 0.3408 , 0.3389 ,\n",
       "            0.3386 , 0.337  , 0.3352 , 0.331  , 0.3281 , 0.3262 , 0.326  ,\n",
       "            0.325  , 0.3235 , 0.3228 , 0.3215 , 0.32   , 0.3147 , 0.3135 ,\n",
       "            0.3076 , 0.306  , 0.3042 , 0.3037 , 0.299  , 0.288  , 0.273  ,\n",
       "            0.2715 , 0.26   , 0.2595 , 0.258  , 0.2249 , 0.2137 , 0.1819 ,\n",
       "            0.1736 , 0.1453 , 0.1371 , 0.1368 , 0.1357 , 0.134  , 0.1326 ,\n",
       "            0.1276 , 0.1241 , 0.122  , 0.1158 , 0.1136 , 0.10913, 0.10126,\n",
       "            0.1009 , 0.0981 , 0.076  , 0.03635, 0.03403, 0.02208],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.11864407, dtype=float32),\n",
       "    'tpr': array(0.9469697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11016949, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3644068 , 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44915253, 0.45762712, 0.4661017 , 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.9015151 , 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.92424244, 0.92424244,\n",
       "            0.92424244, 0.92424244, 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9805 , 0.9717 , 0.9673 , 0.967  , 0.9653 , 0.965  ,\n",
       "            0.964  , 0.9624 , 0.961  , 0.9526 , 0.95   , 0.9478 , 0.9473 ,\n",
       "            0.943  , 0.942  , 0.9414 , 0.9346 , 0.9297 , 0.929  , 0.9263 ,\n",
       "            0.926  , 0.9224 , 0.9175 , 0.917  , 0.9146 , 0.913  , 0.911  ,\n",
       "            0.909  , 0.9067 , 0.906  , 0.9033 , 0.901  , 0.9    , 0.8994 ,\n",
       "            0.897  , 0.893  , 0.8745 , 0.872  , 0.8643 , 0.8623 , 0.8574 ,\n",
       "            0.8467 , 0.8276 , 0.8267 , 0.821  , 0.8174 , 0.8154 , 0.809  ,\n",
       "            0.798  , 0.784  , 0.7793 , 0.772  , 0.7563 , 0.7544 , 0.747  ,\n",
       "            0.7397 , 0.7236 , 0.723  , 0.708  , 0.699  , 0.693  , 0.6904 ,\n",
       "            0.689  , 0.688  , 0.686  , 0.6826 , 0.6807 , 0.68   , 0.679  ,\n",
       "            0.6753 , 0.673  , 0.6724 , 0.672  , 0.67   , 0.6694 , 0.669  ,\n",
       "            0.667  , 0.663  , 0.6616 , 0.661  , 0.6577 , 0.6553 , 0.6514 ,\n",
       "            0.651  , 0.6494 , 0.647  , 0.64   , 0.6396 , 0.6377 , 0.6343 ,\n",
       "            0.633  , 0.6323 , 0.6313 , 0.628  , 0.627  , 0.6245 , 0.6167 ,\n",
       "            0.6133 , 0.6104 , 0.609  , 0.602  , 0.5986 , 0.5977 , 0.5947 ,\n",
       "            0.593  , 0.5923 , 0.592  , 0.5815 , 0.576  , 0.5723 , 0.5586 ,\n",
       "            0.552  , 0.5493 , 0.548  , 0.5474 , 0.5396 , 0.538  , 0.5327 ,\n",
       "            0.532  , 0.5303 , 0.5273 , 0.521  , 0.52   , 0.5166 , 0.514  ,\n",
       "            0.5137 , 0.5117 , 0.509  , 0.508  , 0.4956 , 0.4946 , 0.4832 ,\n",
       "            0.48   , 0.4792 , 0.4785 , 0.4678 , 0.467  , 0.463  , 0.4622 ,\n",
       "            0.4592 , 0.4556 , 0.4517 , 0.4485 , 0.4468 , 0.4443 , 0.4355 ,\n",
       "            0.432  , 0.4312 , 0.4285 , 0.4275 , 0.4265 , 0.422  , 0.4214 ,\n",
       "            0.421  , 0.419  , 0.4163 , 0.4148 , 0.4097 , 0.4092 , 0.407  ,\n",
       "            0.3965 , 0.3955 , 0.395  , 0.3943 , 0.392  , 0.39   , 0.384  ,\n",
       "            0.3833 , 0.3777 , 0.376  , 0.365  , 0.3647 , 0.3638 , 0.362  ,\n",
       "            0.3567 , 0.3542 , 0.354  , 0.35   , 0.3477 , 0.344  , 0.343  ,\n",
       "            0.3423 , 0.3416 , 0.339  , 0.3386 , 0.338  , 0.3374 , 0.3335 ,\n",
       "            0.3306 , 0.3286 , 0.326  , 0.3245 , 0.322  , 0.3198 , 0.3196 ,\n",
       "            0.3164 , 0.3157 , 0.3127 , 0.3115 , 0.311  , 0.304  , 0.301  ,\n",
       "            0.2957 , 0.2954 , 0.2869 , 0.2744 , 0.268  , 0.2559 , 0.2556 ,\n",
       "            0.2542 , 0.2191 , 0.2076 , 0.1794 , 0.1688 , 0.1398 , 0.1348 ,\n",
       "            0.1337 , 0.1304 , 0.1287 , 0.1272 , 0.1222 , 0.1201 , 0.1166 ,\n",
       "            0.11145, 0.1099 , 0.1078 , 0.0993 , 0.09534, 0.0925 , 0.0712 ,\n",
       "            0.0336 , 0.03137, 0.01991], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.11864407, dtype=float32),\n",
       "    'tpr': array(0.9621212, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.82575756, 0.8333333 , 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.92424244, 0.92424244,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.984  , 0.976  , 0.972  , 0.9707 , 0.9697 , 0.969  ,\n",
       "            0.9688 , 0.968  , 0.967  , 0.9595 , 0.9565 , 0.955  , 0.9546 ,\n",
       "            0.9507 , 0.949  , 0.9487 , 0.943  , 0.938  , 0.9375 , 0.935  ,\n",
       "            0.9346 , 0.931  , 0.9272 , 0.9263 , 0.9243 , 0.923  , 0.9204 ,\n",
       "            0.919  , 0.9165 , 0.9155 , 0.9136 , 0.912  , 0.91   , 0.9097 ,\n",
       "            0.9077 , 0.9033 , 0.8853 , 0.884  , 0.8755 , 0.875  , 0.8706 ,\n",
       "            0.857  , 0.8423 , 0.8394 , 0.8335 , 0.8315 , 0.828  , 0.8228 ,\n",
       "            0.8096 , 0.8    , 0.793  , 0.7847 , 0.776  , 0.7676 , 0.7607 ,\n",
       "            0.756  , 0.7466 , 0.7363 , 0.729  , 0.716  , 0.7134 , 0.712  ,\n",
       "            0.711  , 0.709  , 0.705  , 0.7046 , 0.703  , 0.6987 , 0.6963 ,\n",
       "            0.6943 , 0.693  , 0.6924 , 0.691  , 0.69   , 0.6895 , 0.6885 ,\n",
       "            0.685  , 0.6836 , 0.6816 , 0.6807 , 0.6772 , 0.676  , 0.674  ,\n",
       "            0.6733 , 0.6724 , 0.6675 , 0.6616 , 0.661  , 0.6577 , 0.656  ,\n",
       "            0.6553 , 0.65   , 0.649  , 0.6484 , 0.646  , 0.644  , 0.6406 ,\n",
       "            0.64   , 0.6357 , 0.631  , 0.6265 , 0.626  , 0.6206 , 0.6187 ,\n",
       "            0.6157 , 0.614  , 0.6133 , 0.6064 , 0.6035 , 0.5986 , 0.59   ,\n",
       "            0.58   , 0.5674 , 0.566  , 0.5635 , 0.5615 , 0.5566 , 0.5493 ,\n",
       "            0.549  , 0.54   , 0.5386 , 0.537  , 0.535  , 0.5254 , 0.5244 ,\n",
       "            0.5234 , 0.523  , 0.5195 , 0.5186 , 0.5156 , 0.5083 , 0.4946 ,\n",
       "            0.4927 , 0.491  , 0.486  , 0.4795 , 0.472  , 0.4697 , 0.467  ,\n",
       "            0.4644 , 0.4636 , 0.4612 , 0.4568 , 0.4521 , 0.4517 , 0.4485 ,\n",
       "            0.4463 , 0.4397 , 0.4373 , 0.431  , 0.4307 , 0.4304 , 0.4294 ,\n",
       "            0.4277 , 0.4204 , 0.4177 , 0.4175 , 0.416  , 0.4155 , 0.415  ,\n",
       "            0.4124 , 0.4033 , 0.4006 , 0.3994 , 0.3972 , 0.3967 , 0.3965 ,\n",
       "            0.3955 , 0.3901 , 0.3806 , 0.3755 , 0.3735 , 0.3694 , 0.3691 ,\n",
       "            0.3682 , 0.3674 , 0.3662 , 0.3635 , 0.3613 , 0.3594 , 0.3572 ,\n",
       "            0.3552 , 0.3525 , 0.3494 , 0.3462 , 0.3447 , 0.344  , 0.3428 ,\n",
       "            0.3408 , 0.3406 , 0.3386 , 0.3367 , 0.3335 , 0.3284 , 0.3274 ,\n",
       "            0.325  , 0.3228 , 0.3208 , 0.3193 , 0.3174 , 0.3145 , 0.3108 ,\n",
       "            0.3086 , 0.3076 , 0.304  , 0.2998 , 0.2925 , 0.289  , 0.2874 ,\n",
       "            0.277  , 0.2666 , 0.2542 , 0.2534 , 0.2522 , 0.2156 , 0.2039 ,\n",
       "            0.178  , 0.1653 , 0.1356 , 0.1332 , 0.1313 , 0.1262 , 0.1242 ,\n",
       "            0.12317, 0.118  , 0.11694, 0.1122 , 0.1099 , 0.10724, 0.1052 ,\n",
       "            0.0977 , 0.0909 , 0.088  , 0.06744, 0.0312 , 0.02925, 0.01813],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.12711865, dtype=float32),\n",
       "    'tpr': array(0.97727275, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.18644068, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.10606061, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.15151516, 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.5681818 , 0.57575756, 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.6969697 , 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.75      ,\n",
       "            0.75757575, 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9873 , 0.981  , 0.9775 , 0.976  , 0.9756 , 0.9746 ,\n",
       "            0.9736 , 0.9727 , 0.967  , 0.964  , 0.9624 , 0.959  , 0.9575 ,\n",
       "            0.957  , 0.952  , 0.9473 , 0.9453 , 0.945  , 0.9443 , 0.941  ,\n",
       "            0.938  , 0.9365 , 0.9355 , 0.933  , 0.9316 , 0.93   , 0.9277 ,\n",
       "            0.9272 , 0.9253 , 0.924  , 0.9224 , 0.922  , 0.92   , 0.916  ,\n",
       "            0.899  , 0.8975 , 0.89   , 0.8896 , 0.8857 , 0.869  , 0.859  ,\n",
       "            0.8555 , 0.8496 , 0.8477 , 0.8447 , 0.84   , 0.8237 , 0.818  ,\n",
       "            0.8105 , 0.8027 , 0.7964 , 0.782  , 0.779  , 0.775  , 0.7686 ,\n",
       "            0.7544 , 0.7495 , 0.738  , 0.735  , 0.7334 , 0.7324 , 0.731  ,\n",
       "            0.7295 , 0.728  , 0.727  , 0.725  , 0.7227 , 0.721  , 0.72   ,\n",
       "            0.716  , 0.7144 , 0.712  , 0.709  , 0.708  , 0.7065 , 0.705  ,\n",
       "            0.7046 , 0.7    , 0.6997 , 0.698  , 0.6973 , 0.6953 , 0.695  ,\n",
       "            0.6943 , 0.693  , 0.6865 , 0.681  , 0.679  , 0.6772 , 0.673  ,\n",
       "            0.6704 , 0.6685 , 0.665  , 0.664  , 0.6616 , 0.658  , 0.6562 ,\n",
       "            0.652  , 0.65   , 0.6436 , 0.6426 , 0.6377 , 0.636  , 0.6357 ,\n",
       "            0.6353 , 0.6323 , 0.6255 , 0.6226 , 0.6216 , 0.607  , 0.603  ,\n",
       "            0.584  , 0.5835 , 0.5796 , 0.5776 , 0.576  , 0.5703 , 0.5674 ,\n",
       "            0.558  , 0.553  , 0.552  , 0.548  , 0.542  , 0.5405 , 0.5347 ,\n",
       "            0.534  , 0.5337 , 0.533  , 0.5264 , 0.525  , 0.52   , 0.509  ,\n",
       "            0.5063 , 0.4968 , 0.4912 , 0.4858 , 0.483  , 0.4802 , 0.48   ,\n",
       "            0.4717 , 0.471  , 0.4648 , 0.4622 , 0.4578 , 0.4553 , 0.454  ,\n",
       "            0.4514 , 0.4456 , 0.4436 , 0.4414 , 0.436  , 0.4358 , 0.4324 ,\n",
       "            0.43   , 0.4285 , 0.4272 , 0.4236 , 0.4224 , 0.42   , 0.4165 ,\n",
       "            0.4136 , 0.4126 , 0.4111 , 0.4087 , 0.4082 , 0.403  , 0.4014 ,\n",
       "            0.4006 , 0.3877 , 0.3848 , 0.381  , 0.3809 , 0.38   , 0.379  ,\n",
       "            0.3708 , 0.3694 , 0.368  , 0.3672 , 0.3652 , 0.3608 , 0.357  ,\n",
       "            0.3555 , 0.3516 , 0.3477 , 0.3474 , 0.3462 , 0.3442 , 0.344  ,\n",
       "            0.343  , 0.3403 , 0.3357 , 0.3313 , 0.3274 , 0.3264 , 0.3245 ,\n",
       "            0.3242 , 0.3228 , 0.322  , 0.3162 , 0.3157 , 0.3125 , 0.3047 ,\n",
       "            0.3    , 0.2988 , 0.2935 , 0.288  , 0.2798 , 0.2656 , 0.255  ,\n",
       "            0.2507 , 0.2129 , 0.2006 , 0.1763 , 0.1617 , 0.1313 , 0.1312 ,\n",
       "            0.1288 , 0.1222 , 0.1201 , 0.119  , 0.11395, 0.1136 , 0.1082 ,\n",
       "            0.1076 , 0.1058 , 0.1009 , 0.0957 , 0.0869 , 0.08405, 0.06396,\n",
       "            0.02887, 0.02744, 0.0164 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.13559322, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.59090906, 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.75      ,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8484849 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9897 , 0.9844 , 0.9814 , 0.98   , 0.9795 , 0.979  ,\n",
       "            0.978  , 0.9775 , 0.9727 , 0.9697 , 0.9688 , 0.9683 , 0.9653 ,\n",
       "            0.964  , 0.9634 , 0.9595 , 0.955  , 0.9546 , 0.953  , 0.9526 ,\n",
       "            0.9517 , 0.949  , 0.947  , 0.9453 , 0.9443 , 0.9424 , 0.9404 ,\n",
       "            0.939  , 0.937  , 0.9365 , 0.9346 , 0.934  , 0.932  , 0.931  ,\n",
       "            0.9307 , 0.926  , 0.9106 , 0.909  , 0.903  , 0.9014 , 0.899  ,\n",
       "            0.882  , 0.874  , 0.869  , 0.864  , 0.8633 , 0.8584 , 0.854  ,\n",
       "            0.838  , 0.8345 , 0.8257 , 0.818  , 0.815  , 0.7974 , 0.7944 ,\n",
       "            0.793  , 0.788  , 0.7705 , 0.768  , 0.7583 , 0.7534 , 0.753  ,\n",
       "            0.7515 , 0.7495 , 0.7485 , 0.746  , 0.745  , 0.742  , 0.7417 ,\n",
       "            0.741  , 0.7407 , 0.7363 , 0.736  , 0.735  , 0.7305 , 0.727  ,\n",
       "            0.7266 , 0.726  , 0.7246 , 0.7183 , 0.718  , 0.7173 , 0.7144 ,\n",
       "            0.7124 , 0.7114 , 0.711  , 0.706  , 0.701  , 0.7    , 0.699  ,\n",
       "            0.698  , 0.6943 , 0.6914 , 0.687  , 0.678  , 0.6772 , 0.675  ,\n",
       "            0.674  , 0.672  , 0.6685 , 0.6646 , 0.6597 , 0.6562 , 0.656  ,\n",
       "            0.655  , 0.651  , 0.6455 , 0.642  , 0.639  , 0.6235 , 0.6    ,\n",
       "            0.5996 , 0.5977 , 0.594  , 0.5903 , 0.59   , 0.5864 , 0.5767 ,\n",
       "            0.5645 , 0.562  , 0.558  , 0.5576 , 0.5547 , 0.5537 , 0.547  ,\n",
       "            0.5464 , 0.544  , 0.539  , 0.5356 , 0.528  , 0.524  , 0.5225 ,\n",
       "            0.5195 , 0.506  , 0.504  , 0.4973 , 0.4958 , 0.4937 , 0.4878 ,\n",
       "            0.4836 , 0.479  , 0.4768 , 0.4749 , 0.4746 , 0.465  , 0.4648 ,\n",
       "            0.4624 , 0.4565 , 0.4539 , 0.4495 , 0.443  , 0.4426 , 0.4407 ,\n",
       "            0.4397 , 0.436  , 0.434  , 0.4287 , 0.4277 , 0.4258 , 0.4233 ,\n",
       "            0.423  , 0.421  , 0.419  , 0.4167 , 0.4165 , 0.4119 , 0.4072 ,\n",
       "            0.4062 , 0.391  , 0.39   , 0.3887 , 0.3884 , 0.3865 , 0.3823 ,\n",
       "            0.3777 , 0.3757 , 0.3748 , 0.3738 , 0.3728 , 0.3655 , 0.3633 ,\n",
       "            0.3625 , 0.362  , 0.358  , 0.3538 , 0.3518 , 0.3503 , 0.35   ,\n",
       "            0.3474 , 0.3467 , 0.3433 , 0.3396 , 0.3354 , 0.3308 , 0.3296 ,\n",
       "            0.3293 , 0.3274 , 0.327  , 0.3257 , 0.3179 , 0.317  , 0.3125 ,\n",
       "            0.3064 , 0.3013 , 0.3    , 0.2927 , 0.2898 , 0.2832 , 0.2659 ,\n",
       "            0.2576 , 0.2505 , 0.2493 , 0.211  , 0.199  , 0.1741 , 0.1584 ,\n",
       "            0.1288 , 0.1278 , 0.126  , 0.1186 , 0.11633, 0.11536, 0.1105 ,\n",
       "            0.1103 , 0.1052 , 0.1045 , 0.10376, 0.0972 , 0.0933 , 0.0831 ,\n",
       "            0.0804 , 0.06097, 0.0267 , 0.02596, 0.01484], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.16949153, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.10606061, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.4848485 ,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.67424244,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.77272725, 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.9318182 , 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9917  , 0.9873  , 0.985   , 0.984   , 0.9834  ,\n",
       "            0.983   , 0.9824  , 0.982   , 0.9775  , 0.975   , 0.974   ,\n",
       "            0.9717  , 0.97    , 0.9697  , 0.9663  , 0.9624  , 0.962   ,\n",
       "            0.961   , 0.96    , 0.9595  , 0.957   , 0.955   , 0.9536  ,\n",
       "            0.9526  , 0.9507  , 0.949   , 0.948   , 0.9463  , 0.946   ,\n",
       "            0.944   , 0.942   , 0.9414  , 0.9404  , 0.9365  , 0.9224  ,\n",
       "            0.921   , 0.915   , 0.914   , 0.9116  , 0.894   , 0.8887  ,\n",
       "            0.8843  , 0.879   , 0.878   , 0.874   , 0.8696  , 0.852   ,\n",
       "            0.851   , 0.843   , 0.835   , 0.833   , 0.8125  , 0.811   ,\n",
       "            0.806   , 0.7886  , 0.786   , 0.777   , 0.773   , 0.772   ,\n",
       "            0.7715  , 0.77    , 0.7666  , 0.766   , 0.764   , 0.763   ,\n",
       "            0.76    , 0.7593  , 0.7583  , 0.755   , 0.7544  , 0.7505  ,\n",
       "            0.7485  , 0.746   , 0.7446  , 0.744   , 0.7437  , 0.7383  ,\n",
       "            0.7373  , 0.736   , 0.7354  , 0.733   , 0.7305  , 0.729   ,\n",
       "            0.7275  , 0.724   , 0.7207  , 0.7183  , 0.7173  , 0.712   ,\n",
       "            0.7114  , 0.7046  , 0.699   , 0.6978  , 0.6963  , 0.694   ,\n",
       "            0.6914  , 0.688   , 0.687   , 0.6772  , 0.6763  , 0.676   ,\n",
       "            0.6743  , 0.6733  , 0.6694  , 0.668   , 0.666   , 0.6562  ,\n",
       "            0.6475  , 0.64    , 0.6206  , 0.618   , 0.6143  , 0.6133  ,\n",
       "            0.609   , 0.6084  , 0.605   , 0.6006  , 0.5815  , 0.5776  ,\n",
       "            0.577   , 0.573   , 0.5713  , 0.5703  , 0.5635  , 0.5596  ,\n",
       "            0.557   , 0.5566  , 0.5547  , 0.5454  , 0.5425  , 0.541   ,\n",
       "            0.5376  , 0.537   , 0.519   , 0.5146  , 0.514   , 0.5127  ,\n",
       "            0.501   , 0.5005  , 0.494   , 0.4893  , 0.489   , 0.4863  ,\n",
       "            0.4812  , 0.4785  , 0.4736  , 0.4734  , 0.4722  , 0.4697  ,\n",
       "            0.4626  , 0.46    , 0.4578  , 0.4502  , 0.4497  , 0.4443  ,\n",
       "            0.441   , 0.4382  , 0.438   , 0.435   , 0.4348  , 0.4329  ,\n",
       "            0.432   , 0.431   , 0.43    , 0.427   , 0.4128  , 0.4114  ,\n",
       "            0.4055  , 0.402   , 0.4016  , 0.4001  , 0.3997  , 0.3992  ,\n",
       "            0.3909  , 0.3904  , 0.3901  , 0.388   , 0.3804  , 0.3787  ,\n",
       "            0.3772  , 0.3757  , 0.3748  , 0.3706  , 0.3694  , 0.3682  ,\n",
       "            0.3665  , 0.3628  , 0.362   , 0.3538  , 0.3513  , 0.35    ,\n",
       "            0.3496  , 0.3489  , 0.3418  , 0.341   , 0.3394  , 0.3315  ,\n",
       "            0.3313  , 0.329   , 0.328   , 0.3257  , 0.323   , 0.3179  ,\n",
       "            0.3079  , 0.3071  , 0.302   , 0.2974  , 0.2898  , 0.2852  ,\n",
       "            0.2651  , 0.2595  , 0.2494  , 0.2471  , 0.209   , 0.1968  ,\n",
       "            0.1718  , 0.1547  , 0.126   , 0.1238  , 0.12274 , 0.1144  ,\n",
       "            0.1124  , 0.11127 , 0.1069  , 0.10614 , 0.1025  , 0.10144 ,\n",
       "            0.1005  , 0.093   , 0.0906  , 0.0792  , 0.0764  , 0.0578  ,\n",
       "            0.02452 , 0.02448 , 0.013374], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1779661, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.06060606, 0.07575758, 0.08333334, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.5681818 , 0.57575756, 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.7878788 , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.82575756, 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 , 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.993   , 0.9893  , 0.9873  , 0.9863  , 0.986   ,\n",
       "            0.9854  , 0.985   , 0.981   , 0.978   , 0.9756  , 0.974   ,\n",
       "            0.973   , 0.9707  , 0.9673  , 0.966   , 0.965   , 0.964   ,\n",
       "            0.962   , 0.961   , 0.9585  , 0.958   , 0.9565  , 0.9546  ,\n",
       "            0.9536  , 0.952   , 0.951   , 0.95    , 0.9497  , 0.9478  ,\n",
       "            0.9473  , 0.9424  , 0.929   , 0.928   , 0.9233  , 0.9214  ,\n",
       "            0.9204  , 0.902   , 0.898   , 0.8926  , 0.888   , 0.8877  ,\n",
       "            0.883   , 0.879   , 0.862   , 0.861   , 0.8525  , 0.85    ,\n",
       "            0.844   , 0.8237  , 0.823   , 0.8228  , 0.822   , 0.8037  ,\n",
       "            0.7983  , 0.795   , 0.7935  , 0.7915  , 0.791   , 0.79    ,\n",
       "            0.789   , 0.7866  , 0.7837  , 0.781   , 0.7773  , 0.7744  ,\n",
       "            0.7734  , 0.7715  , 0.766   , 0.764   , 0.7627  , 0.762   ,\n",
       "            0.761   , 0.76    , 0.7563  , 0.7534  , 0.753   , 0.751   ,\n",
       "            0.7485  , 0.7466  , 0.742   , 0.7407  , 0.7397  , 0.739   ,\n",
       "            0.7383  , 0.7354  , 0.735   , 0.7344  , 0.7324  , 0.723   ,\n",
       "            0.722   , 0.7124  , 0.7104  , 0.7056  , 0.7036  , 0.6978  ,\n",
       "            0.697   , 0.6924  , 0.692   , 0.6885  , 0.6875  , 0.67    ,\n",
       "            0.6685  , 0.6567  , 0.642   , 0.6353  , 0.6343  , 0.6304  ,\n",
       "            0.6284  , 0.622   , 0.6177  , 0.603   , 0.5884  , 0.585   ,\n",
       "            0.579   , 0.576   , 0.5737  , 0.5723  , 0.567   , 0.5654  ,\n",
       "            0.56    , 0.5566  , 0.552   , 0.55    , 0.541   , 0.529   ,\n",
       "            0.528   , 0.527   , 0.5234  , 0.521   , 0.5137  , 0.5083  ,\n",
       "            0.5015  , 0.4983  , 0.4927  , 0.491   , 0.49    , 0.4858  ,\n",
       "            0.4856  , 0.4807  , 0.477   , 0.4753  , 0.4722  , 0.4695  ,\n",
       "            0.4683  , 0.4573  , 0.452   , 0.4504  , 0.4475  , 0.446   ,\n",
       "            0.4443  , 0.4429  , 0.4392  , 0.4382  , 0.4375  , 0.4368  ,\n",
       "            0.436   , 0.4336  , 0.4272  , 0.4153  , 0.414   , 0.413   ,\n",
       "            0.4092  , 0.4084  , 0.4062  , 0.4023  , 0.3997  , 0.3965  ,\n",
       "            0.3962  , 0.3958  , 0.3867  , 0.3843  , 0.381   , 0.3806  ,\n",
       "            0.3774  , 0.376   , 0.3745  , 0.3723  , 0.3718  , 0.3684  ,\n",
       "            0.3665  , 0.3538  , 0.3518  , 0.3506  , 0.35    , 0.3496  ,\n",
       "            0.3455  , 0.3452  , 0.343   , 0.3357  , 0.3315  , 0.3298  ,\n",
       "            0.3286  , 0.3252  , 0.3184  , 0.3105  , 0.3066  , 0.3054  ,\n",
       "            0.3005  , 0.29    , 0.2888  , 0.2869  , 0.263   , 0.258   ,\n",
       "            0.247   , 0.243   , 0.2048  , 0.1927  , 0.1696  , 0.1506  ,\n",
       "            0.1239  , 0.1198  , 0.1193  , 0.1101  , 0.108   , 0.10706 ,\n",
       "            0.1036  , 0.1019  , 0.10034 , 0.1     , 0.0962  , 0.0887  ,\n",
       "            0.075   , 0.0724  , 0.0544  , 0.02298 , 0.02254 , 0.012054],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.22033899, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.06060606, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.10606061, 0.11363637, 0.12121212, 0.12878788, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.50757575, 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9946 , 0.9917 , 0.9897 , 0.9893 , 0.989  , 0.9883 ,\n",
       "            0.988  , 0.9844 , 0.9824 , 0.982  , 0.98   , 0.9785 , 0.978  ,\n",
       "            0.976  , 0.973  , 0.972  , 0.9717 , 0.9707 , 0.97   , 0.9688 ,\n",
       "            0.968  , 0.966  , 0.9653 , 0.9634 , 0.9624 , 0.9614 , 0.96   ,\n",
       "            0.9595 , 0.9585 , 0.958  , 0.956  , 0.9556 , 0.955  , 0.9517 ,\n",
       "            0.94   , 0.9385 , 0.9336 , 0.9326 , 0.9316 , 0.9136 , 0.911  ,\n",
       "            0.9062 , 0.902  , 0.9014 , 0.8975 , 0.8936 , 0.878  , 0.875  ,\n",
       "            0.869  , 0.8657 , 0.862  , 0.841  , 0.8374 , 0.821  , 0.818  ,\n",
       "            0.8135 , 0.8125 , 0.8115 , 0.81   , 0.8086 , 0.8076 , 0.807  ,\n",
       "            0.8057 , 0.8027 , 0.8013 , 0.795  , 0.7944 , 0.794  , 0.7935 ,\n",
       "            0.7915 , 0.791  , 0.785  , 0.783  , 0.7817 , 0.78   , 0.7793 ,\n",
       "            0.779  , 0.7783 , 0.774  , 0.7705 , 0.77   , 0.7686 , 0.768  ,\n",
       "            0.7656 , 0.764  , 0.7607 , 0.7603 , 0.759  , 0.7573 , 0.757  ,\n",
       "            0.7563 , 0.753  , 0.7524 , 0.752  , 0.7476 , 0.7397 , 0.7334 ,\n",
       "            0.7314 , 0.727  , 0.7236 , 0.72   , 0.719  , 0.7183 , 0.712  ,\n",
       "            0.711  , 0.71   , 0.7075 , 0.7065 , 0.694  , 0.686  , 0.674  ,\n",
       "            0.666  , 0.6597 , 0.6543 , 0.653  , 0.647  , 0.6445 , 0.6377 ,\n",
       "            0.6333 , 0.628  , 0.6035 , 0.603  , 0.6025 , 0.602  , 0.5986 ,\n",
       "            0.593  , 0.592  , 0.583  , 0.577  , 0.5767 , 0.5728 , 0.5713 ,\n",
       "            0.564  , 0.562  , 0.5615 , 0.5513 , 0.5493 , 0.5415 , 0.54   ,\n",
       "            0.538  , 0.5327 , 0.529  , 0.52   , 0.515  , 0.511  , 0.509  ,\n",
       "            0.505  , 0.4998 , 0.499  , 0.4915 , 0.49   , 0.4888 , 0.4846 ,\n",
       "            0.4841 , 0.4736 , 0.4685 , 0.465  , 0.4624 , 0.4617 , 0.4612 ,\n",
       "            0.4597 , 0.4563 , 0.4543 , 0.4539 , 0.4531 , 0.4504 , 0.446  ,\n",
       "            0.4446 , 0.4338 , 0.4258 , 0.4248 , 0.4224 , 0.4207 , 0.4197 ,\n",
       "            0.4177 , 0.4163 , 0.4143 , 0.4124 , 0.4094 , 0.399  , 0.3965 ,\n",
       "            0.3962 , 0.3926 , 0.3916 , 0.3884 , 0.388  , 0.384  , 0.3823 ,\n",
       "            0.381  , 0.3804 , 0.3767 , 0.366  , 0.3623 , 0.36   , 0.3599 ,\n",
       "            0.3547 , 0.354  , 0.3481 , 0.3398 , 0.3372 , 0.3352 , 0.333  ,\n",
       "            0.3318 , 0.3296 , 0.322  , 0.318  , 0.3074 , 0.3027 , 0.3003 ,\n",
       "            0.29   , 0.2888 , 0.2634 , 0.263  , 0.2471 , 0.2424 , 0.2042 ,\n",
       "            0.1924 , 0.1672 , 0.1473 , 0.121  , 0.11694, 0.11597, 0.1067 ,\n",
       "            0.10486, 0.1036 , 0.10034, 0.0986 , 0.0974 , 0.0972 , 0.093  ,\n",
       "            0.0857 , 0.0854 , 0.07196, 0.0693 , 0.05203, 0.02187, 0.02077,\n",
       "            0.01086], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.26271185, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.04545455,\n",
       "            0.06060606, 0.07575758, 0.08333334, 0.09090909, 0.10606061,\n",
       "            0.11363637, 0.12878788, 0.13636364, 0.15151516, 0.1590909 ,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.24242425, 0.25757575,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.5378788 , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.996  , 0.9937 , 0.9927 , 0.9917 , 0.991  , 0.9907 ,\n",
       "            0.9883 , 0.9863 , 0.986  , 0.9844 , 0.9834 , 0.981  , 0.9785 ,\n",
       "            0.9775 , 0.977  , 0.975  , 0.974  , 0.973  , 0.972  , 0.97   ,\n",
       "            0.969  , 0.9688 , 0.968  , 0.9663 , 0.9644 , 0.9634 , 0.961  ,\n",
       "            0.9507 , 0.9497 , 0.945  , 0.9434 , 0.9253 , 0.924  , 0.9214 ,\n",
       "            0.9175 , 0.914  , 0.9136 , 0.9097 , 0.895  , 0.8877 , 0.887  ,\n",
       "            0.8813 , 0.88   , 0.8613 , 0.861  , 0.8564 , 0.8516 , 0.841  ,\n",
       "            0.837  , 0.832  , 0.83   , 0.8296 , 0.8286 , 0.825  , 0.824  ,\n",
       "            0.8237 , 0.8228 , 0.821  , 0.8184 , 0.8154 , 0.814  , 0.8105 ,\n",
       "            0.8076 , 0.8022 , 0.8    , 0.799  , 0.7974 , 0.7964 , 0.7954 ,\n",
       "            0.795  , 0.7905 , 0.7886 , 0.787  , 0.7866 , 0.7856 , 0.7827 ,\n",
       "            0.7812 , 0.7803 , 0.7783 , 0.7764 , 0.7744 , 0.7734 , 0.772  ,\n",
       "            0.771  , 0.769  , 0.7563 , 0.756  , 0.753  , 0.751  , 0.7495 ,\n",
       "            0.7417 , 0.7397 , 0.739  , 0.7354 , 0.731  , 0.729  , 0.7246 ,\n",
       "            0.7236 , 0.718  , 0.7046 , 0.6904 , 0.69   , 0.6846 , 0.6787 ,\n",
       "            0.673  , 0.6724 , 0.6606 , 0.654  , 0.6533 , 0.649  , 0.6343 ,\n",
       "            0.6294 , 0.624  , 0.622  , 0.6167 , 0.615  , 0.613  , 0.599  ,\n",
       "            0.598  , 0.593  , 0.5923 , 0.5884 , 0.5854 , 0.579  , 0.5723 ,\n",
       "            0.5713 , 0.5674 , 0.5605 , 0.5537 , 0.551  , 0.545  , 0.5337 ,\n",
       "            0.533  , 0.5317 , 0.5293 , 0.526  , 0.519  , 0.513  , 0.5107 ,\n",
       "            0.508  , 0.5044 , 0.501  , 0.4927 , 0.4924 , 0.4902 , 0.4885 ,\n",
       "            0.4854 , 0.4824 , 0.4788 , 0.476  , 0.4756 , 0.474  , 0.4724 ,\n",
       "            0.472  , 0.471  , 0.4697 , 0.455  , 0.4539 , 0.4446 , 0.4436 ,\n",
       "            0.4412 , 0.4385 , 0.4348 , 0.434  , 0.4307 , 0.4302 , 0.4263 ,\n",
       "            0.426  , 0.4211 , 0.4148 , 0.4146 , 0.4102 , 0.4067 , 0.4026 ,\n",
       "            0.4023 , 0.3997 , 0.399  , 0.3945 , 0.3877 , 0.3865 , 0.3833 ,\n",
       "            0.3809 , 0.3796 , 0.378  , 0.3772 , 0.365  , 0.3582 , 0.3572 ,\n",
       "            0.3535 , 0.3528 , 0.3464 , 0.345  , 0.3408 , 0.3386 , 0.336  ,\n",
       "            0.3347 , 0.3342 , 0.3174 , 0.309  , 0.3044 , 0.291  , 0.2908 ,\n",
       "            0.2666 , 0.2637 , 0.247  , 0.241  , 0.2029 , 0.191  , 0.1653 ,\n",
       "            0.1444 , 0.119  , 0.1142 , 0.1128 , 0.1034 , 0.10144, 0.10034,\n",
       "            0.0974 , 0.096  , 0.0955 , 0.09534, 0.0896 , 0.08386, 0.0821 ,\n",
       "            0.06866, 0.0661 , 0.0495 , 0.02072, 0.01912, 0.00982],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.29661018, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.4915254 , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.04545455,\n",
       "            0.06060606, 0.07575758, 0.08333334, 0.09090909, 0.10606061,\n",
       "            0.11363637, 0.12878788, 0.13636364, 0.15151516, 0.1590909 ,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.23484848, 0.24242425, 0.25757575,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.7348485 , 0.75      , 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.997  , 0.995  , 0.994  , 0.9937 , 0.993  , 0.9927 ,\n",
       "            0.99   , 0.9893 , 0.989  , 0.9873 , 0.9863 , 0.9844 , 0.9824 ,\n",
       "            0.9814 , 0.981  , 0.9795 , 0.9785 , 0.9775 , 0.977  , 0.975  ,\n",
       "            0.974  , 0.9736 , 0.973  , 0.972  , 0.97   , 0.969  , 0.9673 ,\n",
       "            0.9585 , 0.9575 , 0.953  , 0.9517 , 0.9507 , 0.9355 , 0.932  ,\n",
       "            0.931  , 0.928  , 0.925  , 0.924  , 0.921  , 0.908  , 0.901  ,\n",
       "            0.897  , 0.8955 , 0.894  , 0.8765 , 0.876  , 0.8716 , 0.863  ,\n",
       "            0.857  , 0.8525 , 0.849  , 0.847  , 0.845  , 0.842  , 0.841  ,\n",
       "            0.8403 , 0.8394 , 0.839  , 0.8374 , 0.836  , 0.8335 , 0.832  ,\n",
       "            0.8276 , 0.827  , 0.8247 , 0.82   , 0.8164 , 0.816  , 0.8154 ,\n",
       "            0.8135 , 0.812  , 0.811  , 0.808  , 0.807  , 0.8037 , 0.803  ,\n",
       "            0.8027 , 0.8    , 0.7983 , 0.7974 , 0.796  , 0.793  , 0.792  ,\n",
       "            0.791  , 0.7905 , 0.787  , 0.786  , 0.777  , 0.7754 , 0.774  ,\n",
       "            0.7725 , 0.771  , 0.768  , 0.76   , 0.7593 , 0.759  , 0.756  ,\n",
       "            0.7515 , 0.748  , 0.7476 , 0.7437 , 0.7393 , 0.721  , 0.7114 ,\n",
       "            0.707  , 0.706  , 0.7    , 0.694  , 0.6934 , 0.679  , 0.676  ,\n",
       "            0.6694 , 0.6646 , 0.656  , 0.6504 , 0.644  , 0.6387 , 0.6343 ,\n",
       "            0.6304 , 0.63   , 0.6157 , 0.6143 , 0.6123 , 0.6094 , 0.602  ,\n",
       "            0.5986 , 0.596  , 0.594  , 0.589  , 0.5874 , 0.5815 , 0.5767 ,\n",
       "            0.571  , 0.5693 , 0.5645 , 0.564  , 0.5513 , 0.5493 , 0.548  ,\n",
       "            0.546  , 0.543  , 0.5356 , 0.53   , 0.5273 , 0.5195 , 0.515  ,\n",
       "            0.51   , 0.5073 , 0.507  , 0.5044 , 0.501  , 0.5    , 0.4978 ,\n",
       "            0.4937 , 0.4924 , 0.4905 , 0.4895 , 0.4873 , 0.4866 , 0.4768 ,\n",
       "            0.471  , 0.4602 , 0.459  , 0.4578 , 0.455  , 0.4539 , 0.45   ,\n",
       "            0.4465 , 0.4443 , 0.444  , 0.435  , 0.432  , 0.4316 , 0.428  ,\n",
       "            0.4233 , 0.4202 , 0.4158 , 0.4155 , 0.4114 , 0.4075 , 0.3992 ,\n",
       "            0.3955 , 0.3953 , 0.3904 , 0.3894 , 0.3853 , 0.3691 , 0.3638 ,\n",
       "            0.362  , 0.3604 , 0.3584 , 0.356  , 0.351  , 0.3506 , 0.3438 ,\n",
       "            0.3418 , 0.339  , 0.3376 , 0.3267 , 0.3108 , 0.306  , 0.2942 ,\n",
       "            0.2917 , 0.2686 , 0.2642 , 0.2471 , 0.2391 , 0.2012 , 0.1892 ,\n",
       "            0.1641 , 0.1423 , 0.1178 , 0.1122 , 0.1099 , 0.1007 , 0.0986 ,\n",
       "            0.09753, 0.0957 , 0.09515, 0.09436, 0.0925 , 0.0868 , 0.0828 ,\n",
       "            0.0789 , 0.06586, 0.0631 , 0.0471 , 0.01964, 0.01778, 0.00895],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.37288135, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.04545455,\n",
       "            0.06818182, 0.07575758, 0.08333334, 0.09090909, 0.10606061,\n",
       "            0.11363637, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.23484848, 0.25757575,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.50757575, 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.70454544,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75757575, 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.998  , 0.996  , 0.9956 , 0.995  , 0.9946 , 0.994  ,\n",
       "            0.992  , 0.991  , 0.9907 , 0.9897 , 0.9893 , 0.9873 , 0.986  ,\n",
       "            0.9854 , 0.985  , 0.9844 , 0.9834 , 0.9824 , 0.982  , 0.981  ,\n",
       "            0.9795 , 0.9785 , 0.978  , 0.9766 , 0.9756 , 0.9736 , 0.973  ,\n",
       "            0.9653 , 0.964  , 0.961  , 0.959  , 0.957  , 0.945  , 0.942  ,\n",
       "            0.9385 , 0.938  , 0.9355 , 0.932  , 0.9316 , 0.9194 , 0.913  ,\n",
       "            0.9087 , 0.9062 , 0.9053 , 0.8906 , 0.888  , 0.8853 , 0.873  ,\n",
       "            0.8726 , 0.8667 , 0.866  , 0.865  , 0.8633 , 0.86   , 0.857  ,\n",
       "            0.856  , 0.8555 , 0.855  , 0.8545 , 0.8535 , 0.8525 , 0.852  ,\n",
       "            0.8486 , 0.8433 , 0.8423 , 0.8403 , 0.8354 , 0.832  , 0.8315 ,\n",
       "            0.8286 , 0.827  , 0.8267 , 0.8237 , 0.819  , 0.8184 , 0.818  ,\n",
       "            0.8164 , 0.816  , 0.814  , 0.8115 , 0.808  , 0.8066 , 0.8022 ,\n",
       "            0.802  , 0.7983 , 0.797  , 0.793  , 0.7925 , 0.7896 , 0.7847 ,\n",
       "            0.779  , 0.7783 , 0.7773 , 0.776  , 0.771  , 0.7656 , 0.765  ,\n",
       "            0.7627 , 0.761  , 0.7563 , 0.737  , 0.735  , 0.73   , 0.724  ,\n",
       "            0.7236 , 0.7183 , 0.7134 , 0.7007 , 0.6973 , 0.685  , 0.68   ,\n",
       "            0.6797 , 0.6743 , 0.668  , 0.6577 , 0.655  , 0.651  , 0.6426 ,\n",
       "            0.6387 , 0.6377 , 0.6304 , 0.623  , 0.6123 , 0.6113 , 0.6094 ,\n",
       "            0.605  , 0.5977 , 0.596  , 0.5923 , 0.59   , 0.5864 , 0.5786 ,\n",
       "            0.573  , 0.569  , 0.568  , 0.5664 , 0.5645 , 0.556  , 0.5522 ,\n",
       "            0.55   , 0.5386 , 0.5293 , 0.5254 , 0.525  , 0.5225 , 0.5215 ,\n",
       "            0.5166 , 0.516  , 0.513  , 0.5127 , 0.5103 , 0.508  , 0.5073 ,\n",
       "            0.5054 , 0.505  , 0.4932 , 0.4824 , 0.4785 , 0.477  , 0.4756 ,\n",
       "            0.474  , 0.4717 , 0.4648 , 0.4631 , 0.4617 , 0.453  , 0.447  ,\n",
       "            0.4465 , 0.4421 , 0.4392 , 0.437  , 0.4355 , 0.4348 , 0.4292 ,\n",
       "            0.4165 , 0.413  , 0.4087 , 0.407  , 0.4058 , 0.405  , 0.4019 ,\n",
       "            0.393  , 0.3896 , 0.3792 , 0.3716 , 0.3706 , 0.366  , 0.3655 ,\n",
       "            0.364  , 0.362  , 0.359  , 0.3572 , 0.3435 , 0.3408 , 0.3406 ,\n",
       "            0.3403 , 0.312  , 0.3064 , 0.297  , 0.2925 , 0.2683 , 0.264  ,\n",
       "            0.2463 , 0.2367 , 0.1981 , 0.1858 , 0.1622 , 0.1396 , 0.11633,\n",
       "            0.1097 , 0.1065 , 0.0977 , 0.09503, 0.09485, 0.0942 , 0.0927 ,\n",
       "            0.0922 , 0.0891 , 0.083  , 0.08136, 0.0752 , 0.06232, 0.05975,\n",
       "            0.0442 , 0.01826, 0.01634, 0.008  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.38135594, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.29661018, 0.31355932,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.34745762, 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.06060606,\n",
       "            0.06818182, 0.07575758, 0.08333334, 0.09090909, 0.10606061,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.5       , 0.50757575, 0.52272725, 0.530303  ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9985  , 0.997   , 0.9966  , 0.996   , 0.9956  ,\n",
       "            0.995   , 0.994   , 0.993   , 0.9927  , 0.9917  , 0.99    ,\n",
       "            0.989   , 0.9883  , 0.988   , 0.987   , 0.986   , 0.9854  ,\n",
       "            0.985   , 0.9834  , 0.983   , 0.9824  , 0.982   , 0.9814  ,\n",
       "            0.981   , 0.9805  , 0.98    , 0.9785  , 0.978   , 0.971   ,\n",
       "            0.97    , 0.968   , 0.966   , 0.964   , 0.953   , 0.9507  ,\n",
       "            0.9478  , 0.9463  , 0.9453  , 0.942   , 0.931   , 0.9253  ,\n",
       "            0.9214  , 0.9175  , 0.916   , 0.905   , 0.9023  , 0.898   ,\n",
       "            0.889   , 0.8857  , 0.8804  , 0.88    , 0.8794  , 0.877   ,\n",
       "            0.8735  , 0.871   , 0.8706  , 0.8696  , 0.869   , 0.8687  ,\n",
       "            0.8667  , 0.8657  , 0.8574  , 0.8564  , 0.8545  , 0.8496  ,\n",
       "            0.8467  , 0.846   , 0.8457  , 0.8433  , 0.842   , 0.841   ,\n",
       "            0.8384  , 0.8335  , 0.833   , 0.8325  , 0.8306  , 0.829   ,\n",
       "            0.8276  , 0.8267  , 0.823   , 0.8223  , 0.82    , 0.8174  ,\n",
       "            0.817   , 0.816   , 0.8145  , 0.813   , 0.8125  , 0.8047  ,\n",
       "            0.8     , 0.796   , 0.7954  , 0.794   , 0.7915  , 0.7886  ,\n",
       "            0.782   , 0.7817  , 0.7803  , 0.778   , 0.772   , 0.7554  ,\n",
       "            0.7534  , 0.7485  , 0.743   , 0.7397  , 0.7373  , 0.732   ,\n",
       "            0.7207  , 0.7153  , 0.705   , 0.7017  , 0.6987  , 0.696   ,\n",
       "            0.6875  , 0.676   , 0.6743  , 0.668   , 0.6636  , 0.658   ,\n",
       "            0.6577  , 0.652   , 0.6475  , 0.642   , 0.633   , 0.63    ,\n",
       "            0.629   , 0.6226  , 0.621   , 0.619   , 0.6133  , 0.61    ,\n",
       "            0.6094  , 0.6045  , 0.5977  , 0.5933  , 0.586   , 0.585   ,\n",
       "            0.5835  , 0.5815  , 0.573   , 0.5693  , 0.567   , 0.558   ,\n",
       "            0.5513  , 0.5425  , 0.5415  , 0.538   , 0.5356  , 0.534   ,\n",
       "            0.5327  , 0.53    , 0.5293  , 0.527   , 0.5215  , 0.5195  ,\n",
       "            0.51    , 0.495   , 0.4944  , 0.493   , 0.492   , 0.49    ,\n",
       "            0.4878  , 0.4802  , 0.4788  , 0.4785  , 0.4756  , 0.4722  ,\n",
       "            0.4624  , 0.462   , 0.4575  , 0.4546  , 0.4502  , 0.45    ,\n",
       "            0.4475  , 0.445   , 0.444   , 0.4277  , 0.4258  , 0.4233  ,\n",
       "            0.4214  , 0.4194  , 0.4143  , 0.4136  , 0.4011  , 0.3967  ,\n",
       "            0.392   , 0.3828  , 0.3804  , 0.379   , 0.3726  , 0.3718  ,\n",
       "            0.3713  , 0.3691  , 0.3645  , 0.352   , 0.3496  , 0.3467  ,\n",
       "            0.3464  , 0.3167  , 0.3115  , 0.3013  , 0.296   , 0.2764  ,\n",
       "            0.2673  , 0.249   , 0.2382  , 0.1993  , 0.1874  , 0.1615  ,\n",
       "            0.1385  , 0.11475 , 0.108   , 0.1047  , 0.0962  , 0.0937  ,\n",
       "            0.0933  , 0.0922  , 0.09125 , 0.0904  , 0.0874  , 0.08105 ,\n",
       "            0.0799  , 0.0732  , 0.06042 , 0.0578  , 0.04272 , 0.01772 ,\n",
       "            0.01525 , 0.007317], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.47457626, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.33050847,\n",
       "            0.33898306, 0.3559322 , 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03787879, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09848485, 0.10606061, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.17424242, 0.18181819, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.4469697 , 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.999  , 0.998  , 0.9976 , 0.997  , 0.9966 , 0.9956 ,\n",
       "            0.995  , 0.9946 , 0.994  , 0.9937 , 0.9927 , 0.992  , 0.9917 ,\n",
       "            0.991  , 0.9907 , 0.99   , 0.9897 , 0.989  , 0.9883 , 0.9873 ,\n",
       "            0.987  , 0.9863 , 0.986  , 0.9854 , 0.985  , 0.984  , 0.9834 ,\n",
       "            0.9785 , 0.9775 , 0.976  , 0.9736 , 0.971  , 0.963  , 0.962  ,\n",
       "            0.96   , 0.958  , 0.9556 , 0.954  , 0.952  , 0.9443 , 0.9404 ,\n",
       "            0.9385 , 0.929  , 0.9277 , 0.9233 , 0.9185 , 0.911  , 0.9097 ,\n",
       "            0.9014 , 0.897  , 0.895  , 0.8926 , 0.89   , 0.8877 , 0.8867 ,\n",
       "            0.8843 , 0.884  , 0.883  , 0.8823 , 0.882  , 0.8804 , 0.8716 ,\n",
       "            0.87   , 0.8687 , 0.8643 , 0.861  , 0.8604 , 0.86   , 0.8574 ,\n",
       "            0.857  , 0.8555 , 0.855  , 0.854  , 0.8535 , 0.853  , 0.8496 ,\n",
       "            0.848  , 0.8477 , 0.847  , 0.845  , 0.8438 , 0.842  , 0.841  ,\n",
       "            0.8384 , 0.8374 , 0.833  , 0.832  , 0.8315 , 0.82   , 0.819  ,\n",
       "            0.8154 , 0.812  , 0.8105 , 0.8066 , 0.806  , 0.8057 , 0.7993 ,\n",
       "            0.798  , 0.795  , 0.7866 , 0.78   , 0.779  , 0.7754 , 0.7695 ,\n",
       "            0.7656 , 0.757  , 0.7515 , 0.75   , 0.748  , 0.735  , 0.721  ,\n",
       "            0.719  , 0.715  , 0.711  , 0.7026 , 0.6997 , 0.696  , 0.691  ,\n",
       "            0.689  , 0.6807 , 0.677  , 0.6763 , 0.6675 , 0.6655 , 0.659  ,\n",
       "            0.658  , 0.6577 , 0.644  , 0.6426 , 0.642  , 0.6416 , 0.638  ,\n",
       "            0.6245 , 0.6187 , 0.6167 , 0.616  , 0.6157 , 0.6143 , 0.6064 ,\n",
       "            0.6055 , 0.603  , 0.597  , 0.5913 , 0.5903 , 0.581  , 0.5767 ,\n",
       "            0.5757 , 0.5737 , 0.5635 , 0.5615 , 0.5557 , 0.555  , 0.5493 ,\n",
       "            0.549  , 0.536  , 0.5337 , 0.5317 , 0.5312 , 0.53   , 0.5293 ,\n",
       "            0.5283 , 0.5264 , 0.516  , 0.515  , 0.5146 , 0.5005 , 0.4993 ,\n",
       "            0.4956 , 0.4934 , 0.4917 , 0.4888 , 0.4885 , 0.4814 , 0.4656 ,\n",
       "            0.4624 , 0.4622 , 0.4597 , 0.4595 , 0.4348 , 0.432  , 0.431  ,\n",
       "            0.4297 , 0.4265 , 0.423  , 0.4136 , 0.4114 , 0.4058 , 0.4006 ,\n",
       "            0.3943 , 0.3816 , 0.3806 , 0.3804 , 0.3716 , 0.3586 , 0.355  ,\n",
       "            0.3547 , 0.3245 , 0.3196 , 0.306  , 0.3008 , 0.2886 , 0.2727 ,\n",
       "            0.2527 , 0.2418 , 0.2029 , 0.1923 , 0.161  , 0.1382 , 0.1134 ,\n",
       "            0.1065 , 0.10376, 0.09534, 0.0922 , 0.0909 , 0.0895 , 0.089  ,\n",
       "            0.086  , 0.0798 , 0.07825, 0.0721 , 0.0591 , 0.05655, 0.04163,\n",
       "            0.01724, 0.01423, 0.00669], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5338983, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3644068 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.06818182, 0.07575758,\n",
       "            0.09090909, 0.10606061, 0.11363637, 0.12878788, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.2651515 , 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.6969697 , 0.70454544, 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.9985  , 0.998   , 0.9976  , 0.9966  ,\n",
       "            0.996   , 0.9956  , 0.995   , 0.994   , 0.9937  , 0.993   ,\n",
       "            0.9927  , 0.992   , 0.9917  , 0.991   , 0.9907  , 0.9897  ,\n",
       "            0.9893  , 0.989   , 0.9883  , 0.9873  , 0.987   , 0.983   ,\n",
       "            0.982   , 0.981   , 0.9785  , 0.9756  , 0.969   , 0.9688  ,\n",
       "            0.9673  , 0.966   , 0.962   , 0.9614  , 0.959   , 0.953   ,\n",
       "            0.95    , 0.949   , 0.9375  , 0.936   , 0.9355  , 0.9287  ,\n",
       "            0.9253  , 0.9194  , 0.913   , 0.912   , 0.9087  , 0.906   ,\n",
       "            0.9033  , 0.902   , 0.9014  , 0.9004  , 0.898   , 0.895   ,\n",
       "            0.8945  , 0.894   , 0.8936  , 0.892   , 0.8833  , 0.882   ,\n",
       "            0.8804  , 0.88    , 0.8765  , 0.876   , 0.8735  , 0.873   ,\n",
       "            0.8716  , 0.871   , 0.869   , 0.867   , 0.8667  , 0.8657  ,\n",
       "            0.864   , 0.8633  , 0.861   , 0.86    , 0.858   , 0.8564  ,\n",
       "            0.855   , 0.8516  , 0.8506  , 0.8496  , 0.845   , 0.8447  ,\n",
       "            0.8384  , 0.833   , 0.8286  , 0.8267  , 0.825   , 0.821   ,\n",
       "            0.8203  , 0.814   , 0.8115  , 0.8096  , 0.802   , 0.801   ,\n",
       "            0.7983  , 0.7974  , 0.792   , 0.7896  , 0.7876  , 0.7783  ,\n",
       "            0.7754  , 0.772   , 0.769   , 0.7524  , 0.7515  , 0.738   ,\n",
       "            0.735   , 0.731   , 0.7266  , 0.722   , 0.7207  , 0.72    ,\n",
       "            0.7188  , 0.711   , 0.7007  , 0.6953  , 0.6943  , 0.6914  ,\n",
       "            0.6904  , 0.69    , 0.6865  , 0.667   , 0.666   , 0.6626  ,\n",
       "            0.661   , 0.653   , 0.6523  , 0.6445  , 0.6436  , 0.643   ,\n",
       "            0.639   , 0.634   , 0.633   , 0.6313  , 0.627   , 0.6265  ,\n",
       "            0.6245  , 0.623   , 0.611   , 0.6045  , 0.601   , 0.592   ,\n",
       "            0.59    , 0.589   , 0.582   , 0.5815  , 0.579   , 0.572   ,\n",
       "            0.567   , 0.565   , 0.5625  , 0.559   , 0.5586  , 0.557   ,\n",
       "            0.554   , 0.55    , 0.5435  , 0.543   , 0.5293  , 0.529   ,\n",
       "            0.5273  , 0.5244  , 0.523   , 0.518   , 0.5093  , 0.5034  ,\n",
       "            0.494   , 0.492   , 0.4888  , 0.474   , 0.4705  , 0.465   ,\n",
       "            0.4612  , 0.4587  , 0.4487  , 0.4443  , 0.441   , 0.4373  ,\n",
       "            0.4346  , 0.4233  , 0.417   , 0.4048  , 0.3916  , 0.391   ,\n",
       "            0.3896  , 0.3833  , 0.3667  , 0.363   , 0.3628  , 0.3315  ,\n",
       "            0.3267  , 0.314   , 0.3071  , 0.2974  , 0.2778  , 0.2563  ,\n",
       "            0.2452  , 0.206   , 0.1958  , 0.1635  , 0.1393  , 0.1152  ,\n",
       "            0.10706 , 0.1036  , 0.09534 , 0.09436 , 0.09186 , 0.0909  ,\n",
       "            0.09076 , 0.089   , 0.0854  , 0.0792  , 0.07904 , 0.0712  ,\n",
       "            0.05814 , 0.0556  , 0.04092 , 0.01692 , 0.01363 , 0.006313],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.60169494, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.27966103, 0.2881356 , 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.4915254 , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5423729 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.06818182, 0.07575758,\n",
       "            0.09090909, 0.11363637, 0.12878788, 0.14393939, 0.15151516,\n",
       "            0.18939394, 0.20454545, 0.21212122, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.5833333 , 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6666667 , 0.67424244, 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.999   , 0.9985  , 0.998   , 0.9976  ,\n",
       "            0.997   , 0.9966  , 0.996   , 0.9956  , 0.9946  , 0.9937  ,\n",
       "            0.993   , 0.9927  , 0.992   , 0.9917  , 0.991   , 0.99    ,\n",
       "            0.9897  , 0.9873  , 0.987   , 0.9863  , 0.983   , 0.9805  ,\n",
       "            0.9766  , 0.9756  , 0.975   , 0.9746  , 0.9707  , 0.9688  ,\n",
       "            0.967   , 0.9624  , 0.962   , 0.9614  , 0.9497  , 0.948   ,\n",
       "            0.943   , 0.9424  , 0.942   , 0.934   , 0.9272  , 0.9263  ,\n",
       "            0.92    , 0.9194  , 0.915   , 0.9116  , 0.911   , 0.9106  ,\n",
       "            0.91    , 0.9097  , 0.907   , 0.905   , 0.904   , 0.9033  ,\n",
       "            0.903   , 0.902   , 0.8936  , 0.891   , 0.8906  , 0.889   ,\n",
       "            0.887   , 0.8867  , 0.8843  , 0.8833  , 0.8813  , 0.8794  ,\n",
       "            0.877   , 0.8765  , 0.8745  , 0.872   , 0.8716  , 0.87    ,\n",
       "            0.8696  , 0.869   , 0.8677  , 0.866   , 0.864   , 0.863   ,\n",
       "            0.862   , 0.8564  , 0.856   , 0.8467  , 0.844   , 0.8403  ,\n",
       "            0.84    , 0.839   , 0.8384  , 0.8345  , 0.832   , 0.8276  ,\n",
       "            0.826   , 0.8237  , 0.8228  , 0.8223  , 0.8213  , 0.8174  ,\n",
       "            0.815   , 0.814   , 0.8096  , 0.802   , 0.7876  , 0.785   ,\n",
       "            0.7695  , 0.7666  , 0.762   , 0.7607  , 0.756   , 0.754   ,\n",
       "            0.7515  , 0.75    , 0.747   , 0.7466  , 0.744   , 0.742   ,\n",
       "            0.7305  , 0.7295  , 0.729   , 0.7163  , 0.711   , 0.703   ,\n",
       "            0.7     , 0.698   , 0.697   , 0.6904  , 0.6826  , 0.68    ,\n",
       "            0.679   , 0.6777  , 0.6733  , 0.672   , 0.67    , 0.6685  ,\n",
       "            0.6665  , 0.6445  , 0.6436  , 0.64    , 0.6396  , 0.638   ,\n",
       "            0.6353  , 0.633   , 0.628   , 0.6274  , 0.6245  , 0.621   ,\n",
       "            0.62    , 0.609   , 0.605   , 0.6016  , 0.601   , 0.599   ,\n",
       "            0.596   , 0.594   , 0.586   , 0.5854  , 0.5757  , 0.574   ,\n",
       "            0.572   , 0.57    , 0.5693  , 0.565   , 0.5586  , 0.554   ,\n",
       "            0.544   , 0.5405  , 0.5366  , 0.5293  , 0.525   , 0.515   ,\n",
       "            0.507   , 0.4983  , 0.4966  , 0.495   , 0.4714  , 0.4673  ,\n",
       "            0.4553  , 0.446   , 0.4365  , 0.4287  , 0.412   , 0.41    ,\n",
       "            0.4097  , 0.3994  , 0.3862  , 0.382   , 0.38    , 0.349   ,\n",
       "            0.3447  , 0.3276  , 0.3215  , 0.3176  , 0.2925  , 0.2693  ,\n",
       "            0.258   , 0.218   , 0.2079  , 0.1696  , 0.145   , 0.1188  ,\n",
       "            0.11066 , 0.1076  , 0.0991  , 0.0974  , 0.09534 , 0.09436 ,\n",
       "            0.0935  , 0.09186 , 0.0885  , 0.0818  , 0.08154 , 0.07385 ,\n",
       "            0.05997 , 0.05737 , 0.04208 , 0.01724 , 0.01359 , 0.006218],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.62711865, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.11016949, 0.11016949,\n",
       "            0.11016949, 0.11016949, 0.11016949, 0.11016949, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01515152, 0.06818182, 0.07575758, 0.09090909,\n",
       "            0.11363637, 0.13636364, 0.15151516, 0.18939394, 0.21212122,\n",
       "            0.22727273, 0.24242425, 0.25      , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3560606 , 0.36363637, 0.37121212, 0.37121212,\n",
       "            0.37878788, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.45454547, 0.46212122, 0.46969697, 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.8181818 , 0.82575756, 0.82575756, 0.8333333 , 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.999   , 0.9985  , 0.998   , 0.9976  ,\n",
       "            0.997   , 0.9966  , 0.9956  , 0.9946  , 0.994   , 0.9937  ,\n",
       "            0.993   , 0.9927  , 0.9917  , 0.991   , 0.9897  , 0.989   ,\n",
       "            0.9854  , 0.9834  , 0.9805  , 0.979   , 0.975   , 0.973   ,\n",
       "            0.9707  , 0.968   , 0.967   , 0.9565  , 0.955   , 0.951   ,\n",
       "            0.9478  , 0.9463  , 0.9443  , 0.9355  , 0.9316  , 0.9287  ,\n",
       "            0.9272  , 0.9253  , 0.92    , 0.916   , 0.9155  , 0.912   ,\n",
       "            0.9097  , 0.909   , 0.908   , 0.9077  , 0.907   , 0.9043  ,\n",
       "            0.899   , 0.898   , 0.8965  , 0.896   , 0.894   , 0.8926  ,\n",
       "            0.89    , 0.889   , 0.887   , 0.8867  , 0.885   , 0.8823  ,\n",
       "            0.8804  , 0.878   , 0.876   , 0.8755  , 0.875   , 0.8735  ,\n",
       "            0.8726  , 0.8706  , 0.8687  , 0.868   , 0.8643  , 0.8623  ,\n",
       "            0.862   , 0.8564  , 0.8525  , 0.85    , 0.8467  , 0.846   ,\n",
       "            0.8447  , 0.8413  , 0.839   , 0.8384  , 0.835   , 0.8335  ,\n",
       "            0.833   , 0.8306  , 0.829   , 0.8267  , 0.8247  , 0.815   ,\n",
       "            0.796   , 0.7954  , 0.7935  , 0.7896  , 0.788   , 0.7754  ,\n",
       "            0.7744  , 0.773   , 0.7705  , 0.7666  , 0.766   , 0.7627  ,\n",
       "            0.7573  , 0.756   , 0.7534  , 0.7495  , 0.749   , 0.7446  ,\n",
       "            0.7407  , 0.737   , 0.722   , 0.718   , 0.7134  , 0.7114  ,\n",
       "            0.701   , 0.6997  , 0.6978  , 0.697   , 0.696   , 0.6943  ,\n",
       "            0.6934  , 0.693   , 0.691   , 0.688   , 0.6855  , 0.6846  ,\n",
       "            0.6816  , 0.674   , 0.665   , 0.6626  , 0.659   , 0.657   ,\n",
       "            0.656   , 0.6494  , 0.6436  , 0.642   , 0.6353  , 0.632   ,\n",
       "            0.6304  , 0.629   , 0.6255  , 0.6235  , 0.6206  , 0.6104  ,\n",
       "            0.601   , 0.6006  , 0.5977  , 0.5967  , 0.5938  , 0.5933  ,\n",
       "            0.593   , 0.5923  , 0.582   , 0.581   , 0.5693  , 0.5684  ,\n",
       "            0.565   , 0.552   , 0.5513  , 0.549   , 0.531   , 0.517   ,\n",
       "            0.516   , 0.4973  , 0.4807  , 0.4688  , 0.4658  , 0.452   ,\n",
       "            0.4517  , 0.4336  , 0.425   , 0.424   , 0.4126  , 0.4028  ,\n",
       "            0.3987  , 0.3948  , 0.3652  , 0.3628  , 0.3433  , 0.34    ,\n",
       "            0.3352  , 0.3071  , 0.283   , 0.2727  , 0.2335  , 0.2238  ,\n",
       "            0.1776  , 0.1528  , 0.1245  , 0.11597 , 0.1138  , 0.10486 ,\n",
       "            0.1021  , 0.10126 , 0.1     , 0.0981  , 0.0967  , 0.0937  ,\n",
       "            0.0874  , 0.0856  , 0.0792  , 0.0642  , 0.06152 , 0.04553 ,\n",
       "            0.01909 , 0.01439 , 0.006588], dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.05      , 0.06666667, 0.075     , 0.08333334, 0.1       ,\n",
       "            0.11666667, 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.15833333, 0.175     , 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.25833333, 0.25833333, 0.26666668, 0.26666668,\n",
       "            0.26666668, 0.28333333, 0.28333333, 0.28333333, 0.29166666,\n",
       "            0.3       , 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.325     , 0.325     , 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.4       , 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.425     , 0.425     ,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45      , 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.51666665, 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.575     , 0.575     , 0.5833333 , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.6       , 0.60833335, 0.60833335,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.6333333 ,\n",
       "            0.6333333 , 0.6333333 , 0.64166665, 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.675     , 0.68333334, 0.68333334, 0.68333334,\n",
       "            0.68333334, 0.68333334, 0.69166666, 0.7       , 0.7       ,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.71666664, 0.725     ,\n",
       "            0.725     , 0.725     , 0.7416667 , 0.75      , 0.75      ,\n",
       "            0.7583333 , 0.7583333 , 0.76666665, 0.775     , 0.775     ,\n",
       "            0.775     , 0.78333336, 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.8       , 0.80833334, 0.80833334, 0.80833334, 0.80833334,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.8333333 ,\n",
       "            0.84166664, 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.8666667 , 0.8666667 , 0.8666667 , 0.875     , 0.875     ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.89166665, 0.89166665,\n",
       "            0.89166665, 0.89166665, 0.89166665, 0.89166665, 0.89166665,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.90833336, 0.90833336,\n",
       "            0.9166667 , 0.9166667 , 0.925     , 0.925     , 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.93333334, 0.94166666, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.975     , 0.975     , 0.98333335, 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.03076923, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.04615385, 0.05384615, 0.06153846, 0.08461539,\n",
       "            0.08461539, 0.08461539, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.14615385, 0.14615385, 0.15384616, 0.16153847, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.24615385,\n",
       "            0.24615385, 0.24615385, 0.25384617, 0.26153848, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.2923077 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33076924, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.3923077 , 0.4       , 0.4076923 , 0.4076923 ,\n",
       "            0.4076923 , 0.4076923 , 0.4076923 , 0.4076923 , 0.42307693,\n",
       "            0.42307693, 0.42307693, 0.43076923, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.44615385, 0.44615385, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46153846, 0.46153846, 0.46153846, 0.46923077,\n",
       "            0.4846154 , 0.4923077 , 0.4923077 , 0.4923077 , 0.4923077 ,\n",
       "            0.4923077 , 0.5       , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.5307692 , 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.54615384, 0.54615384, 0.5538462 , 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5769231 , 0.5923077 ,\n",
       "            0.5923077 , 0.6       , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.63846153, 0.63846153,\n",
       "            0.64615387, 0.64615387, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6846154 , 0.6846154 , 0.6923077 ,\n",
       "            0.6923077 , 0.7       , 0.7       , 0.7       , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.72307694, 0.73846155,\n",
       "            0.74615383, 0.76153845, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.484 , 0.4832, 0.4814, 0.48  , 0.4768, 0.4734, 0.473 ,\n",
       "            0.472 , 0.47  , 0.469 , 0.4688, 0.465 , 0.4646, 0.4636, 0.4617,\n",
       "            0.461 , 0.4607, 0.4604, 0.4597, 0.4595, 0.459 , 0.4587, 0.4563,\n",
       "            0.456 , 0.4548, 0.454 , 0.4539, 0.4536, 0.4534, 0.4524, 0.4521,\n",
       "            0.4514, 0.4512, 0.451 , 0.4507, 0.4504, 0.4497, 0.4495, 0.449 ,\n",
       "            0.4478, 0.4475, 0.4473, 0.4465, 0.4436, 0.443 , 0.4421, 0.4414,\n",
       "            0.4404, 0.4402, 0.4387, 0.4385, 0.4377, 0.4375, 0.4363, 0.4355,\n",
       "            0.4353, 0.435 , 0.4343, 0.4338, 0.4329, 0.4302, 0.4297, 0.4294,\n",
       "            0.429 , 0.4287, 0.4285, 0.4282, 0.4277, 0.427 , 0.4268, 0.426 ,\n",
       "            0.4253, 0.425 , 0.4248, 0.4246, 0.4238, 0.4224, 0.422 , 0.4216,\n",
       "            0.4214, 0.421 , 0.4194, 0.4182, 0.4172, 0.4165, 0.4155, 0.4106,\n",
       "            0.4104, 0.4075, 0.402 , 0.4016, 0.3928, 0.3926, 0.3923, 0.392 ,\n",
       "            0.3906, 0.388 , 0.3865, 0.3818, 0.3816, 0.379 , 0.3755, 0.3733,\n",
       "            0.3726, 0.3718, 0.3716, 0.3706, 0.3694, 0.3687, 0.368 , 0.3674,\n",
       "            0.3652, 0.3645, 0.3635, 0.3628, 0.3625, 0.3623, 0.361 , 0.359 ,\n",
       "            0.3582, 0.3562, 0.3552, 0.355 , 0.3545, 0.3542, 0.354 , 0.3528,\n",
       "            0.3518, 0.3516, 0.3474, 0.3467, 0.3457, 0.345 , 0.3447, 0.3438,\n",
       "            0.3435, 0.341 , 0.3408, 0.3403, 0.34  , 0.338 , 0.3376, 0.337 ,\n",
       "            0.3367, 0.3364, 0.3362, 0.3325, 0.332 , 0.3318, 0.331 , 0.3308,\n",
       "            0.3284, 0.3276, 0.3274, 0.3257, 0.3242, 0.323 , 0.3225, 0.322 ,\n",
       "            0.3218, 0.3213, 0.321 , 0.3208, 0.3206, 0.3203, 0.3193, 0.319 ,\n",
       "            0.3184, 0.318 , 0.3179, 0.3174, 0.3171, 0.3162, 0.3157, 0.3152,\n",
       "            0.315 , 0.3147, 0.3142, 0.313 , 0.3127, 0.3123, 0.312 , 0.3118,\n",
       "            0.3115, 0.3105, 0.31  , 0.3096, 0.3086, 0.3079, 0.3074, 0.307 ,\n",
       "            0.3064, 0.3054, 0.3037, 0.3025, 0.3015, 0.2993, 0.2976, 0.2974,\n",
       "            0.293 , 0.2917, 0.2908, 0.2874, 0.2793, 0.2786, 0.255 , 0.2355],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.025     , 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.375     , 0.375     , 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.425     , 0.425     , 0.425     ,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.45      , 0.45      ,\n",
       "            0.45      , 0.45833334, 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.49166667, 0.49166667, 0.49166667,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.5083333 , 0.5083333 ,\n",
       "            0.5083333 , 0.5083333 , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.525     , 0.525     , 0.525     , 0.525     , 0.525     ,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.55      , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.59166664, 0.59166664, 0.6       , 0.6       , 0.60833335,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.625     , 0.625     ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65      , 0.65833336, 0.6666667 , 0.6666667 ,\n",
       "            0.68333334, 0.68333334, 0.68333334, 0.68333334, 0.69166666,\n",
       "            0.69166666, 0.69166666, 0.7       , 0.71666664, 0.725     ,\n",
       "            0.725     , 0.73333335, 0.73333335, 0.7416667 , 0.7416667 ,\n",
       "            0.7416667 , 0.7416667 , 0.75      , 0.7583333 , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.775     , 0.78333336, 0.8       ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.8333333 , 0.8333333 ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85      , 0.85      ,\n",
       "            0.85      , 0.85      , 0.85      , 0.85      , 0.85      ,\n",
       "            0.85833335, 0.85833335, 0.85833335, 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.9       , 0.90833336, 0.90833336, 0.9166667 , 0.9166667 ,\n",
       "            0.925     , 0.925     , 0.93333334, 0.93333334, 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.96666664, 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.02307692, 0.02307692, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.03846154, 0.04615385, 0.04615385,\n",
       "            0.05384615, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.13076924, 0.13076924,\n",
       "            0.14615385, 0.14615385, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.2       , 0.2       , 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.23846154, 0.24615385, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.31538463, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3846154 , 0.3846154 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.42307693, 0.43076923,\n",
       "            0.43076923, 0.43846154, 0.43846154, 0.43846154, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4846154 , 0.4923077 , 0.4923077 ,\n",
       "            0.50769234, 0.5153846 , 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.5538462 , 0.56153846, 0.56153846, 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.61538464, 0.61538464, 0.61538464,\n",
       "            0.63076925, 0.63076925, 0.63846153, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.6769231 , 0.6769231 , 0.6846154 ,\n",
       "            0.6846154 , 0.6846154 , 0.6923077 , 0.6923077 , 0.6923077 ,\n",
       "            0.7       , 0.7       , 0.7       , 0.7       , 0.7153846 ,\n",
       "            0.7307692 , 0.7307692 , 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.83076924, 0.8384615 , 0.8384615 ,\n",
       "            0.8384615 , 0.86153847, 0.86923075, 0.86923075, 0.86923075,\n",
       "            0.88461536, 0.8923077 , 0.9076923 , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4546, 0.4526, 0.4512, 0.4495, 0.4465, 0.4456, 0.4443,\n",
       "            0.4438, 0.4426, 0.4404, 0.44  , 0.4397, 0.437 , 0.4355, 0.4353,\n",
       "            0.4348, 0.4333, 0.4326, 0.432 , 0.4314, 0.4307, 0.4294, 0.428 ,\n",
       "            0.4277, 0.4272, 0.426 , 0.4238, 0.4226, 0.4211, 0.421 , 0.4204,\n",
       "            0.4194, 0.419 , 0.4187, 0.4167, 0.4165, 0.4158, 0.4148, 0.4124,\n",
       "            0.4114, 0.4111, 0.4097, 0.408 , 0.4072, 0.4067, 0.406 , 0.4058,\n",
       "            0.4053, 0.4043, 0.4036, 0.403 , 0.4028, 0.4016, 0.401 , 0.4001,\n",
       "            0.3994, 0.3992, 0.3977, 0.3967, 0.3965, 0.3962, 0.3955, 0.395 ,\n",
       "            0.3945, 0.393 , 0.3923, 0.3918, 0.391 , 0.39  , 0.3887, 0.388 ,\n",
       "            0.3877, 0.387 , 0.3867, 0.3865, 0.386 , 0.3857, 0.3853, 0.3848,\n",
       "            0.3845, 0.384 , 0.383 , 0.3823, 0.382 , 0.3818, 0.3806, 0.3804,\n",
       "            0.3796, 0.3792, 0.3784, 0.3782, 0.377 , 0.3752, 0.374 , 0.3733,\n",
       "            0.3728, 0.3708, 0.3694, 0.3687, 0.367 , 0.3665, 0.3652, 0.3638,\n",
       "            0.358 , 0.354 , 0.3508, 0.3489, 0.3464, 0.3462, 0.3438, 0.3403,\n",
       "            0.3347, 0.3345, 0.332 , 0.3308, 0.3293, 0.3284, 0.3271, 0.327 ,\n",
       "            0.326 , 0.3252, 0.3247, 0.3215, 0.321 , 0.318 , 0.3162, 0.3147,\n",
       "            0.311 , 0.3098, 0.309 , 0.3066, 0.3064, 0.306 , 0.304 , 0.303 ,\n",
       "            0.302 , 0.3018, 0.3015, 0.3005, 0.2993, 0.299 , 0.2964, 0.2954,\n",
       "            0.2947, 0.2942, 0.294 , 0.293 , 0.292 , 0.2915, 0.2908, 0.2903,\n",
       "            0.2896, 0.2869, 0.2854, 0.2852, 0.2847, 0.2842, 0.2837, 0.2832,\n",
       "            0.2825, 0.28  , 0.2766, 0.2756, 0.2754, 0.2751, 0.2742, 0.2737,\n",
       "            0.2732, 0.273 , 0.2727, 0.2722, 0.2715, 0.2712, 0.271 , 0.2703,\n",
       "            0.2698, 0.2695, 0.2693, 0.269 , 0.2668, 0.2664, 0.2654, 0.265 ,\n",
       "            0.2642, 0.2637, 0.2605, 0.26  , 0.2598, 0.2595, 0.2588, 0.2578,\n",
       "            0.2573, 0.2563, 0.2554, 0.2542, 0.2537, 0.2524, 0.2522, 0.252 ,\n",
       "            0.2512, 0.2487, 0.2478, 0.2474, 0.2458, 0.2445, 0.2413, 0.2399,\n",
       "            0.2382, 0.2366, 0.2302, 0.2252, 0.2222, 0.2   , 0.1791],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.10833333, 0.11666667, 0.125     , 0.14166667,\n",
       "            0.15833333, 0.175     , 0.18333334, 0.2       , 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.425     , 0.425     ,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.45      , 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.49166667, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.5083333 , 0.5083333 , 0.5083333 , 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.525     ,\n",
       "            0.525     , 0.525     , 0.525     , 0.525     , 0.525     ,\n",
       "            0.525     , 0.525     , 0.525     , 0.525     , 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.55      , 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.56666666,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.60833335, 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.625     , 0.625     , 0.625     ,\n",
       "            0.625     , 0.625     , 0.625     , 0.625     , 0.6333333 ,\n",
       "            0.6333333 , 0.6333333 , 0.64166665, 0.65      , 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.675     , 0.675     ,\n",
       "            0.68333334, 0.68333334, 0.69166666, 0.69166666, 0.69166666,\n",
       "            0.7       , 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.7583333 , 0.7583333 , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.775     , 0.775     , 0.775     , 0.775     , 0.78333336,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8       , 0.80833334, 0.81666666, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.84166664, 0.84166664, 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.8666667 , 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.8833333 , 0.89166665, 0.89166665, 0.9       , 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.925     , 0.925     , 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.94166666, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.96666664, 0.975     , 0.975     ,\n",
       "            0.98333335, 0.9916667 , 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.02307692, 0.02307692, 0.03076923,\n",
       "            0.03076923, 0.04615385, 0.05384615, 0.05384615, 0.05384615,\n",
       "            0.05384615, 0.06153846, 0.06923077, 0.07692308, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.1       ,\n",
       "            0.10769231, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.17692308, 0.1923077 , 0.1923077 ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.26923078,\n",
       "            0.2846154 , 0.3       , 0.31538463, 0.31538463, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.42307693, 0.43076923, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4846154 , 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.5153846 , 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.6230769 , 0.6230769 , 0.63846153,\n",
       "            0.63846153, 0.63846153, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.6615385 , 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6769231 , 0.6846154 , 0.6846154 , 0.6846154 , 0.6846154 ,\n",
       "            0.6923077 , 0.6923077 , 0.6923077 , 0.7       , 0.7153846 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.7307692 , 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.77692306, 0.7846154 , 0.7846154 ,\n",
       "            0.7923077 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.8769231 , 0.8923077 ,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.424 , 0.423 , 0.4216, 0.4214, 0.4185, 0.4163, 0.4158,\n",
       "            0.4138, 0.4126, 0.4124, 0.4114, 0.4102, 0.4087, 0.4058, 0.405 ,\n",
       "            0.404 , 0.403 , 0.4026, 0.4023, 0.4019, 0.4001, 0.3997, 0.3994,\n",
       "            0.3992, 0.399 , 0.3958, 0.3948, 0.392 , 0.3918, 0.391 , 0.3909,\n",
       "            0.3904, 0.3872, 0.385 , 0.3835, 0.3828, 0.3792, 0.3774, 0.3752,\n",
       "            0.3748, 0.3745, 0.3743, 0.3713, 0.371 , 0.3706, 0.37  , 0.369 ,\n",
       "            0.3667, 0.366 , 0.3657, 0.3635, 0.3594, 0.359 , 0.3577, 0.3574,\n",
       "            0.3564, 0.356 , 0.3557, 0.3555, 0.355 , 0.3545, 0.3535, 0.351 ,\n",
       "            0.3506, 0.3494, 0.349 , 0.3474, 0.3447, 0.3445, 0.3442, 0.344 ,\n",
       "            0.3423, 0.342 , 0.3408, 0.3396, 0.3389, 0.3381, 0.338 , 0.3372,\n",
       "            0.337 , 0.3354, 0.3342, 0.3337, 0.3328, 0.3315, 0.331 , 0.3306,\n",
       "            0.33  , 0.3293, 0.3276, 0.327 , 0.3267, 0.3218, 0.3196, 0.3186,\n",
       "            0.3147, 0.313 , 0.31  , 0.3093, 0.3079, 0.3062, 0.3025, 0.2979,\n",
       "            0.292 , 0.2903, 0.29  , 0.2883, 0.2876, 0.286 , 0.2856, 0.2817,\n",
       "            0.281 , 0.2805, 0.279 , 0.2783, 0.2776, 0.2764, 0.2754, 0.2725,\n",
       "            0.2715, 0.2712, 0.2673, 0.266 , 0.2632, 0.2622, 0.262 , 0.2612,\n",
       "            0.2607, 0.2595, 0.257 , 0.2554, 0.2544, 0.2532, 0.251 , 0.2507,\n",
       "            0.2498, 0.2493, 0.2489, 0.2474, 0.2463, 0.2456, 0.2451, 0.2444,\n",
       "            0.2441, 0.244 , 0.2433, 0.243 , 0.2426, 0.2418, 0.241 , 0.2401,\n",
       "            0.2399, 0.2384, 0.2346, 0.234 , 0.2334, 0.2323, 0.2319, 0.2313,\n",
       "            0.231 , 0.2306, 0.2301, 0.2299, 0.229 , 0.2285, 0.2281, 0.2277,\n",
       "            0.2272, 0.226 , 0.2256, 0.2255, 0.2247, 0.2242, 0.2239, 0.223 ,\n",
       "            0.2212, 0.2208, 0.2203, 0.2181, 0.2179, 0.2175, 0.217 , 0.2167,\n",
       "            0.2166, 0.2163, 0.2161, 0.2156, 0.2152, 0.215 , 0.2142, 0.2137,\n",
       "            0.2129, 0.2124, 0.2119, 0.2115, 0.2094, 0.2091, 0.2081, 0.2079,\n",
       "            0.2069, 0.2043, 0.2042, 0.2037, 0.2035, 0.2023, 0.2004, 0.1985,\n",
       "            0.1978, 0.1974, 0.1967, 0.1964, 0.1941, 0.1821, 0.1813, 0.1776,\n",
       "            0.1744, 0.1564, 0.1355], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.16666667, 0.175     , 0.19166666, 0.2       ,\n",
       "            0.21666667, 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.525     , 0.525     ,\n",
       "            0.525     , 0.525     , 0.525     , 0.525     , 0.525     ,\n",
       "            0.525     , 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.60833335, 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.625     , 0.625     ,\n",
       "            0.625     , 0.625     , 0.625     , 0.625     , 0.625     ,\n",
       "            0.625     , 0.6333333 , 0.65      , 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.68333334, 0.68333334,\n",
       "            0.68333334, 0.68333334, 0.69166666, 0.69166666, 0.69166666,\n",
       "            0.7       , 0.7       , 0.7       , 0.7083333 , 0.7083333 ,\n",
       "            0.7083333 , 0.7083333 , 0.725     , 0.725     , 0.7416667 ,\n",
       "            0.75      , 0.75      , 0.75      , 0.75      , 0.76666665,\n",
       "            0.775     , 0.775     , 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 ,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 , 0.8       ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.81666666, 0.81666666,\n",
       "            0.8333333 , 0.84166664, 0.84166664, 0.85      , 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.8833333 , 0.89166665, 0.89166665,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.93333334, 0.94166666, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.04615385, 0.04615385, 0.05384615, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.21538462, 0.23076923, 0.24615385, 0.26153848,\n",
       "            0.26923078, 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.47692308, 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.52307695, 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.6230769 , 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6769231 , 0.6769231 , 0.6846154 , 0.6846154 ,\n",
       "            0.6846154 , 0.6846154 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.75384617, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.83076924, 0.83076924,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3953 , 0.3948 , 0.3945 , 0.3933 , 0.392  , 0.3916 ,\n",
       "            0.389  , 0.3865 , 0.3853 , 0.385  , 0.383  , 0.382  , 0.3816 ,\n",
       "            0.3792 , 0.379  , 0.3782 , 0.3755 , 0.3748 , 0.374  , 0.3738 ,\n",
       "            0.3733 , 0.373  , 0.3726 , 0.3723 , 0.371  , 0.369  , 0.368  ,\n",
       "            0.3652 , 0.3643 , 0.364  , 0.362  , 0.3606 , 0.3564 , 0.3557 ,\n",
       "            0.353  , 0.3518 , 0.3503 , 0.3474 , 0.346  , 0.345  , 0.3447 ,\n",
       "            0.3435 , 0.3396 , 0.3381 , 0.3376 , 0.3357 , 0.3342 , 0.3333 ,\n",
       "            0.3289 , 0.328  , 0.3267 , 0.3264 , 0.3257 , 0.3252 , 0.325  ,\n",
       "            0.3247 , 0.3215 , 0.3206 , 0.3196 , 0.3193 , 0.3167 , 0.3164 ,\n",
       "            0.314  , 0.3127 , 0.3123 , 0.3113 , 0.3098 , 0.3096 , 0.3086 ,\n",
       "            0.3083 , 0.3052 , 0.3044 , 0.3037 , 0.3027 , 0.3018 , 0.301  ,\n",
       "            0.2998 , 0.2993 , 0.2986 , 0.2983 , 0.2966 , 0.2964 , 0.2957 ,\n",
       "            0.2932 , 0.292  , 0.2903 , 0.29   , 0.2898 , 0.2893 , 0.289  ,\n",
       "            0.286  , 0.2856 , 0.2852 , 0.282  , 0.2815 , 0.281  , 0.2793 ,\n",
       "            0.2786 , 0.2761 , 0.2737 , 0.2715 , 0.2712 , 0.268  , 0.266  ,\n",
       "            0.262  , 0.2598 , 0.2556 , 0.2554 , 0.2551 , 0.253  , 0.2524 ,\n",
       "            0.2507 , 0.2448 , 0.2437 , 0.243  , 0.2428 , 0.2421 , 0.2418 ,\n",
       "            0.2378 , 0.2356 , 0.2347 , 0.2339 , 0.231  , 0.2303 , 0.228  ,\n",
       "            0.2266 , 0.2264 , 0.2261 , 0.226  , 0.2255 , 0.2251 , 0.2238 ,\n",
       "            0.2205 , 0.2191 , 0.2177 , 0.2161 , 0.2135 , 0.213  , 0.2108 ,\n",
       "            0.2101 , 0.2084 , 0.2081 , 0.2073 , 0.2063 , 0.2054 , 0.2047 ,\n",
       "            0.2035 , 0.2028 , 0.2021 , 0.2    , 0.1989 , 0.197  , 0.196  ,\n",
       "            0.1958 , 0.1948 , 0.1947 , 0.1936 , 0.1935 , 0.1934 , 0.1927 ,\n",
       "            0.1923 , 0.1919 , 0.1915 , 0.1912 , 0.1909 , 0.1906 , 0.1904 ,\n",
       "            0.1885 , 0.1882 , 0.1876 , 0.1874 , 0.1863 , 0.186  , 0.1858 ,\n",
       "            0.1852 , 0.1844 , 0.1842 , 0.1829 , 0.1826 , 0.1799 , 0.1796 ,\n",
       "            0.179  , 0.1787 , 0.1785 , 0.1783 , 0.1772 , 0.1763 , 0.1757 ,\n",
       "            0.1755 , 0.1747 , 0.1737 , 0.1733 , 0.1724 , 0.1705 , 0.1704 ,\n",
       "            0.1703 , 0.1696 , 0.1685 , 0.1682 , 0.1681 , 0.1677 , 0.1672 ,\n",
       "            0.1663 , 0.166  , 0.1656 , 0.1637 , 0.1636 , 0.1631 , 0.162  ,\n",
       "            0.1619 , 0.161  , 0.1592 , 0.1575 , 0.1567 , 0.1539 , 0.1509 ,\n",
       "            0.145  , 0.1418 , 0.135  , 0.1304 , 0.12103, 0.10156],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.025     , 0.03333334, 0.04166667,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.08333334, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.49166667, 0.5       , 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.525     ,\n",
       "            0.525     , 0.525     , 0.525     , 0.525     , 0.525     ,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.56666666, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.59166664, 0.59166664,\n",
       "            0.59166664, 0.6       , 0.6       , 0.6       , 0.6       ,\n",
       "            0.60833335, 0.60833335, 0.60833335, 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65      , 0.65      ,\n",
       "            0.65      , 0.65      , 0.65      , 0.65      , 0.65833336,\n",
       "            0.65833336, 0.6666667 , 0.6666667 , 0.6666667 , 0.6666667 ,\n",
       "            0.6666667 , 0.675     , 0.675     , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.69166666, 0.69166666, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.73333335,\n",
       "            0.73333335, 0.73333335, 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.75      , 0.7583333 , 0.7583333 , 0.7583333 , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.775     , 0.775     , 0.775     ,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.78333336, 0.7916667 ,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.80833334, 0.80833334,\n",
       "            0.81666666, 0.81666666, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.89166665, 0.9       , 0.90833336,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00769231, 0.01538462, 0.02307692, 0.02307692, 0.03076923,\n",
       "            0.03076923, 0.03076923, 0.03846154, 0.03846154, 0.04615385,\n",
       "            0.04615385, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.14615385, 0.15384616, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.20769231, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.2923077 , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.46923077, 0.47692308, 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.56153846, 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6       , 0.6076923 ,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.6846154 ,\n",
       "            0.6846154 , 0.6846154 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.7846154 , 0.7923077 , 0.7923077 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.8230769 , 0.8230769 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3691 , 0.366  , 0.3655 , 0.365  , 0.362  , 0.3613 ,\n",
       "            0.361  , 0.3596 , 0.3577 , 0.3567 , 0.3547 , 0.3538 , 0.3533 ,\n",
       "            0.353  , 0.3528 , 0.352  , 0.3513 , 0.3499 , 0.348  , 0.3477 ,\n",
       "            0.3472 , 0.347  , 0.3467 , 0.3462 , 0.3447 , 0.344  , 0.3428 ,\n",
       "            0.3416 , 0.3396 , 0.3381 , 0.338  , 0.3376 , 0.3352 , 0.3347 ,\n",
       "            0.3303 , 0.33   , 0.3296 , 0.326  , 0.3252 , 0.324  , 0.321  ,\n",
       "            0.3188 , 0.3174 , 0.317  , 0.3164 , 0.3125 , 0.3108 , 0.31   ,\n",
       "            0.309  , 0.306  , 0.304  , 0.3035 , 0.3    , 0.2976 , 0.2974 ,\n",
       "            0.2969 , 0.2957 , 0.2952 , 0.295  , 0.2942 , 0.2925 , 0.2903 ,\n",
       "            0.288  , 0.2878 , 0.2847 , 0.2827 , 0.2812 , 0.281  , 0.2805 ,\n",
       "            0.279  , 0.2773 , 0.2769 , 0.2761 , 0.273  , 0.272  , 0.2715 ,\n",
       "            0.2708 , 0.2695 , 0.269  , 0.2683 , 0.268  , 0.2678 , 0.2654 ,\n",
       "            0.265  , 0.2646 , 0.2625 , 0.2622 , 0.261  , 0.2588 , 0.2585 ,\n",
       "            0.2563 , 0.256  , 0.2559 , 0.2551 , 0.255  , 0.2507 , 0.2502 ,\n",
       "            0.2498 , 0.2496 , 0.2462 , 0.2456 , 0.2441 , 0.2434 , 0.2418 ,\n",
       "            0.2407 , 0.2378 , 0.2356 , 0.2297 , 0.2252 , 0.2246 , 0.223  ,\n",
       "            0.2229 , 0.2208 , 0.2203 , 0.2186 , 0.215  , 0.2128 , 0.211  ,\n",
       "            0.2058 , 0.2053 , 0.2045 , 0.2039 , 0.2009 , 0.2    , 0.1971 ,\n",
       "            0.197  , 0.1962 , 0.1958 , 0.1953 , 0.1947 , 0.1943 , 0.1935 ,\n",
       "            0.1909 , 0.1904 , 0.1885 , 0.1882 , 0.1876 , 0.1864 , 0.1841 ,\n",
       "            0.1836 , 0.181  , 0.1803 , 0.1783 , 0.1781 , 0.1771 , 0.1764 ,\n",
       "            0.1757 , 0.1735 , 0.1726 , 0.1681 , 0.1675 , 0.1666 , 0.1656 ,\n",
       "            0.1648 , 0.1647 , 0.1641 , 0.1638 , 0.1637 , 0.1633 , 0.1621 ,\n",
       "            0.1619 , 0.1617 , 0.1614 , 0.1611 , 0.1608 , 0.1604 , 0.1593 ,\n",
       "            0.159  , 0.1577 , 0.1567 , 0.1565 , 0.1558 , 0.1548 , 0.1544 ,\n",
       "            0.1539 , 0.1531 , 0.1527 , 0.1523 , 0.1515 , 0.1506 , 0.1505 ,\n",
       "            0.1501 , 0.15   , 0.1499 , 0.1498 , 0.1497 , 0.1493 , 0.1489 ,\n",
       "            0.1488 , 0.1478 , 0.1475 , 0.1473 , 0.1467 , 0.1456 , 0.1455 ,\n",
       "            0.1434 , 0.143  , 0.1422 , 0.1416 , 0.1407 , 0.139  , 0.1388 ,\n",
       "            0.1384 , 0.1368 , 0.1365 , 0.135  , 0.1345 , 0.1344 , 0.1339 ,\n",
       "            0.1335 , 0.1326 , 0.1324 , 0.1322 , 0.1299 , 0.1296 , 0.1294 ,\n",
       "            0.1292 , 0.1285 , 0.1283 , 0.1278 , 0.1276 , 0.1236 , 0.12335,\n",
       "            0.1195 , 0.11694, 0.115  , 0.1099 , 0.1045 , 0.09534, 0.09467,\n",
       "            0.07697], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.05      , 0.05833333, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.11666667, 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.175     , 0.18333334, 0.2       , 0.21666667,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.49166667,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.525     , 0.525     , 0.525     , 0.525     ,\n",
       "            0.525     , 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.56666666, 0.56666666, 0.56666666, 0.575     ,\n",
       "            0.575     , 0.5833333 , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.6       , 0.6       , 0.6       , 0.6       , 0.6       ,\n",
       "            0.60833335, 0.60833335, 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.625     , 0.625     , 0.625     , 0.625     ,\n",
       "            0.625     , 0.625     , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.64166665, 0.64166665, 0.64166665, 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65      , 0.65833336, 0.6666667 , 0.6666667 ,\n",
       "            0.6666667 , 0.6666667 , 0.675     , 0.675     , 0.675     ,\n",
       "            0.675     , 0.675     , 0.68333334, 0.68333334, 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.7083333 , 0.71666664,\n",
       "            0.71666664, 0.71666664, 0.71666664, 0.725     , 0.73333335,\n",
       "            0.75      , 0.75      , 0.7583333 , 0.76666665, 0.76666665,\n",
       "            0.76666665, 0.775     , 0.775     , 0.775     , 0.78333336,\n",
       "            0.78333336, 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.81666666, 0.825     , 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.03076923, 0.03076923, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.04615385, 0.04615385, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23846154, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.56153846,\n",
       "            0.5692308 , 0.5692308 , 0.5769231 , 0.5769231 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.72307694, 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.77692306,\n",
       "            0.77692306, 0.7846154 , 0.7846154 , 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.86923075, 0.86923075,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3423 , 0.3403 , 0.338  , 0.3372 , 0.337  , 0.3367 ,\n",
       "            0.3354 , 0.3333 , 0.3328 , 0.3298 , 0.3293 , 0.329  , 0.328  ,\n",
       "            0.3271 , 0.3257 , 0.3254 , 0.3232 , 0.3228 , 0.3225 , 0.322  ,\n",
       "            0.3215 , 0.3213 , 0.3188 , 0.3184 , 0.3176 , 0.3171 , 0.3154 ,\n",
       "            0.3145 , 0.3137 , 0.3132 , 0.3113 , 0.3108 , 0.3066 , 0.3057 ,\n",
       "            0.3022 , 0.3003 , 0.3    , 0.2976 , 0.2947 , 0.2937 , 0.2917 ,\n",
       "            0.2913 , 0.2886 , 0.2861 , 0.286  , 0.2852 , 0.282  , 0.2817 ,\n",
       "            0.2786 , 0.2756 , 0.2727 , 0.2725 , 0.2722 , 0.2717 , 0.27   ,\n",
       "            0.2695 , 0.2688 , 0.268  , 0.2656 , 0.263  , 0.2627 , 0.2612 ,\n",
       "            0.2595 , 0.258  , 0.2573 , 0.2554 , 0.254  , 0.2537 , 0.2524 ,\n",
       "            0.251  , 0.2474 , 0.2473 , 0.2467 , 0.2466 , 0.2463 , 0.2455 ,\n",
       "            0.2444 , 0.2434 , 0.2433 , 0.2422 , 0.2399 , 0.2395 , 0.2386 ,\n",
       "            0.2379 , 0.2367 , 0.2363 , 0.234  , 0.2334 , 0.2323 , 0.2313 ,\n",
       "            0.231  , 0.2307 , 0.2306 , 0.2297 , 0.229  , 0.2283 , 0.226  ,\n",
       "            0.2257 , 0.2252 , 0.2212 , 0.2207 , 0.22   , 0.219  , 0.2181 ,\n",
       "            0.2152 , 0.2133 , 0.2096 , 0.202  , 0.2002 , 0.2001 , 0.1996 ,\n",
       "            0.1985 , 0.196  , 0.1947 , 0.1921 , 0.1897 , 0.189  , 0.1882 ,\n",
       "            0.1864 , 0.18   , 0.1785 , 0.1779 , 0.1755 , 0.1747 , 0.1741 ,\n",
       "            0.1725 , 0.1721 , 0.1708 , 0.1704 , 0.1696 , 0.1681 , 0.1676 ,\n",
       "            0.1675 , 0.166  , 0.1649 , 0.1638 , 0.1632 , 0.1614 , 0.1609 ,\n",
       "            0.1603 , 0.159  , 0.1583 , 0.1581 , 0.1567 , 0.1558 , 0.1554 ,\n",
       "            0.154  , 0.1539 , 0.1532 , 0.1519 , 0.1433 , 0.1425 , 0.1422 ,\n",
       "            0.1421 , 0.142  , 0.1417 , 0.1409 , 0.14   , 0.1396 , 0.1395 ,\n",
       "            0.1393 , 0.1387 , 0.1384 , 0.1383 , 0.1382 , 0.1376 , 0.1357 ,\n",
       "            0.1354 , 0.1353 , 0.1343 , 0.1333 , 0.133  , 0.132  , 0.1305 ,\n",
       "            0.1294 , 0.1292 , 0.129  , 0.1289 , 0.1287 , 0.1282 , 0.1279 ,\n",
       "            0.1274 , 0.1273 , 0.1272 , 0.1268 , 0.1267 , 0.1257 , 0.12463,\n",
       "            0.1245 , 0.1225 , 0.1222 , 0.12177, 0.1217 , 0.12146, 0.12024,\n",
       "            0.1194 , 0.11816, 0.118  , 0.11755, 0.11615, 0.11456, 0.11395,\n",
       "            0.1138 , 0.1122 , 0.11145, 0.11084, 0.10913, 0.10895, 0.1084 ,\n",
       "            0.1082 , 0.1078 , 0.1065 , 0.1056 , 0.1041 , 0.1034 , 0.103  ,\n",
       "            0.10284, 0.10266, 0.1019 , 0.1011 , 0.0993 , 0.0974 , 0.09503,\n",
       "            0.0901 , 0.0873 , 0.0825 , 0.07654, 0.0725 , 0.06064],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.11666667, 0.125     , 0.13333334,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.19166666,\n",
       "            0.21666667, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.49166667, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.525     , 0.525     , 0.525     , 0.525     ,\n",
       "            0.525     , 0.525     , 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.56666666, 0.56666666, 0.575     , 0.575     ,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.6       ,\n",
       "            0.6       , 0.6       , 0.6       , 0.60833335, 0.60833335,\n",
       "            0.60833335, 0.60833335, 0.60833335, 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.6333333 , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.65833336, 0.65833336, 0.65833336, 0.65833336, 0.6666667 ,\n",
       "            0.6666667 , 0.6666667 , 0.6666667 , 0.6666667 , 0.675     ,\n",
       "            0.675     , 0.675     , 0.675     , 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.71666664, 0.725     , 0.73333335,\n",
       "            0.73333335, 0.7583333 , 0.76666665, 0.76666665, 0.775     ,\n",
       "            0.775     , 0.78333336, 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.8833333 ,\n",
       "            0.89166665, 0.89166665, 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.03076923, 0.03076923, 0.03846154, 0.04615385,\n",
       "            0.04615385, 0.04615385, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.15384616, 0.16153847, 0.16153847, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5769231 , 0.5846154 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8       , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.84615386, 0.84615386,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3157 , 0.3142 , 0.3137 , 0.3135 , 0.3123 , 0.31   ,\n",
       "            0.3093 , 0.3088 , 0.3086 , 0.307  , 0.3066 , 0.3052 , 0.305  ,\n",
       "            0.304  , 0.3032 , 0.3022 , 0.302  , 0.3005 , 0.3    , 0.2998 ,\n",
       "            0.2996 , 0.2988 , 0.2969 , 0.2966 , 0.2952 , 0.2944 , 0.2935 ,\n",
       "            0.2925 , 0.2922 , 0.2915 , 0.291  , 0.289  , 0.2876 , 0.287  ,\n",
       "            0.2852 , 0.2827 , 0.28   , 0.2786 , 0.278  , 0.276  , 0.2742 ,\n",
       "            0.2703 , 0.27   , 0.2673 , 0.2664 , 0.2654 , 0.2651 , 0.263  ,\n",
       "            0.2588 , 0.2573 , 0.2534 , 0.2532 , 0.253  , 0.251  , 0.25   ,\n",
       "            0.2493 , 0.2487 , 0.247  , 0.2451 , 0.2434 , 0.2433 , 0.2421 ,\n",
       "            0.2405 , 0.2379 , 0.2378 , 0.2363 , 0.236  , 0.2355 , 0.235  ,\n",
       "            0.2322 , 0.2316 , 0.2302 , 0.2292 , 0.2283 , 0.2281 , 0.2269 ,\n",
       "            0.2263 , 0.2242 , 0.2233 , 0.2217 , 0.2216 , 0.219  , 0.2185 ,\n",
       "            0.2175 , 0.2172 , 0.2153 , 0.2148 , 0.2135 , 0.2133 , 0.213  ,\n",
       "            0.212  , 0.2113 , 0.2108 , 0.2096 , 0.2084 , 0.206  , 0.2056 ,\n",
       "            0.2047 , 0.2045 , 0.2009 , 0.1981 , 0.1978 , 0.1919 , 0.1863 ,\n",
       "            0.1855 , 0.1848 , 0.1836 , 0.1831 , 0.182  , 0.1797 , 0.177  ,\n",
       "            0.1752 , 0.1733 , 0.1711 , 0.1696 , 0.1658 , 0.1656 , 0.1632 ,\n",
       "            0.161  , 0.1605 , 0.1588 , 0.1572 , 0.1561 , 0.1559 , 0.1558 ,\n",
       "            0.1545 , 0.1533 , 0.1509 , 0.1503 , 0.1494 , 0.1493 , 0.1488 ,\n",
       "            0.1472 , 0.1469 , 0.145  , 0.1438 , 0.1437 , 0.1426 , 0.1422 ,\n",
       "            0.1416 , 0.1415 , 0.1411 , 0.1381 , 0.1326 , 0.1307 , 0.1304 ,\n",
       "            0.13   , 0.1289 , 0.1273 , 0.1271 , 0.1265 , 0.1254 , 0.1252 ,\n",
       "            0.1251 , 0.1236 , 0.12317, 0.12305, 0.12274, 0.1216 , 0.1204 ,\n",
       "            0.1192 , 0.119  , 0.1188 , 0.1184 , 0.1178 , 0.1172 , 0.11633,\n",
       "            0.11597, 0.11554, 0.11536, 0.11456, 0.1136 , 0.1124 , 0.112  ,\n",
       "            0.111  , 0.11084, 0.1084 , 0.1078 , 0.1076 , 0.10614, 0.10596,\n",
       "            0.10504, 0.1034 , 0.103  , 0.10126, 0.1011 , 0.0995 , 0.09875,\n",
       "            0.0979 , 0.09753, 0.09705, 0.09686, 0.0964 , 0.0945 , 0.0935 ,\n",
       "            0.0927 , 0.09125, 0.0909 , 0.0901 , 0.0887 , 0.0883 , 0.0879 ,\n",
       "            0.0874 , 0.0869 , 0.086  , 0.0857 , 0.0825 , 0.08093, 0.076  ,\n",
       "            0.07477, 0.0707 , 0.06805, 0.0602 , 0.0531 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.06666667, 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.14166667, 0.15      ,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.21666667, 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.275     , 0.28333333, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.33333334, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.45      , 0.45      , 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.475     , 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.5       , 0.5       , 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.525     , 0.525     , 0.525     , 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.56666666, 0.56666666,\n",
       "            0.56666666, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.59166664, 0.59166664, 0.59166664, 0.6       , 0.6       ,\n",
       "            0.6       , 0.60833335, 0.60833335, 0.60833335, 0.60833335,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.625     , 0.625     , 0.625     , 0.625     ,\n",
       "            0.625     , 0.6333333 , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65      , 0.65833336, 0.65833336, 0.65833336,\n",
       "            0.65833336, 0.6666667 , 0.6666667 , 0.675     , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.7083333 , 0.71666664, 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.76666665, 0.775     , 0.775     ,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.02307692, 0.02307692, 0.03846154, 0.03846154,\n",
       "            0.03846154, 0.04615385, 0.04615385, 0.06153846, 0.06153846,\n",
       "            0.06923077, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.15384616,\n",
       "            0.15384616, 0.16923077, 0.17692308, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.32307693, 0.33076924, 0.33076924, 0.33846155,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.6230769 , 0.6230769 , 0.6230769 , 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9076923 , 0.9076923 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.295  , 0.2947 , 0.2937 , 0.292  , 0.2917 , 0.2903 ,\n",
       "            0.289  , 0.288  , 0.2874 , 0.2869 , 0.2866 , 0.2847 , 0.2844 ,\n",
       "            0.2842 , 0.284  , 0.2837 , 0.2834 , 0.283  , 0.2822 , 0.282  ,\n",
       "            0.281  , 0.2808 , 0.2805 , 0.28   , 0.279  , 0.2788 , 0.2786 ,\n",
       "            0.2783 , 0.2776 , 0.2769 , 0.2756 , 0.2742 , 0.2732 , 0.272  ,\n",
       "            0.269  , 0.2676 , 0.2668 , 0.2646 , 0.2625 , 0.2595 , 0.2593 ,\n",
       "            0.258  , 0.2578 , 0.2566 , 0.2556 , 0.2515 , 0.2502 , 0.2471 ,\n",
       "            0.2463 , 0.2458 , 0.2452 , 0.2437 , 0.2422 , 0.2418 , 0.2397 ,\n",
       "            0.2378 , 0.2363 , 0.2358 , 0.2338 , 0.2327 , 0.2319 , 0.2314 ,\n",
       "            0.231  , 0.2307 , 0.2302 , 0.2295 , 0.2277 , 0.2257 , 0.2256 ,\n",
       "            0.2252 , 0.2246 , 0.2239 , 0.2238 , 0.2211 , 0.22   , 0.2197 ,\n",
       "            0.2194 , 0.2184 , 0.2179 , 0.2168 , 0.2145 , 0.2124 , 0.2123 ,\n",
       "            0.212  , 0.2118 , 0.2114 , 0.2109 , 0.2106 , 0.2096 , 0.2094 ,\n",
       "            0.2073 , 0.2064 , 0.206  , 0.2043 , 0.2015 , 0.1985 , 0.1967 ,\n",
       "            0.1921 , 0.1915 , 0.1891 , 0.1864 , 0.185  , 0.183  , 0.182  ,\n",
       "            0.1812 , 0.1757 , 0.174  , 0.173  , 0.1707 , 0.1678 , 0.167  ,\n",
       "            0.1659 , 0.1658 , 0.1637 , 0.1631 , 0.16   , 0.1586 , 0.1584 ,\n",
       "            0.1575 , 0.1561 , 0.1534 , 0.1532 , 0.1531 , 0.151  , 0.1504 ,\n",
       "            0.1498 , 0.1494 , 0.1484 , 0.1464 , 0.1461 , 0.1454 , 0.1453 ,\n",
       "            0.1447 , 0.1445 , 0.1444 , 0.1437 , 0.143  , 0.1427 , 0.1426 ,\n",
       "            0.1377 , 0.1366 , 0.1343 , 0.1329 , 0.1328 , 0.1323 , 0.1312 ,\n",
       "            0.1307 , 0.1304 , 0.1288 , 0.1284 , 0.1272 , 0.1271 , 0.127  ,\n",
       "            0.1263 , 0.1255 , 0.1251 , 0.1232 , 0.12305, 0.1229 , 0.12274,\n",
       "            0.1223 , 0.12177, 0.1213 , 0.1204 , 0.12036, 0.1201 , 0.1192 ,\n",
       "            0.1188 , 0.1186 , 0.1184 , 0.11694, 0.11554, 0.11536, 0.1144 ,\n",
       "            0.1128 , 0.1122 , 0.1118 , 0.11163, 0.111  , 0.1101 , 0.1099 ,\n",
       "            0.1095 , 0.1082 , 0.10706, 0.1056 , 0.1054 , 0.1052 , 0.1047 ,\n",
       "            0.10376, 0.103  , 0.10126, 0.0995 , 0.0991 , 0.09845, 0.09686,\n",
       "            0.096  , 0.09467, 0.0935 , 0.0925 , 0.09204, 0.09106, 0.0903 ,\n",
       "            0.0888 , 0.0883 , 0.0879 , 0.0877 , 0.0876 , 0.0869 , 0.086  ,\n",
       "            0.08374, 0.08124, 0.0764 , 0.07556, 0.07184, 0.0716 , 0.0613 ,\n",
       "            0.05594], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.01666667, 0.025     , 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.08333334, 0.09166667,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.19166666, 0.2       , 0.20833333, 0.225     ,\n",
       "            0.23333333, 0.25      , 0.25833333, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5       ,\n",
       "            0.5083333 , 0.5083333 , 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.525     , 0.525     , 0.525     , 0.525     , 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.5416667 , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.56666666,\n",
       "            0.56666666, 0.56666666, 0.575     , 0.575     , 0.575     ,\n",
       "            0.575     , 0.575     , 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.60833335, 0.60833335, 0.60833335,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.625     ,\n",
       "            0.625     , 0.625     , 0.625     , 0.625     , 0.625     ,\n",
       "            0.625     , 0.625     , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65      , 0.65833336, 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.675     , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.725     , 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.8       , 0.80833334, 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00769231, 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.03076923, 0.03846154, 0.04615385,\n",
       "            0.04615385, 0.05384615, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.06923077, 0.07692308, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.11538462, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.17692308, 0.1923077 , 0.2       , 0.21538462, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.36923078, 0.36923078, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.6615385 , 0.66923076,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6923077 , 0.7       ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.288  , 0.287  , 0.2866 , 0.285  , 0.2842 , 0.2837 ,\n",
       "            0.2827 , 0.282  , 0.2817 , 0.2815 , 0.2812 , 0.2808 , 0.28   ,\n",
       "            0.2795 , 0.2786 , 0.2783 , 0.278  , 0.2778 , 0.2776 , 0.2773 ,\n",
       "            0.277  , 0.2766 , 0.276  , 0.2747 , 0.2744 , 0.2742 , 0.2715 ,\n",
       "            0.271  , 0.2708 , 0.2705 , 0.2703 , 0.2688 , 0.2686 , 0.2683 ,\n",
       "            0.268  , 0.2678 , 0.266  , 0.2651 , 0.265  , 0.2646 , 0.2634 ,\n",
       "            0.2632 , 0.2622 , 0.2617 , 0.258  , 0.257  , 0.2554 , 0.255  ,\n",
       "            0.2537 , 0.2534 , 0.253  , 0.2527 , 0.2515 , 0.2512 , 0.2493 ,\n",
       "            0.2489 , 0.2485 , 0.2467 , 0.2466 , 0.2463 , 0.2456 , 0.2455 ,\n",
       "            0.244  , 0.2438 , 0.2437 , 0.2418 , 0.2413 , 0.2411 , 0.2401 ,\n",
       "            0.2386 , 0.2379 , 0.2372 , 0.236  , 0.2356 , 0.2355 , 0.2352 ,\n",
       "            0.2343 , 0.233  , 0.2318 , 0.2306 , 0.2297 , 0.2292 , 0.2264 ,\n",
       "            0.226  , 0.2257 , 0.2256 , 0.2255 , 0.2239 , 0.223  , 0.2227 ,\n",
       "            0.2217 , 0.219  , 0.2189 , 0.217  , 0.2142 , 0.214  , 0.2103 ,\n",
       "            0.2095 , 0.2069 , 0.2004 , 0.1987 , 0.1976 , 0.1964 , 0.196  ,\n",
       "            0.1948 , 0.1903 , 0.187  , 0.185  , 0.1844 , 0.1838 , 0.1814 ,\n",
       "            0.1813 , 0.1803 , 0.1792 , 0.1788 , 0.1754 , 0.1748 , 0.1738 ,\n",
       "            0.1726 , 0.1699 , 0.1672 , 0.1671 , 0.1665 , 0.1656 , 0.1646 ,\n",
       "            0.1641 , 0.1635 , 0.162  , 0.1619 , 0.1617 , 0.1611 , 0.1602 ,\n",
       "            0.1599 , 0.1586 , 0.1575 , 0.1558 , 0.1556 , 0.1538 , 0.1515 ,\n",
       "            0.1511 , 0.15   , 0.1489 , 0.1486 , 0.1481 , 0.1472 , 0.146  ,\n",
       "            0.1445 , 0.1444 , 0.1438 , 0.1432 , 0.1425 , 0.1418 , 0.1407 ,\n",
       "            0.1405 , 0.1404 , 0.1401 , 0.1398 , 0.1392 , 0.1382 , 0.138  ,\n",
       "            0.137  , 0.1366 , 0.1361 , 0.1355 , 0.1349 , 0.1343 , 0.134  ,\n",
       "            0.1334 , 0.1328 , 0.1327 , 0.1322 , 0.1311 , 0.1302 , 0.1287 ,\n",
       "            0.1282 , 0.127  , 0.1268 , 0.1266 , 0.12463, 0.12445, 0.124  ,\n",
       "            0.1235 , 0.1217 , 0.1216 , 0.1214 , 0.12067, 0.1193 , 0.1188 ,\n",
       "            0.1172 , 0.11694, 0.11676, 0.115  , 0.11395, 0.1138 , 0.1128 ,\n",
       "            0.11163, 0.1103 , 0.10895, 0.1086 , 0.1076 , 0.1063 , 0.1052 ,\n",
       "            0.10394, 0.1023 , 0.1021 , 0.1019 , 0.1011 , 0.10034, 0.10016,\n",
       "            0.0991 , 0.09827, 0.09753, 0.0964 , 0.0925 , 0.0877 , 0.0871 ,\n",
       "            0.0862 , 0.08344, 0.07196, 0.0682 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.01666667, 0.025     , 0.03333334, 0.04166667,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.1       , 0.10833333,\n",
       "            0.11666667, 0.13333334, 0.14166667, 0.16666667, 0.175     ,\n",
       "            0.19166666, 0.2       , 0.21666667, 0.23333333, 0.24166666,\n",
       "            0.25      , 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.325     , 0.33333334,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.39166668, 0.39166668, 0.4       , 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.46666667, 0.475     , 0.475     , 0.48333332, 0.49166667,\n",
       "            0.49166667, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5083333 , 0.5083333 , 0.5083333 , 0.5083333 , 0.5083333 ,\n",
       "            0.51666665, 0.51666665, 0.525     , 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.5416667 , 0.5416667 , 0.5416667 , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.575     , 0.575     , 0.575     , 0.575     , 0.575     ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.59166664, 0.59166664,\n",
       "            0.6       , 0.6       , 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.625     , 0.625     ,\n",
       "            0.625     , 0.625     , 0.625     , 0.625     , 0.625     ,\n",
       "            0.6333333 , 0.6333333 , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.68333334, 0.68333334, 0.69166666, 0.7       , 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.7916667 , 0.8       , 0.8       , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.04615385, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.12307692, 0.12307692, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.14615385, 0.15384616, 0.16923077,\n",
       "            0.16923077, 0.16923077, 0.17692308, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.1923077 , 0.2       , 0.20769231, 0.22307692,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.25384617, 0.26153848,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.3923077 , 0.4       , 0.4076923 , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7076923 , 0.7153846 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.278  , 0.2766 , 0.2764 , 0.276  , 0.2756 , 0.2754 ,\n",
       "            0.2747 , 0.2744 , 0.2742 , 0.274  , 0.2737 , 0.2734 , 0.2732 ,\n",
       "            0.2722 , 0.272  , 0.2717 , 0.2712 , 0.2705 , 0.2703 , 0.2698 ,\n",
       "            0.2695 , 0.2688 , 0.2683 , 0.268  , 0.2678 , 0.267  , 0.2668 ,\n",
       "            0.2664 , 0.266  , 0.2654 , 0.265  , 0.2642 , 0.2637 , 0.263  ,\n",
       "            0.2622 , 0.2615 , 0.2607 , 0.2605 , 0.2603 , 0.26   , 0.2595 ,\n",
       "            0.2593 , 0.2588 , 0.2585 , 0.2578 , 0.2576 , 0.257  , 0.2563 ,\n",
       "            0.256  , 0.2556 , 0.255  , 0.2542 , 0.254  , 0.2534 , 0.2524 ,\n",
       "            0.252  , 0.2515 , 0.2512 , 0.2502 , 0.249  , 0.2483 , 0.2482 ,\n",
       "            0.248  , 0.2474 , 0.2471 , 0.2462 , 0.2458 , 0.2456 , 0.2445 ,\n",
       "            0.2438 , 0.2434 , 0.2433 , 0.2429 , 0.2417 , 0.2405 , 0.2402 ,\n",
       "            0.2401 , 0.2394 , 0.2368 , 0.2355 , 0.234  , 0.2338 , 0.2328 ,\n",
       "            0.2322 , 0.2319 , 0.2303 , 0.2297 , 0.2277 , 0.2246 , 0.222  ,\n",
       "            0.2205 , 0.213  , 0.2123 , 0.211  , 0.2104 , 0.2089 , 0.2058 ,\n",
       "            0.2037 , 0.2006 , 0.1996 , 0.199  , 0.1968 , 0.1967 , 0.1947 ,\n",
       "            0.1942 , 0.1935 , 0.1907 , 0.1901 , 0.19   , 0.1886 , 0.1884 ,\n",
       "            0.1873 , 0.1863 , 0.1836 , 0.183  , 0.1827 , 0.1783 , 0.178  ,\n",
       "            0.1779 , 0.1776 , 0.1775 , 0.1772 , 0.1755 , 0.1752 , 0.1744 ,\n",
       "            0.1738 , 0.171  , 0.1705 , 0.1688 , 0.1677 , 0.1675 , 0.166  ,\n",
       "            0.1658 , 0.1648 , 0.1637 , 0.1622 , 0.161  , 0.1602 , 0.16   ,\n",
       "            0.1592 , 0.1586 , 0.1583 , 0.158  , 0.1578 , 0.1577 , 0.157  ,\n",
       "            0.1567 , 0.1559 , 0.1543 , 0.1542 , 0.1533 , 0.1525 , 0.1519 ,\n",
       "            0.1511 , 0.1505 , 0.1501 , 0.1488 , 0.1486 , 0.1483 , 0.1464 ,\n",
       "            0.146  , 0.1451 , 0.1449 , 0.1448 , 0.1437 , 0.1426 , 0.1417 ,\n",
       "            0.1416 , 0.1399 , 0.139  , 0.1384 , 0.1377 , 0.1366 , 0.1365 ,\n",
       "            0.136  , 0.1359 , 0.1349 , 0.1332 , 0.1326 , 0.1318 , 0.1288 ,\n",
       "            0.1285 , 0.1284 , 0.128  , 0.1271 , 0.127  , 0.1265 , 0.1252 ,\n",
       "            0.12177, 0.1201 , 0.11993, 0.1194 , 0.118  , 0.11676, 0.1166 ,\n",
       "            0.1158 , 0.11475, 0.1142 , 0.1138 , 0.1134 , 0.11316, 0.112  ,\n",
       "            0.11084, 0.1105 , 0.1101 , 0.10913, 0.1043 , 0.1019 , 0.0998 ,\n",
       "            0.0993 , 0.0959 , 0.08417, 0.0818 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05      , 0.05      , 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.06666667, 0.075     , 0.09166667,\n",
       "            0.1       , 0.10833333, 0.125     , 0.13333334, 0.15      ,\n",
       "            0.16666667, 0.19166666, 0.2       , 0.2       , 0.20833333,\n",
       "            0.21666667, 0.21666667, 0.23333333, 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.325     , 0.33333334, 0.35      , 0.35      , 0.35      ,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.38333333, 0.38333333,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.45      , 0.45      ,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.525     ,\n",
       "            0.525     , 0.53333336, 0.53333336, 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.56666666, 0.56666666, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.59166664, 0.59166664, 0.59166664,\n",
       "            0.59166664, 0.6       , 0.6       , 0.6       , 0.60833335,\n",
       "            0.60833335, 0.60833335, 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.625     , 0.625     , 0.625     , 0.625     , 0.6333333 ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.78333336,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00769231, 0.01538462, 0.02307692, 0.03076923, 0.03846154,\n",
       "            0.06153846, 0.08461539, 0.08461539, 0.08461539, 0.08461539,\n",
       "            0.08461539, 0.08461539, 0.09230769, 0.10769231, 0.11538462,\n",
       "            0.11538462, 0.13076924, 0.13076924, 0.13846155, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.16153847, 0.17692308, 0.17692308,\n",
       "            0.17692308, 0.17692308, 0.17692308, 0.17692308, 0.17692308,\n",
       "            0.18461539, 0.18461539, 0.18461539, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.2       , 0.2       , 0.20769231, 0.21538462,\n",
       "            0.21538462, 0.22307692, 0.23846154, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.25384617, 0.26923078, 0.2769231 , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.33846155, 0.33846155, 0.33846155, 0.34615386, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3923077 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.4076923 , 0.4076923 ,\n",
       "            0.41538462, 0.41538462, 0.42307693, 0.42307693, 0.42307693,\n",
       "            0.43076923, 0.43076923, 0.43846154, 0.44615385, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.53846157, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9307692 , 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2822 , 0.2815 , 0.2812 , 0.281  , 0.2805 , 0.2803 ,\n",
       "            0.28   , 0.2798 , 0.279  , 0.2788 , 0.2786 , 0.2783 , 0.278  ,\n",
       "            0.2778 , 0.2773 , 0.2764 , 0.2761 , 0.276  , 0.2756 , 0.2754 ,\n",
       "            0.275  , 0.2747 , 0.2744 , 0.274  , 0.2737 , 0.2734 , 0.2732 ,\n",
       "            0.2727 , 0.2722 , 0.272  , 0.2712 , 0.271  , 0.2708 , 0.2705 ,\n",
       "            0.2703 , 0.27   , 0.2698 , 0.2695 , 0.269  , 0.2686 , 0.268  ,\n",
       "            0.2678 , 0.2676 , 0.2673 , 0.267  , 0.2666 , 0.2664 , 0.266  ,\n",
       "            0.2659 , 0.2654 , 0.2637 , 0.2634 , 0.2627 , 0.2622 , 0.262  ,\n",
       "            0.2617 , 0.2612 , 0.261  , 0.2605 , 0.2595 , 0.259  , 0.258  ,\n",
       "            0.257  , 0.2566 , 0.2563 , 0.2556 , 0.255  , 0.2534 , 0.252  ,\n",
       "            0.2512 , 0.2507 , 0.2487 , 0.2485 , 0.2466 , 0.2448 , 0.2426 ,\n",
       "            0.2413 , 0.2395 , 0.2383 , 0.236  , 0.2358 , 0.2347 , 0.2343 ,\n",
       "            0.2334 , 0.2332 , 0.2318 , 0.229  , 0.2283 , 0.2273 , 0.2263 ,\n",
       "            0.2239 , 0.2222 , 0.222  , 0.2207 , 0.2186 , 0.2166 , 0.2148 ,\n",
       "            0.213  , 0.2128 , 0.2119 , 0.2118 , 0.2106 , 0.2095 , 0.2089 ,\n",
       "            0.2085 , 0.2054 , 0.2043 , 0.2037 , 0.2032 , 0.2009 , 0.2006 ,\n",
       "            0.2004 , 0.199  , 0.1987 , 0.1981 , 0.1978 , 0.1965 , 0.1954 ,\n",
       "            0.1942 , 0.1934 , 0.1907 , 0.1904 , 0.1903 , 0.1893 , 0.189  ,\n",
       "            0.1887 , 0.187  , 0.1869 , 0.1866 , 0.1864 , 0.186  , 0.1858 ,\n",
       "            0.1857 , 0.1855 , 0.1846 , 0.1843 , 0.1833 , 0.1827 , 0.1823 ,\n",
       "            0.182  , 0.1816 , 0.1814 , 0.1812 , 0.18   , 0.1775 , 0.1764 ,\n",
       "            0.1755 , 0.1744 , 0.1741 , 0.1731 , 0.1727 , 0.1716 , 0.1687 ,\n",
       "            0.1681 , 0.1666 , 0.1646 , 0.1633 , 0.1625 , 0.1621 , 0.1615 ,\n",
       "            0.1605 , 0.1587 , 0.1584 , 0.1578 , 0.1572 , 0.1566 , 0.155  ,\n",
       "            0.1544 , 0.1543 , 0.1525 , 0.1516 , 0.1512 , 0.151  , 0.1477 ,\n",
       "            0.1476 , 0.1475 , 0.1472 , 0.1469 , 0.1421 , 0.1409 , 0.14   ,\n",
       "            0.1396 , 0.1384 , 0.1376 , 0.1365 , 0.1346 , 0.1345 , 0.1339 ,\n",
       "            0.1335 , 0.1332 , 0.1329 , 0.132  , 0.1311 , 0.1296 , 0.129  ,\n",
       "            0.1288 , 0.1263 , 0.12305, 0.119  , 0.1188 , 0.11615, 0.1041 ,\n",
       "            0.1034 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.09166667, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.10833333, 0.11666667, 0.13333334, 0.14166667, 0.14166667,\n",
       "            0.14166667, 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.175     , 0.175     , 0.18333334, 0.2       , 0.20833333,\n",
       "            0.20833333, 0.225     , 0.25      , 0.25      , 0.26666668,\n",
       "            0.275     , 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.35833332, 0.35833332, 0.35833332, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.49166667,\n",
       "            0.49166667, 0.49166667, 0.49166667, 0.49166667, 0.49166667,\n",
       "            0.49166667, 0.5       , 0.5       , 0.5083333 , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.51666665, 0.51666665, 0.525     ,\n",
       "            0.525     , 0.525     , 0.53333336, 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55833334, 0.56666666, 0.56666666,\n",
       "            0.575     , 0.575     , 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.6       , 0.6       , 0.6       , 0.6       ,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.625     ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.90833336, 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.05384615, 0.06153846, 0.07692308, 0.08461539,\n",
       "            0.1       , 0.10769231, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.16153847, 0.16153847, 0.16923077,\n",
       "            0.16923077, 0.17692308, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.1923077 , 0.1923077 , 0.1923077 , 0.1923077 , 0.2       ,\n",
       "            0.2       , 0.20769231, 0.23076923, 0.23076923, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.25384617, 0.26923078,\n",
       "            0.2769231 , 0.3       , 0.30769232, 0.30769232, 0.30769232,\n",
       "            0.30769232, 0.31538463, 0.31538463, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33076924, 0.34615386, 0.35384616, 0.35384616,\n",
       "            0.36153847, 0.36153847, 0.36153847, 0.36153847, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3846154 , 0.3846154 ,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.4076923 ,\n",
       "            0.4076923 , 0.41538462, 0.41538462, 0.41538462, 0.41538462,\n",
       "            0.42307693, 0.42307693, 0.43076923, 0.43846154, 0.43846154,\n",
       "            0.45384616, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.4923077 , 0.5       ,\n",
       "            0.5       , 0.50769234, 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.5692308 ,\n",
       "            0.5769231 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.6076923 , 0.61538464, 0.6230769 , 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.63846153, 0.64615387, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.6923077 , 0.6923077 , 0.7       ,\n",
       "            0.7       , 0.7076923 , 0.72307694, 0.74615383, 0.74615383,\n",
       "            0.76153845, 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.86923075,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.311 , 0.3096, 0.3076, 0.3066, 0.3037, 0.3032, 0.3025,\n",
       "            0.3022, 0.302 , 0.2998, 0.2988, 0.2983, 0.2974, 0.2961, 0.2952,\n",
       "            0.2935, 0.2922, 0.2905, 0.2898, 0.2896, 0.2893, 0.288 , 0.2878,\n",
       "            0.2876, 0.2874, 0.2869, 0.2864, 0.2861, 0.286 , 0.2854, 0.2852,\n",
       "            0.285 , 0.2847, 0.2842, 0.284 , 0.2837, 0.2834, 0.283 , 0.2822,\n",
       "            0.282 , 0.2815, 0.281 , 0.2808, 0.28  , 0.2798, 0.2795, 0.2788,\n",
       "            0.2786, 0.2778, 0.277 , 0.2769, 0.2766, 0.2764, 0.2756, 0.2754,\n",
       "            0.2751, 0.2747, 0.2744, 0.274 , 0.273 , 0.2722, 0.272 , 0.2712,\n",
       "            0.2708, 0.2703, 0.2695, 0.2693, 0.2686, 0.268 , 0.2678, 0.2666,\n",
       "            0.2664, 0.2659, 0.265 , 0.2617, 0.2603, 0.2588, 0.2578, 0.2559,\n",
       "            0.2556, 0.2554, 0.255 , 0.2542, 0.2505, 0.2502, 0.2489, 0.2483,\n",
       "            0.2466, 0.2463, 0.2456, 0.2452, 0.2449, 0.2433, 0.2421, 0.2411,\n",
       "            0.2405, 0.2394, 0.2384, 0.2383, 0.2363, 0.236 , 0.2356, 0.2352,\n",
       "            0.2339, 0.2335, 0.231 , 0.2302, 0.2297, 0.2292, 0.2283, 0.2281,\n",
       "            0.228 , 0.2274, 0.2256, 0.2255, 0.2242, 0.2238, 0.2234, 0.223 ,\n",
       "            0.2229, 0.2222, 0.2208, 0.2198, 0.2194, 0.2191, 0.2163, 0.2162,\n",
       "            0.2158, 0.2153, 0.2142, 0.214 , 0.2129, 0.2125, 0.2119, 0.2104,\n",
       "            0.2103, 0.2095, 0.2094, 0.2091, 0.2085, 0.2081, 0.2074, 0.206 ,\n",
       "            0.2053, 0.205 , 0.204 , 0.2039, 0.2026, 0.2018, 0.201 , 0.2009,\n",
       "            0.1985, 0.1967, 0.1954, 0.1952, 0.1942, 0.194 , 0.1934, 0.1924,\n",
       "            0.1901, 0.1884, 0.1855, 0.1837, 0.183 , 0.1813, 0.1796, 0.1782,\n",
       "            0.178 , 0.1779, 0.1768, 0.1757, 0.1753, 0.1752, 0.1747, 0.1724,\n",
       "            0.1719, 0.1694, 0.1687, 0.1678, 0.1663, 0.1649, 0.1647, 0.1643,\n",
       "            0.1638, 0.1627, 0.1615, 0.1581, 0.1556, 0.1555, 0.1545, 0.1527,\n",
       "            0.1526, 0.152 , 0.1517, 0.1516, 0.1512, 0.15  , 0.1483, 0.147 ,\n",
       "            0.1467, 0.1462, 0.1404, 0.1383, 0.1364, 0.1362, 0.1271, 0.1214],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.1       , 0.11666667,\n",
       "            0.11666667, 0.11666667, 0.125     , 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.15833333, 0.15833333,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.2       , 0.21666667, 0.225     , 0.23333333,\n",
       "            0.23333333, 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.29166666, 0.30833334, 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.325     , 0.325     , 0.325     , 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.35833332, 0.375     , 0.375     , 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.425     , 0.425     ,\n",
       "            0.425     , 0.425     , 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.525     , 0.525     ,\n",
       "            0.525     , 0.525     , 0.53333336, 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.55      , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.7916667 , 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.22307692, 0.23846154, 0.26153848,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.30769232, 0.31538463, 0.31538463,\n",
       "            0.32307693, 0.32307693, 0.33076924, 0.33076924, 0.33076924,\n",
       "            0.33076924, 0.33076924, 0.33076924, 0.33076924, 0.33076924,\n",
       "            0.33846155, 0.35384616, 0.35384616, 0.36153847, 0.36153847,\n",
       "            0.36153847, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.4       , 0.4       , 0.4       , 0.41538462, 0.42307693,\n",
       "            0.42307693, 0.42307693, 0.42307693, 0.42307693, 0.42307693,\n",
       "            0.43076923, 0.44615385, 0.44615385, 0.44615385, 0.44615385,\n",
       "            0.44615385, 0.44615385, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.4923077 , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.54615384, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5692308 , 0.5769231 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63076925, 0.63846153, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.66923076, 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8076923 , 0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.9461538 , 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3525, 0.344 , 0.3396, 0.3374, 0.336 , 0.3345, 0.3342,\n",
       "            0.3328, 0.3325, 0.332 , 0.331 , 0.3306, 0.3303, 0.3254, 0.3252,\n",
       "            0.325 , 0.3245, 0.323 , 0.3203, 0.3145, 0.3118, 0.3108, 0.309 ,\n",
       "            0.3083, 0.3076, 0.3071, 0.3062, 0.306 , 0.3044, 0.3042, 0.304 ,\n",
       "            0.3037, 0.303 , 0.3027, 0.302 , 0.3015, 0.3013, 0.2993, 0.2988,\n",
       "            0.2986, 0.2979, 0.2976, 0.2974, 0.297 , 0.2969, 0.2964, 0.2961,\n",
       "            0.296 , 0.2954, 0.295 , 0.2947, 0.2942, 0.2937, 0.2935, 0.293 ,\n",
       "            0.2927, 0.2925, 0.2917, 0.2915, 0.291 , 0.2908, 0.2886, 0.288 ,\n",
       "            0.2878, 0.2866, 0.2861, 0.2852, 0.285 , 0.2842, 0.2837, 0.2834,\n",
       "            0.2832, 0.2827, 0.2825, 0.2803, 0.28  , 0.2798, 0.2793, 0.2786,\n",
       "            0.2783, 0.278 , 0.2766, 0.276 , 0.2756, 0.2754, 0.274 , 0.2732,\n",
       "            0.2727, 0.2712, 0.27  , 0.2695, 0.2683, 0.2673, 0.267 , 0.2666,\n",
       "            0.2664, 0.2654, 0.2651, 0.2646, 0.2644, 0.2642, 0.2634, 0.2622,\n",
       "            0.262 , 0.2617, 0.2612, 0.2595, 0.2593, 0.2588, 0.258 , 0.2578,\n",
       "            0.2556, 0.255 , 0.2544, 0.2524, 0.2522, 0.252 , 0.2515, 0.2502,\n",
       "            0.25  , 0.2489, 0.2483, 0.248 , 0.2474, 0.247 , 0.2467, 0.2458,\n",
       "            0.2455, 0.2452, 0.2451, 0.2445, 0.2444, 0.2441, 0.2438, 0.2418,\n",
       "            0.2417, 0.241 , 0.2407, 0.2397, 0.2379, 0.237 , 0.236 , 0.2352,\n",
       "            0.2332, 0.2328, 0.2325, 0.2307, 0.2306, 0.2302, 0.2297, 0.2289,\n",
       "            0.228 , 0.2272, 0.2256, 0.224 , 0.2229, 0.2218, 0.2217, 0.2184,\n",
       "            0.2181, 0.2177, 0.2158, 0.2153, 0.2145, 0.214 , 0.2135, 0.211 ,\n",
       "            0.2109, 0.2103, 0.2095, 0.2026, 0.2015, 0.2006, 0.1996, 0.199 ,\n",
       "            0.1979, 0.1974, 0.1973, 0.197 , 0.1968, 0.1964, 0.193 , 0.1929,\n",
       "            0.1917, 0.1896, 0.1876, 0.1866, 0.1865, 0.1855, 0.1837, 0.1831,\n",
       "            0.1826, 0.1804, 0.1783, 0.1781, 0.1759, 0.1752, 0.1748, 0.1743,\n",
       "            0.1731, 0.1726, 0.1724, 0.1709, 0.1693, 0.1678, 0.1676, 0.1661,\n",
       "            0.1658, 0.1611, 0.16  , 0.1599, 0.1564, 0.1549, 0.1426],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.03333334, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.06666667, 0.06666667, 0.06666667, 0.06666667, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.075     , 0.075     , 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.10833333, 0.11666667, 0.11666667,\n",
       "            0.125     , 0.125     , 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.16666667, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.18333334, 0.18333334, 0.18333334, 0.18333334, 0.18333334,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.2       , 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.20833333, 0.20833333, 0.20833333,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.225     , 0.23333333,\n",
       "            0.24166666, 0.24166666, 0.24166666, 0.24166666, 0.24166666,\n",
       "            0.25      , 0.25      , 0.25833333, 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.275     , 0.275     , 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.5       , 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.3923077 , 0.4       , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.43846154, 0.45384616, 0.46153846, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4923077 , 0.5       , 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.53846157, 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.5538462 , 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6923077 , 0.7       , 0.7       , 0.7153846 , 0.7153846 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.7692308 , 0.7692308 , 0.77692306, 0.77692306, 0.77692306,\n",
       "            0.77692306, 0.7846154 , 0.8       , 0.8076923 , 0.8076923 ,\n",
       "            0.8153846 , 0.83076924, 0.83076924, 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.84615386, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.8923077 , 0.8923077 , 0.9       , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3972, 0.3806, 0.3738, 0.373 , 0.3716, 0.3694, 0.3682,\n",
       "            0.365 , 0.3633, 0.3628, 0.3599, 0.3591, 0.3582, 0.3528, 0.3516,\n",
       "            0.3508, 0.3474, 0.3435, 0.3374, 0.3372, 0.3364, 0.336 , 0.3357,\n",
       "            0.3333, 0.3325, 0.3315, 0.331 , 0.33  , 0.3284, 0.3274, 0.3254,\n",
       "            0.3247, 0.3242, 0.324 , 0.3235, 0.3223, 0.3218, 0.3203, 0.3196,\n",
       "            0.319 , 0.3179, 0.3176, 0.3171, 0.3162, 0.3157, 0.315 , 0.3145,\n",
       "            0.3142, 0.3137, 0.3132, 0.3127, 0.3125, 0.3118, 0.3115, 0.311 ,\n",
       "            0.3108, 0.3103, 0.31  , 0.3098, 0.3093, 0.309 , 0.3079, 0.3076,\n",
       "            0.3066, 0.306 , 0.3057, 0.3044, 0.3032, 0.302 , 0.3015, 0.3013,\n",
       "            0.3008, 0.2988, 0.2986, 0.2979, 0.2976, 0.2966, 0.2961, 0.296 ,\n",
       "            0.2954, 0.295 , 0.2944, 0.2942, 0.2937, 0.2935, 0.293 , 0.2925,\n",
       "            0.2922, 0.292 , 0.2915, 0.2913, 0.291 , 0.2908, 0.2903, 0.2898,\n",
       "            0.2893, 0.288 , 0.2878, 0.2876, 0.2874, 0.2869, 0.2864, 0.2861,\n",
       "            0.2854, 0.2847, 0.2834, 0.2832, 0.2827, 0.2825, 0.282 , 0.2815,\n",
       "            0.2805, 0.2803, 0.279 , 0.278 , 0.276 , 0.2756, 0.2742, 0.274 ,\n",
       "            0.2737, 0.2734, 0.2725, 0.2715, 0.2712, 0.271 , 0.2705, 0.2703,\n",
       "            0.27  , 0.2698, 0.268 , 0.267 , 0.2664, 0.2644, 0.2637, 0.2622,\n",
       "            0.262 , 0.261 , 0.259 , 0.258 , 0.2578, 0.2534, 0.2502, 0.2493,\n",
       "            0.2489, 0.2487, 0.2474, 0.2463, 0.2448, 0.243 , 0.2424, 0.2413,\n",
       "            0.2406, 0.2391, 0.239 , 0.2375, 0.2372, 0.2363, 0.2351, 0.235 ,\n",
       "            0.229 , 0.2289, 0.2283, 0.2274, 0.2266, 0.2264, 0.226 , 0.2257,\n",
       "            0.2242, 0.2238, 0.2217, 0.2207, 0.2205, 0.2195, 0.2189, 0.2175,\n",
       "            0.2166, 0.2162, 0.215 , 0.2148, 0.2144, 0.214 , 0.2135, 0.2125,\n",
       "            0.2104, 0.2084, 0.208 , 0.2068, 0.2064, 0.205 , 0.2045, 0.204 ,\n",
       "            0.2037, 0.2034, 0.202 , 0.2015, 0.2006, 0.2   , 0.1998, 0.1996,\n",
       "            0.1968, 0.1962, 0.1954, 0.195 , 0.1946, 0.1927, 0.1925, 0.1918,\n",
       "            0.1912, 0.1863, 0.1831, 0.171 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05      , 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.075     , 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.09166667, 0.09166667, 0.09166667,\n",
       "            0.09166667, 0.09166667, 0.1       , 0.10833333, 0.125     ,\n",
       "            0.125     , 0.125     , 0.125     , 0.13333334, 0.13333334,\n",
       "            0.14166667, 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.15833333, 0.15833333, 0.15833333, 0.16666667, 0.16666667,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.19166666,\n",
       "            0.2       , 0.2       , 0.2       , 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.21666667, 0.225     , 0.225     , 0.23333333,\n",
       "            0.24166666, 0.24166666, 0.25      , 0.25      , 0.25833333,\n",
       "            0.26666668, 0.26666668, 0.275     , 0.275     , 0.275     ,\n",
       "            0.275     , 0.28333333, 0.3       , 0.30833334, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.38333333, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.56666666, 0.575     , 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.6       , 0.60833335, 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.4       , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.46153846, 0.47692308, 0.4846154 ,\n",
       "            0.4846154 , 0.5       , 0.5153846 , 0.52307695, 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5692308 , 0.5846154 , 0.5846154 , 0.5923077 , 0.5923077 ,\n",
       "            0.6076923 , 0.61538464, 0.63076925, 0.63846153, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.66923076, 0.6769231 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7076923 , 0.72307694,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.86153847, 0.86153847,\n",
       "            0.86153847, 0.86923075, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.435 , 0.4172, 0.405 , 0.4043, 0.4019, 0.4006, 0.3972,\n",
       "            0.3943, 0.3938, 0.3909, 0.3894, 0.3882, 0.3857, 0.385 , 0.3762,\n",
       "            0.376 , 0.372 , 0.3672, 0.3584, 0.3582, 0.358 , 0.3564, 0.3552,\n",
       "            0.3535, 0.352 , 0.3508, 0.35  , 0.3499, 0.3494, 0.346 , 0.3455,\n",
       "            0.3447, 0.3425, 0.3406, 0.3398, 0.3396, 0.3384, 0.3376, 0.3352,\n",
       "            0.3342, 0.3337, 0.3335, 0.3325, 0.3315, 0.331 , 0.3298, 0.3293,\n",
       "            0.3289, 0.328 , 0.3276, 0.3257, 0.3254, 0.3252, 0.325 , 0.3247,\n",
       "            0.3245, 0.324 , 0.323 , 0.3228, 0.3215, 0.3213, 0.321 , 0.3203,\n",
       "            0.3198, 0.3196, 0.319 , 0.3186, 0.3171, 0.3167, 0.3164, 0.3162,\n",
       "            0.3152, 0.315 , 0.3145, 0.314 , 0.3137, 0.313 , 0.3125, 0.3123,\n",
       "            0.3115, 0.3113, 0.3108, 0.3103, 0.31  , 0.3093, 0.3088, 0.308 ,\n",
       "            0.3076, 0.3057, 0.3054, 0.3052, 0.3047, 0.3044, 0.303 , 0.3027,\n",
       "            0.3013, 0.3008, 0.3003, 0.3   , 0.2998, 0.299 , 0.2986, 0.2961,\n",
       "            0.296 , 0.2957, 0.2942, 0.2925, 0.2922, 0.291 , 0.2908, 0.29  ,\n",
       "            0.2896, 0.2893, 0.2878, 0.2874, 0.287 , 0.2866, 0.2864, 0.286 ,\n",
       "            0.285 , 0.2847, 0.2844, 0.2842, 0.2825, 0.282 , 0.2798, 0.277 ,\n",
       "            0.2769, 0.276 , 0.274 , 0.2722, 0.2712, 0.27  , 0.2693, 0.2688,\n",
       "            0.268 , 0.265 , 0.2646, 0.2632, 0.2627, 0.2622, 0.2612, 0.2605,\n",
       "            0.26  , 0.259 , 0.2566, 0.2546, 0.2542, 0.2534, 0.2527, 0.2524,\n",
       "            0.252 , 0.2462, 0.2433, 0.243 , 0.2428, 0.2418, 0.2417, 0.2411,\n",
       "            0.241 , 0.2401, 0.2395, 0.2384, 0.2375, 0.2332, 0.233 , 0.2327,\n",
       "            0.2297, 0.2294, 0.2285, 0.2281, 0.228 , 0.2269, 0.2252, 0.2246,\n",
       "            0.2239, 0.2238, 0.2184, 0.2181, 0.2175, 0.2173, 0.217 , 0.2168,\n",
       "            0.2166, 0.2152, 0.2147, 0.214 , 0.213 , 0.2123, 0.2095, 0.2091,\n",
       "            0.2084, 0.2081, 0.2076, 0.2064, 0.206 , 0.2054, 0.205 , 0.2043,\n",
       "            0.2031, 0.2002, 0.1996, 0.1954, 0.1952, 0.1924, 0.1921, 0.1813],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.06666667, 0.06666667,\n",
       "            0.075     , 0.08333334, 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.1       , 0.1       , 0.1       , 0.10833333, 0.11666667,\n",
       "            0.11666667, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15833333, 0.15833333,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.225     , 0.23333333,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.28333333, 0.29166666, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.43333334, 0.44166666,\n",
       "            0.45      , 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.49166667, 0.5       , 0.51666665, 0.51666665, 0.525     ,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.81666666, 0.825     , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06923077, 0.07692308,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.3       , 0.30769232, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.37692308, 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.44615385, 0.45384616, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5846154 , 0.5923077 ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.6615385 , 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.7307692 ,\n",
       "            0.7307692 , 0.7307692 , 0.73846155, 0.74615383, 0.76153845,\n",
       "            0.7692308 , 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8076923 , 0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.86923075, 0.8769231 , 0.8769231 , 0.8923077 ,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.9307692 , 0.9307692 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4802, 0.4597, 0.4443, 0.4414, 0.4395, 0.4377, 0.433 ,\n",
       "            0.4307, 0.4297, 0.4248, 0.4233, 0.422 , 0.4187, 0.4062, 0.406 ,\n",
       "            0.4019, 0.3953, 0.3877, 0.3855, 0.3853, 0.385 , 0.384 , 0.3838,\n",
       "            0.3804, 0.3792, 0.3774, 0.376 , 0.3755, 0.3718, 0.3699, 0.3691,\n",
       "            0.3682, 0.3655, 0.365 , 0.3628, 0.3625, 0.3623, 0.3613, 0.3608,\n",
       "            0.3606, 0.3604, 0.36  , 0.3596, 0.3591, 0.3572, 0.357 , 0.3564,\n",
       "            0.3562, 0.356 , 0.3552, 0.3545, 0.3538, 0.3525, 0.3523, 0.352 ,\n",
       "            0.3516, 0.3513, 0.351 , 0.3508, 0.35  , 0.3496, 0.3494, 0.3489,\n",
       "            0.3486, 0.3481, 0.347 , 0.3464, 0.346 , 0.3457, 0.3445, 0.3442,\n",
       "            0.3438, 0.3433, 0.343 , 0.3428, 0.342 , 0.3418, 0.3416, 0.341 ,\n",
       "            0.3408, 0.3403, 0.338 , 0.3376, 0.3372, 0.3347, 0.3345, 0.3333,\n",
       "            0.333 , 0.3328, 0.3325, 0.3315, 0.3306, 0.3303, 0.328 , 0.3274,\n",
       "            0.327 , 0.3267, 0.3262, 0.3254, 0.325 , 0.3245, 0.324 , 0.323 ,\n",
       "            0.322 , 0.3215, 0.3203, 0.32  , 0.3193, 0.3154, 0.315 , 0.3147,\n",
       "            0.3137, 0.313 , 0.3118, 0.3103, 0.31  , 0.3088, 0.3079, 0.3076,\n",
       "            0.3057, 0.3042, 0.3035, 0.3022, 0.2983, 0.2966, 0.296 , 0.2947,\n",
       "            0.2937, 0.2935, 0.293 , 0.2925, 0.2908, 0.2898, 0.289 , 0.2888,\n",
       "            0.2886, 0.2878, 0.287 , 0.2869, 0.2864, 0.2852, 0.2847, 0.2837,\n",
       "            0.2825, 0.2805, 0.28  , 0.277 , 0.2766, 0.2754, 0.275 , 0.2732,\n",
       "            0.272 , 0.2717, 0.2703, 0.268 , 0.2678, 0.2668, 0.2654, 0.265 ,\n",
       "            0.2646, 0.2637, 0.2622, 0.2615, 0.2603, 0.26  , 0.2595, 0.259 ,\n",
       "            0.2583, 0.258 , 0.2576, 0.2566, 0.2556, 0.2522, 0.252 , 0.2478,\n",
       "            0.2473, 0.2458, 0.2445, 0.2441, 0.244 , 0.2437, 0.2422, 0.2415,\n",
       "            0.2397, 0.2391, 0.2384, 0.2379, 0.2358, 0.2355, 0.2343, 0.2338,\n",
       "            0.2332, 0.2322, 0.2311, 0.2306, 0.2297, 0.229 , 0.2285, 0.2277,\n",
       "            0.2249, 0.2246, 0.224 , 0.2212, 0.22  , 0.2175, 0.2168, 0.2129,\n",
       "            0.212 , 0.2109, 0.2103, 0.2015, 0.2002, 0.1991, 0.1973, 0.187 ,\n",
       "            0.1838], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.01538462, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.04166667, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.075     , 0.09166667,\n",
       "            0.1       , 0.1       , 0.10833333, 0.11666667, 0.11666667,\n",
       "            0.11666667, 0.13333334, 0.14166667, 0.15      , 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.225     , 0.225     , 0.23333333, 0.23333333,\n",
       "            0.24166666, 0.25      , 0.275     , 0.28333333, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.38333333,\n",
       "            0.4       , 0.41666666, 0.425     , 0.43333334, 0.43333334,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.55      , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.5833333 , 0.59166664, 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4076923 , 0.41538462, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.83076924, 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.84615386, 0.85384613, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.86923075, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.8769231 , 0.88461536, 0.88461536, 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.527 , 0.506 , 0.4863, 0.4817, 0.48  , 0.4783, 0.4724,\n",
       "            0.4707, 0.4705, 0.4688, 0.4648, 0.4634, 0.462 , 0.4592, 0.4553,\n",
       "            0.44  , 0.439 , 0.4346, 0.4268, 0.422 , 0.4192, 0.4155, 0.415 ,\n",
       "            0.4136, 0.4097, 0.4065, 0.4055, 0.4045, 0.403 , 0.3972, 0.3962,\n",
       "            0.3958, 0.3955, 0.3948, 0.3943, 0.3938, 0.3933, 0.3928, 0.3916,\n",
       "            0.391 , 0.3909, 0.39  , 0.3894, 0.3882, 0.388 , 0.3877, 0.3875,\n",
       "            0.387 , 0.3865, 0.3855, 0.385 , 0.3848, 0.3845, 0.3838, 0.383 ,\n",
       "            0.382 , 0.3801, 0.38  , 0.3796, 0.3792, 0.378 , 0.3772, 0.3767,\n",
       "            0.3757, 0.3748, 0.3743, 0.374 , 0.3735, 0.373 , 0.3723, 0.372 ,\n",
       "            0.3718, 0.3713, 0.3704, 0.3687, 0.3677, 0.3667, 0.3657, 0.3655,\n",
       "            0.3652, 0.365 , 0.3635, 0.363 , 0.3625, 0.362 , 0.3618, 0.3604,\n",
       "            0.36  , 0.3599, 0.3594, 0.3574, 0.3572, 0.357 , 0.3567, 0.3557,\n",
       "            0.3555, 0.3545, 0.352 , 0.3513, 0.348 , 0.3472, 0.3467, 0.3438,\n",
       "            0.3433, 0.3425, 0.3413, 0.3408, 0.3394, 0.3386, 0.3372, 0.3367,\n",
       "            0.336 , 0.3345, 0.3335, 0.3328, 0.3315, 0.3284, 0.327 , 0.3262,\n",
       "            0.322 , 0.3213, 0.3196, 0.3193, 0.3164, 0.3154, 0.315 , 0.314 ,\n",
       "            0.313 , 0.3125, 0.3115, 0.3108, 0.3098, 0.3096, 0.3079, 0.3074,\n",
       "            0.3071, 0.3054, 0.3022, 0.2998, 0.2986, 0.298 , 0.2974, 0.2969,\n",
       "            0.294 , 0.2925, 0.2917, 0.291 , 0.2886, 0.287 , 0.286 , 0.2834,\n",
       "            0.2832, 0.283 , 0.282 , 0.2812, 0.2803, 0.2786, 0.278 , 0.277 ,\n",
       "            0.275 , 0.2742, 0.274 , 0.272 , 0.2715, 0.27  , 0.2695, 0.268 ,\n",
       "            0.2676, 0.2668, 0.2654, 0.2651, 0.2632, 0.263 , 0.2612, 0.261 ,\n",
       "            0.2603, 0.2598, 0.2585, 0.2573, 0.2568, 0.2566, 0.2554, 0.255 ,\n",
       "            0.2544, 0.2542, 0.254 , 0.2524, 0.2515, 0.251 , 0.2507, 0.2502,\n",
       "            0.25  , 0.2494, 0.2489, 0.247 , 0.2467, 0.246 , 0.2452, 0.2429,\n",
       "            0.2407, 0.2374, 0.2372, 0.2362, 0.2351, 0.2338, 0.2332, 0.2306,\n",
       "            0.2303, 0.2277, 0.2257, 0.2211, 0.2207, 0.2069, 0.2051, 0.1937,\n",
       "            0.1925, 0.1904, 0.1794, 0.1763], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.08461539, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.16666667, 0.175     , 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.19166666, 0.19166666, 0.2       , 0.2       ,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.64166665, 0.65      , 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.71666664, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.31538463, 0.32307693,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.53846157,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.6615385 , 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.8769231 , 0.88461536, 0.88461536, 0.88461536,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.9461538 , 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5654, 0.547 , 0.521 , 0.5166, 0.514 , 0.5063, 0.506 ,\n",
       "            0.5054, 0.503 , 0.501 , 0.498 , 0.493 , 0.4917, 0.4858, 0.4688,\n",
       "            0.467 , 0.4631, 0.4539, 0.451 , 0.4434, 0.4392, 0.439 , 0.437 ,\n",
       "            0.4324, 0.4287, 0.4277, 0.4263, 0.4258, 0.425 , 0.4233, 0.4202,\n",
       "            0.4197, 0.4177, 0.4172, 0.4165, 0.4163, 0.4155, 0.4146, 0.414 ,\n",
       "            0.4128, 0.4124, 0.4116, 0.4106, 0.4104, 0.41  , 0.4094, 0.408 ,\n",
       "            0.407 , 0.4067, 0.4065, 0.4058, 0.4055, 0.405 , 0.4043, 0.4038,\n",
       "            0.4036, 0.4026, 0.4019, 0.4014, 0.401 , 0.3982, 0.3972, 0.3965,\n",
       "            0.3955, 0.3938, 0.392 , 0.3918, 0.3914, 0.391 , 0.3906, 0.3904,\n",
       "            0.3901, 0.39  , 0.3887, 0.3865, 0.3845, 0.3843, 0.3835, 0.3826,\n",
       "            0.382 , 0.3813, 0.38  , 0.3796, 0.3794, 0.379 , 0.3784, 0.378 ,\n",
       "            0.3777, 0.3752, 0.375 , 0.3745, 0.3743, 0.372 , 0.3718, 0.3699,\n",
       "            0.3696, 0.3694, 0.3667, 0.366 , 0.3633, 0.3608, 0.3599, 0.358 ,\n",
       "            0.3552, 0.355 , 0.3538, 0.3518, 0.3494, 0.349 , 0.3489, 0.3481,\n",
       "            0.3467, 0.3462, 0.346 , 0.3455, 0.3452, 0.344 , 0.3408, 0.3403,\n",
       "            0.3386, 0.3354, 0.332 , 0.3315, 0.3293, 0.328 , 0.3262, 0.3252,\n",
       "            0.3242, 0.323 , 0.3228, 0.3218, 0.3213, 0.321 , 0.3193, 0.3186,\n",
       "            0.3174, 0.3171, 0.317 , 0.3152, 0.3123, 0.312 , 0.3098, 0.3093,\n",
       "            0.3074, 0.3025, 0.3022, 0.302 , 0.3018, 0.3015, 0.3005, 0.2988,\n",
       "            0.2974, 0.296 , 0.2957, 0.295 , 0.294 , 0.2937, 0.293 , 0.2925,\n",
       "            0.2915, 0.2908, 0.2896, 0.2893, 0.2878, 0.2869, 0.2864, 0.286 ,\n",
       "            0.2832, 0.28  , 0.2795, 0.2786, 0.2756, 0.2747, 0.2744, 0.2742,\n",
       "            0.274 , 0.271 , 0.2703, 0.2683, 0.2664, 0.2656, 0.2654, 0.2651,\n",
       "            0.2646, 0.2644, 0.2642, 0.2637, 0.263 , 0.2622, 0.2617, 0.2607,\n",
       "            0.2605, 0.2595, 0.2588, 0.258 , 0.2576, 0.2546, 0.2542, 0.252 ,\n",
       "            0.2515, 0.2512, 0.2466, 0.2462, 0.2451, 0.2428, 0.2417, 0.2394,\n",
       "            0.2388, 0.2383, 0.2335, 0.2314, 0.2285, 0.2281, 0.2272, 0.22  ,\n",
       "            0.2139, 0.1991, 0.1968, 0.1848, 0.1838, 0.1813, 0.1698, 0.1666],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.13076924, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.1       ,\n",
       "            0.10833333, 0.10833333, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.125     , 0.13333334, 0.13333334, 0.15      , 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.21666667, 0.225     , 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.28333333, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.46666667, 0.475     , 0.49166667, 0.5       , 0.5       ,\n",
       "            0.5083333 , 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.56153846, 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.86923075, 0.8769231 , 0.88461536, 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6157, 0.595 , 0.5684, 0.5605, 0.56  , 0.558 , 0.55  ,\n",
       "            0.5493, 0.5464, 0.546 , 0.54  , 0.535 , 0.5327, 0.5283, 0.506 ,\n",
       "            0.504 , 0.4993, 0.4973, 0.4885, 0.4814, 0.48  , 0.4773, 0.4758,\n",
       "            0.4753, 0.4744, 0.473 , 0.47  , 0.4685, 0.4675, 0.4666, 0.4656,\n",
       "            0.4634, 0.4626, 0.4612, 0.4604, 0.4602, 0.46  , 0.4597, 0.4592,\n",
       "            0.4587, 0.4578, 0.4575, 0.4548, 0.4546, 0.4539, 0.4536, 0.4526,\n",
       "            0.4524, 0.449 , 0.4487, 0.4468, 0.4458, 0.4453, 0.4436, 0.4434,\n",
       "            0.4429, 0.4421, 0.4414, 0.4395, 0.439 , 0.4387, 0.438 , 0.4377,\n",
       "            0.436 , 0.4346, 0.4329, 0.4326, 0.432 , 0.4304, 0.4302, 0.4297,\n",
       "            0.4277, 0.4263, 0.4246, 0.4243, 0.4236, 0.4233, 0.4226, 0.4216,\n",
       "            0.4214, 0.4197, 0.4172, 0.417 , 0.4167, 0.4165, 0.4148, 0.4136,\n",
       "            0.413 , 0.4126, 0.4124, 0.409 , 0.405 , 0.4045, 0.4033, 0.403 ,\n",
       "            0.4023, 0.4016, 0.3997, 0.3984, 0.3982, 0.3958, 0.395 , 0.3936,\n",
       "            0.3916, 0.3894, 0.3892, 0.3877, 0.386 , 0.3855, 0.3826, 0.3794,\n",
       "            0.379 , 0.3784, 0.3777, 0.3726, 0.3716, 0.3657, 0.3655, 0.3638,\n",
       "            0.3635, 0.3623, 0.3606, 0.3604, 0.358 , 0.357 , 0.3535, 0.3533,\n",
       "            0.3525, 0.3523, 0.349 , 0.3474, 0.3467, 0.3464, 0.344 , 0.3438,\n",
       "            0.3433, 0.342 , 0.3406, 0.339 , 0.3386, 0.3384, 0.3362, 0.3345,\n",
       "            0.3315, 0.3306, 0.3262, 0.3254, 0.3247, 0.324 , 0.3208, 0.3193,\n",
       "            0.3164, 0.316 , 0.3157, 0.3142, 0.3118, 0.3105, 0.3093, 0.3052,\n",
       "            0.305 , 0.3044, 0.304 , 0.3025, 0.301 , 0.3005, 0.3   , 0.298 ,\n",
       "            0.2976, 0.2966, 0.2961, 0.2957, 0.2952, 0.295 , 0.2932, 0.2922,\n",
       "            0.2915, 0.2903, 0.2898, 0.2893, 0.288 , 0.2864, 0.2861, 0.286 ,\n",
       "            0.2852, 0.283 , 0.282 , 0.2817, 0.281 , 0.28  , 0.2793, 0.2783,\n",
       "            0.277 , 0.2761, 0.2717, 0.271 , 0.27  , 0.2693, 0.2688, 0.2683,\n",
       "            0.2664, 0.266 , 0.2656, 0.264 , 0.2634, 0.262 , 0.2612, 0.2598,\n",
       "            0.2595, 0.2578, 0.2505, 0.2477, 0.2441, 0.2283, 0.2256, 0.2252,\n",
       "            0.2179, 0.2091, 0.1943, 0.1912, 0.178 , 0.1775, 0.1743, 0.162 ,\n",
       "            0.1588], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.24615385, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.075     , 0.075     , 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.1       , 0.10833333, 0.11666667, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15833333, 0.15833333,\n",
       "            0.16666667, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.475     , 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.625     , 0.6333333 , 0.65      , 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.73333335, 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.23076923, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.654 , 0.6357, 0.6035, 0.5967, 0.5957, 0.5947, 0.587 ,\n",
       "            0.586 , 0.584 , 0.58  , 0.576 , 0.568 , 0.567 , 0.561 , 0.537 ,\n",
       "            0.5347, 0.5303, 0.5293, 0.524 , 0.518 , 0.5117, 0.5093, 0.508 ,\n",
       "            0.5054, 0.505 , 0.5044, 0.5024, 0.5015, 0.4995, 0.4976, 0.4973,\n",
       "            0.496 , 0.4954, 0.4932, 0.492 , 0.491 , 0.4905, 0.4902, 0.489 ,\n",
       "            0.4868, 0.4866, 0.4856, 0.4846, 0.483 , 0.4802, 0.4797, 0.478 ,\n",
       "            0.4773, 0.4763, 0.4756, 0.4753, 0.475 , 0.4734, 0.4731, 0.4724,\n",
       "            0.4722, 0.472 , 0.47  , 0.464 , 0.4636, 0.4631, 0.463 , 0.4622,\n",
       "            0.4614, 0.461 , 0.4602, 0.46  , 0.4595, 0.4592, 0.459 , 0.4585,\n",
       "            0.4556, 0.4553, 0.4546, 0.4543, 0.453 , 0.452 , 0.4507, 0.4485,\n",
       "            0.4465, 0.4458, 0.445 , 0.4436, 0.4434, 0.442 , 0.4414, 0.441 ,\n",
       "            0.437 , 0.4368, 0.4355, 0.4324, 0.4307, 0.4304, 0.4272, 0.4258,\n",
       "            0.424 , 0.4236, 0.421 , 0.4202, 0.42  , 0.4175, 0.4172, 0.4163,\n",
       "            0.4153, 0.4136, 0.4133, 0.4128, 0.4116, 0.405 , 0.4026, 0.4023,\n",
       "            0.4019, 0.4016, 0.4014, 0.3984, 0.3982, 0.391 , 0.388 , 0.3862,\n",
       "            0.3835, 0.3809, 0.3804, 0.3765, 0.3762, 0.3752, 0.375 , 0.3748,\n",
       "            0.3745, 0.3718, 0.3708, 0.3706, 0.3662, 0.3643, 0.363 , 0.3625,\n",
       "            0.362 , 0.361 , 0.3586, 0.358 , 0.3574, 0.3572, 0.352 , 0.3508,\n",
       "            0.3477, 0.3472, 0.3464, 0.3452, 0.3438, 0.3416, 0.3403, 0.3396,\n",
       "            0.3384, 0.3376, 0.3362, 0.3325, 0.331 , 0.3308, 0.3303, 0.33  ,\n",
       "            0.3276, 0.326 , 0.3252, 0.323 , 0.3225, 0.3218, 0.3188, 0.3186,\n",
       "            0.3179, 0.315 , 0.3147, 0.3145, 0.314 , 0.313 , 0.3105, 0.3103,\n",
       "            0.3074, 0.3064, 0.306 , 0.3047, 0.3044, 0.304 , 0.3032, 0.3025,\n",
       "            0.302 , 0.3005, 0.3003, 0.3   , 0.298 , 0.2969, 0.2961, 0.2937,\n",
       "            0.2932, 0.2908, 0.2878, 0.2864, 0.2861, 0.2844, 0.2837, 0.2815,\n",
       "            0.281 , 0.2808, 0.2793, 0.2786, 0.2761, 0.2747, 0.2744, 0.2693,\n",
       "            0.269 , 0.2659, 0.2632, 0.2627, 0.2612, 0.26  , 0.2595, 0.258 ,\n",
       "            0.2563, 0.2482, 0.2474, 0.2411, 0.224 , 0.2234, 0.2205, 0.2144,\n",
       "            0.2037, 0.1885, 0.1844, 0.1707, 0.1666, 0.1542, 0.151 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.52307695, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.06666667, 0.06666667, 0.075     , 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.125     , 0.13333334, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35      , 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.40833333, 0.41666666,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.5833333 , 0.59166664, 0.6       , 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.24615385, 0.25384617, 0.26923078, 0.2846154 , 0.2923077 ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.3846154 ,\n",
       "            0.3923077 , 0.4076923 , 0.41538462, 0.42307693, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.88461536, 0.8923077 , 0.8923077 , 0.9       , 0.9       ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9230769 , 0.93846154, 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6997, 0.6826, 0.6475, 0.64  , 0.6396, 0.6387, 0.6313,\n",
       "            0.631 , 0.63  , 0.6274, 0.622 , 0.619 , 0.61  , 0.6084, 0.602 ,\n",
       "            0.576 , 0.575 , 0.5728, 0.5684, 0.568 , 0.5605, 0.5547, 0.554 ,\n",
       "            0.5527, 0.55  , 0.5493, 0.5483, 0.5464, 0.5425, 0.542 , 0.541 ,\n",
       "            0.5376, 0.537 , 0.5347, 0.534 , 0.5337, 0.533 , 0.5283, 0.5273,\n",
       "            0.526 , 0.5234, 0.521 , 0.52  , 0.519 , 0.5186, 0.5176, 0.5166,\n",
       "            0.516 , 0.5156, 0.5146, 0.512 , 0.5117, 0.509 , 0.506 , 0.505 ,\n",
       "            0.504 , 0.5024, 0.5015, 0.501 , 0.5005, 0.4966, 0.495 , 0.4944,\n",
       "            0.4941, 0.4937, 0.493 , 0.4927, 0.4922, 0.491 , 0.4902, 0.49  ,\n",
       "            0.4893, 0.4885, 0.4844, 0.4814, 0.4812, 0.4805, 0.48  , 0.4795,\n",
       "            0.478 , 0.4758, 0.475 , 0.4739, 0.473 , 0.4683, 0.4668, 0.4656,\n",
       "            0.4646, 0.4595, 0.4585, 0.4583, 0.458 , 0.456 , 0.4556, 0.4553,\n",
       "            0.4514, 0.4512, 0.4492, 0.4487, 0.446 , 0.4436, 0.4421, 0.4414,\n",
       "            0.4387, 0.4373, 0.4358, 0.434 , 0.4314, 0.431 , 0.428 , 0.4277,\n",
       "            0.4268, 0.4263, 0.425 , 0.4187, 0.4124, 0.4053, 0.4011, 0.3992,\n",
       "            0.3965, 0.3962, 0.394 , 0.3928, 0.3926, 0.3923, 0.3909, 0.3901,\n",
       "            0.39  , 0.3862, 0.386 , 0.3848, 0.3809, 0.3804, 0.376 , 0.3752,\n",
       "            0.3738, 0.3716, 0.3704, 0.3694, 0.3691, 0.3674, 0.366 , 0.363 ,\n",
       "            0.3599, 0.3586, 0.358 , 0.3567, 0.3552, 0.351 , 0.3499, 0.3489,\n",
       "            0.3484, 0.347 , 0.3464, 0.3425, 0.342 , 0.3408, 0.3406, 0.3394,\n",
       "            0.3389, 0.3381, 0.3372, 0.3337, 0.3308, 0.3289, 0.3281, 0.3254,\n",
       "            0.3252, 0.3237, 0.3232, 0.3215, 0.321 , 0.3206, 0.32  , 0.3198,\n",
       "            0.3154, 0.312 , 0.3113, 0.3108, 0.31  , 0.3088, 0.3076, 0.307 ,\n",
       "            0.3062, 0.3042, 0.3022, 0.3018, 0.3013, 0.3005, 0.2998, 0.2993,\n",
       "            0.2979, 0.2966, 0.2898, 0.289 , 0.2869, 0.2842, 0.283 , 0.2783,\n",
       "            0.2712, 0.2705, 0.2686, 0.2644, 0.2637, 0.2622, 0.2595, 0.2585,\n",
       "            0.251 , 0.2467, 0.2407, 0.223 , 0.2217, 0.2177, 0.2133, 0.1996,\n",
       "            0.1844, 0.1798, 0.1652, 0.1647, 0.1605, 0.1476, 0.1443],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00833333, dtype=float32),\n",
       "    'tpr': array(0.66923076, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.06666667, 0.06666667,\n",
       "            0.06666667, 0.06666667, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.25      , 0.25833333, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.5083333 , 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.80833334, 0.81666666, 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.3       , 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.5       ,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.56153846, 0.5692308 , 0.5846154 , 0.5923077 , 0.6076923 ,\n",
       "            0.61538464, 0.63076925, 0.63076925, 0.63846153, 0.65384614,\n",
       "            0.66923076, 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.734 , 0.7207, 0.6807, 0.6753, 0.6743, 0.671 , 0.668 ,\n",
       "            0.667 , 0.661 , 0.656 , 0.6543, 0.643 , 0.6426, 0.6333, 0.611 ,\n",
       "            0.6084, 0.604 , 0.603 , 0.602 , 0.6   , 0.5938, 0.586 , 0.5854,\n",
       "            0.585 , 0.581 , 0.5806, 0.5796, 0.573 , 0.5723, 0.5713, 0.571 ,\n",
       "            0.569 , 0.568 , 0.5664, 0.565 , 0.564 , 0.5625, 0.562 , 0.5605,\n",
       "            0.555 , 0.554 , 0.5537, 0.551 , 0.5483, 0.547 , 0.5464, 0.545 ,\n",
       "            0.544 , 0.5435, 0.542 , 0.5415, 0.5405, 0.54  , 0.5386, 0.5366,\n",
       "            0.5327, 0.5303, 0.5293, 0.529 , 0.5254, 0.5244, 0.521 , 0.5205,\n",
       "            0.52  , 0.518 , 0.517 , 0.5156, 0.515 , 0.513 , 0.5127, 0.5117,\n",
       "            0.509 , 0.506 , 0.503 , 0.5024, 0.4993, 0.4985, 0.4973, 0.495 ,\n",
       "            0.494 , 0.4934, 0.491 , 0.4895, 0.4885, 0.4858, 0.485 , 0.4841,\n",
       "            0.4792, 0.4788, 0.478 , 0.4763, 0.476 , 0.4739, 0.47  , 0.4697,\n",
       "            0.4695, 0.4673, 0.4663, 0.4622, 0.4612, 0.4597, 0.4583, 0.458 ,\n",
       "            0.4558, 0.4553, 0.4507, 0.4487, 0.4485, 0.4429, 0.4421, 0.4412,\n",
       "            0.4377, 0.4373, 0.4307, 0.43  , 0.422 , 0.4143, 0.414 , 0.412 ,\n",
       "            0.4102, 0.4092, 0.4067, 0.4055, 0.4048, 0.403 , 0.4001, 0.4   ,\n",
       "            0.3992, 0.3967, 0.3962, 0.393 , 0.3923, 0.392 , 0.3918, 0.3887,\n",
       "            0.3865, 0.3845, 0.383 , 0.3823, 0.3801, 0.3774, 0.375 , 0.3684,\n",
       "            0.367 , 0.3665, 0.3662, 0.3635, 0.362 , 0.3616, 0.3608, 0.3555,\n",
       "            0.355 , 0.3538, 0.3533, 0.353 , 0.3525, 0.3518, 0.3513, 0.3508,\n",
       "            0.35  , 0.3499, 0.348 , 0.3477, 0.3418, 0.3416, 0.3396, 0.3384,\n",
       "            0.3345, 0.334 , 0.3333, 0.3328, 0.3323, 0.3289, 0.3274, 0.3271,\n",
       "            0.3267, 0.3247, 0.3235, 0.3228, 0.3203, 0.3188, 0.3186, 0.3184,\n",
       "            0.3176, 0.3145, 0.3127, 0.311 , 0.31  , 0.3096, 0.3093, 0.308 ,\n",
       "            0.3071, 0.3064, 0.306 , 0.3052, 0.304 , 0.298 , 0.2947, 0.2898,\n",
       "            0.2869, 0.2852, 0.28  , 0.2783, 0.2754, 0.2664, 0.2642, 0.2612,\n",
       "            0.2593, 0.258 , 0.2573, 0.2566, 0.2544, 0.2515, 0.2402, 0.2343,\n",
       "            0.2203, 0.2157, 0.2103, 0.2063, 0.1929, 0.1758, 0.1709, 0.156 ,\n",
       "            0.1554, 0.1511, 0.1385, 0.1349], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.025, dtype=float32),\n",
       "    'tpr': array(0.7923077, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05833333, 0.05833333, 0.06666667, 0.06666667, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.36666667, 0.38333333,\n",
       "            0.38333333, 0.39166668, 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.81666666,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.74615383, 0.76153845,\n",
       "            0.77692306, 0.7846154 , 0.7846154 , 0.7923077 , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7646, 0.7563, 0.7114, 0.709 , 0.7085, 0.706 , 0.7036,\n",
       "            0.7026, 0.694 , 0.691 , 0.6846, 0.677 , 0.6743, 0.664 , 0.6577,\n",
       "            0.6475, 0.64  , 0.638 , 0.6343, 0.633 , 0.632 , 0.629 , 0.628 ,\n",
       "            0.623 , 0.622 , 0.6167, 0.613 , 0.6113, 0.611 , 0.6094, 0.606 ,\n",
       "            0.602 , 0.6016, 0.601 , 0.6006, 0.5957, 0.595 , 0.5923, 0.591 ,\n",
       "            0.5894, 0.589 , 0.5874, 0.5845, 0.584 , 0.5806, 0.58  , 0.578 ,\n",
       "            0.576 , 0.5747, 0.573 , 0.5723, 0.5703, 0.57  , 0.5684, 0.5664,\n",
       "            0.566 , 0.565 , 0.56  , 0.559 , 0.5557, 0.555 , 0.5537, 0.552 ,\n",
       "            0.5513, 0.5503, 0.5493, 0.548 , 0.546 , 0.545 , 0.543 , 0.54  ,\n",
       "            0.539 , 0.5376, 0.537 , 0.5366, 0.536 , 0.535 , 0.5347, 0.5337,\n",
       "            0.53  , 0.5283, 0.5273, 0.527 , 0.5264, 0.525 , 0.524 , 0.523 ,\n",
       "            0.52  , 0.5117, 0.507 , 0.5034, 0.502 , 0.5005, 0.5   , 0.499 ,\n",
       "            0.4958, 0.4902, 0.4878, 0.4846, 0.4836, 0.483 , 0.4805, 0.4792,\n",
       "            0.4749, 0.474 , 0.4722, 0.465 , 0.4644, 0.46  , 0.4587, 0.457 ,\n",
       "            0.456 , 0.447 , 0.441 , 0.4368, 0.434 , 0.4312, 0.4272, 0.4238,\n",
       "            0.423 , 0.4207, 0.4155, 0.4143, 0.4136, 0.4126, 0.4124, 0.411 ,\n",
       "            0.41  , 0.4075, 0.4053, 0.4045, 0.4038, 0.4014, 0.4011, 0.4006,\n",
       "            0.4001, 0.3994, 0.398 , 0.3906, 0.3904, 0.389 , 0.3867, 0.3843,\n",
       "            0.382 , 0.3809, 0.38  , 0.3774, 0.3772, 0.374 , 0.3718, 0.3708,\n",
       "            0.37  , 0.3694, 0.3684, 0.3662, 0.363 , 0.3604, 0.3596, 0.3594,\n",
       "            0.3582, 0.355 , 0.3503, 0.35  , 0.3484, 0.3474, 0.344 , 0.3438,\n",
       "            0.3433, 0.3418, 0.3398, 0.339 , 0.3364, 0.3362, 0.3345, 0.3337,\n",
       "            0.332 , 0.3306, 0.329 , 0.3286, 0.3271, 0.3252, 0.325 , 0.324 ,\n",
       "            0.3218, 0.3215, 0.3203, 0.3198, 0.3186, 0.3164, 0.3145, 0.312 ,\n",
       "            0.3086, 0.3071, 0.3064, 0.2988, 0.2952, 0.2935, 0.2869, 0.2844,\n",
       "            0.28  , 0.2769, 0.2744, 0.2654, 0.2642, 0.2612, 0.258 , 0.2566,\n",
       "            0.2556, 0.2546, 0.253 , 0.2527, 0.2367, 0.2311, 0.2185, 0.2114,\n",
       "            0.2051, 0.2029, 0.1874, 0.1698, 0.1644, 0.149 , 0.1481, 0.1437,\n",
       "            0.131 , 0.1271], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04166667, dtype=float32),\n",
       "    'tpr': array(0.86153847, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.06666667, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.11666667,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.35      , 0.36666667, 0.375     , 0.38333333,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.65      , 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.18461539, 0.2       , 0.20769231,\n",
       "            0.21538462, 0.23076923, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.4846154 , 0.4923077 , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6076923 , 0.61538464,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.66923076, 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.7307692 , 0.73846155, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.7886 , 0.7847 , 0.739  , 0.7363 , 0.736  , 0.7354 ,\n",
       "            0.7324 , 0.731  , 0.7305 , 0.72   , 0.719  , 0.709  , 0.704  ,\n",
       "            0.7    , 0.6973 , 0.6875 , 0.686  , 0.6763 , 0.6655 , 0.665  ,\n",
       "            0.659  , 0.658  , 0.657  , 0.6553 , 0.6475 , 0.6445 , 0.644  ,\n",
       "            0.641  , 0.639  , 0.635  , 0.634  , 0.6284 , 0.624  , 0.623  ,\n",
       "            0.622  , 0.621  , 0.6167 , 0.616  , 0.614  , 0.612  , 0.611  ,\n",
       "            0.609  , 0.6084 , 0.608  , 0.6064 , 0.6055 , 0.6016 , 0.6    ,\n",
       "            0.597  , 0.595  , 0.594  , 0.5938 , 0.591  , 0.59   , 0.589  ,\n",
       "            0.588  , 0.586  , 0.5815 , 0.5806 , 0.58   , 0.5737 , 0.573  ,\n",
       "            0.5728 , 0.5713 , 0.571  , 0.57   , 0.562  , 0.5615 , 0.561  ,\n",
       "            0.56   , 0.5596 , 0.5586 , 0.557  , 0.5566 , 0.555  , 0.5547 ,\n",
       "            0.554  , 0.553  , 0.5513 , 0.55   , 0.5464 , 0.544  , 0.5405 ,\n",
       "            0.536  , 0.5327 , 0.5317 , 0.5283 , 0.5254 , 0.5234 , 0.5215 ,\n",
       "            0.52   , 0.5186 , 0.5166 , 0.5156 , 0.507  , 0.5054 , 0.505  ,\n",
       "            0.5044 , 0.503  , 0.5024 , 0.502  , 0.4973 , 0.495  , 0.4946 ,\n",
       "            0.4934 , 0.4885 , 0.487  , 0.486  , 0.4827 , 0.4785 , 0.4768 ,\n",
       "            0.4727 , 0.4714 , 0.4688 , 0.4668 , 0.4624 , 0.4543 , 0.453  ,\n",
       "            0.4443 , 0.4412 , 0.437  , 0.432  , 0.4307 , 0.4282 , 0.4277 ,\n",
       "            0.4246 , 0.422  , 0.421  , 0.4202 , 0.4197 , 0.4172 , 0.4165 ,\n",
       "            0.4158 , 0.4136 , 0.4114 , 0.4106 , 0.41   , 0.4092 , 0.407  ,\n",
       "            0.405  , 0.3955 , 0.3953 , 0.3945 , 0.39   , 0.3892 , 0.3872 ,\n",
       "            0.3865 , 0.3857 , 0.3843 , 0.3838 , 0.383  , 0.382  , 0.377  ,\n",
       "            0.3718 , 0.3716 , 0.3691 , 0.366  , 0.3655 , 0.3652 , 0.3633 ,\n",
       "            0.362  , 0.3616 , 0.357  , 0.3564 , 0.3562 , 0.3499 , 0.3494 ,\n",
       "            0.349  , 0.3489 , 0.347  , 0.3457 , 0.3445 , 0.344  , 0.3408 ,\n",
       "            0.3406 , 0.3403 , 0.339  , 0.3386 , 0.338  , 0.3337 , 0.3335 ,\n",
       "            0.3323 , 0.3315 , 0.3306 , 0.3296 , 0.328  , 0.327  , 0.3257 ,\n",
       "            0.3242 , 0.32   , 0.315  , 0.3088 , 0.3057 , 0.3032 , 0.3025 ,\n",
       "            0.2942 , 0.2922 , 0.2903 , 0.2805 , 0.278  , 0.2742 , 0.27   ,\n",
       "            0.2686 , 0.259  , 0.2588 , 0.2573 , 0.2563 , 0.256  , 0.2515 ,\n",
       "            0.2512 , 0.249  , 0.2478 , 0.2474 , 0.2462 , 0.2281 , 0.223  ,\n",
       "            0.2123 , 0.2028 , 0.1953 , 0.1947 , 0.178  , 0.1598 , 0.1539 ,\n",
       "            0.1384 , 0.1371 , 0.1327 , 0.12024, 0.11633], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.05, dtype=float32),\n",
       "    'tpr': array(0.9307692, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.075     , 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.10833333, 0.11666667, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25      , 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.625     , 0.6333333 , 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.80833334, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.23076923, 0.23846154, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.3846154 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.56153846, 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.6615385 , 0.66923076, 0.6846154 , 0.6923077 ,\n",
       "            0.7076923 , 0.7153846 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.82   , 0.8193 , 0.7773 , 0.7715 , 0.769  , 0.768  ,\n",
       "            0.7676 , 0.763  , 0.7563 , 0.755  , 0.7417 , 0.74   , 0.738  ,\n",
       "            0.7354 , 0.7266 , 0.7207 , 0.716  , 0.7046 , 0.704  , 0.701  ,\n",
       "            0.697  , 0.6963 , 0.693  , 0.6924 , 0.6895 , 0.6855 , 0.682  ,\n",
       "            0.6816 , 0.6763 , 0.673  , 0.672  , 0.6714 , 0.6704 , 0.6665 ,\n",
       "            0.663  , 0.658  , 0.6567 , 0.6533 , 0.653  , 0.652  , 0.6484 ,\n",
       "            0.6465 , 0.6455 , 0.6445 , 0.643  , 0.641  , 0.639  , 0.6357 ,\n",
       "            0.635  , 0.631  , 0.6304 , 0.626  , 0.6255 , 0.623  , 0.6226 ,\n",
       "            0.622  , 0.6216 , 0.62   , 0.6196 , 0.6167 , 0.615  , 0.6147 ,\n",
       "            0.6055 , 0.604  , 0.6035 , 0.603  , 0.6006 , 0.5967 , 0.595  ,\n",
       "            0.5933 , 0.593  , 0.5913 , 0.591  , 0.5884 , 0.5864 , 0.586  ,\n",
       "            0.5854 , 0.585  , 0.584  , 0.5835 , 0.579  , 0.5776 , 0.576  ,\n",
       "            0.5757 , 0.5728 , 0.5654 , 0.5635 , 0.5596 , 0.5557 , 0.5547 ,\n",
       "            0.554  , 0.5513 , 0.5503 , 0.5493 , 0.5483 , 0.543  , 0.542  ,\n",
       "            0.538  , 0.5376 , 0.533  , 0.531  , 0.5303 , 0.53   , 0.5273 ,\n",
       "            0.5225 , 0.5205 , 0.519  , 0.518  , 0.5156 , 0.514  , 0.512  ,\n",
       "            0.508  , 0.5073 , 0.506  , 0.4954 , 0.4944 , 0.494  , 0.4927 ,\n",
       "            0.4875 , 0.4797 , 0.4795 , 0.4712 , 0.47   , 0.4644 , 0.454  ,\n",
       "            0.4539 , 0.4512 , 0.4485 , 0.4465 , 0.4426 , 0.442  , 0.437  ,\n",
       "            0.4348 , 0.4336 , 0.433  , 0.432  , 0.4316 , 0.4307 , 0.4302 ,\n",
       "            0.4282 , 0.4238 , 0.4233 , 0.4192 , 0.411  , 0.4106 , 0.4094 ,\n",
       "            0.4077 , 0.407  , 0.4067 , 0.406  , 0.4058 , 0.4055 , 0.4043 ,\n",
       "            0.3997 , 0.397  , 0.3901 , 0.3867 , 0.3855 , 0.3838 , 0.3828 ,\n",
       "            0.3801 , 0.38   , 0.3765 , 0.3757 , 0.3745 , 0.3743 , 0.369  ,\n",
       "            0.3662 , 0.3652 , 0.365  , 0.3643 , 0.3625 , 0.3623 , 0.3596 ,\n",
       "            0.3567 , 0.355  , 0.3547 , 0.3542 , 0.3533 , 0.3508 , 0.35   ,\n",
       "            0.3477 , 0.3474 , 0.346  , 0.3457 , 0.3438 , 0.3435 , 0.3428 ,\n",
       "            0.342  , 0.336  , 0.331  , 0.3276 , 0.3206 , 0.3115 , 0.3093 ,\n",
       "            0.3052 , 0.3044 , 0.298  , 0.2954 , 0.2908 , 0.28   , 0.277  ,\n",
       "            0.2737 , 0.2688 , 0.2686 , 0.2576 , 0.2573 , 0.2554 , 0.2524 ,\n",
       "            0.2515 , 0.2493 , 0.2455 , 0.2451 , 0.244  , 0.2246 , 0.2194 ,\n",
       "            0.2114 , 0.1987 , 0.19   , 0.1897 , 0.1729 , 0.1533 , 0.1475 ,\n",
       "            0.1313 , 0.1298 , 0.1255 , 0.11316, 0.10876], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.05833333, dtype=float32),\n",
       "    'tpr': array(0.95384616, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.10833333, 0.11666667,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25      , 0.25833333, 0.26666668, 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.61538464, 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6846154 , 0.7       ,\n",
       "            0.7076923 , 0.7076923 , 0.7153846 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8230769 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.845  , 0.842  , 0.8076 , 0.799  , 0.798  , 0.796  ,\n",
       "            0.791  , 0.7876 , 0.785  , 0.7803 , 0.768  , 0.766  , 0.7617 ,\n",
       "            0.7603 , 0.7485 , 0.7446 , 0.737  , 0.7285 , 0.726  , 0.7246 ,\n",
       "            0.7207 , 0.7188 , 0.717  , 0.716  , 0.7153 , 0.711  , 0.705  ,\n",
       "            0.703  , 0.7007 , 0.7    , 0.696  , 0.691  , 0.69   , 0.6895 ,\n",
       "            0.684  , 0.6807 , 0.6753 , 0.674  , 0.6704 , 0.669  , 0.6685 ,\n",
       "            0.6646 , 0.664  , 0.6626 , 0.6606 , 0.66   , 0.659  , 0.657  ,\n",
       "            0.653  , 0.651  , 0.6484 , 0.647  , 0.646  , 0.6426 , 0.641  ,\n",
       "            0.6396 , 0.6387 , 0.637  , 0.6357 , 0.631  , 0.6304 , 0.63   ,\n",
       "            0.624  , 0.6235 , 0.623  , 0.62   , 0.618  , 0.617  , 0.6133 ,\n",
       "            0.612  , 0.6094 , 0.607  , 0.6045 , 0.604  , 0.6035 , 0.603  ,\n",
       "            0.6006 , 0.5996 , 0.599  , 0.5986 , 0.598  , 0.5933 , 0.593  ,\n",
       "            0.5923 , 0.5894 , 0.5864 , 0.576  , 0.575  , 0.571  , 0.5684 ,\n",
       "            0.5664 , 0.566  , 0.563  , 0.5605 , 0.5493 , 0.5483 , 0.5464 ,\n",
       "            0.546  , 0.545  , 0.542  , 0.54   , 0.533  , 0.5327 , 0.532  ,\n",
       "            0.5273 , 0.527  , 0.5264 , 0.5254 , 0.517  , 0.5156 , 0.5146 ,\n",
       "            0.509  , 0.508  , 0.503  , 0.501  , 0.4922 , 0.4873 , 0.4866 ,\n",
       "            0.4795 , 0.4778 , 0.472  , 0.462  , 0.4595 , 0.4575 , 0.4534 ,\n",
       "            0.4514 , 0.4482 , 0.447  , 0.4397 , 0.4387 , 0.4382 , 0.4363 ,\n",
       "            0.4358 , 0.4346 , 0.4338 , 0.4336 , 0.4314 , 0.4272 , 0.4238 ,\n",
       "            0.423  , 0.4229 , 0.4185 , 0.4143 , 0.4106 , 0.41   , 0.4097 ,\n",
       "            0.4084 , 0.4082 , 0.4075 , 0.4072 , 0.4055 , 0.4028 , 0.4016 ,\n",
       "            0.3987 , 0.3914 , 0.3872 , 0.3833 , 0.3826 , 0.3823 , 0.3804 ,\n",
       "            0.3801 , 0.376  , 0.3752 , 0.375  , 0.372  , 0.365  , 0.3645 ,\n",
       "            0.3638 , 0.3635 , 0.362  , 0.3594 , 0.3577 , 0.3574 , 0.355  ,\n",
       "            0.3525 , 0.3513 , 0.351  , 0.3503 , 0.3486 , 0.3481 , 0.3452 ,\n",
       "            0.345  , 0.3447 , 0.3445 , 0.343  , 0.342  , 0.3408 , 0.34   ,\n",
       "            0.338  , 0.3313 , 0.3235 , 0.32   , 0.306  , 0.3052 , 0.2993 ,\n",
       "            0.298  , 0.2976 , 0.2874 , 0.2815 , 0.271  , 0.268  , 0.2637 ,\n",
       "            0.2622 , 0.2588 , 0.2537 , 0.2534 , 0.2496 , 0.2482 , 0.2473 ,\n",
       "            0.2388 , 0.2352 , 0.2346 , 0.2332 , 0.2139 , 0.2081 , 0.2064 ,\n",
       "            0.1901 , 0.1792 , 0.1782 , 0.1641 , 0.1417 , 0.1361 , 0.12036,\n",
       "            0.1192 , 0.1152 , 0.1034 , 0.0986 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.075, dtype=float32),\n",
       "    'tpr': array(0.96153843, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.1       , 0.10833333, 0.11666667,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.46666667, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.52307695,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6769231 , 0.6846154 , 0.7       , 0.7076923 ,\n",
       "            0.7076923 , 0.7076923 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8       , 0.8076923 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.869  , 0.8623 , 0.8335 , 0.824  , 0.823  , 0.8228 ,\n",
       "            0.822  , 0.8135 , 0.811  , 0.8105 , 0.803  , 0.794  , 0.79   ,\n",
       "            0.789  , 0.787  , 0.7783 , 0.768  , 0.766  , 0.755  , 0.7544 ,\n",
       "            0.7534 , 0.7466 , 0.7456 , 0.744  , 0.743  , 0.734  , 0.7334 ,\n",
       "            0.729  , 0.7285 , 0.7275 , 0.727  , 0.724  , 0.718  , 0.7173 ,\n",
       "            0.717  , 0.711  , 0.7085 , 0.7017 , 0.701  , 0.697  , 0.6963 ,\n",
       "            0.695  , 0.6924 , 0.6914 , 0.691  , 0.6885 , 0.6875 , 0.6865 ,\n",
       "            0.6855 , 0.6826 , 0.682  , 0.6787 , 0.6772 , 0.6724 , 0.6714 ,\n",
       "            0.6694 , 0.667  , 0.666  , 0.663  , 0.6626 , 0.6616 , 0.661  ,\n",
       "            0.6567 , 0.655  , 0.6543 , 0.6465 , 0.6455 , 0.6445 , 0.6436 ,\n",
       "            0.6426 , 0.641  , 0.6387 , 0.6353 , 0.6333 , 0.631  , 0.6304 ,\n",
       "            0.63   , 0.627  , 0.6255 , 0.625  , 0.623  , 0.6226 , 0.6216 ,\n",
       "            0.6206 , 0.6196 , 0.619  , 0.6157 , 0.6143 , 0.612  , 0.6064 ,\n",
       "            0.598  , 0.5957 , 0.595  , 0.5913 , 0.588  , 0.5864 , 0.585  ,\n",
       "            0.581  , 0.5806 , 0.5796 , 0.5713 , 0.5693 , 0.565  , 0.5635 ,\n",
       "            0.5625 , 0.559  , 0.552  , 0.5503 , 0.55   , 0.5454 , 0.5435 ,\n",
       "            0.543  , 0.5425 , 0.536  , 0.5337 , 0.533  , 0.5244 , 0.523  ,\n",
       "            0.521  , 0.5205 , 0.505  , 0.5044 , 0.503  , 0.4932 , 0.4912 ,\n",
       "            0.485  , 0.4753 , 0.475  , 0.474  , 0.4663 , 0.4626 , 0.4617 ,\n",
       "            0.457  , 0.454  , 0.4502 , 0.4475 , 0.4473 , 0.4453 , 0.445  ,\n",
       "            0.444  , 0.4421 , 0.442  , 0.4417 , 0.436  , 0.4336 , 0.431  ,\n",
       "            0.429  , 0.4275 , 0.4272 , 0.4233 , 0.4229 , 0.4224 , 0.421  ,\n",
       "            0.42   , 0.4175 , 0.414  , 0.4138 , 0.4111 , 0.4104 , 0.4058 ,\n",
       "            0.4036 , 0.4023 , 0.3923 , 0.3918 , 0.388  , 0.386  , 0.385  ,\n",
       "            0.3848 , 0.383  , 0.3794 , 0.3784 , 0.3765 , 0.3713 , 0.3696 ,\n",
       "            0.366  , 0.3655 , 0.363  , 0.3606 , 0.3604 , 0.3586 , 0.3584 ,\n",
       "            0.355  , 0.3545 , 0.354  , 0.3538 , 0.351  , 0.3484 , 0.3481 ,\n",
       "            0.3477 , 0.3464 , 0.3457 , 0.3452 , 0.3447 , 0.3413 , 0.3403 ,\n",
       "            0.3374 , 0.3352 , 0.3218 , 0.3193 , 0.3186 , 0.3035 , 0.3018 ,\n",
       "            0.2993 , 0.2942 , 0.2937 , 0.2832 , 0.2766 , 0.2646 , 0.262  ,\n",
       "            0.258  , 0.2566 , 0.2527 , 0.2496 , 0.2489 , 0.2463 , 0.2437 ,\n",
       "            0.2415 , 0.2407 , 0.2402 , 0.2322 , 0.2277 , 0.2274 , 0.2268 ,\n",
       "            0.206  , 0.2009 , 0.2004 , 0.1824 , 0.1704 , 0.1565 , 0.1328 ,\n",
       "            0.1271 , 0.11145, 0.1097 , 0.10614, 0.0945 , 0.0896 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.09166667, dtype=float32),\n",
       "    'tpr': array(0.96153843, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.10833333, 0.11666667, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.475     , 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26923078, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.66923076, 0.6769231 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.891  , 0.8813 , 0.8594 , 0.849  , 0.8486 , 0.847  ,\n",
       "            0.8467 , 0.837  , 0.835  , 0.833  , 0.826  , 0.82   , 0.8193 ,\n",
       "            0.812  , 0.807  , 0.795  , 0.7915 , 0.784  , 0.7812 , 0.781  ,\n",
       "            0.774  , 0.7734 , 0.772  , 0.771  , 0.7705 , 0.7617 , 0.757  ,\n",
       "            0.7563 , 0.7554 , 0.755  , 0.7524 , 0.7456 , 0.745  , 0.744  ,\n",
       "            0.739  , 0.737  , 0.7285 , 0.7246 , 0.7217 , 0.7188 , 0.717  ,\n",
       "            0.7153 , 0.7144 , 0.714  , 0.713  , 0.7095 , 0.709  , 0.705  ,\n",
       "            0.7046 , 0.699  , 0.696  , 0.6953 , 0.695  , 0.693  , 0.691  ,\n",
       "            0.6895 , 0.689  , 0.6875 , 0.6836 , 0.682  , 0.6807 , 0.68   ,\n",
       "            0.679  , 0.67   , 0.669  , 0.6675 , 0.667  , 0.6665 , 0.6655 ,\n",
       "            0.659  , 0.658  , 0.655  , 0.6543 , 0.6514 , 0.649  , 0.648  ,\n",
       "            0.6475 , 0.6455 , 0.644  , 0.641  , 0.64   , 0.6377 , 0.635  ,\n",
       "            0.627  , 0.622  , 0.618  , 0.615  , 0.6123 , 0.6113 , 0.6094 ,\n",
       "            0.6084 , 0.608  , 0.602  , 0.601  , 0.6006 , 0.5996 , 0.595  ,\n",
       "            0.592  , 0.5845 , 0.581  , 0.579  , 0.577  , 0.5723 , 0.5693 ,\n",
       "            0.5684 , 0.567  , 0.562  , 0.559  , 0.557  , 0.554  , 0.552  ,\n",
       "            0.542  , 0.541  , 0.5405 , 0.523  , 0.5205 , 0.5186 , 0.507  ,\n",
       "            0.505  , 0.4983 , 0.4941 , 0.4922 , 0.4868 , 0.4802 , 0.4775 ,\n",
       "            0.4756 , 0.4712 , 0.466  , 0.4617 , 0.458  , 0.4573 , 0.4565 ,\n",
       "            0.4558 , 0.455  , 0.4524 , 0.4504 , 0.45   , 0.4495 , 0.4417 ,\n",
       "            0.439  , 0.4385 , 0.4382 , 0.437  , 0.4368 , 0.4363 , 0.4346 ,\n",
       "            0.4343 , 0.4326 , 0.4248 , 0.421  , 0.4194 , 0.4163 , 0.4143 ,\n",
       "            0.4092 , 0.4084 , 0.4033 , 0.398  , 0.3933 , 0.3928 , 0.39   ,\n",
       "            0.3875 , 0.3845 , 0.3809 , 0.3801 , 0.3796 , 0.3782 , 0.3767 ,\n",
       "            0.3694 , 0.3667 , 0.3647 , 0.3635 , 0.3616 , 0.3586 , 0.3577 ,\n",
       "            0.3572 , 0.357  , 0.3538 , 0.3523 , 0.3518 , 0.3481 , 0.3472 ,\n",
       "            0.3455 , 0.344  , 0.3428 , 0.3394 , 0.336  , 0.3203 , 0.3188 ,\n",
       "            0.3157 , 0.3022 , 0.3015 , 0.298  , 0.29   , 0.2896 , 0.2776 ,\n",
       "            0.2705 , 0.258  , 0.2551 , 0.2532 , 0.2512 , 0.2466 , 0.2458 ,\n",
       "            0.2456 , 0.2448 , 0.2402 , 0.2347 , 0.234  , 0.2335 , 0.2244 ,\n",
       "            0.2197 , 0.2191 , 0.1978 , 0.1962 , 0.1918 , 0.1761 , 0.1615 ,\n",
       "            0.1495 , 0.1232 , 0.1178 , 0.1023 , 0.1007 , 0.09705, 0.086  ,\n",
       "            0.08093], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.09166667, dtype=float32),\n",
       "    'tpr': array(0.96153843, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.10833333, 0.11666667, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.2       , 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.35384616, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.66923076,\n",
       "            0.6769231 , 0.6769231 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9087 , 0.8955 , 0.881  , 0.869  , 0.8677 , 0.866  ,\n",
       "            0.858  , 0.851  , 0.8496 , 0.8438 , 0.8413 , 0.8384 , 0.832  ,\n",
       "            0.8296 , 0.8267 , 0.814  , 0.809  , 0.803  , 0.799  , 0.7964 ,\n",
       "            0.7925 , 0.792  , 0.79   , 0.7886 , 0.7803 , 0.779  , 0.774  ,\n",
       "            0.773  , 0.7725 , 0.772  , 0.771  , 0.7637 , 0.762  , 0.7617 ,\n",
       "            0.7554 , 0.753  , 0.746  , 0.745  , 0.7407 , 0.7383 , 0.737  ,\n",
       "            0.736  , 0.7354 , 0.7324 , 0.7305 , 0.73   , 0.726  , 0.7256 ,\n",
       "            0.722  , 0.7217 , 0.72   , 0.7153 , 0.715  , 0.7114 , 0.71   ,\n",
       "            0.7095 , 0.7065 , 0.7046 , 0.703  , 0.6997 , 0.696  , 0.6953 ,\n",
       "            0.694  , 0.6904 , 0.6855 , 0.684  , 0.683  , 0.682  , 0.681  ,\n",
       "            0.68   , 0.679  , 0.6733 , 0.673  , 0.6694 , 0.669  , 0.667  ,\n",
       "            0.6655 , 0.665  , 0.6616 , 0.661  , 0.66   , 0.6597 , 0.6587 ,\n",
       "            0.6562 , 0.655  , 0.654  , 0.649  , 0.639  , 0.637  , 0.635  ,\n",
       "            0.627  , 0.626  , 0.625  , 0.6235 , 0.6206 , 0.6196 , 0.6187 ,\n",
       "            0.6167 , 0.6143 , 0.609  , 0.606  , 0.6025 , 0.598  , 0.5933 ,\n",
       "            0.59   , 0.589  , 0.5874 , 0.5825 , 0.58   , 0.576  , 0.575  ,\n",
       "            0.5674 , 0.566  , 0.563  , 0.561  , 0.5537 , 0.553  , 0.5483 ,\n",
       "            0.53   , 0.5273 , 0.5244 , 0.51   , 0.5063 , 0.5    , 0.498  ,\n",
       "            0.4968 , 0.4902 , 0.485  , 0.4832 , 0.4812 , 0.4736 , 0.4688 ,\n",
       "            0.464  , 0.4597 , 0.4595 , 0.457  , 0.4558 , 0.4521 , 0.452  ,\n",
       "            0.4517 , 0.4512 , 0.4456 , 0.4426 , 0.44   , 0.4382 , 0.4375 ,\n",
       "            0.4368 , 0.435  , 0.4336 , 0.4333 , 0.4246 , 0.422  , 0.417  ,\n",
       "            0.4146 , 0.4136 , 0.408  , 0.407  , 0.4016 , 0.3962 , 0.3953 ,\n",
       "            0.3909 , 0.3875 , 0.3865 , 0.3843 , 0.383  , 0.3767 , 0.3757 ,\n",
       "            0.3748 , 0.3745 , 0.3733 , 0.3628 , 0.3625 , 0.3623 , 0.3599 ,\n",
       "            0.3584 , 0.3582 , 0.3557 , 0.3538 , 0.3535 , 0.3525 , 0.3513 ,\n",
       "            0.35   , 0.349  , 0.348  , 0.3467 , 0.346  , 0.3452 , 0.341  ,\n",
       "            0.3408 , 0.3386 , 0.3313 , 0.3306 , 0.33   , 0.319  , 0.3115 ,\n",
       "            0.3083 , 0.3018 , 0.2979 , 0.2908 , 0.2822 , 0.282  , 0.2686 ,\n",
       "            0.2612 , 0.2487 , 0.2473 , 0.2455 , 0.2424 , 0.2422 , 0.2415 ,\n",
       "            0.241  , 0.2363 , 0.2355 , 0.2255 , 0.2249 , 0.2234 , 0.2142 ,\n",
       "            0.2094 , 0.2091 , 0.191  , 0.1874 , 0.1813 , 0.1686 , 0.1514 ,\n",
       "            0.1509 , 0.1418 , 0.11316, 0.108  , 0.09283, 0.09174, 0.088  ,\n",
       "            0.07794, 0.0724 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.14166667, dtype=float32),\n",
       "    'tpr': array(0.97692305, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.125     , 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45833334, 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.46153846, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.7692308 ,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9272 , 0.9146 , 0.9033 , 0.8926 , 0.892  , 0.8906 ,\n",
       "            0.889  , 0.8823 , 0.874  , 0.873  , 0.867  , 0.8667 , 0.8647 ,\n",
       "            0.8574 , 0.854  , 0.8535 , 0.8413 , 0.835  , 0.831  , 0.8306 ,\n",
       "            0.827  , 0.824  , 0.8203 , 0.82   , 0.8184 , 0.8174 , 0.81   ,\n",
       "            0.8076 , 0.8037 , 0.8022 , 0.802  , 0.8013 , 0.8    , 0.7925 ,\n",
       "            0.7915 , 0.7866 , 0.785  , 0.7754 , 0.775  , 0.772  , 0.7686 ,\n",
       "            0.766  , 0.7646 , 0.764  , 0.762  , 0.761  , 0.7603 , 0.759  ,\n",
       "            0.756  , 0.7544 , 0.7524 , 0.751  , 0.75   , 0.746  , 0.745  ,\n",
       "            0.7446 , 0.7397 , 0.737  , 0.7363 , 0.7344 , 0.733  , 0.728  ,\n",
       "            0.727  , 0.7266 , 0.725  , 0.7236 , 0.7197 , 0.717  , 0.714  ,\n",
       "            0.7124 , 0.7104 , 0.709  , 0.7085 , 0.7036 , 0.703  , 0.699  ,\n",
       "            0.6973 , 0.697  , 0.695  , 0.6943 , 0.694  , 0.693  , 0.6914 ,\n",
       "            0.689  , 0.6875 , 0.6855 , 0.685  , 0.6846 , 0.679  , 0.6763 ,\n",
       "            0.666  , 0.6655 , 0.6646 , 0.6543 , 0.6514 , 0.651  , 0.649  ,\n",
       "            0.6465 , 0.6445 , 0.642  , 0.6396 , 0.639  , 0.6333 , 0.626  ,\n",
       "            0.62   , 0.6196 , 0.617  , 0.6157 , 0.611  , 0.6094 , 0.607  ,\n",
       "            0.606  , 0.602  , 0.5967 , 0.596  , 0.593  , 0.59   , 0.5864 ,\n",
       "            0.5806 , 0.5796 , 0.578  , 0.577  , 0.5586 , 0.554  , 0.544  ,\n",
       "            0.5386 , 0.5366 , 0.531  , 0.5293 , 0.525  , 0.516  , 0.5083 ,\n",
       "            0.5073 , 0.5044 , 0.4875 , 0.4841 , 0.4836 , 0.4817 , 0.4802 ,\n",
       "            0.4785 , 0.4778 , 0.4758 , 0.4697 , 0.4656 , 0.4648 , 0.4636 ,\n",
       "            0.4634 , 0.4631 , 0.4612 , 0.4575 , 0.4534 , 0.4487 , 0.4453 ,\n",
       "            0.4438 , 0.4421 , 0.4407 , 0.4395 , 0.4377 , 0.4263 , 0.4246 ,\n",
       "            0.4182 , 0.4155 , 0.4128 , 0.4116 , 0.4102 , 0.4062 , 0.4023 ,\n",
       "            0.3972 , 0.3955 , 0.395  , 0.392  , 0.3918 , 0.3835 , 0.38   ,\n",
       "            0.379  , 0.3782 , 0.376  , 0.3757 , 0.3716 , 0.3708 , 0.3684 ,\n",
       "            0.3662 , 0.366  , 0.3655 , 0.3652 , 0.365  , 0.3645 , 0.3635 ,\n",
       "            0.362  , 0.3586 , 0.356  , 0.3555 , 0.3494 , 0.3489 , 0.344  ,\n",
       "            0.3435 , 0.334  , 0.3245 , 0.3125 , 0.309  , 0.3062 , 0.3018 ,\n",
       "            0.2917 , 0.2827 , 0.282  , 0.2676 , 0.2595 , 0.247  , 0.246  ,\n",
       "            0.2433 , 0.2426 , 0.2422 , 0.2407 , 0.2386 , 0.2351 , 0.2338 ,\n",
       "            0.2224 , 0.2216 , 0.2197 , 0.2101 , 0.2051 , 0.205  , 0.2048 ,\n",
       "            0.1887 , 0.1826 , 0.1759 , 0.1646 , 0.1453 , 0.1447 , 0.1371 ,\n",
       "            0.1065 , 0.10144, 0.0865 , 0.0851 , 0.08167, 0.07196, 0.0661 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.14166667, dtype=float32),\n",
       "    'tpr': array(0.97692305, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05      , 0.05      , 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.15833333, 0.16666667, 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33846155,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9404 , 0.9263 , 0.9204 , 0.9097 , 0.909  , 0.908  ,\n",
       "            0.9053 , 0.9004 , 0.888  , 0.8857 , 0.8853 , 0.883  , 0.875  ,\n",
       "            0.8745 , 0.8696 , 0.8613 , 0.853  , 0.8516 , 0.8477 , 0.8457 ,\n",
       "            0.8423 , 0.841  , 0.839  , 0.8384 , 0.831  , 0.83   , 0.824  ,\n",
       "            0.8237 , 0.8223 , 0.817  , 0.815  , 0.813  , 0.8125 , 0.807  ,\n",
       "            0.8057 , 0.798  , 0.7964 , 0.793  , 0.7896 , 0.784  , 0.783  ,\n",
       "            0.7812 , 0.777  , 0.776  , 0.774  , 0.7734 , 0.772  , 0.7676 ,\n",
       "            0.764  , 0.7617 , 0.76   , 0.758  , 0.7573 , 0.756  , 0.7544 ,\n",
       "            0.748  , 0.7476 , 0.746  , 0.7456 , 0.7427 , 0.7397 , 0.7373 ,\n",
       "            0.735  , 0.7344 , 0.7314 , 0.731  , 0.73   , 0.728  , 0.7246 ,\n",
       "            0.724  , 0.72   , 0.7188 , 0.718  , 0.7153 , 0.7144 , 0.714  ,\n",
       "            0.7134 , 0.712  , 0.7095 , 0.709  , 0.7075 , 0.705  , 0.704  ,\n",
       "            0.6997 , 0.6973 , 0.6875 , 0.6855 , 0.6846 , 0.675  , 0.674  ,\n",
       "            0.671  , 0.6704 , 0.6685 , 0.6675 , 0.6646 , 0.661  , 0.6577 ,\n",
       "            0.652  , 0.6514 , 0.642  , 0.6353 , 0.635  , 0.6304 , 0.6284 ,\n",
       "            0.6265 , 0.624  , 0.6206 , 0.619  , 0.6133 , 0.61   , 0.6064 ,\n",
       "            0.6035 , 0.596  , 0.595  , 0.5947 , 0.5933 , 0.5737 , 0.569  ,\n",
       "            0.5576 , 0.544  , 0.5435 , 0.54   , 0.5376 , 0.533  , 0.522  ,\n",
       "            0.52   , 0.5195 , 0.5166 , 0.5156 , 0.494  , 0.4932 , 0.4883 ,\n",
       "            0.4875 , 0.4856 , 0.4841 , 0.484  , 0.4797 , 0.479  , 0.4753 ,\n",
       "            0.4744 , 0.4739 , 0.4736 , 0.4727 , 0.4722 , 0.4697 , 0.466  ,\n",
       "            0.4614 , 0.4558 , 0.4507 , 0.4504 , 0.446  , 0.4448 , 0.4407 ,\n",
       "            0.4404 , 0.4324 , 0.43   , 0.4233 , 0.4204 , 0.4185 , 0.4177 ,\n",
       "            0.4111 , 0.4023 , 0.4014 , 0.4006 , 0.3994 , 0.3984 , 0.3962 ,\n",
       "            0.3955 , 0.3867 , 0.3865 , 0.3826 , 0.3796 , 0.3765 , 0.374  ,\n",
       "            0.371  , 0.3708 , 0.3694 , 0.3687 , 0.3665 , 0.3662 , 0.3655 ,\n",
       "            0.365  , 0.3645 , 0.3638 , 0.3604 , 0.3594 , 0.3591 , 0.3547 ,\n",
       "            0.3516 , 0.345  , 0.344  , 0.3403 , 0.334  , 0.3264 , 0.3113 ,\n",
       "            0.3093 , 0.308  , 0.3025 , 0.2888 , 0.2798 , 0.2788 , 0.2634 ,\n",
       "            0.2554 , 0.244  , 0.2434 , 0.2406 , 0.2402 , 0.239  , 0.2368 ,\n",
       "            0.2338 , 0.233  , 0.2285 , 0.2167 , 0.2166 , 0.2142 , 0.2043 ,\n",
       "            0.1995 , 0.199  , 0.1987 , 0.1858 , 0.1761 , 0.1694 , 0.1597 ,\n",
       "            0.1382 , 0.1381 , 0.1318 , 0.0995 , 0.0945 , 0.0798 , 0.0785 ,\n",
       "            0.0752 , 0.066  , 0.05988], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.14166667, dtype=float32),\n",
       "    'tpr': array(0.97692305, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.05      ,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.4       , 0.40833333, 0.41666666,\n",
       "            0.425     , 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.51666665, 0.525     , 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.23076923,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9497 , 0.934  , 0.933  , 0.9224 , 0.921  , 0.9204 ,\n",
       "            0.9165 , 0.9136 , 0.9    , 0.8994 , 0.8984 , 0.8975 , 0.8936 ,\n",
       "            0.8896 , 0.8867 , 0.8804 , 0.8765 , 0.868  , 0.8667 , 0.8633 ,\n",
       "            0.8623 , 0.862  , 0.8574 , 0.856  , 0.854  , 0.8535 , 0.8467 ,\n",
       "            0.846  , 0.8394 , 0.8374 , 0.83   , 0.8286 , 0.8276 , 0.8257 ,\n",
       "            0.8223 , 0.821  , 0.8135 , 0.8115 , 0.808  , 0.805  , 0.8047 ,\n",
       "            0.8    , 0.7993 , 0.7964 , 0.792  , 0.7915 , 0.789  , 0.7886 ,\n",
       "            0.786  , 0.783  , 0.7827 , 0.7803 , 0.7783 , 0.7773 , 0.773  ,\n",
       "            0.7725 , 0.7715 , 0.771  , 0.769  , 0.768  , 0.7627 , 0.762  ,\n",
       "            0.761  , 0.7583 , 0.756  , 0.7515 , 0.7495 , 0.749  , 0.746  ,\n",
       "            0.7427 , 0.742  , 0.739  , 0.7383 , 0.7344 , 0.733  , 0.7324 ,\n",
       "            0.7314 , 0.7295 , 0.728  , 0.7275 , 0.726  , 0.7256 , 0.7236 ,\n",
       "            0.722  , 0.7188 , 0.7134 , 0.7114 , 0.711  , 0.7075 , 0.7026 ,\n",
       "            0.6987 , 0.6963 , 0.687  , 0.6865 , 0.6826 , 0.682  , 0.6816 ,\n",
       "            0.681  , 0.6807 , 0.677  , 0.674  , 0.6694 , 0.6636 , 0.6543 ,\n",
       "            0.651  , 0.647  , 0.642  , 0.639  , 0.637  , 0.6353 , 0.635  ,\n",
       "            0.6284 , 0.628  , 0.627  , 0.623  , 0.6196 , 0.6143 , 0.6133 ,\n",
       "            0.608  , 0.605  , 0.6045 , 0.603  , 0.6025 , 0.5815 , 0.5767 ,\n",
       "            0.5625 , 0.549  , 0.5435 , 0.539  , 0.5327 , 0.527  , 0.525  ,\n",
       "            0.521  , 0.52   , 0.5186 , 0.4954 , 0.491  , 0.4895 , 0.487  ,\n",
       "            0.4849 , 0.481  , 0.4802 , 0.4775 , 0.4763 , 0.476  , 0.475  ,\n",
       "            0.4746 , 0.474  , 0.4739 , 0.4736 , 0.4714 , 0.4712 , 0.4675 ,\n",
       "            0.4612 , 0.4531 , 0.453  , 0.4478 , 0.4448 , 0.437  , 0.4316 ,\n",
       "            0.4287 , 0.4265 , 0.42   , 0.418  , 0.4167 , 0.4163 , 0.4036 ,\n",
       "            0.3977 , 0.397  , 0.395  , 0.3938 , 0.393  , 0.3906 , 0.3904 ,\n",
       "            0.3813 , 0.3792 , 0.3755 , 0.374  , 0.3704 , 0.3647 , 0.3645 ,\n",
       "            0.3633 , 0.36   , 0.359  , 0.3584 , 0.358  , 0.357  , 0.3513 ,\n",
       "            0.3508 , 0.3477 , 0.3472 , 0.3416 , 0.3367 , 0.3364 , 0.3357 ,\n",
       "            0.3262 , 0.3257 , 0.322  , 0.3074 , 0.3018 , 0.2986 , 0.2961 ,\n",
       "            0.2795 , 0.2703 , 0.2693 , 0.2527 , 0.2445 , 0.2397 , 0.2358 ,\n",
       "            0.2343 , 0.2322 , 0.2292 , 0.2263 , 0.2256 , 0.2224 , 0.2175 ,\n",
       "            0.2063 , 0.2053 , 0.2028 , 0.193  , 0.188  , 0.1877 , 0.1873 ,\n",
       "            0.1794 , 0.1649 , 0.1582 , 0.151  , 0.1279 , 0.1273 , 0.1235 ,\n",
       "            0.0899 , 0.0854 , 0.07135, 0.0703 , 0.0672 , 0.05933, 0.0527 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.2, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05      , 0.05      , 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.125     , 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.4       , 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.575     , 0.5833333 , 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.31538463, 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6076923 , 0.61538464, 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9614 , 0.948  , 0.9473 , 0.9385 , 0.937  , 0.933  ,\n",
       "            0.931  , 0.918  , 0.917  , 0.9155 , 0.9116 , 0.9077 , 0.9053 ,\n",
       "            0.8994 , 0.895  , 0.889  , 0.888  , 0.8843 , 0.8833 , 0.883  ,\n",
       "            0.879  , 0.8774 , 0.8745 , 0.874  , 0.87   , 0.867  , 0.861  ,\n",
       "            0.8594 , 0.859  , 0.8525 , 0.851  , 0.8506 , 0.8496 , 0.8457 ,\n",
       "            0.8447 , 0.835  , 0.832  , 0.8286 , 0.828  , 0.8228 , 0.8223 ,\n",
       "            0.822  , 0.817  , 0.8154 , 0.8135 , 0.8125 , 0.812  , 0.8105 ,\n",
       "            0.8086 , 0.8076 , 0.807  , 0.804  , 0.8037 , 0.7993 , 0.798  ,\n",
       "            0.795  , 0.7944 , 0.7935 , 0.788  , 0.7876 , 0.786  , 0.785  ,\n",
       "            0.7827 , 0.78   , 0.7764 , 0.7744 , 0.773  , 0.769  , 0.7666 ,\n",
       "            0.765  , 0.764  , 0.763  , 0.76   , 0.7593 , 0.757  , 0.7544 ,\n",
       "            0.754  , 0.753  , 0.7524 , 0.7515 , 0.7505 , 0.748  , 0.7476 ,\n",
       "            0.745  , 0.7407 , 0.7354 , 0.735  , 0.732  , 0.7314 , 0.725  ,\n",
       "            0.718  , 0.7153 , 0.7124 , 0.71   , 0.709  , 0.7056 , 0.7046 ,\n",
       "            0.703  , 0.7026 , 0.698  , 0.6978 , 0.69   , 0.6836 , 0.6772 ,\n",
       "            0.671  , 0.669  , 0.6646 , 0.664  , 0.662  , 0.661  , 0.6567 ,\n",
       "            0.6553 , 0.654  , 0.65   , 0.6455 , 0.636  , 0.6343 , 0.633  ,\n",
       "            0.6304 , 0.629  , 0.628  , 0.607  , 0.6006 , 0.579  , 0.5776 ,\n",
       "            0.568  , 0.5664 , 0.5605 , 0.5537 , 0.549  , 0.547  , 0.5454 ,\n",
       "            0.5435 , 0.5425 , 0.514  , 0.5117 , 0.5083 , 0.507  , 0.505  ,\n",
       "            0.5015 , 0.501  , 0.5005 , 0.5    , 0.4998 , 0.499  , 0.497  ,\n",
       "            0.4968 , 0.495  , 0.4941 , 0.489  , 0.4868 , 0.4841 , 0.473  ,\n",
       "            0.4702 , 0.466  , 0.4607 , 0.4583 , 0.4553 , 0.453  , 0.4521 ,\n",
       "            0.451  , 0.4358 , 0.4338 , 0.4329 , 0.4275 , 0.4219 , 0.4187 ,\n",
       "            0.4177 , 0.4136 , 0.409  , 0.4077 , 0.4075 , 0.407  , 0.396  ,\n",
       "            0.3948 , 0.3918 , 0.3892 , 0.3877 , 0.3857 , 0.381  , 0.3767 ,\n",
       "            0.3752 , 0.3743 , 0.374  , 0.372  , 0.3716 , 0.371  , 0.3677 ,\n",
       "            0.3625 , 0.3604 , 0.3538 , 0.3523 , 0.3506 , 0.3396 , 0.3394 ,\n",
       "            0.3367 , 0.3276 , 0.3274 , 0.3142 , 0.3    , 0.2998 , 0.2969 ,\n",
       "            0.279  , 0.2695 , 0.268  , 0.2502 , 0.2424 , 0.241  , 0.2352 ,\n",
       "            0.2351 , 0.2327 , 0.2266 , 0.2257 , 0.2216 , 0.2179 , 0.2134 ,\n",
       "            0.2026 , 0.2001 , 0.1976 , 0.1876 , 0.1826 , 0.1824 , 0.182  ,\n",
       "            0.1782 , 0.1593 , 0.152  , 0.1473 , 0.1222 , 0.12054, 0.1192 ,\n",
       "            0.0836 , 0.07935, 0.06573, 0.06476, 0.0621 , 0.0547 , 0.0476 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.26666668, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.2769231 , 0.2846154 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5769231 , 0.5846154 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9683 , 0.9575 , 0.9546 , 0.948  , 0.9473 , 0.947  ,\n",
       "            0.9434 , 0.942  , 0.9307 , 0.93   , 0.9263 , 0.926  , 0.923  ,\n",
       "            0.9224 , 0.917  , 0.911  , 0.91   , 0.904  , 0.9033 , 0.8994 ,\n",
       "            0.899  , 0.896  , 0.8936 , 0.8916 , 0.8906 , 0.8857 , 0.885  ,\n",
       "            0.8784 , 0.877  , 0.8765 , 0.87   , 0.869  , 0.868  , 0.8643 ,\n",
       "            0.864  , 0.854  , 0.852  , 0.8516 , 0.848  , 0.8477 , 0.8423 ,\n",
       "            0.842  , 0.8374 , 0.8354 , 0.834  , 0.832  , 0.8315 , 0.828  ,\n",
       "            0.8276 , 0.827  , 0.8257 , 0.824  , 0.8203 , 0.82   , 0.819  ,\n",
       "            0.8164 , 0.815  , 0.814  , 0.812  , 0.81   , 0.8086 , 0.808  ,\n",
       "            0.8057 , 0.8047 , 0.8027 , 0.7983 , 0.7954 , 0.7935 , 0.793  ,\n",
       "            0.792  , 0.7866 , 0.7856 , 0.785  , 0.784  , 0.7817 , 0.781  ,\n",
       "            0.7783 , 0.7773 , 0.777  , 0.775  , 0.7744 , 0.7725 , 0.77   ,\n",
       "            0.769  , 0.7666 , 0.757  , 0.755  , 0.751  , 0.75   , 0.7495 ,\n",
       "            0.747  , 0.7363 , 0.735  , 0.734  , 0.731  , 0.7285 , 0.7266 ,\n",
       "            0.723  , 0.7217 , 0.7207 , 0.72   , 0.7188 , 0.712  , 0.698  ,\n",
       "            0.694  , 0.6914 , 0.6855 , 0.685  , 0.683  , 0.6797 , 0.679  ,\n",
       "            0.673  , 0.6714 , 0.67   , 0.669  , 0.667  , 0.656  , 0.655  ,\n",
       "            0.6514 , 0.65   , 0.649  , 0.6475 , 0.6455 , 0.6274 , 0.6206 ,\n",
       "            0.599  , 0.5938 , 0.588  , 0.576  , 0.569  , 0.568  , 0.5674 ,\n",
       "            0.5625 , 0.562  , 0.556  , 0.553  , 0.5317 , 0.5225 , 0.5215 ,\n",
       "            0.5195 , 0.517  , 0.5166 , 0.514  , 0.513  , 0.5117 , 0.511  ,\n",
       "            0.509  , 0.5073 , 0.5054 , 0.5024 , 0.4966 , 0.492  , 0.4824 ,\n",
       "            0.4817 , 0.4805 , 0.468  , 0.4658 , 0.464  , 0.4607 , 0.4578 ,\n",
       "            0.455  , 0.4495 , 0.441  , 0.4392 , 0.4329 , 0.4314 , 0.4253 ,\n",
       "            0.424  , 0.42   , 0.4146 , 0.4124 , 0.4102 , 0.4055 , 0.4028 ,\n",
       "            0.3992 , 0.3926 , 0.3914 , 0.388  , 0.384  , 0.3833 , 0.383  ,\n",
       "            0.3804 , 0.3801 , 0.3792 , 0.3782 , 0.3765 , 0.3735 , 0.3706 ,\n",
       "            0.3687 , 0.3672 , 0.3633 , 0.3604 , 0.3582 , 0.351  , 0.3428 ,\n",
       "            0.3396 , 0.3345 , 0.3271 , 0.327  , 0.3145 , 0.299  , 0.2964 ,\n",
       "            0.293  , 0.2761 , 0.2664 , 0.2646 , 0.2452 , 0.2399 , 0.2355 ,\n",
       "            0.2316 , 0.2313 , 0.229  , 0.2229 , 0.22   , 0.2156 , 0.2115 ,\n",
       "            0.2074 , 0.197  , 0.1934 , 0.1907 , 0.1804 , 0.1757 , 0.1753 ,\n",
       "            0.1752 , 0.1735 , 0.1523 , 0.1447 , 0.1415 , 0.11536, 0.11316,\n",
       "            0.1128 , 0.07666, 0.0729 , 0.05966, 0.059  , 0.05634, 0.04968,\n",
       "            0.0424 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.275, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.07692308, 0.08461539,\n",
       "            0.09230769, 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.23076923, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5769231 , 0.5846154 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.86153847, 0.86923075, 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.975  , 0.9663 , 0.9624 , 0.958  , 0.957  , 0.953  ,\n",
       "            0.9526 , 0.942  , 0.937  , 0.9365 , 0.934  , 0.929  , 0.9233 ,\n",
       "            0.923  , 0.918  , 0.917  , 0.914  , 0.9126 , 0.9097 , 0.909  ,\n",
       "            0.9077 , 0.9053 , 0.9043 , 0.902  , 0.899  , 0.8926 , 0.8916 ,\n",
       "            0.891  , 0.8853 , 0.884  , 0.8833 , 0.883  , 0.88   , 0.8794 ,\n",
       "            0.8784 , 0.8696 , 0.8677 , 0.867  , 0.8643 , 0.864  , 0.859  ,\n",
       "            0.858  , 0.8545 , 0.852  , 0.851  , 0.849  , 0.848  , 0.847  ,\n",
       "            0.846  , 0.8447 , 0.8438 , 0.8413 , 0.839  , 0.8374 , 0.8364 ,\n",
       "            0.835  , 0.832  , 0.831  , 0.828  , 0.8276 , 0.8267 , 0.8257 ,\n",
       "            0.824  , 0.823  , 0.8213 , 0.8164 , 0.813  , 0.8125 , 0.8105 ,\n",
       "            0.8096 , 0.8066 , 0.8047 , 0.8037 , 0.8003 , 0.8    , 0.799  ,\n",
       "            0.798  , 0.795  , 0.7944 , 0.793  , 0.791  , 0.7896 , 0.789  ,\n",
       "            0.787  , 0.785  , 0.7754 , 0.7725 , 0.771  , 0.7695 , 0.7656 ,\n",
       "            0.7646 , 0.7534 , 0.753  , 0.7515 , 0.75   , 0.749  , 0.7446 ,\n",
       "            0.7427 , 0.7397 , 0.7373 , 0.7363 , 0.7354 , 0.7305 , 0.7153 ,\n",
       "            0.7124 , 0.709  , 0.703  , 0.7017 , 0.698  , 0.692  , 0.69   ,\n",
       "            0.6885 , 0.6855 , 0.684  , 0.6733 , 0.6724 , 0.667  , 0.666  ,\n",
       "            0.6655 , 0.664  , 0.645  , 0.637  , 0.6177 , 0.605  , 0.604  ,\n",
       "            0.5884 , 0.584  , 0.5835 , 0.5806 , 0.576  , 0.574  , 0.5703 ,\n",
       "            0.566  , 0.5464 , 0.537  , 0.533  , 0.5312 , 0.529  , 0.5283 ,\n",
       "            0.5273 , 0.526  , 0.5254 , 0.5215 , 0.5186 , 0.5166 , 0.516  ,\n",
       "            0.511  , 0.503  , 0.496  , 0.4941 , 0.492  , 0.4888 , 0.4802 ,\n",
       "            0.4714 , 0.468  , 0.465  , 0.463  , 0.4612 , 0.4602 , 0.45   ,\n",
       "            0.442  , 0.441  , 0.4346 , 0.4343 , 0.4294 , 0.428  , 0.4258 ,\n",
       "            0.421  , 0.417  , 0.4146 , 0.4133 , 0.411  , 0.4077 , 0.3994 ,\n",
       "            0.3992 , 0.3948 , 0.3914 , 0.3901 , 0.39   , 0.3872 , 0.3845 ,\n",
       "            0.3828 , 0.382  , 0.379  , 0.3762 , 0.3752 , 0.3694 , 0.3667 ,\n",
       "            0.3643 , 0.3635 , 0.347  , 0.3435 , 0.3372 , 0.3298 , 0.3281 ,\n",
       "            0.3235 , 0.3176 , 0.2979 , 0.2903 , 0.2866 , 0.271  , 0.2612 ,\n",
       "            0.2595 , 0.2399 , 0.2386 , 0.2294 , 0.228  , 0.2272 , 0.2266 ,\n",
       "            0.2202 , 0.2129 , 0.2079 , 0.2035 , 0.2    , 0.1912 , 0.1849 ,\n",
       "            0.1824 , 0.172  , 0.17   , 0.1677 , 0.1674 , 0.1669 , 0.1443 ,\n",
       "            0.1364 , 0.1359 , 0.1082 , 0.1076 , 0.1047 , 0.0698 , 0.06647,\n",
       "            0.0538 , 0.0535 , 0.0511 , 0.0451 , 0.03754], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.28333333, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5769231 ,\n",
       "            0.5846154 , 0.6       , 0.61538464, 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.98   , 0.9727 , 0.9683 , 0.9653 , 0.9644 , 0.964  ,\n",
       "            0.9604 , 0.951  , 0.95   , 0.9453 , 0.9443 , 0.9434 , 0.9424 ,\n",
       "            0.9385 , 0.9326 , 0.929  , 0.927  , 0.926  , 0.923  , 0.921  ,\n",
       "            0.9194 , 0.918  , 0.916  , 0.915  , 0.9146 , 0.91   , 0.904  ,\n",
       "            0.9033 , 0.903  , 0.897  , 0.8955 , 0.895  , 0.892  , 0.8916 ,\n",
       "            0.8896 , 0.8823 , 0.88   , 0.8784 , 0.877  , 0.8765 , 0.8716 ,\n",
       "            0.87   , 0.867  , 0.8647 , 0.8643 , 0.863  , 0.8623 , 0.862  ,\n",
       "            0.861  , 0.858  , 0.857  , 0.8545 , 0.853  , 0.8506 , 0.8496 ,\n",
       "            0.8457 , 0.8447 , 0.8413 , 0.8403 , 0.84   , 0.8394 , 0.837  ,\n",
       "            0.836  , 0.83   , 0.829  , 0.8267 , 0.8237 , 0.823  , 0.8213 ,\n",
       "            0.8203 , 0.818  , 0.814  , 0.8125 , 0.8096 , 0.807  , 0.8066 ,\n",
       "            0.806  , 0.805  , 0.803  , 0.8013 , 0.801  , 0.8    , 0.7896 ,\n",
       "            0.788  , 0.7856 , 0.7827 , 0.7803 , 0.776  , 0.7695 , 0.7676 ,\n",
       "            0.766  , 0.764  , 0.763  , 0.759  , 0.755  , 0.7505 , 0.7495 ,\n",
       "            0.7466 , 0.745  , 0.727  , 0.7266 , 0.7227 , 0.7173 , 0.717  ,\n",
       "            0.716  , 0.713  , 0.7114 , 0.7065 , 0.704  , 0.7017 , 0.699  ,\n",
       "            0.694  , 0.687  , 0.6855 , 0.68   , 0.678  , 0.6772 , 0.676  ,\n",
       "            0.6577 , 0.65   , 0.6304 , 0.616  , 0.613  , 0.596  , 0.595  ,\n",
       "            0.5947 , 0.5864 , 0.5854 , 0.581  , 0.5796 , 0.573  , 0.5566 ,\n",
       "            0.547  , 0.541  , 0.54   , 0.5376 , 0.536  , 0.5356 , 0.5347 ,\n",
       "            0.5312 , 0.5273 , 0.527  , 0.523  , 0.5205 , 0.519  , 0.5146 ,\n",
       "            0.505  , 0.502  , 0.5    , 0.4968 , 0.492  , 0.4878 , 0.4734 ,\n",
       "            0.467  , 0.4666 , 0.4663 , 0.4617 , 0.4612 , 0.4556 , 0.448  ,\n",
       "            0.4395 , 0.439  , 0.4333 , 0.4321 , 0.4304 , 0.4236 , 0.4229 ,\n",
       "            0.4172 , 0.4148 , 0.4138 , 0.412  , 0.403  , 0.396  , 0.3943 ,\n",
       "            0.3936 , 0.3928 , 0.39   , 0.3867 , 0.3845 , 0.3833 , 0.3804 ,\n",
       "            0.3787 , 0.3774 , 0.3726 , 0.3684 , 0.3643 , 0.362  , 0.3618 ,\n",
       "            0.3406 , 0.3396 , 0.332  , 0.3262 , 0.3218 , 0.3176 , 0.3174 ,\n",
       "            0.2935 , 0.2815 , 0.2776 , 0.264  , 0.2542 , 0.252  , 0.2368 ,\n",
       "            0.2297 , 0.2246 , 0.2216 , 0.2207 , 0.2185 , 0.2148 , 0.2043 ,\n",
       "            0.1985 , 0.1936 , 0.1907 , 0.1835 , 0.1748 , 0.1726 , 0.1648 ,\n",
       "            0.1622 , 0.1583 , 0.1581 , 0.157  , 0.1351 , 0.1289 , 0.1271 ,\n",
       "            0.1009 , 0.10034, 0.0957 , 0.0628 , 0.05975, 0.04794, 0.0478 ,\n",
       "            0.04596, 0.04037, 0.03284], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.29166666, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.36153847, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.65384614, 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.84615386, 0.86153847, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9230769 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.984  , 0.9785 , 0.9727 , 0.9717 , 0.971  , 0.97   ,\n",
       "            0.968  , 0.967  , 0.9595 , 0.958  , 0.952  , 0.9517 , 0.951  ,\n",
       "            0.9497 , 0.9463 , 0.941  , 0.9404 , 0.9395 , 0.9365 , 0.932  ,\n",
       "            0.9316 , 0.9287 , 0.928  , 0.927  , 0.9253 , 0.9243 , 0.9204 ,\n",
       "            0.914  , 0.913  , 0.9087 , 0.906  , 0.9053 , 0.902  , 0.9014 ,\n",
       "            0.8984 , 0.893  , 0.891  , 0.8906 , 0.8896 , 0.887  , 0.885  ,\n",
       "            0.8833 , 0.879  , 0.877  , 0.8765 , 0.875  , 0.874  , 0.8726 ,\n",
       "            0.869  , 0.867  , 0.8657 , 0.863  , 0.862  , 0.8613 , 0.858  ,\n",
       "            0.8564 , 0.856  , 0.854  , 0.853  , 0.852  , 0.8516 , 0.849  ,\n",
       "            0.846  , 0.8447 , 0.8423 , 0.839  , 0.838  , 0.836  , 0.8335 ,\n",
       "            0.831  , 0.83   , 0.8296 , 0.8286 , 0.8267 , 0.826  , 0.825  ,\n",
       "            0.8228 , 0.821  , 0.8193 , 0.817  , 0.8164 , 0.814  , 0.8135 ,\n",
       "            0.8115 , 0.8057 , 0.8013 , 0.7993 , 0.793  , 0.792  , 0.7915 ,\n",
       "            0.7856 , 0.783  , 0.7793 , 0.7773 , 0.776  , 0.775  , 0.771  ,\n",
       "            0.765  , 0.7637 , 0.763  , 0.761  , 0.7563 , 0.7393 , 0.735  ,\n",
       "            0.734  , 0.7285 , 0.726  , 0.7227 , 0.721  , 0.714  , 0.7134 ,\n",
       "            0.709  , 0.697  , 0.6963 , 0.696  , 0.6953 , 0.692  , 0.6895 ,\n",
       "            0.688  , 0.683  , 0.666  , 0.6587 , 0.6353 , 0.6226 , 0.622  ,\n",
       "            0.5996 , 0.599  , 0.5938 , 0.5923 , 0.5806 , 0.5757 , 0.574  ,\n",
       "            0.5596 , 0.549  , 0.5483 , 0.5425 , 0.541  , 0.5396 , 0.539  ,\n",
       "            0.538  , 0.536  , 0.5356 , 0.5337 , 0.529  , 0.52   , 0.5156 ,\n",
       "            0.5117 , 0.5093 , 0.509  , 0.508  , 0.502  , 0.4995 , 0.4956 ,\n",
       "            0.4863 , 0.4668 , 0.4648 , 0.4631 , 0.4622 , 0.4607 , 0.4504 ,\n",
       "            0.444  , 0.4395 , 0.4368 , 0.4329 , 0.4307 , 0.4265 , 0.4233 ,\n",
       "            0.4226 , 0.414  , 0.4114 , 0.411  , 0.4067 , 0.4038 , 0.3977 ,\n",
       "            0.3943 , 0.3892 , 0.3877 , 0.3875 , 0.3872 , 0.385  , 0.3828 ,\n",
       "            0.381  , 0.38   , 0.3713 , 0.3708 , 0.3696 , 0.3594 , 0.359  ,\n",
       "            0.3555 , 0.354  , 0.3494 , 0.3347 , 0.3276 , 0.3257 , 0.3242 ,\n",
       "            0.3196 , 0.3174 , 0.313  , 0.2898 , 0.2751 , 0.2717 , 0.2573 ,\n",
       "            0.248  , 0.2452 , 0.2363 , 0.2222 , 0.2217 , 0.2181 , 0.2158 ,\n",
       "            0.2115 , 0.2106 , 0.197  , 0.1901 , 0.1858 , 0.1829 , 0.177  ,\n",
       "            0.1671 , 0.1647 , 0.1615 , 0.1543 , 0.1504 , 0.1501 , 0.1492 ,\n",
       "            0.1274 , 0.1232 , 0.1194 , 0.0955 , 0.0939 , 0.0891 , 0.0572 ,\n",
       "            0.0544 , 0.04352, 0.04303, 0.0417 , 0.0365 , 0.02898],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.31666666, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.05      ,\n",
       "            0.05      , 0.05      , 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.075     , 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.17692308, 0.1923077 , 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.2769231 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.3846154 , 0.3923077 ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.61538464, 0.6230769 ,\n",
       "            0.63846153, 0.65384614, 0.66923076, 0.6769231 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.988  , 0.983  , 0.978  , 0.9775 , 0.977  , 0.976  ,\n",
       "            0.974  , 0.973  , 0.968  , 0.967  , 0.9624 , 0.96   , 0.959  ,\n",
       "            0.958  , 0.955  , 0.9526 , 0.9497 , 0.949  , 0.9473 , 0.945  ,\n",
       "            0.9424 , 0.939  , 0.9385 , 0.9346 , 0.9297 , 0.929  , 0.9287 ,\n",
       "            0.928  , 0.925  , 0.922  , 0.9214 , 0.919  , 0.9185 , 0.911  ,\n",
       "            0.91   , 0.9087 , 0.9077 , 0.9053 , 0.903  , 0.902  , 0.9014 ,\n",
       "            0.895  , 0.8945 , 0.8936 , 0.893  , 0.889  , 0.887  , 0.883  ,\n",
       "            0.882  , 0.8813 , 0.879  , 0.878  , 0.877  , 0.874  , 0.873  ,\n",
       "            0.872  , 0.8696 , 0.869  , 0.863  , 0.8604 , 0.8594 , 0.859  ,\n",
       "            0.856  , 0.8545 , 0.852  , 0.851  , 0.848  , 0.8477 , 0.8467 ,\n",
       "            0.844  , 0.8423 , 0.842  , 0.8403 , 0.8364 , 0.835  , 0.8345 ,\n",
       "            0.825  , 0.822  , 0.82   , 0.8164 , 0.814  , 0.8115 , 0.8057 ,\n",
       "            0.804  , 0.803  , 0.801  , 0.8003 , 0.7954 , 0.795  , 0.792  ,\n",
       "            0.787  , 0.7866 , 0.784  , 0.782  , 0.76   , 0.7593 , 0.754  ,\n",
       "            0.753  , 0.7485 , 0.7466 , 0.7427 , 0.742  , 0.7407 , 0.736  ,\n",
       "            0.734  , 0.7236 , 0.7217 , 0.7163 , 0.716  , 0.7124 , 0.711  ,\n",
       "            0.703  , 0.6934 , 0.6846 , 0.6646 , 0.649  , 0.6436 , 0.628  ,\n",
       "            0.6265 , 0.617  , 0.6123 , 0.611  , 0.5977 , 0.5933 , 0.5923 ,\n",
       "            0.585  , 0.5747 , 0.5684 , 0.5654 , 0.5645 , 0.561  , 0.558  ,\n",
       "            0.5547 , 0.5527 , 0.552  , 0.551  , 0.536  , 0.5312 , 0.5273 ,\n",
       "            0.5254 , 0.5244 , 0.5215 , 0.5127 , 0.51   , 0.5083 , 0.4858 ,\n",
       "            0.4805 , 0.477  , 0.475  , 0.474  , 0.4653 , 0.4631 , 0.4553 ,\n",
       "            0.4492 , 0.4475 , 0.442  , 0.4387 , 0.4343 , 0.4314 , 0.4312 ,\n",
       "            0.4285 , 0.4255 , 0.4214 , 0.4155 , 0.4146 , 0.4055 , 0.4048 ,\n",
       "            0.4045 , 0.4011 , 0.4006 , 0.3967 , 0.3936 , 0.3884 , 0.3875 ,\n",
       "            0.3865 , 0.3796 , 0.3777 , 0.3684 , 0.3682 , 0.3672 , 0.367  ,\n",
       "            0.3635 , 0.357  , 0.3372 , 0.3318 , 0.3308 , 0.328  , 0.323  ,\n",
       "            0.3206 , 0.3154 , 0.2896 , 0.2754 , 0.2725 , 0.2559 , 0.246  ,\n",
       "            0.2437 , 0.2362 , 0.22   , 0.2194 , 0.2166 , 0.2135 , 0.2096 ,\n",
       "            0.2073 , 0.193  , 0.1857 , 0.1819 , 0.1788 , 0.1727 , 0.1632 ,\n",
       "            0.1603 , 0.1583 , 0.1498 , 0.1458 , 0.1454 , 0.1447 , 0.12244,\n",
       "            0.1186 , 0.1144 , 0.0909 , 0.0891 , 0.08466, 0.05292, 0.05014,\n",
       "            0.03986, 0.03912, 0.03812, 0.03314, 0.02576], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.325, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.1       , 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.4       , 0.4       , 0.40833333, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.24615385, 0.25384617, 0.26923078, 0.2769231 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.45384616, 0.46153846, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.56153846, 0.5692308 , 0.5846154 , 0.5923077 , 0.6076923 ,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.6615385 , 0.6769231 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.73846155, 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9907 , 0.9873 , 0.9824 , 0.982  , 0.9814 , 0.9795 ,\n",
       "            0.9785 , 0.975  , 0.9736 , 0.9707 , 0.967  , 0.966  , 0.965  ,\n",
       "            0.963  , 0.962  , 0.9595 , 0.9585 , 0.9575 , 0.9565 , 0.9546 ,\n",
       "            0.9526 , 0.952  , 0.9497 , 0.949  , 0.9487 , 0.948  , 0.9463 ,\n",
       "            0.9424 , 0.9414 , 0.941  , 0.938  , 0.9346 , 0.934  , 0.932  ,\n",
       "            0.9243 , 0.9233 , 0.923  , 0.9204 , 0.918  , 0.917  , 0.916  ,\n",
       "            0.9106 , 0.9097 , 0.908  , 0.9077 , 0.907  , 0.9053 , 0.9014 ,\n",
       "            0.899  , 0.897  , 0.896  , 0.895  , 0.894  , 0.8926 , 0.891  ,\n",
       "            0.8906 , 0.89   , 0.889  , 0.8877 , 0.887  , 0.8843 , 0.8794 ,\n",
       "            0.8784 , 0.8774 , 0.876  , 0.8745 , 0.871  , 0.867  , 0.8667 ,\n",
       "            0.8643 , 0.864  , 0.862  , 0.861  , 0.8594 , 0.856  , 0.855  ,\n",
       "            0.8516 , 0.844  , 0.841  , 0.8374 , 0.833  , 0.8296 , 0.8257 ,\n",
       "            0.8247 , 0.8228 , 0.82   , 0.8164 , 0.8145 , 0.8086 , 0.8066 ,\n",
       "            0.804  , 0.8037 , 0.7817 , 0.779  , 0.7764 , 0.776  , 0.7725 ,\n",
       "            0.768  , 0.767  , 0.764  , 0.762  , 0.7593 , 0.7534 , 0.7476 ,\n",
       "            0.7437 , 0.7397 , 0.737  , 0.7344 , 0.733  , 0.7305 , 0.722  ,\n",
       "            0.7163 , 0.7075 , 0.6895 , 0.6724 , 0.6616 , 0.652  , 0.649  ,\n",
       "            0.6377 , 0.63   , 0.6294 , 0.614  , 0.61   , 0.6094 , 0.6064 ,\n",
       "            0.5967 , 0.5903 , 0.586  , 0.5835 , 0.5825 , 0.575  , 0.573  ,\n",
       "            0.572  , 0.567  , 0.563  , 0.552  , 0.546  , 0.545  , 0.5415 ,\n",
       "            0.5405 , 0.5386 , 0.5317 , 0.529  , 0.523  , 0.518  , 0.5034 ,\n",
       "            0.4934 , 0.4888 , 0.4868 , 0.4849 , 0.483  , 0.4827 , 0.4749 ,\n",
       "            0.4705 , 0.4617 , 0.4558 , 0.451  , 0.4482 , 0.446  , 0.445  ,\n",
       "            0.4426 , 0.4402 , 0.438  , 0.4324 , 0.4294 , 0.4246 , 0.4187 ,\n",
       "            0.4182 , 0.4126 , 0.408  , 0.4058 , 0.4    , 0.3987 , 0.3962 ,\n",
       "            0.3914 , 0.387  , 0.3845 , 0.38   , 0.3784 , 0.3745 , 0.373  ,\n",
       "            0.3662 , 0.3633 , 0.3376 , 0.3374 , 0.3318 , 0.3306 , 0.3271 ,\n",
       "            0.3218 , 0.3157 , 0.2896 , 0.2734 , 0.2715 , 0.2542 , 0.2428 ,\n",
       "            0.2406 , 0.237  , 0.219  , 0.2156 , 0.2152 , 0.2118 , 0.2081 ,\n",
       "            0.2026 , 0.1886 , 0.1805 , 0.177  , 0.1738 , 0.1687 , 0.1583 ,\n",
       "            0.1561 , 0.155  , 0.1444 , 0.1405 , 0.1399 , 0.1394 , 0.11694,\n",
       "            0.1144 , 0.10876, 0.0866 , 0.0845 , 0.07965, 0.04858, 0.04602,\n",
       "            0.0365 , 0.03555, 0.03482, 0.03004, 0.02293], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.325, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.04166667, 0.05      ,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.1       , 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.2769231 , 0.2923077 ,\n",
       "            0.3       , 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.47692308,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.63076925, 0.63846153, 0.65384614, 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.73846155, 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9927 , 0.9897 , 0.986  , 0.9854 , 0.985  , 0.983  ,\n",
       "            0.982  , 0.9795 , 0.9775 , 0.9756 , 0.9717 , 0.9707 , 0.97   ,\n",
       "            0.9683 , 0.968  , 0.9663 , 0.9644 , 0.9634 , 0.963  , 0.9614 ,\n",
       "            0.96   , 0.959  , 0.957  , 0.9565 , 0.9556 , 0.955  , 0.9536 ,\n",
       "            0.9507 , 0.949  , 0.9487 , 0.947  , 0.9434 , 0.943  , 0.941  ,\n",
       "            0.9336 , 0.9326 , 0.931  , 0.9297 , 0.9287 , 0.9272 , 0.9263 ,\n",
       "            0.921  , 0.9204 , 0.9194 , 0.9175 , 0.917  , 0.9155 , 0.911  ,\n",
       "            0.9097 , 0.907  , 0.9067 , 0.9062 , 0.906  , 0.9053 , 0.9033 ,\n",
       "            0.902  , 0.9014 , 0.901  , 0.899  , 0.8955 , 0.891  , 0.8906 ,\n",
       "            0.8896 , 0.887  , 0.886  , 0.8833 , 0.883  , 0.88   , 0.879  ,\n",
       "            0.8784 , 0.8765 , 0.8745 , 0.8735 , 0.8726 , 0.872  , 0.869  ,\n",
       "            0.8687 , 0.8677 , 0.8643 , 0.8574 , 0.8535 , 0.8506 , 0.8467 ,\n",
       "            0.842  , 0.8394 , 0.8384 , 0.837  , 0.836  , 0.8345 , 0.8306 ,\n",
       "            0.828  , 0.8276 , 0.8228 , 0.821  , 0.819  , 0.8184 , 0.796  ,\n",
       "            0.7935 , 0.7905 , 0.7896 , 0.7847 , 0.782  , 0.7817 , 0.778  ,\n",
       "            0.777  , 0.7764 , 0.7734 , 0.768  , 0.761  , 0.7583 , 0.7534 ,\n",
       "            0.7505 , 0.7476 , 0.745  , 0.7437 , 0.735  , 0.73   , 0.721  ,\n",
       "            0.702  , 0.685  , 0.674  , 0.6636 , 0.661  , 0.6504 , 0.6416 ,\n",
       "            0.639  , 0.621  , 0.62   , 0.617  , 0.6064 , 0.5996 , 0.5957 ,\n",
       "            0.592  , 0.5845 , 0.5825 , 0.582  , 0.5757 , 0.569  , 0.5596 ,\n",
       "            0.553  , 0.552  , 0.551  , 0.5464 , 0.5444 , 0.5366 , 0.536  ,\n",
       "            0.528  , 0.522  , 0.51   , 0.4978 , 0.4966 , 0.4915 , 0.4888 ,\n",
       "            0.4878 , 0.4866 , 0.477  , 0.4756 , 0.4668 , 0.4575 , 0.4565 ,\n",
       "            0.4521 , 0.4492 , 0.449  , 0.446  , 0.4434 , 0.44   , 0.4365 ,\n",
       "            0.4321 , 0.426  , 0.421  , 0.4202 , 0.415  , 0.4104 , 0.4053 ,\n",
       "            0.4004 , 0.4    , 0.3953 , 0.3906 , 0.3887 , 0.3843 , 0.38   ,\n",
       "            0.379  , 0.374  , 0.3713 , 0.3647 , 0.362  , 0.3345 , 0.3335 ,\n",
       "            0.3296 , 0.3286 , 0.3274 , 0.321  , 0.3123 , 0.2861 , 0.2695 ,\n",
       "            0.2688 , 0.2493 , 0.2366 , 0.235  , 0.234  , 0.2153 , 0.2113 ,\n",
       "            0.209  , 0.2073 , 0.2042 , 0.196  , 0.182  , 0.1735 , 0.1707 ,\n",
       "            0.1672 , 0.1632 , 0.1527 , 0.152  , 0.1488 , 0.1383 , 0.134  ,\n",
       "            0.1333 , 0.1332 , 0.11084, 0.10913, 0.10284, 0.082  , 0.07947,\n",
       "            0.0752 , 0.04468, 0.04208, 0.03333, 0.0323 , 0.03174, 0.02718,\n",
       "            0.0205 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.35833332, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.05      ,\n",
       "            0.05      , 0.05      , 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.075     , 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.21538462, 0.22307692, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.2769231 , 0.2923077 , 0.3       , 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.37692308, 0.3846154 , 0.4076923 , 0.41538462,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.50769234, 0.5153846 ,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.54615384, 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.6       , 0.61538464,\n",
       "            0.6230769 , 0.63846153, 0.64615387, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.7923077 , 0.8       , 0.8076923 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.85384613, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.994  , 0.9917 , 0.989  , 0.9883 , 0.988  , 0.9863 ,\n",
       "            0.9854 , 0.9844 , 0.982  , 0.981  , 0.9766 , 0.976  , 0.9756 ,\n",
       "            0.974  , 0.9736 , 0.973  , 0.9707 , 0.9697 , 0.969  , 0.9688 ,\n",
       "            0.968  , 0.966  , 0.965  , 0.9644 , 0.963  , 0.962  , 0.9595 ,\n",
       "            0.958  , 0.956  , 0.953  , 0.9526 , 0.951  , 0.945  , 0.944  ,\n",
       "            0.9434 , 0.942  , 0.9414 , 0.94   , 0.9385 , 0.9375 , 0.9336 ,\n",
       "            0.931  , 0.9287 , 0.928  , 0.9233 , 0.92   , 0.9194 , 0.919  ,\n",
       "            0.9185 , 0.9175 , 0.917  , 0.916  , 0.9155 , 0.915  , 0.913  ,\n",
       "            0.9087 , 0.906  , 0.9053 , 0.9043 , 0.9    , 0.8994 , 0.897  ,\n",
       "            0.895  , 0.893  , 0.891  , 0.8906 , 0.89   , 0.889  , 0.8877 ,\n",
       "            0.886  , 0.8857 , 0.8853 , 0.8794 , 0.872  , 0.87   , 0.869  ,\n",
       "            0.8667 , 0.8623 , 0.8594 , 0.8584 , 0.856  , 0.854  , 0.852  ,\n",
       "            0.8516 , 0.849  , 0.8486 , 0.844  , 0.842  , 0.839  , 0.837  ,\n",
       "            0.816  , 0.812  , 0.8115 , 0.8057 , 0.8013 , 0.801  , 0.8003 ,\n",
       "            0.796  , 0.7944 , 0.787  , 0.785  , 0.7793 , 0.777  , 0.7686 ,\n",
       "            0.7666 , 0.762  , 0.7563 , 0.754  , 0.744  , 0.729  , 0.7095 ,\n",
       "            0.692  , 0.6904 , 0.6855 , 0.6724 , 0.663  , 0.659  , 0.6455 ,\n",
       "            0.6426 , 0.642  , 0.6323 , 0.6255 , 0.6206 , 0.62   , 0.6167 ,\n",
       "            0.611  , 0.606  , 0.603  , 0.5923 , 0.5815 , 0.5767 , 0.574  ,\n",
       "            0.5693 , 0.5664 , 0.565  , 0.56   , 0.548  , 0.5386 , 0.532  ,\n",
       "            0.5312 , 0.518  , 0.511  , 0.5103 , 0.509  , 0.498  , 0.4973 ,\n",
       "            0.4956 , 0.4949 , 0.4844 , 0.4734 , 0.4668 , 0.4653 , 0.4648 ,\n",
       "            0.4646 , 0.4634 , 0.456  , 0.4526 , 0.4514 , 0.4468 , 0.4438 ,\n",
       "            0.4392 , 0.4387 , 0.4385 , 0.4316 , 0.4253 , 0.417  , 0.4114 ,\n",
       "            0.4102 , 0.402  , 0.4    , 0.3975 , 0.3948 , 0.394  , 0.3862 ,\n",
       "            0.3848 , 0.3748 , 0.3672 , 0.3464 , 0.3347 , 0.3298 , 0.3281 ,\n",
       "            0.3254 , 0.3228 , 0.3127 , 0.284  , 0.2686 , 0.2683 , 0.2473 ,\n",
       "            0.2327 , 0.2303 , 0.2302 , 0.2106 , 0.2065 , 0.2045 , 0.2026 ,\n",
       "            0.1993 , 0.1915 , 0.1766 , 0.1683 , 0.1658 , 0.162  , 0.1577 ,\n",
       "            0.1481 , 0.1462 , 0.1437 , 0.133  , 0.1285 , 0.1283 , 0.1277 ,\n",
       "            0.1052 , 0.1036 , 0.09753, 0.07684, 0.07434, 0.0708 , 0.04083,\n",
       "            0.0384 , 0.03004, 0.02908, 0.02855, 0.02423, 0.01816],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.39166668, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05      , 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.075     , 0.075     ,\n",
       "            0.08333334, 0.1       , 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.39166668, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.2       , 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.24615385, 0.25384617, 0.26923078, 0.2769231 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3923077 , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.46153846, 0.47692308, 0.4846154 , 0.4923077 , 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5846154 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.63076925, 0.63846153, 0.65384614, 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.996  , 0.994  , 0.9917 , 0.991  , 0.9907 , 0.9897 ,\n",
       "            0.989  , 0.988  , 0.9863 , 0.985  , 0.9814 , 0.981  , 0.9805 ,\n",
       "            0.979  , 0.9775 , 0.977  , 0.976  , 0.974  , 0.973  , 0.9727 ,\n",
       "            0.971  , 0.9707 , 0.969  , 0.9683 , 0.966  , 0.9653 , 0.9624 ,\n",
       "            0.961  , 0.9604 , 0.9595 , 0.9536 , 0.9526 , 0.952  , 0.9517 ,\n",
       "            0.951  , 0.9507 , 0.948  , 0.9473 , 0.947  , 0.944  , 0.9434 ,\n",
       "            0.9424 , 0.9414 , 0.94   , 0.9395 , 0.9355 , 0.9346 , 0.932  ,\n",
       "            0.9316 , 0.931  , 0.93   , 0.9287 , 0.928  , 0.9277 , 0.927  ,\n",
       "            0.9253 , 0.9224 , 0.9194 , 0.9185 , 0.915  , 0.9146 , 0.9126 ,\n",
       "            0.9087 , 0.907  , 0.9067 , 0.9062 , 0.9053 , 0.904  , 0.9033 ,\n",
       "            0.901  , 0.9    , 0.8994 , 0.896  , 0.8906 , 0.885  , 0.8843 ,\n",
       "            0.8833 , 0.8774 , 0.8745 , 0.8735 , 0.8726 , 0.872  , 0.866  ,\n",
       "            0.8657 , 0.8647 , 0.8643 , 0.858  , 0.8564 , 0.853  , 0.8506 ,\n",
       "            0.8335 , 0.8325 , 0.8306 , 0.83   , 0.8276 , 0.8228 , 0.822  ,\n",
       "            0.82   , 0.8174 , 0.817  , 0.8154 , 0.809  , 0.8057 , 0.798  ,\n",
       "            0.7964 , 0.793  , 0.792  , 0.7896 , 0.7803 , 0.7773 , 0.7744 ,\n",
       "            0.764  , 0.752  , 0.731  , 0.714  , 0.707  , 0.692  , 0.689  ,\n",
       "            0.683  , 0.6714 , 0.6675 , 0.6636 , 0.6543 , 0.648  , 0.6426 ,\n",
       "            0.642  , 0.6387 , 0.635  , 0.63   , 0.627  , 0.6265 , 0.607  ,\n",
       "            0.6055 , 0.598  , 0.5977 , 0.5933 , 0.592  , 0.5903 , 0.5874 ,\n",
       "            0.581  , 0.557  , 0.5503 , 0.5474 , 0.5415 , 0.54   , 0.5327 ,\n",
       "            0.5303 , 0.529  , 0.52   , 0.5117 , 0.503  , 0.5024 , 0.5    ,\n",
       "            0.4927 , 0.4827 , 0.4812 , 0.481  , 0.4807 , 0.4712 , 0.471  ,\n",
       "            0.468  , 0.4626 , 0.4622 , 0.4556 , 0.4546 , 0.4539 , 0.452  ,\n",
       "            0.446  , 0.4382 , 0.4316 , 0.4275 , 0.4146 , 0.414  , 0.4124 ,\n",
       "            0.4111 , 0.4072 , 0.3987 , 0.3982 , 0.398  , 0.3875 , 0.3691 ,\n",
       "            0.3586 , 0.3398 , 0.3384 , 0.3342 , 0.332  , 0.3223 , 0.3132 ,\n",
       "            0.289  , 0.2664 , 0.266  , 0.248  , 0.2394 , 0.2306 , 0.2281 ,\n",
       "            0.2152 , 0.2104 , 0.2048 , 0.2031 , 0.2017 , 0.1874 , 0.1749 ,\n",
       "            0.1658 , 0.1611 , 0.1582 , 0.1566 , 0.1489 , 0.1432 , 0.139  ,\n",
       "            0.1284 , 0.1243 , 0.1236 , 0.1235 , 0.1025 , 0.1011 , 0.093  ,\n",
       "            0.0753 , 0.0716 , 0.0666 , 0.03775, 0.03555, 0.02802, 0.02661,\n",
       "            0.02258, 0.01653], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.39166668, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.075     , 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.24615385, 0.25384617,\n",
       "            0.26923078, 0.2769231 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.36153847, 0.3846154 , 0.3923077 , 0.4       , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4923077 , 0.5       , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.66923076, 0.6769231 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86153847, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.997  , 0.9956 , 0.9937 , 0.993  , 0.9927 , 0.992  ,\n",
       "            0.991  , 0.99   , 0.9893 , 0.988  , 0.985  , 0.9844 , 0.984  ,\n",
       "            0.983  , 0.9824 , 0.982  , 0.9814 , 0.9805 , 0.98   , 0.9785 ,\n",
       "            0.978  , 0.9775 , 0.976  , 0.9756 , 0.974  , 0.9736 , 0.9717 ,\n",
       "            0.9707 , 0.9688 , 0.967  , 0.9663 , 0.966  , 0.9653 , 0.9604 ,\n",
       "            0.9595 , 0.959  , 0.9585 , 0.9575 , 0.956  , 0.9546 , 0.951  ,\n",
       "            0.9497 , 0.9487 , 0.9478 , 0.944  , 0.9434 , 0.941  , 0.9404 ,\n",
       "            0.94   , 0.9395 , 0.939  , 0.9375 , 0.937  , 0.9365 , 0.9346 ,\n",
       "            0.932  , 0.93   , 0.9287 , 0.928  , 0.926  , 0.925  , 0.924  ,\n",
       "            0.923  , 0.9194 , 0.919  , 0.918  , 0.917  , 0.916  , 0.9155 ,\n",
       "            0.9146 , 0.914  , 0.9126 , 0.9106 , 0.9077 , 0.904  , 0.897  ,\n",
       "            0.8965 , 0.896  , 0.8896 , 0.887  , 0.886  , 0.885  , 0.879  ,\n",
       "            0.8784 , 0.8716 , 0.8696 , 0.867  , 0.865  , 0.848  , 0.847  ,\n",
       "            0.8447 , 0.844  , 0.841  , 0.8374 , 0.8345 , 0.8325 , 0.832  ,\n",
       "            0.8296 , 0.824  , 0.8203 , 0.813  , 0.8115 , 0.8086 , 0.8057 ,\n",
       "            0.805  , 0.7944 , 0.7935 , 0.7896 , 0.78   , 0.7666 , 0.746  ,\n",
       "            0.7285 , 0.723  , 0.722  , 0.707  , 0.701  , 0.699  , 0.6826 ,\n",
       "            0.6807 , 0.679  , 0.678  , 0.6685 , 0.662  , 0.6562 , 0.656  ,\n",
       "            0.6523 , 0.6504 , 0.643  , 0.6406 , 0.64   , 0.621  , 0.6167 ,\n",
       "            0.6104 , 0.609  , 0.604  , 0.603  , 0.602  , 0.6006 , 0.5933 ,\n",
       "            0.568  , 0.562  , 0.5586 , 0.5513 , 0.548  , 0.5425 , 0.541  ,\n",
       "            0.5405 , 0.5254 , 0.522  , 0.513  , 0.512  , 0.51   , 0.5015 ,\n",
       "            0.4915 , 0.4905 , 0.4897 , 0.489  , 0.479  , 0.4785 , 0.476  ,\n",
       "            0.4688 , 0.4673 , 0.463  , 0.4622 , 0.4614 , 0.46   , 0.4531 ,\n",
       "            0.4453 , 0.438  , 0.4302 , 0.421  , 0.4192 , 0.4175 , 0.4133 ,\n",
       "            0.4126 , 0.4028 , 0.4014 , 0.3992 , 0.3892 , 0.3728 , 0.358  ,\n",
       "            0.3477 , 0.343  , 0.3367 , 0.334  , 0.3271 , 0.3147 , 0.2908 ,\n",
       "            0.2688 , 0.2676 , 0.2473 , 0.2434 , 0.2285 , 0.226  , 0.2166 ,\n",
       "            0.2113 , 0.2045 , 0.2037 , 0.1991 , 0.1846 , 0.1726 , 0.1627 ,\n",
       "            0.1584 , 0.1548 , 0.1543 , 0.1488 , 0.1409 , 0.1359 , 0.1254 ,\n",
       "            0.12085, 0.1204 , 0.11993, 0.10034, 0.09753, 0.0896 , 0.0732 ,\n",
       "            0.06866, 0.0642 , 0.03534, 0.03314, 0.02611, 0.02475, 0.02466,\n",
       "            0.02101, 0.01513], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.425, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16923077,\n",
       "            0.17692308, 0.1923077 , 0.2       , 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.24615385, 0.25384617, 0.26923078, 0.2769231 ,\n",
       "            0.2923077 , 0.3       , 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.43846154, 0.45384616,\n",
       "            0.46923077, 0.5       , 0.50769234, 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.75384617, 0.75384617,\n",
       "            0.7692308 , 0.77692306, 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9976 , 0.9966 , 0.995  , 0.9946 , 0.994  , 0.9937 ,\n",
       "            0.993  , 0.9927 , 0.991  , 0.9907 , 0.988  , 0.9873 , 0.987  ,\n",
       "            0.9863 , 0.986  , 0.985  , 0.984  , 0.9834 , 0.983  , 0.982  ,\n",
       "            0.9805 , 0.98   , 0.979  , 0.9785 , 0.9775 , 0.9766 , 0.975  ,\n",
       "            0.973  , 0.9727 , 0.972  , 0.968  , 0.9673 , 0.967  , 0.9653 ,\n",
       "            0.965  , 0.9644 , 0.9634 , 0.9624 , 0.9604 , 0.9595 , 0.9585 ,\n",
       "            0.958  , 0.9575 , 0.9565 , 0.9556 , 0.953  , 0.952  , 0.9497 ,\n",
       "            0.949  , 0.9487 , 0.9478 , 0.9473 , 0.9463 , 0.945  , 0.9414 ,\n",
       "            0.94   , 0.9395 , 0.938  , 0.935  , 0.934  , 0.9316 , 0.931  ,\n",
       "            0.9307 , 0.9297 , 0.9287 , 0.9277 , 0.9272 , 0.927  , 0.9263 ,\n",
       "            0.9253 , 0.9243 , 0.924  , 0.919  , 0.9155 , 0.9116 , 0.9106 ,\n",
       "            0.9087 , 0.903  , 0.9014 , 0.9004 , 0.8994 , 0.896  , 0.8955 ,\n",
       "            0.894  , 0.8926 , 0.8877 , 0.886  , 0.8843 , 0.8823 , 0.8657 ,\n",
       "            0.864  , 0.863  , 0.8623 , 0.8574 , 0.8545 , 0.8535 , 0.8496 ,\n",
       "            0.849  , 0.8486 , 0.842  , 0.8413 , 0.8325 , 0.832  , 0.826  ,\n",
       "            0.824  , 0.8237 , 0.814  , 0.8135 , 0.8115 , 0.8013 , 0.792  ,\n",
       "            0.77   , 0.755  , 0.7466 , 0.7446 , 0.7295 , 0.7236 , 0.7197 ,\n",
       "            0.7056 , 0.7036 , 0.702  , 0.7017 , 0.695  , 0.6885 , 0.682  ,\n",
       "            0.6816 , 0.678  , 0.6675 , 0.6655 , 0.6646 , 0.661  , 0.642  ,\n",
       "            0.6387 , 0.6357 , 0.631  , 0.624  , 0.6226 , 0.622  , 0.6187 ,\n",
       "            0.586  , 0.585  , 0.5757 , 0.5693 , 0.5674 , 0.5654 , 0.5615 ,\n",
       "            0.56   , 0.5464 , 0.5435 , 0.5303 , 0.529  , 0.528  , 0.5205 ,\n",
       "            0.512  , 0.5117 , 0.5107 , 0.507  , 0.498  , 0.497  , 0.4922 ,\n",
       "            0.486  , 0.4846 , 0.4834 , 0.4817 , 0.4814 , 0.4736 , 0.4724 ,\n",
       "            0.4626 , 0.458  , 0.4475 , 0.4377 , 0.4312 , 0.4307 , 0.4297 ,\n",
       "            0.4292 , 0.4282 , 0.4155 , 0.4143 , 0.4126 , 0.4036 , 0.3813 ,\n",
       "            0.3726 , 0.3525 , 0.348  , 0.343  , 0.3406 , 0.3357 , 0.3203 ,\n",
       "            0.2944 , 0.2742 , 0.2717 , 0.2498 , 0.2441 , 0.2292 , 0.2266 ,\n",
       "            0.2166 , 0.2113 , 0.2047 , 0.2035 , 0.1987 , 0.1837 , 0.1718 ,\n",
       "            0.1616 , 0.1571 , 0.1531 , 0.1527 , 0.1469 , 0.1396 , 0.1342 ,\n",
       "            0.1235 , 0.1186 , 0.1174 , 0.0979 , 0.09485, 0.0871 , 0.07056,\n",
       "            0.066  , 0.06223, 0.0332 , 0.03102, 0.02423, 0.02293, 0.0228 ,\n",
       "            0.01935, 0.01385], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.48333332, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03076923, 0.04615385,\n",
       "            0.05384615, 0.06923077, 0.08461539, 0.1       , 0.10769231,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16923077, 0.17692308, 0.2       , 0.21538462, 0.22307692,\n",
       "            0.24615385, 0.25384617, 0.2769231 , 0.2923077 , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.44615385, 0.46153846, 0.47692308, 0.4846154 ,\n",
       "            0.5       , 0.5153846 , 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5846154 ,\n",
       "            0.5923077 , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.76153845,\n",
       "            0.77692306, 0.77692306, 0.7846154 , 0.8       , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.84615386, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.998  , 0.9976 , 0.996  , 0.9956 , 0.995  , 0.9946 ,\n",
       "            0.993  , 0.99   , 0.9897 , 0.9893 , 0.989  , 0.9883 , 0.9873 ,\n",
       "            0.987  , 0.9863 , 0.986  , 0.9844 , 0.983  , 0.982  , 0.981  ,\n",
       "            0.98   , 0.978  , 0.9775 , 0.9736 , 0.973  , 0.9727 , 0.9717 ,\n",
       "            0.971  , 0.9707 , 0.97   , 0.9688 , 0.9673 , 0.9663 , 0.966  ,\n",
       "            0.9653 , 0.965  , 0.9644 , 0.963  , 0.961  , 0.9604 , 0.958  ,\n",
       "            0.9575 , 0.957  , 0.9565 , 0.956  , 0.9556 , 0.955  , 0.9536 ,\n",
       "            0.952  , 0.9507 , 0.9497 , 0.9487 , 0.9478 , 0.945  , 0.942  ,\n",
       "            0.9414 , 0.941  , 0.94   , 0.9395 , 0.9385 , 0.938  , 0.9375 ,\n",
       "            0.9365 , 0.9355 , 0.9346 , 0.9307 , 0.928  , 0.9243 , 0.9233 ,\n",
       "            0.922  , 0.917  , 0.916  , 0.915  , 0.9146 , 0.914  , 0.911  ,\n",
       "            0.9097 , 0.9077 , 0.9014 , 0.899  , 0.897  , 0.881  , 0.879  ,\n",
       "            0.877  , 0.872  , 0.871  , 0.87   , 0.8677 , 0.8667 , 0.8613 ,\n",
       "            0.8594 , 0.8516 , 0.849  , 0.8486 , 0.8467 , 0.8438 , 0.836  ,\n",
       "            0.833  , 0.832  , 0.8213 , 0.8164 , 0.793  , 0.781  , 0.7705 ,\n",
       "            0.7656 , 0.7524 , 0.7505 , 0.744  , 0.737  , 0.7324 , 0.73   ,\n",
       "            0.729  , 0.721  , 0.716  , 0.709  , 0.708  , 0.705  , 0.692  ,\n",
       "            0.691  , 0.6904 , 0.6875 , 0.6685 , 0.6636 , 0.6626 , 0.662  ,\n",
       "            0.6567 , 0.654  , 0.6465 , 0.6426 , 0.612  , 0.6045 , 0.5996 ,\n",
       "            0.5947 , 0.5938 , 0.5913 , 0.586  , 0.5835 , 0.579  , 0.5674 ,\n",
       "            0.5522 , 0.5474 , 0.5464 , 0.546  , 0.538  , 0.5356 , 0.535  ,\n",
       "            0.5273 , 0.5234 , 0.5225 , 0.5146 , 0.5103 , 0.509  , 0.5083 ,\n",
       "            0.5054 , 0.4973 , 0.4949 , 0.4902 , 0.4824 , 0.4817 , 0.4749 ,\n",
       "            0.463  , 0.4524 , 0.4502 , 0.449  , 0.4448 , 0.4434 , 0.4373 ,\n",
       "            0.434  , 0.4255 , 0.424  , 0.395  , 0.3933 , 0.3657 , 0.3606 ,\n",
       "            0.3533 , 0.3513 , 0.348  , 0.3293 , 0.3037 , 0.2827 , 0.2798 ,\n",
       "            0.2568 , 0.2522 , 0.2335 , 0.2314 , 0.2224 , 0.2168 , 0.2098 ,\n",
       "            0.2089 , 0.202  , 0.1864 , 0.1748 , 0.1641 , 0.1587 , 0.1547 ,\n",
       "            0.1543 , 0.1497 , 0.1409 , 0.135  , 0.1239 , 0.1188 , 0.11755,\n",
       "            0.09827, 0.09436, 0.0865 , 0.0702 , 0.06525, 0.0619 , 0.03204,\n",
       "            0.02982, 0.0232 , 0.02194, 0.02174, 0.01848, 0.01312],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5416667, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05      , 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.075     , 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.10833333,\n",
       "            0.11666667, 0.125     , 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03846154, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.10769231,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.22307692, 0.23846154, 0.25384617, 0.2923077 , 0.3       ,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.42307693, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46923077, 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.5307692 , 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5846154 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.64615387, 0.65384614, 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.76153845,\n",
       "            0.76153845, 0.7692308 , 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9985 , 0.998  , 0.997  , 0.9966 , 0.996  , 0.9956 ,\n",
       "            0.995  , 0.9946 , 0.992  , 0.9917 , 0.991  , 0.9907 , 0.99   ,\n",
       "            0.9897 , 0.989  , 0.9883 , 0.988  , 0.9873 , 0.987  , 0.9863 ,\n",
       "            0.9854 , 0.985  , 0.983  , 0.9795 , 0.979  , 0.9785 , 0.9775 ,\n",
       "            0.977  , 0.9766 , 0.975  , 0.9746 , 0.9736 , 0.9727 , 0.9717 ,\n",
       "            0.971  , 0.9707 , 0.969  , 0.967  , 0.9663 , 0.966  , 0.965  ,\n",
       "            0.9644 , 0.964  , 0.9634 , 0.963  , 0.9624 , 0.9585 , 0.958  ,\n",
       "            0.9575 , 0.9556 , 0.9536 , 0.9526 , 0.9517 , 0.9507 , 0.95   ,\n",
       "            0.949  , 0.9487 , 0.948  , 0.9478 , 0.9473 , 0.9463 , 0.946  ,\n",
       "            0.9404 , 0.939  , 0.938  , 0.936  , 0.933  , 0.931  , 0.929  ,\n",
       "            0.9277 , 0.9272 , 0.927  , 0.9263 , 0.9233 , 0.9224 , 0.9204 ,\n",
       "            0.9185 , 0.9165 , 0.9136 , 0.911  , 0.9004 , 0.8984 , 0.897  ,\n",
       "            0.894  , 0.8936 , 0.8926 , 0.8887 , 0.8867 , 0.8853 , 0.8843 ,\n",
       "            0.884  , 0.883  , 0.8755 , 0.874  , 0.869  , 0.868  , 0.864  ,\n",
       "            0.861  , 0.857  , 0.8555 , 0.8525 , 0.846  , 0.845  , 0.8213 ,\n",
       "            0.8135 , 0.8003 , 0.7866 , 0.7773 , 0.777  , 0.7656 , 0.7637 ,\n",
       "            0.7617 , 0.7583 , 0.7563 , 0.7544 , 0.751  , 0.744  , 0.7427 ,\n",
       "            0.7397 , 0.7246 , 0.717  , 0.712  , 0.7095 , 0.698  , 0.6943 ,\n",
       "            0.689  , 0.6875 , 0.6846 , 0.684  , 0.681  , 0.668  , 0.6636 ,\n",
       "            0.6475 , 0.6333 , 0.6265 , 0.625  , 0.6177 , 0.6143 , 0.6074 ,\n",
       "            0.6064 , 0.6035 , 0.601  , 0.5835 , 0.576  , 0.57   , 0.569  ,\n",
       "            0.5654 , 0.5645 , 0.561  , 0.5483 , 0.548  , 0.5454 , 0.545  ,\n",
       "            0.5405 , 0.54   , 0.528  , 0.5264 , 0.517  , 0.5137 , 0.5117 ,\n",
       "            0.506  , 0.501  , 0.5005 , 0.4854 , 0.473  , 0.4712 , 0.461  ,\n",
       "            0.4573 , 0.4553 , 0.4473 , 0.4385 , 0.4255 , 0.4038 , 0.3728 ,\n",
       "            0.3674 , 0.362  , 0.3608 , 0.3577 , 0.3372 , 0.3086 , 0.2888 ,\n",
       "            0.2852 , 0.262  , 0.255  , 0.236  , 0.2343 , 0.2235 , 0.218  ,\n",
       "            0.2108 , 0.2095 , 0.2029 , 0.1869 , 0.1754 , 0.1644 , 0.158  ,\n",
       "            0.1536 , 0.1534 , 0.1484 , 0.1401 , 0.1337 , 0.1222 , 0.11694,\n",
       "            0.11597, 0.0962 , 0.09204, 0.08417, 0.0678 , 0.0627 , 0.05966,\n",
       "            0.02998, 0.0278 , 0.02148, 0.02025, 0.02007, 0.01698, 0.01196],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.575, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.075     ,\n",
       "            0.075     , 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.11666667, 0.11666667, 0.125     , 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03076923, 0.05384615,\n",
       "            0.06923077, 0.08461539, 0.10769231, 0.12307692, 0.13846155,\n",
       "            0.14615385, 0.16153847, 0.17692308, 0.2       , 0.21538462,\n",
       "            0.22307692, 0.23846154, 0.24615385, 0.25384617, 0.2846154 ,\n",
       "            0.2923077 , 0.30769232, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36923078, 0.37692308, 0.4       , 0.4076923 ,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.46153846, 0.46923077,\n",
       "            0.4846154 , 0.4923077 , 0.50769234, 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.5538462 , 0.5692308 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.61538464, 0.63076925, 0.63846153, 0.65384614,\n",
       "            0.66923076, 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.73846155, 0.75384617, 0.76153845,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.85384613, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.999  , 0.9985 , 0.998  , 0.9976 , 0.997  , 0.996  ,\n",
       "            0.994  , 0.9937 , 0.993  , 0.9927 , 0.992  , 0.9917 , 0.9907 ,\n",
       "            0.9897 , 0.9893 , 0.989  , 0.9883 , 0.988  , 0.987  , 0.9863 ,\n",
       "            0.984  , 0.983  , 0.9824 , 0.9814 , 0.981  , 0.98   , 0.979  ,\n",
       "            0.9775 , 0.9766 , 0.9756 , 0.975  , 0.974  , 0.9727 , 0.972  ,\n",
       "            0.9717 , 0.971  , 0.9707 , 0.97   , 0.9697 , 0.9673 , 0.9663 ,\n",
       "            0.9644 , 0.963  , 0.9624 , 0.9614 , 0.9604 , 0.959  , 0.9585 ,\n",
       "            0.958  , 0.9575 , 0.9565 , 0.956  , 0.9556 , 0.9517 , 0.95   ,\n",
       "            0.9497 , 0.946  , 0.9434 , 0.9424 , 0.942  , 0.94   , 0.939  ,\n",
       "            0.935  , 0.9346 , 0.933  , 0.9297 , 0.9253 , 0.921  , 0.918  ,\n",
       "            0.914  , 0.911  , 0.9077 , 0.9053 , 0.905  , 0.903  , 0.902  ,\n",
       "            0.895  , 0.894  , 0.887  , 0.884  , 0.881  , 0.8794 , 0.874  ,\n",
       "            0.8687 , 0.868  , 0.848  , 0.8447 , 0.829  , 0.8135 , 0.804  ,\n",
       "            0.8027 , 0.7983 , 0.795  , 0.792  , 0.791  , 0.79   , 0.787  ,\n",
       "            0.78   , 0.778  , 0.776  , 0.7593 , 0.753  , 0.747  , 0.7363 ,\n",
       "            0.735  , 0.7314 , 0.73   , 0.7246 , 0.724  , 0.7114 , 0.6953 ,\n",
       "            0.6865 , 0.6816 , 0.677  , 0.6704 , 0.6616 , 0.6567 , 0.643  ,\n",
       "            0.6387 , 0.6313 , 0.629  , 0.625  , 0.62   , 0.618  , 0.6094 ,\n",
       "            0.6084 , 0.6064 , 0.604  , 0.592  , 0.588  , 0.587  , 0.5845 ,\n",
       "            0.581  , 0.5806 , 0.5796 , 0.5776 , 0.566  , 0.559  , 0.547  ,\n",
       "            0.5464 , 0.546  , 0.542  , 0.53   , 0.525  , 0.5176 , 0.513  ,\n",
       "            0.5063 , 0.5005 , 0.4907 , 0.483  , 0.4727 , 0.4702 , 0.4695 ,\n",
       "            0.45   , 0.4119 , 0.387  , 0.3806 , 0.372  , 0.3682 , 0.3618 ,\n",
       "            0.3445 , 0.3184 , 0.2905 , 0.2874 , 0.2703 , 0.2627 , 0.2391 ,\n",
       "            0.2386 , 0.2289 , 0.223  , 0.215  , 0.214  , 0.2042 , 0.187  ,\n",
       "            0.1775 , 0.1664 , 0.1562 , 0.1544 , 0.1527 , 0.15   , 0.1376 ,\n",
       "            0.1312 , 0.1196 , 0.1152 , 0.11475, 0.1138 , 0.09534, 0.0898 ,\n",
       "            0.08167, 0.06647, 0.06085, 0.05634, 0.02774, 0.0258 , 0.01999,\n",
       "            0.0188 , 0.01837, 0.01572, 0.0109 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.59166664, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.04166667, 0.05      ,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.075     , 0.075     ,\n",
       "            0.075     , 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.24166666, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03846154, 0.05384615,\n",
       "            0.06923077, 0.08461539, 0.1       , 0.12307692, 0.13846155,\n",
       "            0.14615385, 0.16923077, 0.17692308, 0.2       , 0.22307692,\n",
       "            0.23076923, 0.24615385, 0.25384617, 0.2769231 , 0.2923077 ,\n",
       "            0.30769232, 0.33076924, 0.33846155, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3923077 , 0.4       , 0.41538462,\n",
       "            0.43076923, 0.43846154, 0.43846154, 0.46153846, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.63846153,\n",
       "            0.65384614, 0.66923076, 0.6769231 , 0.6846154 , 0.7       ,\n",
       "            0.7076923 , 0.72307694, 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9995 , 0.999  , 0.9985 , 0.998  , 0.9976 , 0.997  ,\n",
       "            0.9956 , 0.995  , 0.9946 , 0.994  , 0.9937 , 0.993  , 0.9927 ,\n",
       "            0.9917 , 0.991  , 0.9907 , 0.99   , 0.9897 , 0.9893 , 0.9873 ,\n",
       "            0.9863 , 0.986  , 0.985  , 0.9844 , 0.984  , 0.983  , 0.982  ,\n",
       "            0.9814 , 0.9805 , 0.98   , 0.979  , 0.9785 , 0.9775 , 0.977  ,\n",
       "            0.9766 , 0.976  , 0.9756 , 0.975  , 0.9727 , 0.972  , 0.9707 ,\n",
       "            0.97   , 0.969  , 0.9688 , 0.968  , 0.9673 , 0.967  , 0.966  ,\n",
       "            0.9653 , 0.965  , 0.9644 , 0.964  , 0.9634 , 0.963  , 0.959  ,\n",
       "            0.9575 , 0.954  , 0.9526 , 0.952  , 0.9517 , 0.9487 , 0.9478 ,\n",
       "            0.9443 , 0.944  , 0.9434 , 0.9424 , 0.9395 , 0.9355 , 0.931  ,\n",
       "            0.93   , 0.9277 , 0.926  , 0.9253 , 0.9243 , 0.923  , 0.921  ,\n",
       "            0.919  , 0.918  , 0.915  , 0.9146 , 0.911  , 0.9087 , 0.901  ,\n",
       "            0.8975 , 0.897  , 0.8955 , 0.895  , 0.8926 , 0.8843 , 0.8833 ,\n",
       "            0.867  , 0.866  , 0.849  , 0.8364 , 0.829  , 0.8228 , 0.8213 ,\n",
       "            0.82   , 0.818  , 0.8154 , 0.813  , 0.812  , 0.8105 , 0.804  ,\n",
       "            0.8027 , 0.8003 , 0.783  , 0.777  , 0.7705 , 0.762  , 0.7607 ,\n",
       "            0.759  , 0.752  , 0.7305 , 0.7144 , 0.714  , 0.707  , 0.6987 ,\n",
       "            0.69   , 0.6875 , 0.6646 , 0.6597 , 0.65   , 0.648  , 0.6475 ,\n",
       "            0.6426 , 0.641  , 0.6367 , 0.634  , 0.6333 , 0.633  , 0.622  ,\n",
       "            0.617  , 0.6157 , 0.61   , 0.6084 , 0.604  , 0.595  , 0.5933 ,\n",
       "            0.5923 , 0.588  , 0.578  , 0.5757 , 0.5693 , 0.556  , 0.552  ,\n",
       "            0.5435 , 0.5396 , 0.5312 , 0.531  , 0.5273 , 0.516  , 0.508  ,\n",
       "            0.4983 , 0.4841 , 0.4817 , 0.4607 , 0.42   , 0.396  , 0.389  ,\n",
       "            0.3796 , 0.3752 , 0.371  , 0.3503 , 0.324  , 0.2966 , 0.292  ,\n",
       "            0.2756 , 0.2668 , 0.2405 , 0.2314 , 0.2252 , 0.217  , 0.2158 ,\n",
       "            0.2035 , 0.1864 , 0.1775 , 0.1664 , 0.1549 , 0.1538 , 0.151  ,\n",
       "            0.15   , 0.1367 , 0.1295 , 0.11755, 0.1128 , 0.112  , 0.0939 ,\n",
       "            0.0873 , 0.0792 , 0.06476, 0.05865, 0.0548 , 0.026  , 0.02414,\n",
       "            0.01862, 0.01752, 0.01698, 0.01456, 0.01001], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6166667, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.06666667, 0.075     , 0.075     , 0.075     , 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.14166667, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.375     , 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01538462, 0.04615385, 0.06923077, 0.08461539,\n",
       "            0.1       , 0.12307692, 0.13846155, 0.16923077, 0.17692308,\n",
       "            0.2       , 0.20769231, 0.23076923, 0.24615385, 0.26923078,\n",
       "            0.2846154 , 0.2923077 , 0.30769232, 0.31538463, 0.33076924,\n",
       "            0.33846155, 0.36153847, 0.37692308, 0.3846154 , 0.4076923 ,\n",
       "            0.41538462, 0.43846154, 0.44615385, 0.46923077, 0.4846154 ,\n",
       "            0.5       , 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5769231 , 0.5923077 ,\n",
       "            0.6       , 0.61538464, 0.65384614, 0.6615385 , 0.6769231 ,\n",
       "            0.6846154 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.999   , 0.9985  , 0.998   , 0.997   ,\n",
       "            0.9966  , 0.996   , 0.9956  , 0.995   , 0.9946  , 0.994   ,\n",
       "            0.9937  , 0.993   , 0.9927  , 0.992   , 0.9917  , 0.9907  ,\n",
       "            0.99    , 0.9897  , 0.9893  , 0.9883  , 0.9873  , 0.987   ,\n",
       "            0.9863  , 0.9854  , 0.985   , 0.984   , 0.983   , 0.9824  ,\n",
       "            0.982   , 0.9814  , 0.981   , 0.9805  , 0.9795  , 0.979   ,\n",
       "            0.9785  , 0.9775  , 0.977   , 0.9766  , 0.976   , 0.975   ,\n",
       "            0.973   , 0.9727  , 0.972   , 0.971   , 0.9707  , 0.9683  ,\n",
       "            0.968   , 0.967   , 0.965   , 0.9644  , 0.9634  , 0.963   ,\n",
       "            0.9604  , 0.959   , 0.9565  , 0.956   , 0.9556  , 0.9536  ,\n",
       "            0.953   , 0.951   , 0.9478  , 0.9473  , 0.9463  , 0.9434  ,\n",
       "            0.942   , 0.941   , 0.9395  , 0.939   , 0.9385  , 0.938   ,\n",
       "            0.9375  , 0.935   , 0.933   , 0.931   , 0.9287  , 0.927   ,\n",
       "            0.923   , 0.9214  , 0.918   , 0.9175  , 0.914   , 0.9067  ,\n",
       "            0.902   , 0.9004  , 0.896   , 0.881   , 0.878   , 0.8765  ,\n",
       "            0.8687  , 0.8564  , 0.8545  , 0.8496  , 0.8467  , 0.8447  ,\n",
       "            0.844   , 0.843   , 0.842   , 0.825   , 0.82    , 0.817   ,\n",
       "            0.813   , 0.812   , 0.811   , 0.8096  , 0.808   , 0.8027  ,\n",
       "            0.7837  , 0.766   , 0.7656  , 0.762   , 0.76    , 0.759   ,\n",
       "            0.75    , 0.7495  , 0.73    , 0.717   , 0.713   , 0.697   ,\n",
       "            0.6943  , 0.693   , 0.6914  , 0.6875  , 0.687   , 0.6855  ,\n",
       "            0.681   , 0.68    , 0.6753  , 0.669   , 0.6655  , 0.654   ,\n",
       "            0.653   , 0.6523  , 0.651   , 0.6504  , 0.6265  , 0.6235  ,\n",
       "            0.6206  , 0.615   , 0.6123  , 0.603   , 0.598   , 0.5894  ,\n",
       "            0.5835  , 0.581   , 0.577   , 0.5737  , 0.5605  , 0.5166  ,\n",
       "            0.513   , 0.49    , 0.4463  , 0.4219  , 0.4163  , 0.4082  ,\n",
       "            0.399   , 0.3936  , 0.3743  , 0.3486  , 0.3142  , 0.31    ,\n",
       "            0.3     , 0.2837  , 0.2595  , 0.2583  , 0.247   , 0.2405  ,\n",
       "            0.2323  , 0.2301  , 0.2172  , 0.1979  , 0.1906  , 0.1788  ,\n",
       "            0.1638  , 0.1632  , 0.1598  , 0.1581  , 0.1431  , 0.1356  ,\n",
       "            0.12286 , 0.1193  , 0.1184  , 0.1166  , 0.09845 , 0.0909  ,\n",
       "            0.0821  , 0.06696 , 0.06076 , 0.0556  , 0.0258  , 0.02396 ,\n",
       "            0.01843 , 0.0173  , 0.01666 , 0.014336, 0.009674], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05833333, 0.06666667, 0.075     , 0.075     ,\n",
       "            0.075     , 0.075     , 0.08333334, 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.16666667, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.25      , 0.25833333,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01538462, 0.05384615, 0.07692308, 0.08461539,\n",
       "            0.1       , 0.13846155, 0.15384616, 0.17692308, 0.2       ,\n",
       "            0.20769231, 0.23076923, 0.26153848, 0.2769231 , 0.2923077 ,\n",
       "            0.3       , 0.31538463, 0.33076924, 0.33846155, 0.35384616,\n",
       "            0.36153847, 0.3846154 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.4846154 , 0.4923077 ,\n",
       "            0.50769234, 0.5153846 , 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.64615387, 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.7       , 0.7153846 , 0.72307694, 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7923077 , 0.8       , 0.8       , 0.8076923 , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.9307692 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9995 , 0.999  , 0.9985 , 0.998  , 0.9976 , 0.997  ,\n",
       "            0.9966 , 0.996  , 0.9956 , 0.995  , 0.9946 , 0.994  , 0.9937 ,\n",
       "            0.993  , 0.9927 , 0.992  , 0.991  , 0.9907 , 0.99   , 0.9897 ,\n",
       "            0.9893 , 0.989  , 0.9883 , 0.988  , 0.9873 , 0.987  , 0.986  ,\n",
       "            0.9854 , 0.985  , 0.9844 , 0.984  , 0.9834 , 0.983  , 0.982  ,\n",
       "            0.9814 , 0.981  , 0.9805 , 0.98   , 0.979  , 0.9785 , 0.9775 ,\n",
       "            0.977  , 0.9766 , 0.976  , 0.975  , 0.9746 , 0.9727 , 0.9717 ,\n",
       "            0.9707 , 0.969  , 0.9688 , 0.968  , 0.9663 , 0.965  , 0.963  ,\n",
       "            0.961  , 0.9595 , 0.9585 , 0.9575 , 0.957  , 0.9546 , 0.954  ,\n",
       "            0.951  , 0.9507 , 0.9497 , 0.949  , 0.9487 , 0.9478 , 0.947  ,\n",
       "            0.9463 , 0.9443 , 0.9424 , 0.94   , 0.9395 , 0.939  , 0.9365 ,\n",
       "            0.93   , 0.9287 , 0.927  , 0.9243 , 0.919  , 0.918  , 0.9126 ,\n",
       "            0.911  , 0.903  , 0.9014 , 0.8984 , 0.8955 , 0.8794 , 0.8784 ,\n",
       "            0.878  , 0.8774 , 0.87   , 0.8677 , 0.867  , 0.865  , 0.86   ,\n",
       "            0.853  , 0.849  , 0.846  , 0.8423 , 0.842  , 0.8374 , 0.833  ,\n",
       "            0.8047 , 0.8013 , 0.7993 , 0.7964 , 0.7896 , 0.7812 , 0.7734 ,\n",
       "            0.752  , 0.7515 , 0.749  , 0.737  , 0.735  , 0.7305 , 0.729  ,\n",
       "            0.723  , 0.722  , 0.7217 , 0.716  , 0.7114 , 0.708  , 0.7075 ,\n",
       "            0.7046 , 0.7036 , 0.6987 , 0.6978 , 0.6943 , 0.6875 , 0.6855 ,\n",
       "            0.6665 , 0.6606 , 0.659  , 0.656  , 0.6514 , 0.65   , 0.649  ,\n",
       "            0.6455 , 0.6357 , 0.6323 , 0.6147 , 0.6025 , 0.586  , 0.545  ,\n",
       "            0.538  , 0.515  , 0.4712 , 0.4495 , 0.443  , 0.4333 , 0.4226 ,\n",
       "            0.4185 , 0.3967 , 0.3726 , 0.3362 , 0.3313 , 0.3235 , 0.306  ,\n",
       "            0.2805 , 0.2776 , 0.266  , 0.259  , 0.2502 , 0.2482 , 0.2338 ,\n",
       "            0.2128 , 0.2059 , 0.1937 , 0.1772 , 0.1754 , 0.172  , 0.1714 ,\n",
       "            0.1543 , 0.146  , 0.1323 , 0.1289 , 0.1274 , 0.1254 , 0.1063 ,\n",
       "            0.0979 , 0.0883 , 0.0724 , 0.0656 , 0.0601 , 0.02763, 0.02562,\n",
       "            0.01968, 0.01848, 0.01778, 0.01525, 0.01025], dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.09701493, 0.10447761, 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.1641791 ,\n",
       "            0.17910448, 0.18656716, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.31343284, 0.32089552,\n",
       "            0.32089552, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.54477614, 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5597015 , 0.5597015 , 0.5597015 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.57462686, 0.58208954, 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5970149 , 0.5970149 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.6119403 , 0.6119403 , 0.6119403 , 0.6119403 , 0.6119403 ,\n",
       "            0.619403  , 0.619403  , 0.619403  , 0.619403  , 0.6268657 ,\n",
       "            0.6268657 , 0.6268657 , 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6567164 , 0.6567164 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.67164177, 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.69402987, 0.70149255, 0.70149255, 0.7089552 , 0.7089552 ,\n",
       "            0.7164179 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.7910448 , 0.79850745, 0.80597013, 0.80597013,\n",
       "            0.8134328 , 0.8134328 , 0.8208955 , 0.82835823, 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.8731343 ,\n",
       "            0.8731343 , 0.880597  , 0.880597  , 0.8880597 , 0.8880597 ,\n",
       "            0.8880597 , 0.8955224 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.92537314, 0.9328358 , 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.9477612 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00862069, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.03448276, 0.03448276, 0.03448276, 0.03448276,\n",
       "            0.03448276, 0.04310345, 0.06034483, 0.06034483, 0.06034483,\n",
       "            0.06896552, 0.0775862 , 0.0862069 , 0.09482758, 0.09482758,\n",
       "            0.10344828, 0.10344828, 0.11206897, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.18965517, 0.19827586, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.5086207 , 0.51724136, 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5862069 , 0.5948276 , 0.6034483 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62068963, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.63793105, 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.69827586, 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.7586207 , 0.76724136, 0.7758621 , 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.79310346, 0.79310346, 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.8189655 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8362069 , 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.86206895, 0.86206895, 0.86206895, 0.86206895, 0.86206895,\n",
       "            0.86206895, 0.86206895, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4675, 0.4668, 0.4666, 0.466 , 0.4648, 0.4639, 0.4634,\n",
       "            0.4622, 0.462 , 0.4614, 0.4602, 0.4587, 0.4575, 0.457 , 0.4568,\n",
       "            0.4565, 0.456 , 0.4558, 0.4556, 0.455 , 0.4548, 0.4546, 0.4524,\n",
       "            0.4514, 0.451 , 0.45  , 0.4492, 0.4485, 0.448 , 0.4473, 0.446 ,\n",
       "            0.4412, 0.4377, 0.4375, 0.4358, 0.4353, 0.4336, 0.433 , 0.4326,\n",
       "            0.4297, 0.429 , 0.425 , 0.423 , 0.4224, 0.416 , 0.4133, 0.4106,\n",
       "            0.4104, 0.4087, 0.4084, 0.4082, 0.408 , 0.4072, 0.4016, 0.401 ,\n",
       "            0.4004, 0.3977, 0.3958, 0.391 , 0.3896, 0.3882, 0.3853, 0.3845,\n",
       "            0.3835, 0.3833, 0.3828, 0.3816, 0.377 , 0.376 , 0.375 , 0.3735,\n",
       "            0.3726, 0.3706, 0.37  , 0.3645, 0.364 , 0.3635, 0.3628, 0.362 ,\n",
       "            0.3604, 0.359 , 0.3586, 0.357 , 0.3552, 0.355 , 0.354 , 0.3523,\n",
       "            0.3494, 0.3467, 0.3462, 0.3442, 0.3433, 0.3428, 0.3423, 0.3413,\n",
       "            0.3374, 0.3367, 0.3357, 0.3354, 0.3342, 0.3337, 0.333 , 0.332 ,\n",
       "            0.3308, 0.3281, 0.328 , 0.3262, 0.3254, 0.3228, 0.321 , 0.3147,\n",
       "            0.3137, 0.311 , 0.3098, 0.3086, 0.3074, 0.3054, 0.3052, 0.305 ,\n",
       "            0.3044, 0.3018, 0.2993, 0.2935, 0.2908, 0.2893, 0.2869, 0.2856,\n",
       "            0.2786, 0.2766, 0.276 , 0.2756, 0.2722, 0.2717, 0.2693, 0.2683,\n",
       "            0.268 , 0.2646, 0.2637, 0.2632, 0.2612, 0.2593, 0.258 , 0.2546,\n",
       "            0.2534, 0.2532, 0.2522, 0.2515, 0.2512, 0.2505, 0.2502, 0.2477,\n",
       "            0.2462, 0.246 , 0.2455, 0.2452, 0.2438, 0.243 , 0.2429, 0.2402,\n",
       "            0.2399, 0.2394, 0.2386, 0.2379, 0.2363, 0.2358, 0.2352, 0.2339,\n",
       "            0.2338, 0.2322, 0.2313, 0.2302, 0.2297, 0.2294, 0.2289, 0.2277,\n",
       "            0.2274, 0.2251, 0.2224, 0.2217, 0.2213, 0.2212, 0.2205, 0.2194,\n",
       "            0.2191, 0.2185, 0.2166, 0.2148, 0.2144, 0.2142, 0.2125, 0.2123,\n",
       "            0.2119, 0.2118, 0.2106, 0.2096, 0.209 , 0.2075, 0.2037, 0.2028,\n",
       "            0.2024, 0.1996, 0.1989, 0.1971, 0.1962, 0.1958, 0.1952, 0.195 ,\n",
       "            0.193 , 0.1915, 0.1893, 0.1891, 0.1882, 0.1846, 0.1836, 0.1833,\n",
       "            0.1819, 0.1779, 0.1764, 0.1704, 0.1674, 0.1633, 0.1602, 0.1561,\n",
       "            0.15  , 0.1471, 0.147 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14925373, 0.1641791 , 0.17910448,\n",
       "            0.19402985, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35074627, 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5       , 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5597015 , 0.5597015 , 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5597015 , 0.5597015 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.57462686, 0.57462686, 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5970149 , 0.5970149 , 0.5970149 , 0.5970149 ,\n",
       "            0.5970149 , 0.5970149 , 0.6044776 , 0.6119403 , 0.6119403 ,\n",
       "            0.619403  , 0.619403  , 0.6268657 , 0.63432837, 0.63432837,\n",
       "            0.63432837, 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.7238806 , 0.7238806 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.8208955 , 0.8208955 ,\n",
       "            0.82835823, 0.82835823, 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8880597 , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.91791046, 0.92537314,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00862069, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.02586207, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.04310345, 0.05172414,\n",
       "            0.06034483, 0.06034483, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0775862 , 0.0862069 , 0.09482758, 0.10344828, 0.11206897,\n",
       "            0.12068965, 0.12068965, 0.13793103, 0.14655173, 0.1637931 ,\n",
       "            0.1724138 , 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.28448275,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.51724136, 0.5258621 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.6896552 , 0.69827586, 0.69827586, 0.69827586, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8103448 , 0.8103448 , 0.82758623,\n",
       "            0.82758623, 0.8362069 , 0.8362069 , 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.86206895, 0.86206895, 0.86206895,\n",
       "            0.86206895, 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.87931037, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4473 , 0.446  , 0.4456 , 0.4436 , 0.4429 , 0.4426 ,\n",
       "            0.4417 , 0.4412 , 0.4397 , 0.438  , 0.4373 , 0.437  , 0.4358 ,\n",
       "            0.4353 , 0.4338 , 0.4336 , 0.4333 , 0.4329 , 0.4326 , 0.4316 ,\n",
       "            0.4304 , 0.4287 , 0.4277 , 0.4268 , 0.4265 , 0.4255 , 0.425  ,\n",
       "            0.4219 , 0.4211 , 0.421  , 0.4202 , 0.4182 , 0.4126 , 0.4119 ,\n",
       "            0.411  , 0.4087 , 0.406  , 0.4055 , 0.4053 , 0.403  , 0.4028 ,\n",
       "            0.4026 , 0.3984 , 0.3982 , 0.395  , 0.3906 , 0.385  , 0.3848 ,\n",
       "            0.38   , 0.3792 , 0.3787 , 0.3782 , 0.3777 , 0.371  , 0.37   ,\n",
       "            0.3699 , 0.3613 , 0.3606 , 0.3599 , 0.3586 , 0.3557 , 0.3538 ,\n",
       "            0.35   , 0.3486 , 0.3481 , 0.345  , 0.3447 , 0.3423 , 0.3413 ,\n",
       "            0.3362 , 0.3335 , 0.3313 , 0.3308 , 0.3298 , 0.3296 , 0.327  ,\n",
       "            0.3198 , 0.318  , 0.3167 , 0.3162 , 0.313  , 0.3115 , 0.311  ,\n",
       "            0.309  , 0.306  , 0.3057 , 0.305  , 0.3032 , 0.3025 , 0.3013 ,\n",
       "            0.2998 , 0.297  , 0.2969 , 0.296  , 0.2954 , 0.2922 , 0.2908 ,\n",
       "            0.2878 , 0.2864 , 0.2847 , 0.2837 , 0.2822 , 0.2817 , 0.2812 ,\n",
       "            0.281  , 0.2805 , 0.2778 , 0.2747 , 0.2742 , 0.273  , 0.2727 ,\n",
       "            0.272  , 0.2678 , 0.2676 , 0.2673 , 0.2656 , 0.2615 , 0.2595 ,\n",
       "            0.2556 , 0.255  , 0.2534 , 0.2477 , 0.247  , 0.2463 , 0.2456 ,\n",
       "            0.2406 , 0.2405 , 0.239  , 0.2384 , 0.235  , 0.2274 , 0.2273 ,\n",
       "            0.2272 , 0.2264 , 0.2263 , 0.2246 , 0.2235 , 0.2234 , 0.2207 ,\n",
       "            0.2203 , 0.22   , 0.2157 , 0.2156 , 0.2137 , 0.2134 , 0.2113 ,\n",
       "            0.2094 , 0.2091 , 0.2076 , 0.2069 , 0.2065 , 0.2056 , 0.2029 ,\n",
       "            0.2023 , 0.2012 , 0.1998 , 0.1989 , 0.1959 , 0.1953 , 0.1937 ,\n",
       "            0.1936 , 0.1912 , 0.1898 , 0.1887 , 0.1866 , 0.1841 , 0.1831 ,\n",
       "            0.183  , 0.1826 , 0.1823 , 0.1804 , 0.1797 , 0.1796 , 0.1771 ,\n",
       "            0.1765 , 0.1761 , 0.1755 , 0.1753 , 0.1744 , 0.1727 , 0.1726 ,\n",
       "            0.172  , 0.1719 , 0.1715 , 0.1714 , 0.1685 , 0.1656 , 0.1652 ,\n",
       "            0.1643 , 0.164  , 0.1633 , 0.1615 , 0.1614 , 0.1593 , 0.1588 ,\n",
       "            0.1573 , 0.1566 , 0.1564 , 0.1559 , 0.1554 , 0.1548 , 0.1539 ,\n",
       "            0.153  , 0.1497 , 0.1488 , 0.147  , 0.1466 , 0.1462 , 0.1461 ,\n",
       "            0.1453 , 0.1451 , 0.1447 , 0.1417 , 0.1416 , 0.1384 , 0.1375 ,\n",
       "            0.137  , 0.1367 , 0.136  , 0.1355 , 0.134  , 0.1292 , 0.1279 ,\n",
       "            0.1235 , 0.11676, 0.11536, 0.1093 , 0.10376, 0.0995 , 0.0986 ,\n",
       "            0.09705], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.36567163, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5597015 , 0.5597015 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.58208954, 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.619403  , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.63432837, 0.63432837, 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.73880595, 0.73880595, 0.74626863, 0.75373137, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.8208955 ,\n",
       "            0.8208955 , 0.82835823, 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00862069, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.04310345, 0.05172414,\n",
       "            0.06034483, 0.06034483, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.11206897,\n",
       "            0.12068965, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.20689656, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.6896552 , 0.69827586, 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.82758623, 0.8362069 , 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.427  , 0.4255 , 0.425  , 0.4246 , 0.4233 , 0.4216 ,\n",
       "            0.421  , 0.4204 , 0.4177 , 0.4158 , 0.4155 , 0.4153 , 0.4143 ,\n",
       "            0.4138 , 0.4136 , 0.412  , 0.4114 , 0.411  , 0.4104 , 0.41   ,\n",
       "            0.409  , 0.4087 , 0.4084 , 0.4082 , 0.4058 , 0.405  , 0.4045 ,\n",
       "            0.4038 , 0.4026 , 0.402  , 0.4    , 0.3965 , 0.3958 , 0.395  ,\n",
       "            0.3948 , 0.3936 , 0.3875 , 0.386  , 0.3853 , 0.3843 , 0.382  ,\n",
       "            0.3787 , 0.3774 , 0.3765 , 0.3743 , 0.3735 , 0.3733 , 0.371  ,\n",
       "            0.3677 , 0.366  , 0.3599 , 0.3596 , 0.3523 , 0.3506 , 0.35   ,\n",
       "            0.3481 , 0.345  , 0.3396 , 0.3386 , 0.3367 , 0.3276 , 0.3262 ,\n",
       "            0.3257 , 0.3247 , 0.3242 , 0.3208 , 0.3203 , 0.3142 , 0.3113 ,\n",
       "            0.309  , 0.3079 , 0.3054 , 0.3047 , 0.3037 , 0.2983 , 0.2974 ,\n",
       "            0.2932 , 0.2925 , 0.2915 , 0.2908 , 0.29   , 0.2898 , 0.2874 ,\n",
       "            0.287  , 0.281  , 0.277  , 0.2766 , 0.275  , 0.2708 , 0.2703 ,\n",
       "            0.2695 , 0.269  , 0.2668 , 0.265  , 0.2637 , 0.263  , 0.2627 ,\n",
       "            0.2622 , 0.2603 , 0.2588 , 0.2573 , 0.253  , 0.2515 , 0.249  ,\n",
       "            0.248  , 0.2422 , 0.2417 , 0.2413 , 0.2386 , 0.2367 , 0.2363 ,\n",
       "            0.236  , 0.2352 , 0.2351 , 0.234  , 0.2339 , 0.2332 , 0.2289 ,\n",
       "            0.228  , 0.2264 , 0.2229 , 0.2222 , 0.2198 , 0.2194 , 0.2156 ,\n",
       "            0.2108 , 0.2085 , 0.2075 , 0.2073 , 0.207  , 0.2069 , 0.2068 ,\n",
       "            0.2054 , 0.2042 , 0.2001 , 0.1987 , 0.1947 , 0.1942 , 0.1941 ,\n",
       "            0.1937 , 0.1927 , 0.1903 , 0.19   , 0.1893 , 0.1869 , 0.1855 ,\n",
       "            0.181  , 0.1807 , 0.1805 , 0.1798 , 0.1775 , 0.1766 , 0.1757 ,\n",
       "            0.1752 , 0.1736 , 0.1727 , 0.1724 , 0.1703 , 0.1682 , 0.1669 ,\n",
       "            0.1658 , 0.1656 , 0.1652 , 0.161  , 0.1586 , 0.1584 , 0.1575 ,\n",
       "            0.1552 , 0.154  , 0.1486 , 0.148  , 0.1477 , 0.1469 , 0.1459 ,\n",
       "            0.1454 , 0.1451 , 0.1426 , 0.14   , 0.1399 , 0.1393 , 0.1377 ,\n",
       "            0.1371 , 0.1357 , 0.1339 , 0.1337 , 0.1327 , 0.1326 , 0.1324 ,\n",
       "            0.1312 , 0.1305 , 0.1298 , 0.1289 , 0.1279 , 0.1272 , 0.1261 ,\n",
       "            0.1241 , 0.1219 , 0.12177, 0.1216 , 0.121  , 0.12054, 0.1201 ,\n",
       "            0.1193 , 0.1178 , 0.11755, 0.1166 , 0.1152 , 0.11456, 0.1142 ,\n",
       "            0.1138 , 0.1099 , 0.1086 , 0.1063 , 0.1054 , 0.10486, 0.1047 ,\n",
       "            0.1036 , 0.1032 , 0.1023 , 0.1019 , 0.10144, 0.1007 , 0.0964 ,\n",
       "            0.0959 , 0.09503, 0.0927 , 0.0925 , 0.0898 , 0.0871 , 0.07825,\n",
       "            0.0778 , 0.07306, 0.0673 , 0.066  , 0.06323, 0.06256],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.19402985, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.36567163, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.4402985 , 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.54477614,\n",
       "            0.54477614, 0.54477614, 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5597015 , 0.5597015 , 0.5597015 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6119403 , 0.6268657 ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7164179 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.73880595, 0.75373137,\n",
       "            0.75373137, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8134328 , 0.8208955 , 0.8208955 , 0.82835823, 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.8880597 , 0.8955224 , 0.9029851 , 0.9029851 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.96268654, 0.9701493 , 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00862069, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.03448276, 0.03448276, 0.03448276,\n",
       "            0.04310345, 0.04310345, 0.05172414, 0.06034483, 0.06034483,\n",
       "            0.06896552, 0.06896552, 0.0775862 , 0.0862069 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.21551724, 0.22413793, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.4224138 , 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.54310346, 0.55172414, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.5689655 , 0.57758623, 0.5948276 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.79310346, 0.8103448 ,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.407  , 0.4053 , 0.405  , 0.4043 , 0.4036 , 0.4011 ,\n",
       "            0.4004 , 0.4001 , 0.3997 , 0.3962 , 0.3943 , 0.3938 , 0.3936 ,\n",
       "            0.393  , 0.3923 , 0.392  , 0.3906 , 0.39   , 0.3896 , 0.3894 ,\n",
       "            0.3882 , 0.388  , 0.3875 , 0.3855 , 0.3853 , 0.3826 , 0.3823 ,\n",
       "            0.3816 , 0.3809 , 0.3796 , 0.379  , 0.3755 , 0.3728 , 0.372  ,\n",
       "            0.3713 , 0.3699 , 0.3684 , 0.3635 , 0.3633 , 0.3616 , 0.361  ,\n",
       "            0.3599 , 0.3591 , 0.3528 , 0.3518 , 0.3516 , 0.3513 , 0.3477 ,\n",
       "            0.3464 , 0.3452 , 0.343  , 0.3418 , 0.3362 , 0.3354 , 0.3262 ,\n",
       "            0.3232 , 0.3228 , 0.32   , 0.3164 , 0.3108 , 0.309  , 0.3076 ,\n",
       "            0.3005 , 0.2966 , 0.2954 , 0.295  , 0.2942 , 0.294  , 0.289  ,\n",
       "            0.2837 , 0.283  , 0.278  , 0.2766 , 0.276  , 0.2751 , 0.274  ,\n",
       "            0.2732 , 0.2673 , 0.2646 , 0.261  , 0.2593 , 0.2583 , 0.2563 ,\n",
       "            0.2554 , 0.2551 , 0.2546 , 0.2542 , 0.2522 , 0.2466 , 0.2434 ,\n",
       "            0.2426 , 0.2411 , 0.2407 , 0.2395 , 0.2346 , 0.2335 , 0.2314 ,\n",
       "            0.2295 , 0.228  , 0.2273 , 0.2272 , 0.2266 , 0.2247 , 0.2246 ,\n",
       "            0.2173 , 0.2156 , 0.215  , 0.2148 , 0.2147 , 0.2114 , 0.2098 ,\n",
       "            0.2045 , 0.2034 , 0.2015 , 0.199  , 0.1987 , 0.1973 , 0.197  ,\n",
       "            0.1968 , 0.1953 , 0.1915 , 0.1897 , 0.1887 , 0.188  , 0.1816 ,\n",
       "            0.1814 , 0.1799 , 0.1788 , 0.1782 , 0.1774 , 0.1755 , 0.1692 ,\n",
       "            0.1685 , 0.1681 , 0.167  , 0.1666 , 0.1653 , 0.1626 , 0.1622 ,\n",
       "            0.1605 , 0.1597 , 0.1587 , 0.1542 , 0.154  , 0.1531 , 0.153  ,\n",
       "            0.152  , 0.1515 , 0.1499 , 0.1495 , 0.1483 , 0.1482 , 0.1461 ,\n",
       "            0.1438 , 0.142  , 0.1416 , 0.1404 , 0.1396 , 0.1346 , 0.134  ,\n",
       "            0.1335 , 0.1299 , 0.1277 , 0.1268 , 0.1261 , 0.12115, 0.12085,\n",
       "            0.12036, 0.118  , 0.11633, 0.11554, 0.11475, 0.11395, 0.111  ,\n",
       "            0.1093 , 0.10876, 0.1058 , 0.1052 , 0.1011 , 0.1007 , 0.0997 ,\n",
       "            0.09894, 0.09845, 0.09827, 0.0979 , 0.09753, 0.0964 , 0.0962 ,\n",
       "            0.0957 , 0.09534, 0.09467, 0.0935 , 0.0904 , 0.0898 , 0.0893 ,\n",
       "            0.0891 , 0.0882 , 0.088  , 0.0879 , 0.0866 , 0.0865 , 0.0848 ,\n",
       "            0.0845 , 0.08405, 0.0836 , 0.0833 , 0.0821 , 0.07764, 0.0775 ,\n",
       "            0.07544, 0.0752 , 0.075  , 0.0742 , 0.074  , 0.0732 , 0.0717 ,\n",
       "            0.0715 , 0.0708 , 0.0702 , 0.06757, 0.06586, 0.06396, 0.06244,\n",
       "            0.05933, 0.05243, 0.04886, 0.04376, 0.04068, 0.04037],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.02238806, 0.03731343, 0.04477612,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.19402985, 0.20149253, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.36567163,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.5298507 , 0.5298507 , 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5597015 , 0.5597015 , 0.5597015 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.57462686, 0.57462686, 0.57462686, 0.57462686,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6044776 , 0.6119403 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.6268657 , 0.63432837, 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6492537 , 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7238806 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.75373137, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.8507463 , 0.85820895, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00862069,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.02586207, 0.02586207, 0.03448276, 0.03448276,\n",
       "            0.03448276, 0.04310345, 0.05172414, 0.06034483, 0.06034483,\n",
       "            0.06896552, 0.06896552, 0.0775862 , 0.0775862 , 0.09482758,\n",
       "            0.11206897, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.21551724, 0.22413793,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.27586207, 0.29310346, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.7758621 , 0.7844828 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3843 , 0.3823 , 0.3809 , 0.3787 , 0.3777 , 0.377  ,\n",
       "            0.3762 , 0.373  , 0.3716 , 0.371  , 0.3708 , 0.37   , 0.3696 ,\n",
       "            0.3687 , 0.3667 , 0.366  , 0.3655 , 0.3652 , 0.3645 , 0.3635 ,\n",
       "            0.3618 , 0.361  , 0.3599 , 0.3591 , 0.359  , 0.358  , 0.3574 ,\n",
       "            0.3528 , 0.3516 , 0.351  , 0.3494 , 0.3486 , 0.3474 , 0.3462 ,\n",
       "            0.3418 , 0.341  , 0.3389 , 0.3386 , 0.3364 , 0.3315 , 0.3303 ,\n",
       "            0.329  , 0.3286 , 0.3274 , 0.326  , 0.3228 , 0.3223 , 0.3193 ,\n",
       "            0.3154 , 0.3147 , 0.3044 , 0.3008 , 0.3    , 0.2993 , 0.2974 ,\n",
       "            0.2957 , 0.288  , 0.2878 , 0.2864 , 0.2803 , 0.2754 , 0.2747 ,\n",
       "            0.2734 , 0.266  , 0.2632 , 0.26   , 0.2566 , 0.256  , 0.2542 ,\n",
       "            0.2534 , 0.2467 , 0.2415 , 0.2405 , 0.2394 , 0.2383 , 0.237  ,\n",
       "            0.234  , 0.2339 , 0.2334 , 0.2303 , 0.228  , 0.2233 , 0.2218 ,\n",
       "            0.2198 , 0.2194 , 0.2181 , 0.2134 , 0.2123 , 0.2113 , 0.2081 ,\n",
       "            0.2073 , 0.2064 , 0.2059 , 0.2056 , 0.2037 , 0.2029 , 0.2    ,\n",
       "            0.1979 , 0.1947 , 0.1943 , 0.1941 , 0.1925 , 0.19   , 0.187  ,\n",
       "            0.1837 , 0.1805 , 0.18   , 0.1799 , 0.1783 , 0.178  , 0.1768 ,\n",
       "            0.1763 , 0.1746 , 0.174  , 0.1709 , 0.1688 , 0.1682 , 0.1676 ,\n",
       "            0.1665 , 0.1635 , 0.1627 , 0.1626 , 0.1611 , 0.1608 , 0.1564 ,\n",
       "            0.1562 , 0.1552 , 0.1537 , 0.1532 , 0.1527 , 0.1489 , 0.1471 ,\n",
       "            0.1465 , 0.1462 , 0.146  , 0.1451 , 0.1443 , 0.142  , 0.1418 ,\n",
       "            0.1417 , 0.1396 , 0.1383 , 0.1373 , 0.1367 , 0.1365 , 0.1356 ,\n",
       "            0.1353 , 0.135  , 0.1321 , 0.1312 , 0.1289 , 0.1277 , 0.127  ,\n",
       "            0.1267 , 0.1204 , 0.12   , 0.1194 , 0.1192 , 0.11536, 0.11475,\n",
       "            0.1126 , 0.11145, 0.1086 , 0.1084 , 0.1045 , 0.10394, 0.1036 ,\n",
       "            0.103  , 0.10144, 0.1007 , 0.0967 , 0.096  , 0.0935 , 0.09235,\n",
       "            0.0906 , 0.0903 , 0.0893 , 0.089  , 0.0888 , 0.0851 , 0.08466,\n",
       "            0.0836 , 0.083  , 0.0824 , 0.0823 , 0.0808 , 0.0804 , 0.0799 ,\n",
       "            0.07935, 0.0786 , 0.07764, 0.07697, 0.0753 , 0.0749 , 0.0742 ,\n",
       "            0.07275, 0.07263, 0.0724 , 0.07227, 0.07184, 0.0715 , 0.0707 ,\n",
       "            0.06995, 0.06903, 0.0684 , 0.0683 , 0.06647, 0.06323, 0.06244,\n",
       "            0.06198, 0.0613 , 0.0612 , 0.05954, 0.0591 , 0.058  , 0.0575 ,\n",
       "            0.05728, 0.05664, 0.0546 , 0.0545 , 0.0526 , 0.0511 , 0.05023,\n",
       "            0.047  , 0.04153, 0.04132, 0.03854, 0.03476, 0.03397, 0.03137,\n",
       "            0.0313 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.17910448, 0.20149253, 0.20895523,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5       , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.54477614, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.54477614, 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5597015 , 0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.58208954, 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 , 0.6119403 ,\n",
       "            0.6119403 , 0.619403  , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6492537 , 0.6492537 , 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.6865672 , 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.73880595, 0.73880595, 0.74626863,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00862069, 0.00862069, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.03448276, 0.03448276, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.05172414, 0.06034483, 0.06034483, 0.06034483,\n",
       "            0.06896552, 0.06896552, 0.0775862 , 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.10344828, 0.11206897, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.30172414, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.38793105, 0.39655173,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3606 , 0.3594 , 0.3586 , 0.3577 , 0.357  , 0.3567 ,\n",
       "            0.355  , 0.3545 , 0.3508 , 0.3506 , 0.3503 , 0.35   , 0.3489 ,\n",
       "            0.348  , 0.346  , 0.3452 , 0.3428 , 0.3416 , 0.3413 , 0.341  ,\n",
       "            0.3408 , 0.34   , 0.3396 , 0.3394 , 0.339  , 0.3389 , 0.338  ,\n",
       "            0.3357 , 0.335  , 0.333  , 0.3325 , 0.3323 , 0.3262 , 0.3257 ,\n",
       "            0.324  , 0.3237 , 0.3235 , 0.3228 , 0.322  , 0.3193 , 0.3171 ,\n",
       "            0.317  , 0.316  , 0.3152 , 0.3098 , 0.3086 , 0.3066 , 0.3027 ,\n",
       "            0.302  , 0.2935 , 0.2908 , 0.29   , 0.2893 , 0.2886 , 0.2874 ,\n",
       "            0.2847 , 0.2795 , 0.2783 , 0.2742 , 0.2732 , 0.272  , 0.2712 ,\n",
       "            0.267  , 0.2666 , 0.2622 , 0.2598 , 0.2554 , 0.2551 , 0.2546 ,\n",
       "            0.2537 , 0.251  , 0.2485 , 0.2424 , 0.2422 , 0.2417 , 0.2407 ,\n",
       "            0.2386 , 0.237  , 0.235  , 0.2347 , 0.2344 , 0.2311 , 0.2303 ,\n",
       "            0.2273 , 0.2217 , 0.2208 , 0.2203 , 0.2202 , 0.2179 , 0.2173 ,\n",
       "            0.2156 , 0.2134 , 0.2106 , 0.2104 , 0.2089 , 0.2079 , 0.207  ,\n",
       "            0.205  , 0.2043 , 0.2023 , 0.202  , 0.1998 , 0.1987 , 0.1985 ,\n",
       "            0.1971 , 0.194  , 0.1935 , 0.1892 , 0.1838 , 0.1836 , 0.1831 ,\n",
       "            0.1826 , 0.1821 , 0.1807 , 0.1792 , 0.1765 , 0.1759 , 0.1754 ,\n",
       "            0.1752 , 0.174  , 0.1718 , 0.1692 , 0.1677 , 0.1674 , 0.167  ,\n",
       "            0.1664 , 0.1614 , 0.1597 , 0.1588 , 0.1587 , 0.1582 , 0.158  ,\n",
       "            0.1544 , 0.1525 , 0.1516 , 0.1515 , 0.1505 , 0.1498 , 0.1489 ,\n",
       "            0.1484 , 0.1482 , 0.1466 , 0.1458 , 0.1439 , 0.1431 , 0.1417 ,\n",
       "            0.1416 , 0.1411 , 0.1388 , 0.1355 , 0.135  , 0.1348 , 0.1343 ,\n",
       "            0.1342 , 0.1326 , 0.1305 , 0.1272 , 0.1254 , 0.1251 , 0.1236 ,\n",
       "            0.1219 , 0.1194 , 0.1184 , 0.11755, 0.1158 , 0.11456, 0.112  ,\n",
       "            0.111  , 0.10913, 0.10724, 0.1069 , 0.1054 , 0.10284, 0.1011 ,\n",
       "            0.09845, 0.0979 , 0.09705, 0.09656, 0.0945 , 0.0937 , 0.0932 ,\n",
       "            0.0927 , 0.0922 , 0.089  , 0.0882 , 0.0873 , 0.0871 , 0.0869 ,\n",
       "            0.0866 , 0.086  , 0.08527, 0.08466, 0.08405, 0.0836 , 0.0818 ,\n",
       "            0.08136, 0.08105, 0.0805 , 0.0801 , 0.0799 , 0.0788 , 0.07684,\n",
       "            0.07666, 0.07654, 0.076  , 0.075  , 0.07465, 0.0734 , 0.0733 ,\n",
       "            0.0729 , 0.07275, 0.0693 , 0.06854, 0.06696, 0.0667 , 0.066  ,\n",
       "            0.0643 , 0.06396, 0.0636 , 0.0627 , 0.0619 , 0.06177, 0.0611 ,\n",
       "            0.0592 , 0.0591 , 0.05698, 0.05542, 0.0547 , 0.05127, 0.04578,\n",
       "            0.04553, 0.04288, 0.03934, 0.0379 , 0.03522], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.19402985, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.2238806 , 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35820895, 0.36567163, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.5298507 , 0.5298507 , 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.54477614, 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.58208954, 0.58208954,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6119403 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.63432837, 0.63432837, 0.64179105, 0.6492537 , 0.6492537 ,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7238806 , 0.7238806 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8208955 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.02586207, 0.02586207, 0.03448276, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.04310345, 0.05172414,\n",
       "            0.06034483, 0.06034483, 0.06034483, 0.06896552, 0.06896552,\n",
       "            0.06896552, 0.0775862 , 0.0862069 , 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.10344828, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.25862068, 0.27586207,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.31896552, 0.3275862 , 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.67241377, 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.79310346, 0.79310346,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3384 , 0.3376 , 0.3372 , 0.3354 , 0.335  , 0.3342 ,\n",
       "            0.334  , 0.333  , 0.3328 , 0.3313 , 0.331  , 0.3306 , 0.3296 ,\n",
       "            0.3293 , 0.3276 , 0.3267 , 0.3264 , 0.3262 , 0.326  , 0.325  ,\n",
       "            0.3237 , 0.323  , 0.3228 , 0.3223 , 0.3215 , 0.321  , 0.32   ,\n",
       "            0.3198 , 0.3184 , 0.3179 , 0.317  , 0.3164 , 0.3157 , 0.3154 ,\n",
       "            0.3147 , 0.3145 , 0.3142 , 0.314  , 0.3123 , 0.3103 , 0.3096 ,\n",
       "            0.3066 , 0.3027 , 0.3    , 0.2952 , 0.295  , 0.2944 , 0.292  ,\n",
       "            0.288  , 0.2854 , 0.285  , 0.2847 , 0.2837 , 0.2822 , 0.279  ,\n",
       "            0.2776 , 0.277  , 0.2717 , 0.2693 , 0.268  , 0.2673 , 0.2664 ,\n",
       "            0.2651 , 0.2646 , 0.2637 , 0.2622 , 0.257  , 0.2556 , 0.2551 ,\n",
       "            0.255  , 0.2522 , 0.2517 , 0.251  , 0.2467 , 0.2458 , 0.2455 ,\n",
       "            0.2448 , 0.241  , 0.239  , 0.2384 , 0.2346 , 0.2344 , 0.2334 ,\n",
       "            0.2332 , 0.2314 , 0.2274 , 0.2269 , 0.226  , 0.2252 , 0.2242 ,\n",
       "            0.2229 , 0.2217 , 0.2175 , 0.215  , 0.2148 , 0.2123 , 0.2114 ,\n",
       "            0.2113 , 0.2089 , 0.2081 , 0.2073 , 0.2068 , 0.206  , 0.2059 ,\n",
       "            0.2009 , 0.2007 , 0.2002 , 0.1991 , 0.1989 , 0.1958 , 0.1956 ,\n",
       "            0.195  , 0.1942 , 0.1923 , 0.1917 , 0.1897 , 0.1876 , 0.1866 ,\n",
       "            0.1855 , 0.1843 , 0.1842 , 0.1794 , 0.1791 , 0.1782 , 0.1776 ,\n",
       "            0.1749 , 0.173  , 0.1724 , 0.1715 , 0.1705 , 0.169  , 0.1687 ,\n",
       "            0.1672 , 0.1669 , 0.1659 , 0.1653 , 0.1647 , 0.1626 , 0.1608 ,\n",
       "            0.1592 , 0.1589 , 0.1588 , 0.1567 , 0.1564 , 0.1555 , 0.1554 ,\n",
       "            0.1538 , 0.1505 , 0.1495 , 0.1486 , 0.1484 , 0.147  , 0.1459 ,\n",
       "            0.1458 , 0.1417 , 0.1414 , 0.1389 , 0.1385 , 0.1359 , 0.1353 ,\n",
       "            0.1337 , 0.1312 , 0.1309 , 0.1305 , 0.1301 , 0.1273 , 0.1268 ,\n",
       "            0.126  , 0.1229 , 0.12067, 0.119  , 0.118  , 0.1172 , 0.1134 ,\n",
       "            0.113  , 0.1122 , 0.1099 , 0.1095 , 0.1078 , 0.1074 , 0.1069 ,\n",
       "            0.1056 , 0.1052 , 0.1043 , 0.1007 , 0.1    , 0.0997 , 0.0995 ,\n",
       "            0.09894, 0.09875, 0.0986 , 0.09686, 0.0957 , 0.09515, 0.0942 ,\n",
       "            0.094  , 0.0933 , 0.09204, 0.0906 , 0.0887 , 0.0885 , 0.0883 ,\n",
       "            0.088  , 0.0873 , 0.0869 , 0.0862 , 0.0851 , 0.0845 , 0.0827 ,\n",
       "            0.082  , 0.0788 , 0.07806, 0.0774 , 0.0772 , 0.0753 , 0.07477,\n",
       "            0.0745 , 0.07385, 0.07306, 0.07227, 0.0702 , 0.07007, 0.06793,\n",
       "            0.0662 , 0.06525, 0.06177, 0.05573, 0.05542, 0.05283, 0.04932,\n",
       "            0.0471 , 0.0442 , 0.0441 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.02238806, 0.03731343, 0.05223881, 0.05970149, 0.07462686,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26119402,\n",
       "            0.26119402, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.37313432, 0.37313432,\n",
       "            0.38059703, 0.3955224 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41044775, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.54477614, 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6119403 , 0.619403  , 0.619403  ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6492537 , 0.6567164 , 0.6641791 , 0.6791045 ,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.00862069, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.04310345, 0.04310345,\n",
       "            0.05172414, 0.05172414, 0.05172414, 0.05172414, 0.06034483,\n",
       "            0.06034483, 0.06034483, 0.06896552, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.0862069 , 0.0862069 , 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.12931034,\n",
       "            0.13793103, 0.13793103, 0.13793103, 0.13793103, 0.13793103,\n",
       "            0.14655173, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.22413793, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.2672414 , 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31034482, 0.31034482, 0.31896552, 0.3275862 , 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3262 , 0.3237 , 0.3203 , 0.3196 , 0.3179 , 0.3176 ,\n",
       "            0.3167 , 0.3162 , 0.316  , 0.3152 , 0.3147 , 0.3145 , 0.3142 ,\n",
       "            0.3137 , 0.3135 , 0.3125 , 0.3113 , 0.311  , 0.3108 , 0.3105 ,\n",
       "            0.31   , 0.3093 , 0.3086 , 0.308  , 0.3066 , 0.3064 , 0.3054 ,\n",
       "            0.3047 , 0.3044 , 0.304  , 0.3027 , 0.302  , 0.3013 , 0.3005 ,\n",
       "            0.2993 , 0.299  , 0.2986 , 0.298  , 0.2979 , 0.2961 , 0.296  ,\n",
       "            0.295  , 0.2935 , 0.2915 , 0.2908 , 0.2898 , 0.286  , 0.2854 ,\n",
       "            0.285  , 0.2837 , 0.2832 , 0.2805 , 0.2786 , 0.2783 , 0.2778 ,\n",
       "            0.2751 , 0.2747 , 0.2727 , 0.2722 , 0.2708 , 0.269  , 0.2686 ,\n",
       "            0.2676 , 0.2651 , 0.2627 , 0.2622 , 0.2605 , 0.2588 , 0.2576 ,\n",
       "            0.2573 , 0.2556 , 0.255  , 0.2532 , 0.2515 , 0.2505 , 0.2498 ,\n",
       "            0.2487 , 0.2452 , 0.2444 , 0.2415 , 0.2413 , 0.241  , 0.2374 ,\n",
       "            0.2362 , 0.2344 , 0.234  , 0.2306 , 0.2277 , 0.2249 , 0.2234 ,\n",
       "            0.223  , 0.2225 , 0.2224 , 0.222  , 0.2211 , 0.2205 , 0.2191 ,\n",
       "            0.219  , 0.2185 , 0.2161 , 0.2156 , 0.2145 , 0.2135 , 0.2124 ,\n",
       "            0.2118 , 0.211  , 0.2074 , 0.2065 , 0.2002 , 0.1995 , 0.1991 ,\n",
       "            0.1982 , 0.1941 , 0.194  , 0.1921 , 0.1907 , 0.1896 , 0.1891 ,\n",
       "            0.1874 , 0.1864 , 0.1844 , 0.1835 , 0.1826 , 0.1821 , 0.181  ,\n",
       "            0.1805 , 0.179  , 0.1779 , 0.1766 , 0.1761 , 0.1747 , 0.1738 ,\n",
       "            0.173  , 0.1726 , 0.1724 , 0.1711 , 0.1671 , 0.166  , 0.1656 ,\n",
       "            0.1654 , 0.1631 , 0.1627 , 0.1608 , 0.1593 , 0.1562 , 0.1558 ,\n",
       "            0.1534 , 0.1516 , 0.1504 , 0.1492 , 0.1486 , 0.1471 , 0.1455 ,\n",
       "            0.145  , 0.1404 , 0.138  , 0.1355 , 0.1346 , 0.1342 , 0.1326 ,\n",
       "            0.1315 , 0.1282 , 0.1268 , 0.1265 , 0.126  , 0.1256 , 0.1252 ,\n",
       "            0.1243 , 0.12067, 0.12054, 0.1197 , 0.1184 , 0.11694, 0.11536,\n",
       "            0.11456, 0.1144 , 0.1142 , 0.11395, 0.11316, 0.113  , 0.11145,\n",
       "            0.11127, 0.11084, 0.1099 , 0.10913, 0.1076 , 0.10596, 0.1056 ,\n",
       "            0.1052 , 0.1041 , 0.10394, 0.103  , 0.1025 , 0.10144, 0.1011 ,\n",
       "            0.1007 , 0.1    , 0.0997 , 0.0986 , 0.09534, 0.09503, 0.093  ,\n",
       "            0.09186, 0.09155, 0.0906 , 0.0898 , 0.0883 , 0.0882 , 0.0874 ,\n",
       "            0.0845 , 0.0825 , 0.0808 , 0.07935, 0.076  , 0.06915, 0.06903,\n",
       "            0.0662 , 0.06335, 0.05975, 0.05676, 0.05646], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.06716418, 0.09701493, 0.1119403 , 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.20895523, 0.20895523, 0.21641791, 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.26119402, 0.26865673, 0.26865673, 0.2761194 ,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.3283582 , 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.42537314, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.4402985 , 0.4477612 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.47761193, 0.48507464, 0.48507464,\n",
       "            0.48507464, 0.48507464, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 , 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5970149 , 0.5970149 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.6641791 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.03448276, 0.04310345, 0.05172414, 0.05172414, 0.05172414,\n",
       "            0.05172414, 0.05172414, 0.05172414, 0.06034483, 0.06896552,\n",
       "            0.06896552, 0.06896552, 0.06896552, 0.06896552, 0.0775862 ,\n",
       "            0.0775862 , 0.0775862 , 0.0862069 , 0.0862069 , 0.0862069 ,\n",
       "            0.0862069 , 0.0862069 , 0.0862069 , 0.0862069 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.10344828, 0.10344828, 0.10344828,\n",
       "            0.10344828, 0.10344828, 0.11206897, 0.12068965, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.13793103, 0.13793103, 0.13793103,\n",
       "            0.13793103, 0.13793103, 0.13793103, 0.14655173, 0.14655173,\n",
       "            0.14655173, 0.14655173, 0.14655173, 0.14655173, 0.14655173,\n",
       "            0.14655173, 0.14655173, 0.15517241, 0.15517241, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.1724138 , 0.1724138 , 0.18103448,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.22413793, 0.23275863, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.35344827, 0.36206895, 0.36206895,\n",
       "            0.36206895, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.6637931 ,\n",
       "            0.6810345 , 0.6810345 , 0.6896552 , 0.69827586, 0.7155172 ,\n",
       "            0.7241379 , 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.80172414,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3396 , 0.33   , 0.3267 , 0.3235 , 0.3193 , 0.3186 ,\n",
       "            0.3162 , 0.3157 , 0.3115 , 0.311  , 0.3105 , 0.309  , 0.3088 ,\n",
       "            0.3086 , 0.3079 , 0.3074 , 0.3071 , 0.307  , 0.3064 , 0.3054 ,\n",
       "            0.3052 , 0.3047 , 0.3044 , 0.3042 , 0.3037 , 0.3032 , 0.303  ,\n",
       "            0.3022 , 0.3018 , 0.3013 , 0.301  , 0.3    , 0.2993 , 0.2988 ,\n",
       "            0.2986 , 0.298  , 0.2976 , 0.2964 , 0.2961 , 0.296  , 0.2957 ,\n",
       "            0.2944 , 0.2937 , 0.291  , 0.289  , 0.2886 , 0.2883 , 0.2869 ,\n",
       "            0.2866 , 0.2864 , 0.2854 , 0.2852 , 0.285  , 0.2847 , 0.2842 ,\n",
       "            0.2834 , 0.2827 , 0.2812 , 0.2808 , 0.2805 , 0.28   , 0.278  ,\n",
       "            0.277  , 0.2761 , 0.276  , 0.2747 , 0.2732 , 0.2727 , 0.272  ,\n",
       "            0.2717 , 0.271  , 0.2693 , 0.269  , 0.2678 , 0.2664 , 0.2644 ,\n",
       "            0.264  , 0.2625 , 0.2612 , 0.2595 , 0.2573 , 0.255  , 0.2542 ,\n",
       "            0.2527 , 0.2522 , 0.251  , 0.2502 , 0.2483 , 0.2478 , 0.2474 ,\n",
       "            0.2449 , 0.243  , 0.2428 , 0.2422 , 0.2421 , 0.239  , 0.2388 ,\n",
       "            0.2379 , 0.237  , 0.2352 , 0.2335 , 0.2334 , 0.2332 , 0.2327 ,\n",
       "            0.2303 , 0.2302 , 0.2278 , 0.2268 , 0.2255 , 0.2225 , 0.2186 ,\n",
       "            0.2163 , 0.2161 , 0.2125 , 0.2118 , 0.2106 , 0.2104 , 0.2091 ,\n",
       "            0.2086 , 0.2081 , 0.2065 , 0.2054 , 0.2047 , 0.2043 , 0.2017 ,\n",
       "            0.201  , 0.1995 , 0.1993 , 0.1984 , 0.197  , 0.1958 , 0.195  ,\n",
       "            0.193  , 0.1919 , 0.1913 , 0.1909 , 0.1866 , 0.1858 , 0.1842 ,\n",
       "            0.1819 , 0.1816 , 0.1812 , 0.179  , 0.1774 , 0.1755 , 0.1748 ,\n",
       "            0.1743 , 0.1727 , 0.1719 , 0.1711 , 0.1698 , 0.1693 , 0.1675 ,\n",
       "            0.1669 , 0.1664 , 0.1663 , 0.1622 , 0.1587 , 0.1565 , 0.1555 ,\n",
       "            0.1543 , 0.1539 , 0.1533 , 0.1506 , 0.1477 , 0.1473 , 0.1464 ,\n",
       "            0.1455 , 0.1447 , 0.1421 , 0.1409 , 0.1399 , 0.1378 , 0.1373 ,\n",
       "            0.1372 , 0.1361 , 0.1338 , 0.133  , 0.1318 , 0.1317 , 0.1315 ,\n",
       "            0.1312 , 0.1305 , 0.1292 , 0.1289 , 0.1279 , 0.1278 , 0.1263 ,\n",
       "            0.1259 , 0.1249 , 0.1241 , 0.1226 , 0.1225 , 0.12115, 0.1207 ,\n",
       "            0.1196 , 0.1193 , 0.118  , 0.1172 , 0.11676, 0.11615, 0.1152 ,\n",
       "            0.11395, 0.11084, 0.1093 , 0.108  , 0.1076 , 0.1063 , 0.10504,\n",
       "            0.1043 , 0.1041 , 0.1005 , 0.10034, 0.09875, 0.0967 , 0.09503,\n",
       "            0.09186, 0.08435, 0.08417, 0.08124, 0.07935, 0.0742 , 0.0709 ,\n",
       "            0.07043], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02985075, 0.03731343, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.1119403 , 0.12686567,\n",
       "            0.13432837, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.18656716, 0.18656716, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.23880596, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.2835821 ,\n",
       "            0.2835821 , 0.29850745, 0.33582088, 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.37313432, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3880597 , 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.47761193, 0.48507464, 0.48507464, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5597015 , 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 , 0.57462686,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5970149 , 0.5970149 , 0.5970149 ,\n",
       "            0.6119403 , 0.619403  , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.70149255, 0.7164179 , 0.7238806 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.06896552,\n",
       "            0.0775862 , 0.0862069 , 0.09482758, 0.10344828, 0.11206897,\n",
       "            0.12068965, 0.12931034, 0.13793103, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.15517241, 0.15517241, 0.15517241, 0.15517241,\n",
       "            0.15517241, 0.1637931 , 0.1637931 , 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18103448, 0.18103448, 0.18103448, 0.18965517,\n",
       "            0.18965517, 0.18965517, 0.18965517, 0.18965517, 0.18965517,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.21551724,\n",
       "            0.21551724, 0.21551724, 0.22413793, 0.22413793, 0.22413793,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.2413793 , 0.25      ,\n",
       "            0.25      , 0.25862068, 0.25862068, 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.27586207, 0.27586207, 0.28448275, 0.28448275,\n",
       "            0.28448275, 0.28448275, 0.29310346, 0.30172414, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.31896552, 0.31896552, 0.33620688,\n",
       "            0.3448276 , 0.3448276 , 0.3448276 , 0.3448276 , 0.3448276 ,\n",
       "            0.35344827, 0.35344827, 0.35344827, 0.36206895, 0.36206895,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.37931034, 0.38793105,\n",
       "            0.4051724 , 0.41379312, 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43103448, 0.43103448, 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.4827586 , 0.49137932, 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6637931 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.9310345 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3538 , 0.344  , 0.3418 , 0.3406 , 0.3364 , 0.3337 ,\n",
       "            0.3335 , 0.3306 , 0.33   , 0.329  , 0.3286 , 0.327  , 0.3242 ,\n",
       "            0.3237 , 0.3186 , 0.3184 , 0.3174 , 0.3157 , 0.3137 , 0.3093 ,\n",
       "            0.3086 , 0.3083 , 0.3079 , 0.3074 , 0.3064 , 0.3052 , 0.305  ,\n",
       "            0.3042 , 0.304  , 0.3032 , 0.3022 , 0.3008 , 0.2998 , 0.2996 ,\n",
       "            0.2983 , 0.297  , 0.2966 , 0.2957 , 0.2954 , 0.295  , 0.2944 ,\n",
       "            0.294  , 0.2937 , 0.2935 , 0.2932 , 0.2925 , 0.2917 , 0.2915 ,\n",
       "            0.2908 , 0.2903 , 0.29   , 0.2898 , 0.2893 , 0.289  , 0.2888 ,\n",
       "            0.2883 , 0.2876 , 0.2874 , 0.287  , 0.2869 , 0.2866 , 0.2864 ,\n",
       "            0.286  , 0.2856 , 0.285  , 0.283  , 0.2822 , 0.2815 , 0.2808 ,\n",
       "            0.2788 , 0.2786 , 0.2776 , 0.2773 , 0.2756 , 0.2751 , 0.2734 ,\n",
       "            0.2722 , 0.272  , 0.2715 , 0.271  , 0.2686 , 0.2676 , 0.2673 ,\n",
       "            0.2668 , 0.2651 , 0.265  , 0.2646 , 0.2637 , 0.2632 , 0.263  ,\n",
       "            0.2622 , 0.2617 , 0.2615 , 0.2612 , 0.2598 , 0.2595 , 0.2554 ,\n",
       "            0.2544 , 0.253  , 0.2512 , 0.248  , 0.2471 , 0.247  , 0.2463 ,\n",
       "            0.2451 , 0.2441 , 0.2406 , 0.2384 , 0.2366 , 0.2363 , 0.2328 ,\n",
       "            0.2323 , 0.231  , 0.2289 , 0.2285 , 0.2272 , 0.2263 , 0.226  ,\n",
       "            0.2247 , 0.223  , 0.2229 , 0.2213 , 0.2211 , 0.2207 , 0.2191 ,\n",
       "            0.2175 , 0.2144 , 0.2139 , 0.2134 , 0.213  , 0.2115 , 0.211  ,\n",
       "            0.2108 , 0.2106 , 0.2089 , 0.2085 , 0.2084 , 0.2063 , 0.2053 ,\n",
       "            0.202  , 0.2002 , 0.1987 , 0.1979 , 0.1973 , 0.1931 , 0.1927 ,\n",
       "            0.1921 , 0.1915 , 0.1912 , 0.1904 , 0.1903 , 0.1874 , 0.1871 ,\n",
       "            0.1864 , 0.1853 , 0.1824 , 0.1782 , 0.1765 , 0.1761 , 0.1752 ,\n",
       "            0.1743 , 0.1733 , 0.1693 , 0.1688 , 0.1661 , 0.1659 , 0.1626 ,\n",
       "            0.1621 , 0.1603 , 0.1583 , 0.1582 , 0.1545 , 0.1544 , 0.1533 ,\n",
       "            0.1515 , 0.1509 , 0.1484 , 0.1477 , 0.1475 , 0.1473 , 0.1466 ,\n",
       "            0.1462 , 0.1445 , 0.1439 , 0.1437 , 0.1434 , 0.142  , 0.1387 ,\n",
       "            0.1381 , 0.1372 , 0.1367 , 0.1366 , 0.1362 , 0.1353 , 0.1351 ,\n",
       "            0.1343 , 0.1333 , 0.1332 , 0.1324 , 0.1312 , 0.1259 , 0.1255 ,\n",
       "            0.124  , 0.12305, 0.1223 , 0.12177, 0.12024, 0.1166 , 0.11597,\n",
       "            0.11536, 0.11316, 0.111  , 0.108  , 0.1    , 0.0998 , 0.0967 ,\n",
       "            0.0962 , 0.0893 , 0.086  , 0.08527], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.05970149, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.11940298, 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.18656716, 0.19402985, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26865673, 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.36567163, 0.37313432, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.47014925, 0.48507464, 0.48507464,\n",
       "            0.48507464, 0.48507464, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5597015 , 0.5671642 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.58208954, 0.58208954, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.5970149 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.619403  , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6791045 , 0.6791045 ,\n",
       "            0.6865672 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.25      ,\n",
       "            0.25862068, 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.29310346, 0.29310346, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.31896552, 0.31896552, 0.33620688,\n",
       "            0.33620688, 0.3448276 , 0.3448276 , 0.3448276 , 0.35344827,\n",
       "            0.35344827, 0.35344827, 0.35344827, 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37068966, 0.37068966, 0.37068966, 0.37931034,\n",
       "            0.37931034, 0.37931034, 0.37931034, 0.38793105, 0.38793105,\n",
       "            0.39655173, 0.39655173, 0.39655173, 0.39655173, 0.39655173,\n",
       "            0.39655173, 0.39655173, 0.39655173, 0.39655173, 0.4051724 ,\n",
       "            0.4051724 , 0.4051724 , 0.4051724 , 0.4051724 , 0.4051724 ,\n",
       "            0.4224138 , 0.4224138 , 0.4224138 , 0.4224138 , 0.43103448,\n",
       "            0.43103448, 0.43103448, 0.43965518, 0.43965518, 0.43965518,\n",
       "            0.43965518, 0.43965518, 0.44827586, 0.45689654, 0.45689654,\n",
       "            0.46551725, 0.46551725, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.4827586 , 0.49137932, 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.5258621 , 0.5344828 , 0.55172414, 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.70689654, 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8448276 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3728 , 0.3706 , 0.37   , 0.366  , 0.365  , 0.3635 ,\n",
       "            0.3623 , 0.3613 , 0.359  , 0.358  , 0.3552 , 0.3542 , 0.351  ,\n",
       "            0.35   , 0.348  , 0.3464 , 0.3452 , 0.3433 , 0.342  , 0.338  ,\n",
       "            0.3374 , 0.3306 , 0.3293 , 0.329  , 0.328  , 0.3257 , 0.3247 ,\n",
       "            0.323  , 0.3228 , 0.3198 , 0.3193 , 0.319  , 0.318  , 0.3176 ,\n",
       "            0.3147 , 0.3132 , 0.3123 , 0.3118 , 0.311  , 0.3105 , 0.309  ,\n",
       "            0.3088 , 0.3083 , 0.308  , 0.307  , 0.3066 , 0.3057 , 0.3047 ,\n",
       "            0.304  , 0.3027 , 0.3005 , 0.3003 , 0.3    , 0.2996 , 0.299  ,\n",
       "            0.2986 , 0.2979 , 0.2976 , 0.2974 , 0.2961 , 0.2954 , 0.295  ,\n",
       "            0.2944 , 0.2942 , 0.2932 , 0.2925 , 0.2917 , 0.2913 , 0.2908 ,\n",
       "            0.2905 , 0.2898 , 0.289  , 0.288  , 0.2878 , 0.287  , 0.2861 ,\n",
       "            0.2854 , 0.2852 , 0.2842 , 0.282  , 0.2812 , 0.2805 , 0.2803 ,\n",
       "            0.2798 , 0.2795 , 0.2786 , 0.2783 , 0.2776 , 0.277  , 0.2766 ,\n",
       "            0.2747 , 0.2742 , 0.2737 , 0.2727 , 0.27   , 0.2695 , 0.2686 ,\n",
       "            0.2642 , 0.2637 , 0.2634 , 0.263  , 0.2612 , 0.2598 , 0.2588 ,\n",
       "            0.2563 , 0.256  , 0.2559 , 0.2556 , 0.254  , 0.2527 , 0.252  ,\n",
       "            0.2517 , 0.2487 , 0.2474 , 0.2473 , 0.2467 , 0.2458 , 0.2449 ,\n",
       "            0.2438 , 0.2433 , 0.2418 , 0.2417 , 0.2406 , 0.2399 , 0.2397 ,\n",
       "            0.2374 , 0.2372 , 0.2366 , 0.2362 , 0.2355 , 0.2352 , 0.2334 ,\n",
       "            0.2319 , 0.2318 , 0.2311 , 0.2301 , 0.2299 , 0.2257 , 0.2256 ,\n",
       "            0.2229 , 0.222  , 0.2207 , 0.2184 , 0.2173 , 0.2166 , 0.2158 ,\n",
       "            0.2156 , 0.2153 , 0.2147 , 0.2145 , 0.211  , 0.2086 , 0.2063 ,\n",
       "            0.2043 , 0.2037 , 0.2035 , 0.2012 , 0.2    , 0.1998 , 0.1995 ,\n",
       "            0.1987 , 0.1979 , 0.1974 , 0.1971 , 0.1936 , 0.1934 , 0.1925 ,\n",
       "            0.191  , 0.1876 , 0.1871 , 0.187  , 0.1823 , 0.1813 , 0.18   ,\n",
       "            0.1771 , 0.177  , 0.1748 , 0.1738 , 0.1736 , 0.1724 , 0.1716 ,\n",
       "            0.171  , 0.1705 , 0.1703 , 0.17   , 0.1687 , 0.1681 , 0.1665 ,\n",
       "            0.1664 , 0.1658 , 0.1649 , 0.1616 , 0.1609 , 0.1608 , 0.1602 ,\n",
       "            0.1599 , 0.1598 , 0.1594 , 0.158  , 0.1571 , 0.1556 , 0.1545 ,\n",
       "            0.1506 , 0.1487 , 0.1467 , 0.1466 , 0.1459 , 0.1456 , 0.142  ,\n",
       "            0.1384 , 0.138  , 0.1356 , 0.1328 , 0.1305 , 0.1217 , 0.12146,\n",
       "            0.1195 , 0.1186 , 0.1103 , 0.10706, 0.10596], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.07462686, 0.08208955, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.15671642, 0.1641791 , 0.1641791 ,\n",
       "            0.1641791 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23134328,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.2761194 , 0.30597016,\n",
       "            0.31343284, 0.31343284, 0.31343284, 0.32089552, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.3432836 , 0.35820895, 0.36567163, 0.36567163, 0.37313432,\n",
       "            0.37313432, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.40298507, 0.41044775,\n",
       "            0.41044775, 0.41044775, 0.41791046, 0.41791046, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.53731346, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.619403  , 0.619403  ,\n",
       "            0.6268657 , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.37931034, 0.38793105,\n",
       "            0.38793105, 0.38793105, 0.38793105, 0.39655173, 0.39655173,\n",
       "            0.39655173, 0.4051724 , 0.4051724 , 0.4051724 , 0.4051724 ,\n",
       "            0.41379312, 0.41379312, 0.4224138 , 0.4224138 , 0.4224138 ,\n",
       "            0.4224138 , 0.4224138 , 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.44827586, 0.44827586, 0.44827586, 0.44827586,\n",
       "            0.44827586, 0.44827586, 0.45689654, 0.45689654, 0.46551725,\n",
       "            0.46551725, 0.46551725, 0.46551725, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.49137932, 0.5086207 ,\n",
       "            0.5086207 , 0.5086207 , 0.51724136, 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.5344828 , 0.54310346, 0.55172414, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.5689655 , 0.5689655 , 0.5689655 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.6034483 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6637931 , 0.67241377, 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.6810345 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.7758621 , 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.88793105, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.394 , 0.3938, 0.392 , 0.3918, 0.3914, 0.3867, 0.3865,\n",
       "            0.3857, 0.3833, 0.379 , 0.3767, 0.3726, 0.3718, 0.371 , 0.3708,\n",
       "            0.3706, 0.3665, 0.365 , 0.364 , 0.3616, 0.3574, 0.3535, 0.353 ,\n",
       "            0.3525, 0.3486, 0.3472, 0.3464, 0.3462, 0.3455, 0.3447, 0.3428,\n",
       "            0.342 , 0.34  , 0.3398, 0.339 , 0.3325, 0.3303, 0.3284, 0.3274,\n",
       "            0.3271, 0.3264, 0.322 , 0.321 , 0.3206, 0.3164, 0.3152, 0.3137,\n",
       "            0.3132, 0.3115, 0.31  , 0.3098, 0.3079, 0.3076, 0.3064, 0.3052,\n",
       "            0.303 , 0.3025, 0.3018, 0.3015, 0.3013, 0.301 , 0.2983, 0.2969,\n",
       "            0.2966, 0.2957, 0.2952, 0.2947, 0.2935, 0.293 , 0.2915, 0.2908,\n",
       "            0.29  , 0.2893, 0.289 , 0.2888, 0.2886, 0.2883, 0.2878, 0.2874,\n",
       "            0.2869, 0.2866, 0.2854, 0.2852, 0.284 , 0.2837, 0.2832, 0.2812,\n",
       "            0.2805, 0.2803, 0.2793, 0.2786, 0.2776, 0.277 , 0.2761, 0.276 ,\n",
       "            0.2756, 0.2742, 0.2737, 0.272 , 0.271 , 0.2708, 0.2703, 0.27  ,\n",
       "            0.2695, 0.269 , 0.2683, 0.2673, 0.267 , 0.2664, 0.2642, 0.2637,\n",
       "            0.2634, 0.2622, 0.2617, 0.2612, 0.2607, 0.2605, 0.2598, 0.258 ,\n",
       "            0.2578, 0.2573, 0.2568, 0.2542, 0.2524, 0.2517, 0.251 , 0.2507,\n",
       "            0.25  , 0.2498, 0.2496, 0.2493, 0.2478, 0.2474, 0.2473, 0.2466,\n",
       "            0.2463, 0.2448, 0.2426, 0.2418, 0.2411, 0.2397, 0.2395, 0.2391,\n",
       "            0.2386, 0.2363, 0.2362, 0.2338, 0.2332, 0.233 , 0.2327, 0.2303,\n",
       "            0.2289, 0.2285, 0.2281, 0.2255, 0.2247, 0.224 , 0.223 , 0.2229,\n",
       "            0.2224, 0.222 , 0.2216, 0.22  , 0.2195, 0.2185, 0.2175, 0.2129,\n",
       "            0.2119, 0.2073, 0.2068, 0.2023, 0.2012, 0.2009, 0.2004, 0.2002,\n",
       "            0.1989, 0.1965, 0.1959, 0.1953, 0.1952, 0.1942, 0.194 , 0.1934,\n",
       "            0.1925, 0.191 , 0.1891, 0.1886, 0.1884, 0.188 , 0.1864, 0.1859,\n",
       "            0.1858, 0.185 , 0.1848, 0.1823, 0.182 , 0.1816, 0.181 , 0.1803,\n",
       "            0.1791, 0.1776, 0.1757, 0.1743, 0.1714, 0.17  , 0.1699, 0.1675,\n",
       "            0.1666, 0.163 , 0.1598, 0.1597, 0.1594, 0.1572, 0.1544, 0.1521,\n",
       "            0.1436, 0.1432, 0.1427, 0.1406, 0.1312, 0.1277, 0.1263],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.06716418, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.1119403 , 0.12686567, 0.13432837, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1641791 , 0.1716418 ,\n",
       "            0.18656716, 0.20149253, 0.20149253, 0.20895523, 0.20895523,\n",
       "            0.21641791, 0.21641791, 0.2238806 , 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26865673, 0.26865673,\n",
       "            0.26865673, 0.2761194 , 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.3283582 , 0.3283582 , 0.3283582 , 0.3283582 ,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.35820895, 0.35820895,\n",
       "            0.35820895, 0.36567163, 0.36567163, 0.36567163, 0.37313432,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.3880597 , 0.3880597 ,\n",
       "            0.3880597 , 0.3880597 , 0.3955224 , 0.3955224 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.42537314, 0.42537314, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4402985 , 0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.6268657 , 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.41379312, 0.41379312, 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43103448, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.4827586 , 0.4827586 ,\n",
       "            0.49137932, 0.49137932, 0.5086207 , 0.5086207 , 0.51724136,\n",
       "            0.51724136, 0.51724136, 0.51724136, 0.5258621 , 0.5258621 ,\n",
       "            0.5258621 , 0.5258621 , 0.5258621 , 0.5344828 , 0.5344828 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5948276 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.63793105, 0.63793105, 0.6465517 , 0.6465517 , 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.67241377, 0.6810345 , 0.69827586, 0.70689654,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8189655 , 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.88793105, 0.8965517 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4268, 0.4253, 0.4229, 0.4204, 0.4194, 0.4158, 0.415 ,\n",
       "            0.4146, 0.4133, 0.409 , 0.4055, 0.4048, 0.403 , 0.4016, 0.397 ,\n",
       "            0.3967, 0.3953, 0.3928, 0.391 , 0.39  , 0.3887, 0.3857, 0.3853,\n",
       "            0.3826, 0.3782, 0.376 , 0.3755, 0.375 , 0.3718, 0.371 , 0.3708,\n",
       "            0.3704, 0.3694, 0.3684, 0.3616, 0.3591, 0.3574, 0.3562, 0.3535,\n",
       "            0.353 , 0.3474, 0.347 , 0.3447, 0.3408, 0.3323, 0.3257, 0.325 ,\n",
       "            0.323 , 0.32  , 0.3193, 0.3184, 0.3176, 0.316 , 0.3154, 0.3152,\n",
       "            0.3147, 0.3142, 0.3127, 0.312 , 0.311 , 0.31  , 0.3093, 0.3088,\n",
       "            0.308 , 0.3074, 0.3066, 0.305 , 0.3044, 0.304 , 0.3037, 0.3032,\n",
       "            0.3022, 0.3013, 0.3   , 0.299 , 0.2986, 0.297 , 0.2966, 0.2964,\n",
       "            0.296 , 0.2957, 0.2952, 0.2937, 0.2932, 0.293 , 0.2927, 0.2925,\n",
       "            0.2922, 0.292 , 0.2917, 0.2915, 0.2908, 0.2898, 0.2896, 0.2893,\n",
       "            0.289 , 0.2886, 0.2883, 0.2876, 0.287 , 0.2869, 0.286 , 0.2854,\n",
       "            0.284 , 0.2837, 0.2834, 0.2832, 0.282 , 0.279 , 0.2778, 0.277 ,\n",
       "            0.2764, 0.2751, 0.2742, 0.2732, 0.2715, 0.2708, 0.2703, 0.2698,\n",
       "            0.2693, 0.269 , 0.2686, 0.2683, 0.268 , 0.2678, 0.2676, 0.2654,\n",
       "            0.2632, 0.263 , 0.2622, 0.2607, 0.2605, 0.258 , 0.2573, 0.2568,\n",
       "            0.2563, 0.2556, 0.255 , 0.2534, 0.2524, 0.2512, 0.2494, 0.2478,\n",
       "            0.2477, 0.2463, 0.246 , 0.2441, 0.2434, 0.2424, 0.2422, 0.2417,\n",
       "            0.2415, 0.241 , 0.2388, 0.2384, 0.2372, 0.2352, 0.2318, 0.2301,\n",
       "            0.2283, 0.226 , 0.2257, 0.2247, 0.2234, 0.2218, 0.2216, 0.2205,\n",
       "            0.2202, 0.2198, 0.2195, 0.2194, 0.2166, 0.2153, 0.215 , 0.2144,\n",
       "            0.2125, 0.2113, 0.211 , 0.2104, 0.21  , 0.2096, 0.2091, 0.2085,\n",
       "            0.2065, 0.2039, 0.2032, 0.2023, 0.202 , 0.2015, 0.2007, 0.1995,\n",
       "            0.1979, 0.1962, 0.1937, 0.1935, 0.1931, 0.1886, 0.1873, 0.1838,\n",
       "            0.1813, 0.1807, 0.1805, 0.1785, 0.1783, 0.1755, 0.174 , 0.1683,\n",
       "            0.1638, 0.1632, 0.1624, 0.1512, 0.1484, 0.1467], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08208955, 0.08208955,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.09701493, 0.09701493,\n",
       "            0.09701493, 0.09701493, 0.10447761, 0.10447761, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.12686567, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.15671642, 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20895523, 0.21641791, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.2238806 , 0.23134328, 0.23134328, 0.23134328,\n",
       "            0.23880596, 0.23880596, 0.24626866, 0.24626866, 0.24626866,\n",
       "            0.25373134, 0.25373134, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2835821 , 0.2835821 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.29850745, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.33582088, 0.33582088,\n",
       "            0.3432836 , 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.36567163, 0.36567163, 0.36567163, 0.37313432, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3880597 , 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.43283582, 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.46551725, 0.47413793,\n",
       "            0.49137932, 0.5086207 , 0.51724136, 0.51724136, 0.51724136,\n",
       "            0.5258621 , 0.5258621 , 0.5258621 , 0.5258621 , 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.5862069 , 0.5948276 , 0.5948276 , 0.6034483 ,\n",
       "            0.62931037, 0.63793105, 0.63793105, 0.6465517 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.6896552 , 0.69827586,\n",
       "            0.69827586, 0.69827586, 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4553, 0.451 , 0.4482, 0.4438, 0.4404, 0.4397, 0.435 ,\n",
       "            0.4348, 0.4336, 0.4329, 0.4304, 0.4248, 0.424 , 0.4219, 0.4187,\n",
       "            0.4172, 0.4158, 0.4138, 0.4106, 0.4077, 0.4055, 0.4036, 0.403 ,\n",
       "            0.4   , 0.3958, 0.395 , 0.394 , 0.3928, 0.3926, 0.3901, 0.3894,\n",
       "            0.3887, 0.3875, 0.387 , 0.381 , 0.38  , 0.3787, 0.3748, 0.3706,\n",
       "            0.369 , 0.368 , 0.3613, 0.3552, 0.3499, 0.349 , 0.3438, 0.3428,\n",
       "            0.3403, 0.3367, 0.3364, 0.3347, 0.3345, 0.334 , 0.331 , 0.3281,\n",
       "            0.3276, 0.3274, 0.3232, 0.322 , 0.3203, 0.32  , 0.3186, 0.3184,\n",
       "            0.3171, 0.3167, 0.3162, 0.3154, 0.3152, 0.3137, 0.3135, 0.3132,\n",
       "            0.3127, 0.3118, 0.3115, 0.3113, 0.311 , 0.3103, 0.3098, 0.3096,\n",
       "            0.3088, 0.3076, 0.3064, 0.3052, 0.3047, 0.3044, 0.3042, 0.304 ,\n",
       "            0.3032, 0.303 , 0.3027, 0.3022, 0.3015, 0.3013, 0.301 , 0.3008,\n",
       "            0.3005, 0.3003, 0.2996, 0.2993, 0.299 , 0.2983, 0.2974, 0.2969,\n",
       "            0.2964, 0.2961, 0.2957, 0.2952, 0.2942, 0.2937, 0.2932, 0.291 ,\n",
       "            0.289 , 0.2886, 0.2883, 0.2878, 0.2852, 0.285 , 0.2847, 0.284 ,\n",
       "            0.283 , 0.2822, 0.2812, 0.2808, 0.2803, 0.2798, 0.279 , 0.2786,\n",
       "            0.278 , 0.277 , 0.2769, 0.2761, 0.2734, 0.2695, 0.2686, 0.267 ,\n",
       "            0.266 , 0.265 , 0.2646, 0.2642, 0.263 , 0.2622, 0.262 , 0.2605,\n",
       "            0.258 , 0.2566, 0.2563, 0.2534, 0.2522, 0.2507, 0.2505, 0.2478,\n",
       "            0.2448, 0.2444, 0.2411, 0.2406, 0.2397, 0.2386, 0.2383, 0.2379,\n",
       "            0.2375, 0.2366, 0.2355, 0.235 , 0.2334, 0.2325, 0.2313, 0.231 ,\n",
       "            0.2307, 0.2289, 0.2285, 0.2274, 0.2268, 0.2263, 0.2242, 0.2239,\n",
       "            0.223 , 0.2227, 0.2211, 0.2191, 0.218 , 0.2173, 0.2168, 0.2166,\n",
       "            0.215 , 0.2148, 0.2147, 0.2139, 0.2135, 0.2123, 0.2091, 0.209 ,\n",
       "            0.2085, 0.2084, 0.2054, 0.2023, 0.2004, 0.1968, 0.1959, 0.195 ,\n",
       "            0.1941, 0.1929, 0.1913, 0.1893, 0.1871, 0.1853, 0.1772, 0.1771,\n",
       "            0.1755, 0.1636, 0.163 , 0.1622, 0.1594], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.05223881, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.07462686, 0.08208955, 0.08955224, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.1119403 ,\n",
       "            0.11940298, 0.11940298, 0.12686567, 0.12686567, 0.12686567,\n",
       "            0.13432837, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.15671642, 0.1641791 , 0.1641791 , 0.1716418 , 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.20895523, 0.20895523, 0.21641791,\n",
       "            0.21641791, 0.2238806 , 0.23880596, 0.24626866, 0.24626866,\n",
       "            0.25373134, 0.25373134, 0.26119402, 0.26119402, 0.26865673,\n",
       "            0.26865673, 0.2761194 , 0.2761194 , 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.33582088, 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.3880597 , 0.40298507, 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.57462686, 0.58208954,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.7089552 ,\n",
       "            0.7164179 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.54310346, 0.54310346, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.73275864, 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.8103448 , 0.8103448 , 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8362069 , 0.8362069 ,\n",
       "            0.8362069 , 0.8362069 , 0.8448276 , 0.8534483 , 0.8534483 ,\n",
       "            0.86206895, 0.86206895, 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4883, 0.482 , 0.4783, 0.4773, 0.4717, 0.4683, 0.4668,\n",
       "            0.4666, 0.4646, 0.4602, 0.46  , 0.4578, 0.456 , 0.452 , 0.451 ,\n",
       "            0.4492, 0.4465, 0.4402, 0.4314, 0.4307, 0.4302, 0.4277, 0.426 ,\n",
       "            0.4238, 0.4224, 0.4202, 0.4187, 0.4175, 0.4155, 0.4146, 0.4138,\n",
       "            0.4116, 0.4106, 0.4067, 0.4062, 0.4023, 0.402 , 0.4001, 0.3977,\n",
       "            0.397 , 0.3945, 0.39  , 0.3896, 0.3772, 0.371 , 0.3708, 0.3667,\n",
       "            0.3638, 0.3606, 0.3582, 0.358 , 0.3552, 0.3542, 0.3538, 0.3528,\n",
       "            0.3462, 0.344 , 0.3435, 0.3418, 0.3413, 0.3403, 0.3389, 0.3354,\n",
       "            0.3352, 0.3347, 0.3337, 0.3335, 0.3318, 0.3315, 0.3313, 0.331 ,\n",
       "            0.3303, 0.33  , 0.328 , 0.3264, 0.325 , 0.3242, 0.3235, 0.323 ,\n",
       "            0.3228, 0.3213, 0.321 , 0.3208, 0.3206, 0.3203, 0.32  , 0.3196,\n",
       "            0.3188, 0.3184, 0.3179, 0.3154, 0.3152, 0.314 , 0.3137, 0.3132,\n",
       "            0.3125, 0.3118, 0.3093, 0.3088, 0.3086, 0.3076, 0.3074, 0.3066,\n",
       "            0.3064, 0.3062, 0.3057, 0.3052, 0.305 , 0.3047, 0.3044, 0.3037,\n",
       "            0.3035, 0.3027, 0.3022, 0.302 , 0.3018, 0.3013, 0.2998, 0.2993,\n",
       "            0.2986, 0.2979, 0.2947, 0.2944, 0.2942, 0.2935, 0.2932, 0.2915,\n",
       "            0.2913, 0.29  , 0.2896, 0.2888, 0.2876, 0.2874, 0.2852, 0.2837,\n",
       "            0.2834, 0.283 , 0.2812, 0.2795, 0.2788, 0.2769, 0.2764, 0.2754,\n",
       "            0.275 , 0.2744, 0.2734, 0.271 , 0.2705, 0.266 , 0.263 , 0.262 ,\n",
       "            0.2605, 0.2588, 0.258 , 0.2551, 0.255 , 0.2534, 0.2527, 0.2515,\n",
       "            0.249 , 0.2487, 0.248 , 0.2474, 0.247 , 0.244 , 0.2434, 0.2426,\n",
       "            0.2424, 0.2422, 0.2418, 0.241 , 0.2384, 0.2383, 0.2378, 0.2375,\n",
       "            0.2372, 0.2358, 0.2346, 0.2334, 0.2332, 0.2303, 0.2297, 0.2286,\n",
       "            0.2283, 0.2274, 0.2263, 0.2252, 0.2244, 0.2242, 0.224 , 0.223 ,\n",
       "            0.2212, 0.2205, 0.2195, 0.2181, 0.217 , 0.2123, 0.2115, 0.211 ,\n",
       "            0.2096, 0.206 , 0.2059, 0.2053, 0.205 , 0.204 , 0.2015, 0.2006,\n",
       "            0.1993, 0.199 , 0.1984, 0.197 , 0.1924, 0.1891, 0.188 , 0.1871,\n",
       "            0.1842, 0.1821, 0.1724, 0.1683, 0.1484], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.12931034, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.05970149, 0.05970149, 0.05970149, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.07462686, 0.08208955,\n",
       "            0.08208955, 0.08955224, 0.08955224, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.13432837, 0.14179105, 0.14179105, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.15671642, 0.15671642, 0.15671642, 0.1641791 ,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.20895523, 0.21641791, 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.43283582, 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.6268657 , 0.63432837,\n",
       "            0.6492537 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.5603448 ,\n",
       "            0.5689655 , 0.5689655 , 0.57758623, 0.5862069 , 0.6034483 ,\n",
       "            0.62068963, 0.62068963, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.8534483 , 0.8534483 , 0.86206895, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5396, 0.5303, 0.529 , 0.5244, 0.5225, 0.5146, 0.513 ,\n",
       "            0.5127, 0.5083, 0.5073, 0.507 , 0.5063, 0.5054, 0.5024, 0.5005,\n",
       "            0.4932, 0.4827, 0.4795, 0.4756, 0.4727, 0.4707, 0.4666, 0.4634,\n",
       "            0.461 , 0.4602, 0.4595, 0.4573, 0.4563, 0.4534, 0.4517, 0.4514,\n",
       "            0.4504, 0.4492, 0.449 , 0.4478, 0.4475, 0.444 , 0.4438, 0.4426,\n",
       "            0.44  , 0.4326, 0.432 , 0.4265, 0.423 , 0.4177, 0.4082, 0.4048,\n",
       "            0.4026, 0.4019, 0.4004, 0.3975, 0.3962, 0.3958, 0.3926, 0.3906,\n",
       "            0.3877, 0.3865, 0.3809, 0.3733, 0.373 , 0.3728, 0.3726, 0.372 ,\n",
       "            0.371 , 0.3694, 0.369 , 0.3684, 0.3682, 0.368 , 0.3674, 0.3667,\n",
       "            0.3647, 0.3633, 0.3625, 0.3623, 0.362 , 0.3618, 0.359 , 0.358 ,\n",
       "            0.3572, 0.3567, 0.3562, 0.356 , 0.3552, 0.3525, 0.352 , 0.3508,\n",
       "            0.3503, 0.3494, 0.3477, 0.3452, 0.345 , 0.3445, 0.344 , 0.3435,\n",
       "            0.3423, 0.3416, 0.341 , 0.3384, 0.3364, 0.336 , 0.3357, 0.335 ,\n",
       "            0.3345, 0.3335, 0.333 , 0.3325, 0.3323, 0.3313, 0.331 , 0.3298,\n",
       "            0.329 , 0.3289, 0.3281, 0.3274, 0.3264, 0.3254, 0.3245, 0.3235,\n",
       "            0.3223, 0.3218, 0.321 , 0.3203, 0.3188, 0.3186, 0.3179, 0.3171,\n",
       "            0.317 , 0.315 , 0.3147, 0.3145, 0.314 , 0.3132, 0.313 , 0.3127,\n",
       "            0.3118, 0.3115, 0.3113, 0.311 , 0.31  , 0.3096, 0.3057, 0.3054,\n",
       "            0.3052, 0.3047, 0.3035, 0.303 , 0.3025, 0.3005, 0.295 , 0.2932,\n",
       "            0.2925, 0.2903, 0.2898, 0.289 , 0.2883, 0.2876, 0.2874, 0.2856,\n",
       "            0.2852, 0.2803, 0.2798, 0.2795, 0.2776, 0.2773, 0.277 , 0.2766,\n",
       "            0.276 , 0.2756, 0.2734, 0.2732, 0.2725, 0.2722, 0.2698, 0.2688,\n",
       "            0.2664, 0.265 , 0.2642, 0.2627, 0.2625, 0.2622, 0.2603, 0.2595,\n",
       "            0.258 , 0.2573, 0.2563, 0.2556, 0.255 , 0.2546, 0.2542, 0.2534,\n",
       "            0.252 , 0.2502, 0.2483, 0.2449, 0.244 , 0.2417, 0.2394, 0.2383,\n",
       "            0.2379, 0.2375, 0.2374, 0.2367, 0.235 , 0.2334, 0.2332, 0.2325,\n",
       "            0.2323, 0.2302, 0.2263, 0.2233, 0.2211, 0.2207, 0.2186, 0.2185,\n",
       "            0.2158, 0.2128, 0.2114, 0.207 , 0.2048, 0.2037, 0.2017, 0.2012,\n",
       "            0.1989, 0.1964, 0.1896, 0.1824, 0.179 , 0.1716, 0.1368],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.15517241, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05970149, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.13432837,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.17910448, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.35074627, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.5522388 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.6492537 , 0.6567164 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.69827586, 0.70689654,\n",
       "            0.7241379 , 0.7241379 , 0.73275864, 0.7413793 , 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.76724136, 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.87068963, 0.87931037, 0.87931037, 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9396552 , 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5674, 0.5586, 0.555 , 0.5513, 0.5503, 0.539 , 0.5386,\n",
       "            0.5376, 0.536 , 0.5356, 0.5337, 0.533 , 0.529 , 0.5283, 0.523 ,\n",
       "            0.5127, 0.503 , 0.501 , 0.4988, 0.4963, 0.4946, 0.4866, 0.4858,\n",
       "            0.4817, 0.4795, 0.4788, 0.4768, 0.4722, 0.4712, 0.471 , 0.4702,\n",
       "            0.47  , 0.4692, 0.4675, 0.4658, 0.465 , 0.4646, 0.4614, 0.4612,\n",
       "            0.4526, 0.4521, 0.451 , 0.4453, 0.4346, 0.4338, 0.4302, 0.4243,\n",
       "            0.423 , 0.4207, 0.4204, 0.42  , 0.4175, 0.415 , 0.4148, 0.408 ,\n",
       "            0.4067, 0.405 , 0.4016, 0.401 , 0.3987, 0.398 , 0.3975, 0.3972,\n",
       "            0.397 , 0.395 , 0.3945, 0.393 , 0.392 , 0.391 , 0.3901, 0.39  ,\n",
       "            0.3887, 0.386 , 0.3845, 0.3843, 0.383 , 0.382 , 0.3804, 0.379 ,\n",
       "            0.3782, 0.3774, 0.3772, 0.377 , 0.376 , 0.374 , 0.3735, 0.3726,\n",
       "            0.3718, 0.3706, 0.3704, 0.37  , 0.3691, 0.366 , 0.365 , 0.3628,\n",
       "            0.3625, 0.3596, 0.3584, 0.3567, 0.3552, 0.3538, 0.352 , 0.3513,\n",
       "            0.35  , 0.348 , 0.3467, 0.3464, 0.3423, 0.342 , 0.3408, 0.339 ,\n",
       "            0.3381, 0.337 , 0.3367, 0.3364, 0.336 , 0.3345, 0.334 , 0.3337,\n",
       "            0.3328, 0.3313, 0.3308, 0.33  , 0.329 , 0.3289, 0.3284, 0.327 ,\n",
       "            0.3247, 0.3223, 0.3186, 0.3184, 0.3171, 0.3157, 0.3154, 0.315 ,\n",
       "            0.3132, 0.311 , 0.3108, 0.3076, 0.3071, 0.307 , 0.3057, 0.3047,\n",
       "            0.3044, 0.304 , 0.3037, 0.3035, 0.3032, 0.3018, 0.3013, 0.2986,\n",
       "            0.2979, 0.2947, 0.294 , 0.293 , 0.2898, 0.2893, 0.2886, 0.2878,\n",
       "            0.287 , 0.286 , 0.2852, 0.2847, 0.2825, 0.2822, 0.2795, 0.277 ,\n",
       "            0.2764, 0.276 , 0.275 , 0.274 , 0.2737, 0.2734, 0.2732, 0.2722,\n",
       "            0.271 , 0.27  , 0.2698, 0.2695, 0.268 , 0.2673, 0.265 , 0.264 ,\n",
       "            0.2583, 0.2554, 0.2544, 0.2542, 0.2532, 0.2496, 0.2494, 0.2485,\n",
       "            0.2483, 0.2455, 0.2448, 0.2437, 0.2433, 0.2426, 0.2406, 0.2368,\n",
       "            0.233 , 0.2322, 0.2301, 0.2297, 0.2283, 0.2257, 0.2252, 0.22  ,\n",
       "            0.2173, 0.215 , 0.2115, 0.2114, 0.2108, 0.2091, 0.2034, 0.2028,\n",
       "            0.194 , 0.1912, 0.1904, 0.1858, 0.1788, 0.1711, 0.1676, 0.16  ,\n",
       "            0.1249], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.27586207, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.05970149, 0.05970149, 0.05970149, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.07462686, 0.08208955, 0.08208955, 0.08955224,\n",
       "            0.10447761, 0.10447761, 0.10447761, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.3432836 , 0.35074627, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.54310346,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.92241377, 0.9310345 , 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6055, 0.597 , 0.592 , 0.5913, 0.5864, 0.577 , 0.574 ,\n",
       "            0.5737, 0.573 , 0.5723, 0.572 , 0.5684, 0.5654, 0.56  , 0.554 ,\n",
       "            0.5405, 0.5317, 0.5312, 0.531 , 0.53  , 0.52  , 0.5137, 0.5127,\n",
       "            0.511 , 0.51  , 0.507 , 0.506 , 0.503 , 0.5005, 0.5   , 0.4988,\n",
       "            0.4966, 0.4963, 0.493 , 0.4927, 0.4905, 0.4895, 0.488 , 0.4836,\n",
       "            0.4783, 0.4731, 0.4724, 0.4697, 0.4639, 0.4585, 0.4565, 0.453 ,\n",
       "            0.4524, 0.4485, 0.4473, 0.4448, 0.4424, 0.4417, 0.4407, 0.4402,\n",
       "            0.4363, 0.435 , 0.4343, 0.433 , 0.4326, 0.4324, 0.4321, 0.4307,\n",
       "            0.427 , 0.4263, 0.426 , 0.4255, 0.424 , 0.4233, 0.4229, 0.4163,\n",
       "            0.415 , 0.414 , 0.4136, 0.4126, 0.4124, 0.412 , 0.411 , 0.4094,\n",
       "            0.408 , 0.4072, 0.4038, 0.4023, 0.4011, 0.3972, 0.396 , 0.3958,\n",
       "            0.3953, 0.3943, 0.3926, 0.3923, 0.3904, 0.3887, 0.388 , 0.3843,\n",
       "            0.3838, 0.383 , 0.382 , 0.3818, 0.3796, 0.3792, 0.3772, 0.3752,\n",
       "            0.3745, 0.373 , 0.37  , 0.3657, 0.3655, 0.3652, 0.3647, 0.3608,\n",
       "            0.359 , 0.357 , 0.3567, 0.3564, 0.3557, 0.3555, 0.3552, 0.355 ,\n",
       "            0.3538, 0.353 , 0.3525, 0.3516, 0.3489, 0.3484, 0.3467, 0.3452,\n",
       "            0.3447, 0.3425, 0.3413, 0.3398, 0.3372, 0.3367, 0.332 , 0.331 ,\n",
       "            0.3303, 0.33  , 0.3296, 0.3284, 0.3271, 0.327 , 0.3267, 0.326 ,\n",
       "            0.3247, 0.3237, 0.322 , 0.3218, 0.3208, 0.3198, 0.3176, 0.3171,\n",
       "            0.3157, 0.3152, 0.3147, 0.3142, 0.314 , 0.312 , 0.3108, 0.31  ,\n",
       "            0.309 , 0.3079, 0.307 , 0.3057, 0.3054, 0.3052, 0.3008, 0.3   ,\n",
       "            0.2998, 0.298 , 0.2974, 0.2954, 0.2944, 0.294 , 0.2932, 0.293 ,\n",
       "            0.2925, 0.2917, 0.2915, 0.291 , 0.29  , 0.2893, 0.2883, 0.287 ,\n",
       "            0.2842, 0.2832, 0.283 , 0.2827, 0.2773, 0.2766, 0.2756, 0.2747,\n",
       "            0.2737, 0.2732, 0.273 , 0.2712, 0.271 , 0.269 , 0.268 , 0.2634,\n",
       "            0.2627, 0.2625, 0.2615, 0.261 , 0.2563, 0.251 , 0.2466, 0.2458,\n",
       "            0.2438, 0.2413, 0.2394, 0.2355, 0.2319, 0.2316, 0.2268, 0.2246,\n",
       "            0.2239, 0.2238, 0.2191, 0.2098, 0.205 , 0.2035, 0.2012, 0.197 ,\n",
       "            0.1942, 0.1852, 0.1836, 0.182 , 0.1765, 0.1696, 0.1614, 0.1577,\n",
       "            0.1498, 0.1144], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.39655173, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.05970149, 0.05970149,\n",
       "            0.05970149, 0.05970149, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.12686567, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.46268657, 0.47014925,\n",
       "            0.48507464, 0.49253732, 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.5895522 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06896552, 0.0775862 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8103448 , 0.8189655 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6396, 0.6323, 0.628 , 0.6245, 0.618 , 0.6147, 0.609 ,\n",
       "            0.606 , 0.6025, 0.601 , 0.599 , 0.588 , 0.5825, 0.5664, 0.563 ,\n",
       "            0.5625, 0.5596, 0.558 , 0.552 , 0.5435, 0.542 , 0.5396, 0.539 ,\n",
       "            0.536 , 0.534 , 0.5327, 0.5312, 0.53  , 0.5283, 0.527 , 0.5264,\n",
       "            0.5254, 0.5225, 0.5176, 0.5156, 0.513 , 0.5103, 0.51  , 0.5063,\n",
       "            0.505 , 0.5034, 0.503 , 0.4993, 0.4941, 0.49  , 0.4895, 0.4783,\n",
       "            0.4775, 0.4734, 0.473 , 0.4724, 0.472 , 0.471 , 0.47  , 0.4683,\n",
       "            0.4663, 0.4658, 0.4653, 0.4644, 0.4639, 0.462 , 0.4614, 0.4607,\n",
       "            0.4602, 0.4563, 0.456 , 0.453 , 0.4524, 0.452 , 0.4517, 0.4504,\n",
       "            0.45  , 0.4465, 0.4456, 0.4417, 0.441 , 0.4385, 0.4377, 0.4375,\n",
       "            0.4365, 0.4343, 0.4329, 0.4321, 0.4294, 0.4236, 0.4219, 0.4197,\n",
       "            0.4194, 0.4192, 0.4167, 0.4165, 0.4138, 0.4133, 0.412 , 0.4116,\n",
       "            0.4094, 0.4092, 0.4036, 0.4026, 0.402 , 0.4019, 0.3982, 0.3977,\n",
       "            0.3972, 0.397 , 0.3923, 0.3918, 0.391 , 0.3901, 0.3867, 0.3833,\n",
       "            0.3823, 0.3818, 0.3813, 0.381 , 0.3809, 0.378 , 0.3762, 0.3757,\n",
       "            0.375 , 0.3743, 0.3726, 0.3716, 0.3674, 0.3672, 0.3635, 0.3584,\n",
       "            0.3567, 0.3564, 0.356 , 0.3552, 0.3542, 0.354 , 0.3523, 0.352 ,\n",
       "            0.3506, 0.3477, 0.3474, 0.3467, 0.346 , 0.3442, 0.342 , 0.3418,\n",
       "            0.3403, 0.3386, 0.3381, 0.3372, 0.337 , 0.336 , 0.3352, 0.3337,\n",
       "            0.3335, 0.3315, 0.3313, 0.3298, 0.3271, 0.3267, 0.325 , 0.3247,\n",
       "            0.3218, 0.321 , 0.3206, 0.3203, 0.3196, 0.3193, 0.3186, 0.3174,\n",
       "            0.317 , 0.3162, 0.3152, 0.315 , 0.3147, 0.3145, 0.3137, 0.313 ,\n",
       "            0.3123, 0.3115, 0.3113, 0.3093, 0.3076, 0.306 , 0.3057, 0.3025,\n",
       "            0.301 , 0.2957, 0.2952, 0.295 , 0.2932, 0.293 , 0.2917, 0.2903,\n",
       "            0.2898, 0.2886, 0.288 , 0.2856, 0.2827, 0.282 , 0.281 , 0.2788,\n",
       "            0.2747, 0.273 , 0.272 , 0.271 , 0.2688, 0.2673, 0.2654, 0.259 ,\n",
       "            0.2556, 0.2522, 0.2467, 0.2437, 0.241 , 0.236 , 0.2346, 0.2256,\n",
       "            0.2207, 0.2191, 0.2186, 0.2184, 0.2125, 0.2015, 0.1991, 0.1952,\n",
       "            0.1934, 0.1907, 0.1852, 0.1764, 0.1757, 0.1725, 0.1674, 0.1598,\n",
       "            0.1516, 0.1478, 0.1398, 0.1043], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.45689654, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.05970149, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.24626866, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.42537314, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.8448276 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.661  , 0.6533 , 0.649  , 0.6465 , 0.639  , 0.6353 ,\n",
       "            0.6294 , 0.629  , 0.626  , 0.6235 , 0.622  , 0.62   , 0.6187 ,\n",
       "            0.608  , 0.6016 , 0.585  , 0.5806 , 0.58   , 0.5776 , 0.576  ,\n",
       "            0.5703 , 0.569  , 0.56   , 0.559  , 0.5566 , 0.5557 , 0.551  ,\n",
       "            0.5503 , 0.5493 , 0.548  , 0.546  , 0.5444 , 0.543  , 0.5425 ,\n",
       "            0.5415 , 0.5386 , 0.536  , 0.535  , 0.533  , 0.5312 , 0.5283 ,\n",
       "            0.526  , 0.525  , 0.524  , 0.519  , 0.517  , 0.5166 , 0.514  ,\n",
       "            0.506  , 0.5054 , 0.5005 , 0.4998 , 0.4912 , 0.4905 , 0.49   ,\n",
       "            0.4888 , 0.4863 , 0.4858 , 0.4854 , 0.4846 , 0.4844 , 0.4841 ,\n",
       "            0.4814 , 0.4812 , 0.4795 , 0.479  , 0.477  , 0.4756 , 0.475  ,\n",
       "            0.474  , 0.4739 , 0.473  , 0.4724 , 0.4717 , 0.4714 , 0.4705 ,\n",
       "            0.467  , 0.4626 , 0.461  , 0.458  , 0.4575 , 0.4565 , 0.4543 ,\n",
       "            0.4517 , 0.4512 , 0.4468 , 0.442  , 0.436  , 0.4355 , 0.4343 ,\n",
       "            0.43   , 0.428  , 0.4275 , 0.427  , 0.4268 , 0.424  , 0.4224 ,\n",
       "            0.421  , 0.419  , 0.4175 , 0.4172 , 0.416  , 0.4124 , 0.411  ,\n",
       "            0.409  , 0.4062 , 0.4053 , 0.4048 , 0.4045 , 0.4033 , 0.3987 ,\n",
       "            0.396  , 0.3953 , 0.3936 , 0.3884 , 0.388  , 0.3875 , 0.3872 ,\n",
       "            0.387  , 0.3835 , 0.3828 , 0.3818 , 0.381  , 0.38   , 0.3796 ,\n",
       "            0.3767 , 0.3728 , 0.3699 , 0.368  , 0.3657 , 0.3652 , 0.3608 ,\n",
       "            0.3599 , 0.3596 , 0.3586 , 0.358  , 0.357  , 0.3567 , 0.353  ,\n",
       "            0.3513 , 0.349  , 0.3489 , 0.3486 , 0.3457 , 0.3455 , 0.3447 ,\n",
       "            0.3438 , 0.3425 , 0.3416 , 0.3406 , 0.3396 , 0.337  , 0.3362 ,\n",
       "            0.3354 , 0.3347 , 0.333  , 0.3323 , 0.3303 , 0.3289 , 0.327  ,\n",
       "            0.3264 , 0.3254 , 0.3235 , 0.322  , 0.3218 , 0.321  , 0.3203 ,\n",
       "            0.32   , 0.3193 , 0.3184 , 0.3179 , 0.3176 , 0.3174 , 0.3171 ,\n",
       "            0.3164 , 0.316  , 0.3154 , 0.3142 , 0.3113 , 0.309  , 0.3057 ,\n",
       "            0.3047 , 0.3042 , 0.3035 , 0.303  , 0.3027 , 0.2998 , 0.298  ,\n",
       "            0.297  , 0.2964 , 0.2961 , 0.2954 , 0.2944 , 0.2908 , 0.2903 ,\n",
       "            0.2893 , 0.2844 , 0.2842 , 0.2834 , 0.2832 , 0.281  , 0.278  ,\n",
       "            0.2715 , 0.2712 , 0.2698 , 0.269  , 0.2673 , 0.2664 , 0.2651 ,\n",
       "            0.2556 , 0.254  , 0.2524 , 0.2415 , 0.2388 , 0.2355 , 0.2299 ,\n",
       "            0.2286 , 0.2191 , 0.214  , 0.2134 , 0.212  , 0.2114 , 0.205  ,\n",
       "            0.1934 , 0.1927 , 0.1866 , 0.1848 , 0.1838 , 0.1765 , 0.1685 ,\n",
       "            0.1674 , 0.1632 , 0.158  , 0.1504 , 0.1418 , 0.138  , 0.1299 ,\n",
       "            0.09485], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.5603448, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05970149, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08955224, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.29310346, 0.30172414, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.86206895, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.684 , 0.676 , 0.672 , 0.6685, 0.6606, 0.6567, 0.652 ,\n",
       "            0.6514, 0.647 , 0.6445, 0.6426, 0.6416, 0.6406, 0.628 , 0.6216,\n",
       "            0.6035, 0.601 , 0.6006, 0.5996, 0.597 , 0.5947, 0.589 , 0.5786,\n",
       "            0.5776, 0.5747, 0.574 , 0.5693, 0.5684, 0.567 , 0.5664, 0.5635,\n",
       "            0.5625, 0.5615, 0.561 , 0.5605, 0.56  , 0.557 , 0.554 , 0.5503,\n",
       "            0.549 , 0.5464, 0.541 , 0.54  , 0.5396, 0.536 , 0.5356, 0.5312,\n",
       "            0.531 , 0.527 , 0.5244, 0.5146, 0.5137, 0.513 , 0.511 , 0.509 ,\n",
       "            0.508 , 0.506 , 0.5044, 0.5015, 0.501 , 0.5005, 0.499 , 0.4988,\n",
       "            0.4968, 0.4966, 0.496 , 0.4946, 0.4934, 0.4917, 0.4912, 0.4893,\n",
       "            0.4875, 0.487 , 0.4866, 0.4863, 0.483 , 0.48  , 0.4768, 0.4763,\n",
       "            0.4753, 0.4705, 0.47  , 0.4695, 0.4644, 0.4626, 0.4534, 0.4512,\n",
       "            0.4478, 0.4463, 0.443 , 0.44  , 0.4397, 0.4387, 0.4382, 0.4377,\n",
       "            0.4333, 0.4329, 0.4321, 0.4307, 0.4292, 0.429 , 0.4275, 0.4229,\n",
       "            0.4211, 0.4197, 0.4175, 0.4165, 0.415 , 0.4138, 0.4114, 0.41  ,\n",
       "            0.4084, 0.3997, 0.3992, 0.399 , 0.3977, 0.3972, 0.3916, 0.391 ,\n",
       "            0.3909, 0.3901, 0.3894, 0.3882, 0.3857, 0.384 , 0.3806, 0.3804,\n",
       "            0.3723, 0.3718, 0.371 , 0.367 , 0.366 , 0.3643, 0.363 , 0.3628,\n",
       "            0.3613, 0.3604, 0.3599, 0.3572, 0.357 , 0.3567, 0.3547, 0.3506,\n",
       "            0.3499, 0.349 , 0.3472, 0.3445, 0.344 , 0.3433, 0.343 , 0.3428,\n",
       "            0.3408, 0.3396, 0.339 , 0.3362, 0.3347, 0.3335, 0.3333, 0.3328,\n",
       "            0.3323, 0.3318, 0.331 , 0.3306, 0.3298, 0.3293, 0.328 , 0.3271,\n",
       "            0.327 , 0.3262, 0.3247, 0.3245, 0.3242, 0.3228, 0.3206, 0.3203,\n",
       "            0.3186, 0.3171, 0.317 , 0.3162, 0.315 , 0.3127, 0.31  , 0.3093,\n",
       "            0.3086, 0.3074, 0.3052, 0.3047, 0.3044, 0.3035, 0.3022, 0.3018,\n",
       "            0.301 , 0.3   , 0.2998, 0.2947, 0.2932, 0.2925, 0.2915, 0.2886,\n",
       "            0.2864, 0.2805, 0.2803, 0.2734, 0.2722, 0.2666, 0.2656, 0.2646,\n",
       "            0.2622, 0.2615, 0.26  , 0.2585, 0.2477, 0.235 , 0.2332, 0.2289,\n",
       "            0.2229, 0.2218, 0.2113, 0.2065, 0.2063, 0.2047, 0.2035, 0.1967,\n",
       "            0.1849, 0.1838, 0.1772, 0.1759, 0.1753, 0.1666, 0.1597, 0.158 ,\n",
       "            0.1532, 0.1482, 0.1404, 0.1318, 0.1279, 0.1198, 0.0854],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00746269, dtype=float32),\n",
       "    'tpr': array(0.7413793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.08955224, 0.09701493,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41791046,\n",
       "            0.42537314, 0.4477612 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.86206895, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.715  , 0.707  , 0.7036 , 0.6978 , 0.69   , 0.688  ,\n",
       "            0.6826 , 0.682  , 0.677  , 0.6733 , 0.6714 , 0.6553 , 0.6494 ,\n",
       "            0.641  , 0.6304 , 0.63   , 0.6294 , 0.629  , 0.6245 , 0.62   ,\n",
       "            0.6177 , 0.607  , 0.606  , 0.6045 , 0.6025 , 0.6    , 0.5996 ,\n",
       "            0.598  , 0.597  , 0.596  , 0.5938 , 0.593  , 0.5894 , 0.588  ,\n",
       "            0.5874 , 0.587  , 0.5864 , 0.5845 , 0.5767 , 0.5747 , 0.574  ,\n",
       "            0.573  , 0.5703 , 0.5684 , 0.5674 , 0.5625 , 0.562  , 0.561  ,\n",
       "            0.556  , 0.5547 , 0.55   , 0.549  , 0.5474 , 0.546  , 0.5444 ,\n",
       "            0.544  , 0.5435 , 0.538  , 0.535  , 0.534  , 0.533  , 0.5327 ,\n",
       "            0.5303 , 0.528  , 0.526  , 0.5244 , 0.5215 , 0.5205 , 0.519  ,\n",
       "            0.5166 , 0.5146 , 0.5137 , 0.511  , 0.5107 , 0.5093 , 0.508  ,\n",
       "            0.5073 , 0.507  , 0.5044 , 0.502  , 0.5005 , 0.498  , 0.4963 ,\n",
       "            0.4937 , 0.493  , 0.482  , 0.4775 , 0.4758 , 0.4702 , 0.4685 ,\n",
       "            0.4666 , 0.466  , 0.4622 , 0.4595 , 0.459  , 0.4583 , 0.457  ,\n",
       "            0.455  , 0.4536 , 0.4507 , 0.447  , 0.4463 , 0.446  , 0.4458 ,\n",
       "            0.4424 , 0.4375 , 0.4363 , 0.436  , 0.4346 , 0.4336 , 0.432  ,\n",
       "            0.4287 , 0.4224 , 0.4204 , 0.42   , 0.4194 , 0.4158 , 0.413  ,\n",
       "            0.4126 , 0.4104 , 0.4082 , 0.408  , 0.4055 , 0.4038 , 0.403  ,\n",
       "            0.4011 , 0.3972 , 0.3945 , 0.3877 , 0.387  , 0.384  , 0.3828 ,\n",
       "            0.3826 , 0.3813 , 0.3801 , 0.3796 , 0.3777 , 0.3762 , 0.3755 ,\n",
       "            0.3699 , 0.3691 , 0.3647 , 0.363  , 0.3628 , 0.3623 , 0.3606 ,\n",
       "            0.3591 , 0.3557 , 0.3552 , 0.3545 , 0.3538 , 0.3535 , 0.353  ,\n",
       "            0.3516 , 0.351  , 0.3503 , 0.3494 , 0.3489 , 0.3452 , 0.3445 ,\n",
       "            0.343  , 0.3423 , 0.3403 , 0.3398 , 0.3364 , 0.335  , 0.3345 ,\n",
       "            0.3342 , 0.3337 , 0.331  , 0.3286 , 0.3281 , 0.327  , 0.3262 ,\n",
       "            0.326  , 0.3252 , 0.3237 , 0.3235 , 0.3228 , 0.321  , 0.3186 ,\n",
       "            0.3167 , 0.3164 , 0.3135 , 0.313  , 0.3118 , 0.3093 , 0.307  ,\n",
       "            0.3052 , 0.3032 , 0.302  , 0.2998 , 0.2993 , 0.2944 , 0.289  ,\n",
       "            0.2888 , 0.279  , 0.2786 , 0.2769 , 0.2705 , 0.264  , 0.2637 ,\n",
       "            0.263  , 0.2593 , 0.2566 , 0.243  , 0.2295 , 0.2292 , 0.2235 ,\n",
       "            0.2173 , 0.2161 , 0.2043 , 0.2013 , 0.1993 , 0.1985 , 0.1965 ,\n",
       "            0.1898 , 0.1787 , 0.1752 , 0.1687 , 0.1682 , 0.1665 , 0.1575 ,\n",
       "            0.1517 , 0.1495 , 0.1436 , 0.1393 , 0.1307 , 0.1223 , 0.1184 ,\n",
       "            0.1103 , 0.07654], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00746269, dtype=float32),\n",
       "    'tpr': array(0.80172414, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.40298507, 0.41044775, 0.42537314, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5671642 ,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.6465517 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.87931037, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.744  , 0.737  , 0.7324 , 0.726  , 0.7183 , 0.7173 ,\n",
       "            0.711  , 0.7056 , 0.7017 , 0.7    , 0.6997 , 0.6826 , 0.677  ,\n",
       "            0.6587 , 0.658  , 0.657  , 0.6553 , 0.652  , 0.6465 , 0.645  ,\n",
       "            0.6416 , 0.635  , 0.6343 , 0.6333 , 0.6304 , 0.63   , 0.626  ,\n",
       "            0.6255 , 0.6245 , 0.621  , 0.6187 , 0.6157 , 0.6147 , 0.614  ,\n",
       "            0.6113 , 0.611  , 0.6084 , 0.606  , 0.605  , 0.6045 , 0.602  ,\n",
       "            0.6    , 0.599  , 0.597  , 0.586  , 0.585  , 0.5825 , 0.5815 ,\n",
       "            0.5796 , 0.577  , 0.576  , 0.5757 , 0.5747 , 0.569  , 0.5684 ,\n",
       "            0.567  , 0.565  , 0.564  , 0.563  , 0.5576 , 0.555  , 0.5503 ,\n",
       "            0.55   , 0.549  , 0.5444 , 0.544  , 0.5405 , 0.5366 , 0.536  ,\n",
       "            0.5356 , 0.5347 , 0.534  , 0.5303 , 0.5293 , 0.5283 , 0.526  ,\n",
       "            0.5254 , 0.5244 , 0.52   , 0.514  , 0.5093 , 0.5063 , 0.5015 ,\n",
       "            0.499  , 0.493  , 0.4922 , 0.4863 , 0.485  , 0.4846 , 0.4812 ,\n",
       "            0.4795 , 0.479  , 0.4778 , 0.4766 , 0.4712 , 0.471  , 0.4707 ,\n",
       "            0.464  , 0.4634 , 0.4612 , 0.4604 , 0.4597 , 0.4583 , 0.4573 ,\n",
       "            0.4553 , 0.4548 , 0.4524 , 0.4456 , 0.444  , 0.4429 , 0.4407 ,\n",
       "            0.44   , 0.4395 , 0.436  , 0.4353 , 0.4348 , 0.434  , 0.429  ,\n",
       "            0.4219 , 0.4202 , 0.419  , 0.418  , 0.4177 , 0.416  , 0.4136 ,\n",
       "            0.4092 , 0.4077 , 0.405  , 0.4033 , 0.4023 , 0.402  , 0.4006 ,\n",
       "            0.4001 , 0.398  , 0.3977 , 0.3948 , 0.3909 , 0.388  , 0.3855 ,\n",
       "            0.3828 , 0.3813 , 0.3804 , 0.379  , 0.3787 , 0.3782 , 0.3777 ,\n",
       "            0.3772 , 0.3752 , 0.3743 , 0.3735 , 0.3708 , 0.367  , 0.3638 ,\n",
       "            0.3635 , 0.3623 , 0.3616 , 0.3613 , 0.36   , 0.3591 , 0.3564 ,\n",
       "            0.3542 , 0.353  , 0.3523 , 0.3513 , 0.351  , 0.3489 , 0.3474 ,\n",
       "            0.3472 , 0.3464 , 0.3455 , 0.345  , 0.3442 , 0.342  , 0.339  ,\n",
       "            0.3389 , 0.3354 , 0.3352 , 0.3347 , 0.3286 , 0.3281 , 0.327  ,\n",
       "            0.326  , 0.3242 , 0.3215 , 0.3198 , 0.3196 , 0.3171 , 0.3132 ,\n",
       "            0.3083 , 0.3062 , 0.302  , 0.3003 , 0.2996 , 0.2961 , 0.294  ,\n",
       "            0.288  , 0.278  , 0.268  , 0.2634 , 0.2622 , 0.261  , 0.256  ,\n",
       "            0.2534 , 0.239  , 0.2266 , 0.2246 , 0.2186 , 0.212  , 0.2108 ,\n",
       "            0.1978 , 0.1973 , 0.1934 , 0.193  , 0.1901 , 0.1841 , 0.1731 ,\n",
       "            0.167  , 0.1627 , 0.1599 , 0.1584 , 0.1488 , 0.1437 , 0.1422 ,\n",
       "            0.1348 , 0.1317 , 0.1217 , 0.1138 , 0.1099 , 0.10175, 0.06903],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00746269, dtype=float32),\n",
       "    'tpr': array(0.87931037, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.08208955, 0.08208955, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5970149 , 0.6044776 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.67241377, 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.772  , 0.7646 , 0.7603 , 0.7534 , 0.7466 , 0.7456 ,\n",
       "            0.7393 , 0.739  , 0.734  , 0.729  , 0.7285 , 0.7275 , 0.727  ,\n",
       "            0.71   , 0.709  , 0.7036 , 0.686  , 0.6855 , 0.685  , 0.68   ,\n",
       "            0.6787 , 0.676  , 0.673  , 0.672  , 0.67   , 0.6646 , 0.6626 ,\n",
       "            0.661  , 0.6577 , 0.654  , 0.652  , 0.6514 , 0.6484 , 0.6445 ,\n",
       "            0.643  , 0.6416 , 0.6406 , 0.64   , 0.6396 , 0.639  , 0.638  ,\n",
       "            0.6377 , 0.6353 , 0.6343 , 0.6333 , 0.63   , 0.626  , 0.625  ,\n",
       "            0.6167 , 0.614  , 0.6123 , 0.612  , 0.61   , 0.6074 , 0.607  ,\n",
       "            0.601  , 0.599  , 0.597  , 0.5967 , 0.594  , 0.5938 , 0.5923 ,\n",
       "            0.586  , 0.5835 , 0.5776 , 0.5757 , 0.574  , 0.5713 , 0.5684 ,\n",
       "            0.568  , 0.565  , 0.563  , 0.561  , 0.5596 , 0.559  , 0.558  ,\n",
       "            0.557  , 0.5557 , 0.55   , 0.5493 , 0.5464 , 0.542  , 0.536  ,\n",
       "            0.5356 , 0.534  , 0.5312 , 0.522  , 0.517  , 0.5166 , 0.5103 ,\n",
       "            0.508  , 0.5073 , 0.505  , 0.5034 , 0.501  , 0.499  , 0.4983 ,\n",
       "            0.497  , 0.4958 , 0.4907 , 0.4858 , 0.4846 , 0.4812 , 0.481  ,\n",
       "            0.4792 , 0.479  , 0.4788 , 0.4773 , 0.4768 , 0.4697 , 0.4695 ,\n",
       "            0.4663 , 0.466  , 0.4617 , 0.4612 , 0.46   , 0.4597 , 0.459  ,\n",
       "            0.4573 , 0.456  , 0.446  , 0.4421 , 0.4382 , 0.4363 , 0.4326 ,\n",
       "            0.4314 , 0.431  , 0.4307 , 0.4292 , 0.427  , 0.4268 , 0.426  ,\n",
       "            0.4243 , 0.4214 , 0.421  , 0.4202 , 0.419  , 0.418  , 0.4143 ,\n",
       "            0.406  , 0.4033 , 0.4011 , 0.4001 , 0.4    , 0.398  , 0.397  ,\n",
       "            0.3965 , 0.3962 , 0.396  , 0.3953 , 0.395  , 0.3936 , 0.3914 ,\n",
       "            0.386  , 0.3855 , 0.3843 , 0.3828 , 0.3816 , 0.3813 , 0.3804 ,\n",
       "            0.3777 , 0.3755 , 0.3706 , 0.3694 , 0.3687 , 0.3684 , 0.368  ,\n",
       "            0.3672 , 0.367  , 0.3652 , 0.3628 , 0.362  , 0.3591 , 0.3582 ,\n",
       "            0.3572 , 0.3564 , 0.3555 , 0.3545 , 0.3525 , 0.3477 , 0.3467 ,\n",
       "            0.3457 , 0.344  , 0.3433 , 0.339  , 0.3381 , 0.337  , 0.3298 ,\n",
       "            0.329  , 0.3235 , 0.322  , 0.3174 , 0.3152 , 0.3145 , 0.3135 ,\n",
       "            0.3103 , 0.3018 , 0.3005 , 0.2996 , 0.2937 , 0.2874 , 0.2766 ,\n",
       "            0.2664 , 0.2622 , 0.2607 , 0.258  , 0.253  , 0.25   , 0.2344 ,\n",
       "            0.2233 , 0.2194 , 0.2135 , 0.2065 , 0.2051 , 0.1925 , 0.191  ,\n",
       "            0.1876 , 0.1864 , 0.1835 , 0.178  , 0.1669 , 0.1587 , 0.1561 ,\n",
       "            0.1515 , 0.1503 , 0.1403 , 0.1359 , 0.1344 , 0.126  , 0.1239 ,\n",
       "            0.113  , 0.1054 , 0.10156, 0.0935 , 0.06177], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.02238806, dtype=float32),\n",
       "    'tpr': array(0.8965517, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.46268657, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.6810345 , 0.6896552 , 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.86206895, 0.87068963, 0.87931037, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.7905 , 0.7812 , 0.7764 , 0.7725 , 0.7646 , 0.7617 ,\n",
       "            0.755  , 0.7515 , 0.7476 , 0.7456 , 0.745  , 0.7437 , 0.7314 ,\n",
       "            0.729  , 0.722  , 0.701  , 0.7    , 0.6997 , 0.697  , 0.6963 ,\n",
       "            0.691  , 0.6885 , 0.687  , 0.685  , 0.6807 , 0.6763 , 0.6724 ,\n",
       "            0.669  , 0.666  , 0.6655 , 0.663  , 0.6616 , 0.6587 , 0.657  ,\n",
       "            0.6567 , 0.6562 , 0.6553 , 0.652  , 0.6514 , 0.651  , 0.647  ,\n",
       "            0.642  , 0.6416 , 0.6387 , 0.632  , 0.631  , 0.63   , 0.6274 ,\n",
       "            0.627  , 0.625  , 0.624  , 0.6226 , 0.622  , 0.6157 , 0.6143 ,\n",
       "            0.6133 , 0.611  , 0.6104 , 0.609  , 0.6084 , 0.6025 , 0.5996 ,\n",
       "            0.5913 , 0.586  , 0.5854 , 0.5815 , 0.579  , 0.5786 , 0.578  ,\n",
       "            0.5767 , 0.5757 , 0.5737 , 0.5728 , 0.5703 , 0.5693 , 0.569  ,\n",
       "            0.5684 , 0.5635 , 0.563  , 0.5576 , 0.554  , 0.548  , 0.5464 ,\n",
       "            0.544  , 0.5396 , 0.534  , 0.5283 , 0.527  , 0.5195 , 0.5176 ,\n",
       "            0.514  , 0.512  , 0.5083 , 0.508  , 0.5054 , 0.504  , 0.5005 ,\n",
       "            0.4998 , 0.493  , 0.4915 , 0.4905 , 0.4902 , 0.4885 , 0.4878 ,\n",
       "            0.4849 , 0.4846 , 0.484  , 0.4778 , 0.4714 , 0.468  , 0.4678 ,\n",
       "            0.4675 , 0.4666 , 0.466  , 0.4656 , 0.4653 , 0.4592 , 0.4585 ,\n",
       "            0.4512 , 0.4434 , 0.4414 , 0.441  , 0.4385 , 0.4373 , 0.4343 ,\n",
       "            0.4329 , 0.4324 , 0.4307 , 0.4297 , 0.429  , 0.4285 , 0.4268 ,\n",
       "            0.425  , 0.4204 , 0.4187 , 0.418  , 0.4133 , 0.4104 , 0.4023 ,\n",
       "            0.4011 , 0.4    , 0.3997 , 0.3994 , 0.3984 , 0.3965 , 0.3955 ,\n",
       "            0.3953 , 0.394  , 0.3938 , 0.388  , 0.3865 , 0.385  , 0.3833 ,\n",
       "            0.381  , 0.3801 , 0.3794 , 0.3774 , 0.3772 , 0.3765 , 0.3733 ,\n",
       "            0.3696 , 0.3691 , 0.3684 , 0.3672 , 0.3667 , 0.3652 , 0.3647 ,\n",
       "            0.3638 , 0.363  , 0.3625 , 0.3591 , 0.3586 , 0.3584 , 0.356  ,\n",
       "            0.3535 , 0.3528 , 0.3516 , 0.3464 , 0.3462 , 0.3435 , 0.3433 ,\n",
       "            0.3428 , 0.342  , 0.3403 , 0.3389 , 0.3376 , 0.331  , 0.3293 ,\n",
       "            0.328  , 0.3276 , 0.3213 , 0.3174 , 0.3132 , 0.309  , 0.3083 ,\n",
       "            0.3074 , 0.297  , 0.2966 , 0.2957 , 0.2896 , 0.283  , 0.272  ,\n",
       "            0.2612 , 0.2585 , 0.2573 , 0.2512 , 0.2462 , 0.243  , 0.2272 ,\n",
       "            0.2185 , 0.2114 , 0.2058 , 0.1989 , 0.1973 , 0.187  , 0.1824 ,\n",
       "            0.1804 , 0.1781 , 0.1752 , 0.1705 , 0.16   , 0.149  , 0.1421 ,\n",
       "            0.141  , 0.1307 , 0.1271 , 0.1263 , 0.1166 , 0.1158 , 0.10376,\n",
       "            0.09686, 0.093  , 0.0851 , 0.0549 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04477612, dtype=float32),\n",
       "    'tpr': array(0.9310345, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.05223881, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6551724 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.86206895,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.9310345 , 0.9310345 ,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.812  , 0.8027 , 0.798  , 0.795  , 0.7866 , 0.7837 ,\n",
       "            0.777  , 0.773  , 0.77   , 0.768  , 0.7666 , 0.7656 , 0.757  ,\n",
       "            0.7495 , 0.7446 , 0.7227 , 0.722  , 0.7217 , 0.7197 , 0.719  ,\n",
       "            0.7188 , 0.713  , 0.7104 , 0.7085 , 0.705  , 0.6978 , 0.6973 ,\n",
       "            0.694  , 0.69   , 0.6875 , 0.6865 , 0.684  , 0.683  , 0.6807 ,\n",
       "            0.68   , 0.6797 , 0.679  , 0.678  , 0.6777 , 0.6763 , 0.6753 ,\n",
       "            0.674  , 0.672  , 0.671  , 0.6694 , 0.6636 , 0.662  , 0.659  ,\n",
       "            0.6543 , 0.653  , 0.652  , 0.6494 , 0.648  , 0.647  , 0.6436 ,\n",
       "            0.643  , 0.642  , 0.6367 , 0.6357 , 0.6343 , 0.6323 , 0.6313 ,\n",
       "            0.63   , 0.6235 , 0.622  , 0.6206 , 0.6113 , 0.6045 , 0.604  ,\n",
       "            0.6006 , 0.598  , 0.5977 , 0.595  , 0.5947 , 0.5923 , 0.5913 ,\n",
       "            0.5894 , 0.5884 , 0.5874 , 0.5864 , 0.582  , 0.581  , 0.5757 ,\n",
       "            0.566  , 0.5654 , 0.564  , 0.5615 , 0.5576 , 0.5513 , 0.5454 ,\n",
       "            0.5435 , 0.5356 , 0.533  , 0.53   , 0.5283 , 0.5234 , 0.523  ,\n",
       "            0.5205 , 0.5195 , 0.515  , 0.5083 , 0.507  , 0.503  , 0.5015 ,\n",
       "            0.499  , 0.498  , 0.4907 , 0.4854 , 0.4817 , 0.4807 , 0.4802 ,\n",
       "            0.48   , 0.4797 , 0.479  , 0.4722 , 0.4714 , 0.462  , 0.4539 ,\n",
       "            0.4534 , 0.4517 , 0.4482 , 0.4478 , 0.4429 , 0.4426 , 0.4424 ,\n",
       "            0.4417 , 0.4404 , 0.4387 , 0.4375 , 0.4363 , 0.4312 , 0.4292 ,\n",
       "            0.4287 , 0.428  , 0.4258 , 0.4185 , 0.411  , 0.4104 , 0.4094 ,\n",
       "            0.409  , 0.4082 , 0.4072 , 0.407  , 0.4067 , 0.4055 , 0.4038 ,\n",
       "            0.4026 , 0.401  , 0.397  , 0.3918 , 0.3904 , 0.3887 , 0.388  ,\n",
       "            0.3877 , 0.386  , 0.3853 , 0.3804 , 0.3782 , 0.376  , 0.3752 ,\n",
       "            0.3745 , 0.3743 , 0.374  , 0.3713 , 0.371  , 0.3706 , 0.3682 ,\n",
       "            0.3667 , 0.3652 , 0.3625 , 0.3604 , 0.36   , 0.3599 , 0.3596 ,\n",
       "            0.359  , 0.3523 , 0.3506 , 0.3484 , 0.346  , 0.3455 , 0.345  ,\n",
       "            0.3445 , 0.343  , 0.3384 , 0.3362 , 0.3345 , 0.3296 , 0.3274 ,\n",
       "            0.3235 , 0.3206 , 0.3142 , 0.313  , 0.31   , 0.307  , 0.3057 ,\n",
       "            0.294  , 0.2937 , 0.2927 , 0.288  , 0.281  , 0.268  , 0.258  ,\n",
       "            0.255  , 0.254  , 0.2463 , 0.2411 , 0.2379 , 0.2207 , 0.2137 ,\n",
       "            0.205  , 0.1995 , 0.1923 , 0.1907 , 0.1814 , 0.1748 , 0.1737 ,\n",
       "            0.1709 , 0.1678 , 0.1636 , 0.1532 , 0.142  , 0.1409 , 0.1339 ,\n",
       "            0.1329 , 0.1226 , 0.12024, 0.1186 , 0.1086 , 0.1082 , 0.0959 ,\n",
       "            0.0891 , 0.08527, 0.07764, 0.04877], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04477612, dtype=float32),\n",
       "    'tpr': array(0.9655172, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.05970149, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.6044776 , 0.6119403 , 0.619403  , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5948276 , 0.6034483 , 0.61206895, 0.62931037,\n",
       "            0.6465517 , 0.6637931 , 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.7758621 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.8315 , 0.8223 , 0.8174 , 0.8154 , 0.8076 , 0.8037 ,\n",
       "            0.797  , 0.7964 , 0.793  , 0.7915 , 0.789  , 0.787  , 0.785  ,\n",
       "            0.7812 , 0.7725 , 0.766  , 0.744  , 0.743  , 0.7427 , 0.7417 ,\n",
       "            0.7407 , 0.7383 , 0.734  , 0.7334 , 0.729  , 0.7285 , 0.718  ,\n",
       "            0.7144 , 0.7114 , 0.7075 , 0.7065 , 0.7046 , 0.7036 , 0.7007 ,\n",
       "            0.6997 , 0.698  , 0.6978 , 0.6973 , 0.6963 , 0.6934 , 0.693  ,\n",
       "            0.692  , 0.6846 , 0.6836 , 0.679  , 0.678  , 0.6763 , 0.6753 ,\n",
       "            0.674  , 0.6714 , 0.669  , 0.6665 , 0.6636 , 0.6616 , 0.6597 ,\n",
       "            0.657  , 0.6562 , 0.6543 , 0.654  , 0.6465 , 0.6436 , 0.633  ,\n",
       "            0.6255 , 0.623  , 0.62   , 0.6167 , 0.616  , 0.6133 , 0.613  ,\n",
       "            0.6113 , 0.61   , 0.608  , 0.6064 , 0.6045 , 0.6035 , 0.6006 ,\n",
       "            0.5957 , 0.584  , 0.5815 , 0.5776 , 0.5703 , 0.5645 , 0.5625 ,\n",
       "            0.554  , 0.551  , 0.5483 , 0.5464 , 0.546  , 0.5405 , 0.539  ,\n",
       "            0.537  , 0.5356 , 0.5317 , 0.5303 , 0.526  , 0.524  , 0.521  ,\n",
       "            0.519  , 0.517  , 0.5156 , 0.5127 , 0.504  , 0.4988 , 0.4963 ,\n",
       "            0.496  , 0.4956 , 0.495  , 0.4937 , 0.4932 , 0.485  , 0.4844 ,\n",
       "            0.4744 , 0.4668 , 0.465  , 0.464  , 0.4604 , 0.4592 , 0.4556 ,\n",
       "            0.4543 , 0.454  , 0.4539 , 0.4536 , 0.4524 , 0.4517 , 0.4495 ,\n",
       "            0.4487 , 0.4421 , 0.4397 , 0.4395 , 0.4392 , 0.4385 , 0.4275 ,\n",
       "            0.4229 , 0.4214 , 0.4207 , 0.42   , 0.4187 , 0.4185 , 0.4172 ,\n",
       "            0.4155 , 0.4153 , 0.4114 , 0.4097 , 0.4058 , 0.4011 , 0.4006 ,\n",
       "            0.3972 , 0.397  , 0.3962 , 0.3958 , 0.394  , 0.3936 , 0.3887 ,\n",
       "            0.388  , 0.3862 , 0.3853 , 0.3848 , 0.384  , 0.3813 , 0.3804 ,\n",
       "            0.3777 , 0.3774 , 0.3772 , 0.3762 , 0.3743 , 0.3699 , 0.3691 ,\n",
       "            0.3687 , 0.3657 , 0.3652 , 0.3638 , 0.3591 , 0.3582 , 0.357  ,\n",
       "            0.35   , 0.3484 , 0.3474 , 0.3462 , 0.341  , 0.3394 , 0.3308 ,\n",
       "            0.3303 , 0.3286 , 0.3242 , 0.3208 , 0.3193 , 0.3093 , 0.3054 ,\n",
       "            0.3047 , 0.2935 , 0.2925 , 0.2922 , 0.2856 , 0.2783 , 0.2664 ,\n",
       "            0.2551 , 0.2546 , 0.2534 , 0.2422 , 0.2368 , 0.2335 , 0.2158 ,\n",
       "            0.2115 , 0.199  , 0.194  , 0.1865 , 0.1849 , 0.178  , 0.169  ,\n",
       "            0.1672 , 0.1646 , 0.1614 , 0.1582 , 0.1481 , 0.1366 , 0.1328 ,\n",
       "            0.1259 , 0.1254 , 0.11456, 0.1122 , 0.10156, 0.1007 , 0.0882 ,\n",
       "            0.0825 , 0.0788 , 0.0708 , 0.04337], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.08208955, dtype=float32),\n",
       "    'tpr': array(0.9913793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.05223881, 0.05970149,\n",
       "            0.05970149, 0.07462686, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.10447761, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.1637931 , 0.1724138 ,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.5258621 , 0.54310346, 0.55172414,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.8477 , 0.8384 , 0.834  , 0.833  , 0.825  , 0.8203 ,\n",
       "            0.814  , 0.8135 , 0.81   , 0.8096 , 0.807  , 0.805  , 0.8037 ,\n",
       "            0.8022 , 0.7915 , 0.7847 , 0.767  , 0.762  , 0.7607 , 0.76   ,\n",
       "            0.7593 , 0.757  , 0.753  , 0.7524 , 0.7466 , 0.736  , 0.7354 ,\n",
       "            0.732  , 0.7305 , 0.728  , 0.727  , 0.7246 , 0.724  , 0.7236 ,\n",
       "            0.722  , 0.721  , 0.7207 , 0.7188 , 0.7183 , 0.7163 , 0.716  ,\n",
       "            0.714  , 0.7114 , 0.709  , 0.7036 , 0.702  , 0.701  , 0.6987 ,\n",
       "            0.6973 , 0.697  , 0.6963 , 0.6943 , 0.689  , 0.6885 , 0.6875 ,\n",
       "            0.6826 , 0.6816 , 0.679  , 0.678  , 0.6763 , 0.669  , 0.666  ,\n",
       "            0.659  , 0.654  , 0.646  , 0.641  , 0.639  , 0.6387 , 0.6377 ,\n",
       "            0.637  , 0.636  , 0.633  , 0.632  , 0.63   , 0.6284 , 0.628  ,\n",
       "            0.6235 , 0.622  , 0.62   , 0.6147 , 0.6025 , 0.6016 , 0.6    ,\n",
       "            0.597  , 0.596  , 0.59   , 0.582  , 0.58   , 0.5713 , 0.566  ,\n",
       "            0.565  , 0.5635 , 0.559  , 0.5547 , 0.5537 , 0.5522 , 0.549  ,\n",
       "            0.542  , 0.541  , 0.5396 , 0.5366 , 0.533  , 0.5327 , 0.531  ,\n",
       "            0.5303 , 0.5244 , 0.519  , 0.5103 , 0.51   , 0.5093 , 0.506  ,\n",
       "            0.5034 , 0.4956 , 0.4946 , 0.4844 , 0.4775 , 0.4739 , 0.4736 ,\n",
       "            0.473  , 0.4712 , 0.467  , 0.4658 , 0.4636 , 0.4626 , 0.4622 ,\n",
       "            0.4602 , 0.4558 , 0.4504 , 0.45   , 0.4475 , 0.4473 , 0.4463 ,\n",
       "            0.4375 , 0.432  , 0.4302 , 0.4287 , 0.4277 , 0.4275 , 0.4263 ,\n",
       "            0.4255 , 0.4246 , 0.424  , 0.4211 , 0.4175 , 0.416  , 0.4119 ,\n",
       "            0.4087 , 0.4067 , 0.403  , 0.4028 , 0.402  , 0.4019 , 0.3994 ,\n",
       "            0.3992 , 0.3977 , 0.3948 , 0.394  , 0.3928 , 0.392  , 0.3918 ,\n",
       "            0.3909 , 0.3877 , 0.3867 , 0.382  , 0.3816 , 0.3809 , 0.3774 ,\n",
       "            0.375  , 0.3748 , 0.374  , 0.3735 , 0.371  , 0.3687 , 0.3667 ,\n",
       "            0.364  , 0.362  , 0.3613 , 0.3525 , 0.3516 , 0.3503 , 0.3496 ,\n",
       "            0.348  , 0.3433 , 0.3425 , 0.3413 , 0.3335 , 0.333  , 0.3284 ,\n",
       "            0.3247 , 0.3235 , 0.322  , 0.3071 , 0.3047 , 0.302  , 0.2913 ,\n",
       "            0.29   , 0.2898 , 0.2842 , 0.2766 , 0.263  , 0.2522 , 0.252  ,\n",
       "            0.251  , 0.2375 , 0.2322 , 0.2286 , 0.2101 , 0.2075 , 0.1931 ,\n",
       "            0.1879 , 0.1804 , 0.1787 , 0.1729 , 0.1636 , 0.1599 , 0.158  ,\n",
       "            0.1547 , 0.1517 , 0.1421 , 0.1304 , 0.1251 , 0.1184 , 0.1178 ,\n",
       "            0.10706, 0.1058 , 0.1052 , 0.09485, 0.0935 , 0.0818 , 0.076  ,\n",
       "            0.0724 , 0.0644 , 0.0386 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.10447761, dtype=float32),\n",
       "    'tpr': array(0.9913793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.05970149, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.1119403 ,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.29104477, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.18103448, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.35344827,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.4051724 , 0.41379312,\n",
       "            0.43103448, 0.43965518, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.6810345 , 0.6896552 , 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.8667 , 0.859  , 0.855  , 0.853  , 0.8457 , 0.843  ,\n",
       "            0.836  , 0.8354 , 0.831  , 0.8306 , 0.828  , 0.8257 , 0.8247 ,\n",
       "            0.8125 , 0.806  , 0.795  , 0.792  , 0.784  , 0.7837 , 0.782  ,\n",
       "            0.779  , 0.7734 , 0.771  , 0.7603 , 0.7593 , 0.757  , 0.756  ,\n",
       "            0.755  , 0.7524 , 0.7505 , 0.75   , 0.749  , 0.7466 , 0.746  ,\n",
       "            0.7417 , 0.7393 , 0.7383 , 0.734  , 0.733  , 0.727  , 0.7256 ,\n",
       "            0.7246 , 0.722  , 0.721  , 0.7183 , 0.7124 , 0.711  , 0.7104 ,\n",
       "            0.71   , 0.7075 , 0.7056 , 0.704  , 0.703  , 0.7026 , 0.697  ,\n",
       "            0.6934 , 0.682  , 0.678  , 0.6733 , 0.668  , 0.6646 , 0.6636 ,\n",
       "            0.663  , 0.6616 , 0.6606 , 0.66   , 0.657  , 0.6562 , 0.656  ,\n",
       "            0.6514 , 0.65   , 0.6475 , 0.646  , 0.6445 , 0.6426 , 0.631  ,\n",
       "            0.6294 , 0.6284 , 0.623  , 0.6143 , 0.614  , 0.607  , 0.5986 ,\n",
       "            0.591  , 0.5903 , 0.5874 , 0.5835 , 0.581  , 0.5757 , 0.575  ,\n",
       "            0.5723 , 0.57   , 0.5693 , 0.569  , 0.5674 , 0.559  , 0.5557 ,\n",
       "            0.554  , 0.553  , 0.551  , 0.5503 , 0.548  , 0.54   , 0.5386 ,\n",
       "            0.537  , 0.5356 , 0.532  , 0.531  , 0.5215 , 0.52   , 0.5186 ,\n",
       "            0.5015 , 0.5    , 0.4956 , 0.4922 , 0.491  , 0.4893 , 0.489  ,\n",
       "            0.4866 , 0.486  , 0.4836 , 0.4824 , 0.4812 , 0.4773 , 0.4731 ,\n",
       "            0.4717 , 0.4702 , 0.466  , 0.4658 , 0.4578 , 0.453  , 0.4524 ,\n",
       "            0.451  , 0.4507 , 0.45   , 0.4473 , 0.436  , 0.4355 , 0.4343 ,\n",
       "            0.434  , 0.4312 , 0.4304 , 0.4272 , 0.425  , 0.4243 , 0.4233 ,\n",
       "            0.4214 , 0.42   , 0.4182 , 0.4172 , 0.4165 , 0.4155 , 0.4153 ,\n",
       "            0.4138 , 0.4111 , 0.4102 , 0.4053 , 0.4036 , 0.4006 , 0.4001 ,\n",
       "            0.4    , 0.3962 , 0.3953 , 0.3877 , 0.3872 , 0.3862 , 0.3828 ,\n",
       "            0.3823 , 0.3801 , 0.38   , 0.379  , 0.3718 , 0.3616 , 0.36   ,\n",
       "            0.3562 , 0.3552 , 0.3547 , 0.3533 , 0.352  , 0.3462 , 0.346  ,\n",
       "            0.344  , 0.3345 , 0.3293 , 0.3271 , 0.3064 , 0.305  , 0.3013 ,\n",
       "            0.2905 , 0.2893 , 0.289  , 0.2832 , 0.2754 , 0.2612 , 0.251  ,\n",
       "            0.2502 , 0.2496 , 0.234  , 0.2283 , 0.2247 , 0.2053 , 0.2048 ,\n",
       "            0.188  , 0.1827 , 0.1749 , 0.1733 , 0.1683 , 0.159  , 0.1531 ,\n",
       "            0.1519 , 0.1484 , 0.1464 , 0.1368 , 0.12494, 0.118  , 0.11127,\n",
       "            0.111  , 0.10016, 0.0993 , 0.0991 , 0.0888 , 0.0868 , 0.07587,\n",
       "            0.0702 , 0.0667 , 0.05865, 0.03442], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.14179105, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.10447761, 0.1119403 , 0.12686567, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6810345 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.877  , 0.868  , 0.8643 , 0.864  , 0.857  , 0.8555 ,\n",
       "            0.851  , 0.845  , 0.8447 , 0.843  , 0.842  , 0.839  , 0.836  ,\n",
       "            0.8345 , 0.8257 , 0.82   , 0.8193 , 0.817  , 0.81   , 0.8047 ,\n",
       "            0.7974 , 0.7954 , 0.795  , 0.7944 , 0.7935 , 0.7866 , 0.7847 ,\n",
       "            0.782  , 0.7817 , 0.7812 , 0.7754 , 0.772  , 0.7715 , 0.771  ,\n",
       "            0.7695 , 0.767  , 0.766  , 0.7603 , 0.7593 , 0.759  , 0.7583 ,\n",
       "            0.7573 , 0.755  , 0.754  , 0.752  , 0.7515 , 0.751  , 0.75   ,\n",
       "            0.7495 , 0.7476 , 0.746  , 0.7446 , 0.742  , 0.7397 , 0.7383 ,\n",
       "            0.737  , 0.7363 , 0.7334 , 0.7314 , 0.731  , 0.7305 , 0.7295 ,\n",
       "            0.724  , 0.7227 , 0.719  , 0.7163 , 0.715  , 0.705  , 0.6963 ,\n",
       "            0.6924 , 0.6895 , 0.686  , 0.684  , 0.6826 , 0.682  , 0.681  ,\n",
       "            0.678  , 0.6743 , 0.674  , 0.6733 , 0.6704 , 0.6665 , 0.6646 ,\n",
       "            0.664  , 0.661  , 0.6562 , 0.6543 , 0.6514 , 0.65   , 0.6475 ,\n",
       "            0.6465 , 0.6367 , 0.6274 , 0.6265 , 0.6235 , 0.6177 , 0.61   ,\n",
       "            0.609  , 0.599  , 0.5986 , 0.5903 , 0.59   , 0.5874 , 0.5854 ,\n",
       "            0.584  , 0.5835 , 0.58   , 0.578  , 0.5723 , 0.5713 , 0.562  ,\n",
       "            0.561  , 0.5557 , 0.5537 , 0.553  , 0.5522 , 0.548  , 0.547  ,\n",
       "            0.5366 , 0.533  , 0.5317 , 0.5293 , 0.5225 , 0.5215 , 0.5107 ,\n",
       "            0.5083 , 0.504  , 0.5024 , 0.5015 , 0.4993 , 0.498  , 0.4934 ,\n",
       "            0.488  , 0.4868 , 0.486  , 0.4858 , 0.4841 , 0.4734 , 0.4702 ,\n",
       "            0.47   , 0.4697 , 0.4646 , 0.4636 , 0.4604 , 0.4592 , 0.4585 ,\n",
       "            0.4575 , 0.454  , 0.4487 , 0.4485 , 0.4468 , 0.4397 , 0.4368 ,\n",
       "            0.4363 , 0.4355 , 0.4312 , 0.4294 , 0.426  , 0.4211 , 0.421  ,\n",
       "            0.4207 , 0.4204 , 0.4187 , 0.4185 , 0.4177 , 0.417  , 0.4158 ,\n",
       "            0.414  , 0.4094 , 0.4065 , 0.4048 , 0.401  , 0.3997 , 0.3982 ,\n",
       "            0.39   , 0.3896 , 0.3872 , 0.387  , 0.3862 , 0.3853 , 0.3848 ,\n",
       "            0.3838 , 0.376  , 0.3733 , 0.3667 , 0.3623 , 0.3604 , 0.3562 ,\n",
       "            0.3545 , 0.3538 , 0.3533 , 0.3528 , 0.348  , 0.342  , 0.3403 ,\n",
       "            0.3376 , 0.3289 , 0.326  , 0.3066 , 0.3042 , 0.2983 , 0.2874 ,\n",
       "            0.2866 , 0.2861 , 0.2837 , 0.2751 , 0.257  , 0.2489 , 0.2471 ,\n",
       "            0.2458 , 0.2302 , 0.224  , 0.2205 , 0.1998 , 0.1995 , 0.183  ,\n",
       "            0.1772 , 0.1693 , 0.1675 , 0.1621 , 0.1534 , 0.1465 , 0.1458 ,\n",
       "            0.142  , 0.14   , 0.1302 , 0.1186 , 0.11127, 0.1045 , 0.1043 ,\n",
       "            0.0937 , 0.0935 , 0.0925 , 0.0824 , 0.0804 , 0.0702 , 0.0643 ,\n",
       "            0.06085, 0.0532 , 0.03044], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.18656716, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.10447761, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.0775862 , 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.35344827, 0.36206895, 0.37931034,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.45689654, 0.46551725, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.63793105,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6810345 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.892  , 0.8843 , 0.8804 , 0.875  , 0.8735 , 0.868  ,\n",
       "            0.8623 , 0.861  , 0.859  , 0.857  , 0.854  , 0.8525 , 0.844  ,\n",
       "            0.841  , 0.839  , 0.8384 , 0.832  , 0.826  , 0.8164 , 0.8145 ,\n",
       "            0.8135 , 0.8125 , 0.8076 , 0.8057 , 0.805  , 0.8047 , 0.801  ,\n",
       "            0.798  , 0.7944 , 0.794  , 0.791  , 0.79   , 0.7876 , 0.7866 ,\n",
       "            0.782  , 0.7812 , 0.7793 , 0.778  , 0.7754 , 0.7744 , 0.7734 ,\n",
       "            0.772  , 0.771  , 0.7695 , 0.766  , 0.7656 , 0.765  , 0.7607 ,\n",
       "            0.76   , 0.7593 , 0.7573 , 0.7544 , 0.7534 , 0.7524 , 0.746  ,\n",
       "            0.745  , 0.743  , 0.7363 , 0.736  , 0.7285 , 0.719  , 0.7163 ,\n",
       "            0.7095 , 0.7065 , 0.706  , 0.704  , 0.7017 , 0.6973 , 0.6953 ,\n",
       "            0.6943 , 0.6934 , 0.6875 , 0.687  , 0.686  , 0.682  , 0.677  ,\n",
       "            0.6753 , 0.6743 , 0.673  , 0.6714 , 0.6685 , 0.659  , 0.65   ,\n",
       "            0.649  , 0.6396 , 0.639  , 0.632  , 0.631  , 0.6206 , 0.619  ,\n",
       "            0.6104 , 0.61   , 0.607  , 0.6055 , 0.6035 , 0.5996 , 0.599  ,\n",
       "            0.5933 , 0.592  , 0.591  , 0.58   , 0.579  , 0.5747 , 0.5737 ,\n",
       "            0.573  , 0.5723 , 0.5674 , 0.5664 , 0.555  , 0.5513 , 0.548  ,\n",
       "            0.5474 , 0.5396 , 0.539  , 0.5273 , 0.526  , 0.5215 , 0.521  ,\n",
       "            0.52   , 0.518  , 0.517  , 0.5146 , 0.511  , 0.5073 , 0.502  ,\n",
       "            0.5    , 0.4998 , 0.489  , 0.4854 , 0.4849 , 0.482  , 0.4802 ,\n",
       "            0.477  , 0.476  , 0.4749 , 0.474  , 0.4705 , 0.4626 , 0.4612 ,\n",
       "            0.461  , 0.4531 , 0.452  , 0.4492 , 0.4448 , 0.4446 , 0.4443 ,\n",
       "            0.4392 , 0.436  , 0.4353 , 0.434  , 0.4338 , 0.4336 , 0.4333 ,\n",
       "            0.4307 , 0.4304 , 0.4302 , 0.4285 , 0.424  , 0.4204 , 0.4172 ,\n",
       "            0.415  , 0.4143 , 0.4116 , 0.4106 , 0.4094 , 0.401  , 0.4    ,\n",
       "            0.3984 , 0.396  , 0.3958 , 0.3945 , 0.391  , 0.3894 , 0.3857 ,\n",
       "            0.378  , 0.3765 , 0.3684 , 0.3652 , 0.365  , 0.364  , 0.3628 ,\n",
       "            0.359  , 0.357  , 0.353  , 0.3508 , 0.34   , 0.3298 , 0.3286 ,\n",
       "            0.3074 , 0.3044 , 0.2974 , 0.287  , 0.2856 , 0.2834 , 0.2747 ,\n",
       "            0.2554 , 0.2477 , 0.246  , 0.2448 , 0.2268 , 0.2205 , 0.2167 ,\n",
       "            0.197  , 0.1948 , 0.1781 , 0.1724 , 0.1641 , 0.1624 , 0.1577 ,\n",
       "            0.1492 , 0.1399 , 0.1396 , 0.1359 , 0.1344 , 0.1252 , 0.1134 ,\n",
       "            0.1047 , 0.0981 , 0.0979 , 0.088  , 0.0873 , 0.0869 , 0.07684,\n",
       "            0.07434, 0.0649 , 0.0591 , 0.05582, 0.0484 , 0.02701],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.20149253, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.73275864, 0.7413793 , 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.88793105, 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.9741379 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.906  , 0.8984 , 0.895  , 0.894  , 0.891  , 0.888  ,\n",
       "            0.882  , 0.877  , 0.8745 , 0.8726 , 0.8696 , 0.8677 , 0.8613 ,\n",
       "            0.858  , 0.856  , 0.8506 , 0.8438 , 0.835  , 0.832  , 0.8315 ,\n",
       "            0.83   , 0.829  , 0.8247 , 0.824  , 0.8237 , 0.8228 , 0.8184 ,\n",
       "            0.816  , 0.8125 , 0.8086 , 0.8066 , 0.8057 , 0.805  , 0.8003 ,\n",
       "            0.7993 , 0.7964 , 0.796  , 0.7944 , 0.794  , 0.793  , 0.792  ,\n",
       "            0.7905 , 0.79   , 0.7876 , 0.785  , 0.7837 , 0.7827 , 0.7803 ,\n",
       "            0.78   , 0.779  , 0.7773 , 0.7744 , 0.7734 , 0.7725 , 0.7715 ,\n",
       "            0.77   , 0.7656 , 0.764  , 0.763  , 0.7563 , 0.755  , 0.746  ,\n",
       "            0.738  , 0.736  , 0.7285 , 0.7266 , 0.7246 , 0.724  , 0.723  ,\n",
       "            0.722  , 0.719  , 0.717  , 0.7153 , 0.714  , 0.712  , 0.711  ,\n",
       "            0.7056 , 0.705  , 0.6973 , 0.6934 , 0.693  , 0.692  , 0.6895 ,\n",
       "            0.6865 , 0.6777 , 0.6685 , 0.666  , 0.6567 , 0.6562 , 0.649  ,\n",
       "            0.6475 , 0.6377 , 0.636  , 0.628  , 0.625  , 0.6245 , 0.622  ,\n",
       "            0.62   , 0.6196 , 0.617  , 0.6143 , 0.609  , 0.6084 , 0.608  ,\n",
       "            0.602  , 0.597  , 0.596  , 0.589  , 0.5864 , 0.586  , 0.583  ,\n",
       "            0.5654 , 0.5635 , 0.562  , 0.5557 , 0.5503 , 0.55   , 0.5405 ,\n",
       "            0.533  , 0.532  , 0.5312 , 0.5303 , 0.5283 , 0.523  , 0.5215 ,\n",
       "            0.5137 , 0.5127 , 0.512  , 0.51   , 0.5083 , 0.4968 , 0.4954 ,\n",
       "            0.4927 , 0.4922 , 0.491  , 0.4897 , 0.488  , 0.486  , 0.4841 ,\n",
       "            0.484  , 0.482  , 0.4788 , 0.4714 , 0.4683 , 0.4673 , 0.4602 ,\n",
       "            0.4592 , 0.4558 , 0.4531 , 0.4517 , 0.4487 , 0.4443 , 0.4414 ,\n",
       "            0.4402 , 0.4395 , 0.4387 , 0.4382 , 0.4377 , 0.4375 , 0.4363 ,\n",
       "            0.435  , 0.4338 , 0.4333 , 0.431  , 0.4255 , 0.4243 , 0.422  ,\n",
       "            0.4177 , 0.4163 , 0.4133 , 0.412  , 0.4053 , 0.403  , 0.4019 ,\n",
       "            0.4014 , 0.3975 , 0.3972 , 0.396  , 0.3865 , 0.3828 , 0.377  ,\n",
       "            0.3718 , 0.3677 , 0.3643 , 0.364  , 0.3623 , 0.362  , 0.361  ,\n",
       "            0.353  , 0.3516 , 0.3499 , 0.3416 , 0.3328 , 0.3298 , 0.3079 ,\n",
       "            0.3042 , 0.296  , 0.2866 , 0.2852 , 0.2842 , 0.2827 , 0.2737 ,\n",
       "            0.2537 , 0.2462 , 0.246  , 0.2449 , 0.223  , 0.2167 , 0.2128 ,\n",
       "            0.1956 , 0.1903 , 0.1733 , 0.1676 , 0.1593 , 0.1575 , 0.1545 ,\n",
       "            0.1459 , 0.134  , 0.1335 , 0.1301 , 0.1295 , 0.1214 , 0.10913,\n",
       "            0.0986 , 0.0922 , 0.09204, 0.0828 , 0.082  , 0.08136, 0.0721 ,\n",
       "            0.06903, 0.0601 , 0.0546 , 0.05145, 0.04428, 0.0241 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.26119402, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.09701493, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.12686567, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.13793103, 0.14655173, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.69827586, 0.70689654, 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.88793105, 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9165 , 0.9097 , 0.907  , 0.9062 , 0.906  , 0.9004 ,\n",
       "            0.894  , 0.89   , 0.8896 , 0.889  , 0.887  , 0.8857 , 0.8823 ,\n",
       "            0.8804 , 0.877  , 0.8755 , 0.87   , 0.8623 , 0.8516 , 0.8467 ,\n",
       "            0.846  , 0.8457 , 0.8447 , 0.8438 , 0.8403 , 0.837  , 0.8335 ,\n",
       "            0.833  , 0.8325 , 0.824  , 0.8223 , 0.822  , 0.821  , 0.817  ,\n",
       "            0.8164 , 0.815  , 0.814  , 0.812  , 0.811  , 0.81   , 0.8086 ,\n",
       "            0.8066 , 0.806  , 0.8057 , 0.8037 , 0.803  , 0.8022 , 0.7993 ,\n",
       "            0.799  , 0.7964 , 0.796  , 0.795  , 0.7935 , 0.788  , 0.786  ,\n",
       "            0.7856 , 0.7812 , 0.7734 , 0.7715 , 0.7686 , 0.7603 , 0.7593 ,\n",
       "            0.751  , 0.7466 , 0.745  , 0.7446 , 0.7427 , 0.7417 , 0.7393 ,\n",
       "            0.7334 , 0.7305 , 0.7275 , 0.7236 , 0.7227 , 0.714  , 0.7134 ,\n",
       "            0.712  , 0.71   , 0.7095 , 0.709  , 0.7065 , 0.699  , 0.6904 ,\n",
       "            0.688  , 0.678  , 0.672  , 0.67   , 0.6685 , 0.657  , 0.655  ,\n",
       "            0.6484 , 0.6426 , 0.642  , 0.6406 , 0.638  , 0.6357 , 0.63   ,\n",
       "            0.629  , 0.628  , 0.6274 , 0.616  , 0.614  , 0.6123 , 0.607  ,\n",
       "            0.606  , 0.6055 , 0.602  , 0.601  , 0.5786 , 0.5757 , 0.5684 ,\n",
       "            0.5635 , 0.5576 , 0.5547 , 0.5493 , 0.5483 , 0.5454 , 0.5444 ,\n",
       "            0.5396 , 0.5327 , 0.5303 , 0.526  , 0.5244 , 0.5215 , 0.52   ,\n",
       "            0.5083 , 0.508  , 0.5044 , 0.504  , 0.502  , 0.501  , 0.5005 ,\n",
       "            0.4983 , 0.496  , 0.4927 , 0.483  , 0.4788 , 0.4778 , 0.472  ,\n",
       "            0.471  , 0.466  , 0.4639 , 0.4614 , 0.458  , 0.454  , 0.4531 ,\n",
       "            0.452  , 0.4517 , 0.4504 , 0.4495 , 0.4475 , 0.4473 , 0.4463 ,\n",
       "            0.4446 , 0.444  , 0.4424 , 0.4385 , 0.436  , 0.4312 , 0.431  ,\n",
       "            0.4282 , 0.4263 , 0.4211 , 0.4204 , 0.4133 , 0.4124 , 0.4116 ,\n",
       "            0.4092 , 0.4062 , 0.4043 , 0.404  , 0.401  , 0.3926 , 0.3865 ,\n",
       "            0.3833 , 0.3752 , 0.371  , 0.3704 , 0.3694 , 0.3677 , 0.3647 ,\n",
       "            0.3635 , 0.358  , 0.356  , 0.3547 , 0.343  , 0.3345 , 0.3296 ,\n",
       "            0.3074 , 0.303  , 0.2935 , 0.2847 , 0.2832 , 0.2817 , 0.2815 ,\n",
       "            0.272  , 0.2507 , 0.2441 , 0.244  , 0.243  , 0.2185 , 0.212  ,\n",
       "            0.208  , 0.1924 , 0.1846 , 0.1676 , 0.162  , 0.1536 , 0.1517 ,\n",
       "            0.1497 , 0.1411 , 0.1274 , 0.127  , 0.12366, 0.12335, 0.11615,\n",
       "            0.10394, 0.09204, 0.0859 , 0.0857 , 0.0771 , 0.07684, 0.0753 ,\n",
       "            0.0667 , 0.06323, 0.0552 , 0.04977, 0.04672, 0.03995, 0.02116],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.29104477, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.07462686, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.4224138 , 0.43103448, 0.44827586, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5344828 ,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9243 , 0.9233 , 0.917  , 0.9146 , 0.913  , 0.909  ,\n",
       "            0.901  , 0.9    , 0.8975 , 0.897  , 0.896  , 0.8955 , 0.895  ,\n",
       "            0.894  , 0.891  , 0.889  , 0.8867 , 0.8823 , 0.8804 , 0.866  ,\n",
       "            0.8643 , 0.8623 , 0.858  , 0.8574 , 0.856  , 0.8545 , 0.854  ,\n",
       "            0.8535 , 0.853  , 0.851  , 0.843  , 0.8423 , 0.838  , 0.837  ,\n",
       "            0.8364 , 0.8354 , 0.834  , 0.832  , 0.8315 , 0.8296 , 0.828  ,\n",
       "            0.8276 , 0.8267 , 0.823  , 0.8223 , 0.821  , 0.8203 , 0.8184 ,\n",
       "            0.8174 , 0.8154 , 0.8145 , 0.814  , 0.8105 , 0.809  , 0.8086 ,\n",
       "            0.797  , 0.794  , 0.791  , 0.7847 , 0.784  , 0.7827 , 0.7744 ,\n",
       "            0.7695 , 0.769  , 0.7686 , 0.767  , 0.764  , 0.762  , 0.758  ,\n",
       "            0.7534 , 0.75   , 0.7476 , 0.743  , 0.738  , 0.7373 , 0.736  ,\n",
       "            0.7344 , 0.734  , 0.7314 , 0.73   , 0.7227 , 0.721  , 0.72   ,\n",
       "            0.713  , 0.7095 , 0.699  , 0.6914 , 0.6895 , 0.6816 , 0.6777 ,\n",
       "            0.6704 , 0.669  , 0.6626 , 0.6606 , 0.659  , 0.656  , 0.6504 ,\n",
       "            0.649  , 0.6484 , 0.648  , 0.6475 , 0.64   , 0.6294 , 0.627  ,\n",
       "            0.6245 , 0.6235 , 0.623  , 0.6216 , 0.621  , 0.6206 , 0.6104 ,\n",
       "            0.591  , 0.5835 , 0.581  , 0.5747 , 0.5703 , 0.5693 , 0.567  ,\n",
       "            0.566  , 0.565  , 0.564  , 0.563  , 0.5596 , 0.558  , 0.554  ,\n",
       "            0.543  , 0.535  , 0.5347 , 0.534  , 0.5244 , 0.524  , 0.5176 ,\n",
       "            0.516  , 0.5156 , 0.512  , 0.51   , 0.5093 , 0.5073 , 0.507  ,\n",
       "            0.504  , 0.5034 , 0.4985 , 0.4817 , 0.4807 , 0.4805 , 0.4783 ,\n",
       "            0.473  , 0.4714 , 0.4685 , 0.4614 , 0.4597 , 0.4585 , 0.4583 ,\n",
       "            0.458  , 0.4568 , 0.4563 , 0.4556 , 0.4517 , 0.4485 , 0.446  ,\n",
       "            0.4458 , 0.4456 , 0.4438 , 0.4429 , 0.4421 , 0.4363 , 0.4338 ,\n",
       "            0.4324 , 0.4233 , 0.423  , 0.4216 , 0.4192 , 0.4172 , 0.4155 ,\n",
       "            0.4124 , 0.409  , 0.407  , 0.4026 , 0.3914 , 0.3884 , 0.382  ,\n",
       "            0.3813 , 0.3772 , 0.3726 , 0.3677 , 0.3674 , 0.3647 , 0.3645 ,\n",
       "            0.3582 , 0.3564 , 0.356  , 0.3481 , 0.334  , 0.3298 , 0.311  ,\n",
       "            0.3013 , 0.2917 , 0.2837 , 0.282  , 0.2805 , 0.28   , 0.2734 ,\n",
       "            0.2471 , 0.2441 , 0.2411 , 0.2399 , 0.2156 , 0.2086 , 0.2045 ,\n",
       "            0.188  , 0.1803 , 0.1635 , 0.1572 , 0.1488 , 0.147  , 0.1442 ,\n",
       "            0.136  , 0.1222 , 0.122  , 0.11816, 0.11755, 0.11066, 0.0986 ,\n",
       "            0.0866 , 0.0806 , 0.0805 , 0.07306, 0.07196, 0.0703 , 0.0619 ,\n",
       "            0.05856, 0.05127, 0.04553, 0.04257, 0.03616, 0.01865],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.29850745, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.1119403 ,\n",
       "            0.11940298, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.48507464,\n",
       "            0.49253732, 0.5074627 , 0.51492536, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.934  , 0.9336 , 0.9272 , 0.9253 , 0.9233 , 0.92   ,\n",
       "            0.912  , 0.9116 , 0.909  , 0.9087 , 0.908  , 0.9077 , 0.9067 ,\n",
       "            0.9033 , 0.9023 , 0.9014 , 0.9004 , 0.8955 , 0.8936 , 0.8813 ,\n",
       "            0.8794 , 0.879  , 0.878  , 0.8735 , 0.8716 , 0.8706 , 0.8696 ,\n",
       "            0.868  , 0.8667 , 0.866  , 0.8584 , 0.857  , 0.8545 , 0.8535 ,\n",
       "            0.8525 , 0.8506 , 0.85   , 0.8467 , 0.846  , 0.8447 , 0.844  ,\n",
       "            0.8433 , 0.8384 , 0.838  , 0.8374 , 0.837  , 0.836  , 0.8354 ,\n",
       "            0.8345 , 0.834  , 0.8325 , 0.831  , 0.8296 , 0.8276 , 0.8257 ,\n",
       "            0.825  , 0.8247 , 0.8125 , 0.81   , 0.8086 , 0.8027 , 0.801  ,\n",
       "            0.8003 , 0.792  , 0.787  , 0.7866 , 0.786  , 0.785  , 0.782  ,\n",
       "            0.7803 , 0.775  , 0.7725 , 0.768  , 0.764  , 0.76   , 0.7544 ,\n",
       "            0.752  , 0.751  , 0.7485 , 0.7476 , 0.7407 , 0.7383 , 0.738  ,\n",
       "            0.7373 , 0.731  , 0.728  , 0.718  , 0.7095 , 0.708  , 0.6997 ,\n",
       "            0.6963 , 0.688  , 0.6855 , 0.6807 , 0.678  , 0.6763 , 0.6724 ,\n",
       "            0.667  , 0.666  , 0.6655 , 0.665  , 0.664  , 0.6562 , 0.645  ,\n",
       "            0.6445 , 0.6416 , 0.641  , 0.6406 , 0.6377 , 0.6367 , 0.6255 ,\n",
       "            0.6064 , 0.598  , 0.5957 , 0.59   , 0.5845 , 0.584  , 0.5835 ,\n",
       "            0.5806 , 0.5796 , 0.5786 , 0.575  , 0.5713 , 0.569  , 0.558  ,\n",
       "            0.549  , 0.548  , 0.547  , 0.5366 , 0.53   , 0.5293 , 0.5283 ,\n",
       "            0.5254 , 0.5244 , 0.5234 , 0.523  , 0.5205 , 0.5195 , 0.517  ,\n",
       "            0.515  , 0.5093 , 0.4937 , 0.4917 , 0.4915 , 0.489  , 0.4846 ,\n",
       "            0.4817 , 0.4783 , 0.4727 , 0.471  , 0.4702 , 0.469  , 0.4683 ,\n",
       "            0.468  , 0.4666 , 0.4626 , 0.4583 , 0.4553 , 0.455  , 0.4539 ,\n",
       "            0.4534 , 0.4517 , 0.4514 , 0.444  , 0.4424 , 0.4312 , 0.4302 ,\n",
       "            0.4265 , 0.425  , 0.4197 , 0.4155 , 0.415  , 0.4102 , 0.3987 ,\n",
       "            0.3938 , 0.388  , 0.3843 , 0.38   , 0.3792 , 0.373  , 0.3706 ,\n",
       "            0.3704 , 0.3691 , 0.3647 , 0.3623 , 0.358  , 0.3484 , 0.3386 ,\n",
       "            0.33   , 0.3098 , 0.3013 , 0.2917 , 0.2817 , 0.2815 , 0.28   ,\n",
       "            0.2786 , 0.2712 , 0.2463 , 0.2415 , 0.2413 , 0.2402 , 0.2114 ,\n",
       "            0.2045 , 0.2002 , 0.1866 , 0.1765 , 0.1583 , 0.1525 , 0.1438 ,\n",
       "            0.1418 , 0.141  , 0.1321 , 0.11633, 0.11615, 0.1126 , 0.1124 ,\n",
       "            0.1069 , 0.0945 , 0.08124, 0.07544, 0.0749 , 0.06793, 0.0677 ,\n",
       "            0.0649 , 0.0577 , 0.0537 , 0.0469 , 0.0417 , 0.0389 , 0.03278,\n",
       "            0.01646], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.30597016, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.07462686, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.4224138 , 0.43965518, 0.44827586, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.7413793 , 0.75      , 0.7586207 , 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.943  , 0.941  , 0.9346 , 0.933  , 0.9307 , 0.928  ,\n",
       "            0.921  , 0.9204 , 0.92   , 0.9194 , 0.9175 , 0.9165 , 0.916  ,\n",
       "            0.914  , 0.912  , 0.911  , 0.9097 , 0.9077 , 0.904  , 0.8945 ,\n",
       "            0.8926 , 0.892  , 0.8896 , 0.887  , 0.884  , 0.8823 , 0.882  ,\n",
       "            0.88   , 0.8784 , 0.878  , 0.8765 , 0.8726 , 0.8687 , 0.8677 ,\n",
       "            0.867  , 0.865  , 0.8623 , 0.861  , 0.8594 , 0.859  , 0.858  ,\n",
       "            0.8574 , 0.857  , 0.8564 , 0.8525 , 0.85   , 0.8496 , 0.849  ,\n",
       "            0.8477 , 0.847  , 0.8457 , 0.845  , 0.844  , 0.843  , 0.841  ,\n",
       "            0.8384 , 0.837  , 0.836  , 0.824  , 0.8228 , 0.8164 , 0.816  ,\n",
       "            0.8125 , 0.8076 , 0.803  , 0.8022 , 0.8003 , 0.798  , 0.7964 ,\n",
       "            0.7915 , 0.785  , 0.784  , 0.7783 , 0.772  , 0.7705 , 0.7676 ,\n",
       "            0.7656 , 0.7637 , 0.763  , 0.7573 , 0.75   , 0.7485 , 0.748  ,\n",
       "            0.747  , 0.7437 , 0.7334 , 0.725  , 0.723  , 0.712  , 0.711  ,\n",
       "            0.704  , 0.699  , 0.695  , 0.693  , 0.692  , 0.6855 , 0.6807 ,\n",
       "            0.6797 , 0.6777 , 0.676  , 0.6675 , 0.6606 , 0.658  , 0.6553 ,\n",
       "            0.654  , 0.6533 , 0.6523 , 0.6514 , 0.645  , 0.6357 , 0.6187 ,\n",
       "            0.6055 , 0.6035 , 0.6025 , 0.5938 , 0.5923 , 0.5913 , 0.591  ,\n",
       "            0.5903 , 0.59   , 0.589  , 0.5854 , 0.5815 , 0.5796 , 0.5664 ,\n",
       "            0.558  , 0.5576 , 0.5513 , 0.5425 , 0.542  , 0.54   , 0.5376 ,\n",
       "            0.536  , 0.534  , 0.5317 , 0.531  , 0.5303 , 0.5283 , 0.528  ,\n",
       "            0.525  , 0.5244 , 0.519  , 0.5005 , 0.496  , 0.495  , 0.4946 ,\n",
       "            0.491  , 0.4866 , 0.4846 , 0.478  , 0.4758 , 0.474  , 0.4739 ,\n",
       "            0.4724 , 0.472  , 0.4707 , 0.47   , 0.467  , 0.461  , 0.4587 ,\n",
       "            0.458  , 0.4578 , 0.4573 , 0.4531 , 0.4487 , 0.447  , 0.4458 ,\n",
       "            0.437  , 0.4333 , 0.4326 , 0.4321 , 0.4287 , 0.4265 , 0.4243 ,\n",
       "            0.418  , 0.4165 , 0.4128 , 0.399  , 0.3953 , 0.3875 , 0.386  ,\n",
       "            0.3806 , 0.3794 , 0.3716 , 0.3706 , 0.3699 , 0.369  , 0.363  ,\n",
       "            0.3608 , 0.3564 , 0.3481 , 0.3386 , 0.3274 , 0.3083 , 0.298  ,\n",
       "            0.2888 , 0.279  , 0.2764 , 0.2744 , 0.268  , 0.2429 , 0.2382 ,\n",
       "            0.2379 , 0.2368 , 0.2058 , 0.1987 , 0.1943 , 0.1823 , 0.171  ,\n",
       "            0.152  , 0.1461 , 0.1376 , 0.1357 , 0.1354 , 0.1262 , 0.1101 ,\n",
       "            0.1095 , 0.1069 , 0.1058 , 0.10144, 0.0891 , 0.07556, 0.06964,\n",
       "            0.06903, 0.0631 , 0.0627 , 0.05942, 0.0532 , 0.04886, 0.04272,\n",
       "            0.0377 , 0.035  , 0.02925, 0.01428], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.33582088, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.09701493, 0.1119403 ,\n",
       "            0.11940298, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.4224138 , 0.43965518, 0.44827586, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7758621 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9517 , 0.9497 , 0.944  , 0.9424 , 0.94   , 0.938  ,\n",
       "            0.931  , 0.9307 , 0.93   , 0.9277 , 0.9272 , 0.927  , 0.9263 ,\n",
       "            0.9253 , 0.924  , 0.923  , 0.921  , 0.9194 , 0.915  , 0.907  ,\n",
       "            0.9053 , 0.904  , 0.9    , 0.897  , 0.8955 , 0.895  , 0.893  ,\n",
       "            0.8926 , 0.8906 , 0.8896 , 0.886  , 0.883  , 0.882  , 0.881  ,\n",
       "            0.879  , 0.877  , 0.875  , 0.8735 , 0.873  , 0.872  , 0.8716 ,\n",
       "            0.871  , 0.8706 , 0.8667 , 0.8647 , 0.8643 , 0.864  , 0.8623 ,\n",
       "            0.862  , 0.861  , 0.8604 , 0.86   , 0.858  , 0.856  , 0.854  ,\n",
       "            0.852  , 0.851  , 0.84   , 0.8394 , 0.8384 , 0.8335 , 0.8325 ,\n",
       "            0.832  , 0.8286 , 0.8237 , 0.8203 , 0.8193 , 0.819  , 0.817  ,\n",
       "            0.814  , 0.813  , 0.809  , 0.804  , 0.801  , 0.795  , 0.789  ,\n",
       "            0.787  , 0.785  , 0.7847 , 0.782  , 0.7803 , 0.776  , 0.7676 ,\n",
       "            0.765  , 0.7646 , 0.764  , 0.7607 , 0.75   , 0.742  , 0.74   ,\n",
       "            0.7305 , 0.728  , 0.7227 , 0.717  , 0.712  , 0.71   , 0.7095 ,\n",
       "            0.703  , 0.699  , 0.6978 , 0.697  , 0.6943 , 0.693  , 0.684  ,\n",
       "            0.6777 , 0.6743 , 0.67   , 0.6694 , 0.669  , 0.6685 , 0.66   ,\n",
       "            0.652  , 0.6367 , 0.6196 , 0.6187 , 0.618  , 0.6104 , 0.607  ,\n",
       "            0.6055 , 0.605  , 0.6035 , 0.6    , 0.5957 , 0.5947 , 0.58   ,\n",
       "            0.573  , 0.5723 , 0.564  , 0.555  , 0.5547 , 0.5537 , 0.5503 ,\n",
       "            0.55   , 0.5474 , 0.545  , 0.5435 , 0.543  , 0.5425 , 0.541  ,\n",
       "            0.537  , 0.5366 , 0.5327 , 0.531  , 0.512  , 0.5073 , 0.506  ,\n",
       "            0.505  , 0.5024 , 0.4968 , 0.4963 , 0.4888 , 0.486  , 0.4844 ,\n",
       "            0.4827 , 0.4824 , 0.4805 , 0.4802 , 0.4773 , 0.4705 , 0.469  ,\n",
       "            0.4675 , 0.4673 , 0.4663 , 0.4622 , 0.459  , 0.456  , 0.455  ,\n",
       "            0.4473 , 0.4424 , 0.441  , 0.4407 , 0.4373 , 0.4343 , 0.434  ,\n",
       "            0.4263 , 0.4243 , 0.4226 , 0.4058 , 0.4028 , 0.3936 , 0.3904 ,\n",
       "            0.3853 , 0.385  , 0.377  , 0.3762 , 0.3743 , 0.3738 , 0.368  ,\n",
       "            0.3657 , 0.3591 , 0.3508 , 0.345  , 0.329  , 0.309  , 0.2993 ,\n",
       "            0.2903 , 0.2812 , 0.2788 , 0.277  , 0.2742 , 0.2678 , 0.2438 ,\n",
       "            0.2397 , 0.2386 , 0.2372 , 0.2037 , 0.1958 , 0.1913 , 0.1823 ,\n",
       "            0.1687 , 0.1481 , 0.1422 , 0.1337 , 0.1333 , 0.1317 , 0.12335,\n",
       "            0.1056 , 0.10486, 0.1036 , 0.1011 , 0.09845, 0.086  , 0.07135,\n",
       "            0.0655 , 0.06464, 0.05997, 0.05856, 0.05542, 0.05023, 0.045  ,\n",
       "            0.03943, 0.03476, 0.03217, 0.02666, 0.01267], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3880597, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.07462686, 0.08208955, 0.08955224, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.95689654, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9595 , 0.957  , 0.9517 , 0.95   , 0.9487 , 0.9463 ,\n",
       "            0.9414 , 0.941  , 0.94   , 0.9375 , 0.937  , 0.9365 , 0.936  ,\n",
       "            0.933  , 0.9326 , 0.931  , 0.93   , 0.926  , 0.92   , 0.9185 ,\n",
       "            0.917  , 0.9146 , 0.913  , 0.9106 , 0.9077 , 0.907  , 0.9053 ,\n",
       "            0.9043 , 0.904  , 0.9023 , 0.901  , 0.8965 , 0.8955 , 0.895  ,\n",
       "            0.894  , 0.893  , 0.8896 , 0.8887 , 0.886  , 0.8857 , 0.885  ,\n",
       "            0.8843 , 0.883  , 0.881  , 0.88   , 0.8794 , 0.8784 , 0.878  ,\n",
       "            0.877  , 0.8765 , 0.875  , 0.874  , 0.8735 , 0.8716 , 0.871  ,\n",
       "            0.868  , 0.867  , 0.866  , 0.857  , 0.8555 , 0.854  , 0.8496 ,\n",
       "            0.848  , 0.847  , 0.8447 , 0.8413 , 0.8374 , 0.8364 , 0.836  ,\n",
       "            0.8354 , 0.833  , 0.83   , 0.8257 , 0.8193 , 0.8184 , 0.8115 ,\n",
       "            0.807  , 0.8066 , 0.804  , 0.8022 , 0.8013 , 0.799  , 0.7974 ,\n",
       "            0.794  , 0.786  , 0.7847 , 0.783  , 0.781  , 0.7705 , 0.762  ,\n",
       "            0.761  , 0.749  , 0.7446 , 0.74   , 0.735  , 0.7334 , 0.7314 ,\n",
       "            0.728  , 0.7217 , 0.7183 , 0.7173 , 0.7163 , 0.715  , 0.7124 ,\n",
       "            0.704  , 0.695  , 0.693  , 0.692  , 0.691  , 0.6885 , 0.682  ,\n",
       "            0.6724 , 0.6514 , 0.6416 , 0.6396 , 0.6367 , 0.628  , 0.627  ,\n",
       "            0.6265 , 0.626  , 0.6255 , 0.6226 , 0.622  , 0.6147 , 0.6123 ,\n",
       "            0.604  , 0.5913 , 0.588  , 0.586  , 0.576  , 0.5757 , 0.572  ,\n",
       "            0.569  , 0.5674 , 0.567  , 0.5645 , 0.564  , 0.563  , 0.5615 ,\n",
       "            0.557  , 0.554  , 0.552  , 0.5454 , 0.5312 , 0.527  , 0.526  ,\n",
       "            0.5215 , 0.521  , 0.5137 , 0.5073 , 0.506  , 0.505  , 0.5034 ,\n",
       "            0.5024 , 0.5    , 0.4998 , 0.4988 , 0.4963 , 0.489  , 0.4856 ,\n",
       "            0.4854 , 0.481  , 0.4773 , 0.4753 , 0.4736 , 0.4727 , 0.467  ,\n",
       "            0.4578 , 0.457  , 0.4563 , 0.4546 , 0.4536 , 0.4512 , 0.4424 ,\n",
       "            0.44   , 0.4321 , 0.429  , 0.4219 , 0.4094 , 0.4075 , 0.401  ,\n",
       "            0.394  , 0.3916 , 0.3892 , 0.3884 , 0.3838 , 0.381  , 0.38   ,\n",
       "            0.376  , 0.3604 , 0.3525 , 0.3484 , 0.3293 , 0.3096 , 0.299  ,\n",
       "            0.2903 , 0.2815 , 0.278  , 0.2761 , 0.2727 , 0.2668 , 0.2428 ,\n",
       "            0.2391 , 0.2379 , 0.2355 , 0.201  , 0.1921 , 0.1876 , 0.1799 ,\n",
       "            0.1653 , 0.1433 , 0.138  , 0.1296 , 0.1292 , 0.1267 , 0.1193 ,\n",
       "            0.1009 , 0.0998 , 0.0993 , 0.096  , 0.09467, 0.0823 , 0.0672 ,\n",
       "            0.0612 , 0.0603 , 0.05646, 0.0548 , 0.05176, 0.0469 , 0.04138,\n",
       "            0.0363 , 0.03186, 0.02937, 0.02414, 0.0112 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.43283582, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06896552, 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.12068965, 0.12931034, 0.13793103, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.3448276 , 0.35344827, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.47413793, 0.4827586 , 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.80172414, 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9663 , 0.963  , 0.9585 , 0.9575 , 0.9556 , 0.9536 ,\n",
       "            0.9507 , 0.9478 , 0.946  , 0.9453 , 0.945  , 0.9443 , 0.9414 ,\n",
       "            0.941  , 0.9395 , 0.9346 , 0.932  , 0.9307 , 0.9287 , 0.926  ,\n",
       "            0.924  , 0.9233 , 0.9204 , 0.918  , 0.916  , 0.915  , 0.9146 ,\n",
       "            0.914  , 0.913  , 0.91   , 0.9097 , 0.909  , 0.907  , 0.9053 ,\n",
       "            0.903  , 0.9014 , 0.9004 , 0.898  , 0.8975 , 0.8965 , 0.8955 ,\n",
       "            0.895  , 0.894  , 0.8936 , 0.8906 , 0.89   , 0.889  , 0.8887 ,\n",
       "            0.887  , 0.8867 , 0.886  , 0.8833 , 0.8804 , 0.88   , 0.8794 ,\n",
       "            0.8735 , 0.869  , 0.8677 , 0.866  , 0.8643 , 0.86   , 0.859  ,\n",
       "            0.858  , 0.8545 , 0.854  , 0.8525 , 0.8506 , 0.8477 , 0.8433 ,\n",
       "            0.8374 , 0.8306 , 0.8267 , 0.8257 , 0.8237 , 0.8223 , 0.8213 ,\n",
       "            0.818  , 0.817  , 0.816  , 0.814  , 0.8125 , 0.8022 , 0.8003 ,\n",
       "            0.7905 , 0.782  , 0.781  , 0.7695 , 0.7603 , 0.758  , 0.7544 ,\n",
       "            0.752  , 0.747  , 0.7393 , 0.739  , 0.7373 , 0.736  , 0.732  ,\n",
       "            0.73   , 0.7217 , 0.715  , 0.714  , 0.7134 , 0.7114 , 0.7085 ,\n",
       "            0.708  , 0.707  , 0.699  , 0.6895 , 0.6665 , 0.658  , 0.6567 ,\n",
       "            0.6553 , 0.647  , 0.6465 , 0.645  , 0.6445 , 0.6436 , 0.6426 ,\n",
       "            0.642  , 0.6396 , 0.6387 , 0.6343 , 0.629  , 0.6255 , 0.608  ,\n",
       "            0.6035 , 0.602  , 0.592  , 0.5913 , 0.5854 , 0.585  , 0.5835 ,\n",
       "            0.583  , 0.5806 , 0.5786 , 0.576  , 0.5728 , 0.567  , 0.564  ,\n",
       "            0.5605 , 0.5493 , 0.5415 , 0.5405 , 0.538  , 0.537  , 0.528  ,\n",
       "            0.5244 , 0.5234 , 0.523  , 0.521  , 0.52   , 0.5166 , 0.516  ,\n",
       "            0.5137 , 0.513  , 0.5127 , 0.5024 , 0.5015 , 0.499  , 0.4985 ,\n",
       "            0.494  , 0.492  , 0.4885 , 0.487  , 0.483  , 0.4756 , 0.4705 ,\n",
       "            0.4702 , 0.47   , 0.4697 , 0.4673 , 0.462  , 0.4539 , 0.4524 ,\n",
       "            0.4375 , 0.4338 , 0.4329 , 0.42   , 0.414  , 0.4119 , 0.4026 ,\n",
       "            0.4    , 0.399  , 0.3962 , 0.394  , 0.3933 , 0.383  , 0.3787 ,\n",
       "            0.3623 , 0.3564 , 0.3503 , 0.33   , 0.3115 , 0.2983 , 0.29   ,\n",
       "            0.281  , 0.2788 , 0.2747 , 0.2712 , 0.267  , 0.2411 , 0.2374 ,\n",
       "            0.2362 , 0.2347 , 0.199  , 0.1885 , 0.1838 , 0.1757 , 0.1616 ,\n",
       "            0.1392 , 0.1334 , 0.1249 , 0.1241 , 0.12146, 0.11475, 0.09656,\n",
       "            0.09467, 0.09106, 0.0901 , 0.07794, 0.0631 , 0.05698, 0.05603,\n",
       "            0.0526 , 0.05136, 0.04803, 0.04352, 0.03812, 0.03333, 0.02887,\n",
       "            0.02655, 0.02165, 0.00978], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.4552239, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.05970149, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20895523,\n",
       "            0.21641791, 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.11206897, 0.12931034, 0.13793103,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.45689654, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.94827586, 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.972  , 0.9688 , 0.965  , 0.964  , 0.962  , 0.9604 ,\n",
       "            0.958  , 0.9575 , 0.9556 , 0.9546 , 0.9536 , 0.9526 , 0.952  ,\n",
       "            0.9497 , 0.949  , 0.9478 , 0.944  , 0.9404 , 0.9395 , 0.938  ,\n",
       "            0.935  , 0.934  , 0.9326 , 0.9307 , 0.928  , 0.926  , 0.9253 ,\n",
       "            0.9243 , 0.923  , 0.921  , 0.9204 , 0.92   , 0.918  , 0.916  ,\n",
       "            0.914  , 0.9136 , 0.9126 , 0.912  , 0.9116 , 0.9087 , 0.908  ,\n",
       "            0.9077 , 0.9067 , 0.906  , 0.9043 , 0.9023 , 0.901  , 0.8994 ,\n",
       "            0.899  , 0.8984 , 0.8955 , 0.8936 , 0.8926 , 0.891  , 0.8857 ,\n",
       "            0.882  , 0.881  , 0.8794 , 0.878  , 0.8735 , 0.8726 , 0.872  ,\n",
       "            0.868  , 0.8677 , 0.866  , 0.864  , 0.8623 , 0.858  , 0.8516 ,\n",
       "            0.8477 , 0.842  , 0.84   , 0.8374 , 0.837  , 0.8345 , 0.8335 ,\n",
       "            0.8315 , 0.8306 , 0.829  , 0.828  , 0.818  , 0.817  , 0.8154 ,\n",
       "            0.815  , 0.814  , 0.8057 , 0.798  , 0.796  , 0.7847 , 0.777  ,\n",
       "            0.7754 , 0.769  , 0.7666 , 0.764  , 0.7563 , 0.7544 , 0.7534 ,\n",
       "            0.7524 , 0.747  , 0.7456 , 0.737  , 0.73   , 0.728  , 0.7275 ,\n",
       "            0.725  , 0.7246 , 0.7236 , 0.7124 , 0.704  , 0.682  , 0.672  ,\n",
       "            0.671  , 0.6694 , 0.66   , 0.6597 , 0.659  , 0.658  , 0.6562 ,\n",
       "            0.6553 , 0.654  , 0.6533 , 0.6484 , 0.644  , 0.635  , 0.622  ,\n",
       "            0.618  , 0.612  , 0.6025 , 0.602  , 0.598  , 0.5977 , 0.5947 ,\n",
       "            0.594  , 0.5913 , 0.5894 , 0.587  , 0.5825 , 0.5806 , 0.576  ,\n",
       "            0.574  , 0.559  , 0.551  , 0.5493 , 0.548  , 0.5464 , 0.5376 ,\n",
       "            0.533  , 0.531  , 0.5293 , 0.529  , 0.5273 , 0.5264 , 0.526  ,\n",
       "            0.5205 , 0.51   , 0.5093 , 0.5063 , 0.505  , 0.5005 , 0.4973 ,\n",
       "            0.4958 , 0.4954 , 0.4905 , 0.4846 , 0.4778 , 0.4768 , 0.4753 ,\n",
       "            0.4731 , 0.4707 , 0.4617 , 0.4595 , 0.4458 , 0.4446 , 0.437  ,\n",
       "            0.423  , 0.419  , 0.416  , 0.4048 , 0.4006 , 0.3987 , 0.3965 ,\n",
       "            0.3938 , 0.3894 , 0.381  , 0.3645 , 0.3596 , 0.358  , 0.3313 ,\n",
       "            0.3132 , 0.2993 , 0.2913 , 0.2834 , 0.2795 , 0.2764 , 0.2708 ,\n",
       "            0.2673 , 0.2422 , 0.2397 , 0.2388 , 0.2343 , 0.1974 , 0.1858 ,\n",
       "            0.1819 , 0.1759 , 0.1593 , 0.1359 , 0.1301 , 0.1236 , 0.12024,\n",
       "            0.11755, 0.1124 , 0.09283, 0.09204, 0.09076, 0.088  , 0.0871 ,\n",
       "            0.07574, 0.05988, 0.0537 , 0.0526 , 0.05023, 0.0485 , 0.0452 ,\n",
       "            0.04123, 0.03555, 0.03102, 0.02676, 0.02457, 0.01979, 0.00874],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.48507464, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.1119403 , 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.11206897, 0.12931034, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.41379312, 0.43103448, 0.43965518,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.7586207 , 0.76724136, 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9766 , 0.9736 , 0.9697 , 0.969  , 0.9673 , 0.9663 ,\n",
       "            0.9644 , 0.962  , 0.9604 , 0.96   , 0.959  , 0.9585 , 0.9565 ,\n",
       "            0.956  , 0.954  , 0.951  , 0.9487 , 0.9473 , 0.9463 , 0.944  ,\n",
       "            0.9434 , 0.9414 , 0.94   , 0.9365 , 0.935  , 0.9346 , 0.9336 ,\n",
       "            0.9326 , 0.9316 , 0.9307 , 0.93   , 0.9297 , 0.928  , 0.9253 ,\n",
       "            0.924  , 0.923  , 0.9224 , 0.921  , 0.9194 , 0.9185 , 0.918  ,\n",
       "            0.9175 , 0.917  , 0.9155 , 0.9126 , 0.912  , 0.911  , 0.9106 ,\n",
       "            0.91   , 0.9097 , 0.9087 , 0.906  , 0.9043 , 0.9033 , 0.902  ,\n",
       "            0.898  , 0.893  , 0.8926 , 0.8916 , 0.89   , 0.8877 , 0.885  ,\n",
       "            0.8843 , 0.8813 , 0.88   , 0.8794 , 0.877  , 0.875  , 0.8726 ,\n",
       "            0.8657 , 0.8633 , 0.8555 , 0.854  , 0.852  , 0.8506 , 0.8486 ,\n",
       "            0.847  , 0.844  , 0.843  , 0.833  , 0.831  , 0.83   , 0.8286 ,\n",
       "            0.8276 , 0.821  , 0.813  , 0.8115 , 0.8003 , 0.794  , 0.7935 ,\n",
       "            0.785  , 0.7847 , 0.783  , 0.78   , 0.772  , 0.7705 , 0.77   ,\n",
       "            0.7695 , 0.762  , 0.761  , 0.752  , 0.7476 , 0.7456 , 0.744  ,\n",
       "            0.7437 , 0.7417 , 0.741  , 0.7407 , 0.7266 , 0.719  , 0.7007 ,\n",
       "            0.6875 , 0.685  , 0.6836 , 0.6772 , 0.6763 , 0.675  , 0.6724 ,\n",
       "            0.671  , 0.669  , 0.667  , 0.664  , 0.6587 , 0.6504 , 0.637  ,\n",
       "            0.636  , 0.6245 , 0.6167 , 0.616  , 0.615  , 0.6143 , 0.612  ,\n",
       "            0.6094 , 0.6084 , 0.606  , 0.6025 , 0.601  , 0.5986 , 0.5957 ,\n",
       "            0.5903 , 0.5884 , 0.5723 , 0.563  , 0.561  , 0.559  , 0.55   ,\n",
       "            0.546  , 0.5435 , 0.542  , 0.541  , 0.54   , 0.5396 , 0.538  ,\n",
       "            0.5327 , 0.532  , 0.5312 , 0.521  , 0.5205 , 0.517  , 0.515  ,\n",
       "            0.5103 , 0.509  , 0.5083 , 0.5063 , 0.501  , 0.497  , 0.4902 ,\n",
       "            0.487  , 0.4866 , 0.4856 , 0.4832 , 0.4814 , 0.474  , 0.4692 ,\n",
       "            0.4573 , 0.457  , 0.445  , 0.4304 , 0.4292 , 0.4238 , 0.4124 ,\n",
       "            0.4114 , 0.4072 , 0.406  , 0.4036 , 0.4006 , 0.3984 , 0.3872 ,\n",
       "            0.3699 , 0.3674 , 0.3657 , 0.3354 , 0.317  , 0.303  , 0.2952 ,\n",
       "            0.288  , 0.2817 , 0.2805 , 0.2727 , 0.2693 , 0.2452 , 0.244  ,\n",
       "            0.243  , 0.2356 , 0.1978 , 0.185  , 0.1816 , 0.1771 , 0.1587 ,\n",
       "            0.1339 , 0.1279 , 0.12305, 0.11755, 0.11475, 0.11084, 0.0901 ,\n",
       "            0.0877 , 0.0866 , 0.08417, 0.074  , 0.05728, 0.051  , 0.05005,\n",
       "            0.04822, 0.04602, 0.04282, 0.03934, 0.0334 , 0.02898, 0.02493,\n",
       "            0.02284, 0.01823, 0.00784], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.51492536, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.05970149, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.2238806 , 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.28448275,\n",
       "            0.29310346, 0.31034482, 0.31896552, 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.46551725, 0.47413793, 0.4827586 , 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.981  , 0.9775 , 0.9746 , 0.9736 , 0.9717 , 0.971  ,\n",
       "            0.9707 , 0.9673 , 0.967  , 0.9663 , 0.965  , 0.9644 , 0.9634 ,\n",
       "            0.963  , 0.9624 , 0.9604 , 0.9575 , 0.957  , 0.956  , 0.9546 ,\n",
       "            0.9526 , 0.951  , 0.9507 , 0.9487 , 0.945  , 0.944  , 0.9434 ,\n",
       "            0.9424 , 0.941  , 0.9404 , 0.94   , 0.9385 , 0.935  , 0.934  ,\n",
       "            0.933  , 0.9316 , 0.9307 , 0.93   , 0.929  , 0.9287 , 0.928  ,\n",
       "            0.9277 , 0.9272 , 0.9263 , 0.924  , 0.9224 , 0.922  , 0.921  ,\n",
       "            0.9204 , 0.92   , 0.9185 , 0.916  , 0.9146 , 0.914  , 0.9126 ,\n",
       "            0.911  , 0.9053 , 0.904  , 0.9033 , 0.8994 , 0.899  , 0.896  ,\n",
       "            0.8955 , 0.895  , 0.8945 , 0.893  , 0.8916 , 0.889  , 0.886  ,\n",
       "            0.881  , 0.8774 , 0.87   , 0.868  , 0.8657 , 0.864  , 0.862  ,\n",
       "            0.861  , 0.8584 , 0.8574 , 0.8564 , 0.8496 , 0.8477 , 0.845  ,\n",
       "            0.843  , 0.8413 , 0.8384 , 0.831  , 0.8296 , 0.819  , 0.811  ,\n",
       "            0.809  , 0.8037 , 0.802  , 0.801  , 0.798  , 0.7896 , 0.7886 ,\n",
       "            0.788  , 0.787  , 0.7783 , 0.778  , 0.7686 , 0.7646 , 0.7637 ,\n",
       "            0.762  , 0.7603 , 0.7583 , 0.743  , 0.7363 , 0.7163 , 0.7056 ,\n",
       "            0.7017 , 0.7    , 0.6963 , 0.6953 , 0.6943 , 0.691  , 0.69   ,\n",
       "            0.6895 , 0.6875 , 0.6855 , 0.6836 , 0.683  , 0.6753 , 0.6714 ,\n",
       "            0.6543 , 0.6523 , 0.6406 , 0.636  , 0.6323 , 0.6313 , 0.631  ,\n",
       "            0.6284 , 0.628  , 0.625  , 0.62   , 0.6187 , 0.615  , 0.6113 ,\n",
       "            0.6064 , 0.6035 , 0.591  , 0.5786 , 0.578  , 0.576  , 0.5757 ,\n",
       "            0.5654 , 0.563  , 0.561  , 0.5605 , 0.559  , 0.5576 , 0.5547 ,\n",
       "            0.5527 , 0.5503 , 0.5464 , 0.546  , 0.5376 , 0.535  , 0.5312 ,\n",
       "            0.529  , 0.5254 , 0.524  , 0.523  , 0.52   , 0.511  , 0.508  ,\n",
       "            0.502  , 0.5015 , 0.5    , 0.4998 , 0.4927 , 0.486  , 0.4836 ,\n",
       "            0.4685 , 0.4663 , 0.457  , 0.4417 , 0.4375 , 0.437  , 0.4229 ,\n",
       "            0.4197 , 0.4172 , 0.4163 , 0.4133 , 0.4128 , 0.4058 , 0.3918 ,\n",
       "            0.3755 , 0.374  , 0.3716 , 0.3381 , 0.3206 , 0.3057 , 0.2976 ,\n",
       "            0.2913 , 0.2834 , 0.2827 , 0.2737 , 0.2703 , 0.247  , 0.246  ,\n",
       "            0.2367 , 0.1974 , 0.1833 , 0.181  , 0.1774 , 0.1572 , 0.1312 ,\n",
       "            0.1245 , 0.1217 , 0.1142 , 0.11145, 0.10895, 0.0876 , 0.0871 ,\n",
       "            0.0848 , 0.08435, 0.0808 , 0.07184, 0.0545 , 0.04822, 0.04742,\n",
       "            0.04602, 0.04352, 0.04037, 0.03732, 0.0312 , 0.02701, 0.0231 ,\n",
       "            0.02109, 0.01672, 0.00701], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5522388, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.36567163, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.06896552, 0.09482758, 0.11206897, 0.12931034,\n",
       "            0.13793103, 0.15517241, 0.1637931 , 0.1724138 , 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.28448275,\n",
       "            0.29310346, 0.31034482, 0.31896552, 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.38793105, 0.39655173,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.47413793, 0.4827586 , 0.49137932, 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.95689654, 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.985  , 0.982  , 0.9795 , 0.9785 , 0.9775 , 0.9766 ,\n",
       "            0.9727 , 0.971  , 0.9707 , 0.97   , 0.9688 , 0.968  , 0.9653 ,\n",
       "            0.9644 , 0.9624 , 0.961  , 0.9595 , 0.9585 , 0.9575 , 0.954  ,\n",
       "            0.9536 , 0.952  , 0.9517 , 0.9507 , 0.95   , 0.9497 , 0.9487 ,\n",
       "            0.946  , 0.945  , 0.9434 , 0.9424 , 0.9414 , 0.941  , 0.94   ,\n",
       "            0.9395 , 0.939  , 0.938  , 0.9375 , 0.9355 , 0.934  , 0.9336 ,\n",
       "            0.933  , 0.9326 , 0.9316 , 0.931  , 0.9287 , 0.9263 , 0.926  ,\n",
       "            0.9243 , 0.9194 , 0.918  , 0.917  , 0.913  , 0.911  , 0.9106 ,\n",
       "            0.91   , 0.9097 , 0.9087 , 0.9077 , 0.904  , 0.902  , 0.897  ,\n",
       "            0.8926 , 0.8877 , 0.886  , 0.8853 , 0.8833 , 0.8813 , 0.8794 ,\n",
       "            0.877  , 0.8765 , 0.875  , 0.8745 , 0.868  , 0.8667 , 0.8647 ,\n",
       "            0.8633 , 0.863  , 0.8584 , 0.851  , 0.8506 , 0.8403 , 0.8315 ,\n",
       "            0.8276 , 0.827  , 0.825  , 0.821  , 0.8174 , 0.8125 , 0.8105 ,\n",
       "            0.809  , 0.8086 , 0.8027 , 0.801  , 0.793  , 0.792  , 0.7905 ,\n",
       "            0.787  , 0.783  , 0.7827 , 0.779  , 0.7715 , 0.7627 , 0.738  ,\n",
       "            0.732  , 0.73   , 0.7285 , 0.7246 , 0.72   , 0.7183 , 0.7173 ,\n",
       "            0.717  , 0.716  , 0.7134 , 0.7104 , 0.7085 , 0.706  , 0.6973 ,\n",
       "            0.6807 , 0.6753 , 0.674  , 0.6685 , 0.6636 , 0.663  , 0.66   ,\n",
       "            0.659  , 0.6567 , 0.656  , 0.655  , 0.6504 , 0.65   , 0.643  ,\n",
       "            0.637  , 0.6367 , 0.63   , 0.6206 , 0.6094 , 0.6084 , 0.6035 ,\n",
       "            0.595  , 0.5938 , 0.5933 , 0.5903 , 0.584  , 0.582  , 0.5786 ,\n",
       "            0.5776 , 0.5723 , 0.568  , 0.5664 , 0.5625 , 0.562  , 0.559  ,\n",
       "            0.5566 , 0.553  , 0.5386 , 0.534  , 0.5327 , 0.5317 , 0.5303 ,\n",
       "            0.5293 , 0.5264 , 0.5205 , 0.513  , 0.511  , 0.505  , 0.487  ,\n",
       "            0.4868 , 0.4834 , 0.4717 , 0.4678 , 0.4536 , 0.4514 , 0.4475 ,\n",
       "            0.447  , 0.4436 , 0.4353 , 0.4285 , 0.4204 , 0.404  , 0.3904 ,\n",
       "            0.3855 , 0.3853 , 0.3481 , 0.3315 , 0.3154 , 0.307  , 0.3008 ,\n",
       "            0.2925 , 0.2908 , 0.2808 , 0.2778 , 0.2551 , 0.2546 , 0.2544 ,\n",
       "            0.2434 , 0.2023 , 0.1871 , 0.185  , 0.1815 , 0.1599 , 0.1326 ,\n",
       "            0.12476, 0.12366, 0.11395, 0.11127, 0.1095 , 0.0876 , 0.0869 ,\n",
       "            0.0851 , 0.08344, 0.0798 , 0.0717 , 0.0536 , 0.0469 , 0.04648,\n",
       "            0.04526, 0.04282, 0.03934, 0.0365 , 0.03021, 0.02606, 0.02211,\n",
       "            0.02014, 0.01584, 0.00651], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5597015, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.18656716, 0.19402985,\n",
       "            0.20895523, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.58208954, 0.5895522 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.09482758,\n",
       "            0.10344828, 0.12068965, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25862068, 0.2672414 , 0.28448275, 0.31034482, 0.31896552,\n",
       "            0.33620688, 0.35344827, 0.36206895, 0.37068966, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.47413793, 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9883  , 0.985   , 0.9824  , 0.982   , 0.9814  ,\n",
       "            0.9805  , 0.98    , 0.9775  , 0.9766  , 0.9756  , 0.975   ,\n",
       "            0.9746  , 0.973   , 0.9727  , 0.972   , 0.9717  , 0.971   ,\n",
       "            0.969   , 0.9688  , 0.9683  , 0.967   , 0.9644  , 0.963   ,\n",
       "            0.9624  , 0.959   , 0.9585  , 0.958   , 0.957   , 0.956   ,\n",
       "            0.955   , 0.952   , 0.951   , 0.9507  , 0.9497  , 0.9487  ,\n",
       "            0.948   , 0.9478  , 0.946   , 0.9453  , 0.945   , 0.9434  ,\n",
       "            0.9414  , 0.9404  , 0.9395  , 0.939   , 0.938   , 0.9365  ,\n",
       "            0.936   , 0.934   , 0.9336  , 0.931   , 0.928   , 0.927   ,\n",
       "            0.926   , 0.9253  , 0.9243  , 0.9233  , 0.9214  , 0.921   ,\n",
       "            0.9204  , 0.9194  , 0.918   , 0.9165  , 0.914   , 0.911   ,\n",
       "            0.903   , 0.902   , 0.9014  , 0.899   , 0.8945  , 0.8936  ,\n",
       "            0.8926  , 0.8896  , 0.888   , 0.8867  , 0.884   , 0.8833  ,\n",
       "            0.877   , 0.876   , 0.8755  , 0.868   , 0.859   , 0.848   ,\n",
       "            0.8467  , 0.8447  , 0.8354  , 0.835   , 0.832   , 0.83    ,\n",
       "            0.8247  , 0.824   , 0.8184  , 0.8164  , 0.8145  , 0.8125  ,\n",
       "            0.809   , 0.804   , 0.803   , 0.8027  , 0.7964  , 0.7915  ,\n",
       "            0.788   , 0.78    , 0.75    , 0.7495  , 0.748   , 0.7476  ,\n",
       "            0.7437  , 0.7363  , 0.735   , 0.734   , 0.7334  , 0.7324  ,\n",
       "            0.7314  , 0.727   , 0.716   , 0.6997  , 0.693   , 0.689   ,\n",
       "            0.683   , 0.682   , 0.68    , 0.6797  , 0.676   , 0.674   ,\n",
       "            0.6724  , 0.6685  , 0.662   , 0.656   , 0.6465  , 0.6445  ,\n",
       "            0.644   , 0.6313  , 0.6284  , 0.6274  , 0.625   , 0.6206  ,\n",
       "            0.618   , 0.616   , 0.615   , 0.6143  , 0.6133  , 0.606   ,\n",
       "            0.597   , 0.5967  , 0.5903  , 0.585   , 0.584   , 0.5825  ,\n",
       "            0.581   , 0.5806  , 0.5757  , 0.575   , 0.5596  , 0.5557  ,\n",
       "            0.552   , 0.55    , 0.5483  , 0.543   , 0.5366  , 0.5337  ,\n",
       "            0.5327  , 0.5225  , 0.516   , 0.5044  , 0.491   , 0.489   ,\n",
       "            0.4885  , 0.469   , 0.4644  , 0.464   , 0.458   , 0.4456  ,\n",
       "            0.439   , 0.424   , 0.4084  , 0.3943  , 0.392   , 0.3892  ,\n",
       "            0.3508  , 0.337   , 0.3164  , 0.308   , 0.301   , 0.2947  ,\n",
       "            0.2925  , 0.2812  , 0.281   , 0.2537  , 0.2534  , 0.2527  ,\n",
       "            0.2456  , 0.2023  , 0.1864  , 0.1844  , 0.1775  , 0.1573  ,\n",
       "            0.1301  , 0.12103 , 0.1194  , 0.1103  , 0.1076  , 0.1056  ,\n",
       "            0.08435 , 0.08386 , 0.08124 , 0.0801  , 0.0764  , 0.0682  ,\n",
       "            0.05118 , 0.0441  , 0.04257 , 0.04108 , 0.0372  , 0.0341  ,\n",
       "            0.02834 , 0.02443 , 0.02025 , 0.01837 , 0.01445 , 0.005753],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5895522, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23880596, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5074627 ,\n",
       "            0.51492536, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.04310345, 0.05172414,\n",
       "            0.06034483, 0.06896552, 0.0775862 , 0.0862069 , 0.10344828,\n",
       "            0.12068965, 0.13793103, 0.14655173, 0.15517241, 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.31034482,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.38793105, 0.39655173, 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.44827586, 0.45689654, 0.47413793, 0.49137932,\n",
       "            0.5086207 , 0.5258621 , 0.5344828 , 0.55172414, 0.5689655 ,\n",
       "            0.57758623, 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9907 , 0.9873 , 0.9854 , 0.985  , 0.984  , 0.983  ,\n",
       "            0.982  , 0.9805 , 0.98   , 0.979  , 0.9785 , 0.9775 , 0.977  ,\n",
       "            0.9766 , 0.976  , 0.9746 , 0.974  , 0.9736 , 0.973  , 0.971  ,\n",
       "            0.9697 , 0.968  , 0.9663 , 0.966  , 0.9653 , 0.965  , 0.9644 ,\n",
       "            0.9634 , 0.963  , 0.9624 , 0.962  , 0.9604 , 0.9595 , 0.959  ,\n",
       "            0.958  , 0.9575 , 0.957  , 0.9546 , 0.9536 , 0.9526 , 0.952  ,\n",
       "            0.951  , 0.9487 , 0.9478 , 0.947  , 0.946  , 0.9443 , 0.942  ,\n",
       "            0.9414 , 0.9385 , 0.936  , 0.9355 , 0.9346 , 0.934  , 0.933  ,\n",
       "            0.932  , 0.9287 , 0.928  , 0.9277 , 0.927  , 0.9233 , 0.916  ,\n",
       "            0.9155 , 0.915  , 0.909  , 0.9087 , 0.9053 , 0.9043 , 0.903  ,\n",
       "            0.9    , 0.8994 , 0.8984 , 0.898  , 0.8975 , 0.8906 , 0.889  ,\n",
       "            0.888  , 0.884  , 0.8755 , 0.8657 , 0.864  , 0.8623 , 0.851  ,\n",
       "            0.849  , 0.847  , 0.844  , 0.8394 , 0.834  , 0.832  , 0.825  ,\n",
       "            0.8247 , 0.8213 , 0.8203 , 0.814  , 0.8086 , 0.805  , 0.797  ,\n",
       "            0.77   , 0.769  , 0.768  , 0.7666 , 0.766  , 0.765  , 0.7563 ,\n",
       "            0.756  , 0.755  , 0.754  , 0.7534 , 0.753  , 0.7524 , 0.745  ,\n",
       "            0.7344 , 0.7188 , 0.716  , 0.712  , 0.7085 , 0.7056 , 0.705  ,\n",
       "            0.7026 , 0.7017 , 0.701  , 0.696  , 0.695  , 0.688  , 0.6816 ,\n",
       "            0.6753 , 0.668  , 0.666  , 0.6606 , 0.653  , 0.6484 , 0.647  ,\n",
       "            0.645  , 0.6445 , 0.6406 , 0.638  , 0.6377 , 0.6367 , 0.633  ,\n",
       "            0.6284 , 0.627  , 0.617  , 0.616  , 0.612  , 0.607  , 0.6045 ,\n",
       "            0.6006 , 0.6    , 0.5967 , 0.5947 , 0.583  , 0.5767 , 0.5723 ,\n",
       "            0.5674 , 0.561  , 0.554  , 0.5513 , 0.5396 , 0.534  , 0.5225 ,\n",
       "            0.5093 , 0.507  , 0.504  , 0.5024 , 0.489  , 0.4866 , 0.4844 ,\n",
       "            0.4822 , 0.471  , 0.4607 , 0.454  , 0.4353 , 0.419  , 0.4077 ,\n",
       "            0.4016 , 0.3987 , 0.3586 , 0.3467 , 0.3235 , 0.3147 , 0.3074 ,\n",
       "            0.3025 , 0.2986 , 0.2886 , 0.2866 , 0.2578 , 0.2573 , 0.2566 ,\n",
       "            0.251  , 0.2056 , 0.1887 , 0.1869 , 0.1776 , 0.158  , 0.13   ,\n",
       "            0.1196 , 0.118  , 0.10895, 0.1058 , 0.1043 , 0.0831 , 0.0821 ,\n",
       "            0.07935, 0.07794, 0.07434, 0.06635, 0.0495 , 0.0424 , 0.04208,\n",
       "            0.04077, 0.0398 , 0.0356 , 0.0324 , 0.02692, 0.0231 , 0.01888,\n",
       "            0.01704, 0.01333, 0.00514], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.619403, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.03448276, 0.05172414,\n",
       "            0.06034483, 0.06896552, 0.0775862 , 0.09482758, 0.10344828,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.43103448, 0.43965518, 0.45689654, 0.46551725, 0.4827586 ,\n",
       "            0.5       , 0.5086207 , 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5689655 , 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9927  , 0.99    , 0.989   , 0.9883  , 0.9873  ,\n",
       "            0.987   , 0.9854  , 0.985   , 0.984   , 0.9834  , 0.983   ,\n",
       "            0.9824  , 0.982   , 0.9814  , 0.9795  , 0.979   , 0.9785  ,\n",
       "            0.977   , 0.976   , 0.974   , 0.9727  , 0.972   , 0.9717  ,\n",
       "            0.971   , 0.9707  , 0.97    , 0.9697  , 0.9683  , 0.9673  ,\n",
       "            0.9663  , 0.9653  , 0.9644  , 0.9634  , 0.9624  , 0.962   ,\n",
       "            0.9614  , 0.96    , 0.9585  , 0.958   , 0.9575  , 0.9565  ,\n",
       "            0.9556  , 0.955   , 0.9526  , 0.952   , 0.951   , 0.9478  ,\n",
       "            0.9473  , 0.947   , 0.9453  , 0.945   , 0.9443  , 0.944   ,\n",
       "            0.9434  , 0.941   , 0.9395  , 0.939   , 0.936   , 0.93    ,\n",
       "            0.929   , 0.924   , 0.923   , 0.9194  , 0.919   , 0.917   ,\n",
       "            0.916   , 0.9146  , 0.914   , 0.913   , 0.9126  , 0.9077  ,\n",
       "            0.907   , 0.9067  , 0.901   , 0.9004  , 0.8936  , 0.884   ,\n",
       "            0.8823  , 0.8696  , 0.869   , 0.868   , 0.867   , 0.8643  ,\n",
       "            0.8594  , 0.859   , 0.858   , 0.8564  , 0.855   , 0.8496  ,\n",
       "            0.8457  , 0.843   , 0.8413  , 0.8364  , 0.835   , 0.8306  ,\n",
       "            0.8237  , 0.8003  , 0.7993  , 0.798   , 0.7974  , 0.7944  ,\n",
       "            0.793   , 0.791   , 0.789   , 0.788   , 0.7866  , 0.786   ,\n",
       "            0.781   , 0.7803  , 0.7783  , 0.771   , 0.759   , 0.75    ,\n",
       "            0.7495  , 0.7485  , 0.7393  , 0.7383  , 0.738   , 0.7363  ,\n",
       "            0.736   , 0.7354  , 0.7324  , 0.7285  , 0.7266  , 0.724   ,\n",
       "            0.7207  , 0.7183  , 0.7144  , 0.6997  , 0.6934  , 0.6885  ,\n",
       "            0.6865  , 0.6855  , 0.6846  , 0.6787  , 0.678   , 0.6763  ,\n",
       "            0.6733  , 0.673   , 0.6665  , 0.666   , 0.6606  , 0.657   ,\n",
       "            0.654   , 0.6475  , 0.647   , 0.6436  , 0.6406  , 0.639   ,\n",
       "            0.6357  , 0.6333  , 0.6265  , 0.6255  , 0.615   , 0.61    ,\n",
       "            0.606   , 0.593   , 0.592   , 0.585   , 0.58    , 0.576   ,\n",
       "            0.563   , 0.562   , 0.559   , 0.5493  , 0.547   , 0.5312  ,\n",
       "            0.529   , 0.527   , 0.5254  , 0.5234  , 0.4944  , 0.4814  ,\n",
       "            0.4744  , 0.4573  , 0.4375  , 0.426   , 0.4226  , 0.4163  ,\n",
       "            0.3743  , 0.3613  , 0.3389  , 0.3296  , 0.3225  , 0.3147  ,\n",
       "            0.313   , 0.3003  , 0.2996  , 0.27    , 0.2698  , 0.269   ,\n",
       "            0.261   , 0.213   , 0.1953  , 0.1931  , 0.1844  , 0.1626  ,\n",
       "            0.1327  , 0.1213  , 0.11066 , 0.1067  , 0.1063  , 0.08374 ,\n",
       "            0.0831  , 0.0806  , 0.0778  , 0.0741  , 0.06696 , 0.04895 ,\n",
       "            0.04178 , 0.04147 , 0.04047 , 0.03934 , 0.03488 , 0.03192 ,\n",
       "            0.02611 , 0.02232 , 0.01816 , 0.01628 , 0.01267 , 0.004738],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6268657, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.36567163, 0.38059703,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.06034483, 0.06896552, 0.0775862 , 0.0862069 , 0.09482758,\n",
       "            0.12931034, 0.14655173, 0.15517241, 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.23275863,\n",
       "            0.2413793 , 0.25862068, 0.2672414 , 0.29310346, 0.31034482,\n",
       "            0.3275862 , 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43965518, 0.44827586, 0.4827586 , 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.80172414, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.994   , 0.9927  , 0.9917  , 0.991   , 0.9907  ,\n",
       "            0.9897  , 0.989   , 0.9883  , 0.988   , 0.9873  , 0.987   ,\n",
       "            0.9863  , 0.986   , 0.9854  , 0.9844  , 0.984   , 0.9834  ,\n",
       "            0.983   , 0.982   , 0.979   , 0.978   , 0.9775  , 0.977   ,\n",
       "            0.9766  , 0.976   , 0.9756  , 0.9746  , 0.974   , 0.9736  ,\n",
       "            0.9727  , 0.972   , 0.971   , 0.9707  , 0.97    , 0.9697  ,\n",
       "            0.9688  , 0.9673  , 0.967   , 0.966   , 0.965   , 0.9644  ,\n",
       "            0.964   , 0.963   , 0.9624  , 0.961   , 0.9604  , 0.9595  ,\n",
       "            0.9575  , 0.957   , 0.9565  , 0.9556  , 0.955   , 0.954   ,\n",
       "            0.9526  , 0.952   , 0.949   , 0.9487  , 0.948   , 0.9453  ,\n",
       "            0.944   , 0.943   , 0.9355  , 0.934   , 0.9336  , 0.9326  ,\n",
       "            0.931   , 0.93    , 0.929   , 0.928   , 0.927   , 0.9263  ,\n",
       "            0.9243  , 0.924   , 0.9233  , 0.919   , 0.9175  , 0.913   ,\n",
       "            0.9043  , 0.904   , 0.9     , 0.8906  , 0.8877  , 0.886   ,\n",
       "            0.8857  , 0.8853  , 0.883   , 0.882   , 0.8774  , 0.8735  ,\n",
       "            0.8657  , 0.865   , 0.8643  , 0.863   , 0.8564  , 0.8516  ,\n",
       "            0.8506  , 0.8345  , 0.8325  , 0.8315  , 0.831   , 0.8296  ,\n",
       "            0.8276  , 0.826   , 0.8203  , 0.82    , 0.8154  , 0.8125  ,\n",
       "            0.811   , 0.8037  , 0.8003  , 0.796   , 0.7925  , 0.7896  ,\n",
       "            0.7847  , 0.78    , 0.7793  , 0.779   , 0.777   , 0.776   ,\n",
       "            0.773   , 0.7686  , 0.7676  , 0.764   , 0.761   , 0.7603  ,\n",
       "            0.76    , 0.7583  , 0.743   , 0.7407  , 0.735   , 0.73    ,\n",
       "            0.728   , 0.7275  , 0.7256  , 0.7246  , 0.7197  , 0.7173  ,\n",
       "            0.716   , 0.713   , 0.705   , 0.702   , 0.699   , 0.698   ,\n",
       "            0.6924  , 0.69    , 0.6895  , 0.6855  , 0.6846  , 0.682   ,\n",
       "            0.68    , 0.6655  , 0.6562  , 0.6523  , 0.6514  , 0.64    ,\n",
       "            0.618   , 0.6113  , 0.605   , 0.6045  , 0.5986  , 0.598   ,\n",
       "            0.59    , 0.5835  , 0.5825  , 0.5796  , 0.5776  , 0.552   ,\n",
       "            0.5493  , 0.5156  , 0.4988  , 0.4915  , 0.4773  , 0.4548  ,\n",
       "            0.4414  , 0.4407  , 0.432   , 0.3877  , 0.3716  , 0.3523  ,\n",
       "            0.3423  , 0.3354  , 0.3254  , 0.3228  , 0.3103  , 0.3079  ,\n",
       "            0.2803  , 0.2798  , 0.2795  , 0.268   , 0.2186  , 0.2001  ,\n",
       "            0.1978  , 0.1891  , 0.1658  , 0.1335  , 0.12274 , 0.1216  ,\n",
       "            0.11066 , 0.1067  , 0.10614 , 0.0827  , 0.0805  , 0.0764  ,\n",
       "            0.07263 , 0.06635 , 0.04742 , 0.04025 , 0.0401  , 0.03934 ,\n",
       "            0.0377  , 0.0334  , 0.03079 , 0.02475 , 0.02101 , 0.01718 ,\n",
       "            0.01525 , 0.01178 , 0.004265], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6492537, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.06034483, 0.06896552, 0.0775862 , 0.0862069 , 0.11206897,\n",
       "            0.13793103, 0.15517241, 0.1724138 , 0.18965517, 0.19827586,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25862068,\n",
       "            0.28448275, 0.3275862 , 0.33620688, 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.38793105, 0.41379312, 0.4224138 , 0.43965518,\n",
       "            0.45689654, 0.47413793, 0.5       , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.8103448 , 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9956  , 0.9946  , 0.994   , 0.9937  , 0.993   ,\n",
       "            0.992   , 0.9917  , 0.991   , 0.9907  , 0.99    , 0.9897  ,\n",
       "            0.9893  , 0.9883  , 0.988   , 0.987   , 0.9863  , 0.9854  ,\n",
       "            0.9834  , 0.983   , 0.9824  , 0.982   , 0.9814  , 0.981   ,\n",
       "            0.9805  , 0.9795  , 0.978   , 0.977   , 0.976   , 0.975   ,\n",
       "            0.9746  , 0.9736  , 0.9727  , 0.972   , 0.9717  , 0.9707  ,\n",
       "            0.9697  , 0.969   , 0.9683  , 0.967   , 0.9663  , 0.9653  ,\n",
       "            0.965   , 0.9634  , 0.962   , 0.9614  , 0.961   , 0.959   ,\n",
       "            0.9585  , 0.958   , 0.9575  , 0.956   , 0.955   , 0.9478  ,\n",
       "            0.9473  , 0.947   , 0.9443  , 0.944   , 0.9434  , 0.9424  ,\n",
       "            0.94    , 0.9395  , 0.9385  , 0.935   , 0.9326  , 0.93    ,\n",
       "            0.924   , 0.923   , 0.914   , 0.911   , 0.9106  , 0.907   ,\n",
       "            0.9067  , 0.9043  , 0.904   , 0.9023  , 0.9014  , 0.8984  ,\n",
       "            0.8975  , 0.897   , 0.8955  , 0.895   , 0.886   , 0.8833  ,\n",
       "            0.882   , 0.8784  , 0.8755  , 0.8706  , 0.8696  , 0.868   ,\n",
       "            0.8643  , 0.8604  , 0.859   , 0.8545  , 0.853   , 0.841   ,\n",
       "            0.8384  , 0.8354  , 0.8345  , 0.8286  , 0.8257  , 0.8223  ,\n",
       "            0.8213  , 0.8184  , 0.818   , 0.815   , 0.812   , 0.809   ,\n",
       "            0.806   , 0.8057  , 0.8047  , 0.804   , 0.8027  , 0.7974  ,\n",
       "            0.7856  , 0.785   , 0.7817  , 0.778   , 0.774   , 0.773   ,\n",
       "            0.7725  , 0.7686  , 0.7666  , 0.766   , 0.7603  , 0.7593  ,\n",
       "            0.758   , 0.757   , 0.752   , 0.747   , 0.746   , 0.744   ,\n",
       "            0.7437  , 0.741   , 0.7407  , 0.74    , 0.7383  , 0.7363  ,\n",
       "            0.728   , 0.7173  , 0.706   , 0.7046  , 0.693   , 0.6797  ,\n",
       "            0.669   , 0.6636  , 0.658   , 0.6543  , 0.6465  , 0.646   ,\n",
       "            0.6426  , 0.641   , 0.6333  , 0.631   , 0.625   , 0.61    ,\n",
       "            0.6094  , 0.583   , 0.5786  , 0.5444  , 0.523   , 0.5156  ,\n",
       "            0.505   , 0.4795  , 0.4705  , 0.4636  , 0.4539  , 0.408   ,\n",
       "            0.3906  , 0.3728  , 0.362   , 0.3564  , 0.3457  , 0.3396  ,\n",
       "            0.3281  , 0.3235  , 0.3     , 0.2993  , 0.2974  , 0.2827  ,\n",
       "            0.2307  , 0.2109  , 0.2085  , 0.2021  , 0.1746  , 0.1392  ,\n",
       "            0.1305  , 0.1266  , 0.115   , 0.112   , 0.1101  , 0.0862  ,\n",
       "            0.0854  , 0.0848  , 0.07825 , 0.07434 , 0.0693  , 0.0483  ,\n",
       "            0.04092 , 0.04068 , 0.04037 , 0.0384  , 0.03384 , 0.03143 ,\n",
       "            0.02493 , 0.02109 , 0.01724 , 0.015305, 0.01169 , 0.00415 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6641791, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05223881, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08208955, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.31343284, 0.32089552, 0.3283582 , 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.03448276, 0.05172414,\n",
       "            0.06034483, 0.0775862 , 0.0862069 , 0.11206897, 0.13793103,\n",
       "            0.1724138 , 0.18965517, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.29310346, 0.31896552, 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.4051724 , 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.45689654, 0.5       , 0.5086207 ,\n",
       "            0.5344828 , 0.54310346, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.80172414, 0.8103448 , 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9966  , 0.996   , 0.9956  , 0.995   , 0.9946  ,\n",
       "            0.994   , 0.9937  , 0.993   , 0.9927  , 0.992   , 0.991   ,\n",
       "            0.9907  , 0.9897  , 0.9893  , 0.989   , 0.987   , 0.9863  ,\n",
       "            0.986   , 0.985   , 0.9844  , 0.9834  , 0.983   , 0.9824  ,\n",
       "            0.982   , 0.9814  , 0.981   , 0.98    , 0.979   , 0.9785  ,\n",
       "            0.978   , 0.9775  , 0.9756  , 0.975   , 0.9746  , 0.973   ,\n",
       "            0.9727  , 0.972   , 0.971   , 0.9707  , 0.9697  , 0.969   ,\n",
       "            0.9683  , 0.9673  , 0.967   , 0.966   , 0.9653  , 0.9604  ,\n",
       "            0.959   , 0.9585  , 0.9575  , 0.9565  , 0.9556  , 0.955   ,\n",
       "            0.9546  , 0.9526  , 0.952   , 0.95    , 0.949   , 0.947   ,\n",
       "            0.946   , 0.941   , 0.9404  , 0.9336  , 0.9297  , 0.9287  ,\n",
       "            0.928   , 0.926   , 0.9243  , 0.923   , 0.9194  , 0.919   ,\n",
       "            0.918   , 0.9155  , 0.914   , 0.912   , 0.906   , 0.9053  ,\n",
       "            0.905   , 0.9014  , 0.9004  , 0.897   , 0.895   , 0.8945  ,\n",
       "            0.89    , 0.8887  , 0.886   , 0.8784  , 0.87    , 0.8677  ,\n",
       "            0.864   , 0.8613  , 0.86    , 0.8574  , 0.8555  , 0.8545  ,\n",
       "            0.8516  , 0.8496  , 0.849   , 0.8477  , 0.8467  , 0.846   ,\n",
       "            0.8457  , 0.845   , 0.8413  , 0.8374  , 0.835   , 0.8335  ,\n",
       "            0.8276  , 0.8247  , 0.823   , 0.8223  , 0.815   , 0.813   ,\n",
       "            0.812   , 0.811   , 0.8086  , 0.8057  , 0.8027  , 0.8013  ,\n",
       "            0.7993  , 0.797   , 0.796   , 0.7954  , 0.791   , 0.7905  ,\n",
       "            0.79    , 0.7886  , 0.7803  , 0.775   , 0.771   , 0.762   ,\n",
       "            0.7617  , 0.7524  , 0.7354  , 0.732   , 0.728   , 0.7275  ,\n",
       "            0.7197  , 0.716   , 0.7144  , 0.714   , 0.68    , 0.6675  ,\n",
       "            0.6655  , 0.6587  , 0.644   , 0.6196  , 0.6147  , 0.5806  ,\n",
       "            0.558   , 0.551   , 0.5405  , 0.513   , 0.5063  , 0.498   ,\n",
       "            0.4863  , 0.4377  , 0.4216  , 0.4026  , 0.3916  , 0.3855  ,\n",
       "            0.3745  , 0.3674  , 0.3552  , 0.35    , 0.327   , 0.3262  ,\n",
       "            0.3232  , 0.3066  , 0.251   , 0.2294  , 0.2266  , 0.2203  ,\n",
       "            0.1893  , 0.1505  , 0.1423  , 0.1364  , 0.1238  , 0.1213  ,\n",
       "            0.1184  , 0.09283 , 0.09204 , 0.09186 , 0.08344 , 0.07904 ,\n",
       "            0.0749  , 0.05154 , 0.04346 , 0.0432  , 0.04312 , 0.04132 ,\n",
       "            0.03583 , 0.03333 , 0.02626 , 0.0222  , 0.01805 , 0.01596 ,\n",
       "            0.0121  , 0.004215], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6791045, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.07462686, 0.08208955,\n",
       "            0.08208955, 0.08955224, 0.08955224, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.25373134, 0.26119402,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.3283582 , 0.33582088, 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.05172414, 0.06896552,\n",
       "            0.10344828, 0.12068965, 0.1637931 , 0.1724138 , 0.19827586,\n",
       "            0.20689656, 0.22413793, 0.23275863, 0.2672414 , 0.31896552,\n",
       "            0.3275862 , 0.36206895, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.47413793, 0.5       ,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.5862069 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.6465517 , 0.6551724 , 0.67241377, 0.6896552 , 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.7586207 , 0.76724136,\n",
       "            0.79310346, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8534483 , 0.87068963, 0.87068963, 0.87931037, 0.87931037,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.997  , 0.9966 , 0.996  , 0.9956 , 0.9946 , 0.994  ,\n",
       "            0.9937 , 0.993  , 0.9927 , 0.992  , 0.9907 , 0.99   , 0.9893 ,\n",
       "            0.989  , 0.9883 , 0.988  , 0.9863 , 0.986  , 0.9854 , 0.985  ,\n",
       "            0.984  , 0.9834 , 0.9824 , 0.982  , 0.9814 , 0.981  , 0.9805 ,\n",
       "            0.9795 , 0.979  , 0.9785 , 0.9775 , 0.976  , 0.9756 , 0.9746 ,\n",
       "            0.974  , 0.973  , 0.9727 , 0.9707 , 0.9697 , 0.968  , 0.965  ,\n",
       "            0.9634 , 0.9624 , 0.962  , 0.96   , 0.957  , 0.956  , 0.955  ,\n",
       "            0.9546 , 0.954  , 0.9507 , 0.9473 , 0.943  , 0.94   , 0.9385 ,\n",
       "            0.935  , 0.934  , 0.9326 , 0.9307 , 0.928  , 0.927  , 0.9263 ,\n",
       "            0.925  , 0.9233 , 0.9224 , 0.921  , 0.918  , 0.9165 , 0.9146 ,\n",
       "            0.9116 , 0.91   , 0.9097 , 0.909  , 0.9077 , 0.9067 , 0.9043 ,\n",
       "            0.9004 , 0.893  , 0.8926 , 0.888  , 0.8877 , 0.884  , 0.881  ,\n",
       "            0.878  , 0.8774 , 0.874  , 0.873  , 0.871  , 0.8706 , 0.867  ,\n",
       "            0.8657 , 0.865  , 0.8623 , 0.8604 , 0.8594 , 0.8584 , 0.857  ,\n",
       "            0.856  , 0.854  , 0.851  , 0.849  , 0.8486 , 0.8467 , 0.843  ,\n",
       "            0.842  , 0.8384 , 0.8374 , 0.836  , 0.835  , 0.832  , 0.83   ,\n",
       "            0.828  , 0.8237 , 0.8228 , 0.818  , 0.8164 , 0.8105 , 0.8047 ,\n",
       "            0.8037 , 0.798  , 0.7896 , 0.7876 , 0.787  , 0.7847 , 0.7837 ,\n",
       "            0.783  , 0.7764 , 0.776  , 0.774  , 0.7344 , 0.7    , 0.6875 ,\n",
       "            0.685  , 0.678  , 0.6646 , 0.6636 , 0.638  , 0.635  , 0.6006 ,\n",
       "            0.5786 , 0.571  , 0.5605 , 0.534  , 0.525  , 0.5176 , 0.507  ,\n",
       "            0.4573 , 0.4402 , 0.4211 , 0.4097 , 0.403  , 0.392  , 0.3845 ,\n",
       "            0.3726 , 0.3667 , 0.3416 , 0.341  , 0.3386 , 0.3215 , 0.2637 ,\n",
       "            0.2413 , 0.2383 , 0.2302 , 0.199  , 0.1583 , 0.1487 , 0.143  ,\n",
       "            0.1298 , 0.1268 , 0.1241 , 0.09705, 0.0964 , 0.0959 , 0.0871 ,\n",
       "            0.0825 , 0.07806, 0.0537 , 0.0452 , 0.04492, 0.04477, 0.0432 ,\n",
       "            0.0372 , 0.03455, 0.02722, 0.02307, 0.01859, 0.01646, 0.01243,\n",
       "            0.0043 ], dtype=float16)}}]],\n",
       " 'roc_results': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.00333333, 0.00333333, 0.00333333, 0.00666667,\n",
       "         0.01      , 0.01333333, 0.01333333, 0.01333333, 0.01666667,\n",
       "         0.02      , 0.02666667, 0.03333334, 0.04      , 0.05      ,\n",
       "         0.06      , 0.06333333, 0.08      , 0.08666667, 0.09666666,\n",
       "         0.09666666, 0.1       , 0.11333334, 0.12333333, 0.13333334,\n",
       "         0.13666667, 0.15      , 0.17333333, 0.18333334, 0.20333333,\n",
       "         0.22666667, 0.23      , 0.24666667, 0.25666666, 0.27666667,\n",
       "         0.3       , 0.31666666, 0.32666665, 0.34      , 0.35666665,\n",
       "         0.36333334, 0.36666667, 0.37333333, 0.37666667, 0.38      ,\n",
       "         0.38      , 0.38333333, 0.38333333, 0.38666666, 0.39      ,\n",
       "         0.39666668, 0.39666668, 0.40333334, 0.40666667, 0.40666667,\n",
       "         0.40666667, 0.40666667, 0.40666667, 0.41333333, 0.41666666,\n",
       "         0.42      , 0.43      , 0.43333334, 0.43333334, 0.43333334,\n",
       "         0.43333334, 0.43333334, 0.43666667, 0.44      , 0.44333333,\n",
       "         0.44333333, 0.44666666, 0.45666668, 0.45666668, 0.46      ,\n",
       "         0.46333334, 0.46333334, 0.46333334, 0.46333334, 0.47      ,\n",
       "         0.47333333, 0.47333333, 0.47333333, 0.47666666, 0.48      ,\n",
       "         0.48333332, 0.48333332, 0.48666668, 0.48666668, 0.48666668,\n",
       "         0.48666668, 0.49      , 0.5       , 0.5       , 0.5       ,\n",
       "         0.50666666, 0.50666666, 0.50666666, 0.50666666, 0.50666666,\n",
       "         0.5133333 , 0.5133333 , 0.52      , 0.5233333 , 0.53      ,\n",
       "         0.53333336, 0.54      , 0.54333335, 0.55333334, 0.55333334,\n",
       "         0.5566667 , 0.56      , 0.57      , 0.58      , 0.59      ,\n",
       "         0.5933333 , 0.5933333 , 0.61      , 0.61333334, 0.61333334,\n",
       "         0.6166667 , 0.62666667, 0.62666667, 0.63666666, 0.64666665,\n",
       "         0.6533333 , 0.66      , 0.6666667 , 0.6766667 , 0.68333334,\n",
       "         0.68333334, 0.68666667, 0.6933333 , 0.69666666, 0.69666666,\n",
       "         0.7       , 0.7033333 , 0.71      , 0.71666664, 0.72333336,\n",
       "         0.7266667 , 0.73333335, 0.7366667 , 0.7366667 , 0.74333334,\n",
       "         0.74666667, 0.75      , 0.75666666, 0.76      , 0.7633333 ,\n",
       "         0.76666665, 0.76666665, 0.7733333 , 0.78      , 0.78333336,\n",
       "         0.79      , 0.79333335, 0.79333335, 0.8       , 0.8066667 ,\n",
       "         0.81333333, 0.81666666, 0.82666665, 0.83      , 0.84      ,\n",
       "         0.8466667 , 0.85      , 0.8566667 , 0.86333334, 0.8666667 ,\n",
       "         0.8666667 , 0.87      , 0.87333333, 0.88      , 0.88666666,\n",
       "         0.89      , 0.89      , 0.8933333 , 0.89666665, 0.9       ,\n",
       "         0.9033333 , 0.9066667 , 0.9066667 , 0.9066667 , 0.9066667 ,\n",
       "         0.9066667 , 0.9066667 , 0.91      , 0.91      , 0.91333336,\n",
       "         0.9166667 , 0.92      , 0.92333335, 0.9266667 , 0.93      ,\n",
       "         0.93      , 0.93333334, 0.93333334, 0.93666667, 0.94      ,\n",
       "         0.9433333 , 0.94666666, 0.94666666, 0.94666666, 0.95      ,\n",
       "         0.95      , 0.95      , 0.9533333 , 0.9533333 , 0.9533333 ,\n",
       "         0.95666665, 0.96      , 0.96      , 0.96      , 0.96666664,\n",
       "         0.96666664, 0.96666664, 0.97      , 0.97      , 0.97333336,\n",
       "         0.97333336, 0.97333336, 0.97333336, 0.97333336, 0.9766667 ,\n",
       "         0.98      , 0.98      , 0.98      , 0.98333335, 0.9866667 ,\n",
       "         0.9866667 , 0.9866667 , 0.99      , 0.99      , 0.99      ,\n",
       "         0.99      , 0.99      , 0.99      , 0.99      , 0.99      ,\n",
       "         0.99      , 0.99      , 0.99      , 0.99      , 0.99      ,\n",
       "         0.99      , 0.99      , 0.99      , 0.99      , 0.99      ,\n",
       "         0.99      , 0.99      , 0.99333334, 0.99333334, 0.99333334,\n",
       "         0.99666667, 0.99666667, 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "        dtype=float32),\n",
       "  'tpr': array([0.        , 0.00333333, 0.00666667, 0.01333333, 0.02      ,\n",
       "         0.02333333, 0.03666667, 0.04      , 0.04666667, 0.05      ,\n",
       "         0.05333333, 0.07      , 0.08666667, 0.09      , 0.1       ,\n",
       "         0.10333333, 0.11333334, 0.11666667, 0.12333333, 0.12666667,\n",
       "         0.14      , 0.14666666, 0.15333334, 0.16333333, 0.17      ,\n",
       "         0.17      , 0.17666666, 0.18      , 0.18      , 0.18      ,\n",
       "         0.18666667, 0.18666667, 0.19      , 0.19666667, 0.2       ,\n",
       "         0.20333333, 0.21333334, 0.21333334, 0.21666667, 0.21666667,\n",
       "         0.22666667, 0.23333333, 0.24      , 0.25      , 0.26      ,\n",
       "         0.27666667, 0.28333333, 0.28333333, 0.29      , 0.3       ,\n",
       "         0.3       , 0.30666667, 0.31      , 0.31      , 0.31      ,\n",
       "         0.31333333, 0.31333333, 0.32      , 0.32333332, 0.32333332,\n",
       "         0.32333332, 0.33333334, 0.33666667, 0.34666666, 0.35      ,\n",
       "         0.35333332, 0.35666665, 0.36      , 0.36333334, 0.37333333,\n",
       "         0.38      , 0.38      , 0.38333333, 0.39      , 0.39333335,\n",
       "         0.39666668, 0.4       , 0.40333334, 0.40333334, 0.40333334,\n",
       "         0.40666667, 0.40666667, 0.41      , 0.41666666, 0.42      ,\n",
       "         0.42      , 0.42666668, 0.43      , 0.43333334, 0.43666667,\n",
       "         0.43666667, 0.44      , 0.44666666, 0.45333335, 0.45333335,\n",
       "         0.46      , 0.46333334, 0.46666667, 0.47      , 0.47333333,\n",
       "         0.47666666, 0.48      , 0.48333332, 0.49      , 0.49333334,\n",
       "         0.49666667, 0.50333333, 0.50666666, 0.51      , 0.51666665,\n",
       "         0.51666665, 0.52      , 0.52      , 0.52      , 0.52      ,\n",
       "         0.52      , 0.5233333 , 0.53      , 0.5366667 , 0.54      ,\n",
       "         0.54333335, 0.5466667 , 0.5466667 , 0.5466667 , 0.5466667 ,\n",
       "         0.5466667 , 0.55      , 0.55      , 0.55      , 0.55333334,\n",
       "         0.56666666, 0.57      , 0.57666665, 0.57666665, 0.58      ,\n",
       "         0.58      , 0.5833333 , 0.59      , 0.59      , 0.5933333 ,\n",
       "         0.5966667 , 0.5966667 , 0.5966667 , 0.5966667 , 0.60333335,\n",
       "         0.60333335, 0.60333335, 0.61      , 0.61      , 0.61      ,\n",
       "         0.61      , 0.61      , 0.61333334, 0.62      , 0.62      ,\n",
       "         0.62      , 0.62      , 0.62      , 0.62      , 0.62      ,\n",
       "         0.62      , 0.62333333, 0.6333333 , 0.6333333 , 0.6333333 ,\n",
       "         0.6333333 , 0.6333333 , 0.63666666, 0.64      , 0.64      ,\n",
       "         0.64      , 0.6433333 , 0.65      , 0.65      , 0.6533333 ,\n",
       "         0.6566667 , 0.6566667 , 0.6566667 , 0.6566667 , 0.6566667 ,\n",
       "         0.66333336, 0.6666667 , 0.67      , 0.67      , 0.67      ,\n",
       "         0.67      , 0.67333335, 0.67333335, 0.68      , 0.68      ,\n",
       "         0.68      , 0.68      , 0.68333334, 0.68666667, 0.69      ,\n",
       "         0.6933333 , 0.69666666, 0.69666666, 0.7       , 0.7       ,\n",
       "         0.7       , 0.7       , 0.7       , 0.7       , 0.7       ,\n",
       "         0.71      , 0.7133333 , 0.72      , 0.72333336, 0.72333336,\n",
       "         0.7266667 , 0.7266667 , 0.73      , 0.73333335, 0.73333335,\n",
       "         0.7366667 , 0.74666667, 0.74666667, 0.75      , 0.75333333,\n",
       "         0.75333333, 0.75333333, 0.75666666, 0.76      , 0.76      ,\n",
       "         0.7633333 , 0.77      , 0.77      , 0.7733333 , 0.7733333 ,\n",
       "         0.77666664, 0.78      , 0.78333336, 0.7866667 , 0.7866667 ,\n",
       "         0.79      , 0.79333335, 0.7966667 , 0.7966667 , 0.7966667 ,\n",
       "         0.8       , 0.80333334, 0.80333334, 0.8066667 , 0.81      ,\n",
       "         0.81333333, 0.81666666, 0.82      , 0.8233333 , 0.82666665,\n",
       "         0.83      , 0.8333333 , 0.83666664, 0.8433333 , 0.8466667 ,\n",
       "         0.85      , 0.85333335, 0.8566667 , 0.86      , 0.86333334,\n",
       "         0.8666667 , 0.87      , 0.87      , 0.87333333, 0.87666667,\n",
       "         0.87666667, 0.8833333 , 0.8833333 , 0.88666666, 0.8933333 ,\n",
       "         0.89666665, 0.9       , 0.9033333 , 0.9066667 , 0.91      ,\n",
       "         0.91333336, 0.9166667 , 0.92      , 0.92333335, 0.9266667 ,\n",
       "         0.93      , 0.93333334, 0.93666667, 0.94      , 0.9433333 ,\n",
       "         0.94666666, 0.9533333 , 0.95666665, 0.96      , 0.9633333 ,\n",
       "         0.96666664, 0.97      , 0.97333336, 0.9766667 , 0.98333335,\n",
       "         0.9866667 , 0.99      , 0.99333334, 0.99666667, 1.        ],\n",
       "        dtype=float32),\n",
       "  'thresholds': array([1.    , 0.5254, 0.5244, 0.524 , 0.5234, 0.523 , 0.5225, 0.522 ,\n",
       "         0.5215, 0.521 , 0.5205, 0.52  , 0.5195, 0.519 , 0.5186, 0.518 ,\n",
       "         0.5176, 0.517 , 0.5166, 0.516 , 0.5156, 0.515 , 0.5146, 0.514 ,\n",
       "         0.5137, 0.513 , 0.5127, 0.512 , 0.5117, 0.511 , 0.5107, 0.5103,\n",
       "         0.51  , 0.5093, 0.509 , 0.5083, 0.508 , 0.5073, 0.507 , 0.5063,\n",
       "         0.506 , 0.5054, 0.505 , 0.5044, 0.5034, 0.503 , 0.5024, 0.502 ,\n",
       "         0.5015, 0.501 , 0.5005, 0.5   , 0.4998, 0.4995, 0.4993, 0.499 ,\n",
       "         0.4985, 0.4978, 0.4976, 0.4973, 0.497 , 0.4968, 0.4966, 0.4963,\n",
       "         0.496 , 0.4958, 0.4956, 0.4954, 0.495 , 0.4949, 0.4946, 0.4944,\n",
       "         0.4941, 0.494 , 0.4937, 0.4934, 0.4932, 0.493 , 0.4924, 0.4922,\n",
       "         0.4915, 0.4912, 0.4905, 0.4902, 0.49  , 0.4897, 0.4895, 0.4893,\n",
       "         0.4888, 0.4883, 0.4878, 0.4873, 0.487 , 0.4868, 0.4866, 0.4863,\n",
       "         0.486 , 0.4858, 0.4856, 0.4854, 0.4849, 0.4844, 0.4841, 0.4834,\n",
       "         0.4824, 0.4822, 0.482 , 0.4817, 0.4814, 0.4812, 0.4807, 0.4805,\n",
       "         0.48  , 0.4797, 0.4795, 0.4792, 0.479 , 0.4788, 0.4783, 0.478 ,\n",
       "         0.4778, 0.4775, 0.4773, 0.4768, 0.4766, 0.4758, 0.4756, 0.4753,\n",
       "         0.475 , 0.4749, 0.4746, 0.4744, 0.474 , 0.4739, 0.4736, 0.4734,\n",
       "         0.4731, 0.4727, 0.4724, 0.4722, 0.472 , 0.4717, 0.4714, 0.471 ,\n",
       "         0.4707, 0.4705, 0.4702, 0.47  , 0.4697, 0.4688, 0.4685, 0.4683,\n",
       "         0.468 , 0.4678, 0.467 , 0.4668, 0.4666, 0.466 , 0.4656, 0.4648,\n",
       "         0.4646, 0.4644, 0.464 , 0.4639, 0.4636, 0.4634, 0.463 , 0.4626,\n",
       "         0.4622, 0.462 , 0.4617, 0.4614, 0.4612, 0.461 , 0.4607, 0.4604,\n",
       "         0.46  , 0.4595, 0.4592, 0.4585, 0.458 , 0.4578, 0.4573, 0.4568,\n",
       "         0.4565, 0.4563, 0.456 , 0.4558, 0.4556, 0.4553, 0.455 , 0.4548,\n",
       "         0.4546, 0.4543, 0.454 , 0.4539, 0.4531, 0.453 , 0.4526, 0.4524,\n",
       "         0.4521, 0.452 , 0.4517, 0.4514, 0.4512, 0.451 , 0.4507, 0.4504,\n",
       "         0.4502, 0.45  , 0.449 , 0.4485, 0.4482, 0.448 , 0.4478, 0.4475,\n",
       "         0.4473, 0.447 , 0.446 , 0.4456, 0.4448, 0.4446, 0.4436, 0.4434,\n",
       "         0.443 , 0.4424, 0.4414, 0.441 , 0.4404, 0.44  , 0.4382, 0.438 ,\n",
       "         0.4375, 0.4368, 0.4355, 0.4343, 0.4338, 0.4333, 0.433 , 0.432 ,\n",
       "         0.4312, 0.4304, 0.43  , 0.4294, 0.428 , 0.4277, 0.4275, 0.4272,\n",
       "         0.4268, 0.4265, 0.4263, 0.426 , 0.4253, 0.424 , 0.4238, 0.4233,\n",
       "         0.423 , 0.422 , 0.4219, 0.4216, 0.4211, 0.4202, 0.4194, 0.4187,\n",
       "         0.4185, 0.4182, 0.4177, 0.417 , 0.4163, 0.4146, 0.4114, 0.4106,\n",
       "         0.4102, 0.4087, 0.4084, 0.4026, 0.4019, 0.4016, 0.4004, 0.4001,\n",
       "         0.4   , 0.3977, 0.3975, 0.3962, 0.3953, 0.3918, 0.3916, 0.3914,\n",
       "         0.391 , 0.3901, 0.3894, 0.3867, 0.3835, 0.3826, 0.379 , 0.3772,\n",
       "         0.3735, 0.3728, 0.3706, 0.3572], dtype=float16),\n",
       "  'name': 'Original NN data1',\n",
       "  'auc': array(0.44575554, dtype=float32),\n",
       "  'model': LitClassifier(\n",
       "    (model): SimpleClassifier(\n",
       "      (layer_stack): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): BCEWithLogitsLoss()\n",
       "    (train_accuracy): BinaryAccuracy()\n",
       "    (test_accuracy): BinaryAccuracy()\n",
       "    (test_auc): BinaryAUROC()\n",
       "  )},\n",
       " 'test_loader': <torch.utils.data.dataloader.DataLoader at 0x735411b5cfb0>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle, load_from_pickle\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison\n",
    "from predict_ensemble_and_evaluate import make_curve_monotonic\n",
    "\n",
    "# Save the data\n",
    "save_to_pickle(list_folds_best_models, list_folds_weighted_clfs, results_original_roc, test_loader, filename='pickle/NN_data1_weighted.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3aba17",
   "metadata": {},
   "source": [
    "# Load pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "256006b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle, load_from_pickle\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison\n",
    "from predict_ensemble_and_evaluate import make_curve_monotonic\n",
    "\n",
    "# Load the data\n",
    "list_folds_best_models, list_folds_weighted_clfs, results_original_roc, test_loader = load_from_pickle(filename='pickle/NN_data1_weighted.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5d9c39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the best classifiers of all folds\n",
    "results_lists = []\n",
    "results_lists.extend(list_folds_best_models)\n",
    "results_lists.extend(list_folds_weighted_clfs)\n",
    "plot_roc_comparison(\n",
    "    results_lists=results_lists,\n",
    "    names=[\"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Weighted1\", \"Weighted2\", \"Weighted3\", \"Weighted4\"],\n",
    "    results_original_roc=results_original_roc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275941a6",
   "metadata": {},
   "source": [
    "### Ensemble prediction using voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "586c430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating Ensemble ROC Curve by iterating through FPR values ---\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0000\n",
      "Soft Voting -> Achieved [TPR: 0.8233, FPR: 0.0000]\n",
      "Hard Voting -> Resulted in [TPR: 0.8300, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0204\n",
      "Soft Voting -> Achieved [TPR: 0.8967, FPR: 0.0200]\n",
      "Hard Voting -> Resulted in [TPR: 0.8967, FPR: 0.0200]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0408\n",
      "Soft Voting -> Achieved [TPR: 0.9267, FPR: 0.0367]\n",
      "Hard Voting -> Resulted in [TPR: 0.9300, FPR: 0.0400]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0612\n",
      "Soft Voting -> Achieved [TPR: 0.9467, FPR: 0.0533]\n",
      "Hard Voting -> Resulted in [TPR: 0.9533, FPR: 0.0567]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0816\n",
      "Soft Voting -> Achieved [TPR: 0.9567, FPR: 0.0800]\n",
      "Hard Voting -> Resulted in [TPR: 0.9567, FPR: 0.0767]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1020\n",
      "Soft Voting -> Achieved [TPR: 0.9567, FPR: 0.0833]\n",
      "Hard Voting -> Resulted in [TPR: 0.9467, FPR: 0.0700]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1224\n",
      "Soft Voting -> Achieved [TPR: 0.9667, FPR: 0.1100]\n",
      "Hard Voting -> Resulted in [TPR: 0.9667, FPR: 0.1133]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1429\n",
      "Soft Voting -> Achieved [TPR: 0.9700, FPR: 0.1300]\n",
      "Hard Voting -> Resulted in [TPR: 0.9667, FPR: 0.1100]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1633\n",
      "Soft Voting -> Achieved [TPR: 0.9767, FPR: 0.1567]\n",
      "Hard Voting -> Resulted in [TPR: 0.9667, FPR: 0.1100]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1837\n",
      "Soft Voting -> Achieved [TPR: 0.9800, FPR: 0.1700]\n",
      "Hard Voting -> Resulted in [TPR: 0.9667, FPR: 0.1100]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2041\n",
      "Soft Voting -> Achieved [TPR: 0.9833, FPR: 0.1967]\n",
      "Hard Voting -> Resulted in [TPR: 0.9667, FPR: 0.1100]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2245\n",
      "Soft Voting -> Achieved [TPR: 0.9900, FPR: 0.2233]\n",
      "Hard Voting -> Resulted in [TPR: 0.9933, FPR: 0.2100]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2449\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.2333]\n",
      "Hard Voting -> Resulted in [TPR: 0.9933, FPR: 0.1633]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2653\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.2333]\n",
      "Hard Voting -> Resulted in [TPR: 0.9933, FPR: 0.1633]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2857\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.2333]\n",
      "Hard Voting -> Resulted in [TPR: 0.9933, FPR: 0.1633]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3061\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.2333]\n",
      "Hard Voting -> Resulted in [TPR: 0.9933, FPR: 0.1633]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3265\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.2333]\n",
      "Hard Voting -> Resulted in [TPR: 0.9933, FPR: 0.1633]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3469\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.2333]\n",
      "Hard Voting -> Resulted in [TPR: 0.9933, FPR: 0.1633]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3673\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.2933]\n",
      "Hard Voting -> Resulted in [TPR: 0.9933, FPR: 0.2467]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3878\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.2933]\n",
      "Hard Voting -> Resulted in [TPR: 0.9933, FPR: 0.2467]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4082\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.2933]\n",
      "Hard Voting -> Resulted in [TPR: 0.9933, FPR: 0.2467]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4286\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.2933]\n",
      "Hard Voting -> Resulted in [TPR: 0.9933, FPR: 0.2467]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4490\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.2933]\n",
      "Hard Voting -> Resulted in [TPR: 1.0000, FPR: 0.4467]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4694\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.2933]\n",
      "Hard Voting -> Resulted in [TPR: 1.0000, FPR: 0.4467]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4898\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.2933]\n",
      "Hard Voting -> Resulted in [TPR: 1.0000, FPR: 0.4467]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.5102\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.2933]\n",
      "Hard Voting -> Resulted in [TPR: 1.0000, FPR: 0.4467]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.5306\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.2767]\n",
      "Hard Voting -> Resulted in [TPR: 1.0000, FPR: 0.4467]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.5510\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.2767]\n",
      "Hard Voting -> Resulted in [TPR: 1.0000, FPR: 0.4467]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.5714\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.2767]\n",
      "Hard Voting -> Resulted in [TPR: 1.0000, FPR: 0.4467]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.5918\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.2767]\n",
      "Hard Voting -> Resulted in [TPR: 1.0000, FPR: 0.4467]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.6122\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.4300]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.6327\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.4300]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.6531\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.4300]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.6735\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.4300]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.6939\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.4300]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "\n",
      "--- Filtering curves to be monotonic ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Loop through all the FPR values to generate the ensemble ROC curve ---\n",
    "\n",
    "ensemble_results_soft = []\n",
    "ensemble_results_hard = []\n",
    "\n",
    "print(\"\\n--- Generating Ensemble ROC Curve by iterating through FPR values ---\")\n",
    "# We iterate from a low to high target_fpr to trace the curve\n",
    "for target_fpr in np.linspace(0.0, 1.0, 50): \n",
    "    # 1. Assign the function's output to a single variable first.\n",
    "    result_tuple = predict_ensemble_and_evaluate(\n",
    "        list_folds_best_models=list_folds_best_models,\n",
    "        test_loader=test_loader,\n",
    "        target_fpr=target_fpr\n",
    "    )\n",
    "    \n",
    "    if result_tuple is not None:\n",
    "        \n",
    "        for voting_method, metrics in result_tuple.items():\n",
    "            # Create a dictionary for each point and append it to the list\n",
    "            if voting_method == 'soft_voting':\n",
    "                point_dict = {'fpr': metrics['fpr'], 'tpr': metrics['tpr']}\n",
    "                ensemble_results_soft.append(point_dict)\n",
    "            else:\n",
    "                point_dict = {'fpr': metrics['fpr'], 'tpr': metrics['tpr']}\n",
    "                ensemble_results_hard.append(point_dict)\n",
    "            \n",
    "        \n",
    "# Ensure the curve starts at (0, 0)\n",
    "    if not ensemble_results_soft or ensemble_results_soft[0]['fpr'] > 0.0:\n",
    "        ensemble_results_soft.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if ensemble_results_soft[-1]['fpr'] < 1.0 or ensemble_results_soft[-1]['tpr'] < 1.0:\n",
    "        ensemble_results_soft.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    if not ensemble_results_hard or ensemble_results_hard[0]['fpr'] > 0.0:\n",
    "        ensemble_results_hard.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if ensemble_results_hard[-1]['fpr'] < 1.0 or ensemble_results_hard[-1]['tpr'] < 1.0:\n",
    "        ensemble_results_hard.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    # --- NEW: Post-process the lists to make them monotonic ---\n",
    "print(\"\\n--- Filtering curves to be monotonic ---\")\n",
    "ensemble_results_soft = make_curve_monotonic(ensemble_results_soft)\n",
    "ensemble_results_hard = make_curve_monotonic(ensemble_results_hard)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bae1a225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Plotting all ROC curves for comparison ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the best classifiers of all folds\n",
    "results_lists = []\n",
    "results_lists.extend(list_folds_best_models)\n",
    "results_lists.extend(list_folds_weighted_clfs)\n",
    "results_lists.append(ensemble_results_soft)\n",
    "results_lists.append(ensemble_results_hard)\n",
    "\n",
    "\n",
    "# --- Plot the final comparison ---\n",
    "print(\"\\n--- Plotting all ROC curves for comparison ---\")\n",
    "plot_roc_comparison(\n",
    "    results_lists=results_lists,\n",
    "    names=[\"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Weighted1\", \"Weighted2\", \"Weighted3\", \"Weighted4\", \"Ensemble_voting_soft\", \"Ensemble_voting_hard\"],\n",
    "    results_original_roc=results_original_roc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd54a198",
   "metadata": {},
   "source": [
    "## Check performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667ba0e7",
   "metadata": {},
   "source": [
    "## Check performance on test1 and test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f504bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_performance_tester(classifier_list, test_loader):\n",
    "\n",
    "    list_weighted_clfs = []  # Reset the list for final testing\n",
    "    for i, model_info in enumerate(classifier_list):\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator='gpu',\n",
    "            devices=1,\n",
    "            #strategy='ddp_notebook',\n",
    "            max_epochs=NUM_EPOCHS, # Number of epochs for THIS stage\n",
    "            callbacks=[checkpoint_callback, progress_bar],\n",
    "            logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=f\"stage_{i+1}\"),\n",
    "            precision='16-mixed'\n",
    "            )\n",
    "\n",
    "        model = model_info[\"model\"]\n",
    "        raw_threshold = model_info[\"threshold\"]\n",
    "\n",
    "\n",
    "        # CORRECTED: Use isinstance() to check if model is a string\n",
    "        if isinstance(model, str):\n",
    "            print(f\"Skipping model {i+1} as it is a string placeholder: '{model}'\")\n",
    "            continue\n",
    "\n",
    "        # Check if the stored threshold is a NumPy number or a PyTorch Tensor\n",
    "        if isinstance(raw_threshold, (np.number, torch.Tensor)):\n",
    "            # If it is, we can safely call .item() to extract the Python float\n",
    "            threshold = raw_threshold.item()\n",
    "        else:\n",
    "            # Otherwise, it's already a float or something that can be cast to one\n",
    "            threshold = float(raw_threshold)\n",
    "        model.current_test_threshold = threshold  # Set the threshold for this model\n",
    "\n",
    "        # This code will now only run if 'model' is a PyTorch Lightning module\n",
    "        # and not a string.\n",
    "        print(f\"--- Testing model {i+1} ---\")\n",
    "\n",
    "        trainer.test(model, dataloaders=test_loader, ckpt_path=None)\n",
    "        \n",
    "        results_classifier = model.last_test_results.copy()\n",
    "        current_model = {\n",
    "            \"model\": model,\n",
    "            \"fpr\": results_classifier[\"fpr\"],\n",
    "            \"tpr\": results_classifier[\"tpr\"],\n",
    "            \"threshold\": results_classifier[\"threshold\"],\n",
    "            \"full_roc\": results_classifier[\"full_roc\"]\n",
    "        }\n",
    "        list_weighted_clfs.append(current_model)\n",
    "\n",
    "    # Ensure the curve starts at (0, 0)\n",
    "    if not list_weighted_clfs or list_weighted_clfs[0]['fpr'] > 0.0:\n",
    "        list_weighted_clfs.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if list_weighted_clfs[-1]['fpr'] < 1.0 or list_weighted_clfs[-1]['tpr'] < 1.0:\n",
    "        list_weighted_clfs.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    return list_weighted_clfs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLlabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
