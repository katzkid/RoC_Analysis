{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33420fde",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d11cd5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d840881",
   "metadata": {},
   "source": [
    "## Display function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c24af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for displaying ROC curves of multiple classifiers\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def plot_roc_connected_points(results_list, results_original_roc, name=\"All Classifiers\"):\n",
    "    \"\"\"\n",
    "    Creates a plot showing the performance of all classifiers as points,\n",
    "    and connects them with a line, sorted by FPR.\n",
    "\n",
    "    Args:\n",
    "        results_list: A list of dictionaries, where each dict contains 'fpr', 'tpr'.\n",
    "    \"\"\"\n",
    "    if not results_list:\n",
    "        print(\"No results to plot.\")\n",
    "        return\n",
    "\n",
    "    # Convert results to a pandas DataFrame for easy sorting\n",
    "    df = pd.DataFrame(results_list)\n",
    "    \n",
    "    # Sort the models by their False Positive Rate to create a left-to-right line\n",
    "    df_sorted = df.sort_values(by='fpr').reset_index(drop=True)\n",
    "    \n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    # Plot all the individual model points as a scatter plot\n",
    "    # This helps see the actual performance of each model\n",
    "    plt.scatter(df_sorted['fpr'], df_sorted['tpr'], c='black', marker='o', \n",
    "                alpha=0.6, s=100, zorder=3) # zorder=3 puts dots on top\n",
    "\n",
    "    # Plot the line connecting the points\n",
    "    plt.plot(df_sorted['fpr'], df_sorted['tpr'], color='red', lw=1.5,\n",
    "             alpha=0.8, label=f'{name} (AUC = {auc(df_sorted[\"fpr\"], df_sorted[\"tpr\"]):.2f})')\n",
    "    \n",
    "    #plot the original ROC curve\n",
    "    plt.plot(results_original_roc[\"fpr\"], results_original_roc[\"tpr\"], color='blue', \n",
    "             label=f'{results_original_roc[\"name\"]} (AUC = {results_original_roc[\"auc\"]:.2f})')\n",
    "\n",
    "    # Plot the \"no-skill\" line for reference\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.title('Performance Path of All Trained Classifiers')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23b1ea",
   "metadata": {},
   "source": [
    "## Best ROC envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e350c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def get_best_roc_envelope(results_list, results_original_roc=None):\n",
    "    \"\"\"\n",
    "    Constructs the upper envelope of multiple ROC curves to find the best\n",
    "    possible operating points from a collection of classifiers.\n",
    "\n",
    "    This function is guaranteed to produce a list of points that starts at\n",
    "    (FPR=0, TPR=0) and ends at (FPR=1, TPR=1), making it suitable for direct\n",
    "    plotting and AUC calculation.\n",
    "\n",
    "    Args:\n",
    "        results_list (list): A list of dictionaries. Each dictionary must\n",
    "                             contain a 'model' name and the full ROC results\n",
    "                             under the 'full_roc' key.\n",
    "        results_original_roc (dict, optional): A dictionary containing the\n",
    "                                               ROC results of a baseline model,\n",
    "                                               which will also be included in\n",
    "                                               the comparison. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        list: A sorted list of dictionaries representing the optimal ROC\n",
    "              envelope. Each dictionary includes 'model', 'fpr', 'tpr',\n",
    "              and 'threshold'.\n",
    "    \"\"\"\n",
    "    all_points = []\n",
    "\n",
    "    # Step 1: Gather all ROC points from all provided models\n",
    "    all_results = results_list[:]\n",
    "    if results_original_roc:\n",
    "        all_results.append({\n",
    "            'model': 'original_baseline',\n",
    "            'full_roc': results_original_roc\n",
    "        })\n",
    "\n",
    "    for result in all_results:\n",
    "        model_name = result.get('model', 'Unknown Model')\n",
    "        roc = result.get('full_roc')\n",
    "        if not roc: continue\n",
    "\n",
    "        fprs = roc.get('fpr', [])\n",
    "        tprs = roc.get('tpr', [])\n",
    "        thresholds = roc.get('thresholds', [])\n",
    "\n",
    "        for i in range(len(fprs)):\n",
    "            threshold = thresholds[i] if i < len(thresholds) else thresholds[-1]\n",
    "            all_points.append({\n",
    "                'model': model_name, 'fpr': fprs[i],\n",
    "                'tpr': tprs[i], 'threshold': threshold\n",
    "            })\n",
    "\n",
    "    # Handle case with no data by returning a default diagonal line\n",
    "    if not all_points:\n",
    "        return [\n",
    "            {'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf},\n",
    "            {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}\n",
    "        ]\n",
    "\n",
    "    # Step 2: Sort all points by FPR (asc), then by TPR (desc)\n",
    "    all_points.sort(key=lambda p: (p['fpr'], -p['tpr']))\n",
    "\n",
    "    # Step 3: Build the core ROC envelope\n",
    "    best_roc_envelope = []\n",
    "    max_tpr_so_far = -1.0\n",
    "    for point in all_points:\n",
    "        # Add a point only if it has a strictly higher TPR\n",
    "        if point['tpr'] > max_tpr_so_far:\n",
    "            # To prevent adding multiple points at the same FPR, check if the last point\n",
    "            # has the same FPR and replace it if so (since this one has a higher TPR)\n",
    "            if best_roc_envelope and best_roc_envelope[-1]['fpr'] == point['fpr']:\n",
    "                best_roc_envelope[-1] = point\n",
    "            else:\n",
    "                best_roc_envelope.append(point)\n",
    "            max_tpr_so_far = point['tpr']\n",
    "    \n",
    "    # Step 4: Manually add extremities if they are missing\n",
    "    \n",
    "    # Ensure the curve starts at (0, 0)\n",
    "    if not best_roc_envelope or best_roc_envelope[0]['fpr'] > 0.0:\n",
    "        best_roc_envelope.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if best_roc_envelope[-1]['fpr'] < 1.0 or best_roc_envelope[-1]['tpr'] < 1.0:\n",
    "        best_roc_envelope.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    return best_roc_envelope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b781e9",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c3deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def generate_data(dataset):\n",
    "    if dataset == \"data1\":\n",
    "        no_predictors = 2\n",
    "        no_samples = 1600\n",
    "        no_classes = 2\n",
    "        #kerneltype = 'linear'  #comment out for polynomial kernel\n",
    "        #kerneltype = 'poly'  #comment out for linear kernel\n",
    "\n",
    "\n",
    "\n",
    "        n_samples_per_cluster = 400\n",
    "        n_clusters = 4\n",
    "\n",
    "        # Create the clusters deterministically\n",
    "        np.random.seed(0) # for reproducibility\n",
    "\n",
    "        X = np.zeros((n_samples_per_cluster * n_clusters, 2))\n",
    "        y = np.zeros(n_samples_per_cluster * n_clusters)\n",
    "\n",
    "        # Cluster centers in corners of a square\n",
    "        centers = [[0, 0], [2, 0], [0, 2], [2, 2]]\n",
    "\n",
    "        # Assign points to clusters deterministically\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = slice(i * n_samples_per_cluster, (i + 1) * n_samples_per_cluster)\n",
    "            X[cluster_indices] = centers[i] + np.random.normal(scale=0.5, size=(n_samples_per_cluster, 2))\n",
    "            if i == 0 or i == 3:\n",
    "                y[cluster_indices] = 0\n",
    "            else:\n",
    "                y[cluster_indices] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #Visualize\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap='viridis', s=50)\n",
    "        plt.title('Four Clusters of Equal Size')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "\n",
    "        #add intercept to X\n",
    "        #X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # # shuffle data\n",
    "        # permutation = np.random.permutation(no_samples)\n",
    "        # X = X[permutation]\n",
    "        # y = y[permutation]\n",
    "\n",
    "\n",
    "        #Split data into training and testing sets\n",
    "        # Step 1: Split off the 1000 training samples. The rest (600) go into a temporary pool.\n",
    "        # We can use absolute numbers for the size.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=1000,  # Specify exactly 1000 samples for training\n",
    "            random_state=42,\n",
    "            stratify=y        # Crucial for classification: keeps class proportions the same\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "        train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        val_data = test_data\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "    elif dataset == \"data2\":\n",
    "        no_predictors = 2\n",
    "        no_samples = 1600\n",
    "        no_classes = 2\n",
    "        #kerneltype = 'linear'  #comment out for polynomial kernel\n",
    "        #kerneltype = 'poly'  #comment out for linear kernel\n",
    "\n",
    "\n",
    "\n",
    "        n_samples_per_cluster = 400\n",
    "        n_clusters = 4\n",
    "\n",
    "        # Create the clusters deterministically\n",
    "        np.random.seed(0) # for reproducibility\n",
    "\n",
    "        X = np.zeros((n_samples_per_cluster * n_clusters, 2))\n",
    "        y = np.zeros(n_samples_per_cluster * n_clusters)\n",
    "\n",
    "        # Cluster centers in corners of a square\n",
    "        centers = [[0, 0], [2, 0], [1, 2], [1, 2]]\n",
    "\n",
    "        # Assign points to clusters deterministically\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = slice(i * n_samples_per_cluster, (i + 1) * n_samples_per_cluster)\n",
    "            X[cluster_indices] = centers[i] + np.random.normal(scale=0.5, size=(n_samples_per_cluster, 2))\n",
    "            if i == 0 or i == 3:\n",
    "                y[cluster_indices] = 0\n",
    "            else:\n",
    "                y[cluster_indices] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #Visualize\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap='viridis', s=50)\n",
    "        plt.title('Four Clusters of Equal Size')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "\n",
    "        #add intercept to X\n",
    "        #X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # # shuffle data\n",
    "        # permutation = np.random.permutation(no_samples)\n",
    "        # X = X[permutation]\n",
    "        # y = y[permutation]\n",
    "\n",
    "\n",
    "        #Split data into training and testing sets\n",
    "        # Step 1: Split off the 1000 training samples. The rest (600) go into a temporary pool.\n",
    "        # We can use absolute numbers for the size.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=1000,  # Specify exactly 1000 samples for training\n",
    "            random_state=42,\n",
    "            stratify=y        # Crucial for classification: keeps class proportions the same\n",
    "        )\n",
    "\n",
    "\n",
    "        train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        val_data = test_data\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "    elif dataset == \"pneumoniaMNIST\":\n",
    "        import medmnist\n",
    "        print(medmnist.__version__)\n",
    "        # read in the PneumoniaMNIST dataset\n",
    "        from medmnist import PneumoniaMNIST\n",
    "        train_data = PneumoniaMNIST(split='train', download=True, size=224)\n",
    "        test_data = PneumoniaMNIST(split='test', download=True, size=224)\n",
    "        val_data = PneumoniaMNIST(split='val', download=True, size=224)\n",
    "        # print the dataset info\n",
    "        print(f\"Number of training samples: {len(train_data)}\")\n",
    "        print(f\"Number of test samples: {len(test_data)}\")\n",
    "        print(f\"Number of validation samples: {len(val_data)}\")\n",
    "\n",
    "    return train_data, test_data, val_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c59034e",
   "metadata": {},
   "source": [
    "## Data1: NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74133e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a060ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "IMAGE_SIZE = 224\n",
    "NUM_CLASSES = 1\n",
    "NUM_CHANNELS = 1\n",
    "NUM_EPOCHS = 1\n",
    "NUM_WORKERS = 4\n",
    "K_FOLDS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a702675",
   "metadata": {},
   "source": [
    "### Lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3760e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "\n",
    "# A simple classifier head\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_features=2, hidden_units=32, num_classes=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_features (int): Number of input features (2 for your data)\n",
    "            hidden_units (int): Number of neurons in the hidden layer\n",
    "            num_classes (int): Number of output classes (1 for binary)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            # --- Hidden Layer 1 ---\n",
    "            # Takes 2 features in, outputs a hidden representation of size 32\n",
    "            nn.Linear(in_features=input_features, out_features=hidden_units),\n",
    "            nn.ReLU(),  # <-- The crucial non-linear activation function\n",
    "\n",
    "            # --- Output Layer ---\n",
    "            # Takes the 16-unit hidden representation, outputs 1 logit\n",
    "            nn.Linear(in_features=hidden_units, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)\n",
    "\n",
    "# A new LightningModule just for training the classifier\n",
    "class LitClassifier(pl.LightningModule):\n",
    "    def __init__(self, input_features=512, hidden_units=32, num_classes=1, learning_rate=1e-4, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = SimpleClassifier(\n",
    "            input_features=self.hparams.input_features,\n",
    "            hidden_units=self.hparams.hidden_units,\n",
    "            num_classes=self.hparams.num_classes\n",
    "        )\n",
    "\n",
    "        self.current_test_threshold = 0.5  # Default threshold for binary classification\n",
    "        self.strict_loading = False \n",
    "\n",
    "        # This ensures the model's structure is correct upon initialization\n",
    "        if self.hparams.pos_weight is not None:\n",
    "            self.criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(self.hparams.pos_weight))\n",
    "        else:\n",
    "            self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        \n",
    "        \n",
    "        # --- METRICS ---\n",
    "        self.train_accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.test_accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.test_auc = torchmetrics.AUROC(task=\"binary\")\n",
    "        \n",
    "        # This list will store outputs from each test step\n",
    "        self.test_step_outputs = []\n",
    "        # This dictionary will hold the final results\n",
    "        self.last_test_results = {}\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        features, labels = batch\n",
    "        outputs = self(features)\n",
    "        \n",
    "        # For the loss function, labels need to be reshaped to match outputs\n",
    "        loss = self.criterion(outputs, labels.float().view(-1, 1))\n",
    "        \n",
    "        # For metrics, squeeze predictions to match labels' shape\n",
    "        self.train_accuracy(outputs.squeeze(), labels.int())\n",
    "        \n",
    "        self.log('classifier_train_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('classifier_train_acc', self.train_accuracy, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        features, labels = batch\n",
    "        outputs = self.model(features)\n",
    "        loss = self.criterion(outputs, labels.float().view(-1, 1))\n",
    "\n",
    "        # Append predictions and labels to our list for aggregation\n",
    "        self.test_step_outputs.append({\"preds\": outputs.detach(), \"labels\": labels.detach()})\n",
    "        \n",
    "        self.log('test_loss', loss)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        if not self.test_step_outputs:\n",
    "            return # Avoid errors if test loop was empty\n",
    "\n",
    "        # Concatenate all predictions and labels\n",
    "        all_preds = torch.cat([x['preds'] for x in self.test_step_outputs])\n",
    "        all_labels = torch.cat([x['labels'] for x in self.test_step_outputs])\n",
    "\n",
    "        # --- FIX: Squeeze BOTH predictions and labels to ensure they match ---\n",
    "        squeezed_preds = all_preds.squeeze()\n",
    "        all_probs = torch.sigmoid(squeezed_preds)\n",
    "        # The labels tensor might also be [N, 1], so we squeeze it as well.\n",
    "        int_labels = all_labels.squeeze().int()\n",
    "\n",
    "        # Calculate final scalar metrics\n",
    "        test_acc = self.test_accuracy(squeezed_preds, int_labels)\n",
    "        test_auc_val = self.test_auc(squeezed_preds, int_labels)\n",
    "\n",
    "\n",
    "        # Get the confusion matrix stats at the default 0.0 logit threshold\n",
    "        tp, fp, tn, fn, _ = torchmetrics.functional.stat_scores(\n",
    "            all_probs, int_labels, task=\"binary\", threshold=self.current_test_threshold\n",
    "        ) \n",
    "        \n",
    "        # Calculate TPR and FPR from these raw scores\n",
    "        epsilon = 1e-6\n",
    "        tpr_at_0 = tp / (tp + fn + epsilon)\n",
    "        fpr_at_0 = fp / (fp + tn + epsilon)\n",
    "\n",
    "        # Calculate data for the full ROC Curve\n",
    "        fpr_full, tpr_full, thresholds_full = torchmetrics.functional.roc(\n",
    "            torch.sigmoid(squeezed_preds),\n",
    "            int_labels,\n",
    "            task=\"binary\"\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"\\n--- Final Classifier Test Metrics ---\")\n",
    "        print(f\"Accuracy: {test_acc:.4f}\")\n",
    "        print(f\"AUC: {test_auc_val:.4f}\")\n",
    "        print(\"-------------------------------------\\n\")\n",
    "        \n",
    "        self.last_test_results = {\n",
    "            \"w\": self.hparams.get('w'),\n",
    "            \"fpr\": fpr_at_0.cpu().numpy(),\n",
    "            \"tpr\": tpr_at_0.cpu().numpy(),\n",
    "            \"threshold\": self.current_test_threshold,\n",
    "            \"auc\": test_auc_val.cpu().numpy(),\n",
    "            \"accuracy\": test_acc.cpu().numpy(),\n",
    "            \"full_roc\": {\n",
    "                \"fpr\": fpr_full.cpu().numpy(),\n",
    "                \"tpr\": tpr_full.cpu().numpy(),\n",
    "                \"thresholds\": thresholds_full.cpu().numpy()\n",
    "            }\n",
    "        }\n",
    "        self.test_step_outputs.clear()\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ea652",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4f28dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1000, 2), (1000,)\n",
      "Test data shape: (600, 2), (600,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "train_data, test_data, val_data = generate_data(\"data1\")\n",
    "\n",
    "\n",
    "train_data_tensor = data.TensorDataset(torch.tensor(train_data[:, :-1], dtype=torch.float32),\n",
    "                                        torch.tensor(train_data[:, -1], dtype=torch.float32))\n",
    "train_loader = data.DataLoader(train_data_tensor, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS) #over-write later for k-fold cross-validation\n",
    "test_data_tensor = data.TensorDataset(torch.tensor(test_data[:, :-1], dtype=torch.float32),\n",
    "                                       torch.tensor(test_data[:, -1], dtype=torch.float32))\n",
    "test_loader = data.DataLoader(test_data_tensor, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "# initialize fold\n",
    "kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8065beae",
   "metadata": {},
   "source": [
    "### Regular training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "261a6f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Training for 1 epochs on train_loader ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (16) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52eaa744021e4229bddee7c084953230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v17.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v17.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model from Phase 1 saved to: /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v17.ckpt\n",
      "\n",
      "--- Testing model from Phase 1 checkpoint: /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v17.ckpt ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc66ae79b634a86a378815bd9d07b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4683\n",
      "AUC: 0.4458\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7087163925170898\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Manually Calculating Metrics on Test Set ---\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[190 110]\n",
      " [210  90]]\n",
      "\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.47      0.63      0.54       300\n",
      "     Class 1       0.45      0.30      0.36       300\n",
      "\n",
      "    accuracy                           0.47       600\n",
      "   macro avg       0.46      0.47      0.45       600\n",
      "weighted avg       0.46      0.47      0.45       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# --- Place any constants or unchanging objects outside the loop ---\n",
    "pl.seed_everything(42, workers=True)\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. Instantiate the LightningModule\n",
    "model = LitClassifier(input_features=2, hidden_units=32, learning_rate=LEARNING_RATE)\n",
    "\n",
    "checkpoint_callback_full_model = ModelCheckpoint(\n",
    "    monitor='classifier_train_acc',  # Monitor training accuracy\n",
    "    every_n_epochs=1,                # Save model every epoch\n",
    "    dirpath='checkpoints/',\n",
    "    filename='simple-clf-{epoch:02d}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "train_trainer_1 = pl.Trainer(\n",
    "    accelerator='gpu',                 # Use GPUs\n",
    "    devices=1,                         # Number of GPUs to use\n",
    "    #strategy='ddp_notebook',                    # DistributedDataParallel strategy (best for multi-GPU)\n",
    "    max_epochs=NUM_EPOCHS,              # Total number of epochs\n",
    "    callbacks=[checkpoint_callback_full_model, progress_bar],\n",
    "    logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=\"simple-clf-train\"),\n",
    ")\n",
    "\n",
    "test_trainer_1 = pl.Trainer(\n",
    "    accelerator='gpu',\n",
    "    devices=1,  # Use only one GPU\n",
    "    logger = pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=\"simple-clf-test\"),\n",
    "    # Add the callback here so the Trainer can find the 'best' path\n",
    "    callbacks=[checkpoint_callback_full_model],\n",
    "    precision='16-mixed'  # Use mixed precision for testing\n",
    ")\n",
    "\n",
    "# --- Phase 1 Training ---\n",
    "print(f\"--- Starting Training for {NUM_EPOCHS} epochs on train_loader ---\")\n",
    "train_trainer_1.fit(model, train_dataloaders=train_loader)\n",
    "\n",
    "# CRITICAL: Save the path to the best model from this phase\n",
    "path_after_phase1 = checkpoint_callback_full_model.best_model_path\n",
    "print(f\"Best model from Phase 1 saved to: {path_after_phase1}\")\n",
    "\n",
    "# --- Test 1: Evaluate the model from after Phase 1 ---\n",
    "print(f\"\\n--- Testing model from Phase 1 checkpoint: {path_after_phase1} ---\")\n",
    "model.current_test_title = \"ROC Curve after training on DataLoader 1\"\n",
    "model = LitClassifier.load_from_checkpoint(path_after_phase1)  # Load the model from Phase 1\n",
    "model.eval().to('cuda:0')  # Ensure the model is in evaluation mode and on GPU\n",
    "test_trainer_1.test(model, dataloaders=test_loader, ckpt_path=path_after_phase1)\n",
    "results_phase1 = model.last_test_results.copy()\n",
    "results_original_roc = {\"fpr\": results_phase1[\"full_roc\"][\"fpr\"], \"tpr\": results_phase1[\"full_roc\"][\"tpr\"], \"thresholds\": results_phase1[\"full_roc\"][\"thresholds\"], \"name\": \"Original NN data1\", \"auc\": results_phase1[\"auc\"], \"model\": model}\n",
    "\n",
    "# Metrics\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "model.eval() # Set to evaluation mode\n",
    "\n",
    "final_predictions = [] # This will store binary predictions (0s or 1s)\n",
    "true_labels = []\n",
    "\n",
    "print(\"\\n--- Manually Calculating Metrics on Test Set ---\")\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        # Move input data to the same device as the model\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # 1. Get the raw model output (logits) and convert to probabilities\n",
    "        outputs = torch.sigmoid(model(inputs))\n",
    "\n",
    "        # 2. Convert probabilities to binary class predictions (0 or 1) using a 0.5 threshold\n",
    "        preds = (outputs > 0.5).int()\n",
    "\n",
    "        final_predictions.extend(preds.cpu().numpy().flatten())\n",
    "        true_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "# Ensure they are numpy arrays for sklearn\n",
    "true_labels = np.array(true_labels)\n",
    "final_predictions = np.array(final_predictions)\n",
    "\n",
    "# Now, calculate metrics using the correct binary predictions\n",
    "print(\"\\n--- Confusion Matrix ---\")\n",
    "cm = confusion_matrix(true_labels, final_predictions)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "report = classification_report(true_labels, final_predictions, target_names=['Class 0', 'Class 1'], zero_division=0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6c2d0a",
   "metadata": {},
   "source": [
    "### Weighted ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "226e70dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSIFIERS = 50\n",
    "w = np.linspace(0.001, 0.999, NUM_CLASSIFIERS, endpoint=True)\n",
    "pos_weights = w/(1-w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19d1bd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 1/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1980f91104344a0ead101bee00107e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['criterion.pos_weight']\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v18.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v18.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v18.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v18.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55d901a09ae4897bfe1c92635622c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3624\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7597287893295288\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ae1a63a8364b02b2d7e404e488c44f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9cfbe4abe94e20bdab60a38e446b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3965\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7998822927474976\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf969fe22ca64db6ac97587d101751e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3df1108cf74e0fbfb679184fec00d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4234\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8500174880027771\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5322a310f0b8492fb4efd71fb377d985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e0dd2d49bf4b30a7e2bcba0a1ed786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4395\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9073290824890137\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e51914f67fc14b2eb367404bd50f45f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec221b364b9f4e408a2cee942b6c3ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4515\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9717537760734558\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e587f5e4bd949cdb1fae098b7b82b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f9e94eab164dc59f849a2795a24bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4558\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0089677572250366\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e6f2d52acf46368254ea5275787758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c374df5c4b74eda84341144c644a520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4587\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0133905410766602\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa71df406ff42ba944a0add71be316f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a3130bd68342fa899c65fbe89eccd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4617\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9730748534202576\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e992a392ae9c455c9c85e92c3b922ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ef84701a13479fb88c44fa98553903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4665\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9234933257102966\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d6d10708ea436c9d92a5892f6aed48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba13c83ff49495c85a8f75a415ebac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4744\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8758061528205872\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad4a678f107419181ab5bee7635b351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a48d81baacb4e0fa53afb0cbd2d5a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4911\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8384931087493896\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb5a0bf138904c5495b2063e158b0ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8176dcc6d8664f1393a05d0b08500fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.5287\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7932234406471252\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79dbdb21608b4463b4c2124269107494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3352a4b7364d42a987b17388497ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.6283\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.756634533405304\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794600a60fb0448bae0e135f2c49b1d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457ef0a3eb464bbbbc6a743d538b37df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.7542\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7261484265327454\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80225e98670c42d2ad2457b26e961c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbdf3c94b67b451ca094eddc1ebd9b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.8295\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7093010544776917\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2c135a1a784763a7e18ba4ab2ae5cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "266c460e6e604808b4cb2b97585a2050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.9098\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6740606427192688\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c274da4c83b349a7a2f9a93b7f2a341d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1ee6269814477a859f1593d62ac337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.9380\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6547136306762695\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07bd0a6cc5f640c798c652ff6bd9afaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a25270d1fa4febb2d88333654b8a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5200\n",
      "AUC: 0.9559\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6362302303314209\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09640c7f70e742b5a9445afe35b18760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c00528c8aae4d20aaee60b8a7f03fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5760\n",
      "AUC: 0.9587\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6163405179977417\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b7dc777f5954e54aa10578382067af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79368b3e167241a194828624be3db43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6520\n",
      "AUC: 0.9689\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5975120067596436\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d39eac7fb049118f683bdb21a4b257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa7b95a8afd4a6fbd1ba1a3b582511e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6880\n",
      "AUC: 0.9659\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5829055309295654\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27323cf56e5a406c908ede6d0fd6c822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2eaf03b5bc4343816dea225e474429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7120\n",
      "AUC: 0.9694\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5692366361618042\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a90adcb76c47948747d700dcc53b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01bf93088cb546e0bc2d0dd2420936de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7840\n",
      "AUC: 0.9720\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5562064051628113\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f08f66c84f89491db32f65cb8e1f1c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e4bd0a57d7445e9e9b25bba057ddb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8480\n",
      "AUC: 0.9730\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5440255403518677\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84800251e4045e68f53a46ec8c8292e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03e94b7c4874f98888249f78afc8860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9000\n",
      "AUC: 0.9744\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5331938862800598\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a67830f54a34c14a84615da201a5f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28e86587d554531aba7af38cce5e3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9160\n",
      "AUC: 0.9751\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5237040519714355\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0878644956449eb3701850b876b172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63d4d297bdb493bb092336159385885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9120\n",
      "AUC: 0.9769\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5147244334220886\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccda3cddc9fb427fb8ff7bcd53d6a4d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9cabefcb0aa44348d1ce840d485c403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9280\n",
      "AUC: 0.9788\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5051102638244629\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dceebd9efb34fd29b76cdad64b35c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181cb0126554406cac116d6796da3037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9000\n",
      "AUC: 0.9803\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.49645107984542847\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2bbbbbc900479f8273d67f509403df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1282e6188d99482188d1dad98adecbb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8800\n",
      "AUC: 0.9820\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4885621964931488\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b289523e9b5489cad4e86a61ac42e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bdb5e76a51d45b6b2ddaa9caecb0939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8760\n",
      "AUC: 0.9835\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4760471284389496\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea44d334247c493c96519eecdc82bffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1dfd918db143cabe1232a9367e3040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8360\n",
      "AUC: 0.9828\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.47460752725601196\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a187e4f2880449b48cad9f00c9fe5399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6592c24f19aa41b7a36980958758764a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8080\n",
      "AUC: 0.9840\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4679884612560272\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7af939a533245238df6054b7f443682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a09b3e86d524e4eb0992434bdde340a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7880\n",
      "AUC: 0.9837\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46489909291267395\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6fc52158bb54f61aba3d1bc06b58e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22a3dcb9835405585e0cb1e3257f29d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7560\n",
      "AUC: 0.9841\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46303990483283997\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19427cd5d1834066afb82bc942297d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4595fdab17c4a629b7d92ddd5bcfc8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7560\n",
      "AUC: 0.9846\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.45988935232162476\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a3bd87934d4d97b163cceb0ec11ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3e40f24fd94cb28bcf6f7a3215f35e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.9839\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4615151286125183\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e703d6763252471da3540cf4e7be0ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8139b70e014d85867ea6db9a8f5982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7080\n",
      "AUC: 0.9848\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4616716206073761\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7c6e90d6164dc8a0cce957146d4b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94513e9f711346a6baeea31cbc72431f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6880\n",
      "AUC: 0.9853\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46391236782073975\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664333fcc5a349bf8a08389a745ed433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152ef6e156a647218e29867b4a80fc5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6720\n",
      "AUC: 0.9852\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46831732988357544\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c5326fb6c041c3b22f2b1db04a046a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b55d1188f8437abcc58742d4c28a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6720\n",
      "AUC: 0.9857\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.47003164887428284\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa01c1df4ed4df88cda7860b9359c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b86b07a900421382a5d1253802358d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6520\n",
      "AUC: 0.9858\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.47852733731269836\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92eb487275414221a643cc1a100147f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53de6925014f467d992a897330b74127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6360\n",
      "AUC: 0.9856\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.49548399448394775\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd22170788994e25a06a662db242ddd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0191e0e9f3c0457fb3620e557bf40685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6360\n",
      "AUC: 0.9856\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5077981352806091\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd25cfe5bf64d18af2034680aa7c3a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e164f2ae6b1e428292fd7776abb7ad76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6360\n",
      "AUC: 0.9854\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5277338624000549\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b893a05d0c243c8865b8484af81580f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd4c26bc76b144ad8aecec629ce6fbeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6360\n",
      "AUC: 0.9844\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5620203018188477\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a32e35a51394a92b6587a98f35a6e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88551e923b3e4aa982fa3125d599c357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6320\n",
      "AUC: 0.9835\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6102191209793091\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44aeeddf9365448e9bc63f4f671d18a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4249c3414c48948e4aef56cde19b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6200\n",
      "AUC: 0.9810\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6763134598731995\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eba387b406a4af3b10effd26c9fd926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81cf33190bf42feaafb0057c57765c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6160\n",
      "AUC: 0.9771\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7576197981834412\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e85d22d264840e991d78fe9b958dfa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6220d240aef46a79ccce260bbd284a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6160\n",
      "AUC: 0.9723\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8234801888465881\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 2/4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23b7ac9a551448aa1c60149fee56f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac9abe530c914d11924d28c09f7c7a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5481\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.717371940612793\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dfc563d261446cbb1517db2da3b0acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c3708cdc244b5080ec42aa42966723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5431\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7450451254844666\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d3c5db155f4cb3b8a00d8b4e183e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c5d8bab8e54472b7bba3a6964dc2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5415\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7811105251312256\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b78ae2a76c04eb69e2e052b0c1a9fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9cde198a1b442a97c5bf2b2d6b41a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5404\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8234179615974426\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b036ecf69c4973a5d6bba07c3c0ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992e05ca09394cc2ad657420c4ae7821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5435\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8687893748283386\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b18c8ae915049bc8c9d7353b6b2ca25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e080b1b6dc438880a279b7fd5a38cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5471\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9173064231872559\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "642f8337fc704d2c9f45c340d72bb289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5099b7a611243e09701620b080a47f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5589\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9456800818443298\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19241eb5ee3e4accb70ea8e4e58d0618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea8e84214044bc6861932415b6c21d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5765\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9509041905403137\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916abd6c6d4542469b2aa906eb7f0e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95643207746e4ed0be080d6b344aecc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.6062\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9339728951454163\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b9ac5272ca469cb2fbb3cd9fab7c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0608309c1d64451ca849f2c300ddaaa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.6577\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8939749002456665\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367da1cf1b6d4446a309779ac38dfda4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf088ec45144431aad75b4d377c5d3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.7103\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8550652265548706\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72b2f95aa53498e833e05a3b5b6c2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3131fb850da4c36b04c452690ce5d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.7675\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8201225399971008\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8caa91501ddf49e7aa729fed17dc7990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc4499b160f4fbca214319d5459e63d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.8366\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7815849184989929\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c64a0ffc684a7eae7f18fc89e09b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ac0d2eed19484cb56bc66d8dc05322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.9155\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7512733340263367\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df60d5f2b064691bc6d2ebc8b8dd7e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814e1c76e09d45a0b1f2cc6ec3617a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.9283\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7199587225914001\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914a8eda5da34841a3d4d1c23941c029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d20a08844efa43909dc24ae66192f231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.9288\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6923511028289795\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b290f657deb049cf85290491c70573c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c547bdc7ceaa4ee8949cc95a40d31b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.9188\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.668609619140625\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dda632154e14966b263927bf37426ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91d77a801264edc85aeb203b4b521d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5520\n",
      "AUC: 0.9170\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.644666850566864\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4504c586af2d4d89a1f12415d8a58eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8550b0fee42a471f958992676615e7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6320\n",
      "AUC: 0.9105\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6201967000961304\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14bbdfa83a8e4143aa9bcd5c2fa046b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472da831b5db429f952df22b47af561a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6480\n",
      "AUC: 0.9076\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6054437160491943\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a41e06bcc841ad841ed302c02be7f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bac6f6edb1e43389df556dd16941163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6760\n",
      "AUC: 0.9049\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5848287343978882\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a076210205a4da9958a457f27646998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5da4ba9e4a64c3790835e0dc455bf77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.9128\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5707404017448425\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54703aa4947a438fa25f715f8a998356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce50a3bfbb048eabd8f05db7281ed48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6920\n",
      "AUC: 0.9188\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5530725121498108\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c5a7a187ad4bb29eee504c6aab576b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0175ce2e3e4c6aa890548bc14acea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6800\n",
      "AUC: 0.9211\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5372450947761536\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ed844e3eef4dbb9dc3662401723a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a2432ab852458c8bfa9527d45d39dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.9260\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5211023688316345\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb6c85ba58649208f7ade6666e6be0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5641dab8494edf87b90ae7b5d66294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6960\n",
      "AUC: 0.9369\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5060869455337524\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54cd6e13d956415e9fbcac4e551f34e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d5940395214798b27287e158648e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.9456\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.49144843220710754\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db131fec4f04fd9b58429345a4205d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691b7b970cd348b88cfa5d8b2c02785d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7680\n",
      "AUC: 0.9483\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.47750750184059143\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f80a968537401e845103bf0cbcc666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fed76f041a483ba627c52d0b4564df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8160\n",
      "AUC: 0.9537\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4642047584056854\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa2a8f4d530491aaeecf5ba09f132ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5ea5ff67b84bd499b694d1646d354f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8400\n",
      "AUC: 0.9579\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.450749933719635\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733585cd358845b9a5ef33c2aa720ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a61d926733004d09a2973f5adee9a0a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8720\n",
      "AUC: 0.9615\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4383755028247833\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46db13a3f3b04e2984d12efb137051ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10ed89829bc47069aa5378ba44d595c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8880\n",
      "AUC: 0.9620\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4283220171928406\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb797ff1ed3b4153b093c35aed7ab1d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65262a4f2c894e34b28bb7ae1e65d7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9040\n",
      "AUC: 0.9656\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4170258641242981\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8884bf5407409fb9b877bd8cd8bddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff9a35eafb94a12971c20037b66e839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9000\n",
      "AUC: 0.9669\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.40810224413871765\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec39b5049014a89b722d4812dc38081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10faa7faeeda4663b7b6ebf04d8dc929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9080\n",
      "AUC: 0.9693\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3989730477333069\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6bef237b22c48929a6d120816c420a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07276f08dd2442ddb39c4ce0217974bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9160\n",
      "AUC: 0.9730\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3886931538581848\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b227eff98d4f708b67437b54687769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac1780a4e214a65a6f3ad96bcda9862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9240\n",
      "AUC: 0.9757\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3790704011917114\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7f9acae79a418ab7751423c7d671bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae84af369b73411ea17b4f728e3fc7d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9280\n",
      "AUC: 0.9766\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3731974959373474\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894650f5c0e4457997349a3174b1df88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ca1b3414b34c7fbf27c5c775a3f7d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9280\n",
      "AUC: 0.9775\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.367520809173584\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0008ea72a8401da3ae5ea08e31f3d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8404cf9b56d542699397a004473ce305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9160\n",
      "AUC: 0.9779\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.36424607038497925\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ffc8f1966144b66ad61dc16d621f1f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0f59dd1ada4641852e60eaf77cceba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9120\n",
      "AUC: 0.9796\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.35819339752197266\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af38d3991ee4829a755d90a4341ed4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51b1400725040119c9d2ddb66e56192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8920\n",
      "AUC: 0.9795\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3583759665489197\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26763f9091aa47e89b322c12aa480a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c8f14176c324b0699da7dbd9175f09d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8760\n",
      "AUC: 0.9786\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.36118069291114807\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7829df269dda45398bbecbb3d31b5e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ca669cab344899a8a7f9e753712bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8600\n",
      "AUC: 0.9790\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3625585436820984\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf78aa894be4ac3bf10e9dba1b47020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7d6d2d19f3420085c2d8dd37cfc5bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8240\n",
      "AUC: 0.9787\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3666326403617859\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fbdaf07b1c4fb6a3d17ced518b50c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee7b57e0e4274f5fabee20952c66537f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8200\n",
      "AUC: 0.9778\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.372514933347702\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee7f80521ff4350839541d22f4630e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4866f93be3457298f9e50269d0397e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7760\n",
      "AUC: 0.9740\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.39283594489097595\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e47709a68b44f885f548af1f4c0102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f920cabc392a477fb3e1550fe895ee10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.9725\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.40876996517181396\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ddc7631e4cf4223b7776f956830f2c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c24e16223840b3a3caa2c5b850ac71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.9672\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.44346338510513306\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c415838808194eff969a9907dd838ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016f0560ea1a4948ab0ebbb23d290b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7040\n",
      "AUC: 0.9629\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4677903652191162\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 3/4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e874ea69172487eba1a5e2f967d5597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32d5ef0bc57408ea05591868a9ab86a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.3578\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7646703124046326\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c6eda59e584d7eabf3909b82f4b2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e501adca73fb4235b2497bbb57fb2c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.3447\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8073998093605042\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6019385325f04d42b9c61ed16a1f2f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c37cb5712f41c5a79ccdc2d89812ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.3569\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8571241497993469\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478aa5daf46e4447969beecb24f6b073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b1e6784e35c4a75932e888177261f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.3740\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9122894406318665\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc448f2efb04515bf03ab710f5bc4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c8bf564313b4c308326f7fb76377b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.3892\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9674577116966248\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a325144edbd94968aca8d0c12679431f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a48f5de101f48649771305cbde405fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.4008\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0163524150848389\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74085d552b7241ff86572627dd4743c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa296d3a589341699e1eb0ba7a2b57ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.4124\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.046737551689148\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4558eeec92ed48fcae373f6bf2b71b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a7b1160544479cb65f5f545cd3efca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.4202\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0376032590866089\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4b2ec749154f2096b7b1c4dfc362bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb4f5d163d04ff8845e20688da7082f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.4272\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9943113923072815\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b47fec6d234340b7b38cbf826d1715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e10d749be04d7e8d9f6d2834a929cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.4509\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9544631242752075\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d0d81b6fa8643549d27721fb9011cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc23ddb1b4184551968ee46f5b33b694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.5366\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.900882363319397\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3d1d80f8924616b732b82ab2e4ec17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a164294bbf54f9988e0be589613de80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.6301\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8538217544555664\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91fe73d0e0454b95b887d3868496bbf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa792c9b72747d2b80cd83fbb3bcaf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.7157\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.807612419128418\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9361e655f6493ab90a20b9c90c9c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c052af021d9c40a9b4e86f739f92ed0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.8365\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7581682205200195\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad1e4a466264eafaa058e8022f669ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90795dad9d04d989a8086ff3f2378c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.8946\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7294301986694336\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959eb24e55054519abe433fd16c796b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b2920d2c9da4824bc3d3eb1139522c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.9414\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6935791969299316\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36603df1cf584c70993aea81673abb4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4b82843b9f496aaf6194422099ad96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4880\n",
      "AUC: 0.9606\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6606057286262512\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc3d92f553543378c0843473f4590b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda9d462590d48dcbdabfb062123d4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5240\n",
      "AUC: 0.9677\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.636092483997345\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e3431e67e941d5b13c7947d148478a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55394f5e26b47c894b8ca91789519b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5480\n",
      "AUC: 0.9755\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6007143259048462\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b639d803ebd42639f2c2a129c2d6f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a016d5ddd045ebad558cb1c4e736e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6080\n",
      "AUC: 0.9787\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5747458934783936\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e87a9dcb8c468a9e67e11c4e7858b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f0105f842048e3a4f6e256ead2cb31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7520\n",
      "AUC: 0.9804\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5471512675285339\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b54872005259440f87c4c1e93985e6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b8ac1b43b624115a6206904c8847bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8240\n",
      "AUC: 0.9802\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5269227027893066\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994ae6f5c81d4cc7a854b1c0e23fc294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69dff64d1cc64bbe848e1fac4cd92b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8800\n",
      "AUC: 0.9803\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5050925612449646\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c2e09dc4cf4c0a8cf3a61c21710da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fea4a81ed4a494ca7bfebc771b1040b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9080\n",
      "AUC: 0.9811\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4864676892757416\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9508f255da474545896d804ddf646587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9168920ab1154bef9b32c17425e61cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9400\n",
      "AUC: 0.9809\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46862009167671204\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c085a3b4ccb64e3580175d2e4b113e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef0adbf8d97450985b6e58a3e613c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9480\n",
      "AUC: 0.9813\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.45410534739494324\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078870d8be5a4b44b8c5d391054f42c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19e3d10744b440b808afa2c8186bbaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9440\n",
      "AUC: 0.9816\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.43962836265563965\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2cfda449cb40c2a911eeaabc339d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a7e485a9bc41b883a382f3673c9ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9360\n",
      "AUC: 0.9815\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4254854917526245\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e29f5955884481a74088e2a1b74ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1b9608cbea427292050c18b720a96f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9360\n",
      "AUC: 0.9819\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.41257503628730774\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12a050db0674c98a46aaf1c4fd7468c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b179926e8f64e24a3570ceefd6fe82e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9200\n",
      "AUC: 0.9814\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.40312251448631287\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a621555e9ca54ad4a033b1373aa30805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2a528f6b8e414aa54adbf99b9e3b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9200\n",
      "AUC: 0.9821\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3922138810157776\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e2a9ca635404e89abd50e9ea2594317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b822e292d83d4d7eacefade118f07e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9200\n",
      "AUC: 0.9829\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3806627094745636\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea45391351f4798abccd2fd2f9ab6ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e8521f2fb84d6c8a33553014725a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8960\n",
      "AUC: 0.9827\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.37510231137275696\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5cad75fa8eb4c2e947e080cf0e4fa04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d0b553c98b4a62b393fa3eae92c717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8640\n",
      "AUC: 0.9826\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3690491318702698\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a970714b5f249d691e8cb1e70a32500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee2beeb903c4a31a6d6cc0417dcb957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8600\n",
      "AUC: 0.9829\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.36349326372146606\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d86bfb31684679ba3a79eb8f5bf7d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd6de7cfe29423b8e929039afb96aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8560\n",
      "AUC: 0.9830\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3575969338417053\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e4e25c90fb44128f5507afef9578fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9996102589094c50847f11ec32be082d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8520\n",
      "AUC: 0.9832\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.34994566440582275\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261553e8dcbb4ad38239bac7e421fb30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f404dce4f1943b3a6c0e4f24027af11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8400\n",
      "AUC: 0.9834\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.34980419278144836\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec228c2a9d446639e19d53c61bef891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302d921ce1d44b0197c1d09e06b87dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8360\n",
      "AUC: 0.9836\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.35030269622802734\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2c7bbaea3d4b94b09b4446a05cac75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c92760a8684269b5a2fe438a051bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8360\n",
      "AUC: 0.9837\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3482760787010193\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef452bd16f3499b9bad60883c9c6279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b20b5e250443da82b41a456de7c33e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8200\n",
      "AUC: 0.9835\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3532532751560211\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f1aff460cf42f4a17c2c8f787507c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c62c7e404e43e0bafd3b5895c57923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8040\n",
      "AUC: 0.9834\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3600814640522003\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6edcb637327b490ca95938a4b399bb31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e87dca011d94aeb8ac72972072da7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8120\n",
      "AUC: 0.9836\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.36376574635505676\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b1acedda6b04b42b104ae2e0498533e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2e0643363d413eb4e1bcb28a375a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7960\n",
      "AUC: 0.9836\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3749501705169678\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b17220e9cc454ae18b2d2f456f362181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c2058d6f49a4e54982918d472d9f166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7680\n",
      "AUC: 0.9834\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.39176681637763977\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b0b90e117741ca96858641a44f7382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9596fb15ec24e5599a54cba218080d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.9831\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4122205078601837\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88ec55805ef4e88a375bd8e67cf09f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b555742322f84c82a0e8d18c5738f52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.9822\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4413783550262451\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50aff8b3bb744df9bce46f141d5fcbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb7d3a81a524634967ccfff15d7684e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.9820\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46460089087486267\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4a21d8395f4b71bebd1441e8d13eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df46f37f7f86499b8ccbd17159b1b69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7040\n",
      "AUC: 0.9810\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5206246972084045\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "850925ce9aaa43209f10026c1285e13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41bd0f6ebd884a068ee58d1606e87f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7000\n",
      "AUC: 0.9795\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.564780056476593\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "--- Starting Fold 4/4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f7596babe84606b84913afc709b1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02762265f94a4f72819cff85ad76af50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4104\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7925464510917664\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5e621f0e714872ae0368776154d0c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea7702b5a3c44baa5f383f543a7d1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4246\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8388370275497437\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d47a8d916104e17bbf09d2fa0594fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3213a61314a422387c1891af6c543ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4354\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8921871185302734\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6d2aa3006740109f10720a1cb542b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549c499dfdbe4f54b0a3bde3369adbff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4429\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9488739967346191\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bed7e3e578144aabcb4d1f7b1858854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f69029f00594ea6a23bb70948838484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4494\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9820002317428589\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f51506991d4058b7d27c0bd4ade470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eeea3788b274e668bf866ac020bd59f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4540\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.962270200252533\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e2ea276178948cabd23810430dfe517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1201a70e9fc4c3fbe3a2445571a366d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4607\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9231041669845581\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d990e28839d4bdcae76d624e15fe7f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c18e7bb528bf4870a1ecfba30df86490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4774\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8794955015182495\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e448503389471699717bed085d7282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc28b3c8af2490e968ee1ff72181efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.5194\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.836094856262207\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "097879de61704dbc8e4067b5528f1c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52fcd9e17d704ee995ef550ccef58084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.5893\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7973949909210205\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "430b9f7d8aa04a7ab0fb3bf2f1b0f33b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db94ea1dd6e740ae8b0f86ff9993226d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.6728\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7542611360549927\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51dd691ad8a42f697293b0fb933f662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367d8eeb5146415d9d70cd7fb641a247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.7394\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7173950672149658\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2882015e9c6b4ed19eeaa2ac1454111f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d20f78e01a9476a8d3d1dcf2a7474f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.8237\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6837164163589478\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1df6b73f665453f939a55a51514e1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ba797c8807477593768f17ac9f4fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.8870\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6588457226753235\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0028208132402f8c7983672fc3bb7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4774b80d444e9797f3b9bcc0329a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.9295\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.635445237159729\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c64366747be46bdad7404649a527822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f6fee359d249c3bcc8a987c0281889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5960\n",
      "AUC: 0.9669\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss             0.6011922955513\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ee269f3dd543f897ae11b60b74404b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9580268015694cccab3d4a0f75655761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6080\n",
      "AUC: 0.9783\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5804463028907776\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7666d2b62f542c7adcfbc5f21f149d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c030fc8a49d40bab4cd6cb1801bd18d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6640\n",
      "AUC: 0.9850\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5563154816627502\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ef3b38607e45da8086a01a58a507d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4c2d64a4c84e8683615446f3d77ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.9877\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.536345362663269\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ff4711644e48ba8f346642eba8fd7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76e1e52fa2641feb91609e123487752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.9896\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5204633474349976\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5481f8d48a6a4ac88a1ef9de3d930247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff5c4c3d9ce422b813174fb52a84ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7960\n",
      "AUC: 0.9908\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5062368512153625\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d3cf39f6494a7db84f0d7a0a4d3e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cdfc1c89f534dee9945bfda23eb775b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8760\n",
      "AUC: 0.9916\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4897274971008301\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce82c1aaba5a4904ab2e34cf3d9beeff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa0005c6ab94367b310b010783b23f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9040\n",
      "AUC: 0.9920\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.47598063945770264\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837ea8bb92fa4bddaa33e8c399e6af80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f236984ef04f5dafccbd36ec2b9e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9400\n",
      "AUC: 0.9920\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.46413880586624146\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fed4136d0f6469f833e0b9452b28f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a8954deaf54217a02e930d1b0c77b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9400\n",
      "AUC: 0.9927\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.45240655541419983\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe9980a1d5b4445bb5d12cfb3970134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b35816de8048b1a7486f917d1162e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9440\n",
      "AUC: 0.9927\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.442131370306015\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc904aa8807948fa9fced1fb1495591c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca368c8724c54e93be67729de3f14e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9600\n",
      "AUC: 0.9932\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.43256956338882446\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62af30ded15349408e53c1292e1f4e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b078739d1754d9e8eb1e2b962bf7fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9520\n",
      "AUC: 0.9934\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4233320951461792\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c748aab405414cb16e2c865eaefb4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94445df86d944cf9b99f8d8702d4fdf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9400\n",
      "AUC: 0.9934\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4178410768508911\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0cf19ed5e97475395dd7a3432513917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "280bfa651ca04ef7b215aa5bf28c665d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9240\n",
      "AUC: 0.9945\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.40832072496414185\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1f472d106b41c980b8e80c61289af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d94599c39545ef8db570c8cf9205f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9000\n",
      "AUC: 0.9945\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.40333452820777893\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0918ac93760e4d49b7d92d1ec2f024ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00215e5cf8a4b70b4e1b6b6240e15ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8920\n",
      "AUC: 0.9946\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3970092236995697\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70910bbb3ceb49bb947ead6ed3c34ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e48dab44a54248950aef90f57fff64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8600\n",
      "AUC: 0.9947\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.39271825551986694\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7706198abe16446e9877ca23cdbea486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73cdf2dd7114fd7bc0e63a18ad7cdf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8440\n",
      "AUC: 0.9955\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3874354362487793\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55dbcfbf1c674e709b9234538723b681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e4085d38ad4bea94b2273fdcdb4a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8400\n",
      "AUC: 0.9958\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3857465088367462\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04b8ae1b01643dab5b3d85ad75d8191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dadddb0bddbc4dfc81847608f99f322d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8360\n",
      "AUC: 0.9957\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.381960928440094\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d441022d8a4e7085c170e8224a6b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625f2bf174d24d108b3c8db405244229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8200\n",
      "AUC: 0.9958\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.38210180401802063\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9800f49e3245fd8e7a1f7889bd2a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa28552de104112a1d5cdb6fd752253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7920\n",
      "AUC: 0.9959\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3862249255180359\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9e253d390541fcb27ab752b1d1c1dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae33d294406649cb904364f0410a5ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7680\n",
      "AUC: 0.9959\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.3900529444217682\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05e28a987a140e5a127c25c3435285a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97c0884747d4f31972be3501642f703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7560\n",
      "AUC: 0.9962\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.39183753728866577\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd684dd1e435402489195e8407107923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6938ba301d974844a8f65ca21df711b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.9961\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.39715442061424255\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4ff852d4f74552922c9a0a2d05bdf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d97c59a8a74cd7b2594fc234d20378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.9963\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4049445688724518\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405ca5ffc71143678e7649bdbbabb0a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc14aa70358049ca85cd11f7988f2a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7040\n",
      "AUC: 0.9961\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.42448049783706665\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb3473e7fb0472cb751ce4fe8ee94b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75feead7f9464f77ba15de3227ff0ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7000\n",
      "AUC: 0.9962\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4376722276210785\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e97eb72f4534d7ab8e50a20d172b089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9189dc2d5b754000a4b12d35c484c15f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.9961\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.45417970418930054\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f3bae4c03a4aa29653f8dd7e8ba6a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91777fe7c3504625ba4c962c13c440bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6680\n",
      "AUC: 0.9957\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4867097735404968\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90a00a2880a42faa0a194eb6bdb65aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c4029da5be44d9c86095e53f77e780d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6640\n",
      "AUC: 0.9954\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5291454195976257\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03781bc93e540e9b1dc23ff0cccfc3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e7065e387c4f9baa25175c2cda1bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6520\n",
      "AUC: 0.9949\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5835147500038147\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ff9e72022a4718b45d258070378c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed599b2bd4f4d73bc3cba1cd8899966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6440\n",
      "AUC: 0.9931\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6562725305557251\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1e02f10837432db716833c6de79052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v15.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v15.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56fa9fb3fa0f4a248d5ad8f071726c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6360\n",
      "AUC: 0.9911\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7162198424339294\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "import numpy as np\n",
    "\n",
    "# --- Place any constants or unchanging objects outside the loop ---\n",
    "pl.seed_everything(42, workers=True)\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "#store the weighted classifiers of all the folds\n",
    "list_folds_weighted_clfs = []  # List to store classifiers from all folds\n",
    "#store the best classfiers of all the folds\n",
    "list_folds_best_models = []  # List to store best models from all folds\n",
    "\n",
    "# Dictionary to store the history of each fold\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "\n",
    "# 3. K-fold cross-validation loop\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(train_data_tensor)):\n",
    "    list_weighted_clfs = [] # List to store the models trained at each stage\n",
    "    best_clfs = [] # List to store the best models from each stage\n",
    "    best_model_paths = [] # List to store the path of the best model from each stage\n",
    "    # 1. Instantiate the LightningModule\n",
    "    model = LitClassifier(input_features=2, hidden_units=32, learning_rate=LEARNING_RATE)\n",
    "    print(f\"--- Starting Fold {fold + 1}/{K_FOLDS} ---\")\n",
    "\n",
    "    # 4. Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "\n",
    "    train_loader = data.DataLoader(\n",
    "                      train_data_tensor,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      sampler=train_subsampler,\n",
    "                      num_workers=NUM_WORKERS)\n",
    "    fold_loader = data.DataLoader(\n",
    "                    train_data_tensor,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    sampler=val_subsampler,\n",
    "                    num_workers=NUM_WORKERS)\n",
    "\n",
    "\n",
    "    for i, pos_weight in enumerate(pos_weights):\n",
    "        \n",
    "        model.criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight))  # Set the pos_weight for this stage\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            every_n_epochs=1,                # Save model every epoch\n",
    "            dirpath=f'checkpoints/stage_{i+1}/fold_{fold+1}/',\n",
    "            filename=f'best-model-fold{fold+1}-{{epoch:02d}}',\n",
    "            save_top_k=1,\n",
    "            mode='max',\n",
    "        )\n",
    "        \n",
    "        # 3. Instantiate a NEW Trainer for this specific stage\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator='gpu',\n",
    "            devices=1,\n",
    "            #strategy='ddp_notebook',\n",
    "            max_epochs=NUM_EPOCHS, # Number of epochs for THIS stage\n",
    "            callbacks=[checkpoint_callback, progress_bar],\n",
    "            logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=f\"stage_{i+1}_fold_{fold+1}_ratio_{pos_weight}\"),\n",
    "            precision='16-mixed'\n",
    "            )\n",
    "        \n",
    "        # 4. Train the model. It will start with weights from the previous stage.\n",
    "        trainer.fit(model, train_dataloaders=train_loader)\n",
    "        \n",
    "        # 5. Get the path to the best model from THIS stage and store it\n",
    "        if checkpoint_callback.best_model_path:\n",
    "            best_path_this_stage = checkpoint_callback.best_model_path\n",
    "            print(f\"--- Fold {fold+1} Stage {i+1} complete. Best model path: {best_path_this_stage} ---\")\n",
    "            best_model_paths.append(best_path_this_stage)\n",
    "            \n",
    "            # 6. CRITICAL: Load the best weights back into the model object\n",
    "            # This ensures we carry forward the BEST model to the next stage, not the last.\n",
    "            print(f\"Loading best weights from {best_path_this_stage} to continue...\")\n",
    "            model = LitClassifier.load_from_checkpoint(best_path_this_stage, strict=False)  # Use strict=False to ignore missing keys if any\n",
    "        else:\n",
    "            print(f\"--- Fold {fold+1} Stage {i+1} complete. No checkpoint was saved. ---\")\n",
    "            # If no checkpoint was saved, the model object will just have the weights from the last epoch.\n",
    "\n",
    "        # 7. Test the model after each stage\n",
    "        print(f\"\\n--- Testing model after Fold {fold+1} Stage {i+1} ---\")\n",
    "        trainer.test(model, dataloaders=fold_loader, ckpt_path=best_path_this_stage)\n",
    "        results_classifier = model.last_test_results.copy()\n",
    "        current_model = {\n",
    "            \"model\": model,\n",
    "            \"fpr\": results_classifier[\"fpr\"],\n",
    "            \"tpr\": results_classifier[\"tpr\"],\n",
    "            \"threshold\": results_classifier[\"threshold\"],\n",
    "            \"full_roc\": results_classifier[\"full_roc\"]\n",
    "        }\n",
    "        list_weighted_clfs.append(current_model)\n",
    "        best_clfs = get_best_roc_envelope(list_weighted_clfs, results_original_roc)\n",
    "    list_folds_weighted_clfs.append(list_weighted_clfs)\n",
    "    list_folds_best_models.append(best_clfs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6b93abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to pickle/NN_data1_weighted.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_models': [[{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.8360656),\n",
       "    'threshold': np.float16(0.899)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0078125),\n",
       "    'tpr': np.float32(0.8442623),\n",
       "    'threshold': np.float16(0.9165)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.015625),\n",
       "    'tpr': np.float32(0.8606557),\n",
       "    'threshold': np.float16(0.8125)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0234375),\n",
       "    'tpr': np.float32(0.8852459),\n",
       "    'threshold': np.float16(0.7646)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.03125),\n",
       "    'tpr': np.float32(0.90163934),\n",
       "    'threshold': np.float16(0.8286)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.046875),\n",
       "    'tpr': np.float32(0.90983605),\n",
       "    'threshold': np.float16(0.758)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0546875),\n",
       "    'tpr': np.float32(0.91803277),\n",
       "    'threshold': np.float16(0.7646)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0625),\n",
       "    'tpr': np.float32(0.93442625),\n",
       "    'threshold': np.float16(0.683)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.078125),\n",
       "    'tpr': np.float32(0.94262296),\n",
       "    'threshold': np.float16(0.6865)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0859375),\n",
       "    'tpr': np.float32(0.9590164),\n",
       "    'threshold': np.float16(0.5513)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.09375),\n",
       "    'tpr': np.float32(0.9672131),\n",
       "    'threshold': np.float16(0.542)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1171875),\n",
       "    'tpr': np.float32(0.9836066),\n",
       "    'threshold': np.float16(0.529)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1328125),\n",
       "    'tpr': np.float32(0.9918033),\n",
       "    'threshold': np.float16(0.4846)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1875),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.4663)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.4090909),\n",
       "    'threshold': np.float16(0.4478)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.008474576),\n",
       "    'tpr': np.float32(0.5530303),\n",
       "    'threshold': np.float16(0.7744)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.016949153),\n",
       "    'tpr': np.float32(0.75),\n",
       "    'threshold': np.float16(0.802)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.025423728),\n",
       "    'tpr': np.float32(0.7878788),\n",
       "    'threshold': np.float16(0.7056)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.033898305),\n",
       "    'tpr': np.float32(0.79545456),\n",
       "    'threshold': np.float16(0.6978)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.042372882),\n",
       "    'tpr': np.float32(0.8712121),\n",
       "    'threshold': np.float16(0.7983)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.050847456),\n",
       "    'tpr': np.float32(0.9469697),\n",
       "    'threshold': np.float16(0.603)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.06779661),\n",
       "    'tpr': np.float32(0.9621212),\n",
       "    'threshold': np.float16(0.6304)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.076271184),\n",
       "    'tpr': np.float32(0.97727275),\n",
       "    'threshold': np.float16(0.689)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.10169491),\n",
       "    'tpr': np.float32(0.9848485),\n",
       "    'threshold': np.float16(0.6123)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.13559322),\n",
       "    'tpr': np.float32(0.99242425),\n",
       "    'threshold': np.float16(0.527)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.19491525),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.4407)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.7076923),\n",
       "    'threshold': np.float16(0.5986)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.008333334),\n",
       "    'tpr': np.float32(0.84615386),\n",
       "    'threshold': np.float16(0.3958)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.016666668),\n",
       "    'tpr': np.float32(0.88461536),\n",
       "    'threshold': np.float16(0.4116)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.025),\n",
       "    'tpr': np.float32(0.9),\n",
       "    'threshold': np.float16(0.4023)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.033333335),\n",
       "    'tpr': np.float32(0.93846154),\n",
       "    'threshold': np.float16(0.7163)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.041666668),\n",
       "    'tpr': np.float32(0.9461538),\n",
       "    'threshold': np.float16(0.7476)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.05),\n",
       "    'tpr': np.float32(0.95384616),\n",
       "    'threshold': np.float16(0.688)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.06666667),\n",
       "    'tpr': np.float32(0.96153843),\n",
       "    'threshold': np.float16(0.414)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.075),\n",
       "    'tpr': np.float32(0.9692308),\n",
       "    'threshold': np.float16(0.616)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1),\n",
       "    'tpr': np.float32(0.97692305),\n",
       "    'threshold': np.float16(0.617)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.125),\n",
       "    'tpr': np.float32(0.9846154),\n",
       "    'threshold': np.float16(0.7036)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.34166667),\n",
       "    'tpr': np.float32(0.99230766),\n",
       "    'threshold': np.float16(0.355)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.39166668),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.4734)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.8189655),\n",
       "    'threshold': np.float16(0.815)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0074626864),\n",
       "    'tpr': np.float32(0.92241377),\n",
       "    'threshold': np.float16(0.7886)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.014925373),\n",
       "    'tpr': np.float32(0.94827586),\n",
       "    'threshold': np.float16(0.8984)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.029850746),\n",
       "    'tpr': np.float32(0.95689654),\n",
       "    'threshold': np.float16(0.627)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.03731343),\n",
       "    'tpr': np.float32(0.98275864),\n",
       "    'threshold': np.float16(0.708)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.04477612),\n",
       "    'tpr': np.float32(0.9913793),\n",
       "    'threshold': np.float16(0.8516)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.05970149),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.672)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}]],\n",
       " 'weighted_clfs': [[{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.1640625, 0.1953125, 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.296875 , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.4921875,\n",
       "            0.5      , 0.5      , 0.5      , 0.5      , 0.5      , 0.5      ,\n",
       "            0.5      , 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.6171875, 0.6328125, 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.65625  , 0.6640625, 0.6640625,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.7109375, 0.7109375, 0.7109375, 0.71875  ,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.765625 , 0.78125  , 0.78125  , 0.78125  ,\n",
       "            0.7890625, 0.7890625, 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.8671875, 0.8671875, 0.875    , 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.921875 , 0.9296875, 0.9375   , 0.9375   , 0.9453125,\n",
       "            0.9453125, 0.9453125, 0.9453125, 0.953125 , 0.953125 , 0.953125 ,\n",
       "            0.953125 , 0.953125 , 0.9609375, 0.9609375, 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.984375 , 0.984375 , 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.01639344, 0.01639344, 0.02459016,\n",
       "            0.03278688, 0.04098361, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.07377049, 0.08196721, 0.09016393, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.36885247, 0.37704918, 0.37704918,\n",
       "            0.3852459 , 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.46721312, 0.46721312, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.56557375, 0.57377046,\n",
       "            0.57377046, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6803279 ,\n",
       "            0.6885246 , 0.6885246 , 0.704918  , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.7295082 , 0.73770493, 0.73770493,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.795082  , 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8278689 , 0.8278689 , 0.8278689 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4766, 0.474 , 0.4734, 0.4724, 0.472 , 0.4714, 0.4712,\n",
       "            0.471 , 0.4692, 0.469 , 0.468 , 0.4675, 0.4668, 0.4663, 0.466 ,\n",
       "            0.4658, 0.4656, 0.4653, 0.465 , 0.4648, 0.4646, 0.464 , 0.4639,\n",
       "            0.463 , 0.4626, 0.4624, 0.4612, 0.4607, 0.4595, 0.4568, 0.4558,\n",
       "            0.4556, 0.4548, 0.4546, 0.454 , 0.4487, 0.446 , 0.4446, 0.443 ,\n",
       "            0.4424, 0.4414, 0.4404, 0.438 , 0.4373, 0.4346, 0.4324, 0.43  ,\n",
       "            0.4282, 0.426 , 0.4248, 0.4216, 0.418 , 0.4177, 0.417 , 0.4167,\n",
       "            0.4155, 0.4148, 0.413 , 0.4126, 0.4119, 0.41  , 0.4097, 0.4084,\n",
       "            0.4075, 0.4055, 0.4038, 0.402 , 0.401 , 0.3997, 0.3994, 0.3992,\n",
       "            0.399 , 0.397 , 0.3958, 0.3955, 0.3936, 0.3906, 0.389 , 0.3882,\n",
       "            0.3877, 0.387 , 0.3867, 0.3862, 0.386 , 0.3855, 0.3853, 0.3843,\n",
       "            0.3833, 0.382 , 0.3816, 0.379 , 0.3767, 0.3762, 0.3755, 0.3752,\n",
       "            0.3748, 0.371 , 0.3708, 0.3704, 0.37  , 0.3699, 0.368 , 0.3674,\n",
       "            0.367 , 0.3667, 0.3657, 0.3652, 0.3638, 0.3635, 0.3625, 0.3606,\n",
       "            0.3604, 0.3594, 0.3582, 0.358 , 0.3577, 0.3574, 0.3572, 0.3567,\n",
       "            0.3562, 0.3552, 0.3533, 0.3525, 0.352 , 0.3518, 0.3516, 0.3513,\n",
       "            0.3508, 0.35  , 0.3477, 0.3464, 0.3462, 0.346 , 0.3433, 0.343 ,\n",
       "            0.3423, 0.3418, 0.3406, 0.34  , 0.3396, 0.3394, 0.339 , 0.338 ,\n",
       "            0.3376, 0.3367, 0.3364, 0.3357, 0.3354, 0.3347, 0.3345, 0.3342,\n",
       "            0.334 , 0.3337, 0.3335, 0.3323, 0.3318, 0.3313, 0.3296, 0.3286,\n",
       "            0.3276, 0.327 , 0.326 , 0.325 , 0.3245, 0.324 , 0.3228, 0.322 ,\n",
       "            0.3208, 0.32  , 0.3196, 0.3193, 0.319 , 0.3179, 0.3174, 0.3167,\n",
       "            0.316 , 0.3157, 0.3152, 0.3135, 0.313 , 0.3115, 0.3103, 0.31  ,\n",
       "            0.3098, 0.3086, 0.3083, 0.3076, 0.3052, 0.3037, 0.3035, 0.3032,\n",
       "            0.3022, 0.3015, 0.2996, 0.2993, 0.2964, 0.2952, 0.295 , 0.2942,\n",
       "            0.291 , 0.2908, 0.29  , 0.2876, 0.2842, 0.284 , 0.2832, 0.279 ,\n",
       "            0.273 , 0.2725, 0.264 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.0390625, 0.0546875,\n",
       "            0.0625   , 0.0859375, 0.09375  , 0.109375 , 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.171875 ,\n",
       "            0.1796875, 0.1953125, 0.203125 , 0.2109375, 0.2265625, 0.2421875,\n",
       "            0.25     , 0.265625 , 0.2734375, 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.4296875, 0.4375   , 0.4453125, 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.6171875, 0.625    , 0.625    ,\n",
       "            0.6328125, 0.6328125, 0.6328125, 0.640625 , 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.6953125, 0.703125 , 0.7109375, 0.7109375,\n",
       "            0.71875  , 0.71875  , 0.71875  , 0.7265625, 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.7421875, 0.75     , 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.78125  , 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.796875 , 0.8046875, 0.8125   , 0.8125   , 0.8125   ,\n",
       "            0.8203125, 0.8359375, 0.8359375, 0.84375  , 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.8671875, 0.875    , 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.8984375, 0.9140625, 0.921875 , 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.953125 , 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.01639344, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.22950819, 0.24590164, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.6393443 , 0.6393443 ,\n",
       "            0.647541  , 0.647541  , 0.647541  , 0.6557377 , 0.6557377 ,\n",
       "            0.6639344 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.71311474, 0.71311474, 0.7295082 , 0.7295082 ,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4568, 0.455 , 0.4548, 0.451 , 0.4507, 0.4497, 0.4478,\n",
       "            0.4475, 0.4473, 0.4465, 0.4463, 0.4458, 0.4456, 0.445 , 0.4448,\n",
       "            0.4446, 0.444 , 0.4436, 0.4434, 0.443 , 0.4424, 0.4417, 0.4412,\n",
       "            0.44  , 0.439 , 0.437 , 0.4365, 0.4363, 0.436 , 0.435 , 0.4343,\n",
       "            0.433 , 0.431 , 0.4282, 0.4265, 0.426 , 0.4248, 0.4238, 0.4229,\n",
       "            0.421 , 0.413 , 0.411 , 0.4094, 0.4077, 0.407 , 0.404 , 0.4014,\n",
       "            0.3997, 0.3953, 0.393 , 0.3916, 0.3904, 0.3877, 0.384 , 0.3762,\n",
       "            0.3738, 0.371 , 0.3704, 0.3687, 0.3684, 0.368 , 0.3667, 0.3638,\n",
       "            0.3633, 0.361 , 0.3594, 0.358 , 0.3567, 0.356 , 0.3547, 0.3533,\n",
       "            0.3513, 0.351 , 0.3503, 0.3481, 0.3472, 0.347 , 0.3447, 0.3438,\n",
       "            0.3435, 0.3433, 0.343 , 0.3413, 0.339 , 0.3386, 0.3381, 0.3372,\n",
       "            0.3342, 0.3335, 0.3323, 0.3315, 0.3306, 0.3296, 0.3293, 0.3289,\n",
       "            0.328 , 0.3274, 0.326 , 0.3257, 0.3247, 0.324 , 0.3237, 0.3206,\n",
       "            0.3196, 0.3174, 0.3164, 0.3162, 0.3142, 0.3125, 0.3096, 0.309 ,\n",
       "            0.3086, 0.3066, 0.3062, 0.306 , 0.3057, 0.3054, 0.3047, 0.3044,\n",
       "            0.304 , 0.3037, 0.3015, 0.3013, 0.301 , 0.3005, 0.2998, 0.2993,\n",
       "            0.2966, 0.294 , 0.2937, 0.293 , 0.2927, 0.2908, 0.2903, 0.29  ,\n",
       "            0.2896, 0.2869, 0.2864, 0.286 , 0.2856, 0.2844, 0.284 , 0.2834,\n",
       "            0.2832, 0.2815, 0.2795, 0.2776, 0.2773, 0.2769, 0.2747, 0.273 ,\n",
       "            0.2727, 0.2717, 0.271 , 0.2708, 0.27  , 0.269 , 0.2683, 0.268 ,\n",
       "            0.2673, 0.2668, 0.2664, 0.2651, 0.265 , 0.2644, 0.264 , 0.2627,\n",
       "            0.2622, 0.262 , 0.2617, 0.2612, 0.261 , 0.2595, 0.2588, 0.2573,\n",
       "            0.2556, 0.2554, 0.255 , 0.2522, 0.2512, 0.25  , 0.2496, 0.2485,\n",
       "            0.2473, 0.247 , 0.2458, 0.2456, 0.2455, 0.2452, 0.2448, 0.2444,\n",
       "            0.2433, 0.243 , 0.2417, 0.2413, 0.2394, 0.2372, 0.2363, 0.2362,\n",
       "            0.2334, 0.2332, 0.2311, 0.2302, 0.2277, 0.2274, 0.226 , 0.224 ,\n",
       "            0.2224, 0.22  , 0.2095, 0.2089, 0.2074, 0.2048, 0.2032, 0.1892],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.0234375, 0.03125  , 0.0390625, 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.109375 ,\n",
       "            0.125    , 0.1328125, 0.1484375, 0.15625  , 0.1640625, 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.5859375, 0.59375  , 0.59375  , 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.6328125, 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6875   , 0.6875   , 0.6875   , 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.7734375,\n",
       "            0.78125  , 0.78125  , 0.7890625, 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.875    , 0.8828125,\n",
       "            0.890625 , 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.02459016, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.08196721, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.23770492, 0.25409836, 0.26229507, 0.26229507,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.3114754 , 0.3114754 ,\n",
       "            0.31967214, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.46721312, 0.47540984, 0.47540984, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.60655737,\n",
       "            0.6147541 , 0.6147541 , 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.71311474, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.852459  , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4368, 0.436 , 0.4314, 0.4302, 0.43  , 0.4297, 0.4294,\n",
       "            0.4287, 0.4285, 0.426 , 0.4253, 0.4246, 0.423 , 0.4226, 0.422 ,\n",
       "            0.4214, 0.421 , 0.4204, 0.4202, 0.4192, 0.4185, 0.4182, 0.4175,\n",
       "            0.4172, 0.4155, 0.4143, 0.4136, 0.4133, 0.411 , 0.4102, 0.41  ,\n",
       "            0.4087, 0.4084, 0.4082, 0.4067, 0.4055, 0.4053, 0.402 , 0.3997,\n",
       "            0.397 , 0.3965, 0.3945, 0.393 , 0.391 , 0.38  , 0.379 , 0.3784,\n",
       "            0.3752, 0.3726, 0.3723, 0.3706, 0.3667, 0.3652, 0.3635, 0.3625,\n",
       "            0.36  , 0.3594, 0.3538, 0.35  , 0.3496, 0.3425, 0.3398, 0.3381,\n",
       "            0.3342, 0.3318, 0.3293, 0.328 , 0.3218, 0.3215, 0.3213, 0.321 ,\n",
       "            0.32  , 0.3171, 0.3164, 0.3157, 0.313 , 0.3108, 0.3105, 0.3098,\n",
       "            0.3079, 0.307 , 0.306 , 0.304 , 0.3032, 0.302 , 0.3018, 0.3008,\n",
       "            0.297 , 0.2966, 0.2957, 0.2947, 0.2932, 0.2927, 0.2917, 0.2915,\n",
       "            0.2903, 0.2886, 0.286 , 0.2854, 0.283 , 0.2822, 0.2803, 0.279 ,\n",
       "            0.2776, 0.277 , 0.276 , 0.2754, 0.2744, 0.2742, 0.274 , 0.2715,\n",
       "            0.2695, 0.2693, 0.2683, 0.2664, 0.2656, 0.2646, 0.2642, 0.2637,\n",
       "            0.2634, 0.2625, 0.2583, 0.2563, 0.2556, 0.2551, 0.255 , 0.2532,\n",
       "            0.2502, 0.2496, 0.2477, 0.2474, 0.2467, 0.2466, 0.2463, 0.2452,\n",
       "            0.2444, 0.2428, 0.2424, 0.2418, 0.2415, 0.2405, 0.239 , 0.2383,\n",
       "            0.2363, 0.2335, 0.2334, 0.2332, 0.2328, 0.2306, 0.2302, 0.228 ,\n",
       "            0.2257, 0.2255, 0.2251, 0.224 , 0.2233, 0.2222, 0.2218, 0.2205,\n",
       "            0.2203, 0.2179, 0.2173, 0.2163, 0.2157, 0.2152, 0.2133, 0.2128,\n",
       "            0.2123, 0.2115, 0.211 , 0.2104, 0.2098, 0.2096, 0.2095, 0.208 ,\n",
       "            0.2069, 0.2064, 0.2053, 0.2045, 0.2039, 0.2029, 0.2026, 0.2024,\n",
       "            0.2021, 0.2009, 0.2006, 0.1993, 0.1991, 0.1964, 0.1962, 0.1948,\n",
       "            0.1929, 0.1913, 0.1896, 0.1885, 0.1873, 0.1871, 0.185 , 0.1835,\n",
       "            0.1829, 0.1826, 0.1824, 0.1823, 0.1819, 0.1803, 0.1797, 0.1763,\n",
       "            0.1757, 0.1744, 0.1736, 0.1731, 0.1719, 0.171 , 0.1686, 0.1685,\n",
       "            0.1658, 0.1656, 0.1619, 0.1611, 0.1583, 0.1482, 0.1464, 0.1453,\n",
       "            0.1448, 0.1414, 0.1312], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.6015625, 0.6015625, 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.6015625, 0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.6328125, 0.6328125, 0.6328125, 0.640625 , 0.640625 ,\n",
       "            0.6484375, 0.6484375, 0.6484375, 0.65625  , 0.6640625, 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6875   , 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.02459016,\n",
       "            0.03278688, 0.04098361, 0.04918033, 0.05737705, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.2704918 , 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.30327868, 0.3114754 ,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36065573, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6885246 , 0.6967213 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.72131145,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4177 , 0.4175 , 0.417  , 0.4136 , 0.413  , 0.4116 ,\n",
       "            0.4094 , 0.4087 , 0.4067 , 0.4058 , 0.4038 , 0.4036 , 0.4028 ,\n",
       "            0.4014 , 0.401  , 0.3992 , 0.399  , 0.3984 , 0.3982 , 0.3975 ,\n",
       "            0.3972 , 0.3958 , 0.3948 , 0.394  , 0.3938 , 0.3936 , 0.3926 ,\n",
       "            0.3904 , 0.3892 , 0.3884 , 0.3882 , 0.3853 , 0.3838 , 0.383  ,\n",
       "            0.3823 , 0.3813 , 0.3806 , 0.379  , 0.3782 , 0.3765 , 0.373  ,\n",
       "            0.372  , 0.3691 , 0.3667 , 0.3662 , 0.3645 , 0.3625 , 0.3608 ,\n",
       "            0.3499 , 0.3489 , 0.347  , 0.345  , 0.342  , 0.3386 , 0.3376 ,\n",
       "            0.334  , 0.3325 , 0.33   , 0.3296 , 0.323  , 0.316  , 0.3154 ,\n",
       "            0.3115 , 0.3079 , 0.302  , 0.3    , 0.296  , 0.2927 , 0.2908 ,\n",
       "            0.2864 , 0.2834 , 0.28   , 0.2795 , 0.2793 , 0.2788 , 0.2786 ,\n",
       "            0.2756 , 0.2751 , 0.273  , 0.2712 , 0.2703 , 0.2693 , 0.2664 ,\n",
       "            0.2659 , 0.2656 , 0.2654 , 0.2651 , 0.2646 , 0.2585 , 0.2583 ,\n",
       "            0.2573 , 0.257  , 0.2537 , 0.2534 , 0.253  , 0.251  , 0.2505 ,\n",
       "            0.249  , 0.2489 , 0.2487 , 0.2483 , 0.248  , 0.2463 , 0.2462 ,\n",
       "            0.2445 , 0.2411 , 0.2397 , 0.2372 , 0.2358 , 0.2352 , 0.235  ,\n",
       "            0.233  , 0.2328 , 0.2313 , 0.2306 , 0.2281 , 0.2278 , 0.2272 ,\n",
       "            0.2261 , 0.2251 , 0.2212 , 0.2205 , 0.219  , 0.2186 , 0.2166 ,\n",
       "            0.2148 , 0.214  , 0.212  , 0.2096 , 0.2094 , 0.2091 , 0.2086 ,\n",
       "            0.2081 , 0.2056 , 0.2048 , 0.2047 , 0.2034 , 0.202  , 0.2004 ,\n",
       "            0.2001 , 0.1998 , 0.1971 , 0.1964 , 0.1958 , 0.1953 , 0.1946 ,\n",
       "            0.1917 , 0.1915 , 0.1893 , 0.187  , 0.1869 , 0.1852 , 0.1849 ,\n",
       "            0.1848 , 0.1841 , 0.1821 , 0.1815 , 0.1812 , 0.181  , 0.1805 ,\n",
       "            0.1791 , 0.1787 , 0.1782 , 0.1771 , 0.1757 , 0.1749 , 0.1744 ,\n",
       "            0.1738 , 0.1721 , 0.1711 , 0.1709 , 0.1703 , 0.1697 , 0.169  ,\n",
       "            0.1677 , 0.1675 , 0.1666 , 0.1656 , 0.1652 , 0.1648 , 0.1644 ,\n",
       "            0.1641 , 0.1622 , 0.1615 , 0.161  , 0.1609 , 0.1603 , 0.1594 ,\n",
       "            0.1577 , 0.1572 , 0.1554 , 0.1545 , 0.1542 , 0.1538 , 0.1528 ,\n",
       "            0.1526 , 0.15   , 0.1488 , 0.1476 , 0.1469 , 0.1455 , 0.1439 ,\n",
       "            0.141  , 0.1406 , 0.1388 , 0.1376 , 0.1351 , 0.1349 , 0.1348 ,\n",
       "            0.1337 , 0.1335 , 0.1334 , 0.1318 , 0.1317 , 0.1305 , 0.129  ,\n",
       "            0.1263 , 0.12463, 0.1245 , 0.1235 , 0.12335, 0.1226 , 0.1214 ,\n",
       "            0.1178 , 0.1158 , 0.1124 , 0.11127, 0.1086 , 0.1063 , 0.10126,\n",
       "            0.0977 , 0.0967 , 0.0945 , 0.0898 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0703125, 0.078125 , 0.09375  , 0.1015625,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.578125 , 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.6171875, 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.640625 , 0.6484375, 0.6640625, 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.7109375, 0.7109375, 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.71311474, 0.72131145, 0.72131145,\n",
       "            0.73770493, 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.795082  , 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8770492 , 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3987 , 0.398  , 0.3962 , 0.3948 , 0.3945 , 0.393  ,\n",
       "            0.3892 , 0.3882 , 0.387  , 0.3845 , 0.382  , 0.381  , 0.3806 ,\n",
       "            0.3787 , 0.3784 , 0.3755 , 0.3752 , 0.374  , 0.3735 , 0.3733 ,\n",
       "            0.3718 , 0.3706 , 0.3696 , 0.369  , 0.3687 , 0.3667 , 0.3652 ,\n",
       "            0.363  , 0.3628 , 0.3623 , 0.3582 , 0.356  , 0.355  , 0.353  ,\n",
       "            0.3518 , 0.351  , 0.3496 , 0.3472 , 0.345  , 0.3433 , 0.3423 ,\n",
       "            0.3389 , 0.3357 , 0.3335 , 0.3313 , 0.3245 , 0.323  , 0.32   ,\n",
       "            0.3137 , 0.308  , 0.3074 , 0.3066 , 0.3044 , 0.3042 , 0.303  ,\n",
       "            0.3003 , 0.295  , 0.2878 , 0.2834 , 0.2793 , 0.2788 , 0.2747 ,\n",
       "            0.2634 , 0.263  , 0.2627 , 0.2605 , 0.258  , 0.2559 , 0.255  ,\n",
       "            0.2498 , 0.2462 , 0.2444 , 0.2426 , 0.2406 , 0.2405 , 0.2401 ,\n",
       "            0.2378 , 0.237  , 0.2332 , 0.2328 , 0.2322 , 0.2316 , 0.2302 ,\n",
       "            0.2285 , 0.2274 , 0.2234 , 0.2216 , 0.2191 , 0.2189 , 0.2177 ,\n",
       "            0.2175 , 0.2167 , 0.2166 , 0.2161 , 0.215  , 0.2134 , 0.2115 ,\n",
       "            0.2108 , 0.209  , 0.2089 , 0.2085 , 0.2084 , 0.208  , 0.2069 ,\n",
       "            0.2064 , 0.206  , 0.2053 , 0.2051 , 0.2042 , 0.2026 , 0.2018 ,\n",
       "            0.2017 , 0.1959 , 0.1952 , 0.1942 , 0.1937 , 0.1927 , 0.1923 ,\n",
       "            0.1913 , 0.1863 , 0.1855 , 0.1853 , 0.1838 , 0.1837 , 0.181  ,\n",
       "            0.1808 , 0.1798 , 0.1796 , 0.1791 , 0.1788 , 0.1787 , 0.1766 ,\n",
       "            0.1764 , 0.1757 , 0.1748 , 0.1716 , 0.1709 , 0.1705 , 0.1699 ,\n",
       "            0.1676 , 0.1672 , 0.1643 , 0.1627 , 0.1616 , 0.1615 , 0.1614 ,\n",
       "            0.1598 , 0.1569 , 0.153  , 0.152  , 0.1511 , 0.1504 , 0.1501 ,\n",
       "            0.1498 , 0.1494 , 0.1477 , 0.1473 , 0.1461 , 0.1456 , 0.1453 ,\n",
       "            0.145  , 0.1427 , 0.1411 , 0.1409 , 0.1395 , 0.1394 , 0.1393 ,\n",
       "            0.139  , 0.1389 , 0.1377 , 0.1376 , 0.135  , 0.1349 , 0.1318 ,\n",
       "            0.1312 , 0.1309 , 0.1298 , 0.1278 , 0.1277 , 0.1274 , 0.1238 ,\n",
       "            0.12317, 0.12305, 0.1226 , 0.1214 , 0.12024, 0.119  , 0.1172 ,\n",
       "            0.11536, 0.1152 , 0.1142 , 0.1128 , 0.1122 , 0.1118 , 0.111  ,\n",
       "            0.1095 , 0.10895, 0.1076 , 0.1054 , 0.10486, 0.1032 , 0.1021 ,\n",
       "            0.1011 , 0.09875, 0.09753, 0.09686, 0.09656, 0.0964 , 0.096  ,\n",
       "            0.0955 , 0.09515, 0.09485, 0.0927 , 0.0914 , 0.0901 , 0.0899 ,\n",
       "            0.088  , 0.0873 , 0.0868 , 0.0862 , 0.0836 , 0.0804 , 0.0786 ,\n",
       "            0.0761 , 0.07544, 0.075  , 0.0729 , 0.0689 , 0.0643 , 0.06323,\n",
       "            0.06165, 0.06064], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.421875 , 0.4296875,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.6171875,\n",
       "            0.6171875, 0.625    , 0.640625 , 0.640625 , 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.671875 , 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.02459016, 0.02459016, 0.02459016, 0.03278688,\n",
       "            0.03278688, 0.03278688, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5081967 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59836066, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.63114756, 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.377  , 0.3765 , 0.376  , 0.3743 , 0.3735 , 0.3706 ,\n",
       "            0.3665 , 0.3662 , 0.3643 , 0.3638 , 0.361  , 0.3606 , 0.3584 ,\n",
       "            0.3582 , 0.358  , 0.3564 , 0.3542 , 0.353  , 0.352  , 0.3513 ,\n",
       "            0.351  , 0.3508 , 0.3481 , 0.348  , 0.3474 , 0.3464 , 0.3462 ,\n",
       "            0.34   , 0.3398 , 0.3396 , 0.3386 , 0.3384 , 0.3337 , 0.333  ,\n",
       "            0.3313 , 0.3308 , 0.3267 , 0.3254 , 0.325  , 0.3228 , 0.322  ,\n",
       "            0.3208 , 0.3193 , 0.3154 , 0.3135 , 0.313  , 0.311  , 0.3076 ,\n",
       "            0.306  , 0.2964 , 0.2944 , 0.2905 , 0.29   , 0.2852 , 0.2847 ,\n",
       "            0.2832 , 0.2808 , 0.2805 , 0.2793 , 0.2703 , 0.2664 , 0.2617 ,\n",
       "            0.258  , 0.2566 , 0.2527 , 0.2487 , 0.241  , 0.2402 , 0.2372 ,\n",
       "            0.2368 , 0.2351 , 0.2338 , 0.2319 , 0.2307 , 0.2306 , 0.228  ,\n",
       "            0.2261 , 0.2195 , 0.2186 , 0.2152 , 0.2148 , 0.2147 , 0.2128 ,\n",
       "            0.2124 , 0.2073 , 0.2069 , 0.2064 , 0.206  , 0.2054 , 0.2045 ,\n",
       "            0.2034 , 0.2024 , 0.1991 , 0.1974 , 0.1973 , 0.1971 , 0.1956 ,\n",
       "            0.1948 , 0.1941 , 0.1927 , 0.1917 , 0.1915 , 0.1907 , 0.1898 ,\n",
       "            0.1891 , 0.1882 , 0.1869 , 0.1843 , 0.1842 , 0.183  , 0.1829 ,\n",
       "            0.182  , 0.1807 , 0.1798 , 0.1779 , 0.1774 , 0.1746 , 0.1716 ,\n",
       "            0.1705 , 0.1703 , 0.17   , 0.1693 , 0.1688 , 0.1685 , 0.1678 ,\n",
       "            0.1674 , 0.1659 , 0.1658 , 0.1649 , 0.1611 , 0.1606 , 0.1593 ,\n",
       "            0.1575 , 0.1564 , 0.1559 , 0.1545 , 0.1534 , 0.1476 , 0.1471 ,\n",
       "            0.1453 , 0.1434 , 0.1422 , 0.1417 , 0.1416 , 0.1415 , 0.1409 ,\n",
       "            0.1389 , 0.1388 , 0.1384 , 0.138  , 0.1372 , 0.1348 , 0.1344 ,\n",
       "            0.1328 , 0.1317 , 0.13   , 0.1299 , 0.1282 , 0.1271 , 0.126  ,\n",
       "            0.1259 , 0.1245 , 0.1238 , 0.12366, 0.12317, 0.12115, 0.121  ,\n",
       "            0.1198 , 0.1194 , 0.1178 , 0.11755, 0.11615, 0.1158 , 0.11456,\n",
       "            0.1142 , 0.1122 , 0.11127, 0.111  , 0.1084 , 0.108  , 0.1069 ,\n",
       "            0.1063 , 0.1041 , 0.1032 , 0.103  , 0.1025 , 0.1023 , 0.1019 ,\n",
       "            0.10156, 0.0986 , 0.09845, 0.09753, 0.09485, 0.09436, 0.09283,\n",
       "            0.0927 , 0.0925 , 0.0901 , 0.0899 , 0.0883 , 0.0876 , 0.0869 ,\n",
       "            0.08466, 0.08386, 0.08374, 0.08124, 0.08093, 0.0806 , 0.0802 ,\n",
       "            0.0801 , 0.0789 , 0.07837, 0.07764, 0.0774 , 0.07544, 0.075  ,\n",
       "            0.07477, 0.0729 , 0.07056, 0.06995, 0.06964, 0.0672 , 0.065  ,\n",
       "            0.0643 , 0.06305, 0.06064, 0.0602 , 0.05823, 0.05676, 0.0504 ,\n",
       "            0.05032, 0.04977, 0.04822], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.40625  , 0.4140625, 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.46875  ,\n",
       "            0.4765625, 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   , 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.640625 , 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.78125  , 0.7890625, 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.03278688, 0.03278688, 0.03278688,\n",
       "            0.03278688, 0.04098361, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.37704918, 0.3852459 ,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.4262295 , 0.43442622, 0.44262296, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.72131145, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.36   , 0.3586 , 0.3567 , 0.3562 , 0.355  , 0.3547 ,\n",
       "            0.3533 , 0.3484 , 0.348  , 0.3472 , 0.3457 , 0.3433 , 0.3423 ,\n",
       "            0.342  , 0.34   , 0.3389 , 0.3386 , 0.3381 , 0.3362 , 0.3354 ,\n",
       "            0.3335 , 0.333  , 0.3323 , 0.3298 , 0.329  , 0.3271 , 0.3257 ,\n",
       "            0.3237 , 0.3218 , 0.3215 , 0.3198 , 0.3193 , 0.3184 , 0.3179 ,\n",
       "            0.3137 , 0.3132 , 0.3115 , 0.3108 , 0.308  , 0.3079 , 0.3074 ,\n",
       "            0.3054 , 0.304  , 0.3025 , 0.2988 , 0.2952 , 0.2915 , 0.2905 ,\n",
       "            0.2825 , 0.2795 , 0.2786 , 0.2783 , 0.278  , 0.2734 , 0.2732 ,\n",
       "            0.269  , 0.2646 , 0.2642 , 0.2617 , 0.2588 , 0.2534 , 0.2507 ,\n",
       "            0.2458 , 0.2415 , 0.2391 , 0.2355 , 0.2343 , 0.231  , 0.2301 ,\n",
       "            0.2283 , 0.2264 , 0.2257 , 0.2234 , 0.2217 , 0.2166 , 0.2144 ,\n",
       "            0.2118 , 0.2103 , 0.2074 , 0.2069 , 0.205  , 0.2048 , 0.2035 ,\n",
       "            0.2007 , 0.2004 , 0.1996 , 0.1993 , 0.1989 , 0.1981 , 0.1965 ,\n",
       "            0.1964 , 0.1956 , 0.1943 , 0.1923 , 0.1919 , 0.1904 , 0.1887 ,\n",
       "            0.1886 , 0.1885 , 0.1865 , 0.1859 , 0.1853 , 0.1838 , 0.1823 ,\n",
       "            0.1819 , 0.1807 , 0.18   , 0.1792 , 0.1781 , 0.1774 , 0.1755 ,\n",
       "            0.1747 , 0.1744 , 0.174  , 0.1737 , 0.1724 , 0.1716 , 0.1707 ,\n",
       "            0.1687 , 0.1675 , 0.1671 , 0.1664 , 0.1659 , 0.165  , 0.1648 ,\n",
       "            0.1643 , 0.1641 , 0.162  , 0.1617 , 0.1616 , 0.1586 , 0.1569 ,\n",
       "            0.155  , 0.1536 , 0.153  , 0.1525 , 0.1523 , 0.1516 , 0.1478 ,\n",
       "            0.1431 , 0.1425 , 0.1422 , 0.1416 , 0.1415 , 0.1411 , 0.1409 ,\n",
       "            0.1375 , 0.1371 , 0.1367 , 0.1349 , 0.1348 , 0.1346 , 0.1338 ,\n",
       "            0.1324 , 0.1323 , 0.1309 , 0.1295 , 0.1277 , 0.1263 , 0.1254 ,\n",
       "            0.1242 , 0.1239 , 0.12274, 0.1225 , 0.1216 , 0.12085, 0.1197 ,\n",
       "            0.119  , 0.1188 , 0.118  , 0.1172 , 0.11633, 0.11395, 0.1126 ,\n",
       "            0.11066, 0.1105 , 0.1099 , 0.10913, 0.108  , 0.1052 , 0.10394,\n",
       "            0.1034 , 0.103  , 0.10175, 0.10156, 0.1    , 0.0995 , 0.09875,\n",
       "            0.0986 , 0.09845, 0.0981 , 0.09753, 0.09534, 0.09503, 0.0932 ,\n",
       "            0.093  , 0.09155, 0.0888 , 0.0887 , 0.0883 , 0.0866 , 0.086  ,\n",
       "            0.0859 , 0.08435, 0.0831 , 0.0806 , 0.0804 , 0.0798 , 0.0786 ,\n",
       "            0.07764, 0.0774 , 0.07654, 0.07574, 0.0753 , 0.07465, 0.0745 ,\n",
       "            0.0742 , 0.0732 , 0.0729 , 0.0716 , 0.06964, 0.06805, 0.06696,\n",
       "            0.0666 , 0.0643 , 0.0631 , 0.06232, 0.0603 , 0.058  , 0.0577 ,\n",
       "            0.05582, 0.0551 , 0.04932, 0.04822, 0.0477 , 0.0461 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.140625 , 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125,\n",
       "            0.265625 , 0.28125  , 0.2890625, 0.296875 , 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.3515625, 0.359375 , 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.3984375, 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5703125, 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.03278688, 0.03278688, 0.03278688, 0.03278688, 0.04098361,\n",
       "            0.04098361, 0.04098361, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.44262296, 0.45081967, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.347  , 0.344  , 0.3438 , 0.341  , 0.3367 , 0.3357 ,\n",
       "            0.3352 , 0.3347 , 0.3342 , 0.3337 , 0.3335 , 0.3318 , 0.3313 ,\n",
       "            0.3289 , 0.328  , 0.3274 , 0.3271 , 0.3264 , 0.3257 , 0.325  ,\n",
       "            0.3215 , 0.3213 , 0.3196 , 0.3188 , 0.3186 , 0.317  , 0.3164 ,\n",
       "            0.3162 , 0.3157 , 0.3154 , 0.313  , 0.31   , 0.3093 , 0.3074 ,\n",
       "            0.307  , 0.3064 , 0.3057 , 0.304  , 0.3032 , 0.2998 , 0.2954 ,\n",
       "            0.2947 , 0.2888 , 0.2886 , 0.2861 , 0.2805 , 0.279  , 0.2761 ,\n",
       "            0.2744 , 0.2725 , 0.2715 , 0.2693 , 0.2627 , 0.2625 , 0.261  ,\n",
       "            0.2593 , 0.2556 , 0.2483 , 0.247  , 0.2466 , 0.2455 , 0.244  ,\n",
       "            0.2433 , 0.2421 , 0.2375 , 0.2366 , 0.2356 , 0.2334 , 0.2332 ,\n",
       "            0.2286 , 0.2272 , 0.2251 , 0.223  , 0.2218 , 0.2194 , 0.2191 ,\n",
       "            0.2175 , 0.2173 , 0.2157 , 0.2139 , 0.2134 , 0.2129 , 0.2125 ,\n",
       "            0.2118 , 0.2109 , 0.2106 , 0.2096 , 0.2084 , 0.2079 , 0.207  ,\n",
       "            0.2069 , 0.2048 , 0.2034 , 0.2031 , 0.2018 , 0.2002 , 0.1996 ,\n",
       "            0.1982 , 0.1978 , 0.1976 , 0.1962 , 0.195  , 0.1946 , 0.1943 ,\n",
       "            0.1941 , 0.1934 , 0.1931 , 0.1904 , 0.1898 , 0.189  , 0.1873 ,\n",
       "            0.1871 , 0.1866 , 0.1859 , 0.1858 , 0.185  , 0.1846 , 0.1835 ,\n",
       "            0.183  , 0.1824 , 0.1813 , 0.1798 , 0.1785 , 0.1783 , 0.1774 ,\n",
       "            0.1764 , 0.1757 , 0.1737 , 0.1736 , 0.1735 , 0.1703 , 0.1694 ,\n",
       "            0.1687 , 0.1661 , 0.1659 , 0.1649 , 0.1638 , 0.1608 , 0.1597 ,\n",
       "            0.159  , 0.1584 , 0.158  , 0.1573 , 0.1566 , 0.1559 , 0.1536 ,\n",
       "            0.1525 , 0.1516 , 0.1515 , 0.1499 , 0.1494 , 0.1493 , 0.1492 ,\n",
       "            0.147  , 0.146  , 0.1455 , 0.1453 , 0.1418 , 0.1409 , 0.14   ,\n",
       "            0.139  , 0.1375 , 0.1372 , 0.1371 , 0.1362 , 0.1354 , 0.1338 ,\n",
       "            0.1337 , 0.1335 , 0.1322 , 0.131  , 0.1305 , 0.1278 , 0.1259 ,\n",
       "            0.1254 , 0.1249 , 0.1242 , 0.12335, 0.12305, 0.12274, 0.12244,\n",
       "            0.1201 , 0.1198 , 0.11676, 0.11597, 0.11456, 0.1142 , 0.1138 ,\n",
       "            0.1122 , 0.11163, 0.11145, 0.111  , 0.1101 , 0.10895, 0.10876,\n",
       "            0.1084 , 0.10596, 0.1047 , 0.10175, 0.10144, 0.1011 , 0.1009 ,\n",
       "            0.0997 , 0.09827, 0.09656, 0.0957 , 0.09467, 0.0933 , 0.093  ,\n",
       "            0.09283, 0.09174, 0.0904 , 0.0901 , 0.0891 , 0.0888 , 0.088  ,\n",
       "            0.0876 , 0.0873 , 0.0865 , 0.0859 , 0.0836 , 0.08167, 0.0802 ,\n",
       "            0.0788 , 0.07837, 0.07587, 0.0741 , 0.0717 , 0.06915, 0.06903,\n",
       "            0.06696, 0.0667 , 0.06064, 0.05878, 0.05814, 0.05646],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.015625 , 0.0234375, 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.1640625, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.3515625, 0.359375 , 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.46875  , 0.4765625, 0.4765625, 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5703125, 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.59375  , 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.6171875, 0.625    , 0.625    , 0.6328125,\n",
       "            0.640625 , 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.7890625, 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.03278688, 0.03278688, 0.03278688,\n",
       "            0.03278688, 0.04098361, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.05737705, 0.06557377, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.46721312, 0.48360655, 0.4918033 , 0.4918033 ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3372 , 0.3328 , 0.332  , 0.3298 , 0.3286 , 0.3274 ,\n",
       "            0.3252 , 0.3245 , 0.3242 , 0.3237 , 0.3225 , 0.3223 , 0.3213 ,\n",
       "            0.3206 , 0.32   , 0.3198 , 0.319  , 0.3186 , 0.3184 , 0.3179 ,\n",
       "            0.3174 , 0.315  , 0.3147 , 0.3135 , 0.3125 , 0.3115 , 0.3113 ,\n",
       "            0.3108 , 0.3096 , 0.3093 , 0.309  , 0.3083 , 0.3064 , 0.3062 ,\n",
       "            0.304  , 0.301  , 0.3    , 0.2996 , 0.2983 , 0.2974 , 0.2969 ,\n",
       "            0.2927 , 0.2925 , 0.292  , 0.2903 , 0.2888 , 0.2856 , 0.2852 ,\n",
       "            0.2817 , 0.2786 , 0.2722 , 0.2715 , 0.2664 , 0.266  , 0.265  ,\n",
       "            0.2637 , 0.263  , 0.2605 , 0.2595 , 0.259  , 0.258  , 0.2573 ,\n",
       "            0.255  , 0.2534 , 0.2505 , 0.2462 , 0.246  , 0.2452 , 0.2417 ,\n",
       "            0.2413 , 0.2399 , 0.239  , 0.2388 , 0.2382 , 0.2343 , 0.234  ,\n",
       "            0.2338 , 0.233  , 0.2328 , 0.2323 , 0.231  , 0.2301 , 0.2289 ,\n",
       "            0.2283 , 0.2278 , 0.2273 , 0.2263 , 0.2255 , 0.2244 , 0.2234 ,\n",
       "            0.2233 , 0.2222 , 0.22   , 0.2194 , 0.2173 , 0.2161 , 0.2153 ,\n",
       "            0.2145 , 0.2139 , 0.213  , 0.2128 , 0.2114 , 0.2113 , 0.211  ,\n",
       "            0.2098 , 0.2073 , 0.207  , 0.2069 , 0.2065 , 0.2051 , 0.205  ,\n",
       "            0.2047 , 0.2045 , 0.2042 , 0.2031 , 0.2018 , 0.2012 , 0.1998 ,\n",
       "            0.1995 , 0.1974 , 0.197  , 0.1964 , 0.1952 , 0.195  , 0.1921 ,\n",
       "            0.1917 , 0.189  , 0.1873 , 0.1869 , 0.1827 , 0.1819 , 0.1815 ,\n",
       "            0.181  , 0.1805 , 0.1803 , 0.1798 , 0.179  , 0.1781 , 0.1776 ,\n",
       "            0.1758 , 0.1743 , 0.173  , 0.1725 , 0.1721 , 0.1707 , 0.1683 ,\n",
       "            0.1678 , 0.167  , 0.1666 , 0.1653 , 0.1637 , 0.1622 , 0.1608 ,\n",
       "            0.1598 , 0.1597 , 0.1594 , 0.158  , 0.1565 , 0.1564 , 0.1561 ,\n",
       "            0.1549 , 0.1543 , 0.1527 , 0.1525 , 0.1495 , 0.1493 , 0.1484 ,\n",
       "            0.145  , 0.1447 , 0.1439 , 0.1426 , 0.1423 , 0.1422 , 0.142  ,\n",
       "            0.1371 , 0.1361 , 0.1351 , 0.1344 , 0.1338 , 0.1333 , 0.1329 ,\n",
       "            0.1322 , 0.1315 , 0.1313 , 0.13   , 0.1292 , 0.1289 , 0.1284 ,\n",
       "            0.1251 , 0.12445, 0.1235 , 0.12103, 0.12054, 0.1198 , 0.1192 ,\n",
       "            0.1172 , 0.11554, 0.11475, 0.1126 , 0.1118 , 0.11145, 0.11127,\n",
       "            0.1097 , 0.1095 , 0.1076 , 0.1069 , 0.1065 , 0.1063 , 0.1054 ,\n",
       "            0.10504, 0.1019 , 0.1    , 0.09894, 0.09686, 0.0967 , 0.09515,\n",
       "            0.0939 , 0.0922 , 0.0893 , 0.0866 , 0.0845 , 0.08435, 0.07806,\n",
       "            0.07544, 0.07465, 0.0729 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.015625 , 0.0234375, 0.03125  , 0.046875 , 0.0546875,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.15625  , 0.1640625, 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.2109375, 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.2734375, 0.28125  , 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.296875 , 0.3046875, 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.375    , 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.453125 , 0.453125 , 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.46875  , 0.46875  , 0.4765625, 0.4765625,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5      ,\n",
       "            0.5      , 0.5      , 0.5      , 0.5      , 0.5      , 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.703125 , 0.7109375, 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.04098361, 0.04918033, 0.04918033,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.06557377, 0.07377049,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09016393, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.14754099, 0.1557377 , 0.18032786, 0.18852459, 0.20491803,\n",
       "            0.21311475, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.56557375, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.795082  , 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.93442625, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3333 , 0.331  , 0.329  , 0.3289 , 0.3286 , 0.3235 ,\n",
       "            0.3232 , 0.323  , 0.322  , 0.3213 , 0.3206 , 0.32   , 0.319  ,\n",
       "            0.3186 , 0.3184 , 0.318  , 0.3179 , 0.3171 , 0.317  , 0.3162 ,\n",
       "            0.3154 , 0.3152 , 0.315  , 0.3147 , 0.3137 , 0.3132 , 0.3127 ,\n",
       "            0.3125 , 0.312  , 0.3115 , 0.311  , 0.3108 , 0.31   , 0.3096 ,\n",
       "            0.3088 , 0.3076 , 0.3057 , 0.303  , 0.3022 , 0.3008 , 0.3005 ,\n",
       "            0.2996 , 0.2993 , 0.2966 , 0.2957 , 0.2935 , 0.2903 , 0.2874 ,\n",
       "            0.2847 , 0.2817 , 0.2808 , 0.2803 , 0.2773 , 0.276  , 0.2751 ,\n",
       "            0.275  , 0.2737 , 0.2732 , 0.2717 , 0.2712 , 0.2705 , 0.27   ,\n",
       "            0.2668 , 0.2656 , 0.2654 , 0.2632 , 0.2617 , 0.2615 , 0.259  ,\n",
       "            0.258  , 0.2566 , 0.2556 , 0.255  , 0.2534 , 0.2522 , 0.2517 ,\n",
       "            0.2512 , 0.25   , 0.2498 , 0.2485 , 0.2473 , 0.2444 , 0.2437 ,\n",
       "            0.2434 , 0.2428 , 0.2415 , 0.2405 , 0.2388 , 0.2384 , 0.2378 ,\n",
       "            0.237  , 0.2355 , 0.2352 , 0.2346 , 0.2344 , 0.2339 , 0.2338 ,\n",
       "            0.2328 , 0.2323 , 0.2318 , 0.2314 , 0.2313 , 0.2299 , 0.2294 ,\n",
       "            0.2286 , 0.2278 , 0.2273 , 0.2264 , 0.2261 , 0.226  , 0.2247 ,\n",
       "            0.2246 , 0.223  , 0.2229 , 0.2224 , 0.2202 , 0.2179 , 0.2162 ,\n",
       "            0.2161 , 0.2158 , 0.2142 , 0.214  , 0.2135 , 0.2125 , 0.2124 ,\n",
       "            0.2063 , 0.2056 , 0.2042 , 0.2037 , 0.2035 , 0.2031 , 0.2029 ,\n",
       "            0.2023 , 0.202  , 0.2015 , 0.1991 , 0.1984 , 0.1973 , 0.197  ,\n",
       "            0.1967 , 0.1958 , 0.1946 , 0.1936 , 0.1906 , 0.1898 , 0.1887 ,\n",
       "            0.1886 , 0.1874 , 0.185  , 0.1842 , 0.1838 , 0.182  , 0.181  ,\n",
       "            0.1807 , 0.1792 , 0.1791 , 0.179  , 0.1785 , 0.1768 , 0.1766 ,\n",
       "            0.1759 , 0.1758 , 0.173  , 0.17   , 0.1699 , 0.1698 , 0.1661 ,\n",
       "            0.1646 , 0.1641 , 0.1635 , 0.1631 , 0.163  , 0.1626 , 0.1589 ,\n",
       "            0.1578 , 0.1559 , 0.1544 , 0.1539 , 0.153  , 0.1521 , 0.152  ,\n",
       "            0.1508 , 0.15   , 0.1495 , 0.149  , 0.1473 , 0.146  , 0.1458 ,\n",
       "            0.1414 , 0.141  , 0.1404 , 0.1403 , 0.1381 , 0.136  , 0.1351 ,\n",
       "            0.1334 , 0.1329 , 0.1322 , 0.1315 , 0.13   , 0.1299 , 0.1287 ,\n",
       "            0.1283 , 0.1279 , 0.1256 , 0.1251 , 0.1222 , 0.1201 , 0.12   ,\n",
       "            0.1172 , 0.11676, 0.115  , 0.1136 , 0.11163, 0.10895, 0.1063 ,\n",
       "            0.10596, 0.10376, 0.1034 , 0.09686, 0.09436, 0.093  , 0.09174],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.0234375, 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875,\n",
       "            0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.2578125, 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.3359375, 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.3828125, 0.390625 , 0.3984375, 0.3984375, 0.40625  ,\n",
       "            0.421875 , 0.4375   , 0.4375   , 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.4765625, 0.484375 , 0.484375 , 0.484375 , 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 ,\n",
       "            0.4921875, 0.4921875, 0.4921875, 0.5      , 0.5      , 0.5      ,\n",
       "            0.5      , 0.5      , 0.5      , 0.5      , 0.5      , 0.5      ,\n",
       "            0.5      , 0.5      , 0.5      , 0.5      , 0.5      , 0.5      ,\n",
       "            0.5      , 0.5      , 0.5      , 0.5      , 0.5      , 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.609375 , 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.03278688, 0.04098361, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09016393, 0.09016393, 0.09016393,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.24590164, 0.25409836, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.45901638, 0.47540984, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.852459  , 0.8606557 , 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3323 , 0.331  , 0.3276 , 0.3264 , 0.325  , 0.3245 ,\n",
       "            0.3242 , 0.3235 , 0.3215 , 0.3213 , 0.3203 , 0.3196 , 0.3188 ,\n",
       "            0.3179 , 0.3176 , 0.317  , 0.3167 , 0.3164 , 0.315  , 0.3147 ,\n",
       "            0.3142 , 0.314  , 0.3137 , 0.313  , 0.3108 , 0.31   , 0.3098 ,\n",
       "            0.3096 , 0.309  , 0.3083 , 0.3079 , 0.3076 , 0.3066 , 0.3064 ,\n",
       "            0.306  , 0.3057 , 0.3054 , 0.304  , 0.3037 , 0.302  , 0.3008 ,\n",
       "            0.3005 , 0.2974 , 0.297  , 0.2942 , 0.2937 , 0.2925 , 0.292  ,\n",
       "            0.2903 , 0.2888 , 0.2876 , 0.287  , 0.2869 , 0.2852 , 0.285  ,\n",
       "            0.2837 , 0.2832 , 0.2808 , 0.2803 , 0.2795 , 0.279  , 0.2783 ,\n",
       "            0.2761 , 0.2751 , 0.2747 , 0.2734 , 0.2727 , 0.2722 , 0.272  ,\n",
       "            0.2717 , 0.271  , 0.2708 , 0.27   , 0.2695 , 0.269  , 0.2678 ,\n",
       "            0.2673 , 0.2668 , 0.2651 , 0.2644 , 0.2637 , 0.26   , 0.258  ,\n",
       "            0.2578 , 0.257  , 0.2568 , 0.2563 , 0.256  , 0.2559 , 0.2544 ,\n",
       "            0.2534 , 0.2532 , 0.2527 , 0.252  , 0.2515 , 0.251  , 0.2502 ,\n",
       "            0.2496 , 0.248  , 0.2478 , 0.2471 , 0.2467 , 0.2466 , 0.246  ,\n",
       "            0.2455 , 0.2452 , 0.2444 , 0.2438 , 0.2437 , 0.243  , 0.2424 ,\n",
       "            0.2417 , 0.2382 , 0.2378 , 0.2368 , 0.2366 , 0.2356 , 0.2346 ,\n",
       "            0.2344 , 0.2343 , 0.2335 , 0.2327 , 0.2318 , 0.2314 , 0.2302 ,\n",
       "            0.2283 , 0.2268 , 0.2252 , 0.2246 , 0.2238 , 0.223  , 0.2229 ,\n",
       "            0.2213 , 0.2194 , 0.219  , 0.2185 , 0.2184 , 0.2181 , 0.2175 ,\n",
       "            0.2167 , 0.2163 , 0.2157 , 0.2148 , 0.2119 , 0.2118 , 0.2091 ,\n",
       "            0.2081 , 0.206  , 0.2059 , 0.2054 , 0.205  , 0.2047 , 0.2035 ,\n",
       "            0.2018 , 0.2007 , 0.1987 , 0.196  , 0.195  , 0.1946 , 0.1943 ,\n",
       "            0.194  , 0.1936 , 0.1925 , 0.1915 , 0.1877 , 0.1874 , 0.1858 ,\n",
       "            0.1846 , 0.1808 , 0.1807 , 0.1805 , 0.1785 , 0.1766 , 0.1738 ,\n",
       "            0.1736 , 0.1731 , 0.1724 , 0.172  , 0.1715 , 0.1709 , 0.1693 ,\n",
       "            0.1685 , 0.1683 , 0.1678 , 0.1677 , 0.1675 , 0.1638 , 0.1611 ,\n",
       "            0.1599 , 0.1593 , 0.1587 , 0.1569 , 0.1548 , 0.1536 , 0.153  ,\n",
       "            0.1516 , 0.1508 , 0.1506 , 0.149  , 0.1489 , 0.1486 , 0.1478 ,\n",
       "            0.1475 , 0.145  , 0.1444 , 0.1438 , 0.1411 , 0.14   , 0.1385 ,\n",
       "            0.1362 , 0.1354 , 0.135  , 0.1321 , 0.1302 , 0.1273 , 0.1251 ,\n",
       "            0.1243 , 0.1226 , 0.12177, 0.1158 , 0.113  , 0.11127, 0.1103 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.0390625, 0.046875 , 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.2109375, 0.21875  , 0.21875  , 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.265625 , 0.2734375, 0.2890625, 0.296875 , 0.296875 , 0.296875 ,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.359375 , 0.359375 , 0.3828125, 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.3984375, 0.3984375, 0.3984375, 0.40625  , 0.4296875, 0.4296875,\n",
       "            0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.453125 , 0.453125 ,\n",
       "            0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.453125 ,\n",
       "            0.453125 , 0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.46875  , 0.46875  , 0.46875  , 0.46875  , 0.46875  ,\n",
       "            0.46875  , 0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.4921875,\n",
       "            0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.4921875,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.59375  , 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.03278688, 0.03278688, 0.04098361, 0.04098361, 0.04098361,\n",
       "            0.04098361, 0.04098361, 0.04098361, 0.04098361, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.07377049,\n",
       "            0.08196721, 0.08196721, 0.08196721, 0.08196721, 0.09836066,\n",
       "            0.09836066, 0.10655738, 0.12295082, 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.17213115, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22131148, 0.22950819, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.30327868, 0.3114754 , 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.44262296, 0.44262296,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6639344 , 0.6721311 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90983605, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.341 , 0.338 , 0.337 , 0.3367, 0.336 , 0.3354, 0.333 ,\n",
       "            0.3325, 0.3318, 0.3315, 0.3313, 0.3289, 0.3286, 0.3264, 0.3262,\n",
       "            0.3257, 0.3254, 0.3242, 0.323 , 0.322 , 0.321 , 0.3206, 0.32  ,\n",
       "            0.3196, 0.3186, 0.3179, 0.3162, 0.3154, 0.3152, 0.3147, 0.3142,\n",
       "            0.3132, 0.3123, 0.3115, 0.3108, 0.31  , 0.3093, 0.3083, 0.3076,\n",
       "            0.3074, 0.3071, 0.307 , 0.3066, 0.3062, 0.306 , 0.3047, 0.3042,\n",
       "            0.3022, 0.302 , 0.3018, 0.3015, 0.301 , 0.3008, 0.3003, 0.2998,\n",
       "            0.2996, 0.2993, 0.2986, 0.2983, 0.298 , 0.2976, 0.2974, 0.2961,\n",
       "            0.296 , 0.2957, 0.2952, 0.2937, 0.2932, 0.2915, 0.291 , 0.2908,\n",
       "            0.2898, 0.2888, 0.2886, 0.2878, 0.2874, 0.2864, 0.2852, 0.2844,\n",
       "            0.2825, 0.282 , 0.2815, 0.2808, 0.2805, 0.2803, 0.2795, 0.279 ,\n",
       "            0.2788, 0.2783, 0.278 , 0.2766, 0.2756, 0.2747, 0.2744, 0.2742,\n",
       "            0.274 , 0.2734, 0.2727, 0.2725, 0.2722, 0.272 , 0.2717, 0.271 ,\n",
       "            0.2703, 0.2698, 0.269 , 0.2686, 0.2676, 0.2664, 0.266 , 0.2654,\n",
       "            0.265 , 0.2642, 0.2632, 0.263 , 0.2615, 0.2612, 0.261 , 0.2607,\n",
       "            0.2595, 0.2588, 0.2583, 0.2573, 0.255 , 0.2542, 0.2532, 0.2524,\n",
       "            0.252 , 0.25  , 0.248 , 0.2473, 0.2466, 0.2455, 0.2451, 0.2448,\n",
       "            0.2441, 0.2438, 0.2437, 0.2417, 0.2413, 0.2406, 0.2383, 0.2375,\n",
       "            0.2362, 0.2355, 0.2351, 0.2335, 0.2334, 0.2332, 0.2327, 0.2322,\n",
       "            0.2306, 0.2263, 0.2261, 0.2247, 0.2238, 0.2235, 0.2224, 0.2216,\n",
       "            0.2198, 0.2173, 0.2161, 0.2137, 0.213 , 0.2129, 0.2124, 0.2076,\n",
       "            0.2074, 0.2073, 0.2042, 0.2029, 0.2009, 0.1993, 0.199 , 0.1987,\n",
       "            0.1985, 0.197 , 0.196 , 0.1956, 0.191 , 0.1906, 0.1873, 0.1866,\n",
       "            0.186 , 0.185 , 0.1829, 0.182 , 0.1812, 0.1796, 0.1788, 0.1783,\n",
       "            0.1782, 0.177 , 0.1766, 0.1764, 0.1735, 0.1726, 0.1714, 0.1696,\n",
       "            0.1694, 0.1663, 0.1649, 0.1637, 0.1631, 0.1599, 0.158 , 0.1549,\n",
       "            0.1533, 0.1519, 0.1506, 0.1494, 0.1438, 0.1411, 0.1385, 0.1382],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.0390625, 0.046875 , 0.0546875, 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.09375  , 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1484375, 0.1640625, 0.1640625, 0.171875 , 0.171875 , 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1875   , 0.1953125, 0.1953125, 0.203125 ,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.21875  , 0.21875  , 0.21875  ,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.234375 , 0.234375 , 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.265625 , 0.265625 , 0.2734375, 0.2734375, 0.28125  , 0.28125  ,\n",
       "            0.28125  , 0.296875 , 0.3046875, 0.3046875, 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.328125 , 0.3359375, 0.3359375, 0.3515625,\n",
       "            0.359375 , 0.359375 , 0.375    , 0.375    , 0.390625 , 0.390625 ,\n",
       "            0.390625 , 0.40625  , 0.40625  , 0.40625  , 0.40625  , 0.4140625,\n",
       "            0.4140625, 0.4140625, 0.421875 , 0.421875 , 0.421875 , 0.421875 ,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.4765625, 0.4765625, 0.484375 ,\n",
       "            0.484375 , 0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.4921875,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   , 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.04098361, 0.04098361, 0.04098361,\n",
       "            0.04098361, 0.04098361, 0.04098361, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.12295082, 0.12295082, 0.13934426, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.16393442, 0.16393442, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.26229507, 0.26229507, 0.26229507, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.32786885, 0.33606556, 0.3442623 , 0.36065573,\n",
       "            0.36885247, 0.36885247, 0.36885247, 0.37704918, 0.37704918,\n",
       "            0.3852459 , 0.3852459 , 0.3852459 , 0.40163934, 0.40163934,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.58196723, 0.59016395, 0.60655737, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.7295082 , 0.73770493,\n",
       "            0.73770493, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8606557 , 0.8606557 , 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90983605, 0.91803277, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.349 , 0.3484, 0.3472, 0.346 , 0.3438, 0.3418, 0.341 ,\n",
       "            0.3384, 0.338 , 0.3376, 0.3374, 0.336 , 0.3357, 0.3345, 0.3333,\n",
       "            0.3325, 0.332 , 0.3315, 0.3306, 0.3303, 0.3286, 0.3284, 0.327 ,\n",
       "            0.3264, 0.3262, 0.3254, 0.3252, 0.324 , 0.3237, 0.3235, 0.3228,\n",
       "            0.3225, 0.3223, 0.3215, 0.321 , 0.3208, 0.3206, 0.3203, 0.32  ,\n",
       "            0.3198, 0.3196, 0.3193, 0.3186, 0.318 , 0.3179, 0.3167, 0.3162,\n",
       "            0.3154, 0.3147, 0.3135, 0.313 , 0.3127, 0.3123, 0.312 , 0.3115,\n",
       "            0.311 , 0.3108, 0.3093, 0.309 , 0.3088, 0.3086, 0.3074, 0.3064,\n",
       "            0.3062, 0.3052, 0.3047, 0.3044, 0.3042, 0.304 , 0.3037, 0.3032,\n",
       "            0.3022, 0.302 , 0.3018, 0.3013, 0.3005, 0.2998, 0.2996, 0.299 ,\n",
       "            0.2986, 0.298 , 0.2976, 0.2974, 0.297 , 0.2966, 0.2964, 0.296 ,\n",
       "            0.294 , 0.2937, 0.2935, 0.2932, 0.293 , 0.2925, 0.2922, 0.291 ,\n",
       "            0.2908, 0.2898, 0.2876, 0.287 , 0.2869, 0.286 , 0.2852, 0.2847,\n",
       "            0.2837, 0.2832, 0.283 , 0.2827, 0.2825, 0.2822, 0.2815, 0.2808,\n",
       "            0.28  , 0.2798, 0.279 , 0.2788, 0.2786, 0.2773, 0.276 , 0.2751,\n",
       "            0.2715, 0.2703, 0.2695, 0.2693, 0.269 , 0.2688, 0.2673, 0.2668,\n",
       "            0.2664, 0.266 , 0.2651, 0.265 , 0.2644, 0.2632, 0.2627, 0.262 ,\n",
       "            0.2605, 0.2583, 0.258 , 0.2556, 0.254 , 0.2537, 0.2527, 0.2482,\n",
       "            0.248 , 0.2474, 0.2455, 0.2449, 0.2438, 0.2433, 0.2375, 0.2374,\n",
       "            0.2358, 0.2316, 0.2314, 0.2306, 0.2297, 0.228 , 0.2257, 0.2244,\n",
       "            0.224 , 0.2239, 0.2224, 0.2218, 0.2216, 0.2212, 0.2181, 0.2162,\n",
       "            0.2129, 0.212 , 0.2114, 0.2095, 0.2091, 0.2069, 0.2068, 0.2054,\n",
       "            0.2047, 0.2045, 0.2042, 0.2035, 0.2034, 0.2006, 0.1995, 0.1979,\n",
       "            0.1976, 0.1962, 0.1925, 0.1917, 0.1896, 0.1866, 0.1846, 0.182 ,\n",
       "            0.1808, 0.1788, 0.1782, 0.1764, 0.1718, 0.169 , 0.1664, 0.1659],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0625   , 0.078125 , 0.078125 , 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.1015625, 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.1171875, 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.140625 ,\n",
       "            0.140625 , 0.140625 , 0.15625  , 0.15625  , 0.1640625, 0.1640625,\n",
       "            0.1796875, 0.1796875, 0.1796875, 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.2109375, 0.2109375,\n",
       "            0.2109375, 0.2109375, 0.2109375, 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.2421875, 0.2421875, 0.2421875,\n",
       "            0.2421875, 0.2421875, 0.2421875, 0.25     , 0.25     , 0.25     ,\n",
       "            0.2578125, 0.2578125, 0.2578125, 0.2578125, 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.2734375, 0.2734375, 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.296875 , 0.296875 , 0.296875 , 0.296875 , 0.3125   ,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.328125 , 0.328125 , 0.328125 ,\n",
       "            0.34375  , 0.359375 , 0.359375 , 0.3671875, 0.3828125, 0.390625 ,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4375   , 0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.453125 ,\n",
       "            0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.02459016,\n",
       "            0.03278688, 0.03278688, 0.04098361, 0.05737705, 0.08196721,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.18032786, 0.18852459, 0.19672132, 0.19672132,\n",
       "            0.19672132, 0.19672132, 0.20491803, 0.21311475, 0.22950819,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.26229507, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.36885247,\n",
       "            0.37704918, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4180328 , 0.4180328 , 0.44262296,\n",
       "            0.45081967, 0.47540984, 0.47540984, 0.4918033 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.704918  , 0.71311474, 0.7295082 ,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.75409836, 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8278689 , 0.8278689 , 0.8442623 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3613, 0.3599, 0.3582, 0.3547, 0.3533, 0.3525, 0.352 ,\n",
       "            0.3503, 0.35  , 0.3499, 0.3486, 0.3474, 0.3464, 0.3457, 0.3455,\n",
       "            0.3452, 0.3435, 0.343 , 0.3428, 0.3425, 0.3423, 0.342 , 0.3418,\n",
       "            0.3416, 0.3413, 0.341 , 0.3408, 0.3403, 0.3398, 0.3394, 0.339 ,\n",
       "            0.3389, 0.3384, 0.3381, 0.3376, 0.3374, 0.3357, 0.335 , 0.3345,\n",
       "            0.3335, 0.333 , 0.3328, 0.3323, 0.3315, 0.331 , 0.3303, 0.3296,\n",
       "            0.3281, 0.328 , 0.327 , 0.3257, 0.3245, 0.3235, 0.3228, 0.3225,\n",
       "            0.3223, 0.322 , 0.3218, 0.3215, 0.3213, 0.321 , 0.3203, 0.32  ,\n",
       "            0.3198, 0.3193, 0.3188, 0.3186, 0.3179, 0.3174, 0.3162, 0.3154,\n",
       "            0.315 , 0.3142, 0.3137, 0.3135, 0.3132, 0.313 , 0.3127, 0.3125,\n",
       "            0.3123, 0.3115, 0.3105, 0.3103, 0.309 , 0.3086, 0.308 , 0.3079,\n",
       "            0.3076, 0.3074, 0.3071, 0.306 , 0.3054, 0.3052, 0.3047, 0.304 ,\n",
       "            0.3037, 0.3032, 0.3025, 0.3018, 0.3   , 0.2993, 0.2986, 0.298 ,\n",
       "            0.2976, 0.2969, 0.2966, 0.296 , 0.2954, 0.295 , 0.2947, 0.2944,\n",
       "            0.2927, 0.292 , 0.2913, 0.2905, 0.2903, 0.2898, 0.2893, 0.2888,\n",
       "            0.288 , 0.2874, 0.2869, 0.2861, 0.2852, 0.2842, 0.2837, 0.282 ,\n",
       "            0.281 , 0.2795, 0.279 , 0.278 , 0.2766, 0.2725, 0.2715, 0.2695,\n",
       "            0.2683, 0.268 , 0.2664, 0.2651, 0.2637, 0.2615, 0.2605, 0.2603,\n",
       "            0.2588, 0.258 , 0.2563, 0.2551, 0.2527, 0.2524, 0.252 , 0.2478,\n",
       "            0.2466, 0.246 , 0.2455, 0.2448, 0.2444, 0.244 , 0.2437, 0.243 ,\n",
       "            0.2382, 0.235 , 0.2347, 0.234 , 0.2335, 0.2327, 0.2323, 0.2303,\n",
       "            0.2295, 0.2294, 0.229 , 0.2289, 0.228 , 0.2274, 0.2268, 0.2266,\n",
       "            0.2244, 0.2238, 0.223 , 0.2203, 0.22  , 0.217 , 0.2167, 0.2157,\n",
       "            0.2128, 0.2104, 0.208 , 0.2059, 0.2053, 0.2024, 0.2023, 0.2   ,\n",
       "            0.1967, 0.1942, 0.1917, 0.1903], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.046875 , 0.046875 , 0.0625   , 0.0703125,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.0859375, 0.1015625, 0.109375 ,\n",
       "            0.109375 , 0.109375 , 0.1171875, 0.125    , 0.125    , 0.125    ,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.15625  , 0.1640625, 0.1640625,\n",
       "            0.171875 , 0.171875 , 0.1875   , 0.1875   , 0.1875   , 0.1953125,\n",
       "            0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.1953125,\n",
       "            0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.1953125,\n",
       "            0.1953125, 0.203125 , 0.203125 , 0.2109375, 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.2421875,\n",
       "            0.25     , 0.2578125, 0.2578125, 0.2578125, 0.2578125, 0.2578125,\n",
       "            0.2578125, 0.2578125, 0.2578125, 0.2578125, 0.2578125, 0.265625 ,\n",
       "            0.265625 , 0.265625 , 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.2890625, 0.296875 , 0.296875 , 0.296875 , 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3359375, 0.34375  , 0.34375  , 0.34375  , 0.359375 ,\n",
       "            0.359375 , 0.3671875, 0.3671875, 0.375    , 0.375    , 0.375    ,\n",
       "            0.390625 , 0.390625 , 0.390625 , 0.3984375, 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4375   , 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.4765625, 0.484375 , 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.515625 , 0.5234375, 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.16393442, 0.17213115,\n",
       "            0.17213115, 0.19672132, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22131148, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.26229507, 0.27868852, 0.28688523, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36065573, 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40163934,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4180328 , 0.4262295 ,\n",
       "            0.4262295 , 0.43442622, 0.43442622, 0.44262296, 0.46721312,\n",
       "            0.46721312, 0.47540984, 0.5081967 , 0.5163934 , 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6147541 ,\n",
       "            0.6229508 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6639344 , 0.6639344 , 0.6639344 , 0.6885246 , 0.6967213 ,\n",
       "            0.6967213 , 0.6967213 , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.7704918 , 0.77868855,\n",
       "            0.795082  , 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8196721 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3735, 0.371 , 0.3706, 0.3696, 0.3694, 0.3674, 0.3667,\n",
       "            0.3665, 0.366 , 0.3652, 0.3643, 0.3633, 0.3623, 0.3599, 0.3582,\n",
       "            0.358 , 0.3574, 0.3564, 0.3562, 0.3557, 0.3538, 0.3528, 0.3523,\n",
       "            0.352 , 0.3518, 0.3516, 0.351 , 0.3508, 0.3506, 0.3499, 0.3496,\n",
       "            0.349 , 0.3489, 0.3481, 0.348 , 0.3474, 0.3472, 0.346 , 0.3455,\n",
       "            0.3452, 0.345 , 0.3445, 0.3442, 0.344 , 0.3435, 0.3433, 0.3423,\n",
       "            0.3416, 0.3403, 0.34  , 0.3381, 0.3376, 0.3374, 0.337 , 0.3367,\n",
       "            0.3364, 0.336 , 0.335 , 0.3335, 0.3333, 0.333 , 0.3323, 0.3318,\n",
       "            0.3315, 0.331 , 0.3306, 0.3303, 0.33  , 0.3298, 0.3296, 0.329 ,\n",
       "            0.3267, 0.3252, 0.325 , 0.3247, 0.3242, 0.324 , 0.3237, 0.3232,\n",
       "            0.3228, 0.3225, 0.3223, 0.3206, 0.3196, 0.318 , 0.3176, 0.317 ,\n",
       "            0.3167, 0.3164, 0.3162, 0.3154, 0.3152, 0.315 , 0.3147, 0.3145,\n",
       "            0.314 , 0.3137, 0.3132, 0.313 , 0.3127, 0.312 , 0.3115, 0.3113,\n",
       "            0.31  , 0.3098, 0.308 , 0.3079, 0.3062, 0.306 , 0.3057, 0.3054,\n",
       "            0.3052, 0.3047, 0.3044, 0.3042, 0.3035, 0.3025, 0.3015, 0.3013,\n",
       "            0.3005, 0.3003, 0.3   , 0.2983, 0.298 , 0.2969, 0.2966, 0.2957,\n",
       "            0.2954, 0.2937, 0.2927, 0.2922, 0.2898, 0.289 , 0.2888, 0.2876,\n",
       "            0.2874, 0.2861, 0.2847, 0.2837, 0.2834, 0.2805, 0.2773, 0.2744,\n",
       "            0.2742, 0.2727, 0.2695, 0.269 , 0.268 , 0.2678, 0.2676, 0.265 ,\n",
       "            0.2646, 0.2588, 0.2573, 0.255 , 0.2544, 0.2534, 0.253 , 0.2527,\n",
       "            0.2522, 0.252 , 0.2517, 0.2512, 0.2505, 0.2478, 0.2466, 0.2448,\n",
       "            0.244 , 0.2437, 0.243 , 0.2418, 0.2407, 0.2406, 0.2405, 0.2394,\n",
       "            0.239 , 0.2366, 0.2363, 0.236 , 0.2351, 0.2343, 0.234 , 0.2339,\n",
       "            0.2325, 0.2307, 0.2285, 0.2277, 0.2261, 0.2256, 0.2233, 0.222 ,\n",
       "            0.2202, 0.2186, 0.2156, 0.2142, 0.2108, 0.2101, 0.2079, 0.2054,\n",
       "            0.2039, 0.2012, 0.199 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.078125 , 0.078125 , 0.078125 , 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.109375 , 0.109375 , 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.125    , 0.125    , 0.1328125, 0.140625 , 0.140625 , 0.140625 ,\n",
       "            0.140625 , 0.1484375, 0.1484375, 0.15625  , 0.1640625, 0.1640625,\n",
       "            0.1640625, 0.1640625, 0.1640625, 0.1640625, 0.171875 , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.1953125,\n",
       "            0.203125 , 0.203125 , 0.203125 , 0.21875  , 0.21875  , 0.2265625,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.2578125,\n",
       "            0.2578125, 0.2578125, 0.265625 , 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4921875, 0.5      , 0.5078125, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.609375 , 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.36065573, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.39344263, 0.40163934, 0.40163934, 0.40983605, 0.40983605,\n",
       "            0.4180328 , 0.4180328 , 0.4262295 , 0.44262296, 0.45081967,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.4918033 , 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5081967 , 0.52459013, 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59836066, 0.59836066, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.647541  , 0.647541  , 0.6557377 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.77868855, 0.8032787 ,\n",
       "            0.8114754 , 0.8278689 , 0.8360656 , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.91803277, 0.91803277,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4282, 0.424 , 0.4211, 0.419 , 0.4172, 0.4163, 0.415 ,\n",
       "            0.4138, 0.4072, 0.4065, 0.4055, 0.4048, 0.4038, 0.403 , 0.4023,\n",
       "            0.4016, 0.401 , 0.398 , 0.3972, 0.396 , 0.3953, 0.3923, 0.391 ,\n",
       "            0.3901, 0.3894, 0.3892, 0.388 , 0.387 , 0.3853, 0.3845, 0.3843,\n",
       "            0.3835, 0.3823, 0.3816, 0.3806, 0.3801, 0.3787, 0.3782, 0.378 ,\n",
       "            0.3777, 0.3772, 0.3767, 0.3765, 0.3762, 0.3752, 0.3748, 0.3745,\n",
       "            0.374 , 0.3735, 0.373 , 0.3728, 0.3708, 0.37  , 0.3694, 0.3691,\n",
       "            0.3684, 0.3677, 0.3674, 0.3657, 0.3652, 0.365 , 0.3647, 0.3645,\n",
       "            0.3643, 0.3635, 0.3633, 0.363 , 0.3628, 0.3623, 0.362 , 0.3618,\n",
       "            0.361 , 0.3608, 0.3604, 0.36  , 0.3591, 0.359 , 0.3577, 0.3572,\n",
       "            0.357 , 0.3564, 0.3562, 0.356 , 0.355 , 0.3538, 0.3535, 0.3533,\n",
       "            0.353 , 0.352 , 0.3518, 0.3513, 0.351 , 0.3506, 0.3499, 0.3496,\n",
       "            0.349 , 0.3486, 0.3481, 0.348 , 0.3472, 0.3467, 0.3457, 0.3447,\n",
       "            0.343 , 0.3428, 0.342 , 0.3418, 0.3413, 0.341 , 0.3406, 0.3403,\n",
       "            0.34  , 0.3396, 0.339 , 0.3381, 0.3354, 0.3352, 0.335 , 0.3345,\n",
       "            0.334 , 0.3328, 0.3318, 0.3313, 0.3303, 0.3298, 0.3293, 0.3289,\n",
       "            0.3276, 0.3264, 0.3245, 0.322 , 0.3215, 0.321 , 0.3203, 0.3196,\n",
       "            0.319 , 0.3174, 0.3162, 0.3154, 0.3125, 0.312 , 0.311 , 0.3093,\n",
       "            0.309 , 0.3064, 0.3062, 0.306 , 0.3052, 0.3047, 0.304 , 0.3032,\n",
       "            0.3025, 0.3015, 0.3013, 0.3005, 0.2983, 0.2964, 0.2942, 0.2925,\n",
       "            0.2917, 0.29  , 0.2898, 0.2888, 0.2883, 0.288 , 0.2878, 0.2874,\n",
       "            0.2869, 0.2864, 0.286 , 0.285 , 0.2842, 0.2832, 0.283 , 0.2803,\n",
       "            0.2795, 0.279 , 0.2773, 0.2761, 0.2756, 0.2754, 0.2751, 0.2737,\n",
       "            0.2722, 0.2712, 0.2708, 0.2705, 0.27  , 0.2693, 0.269 , 0.2678,\n",
       "            0.2668, 0.2664, 0.266 , 0.2654, 0.2646, 0.2634, 0.2622, 0.26  ,\n",
       "            0.2593, 0.2566, 0.2534, 0.2524, 0.2522, 0.2477, 0.2473, 0.2452,\n",
       "            0.2444, 0.2434, 0.2429, 0.2424, 0.2422, 0.2383, 0.2225],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.046875 ,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.078125 , 0.078125 , 0.09375  , 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.109375 , 0.109375 , 0.109375 , 0.109375 , 0.109375 ,\n",
       "            0.109375 , 0.109375 , 0.109375 , 0.109375 , 0.1171875, 0.1171875,\n",
       "            0.1328125, 0.1328125, 0.140625 , 0.140625 , 0.1484375, 0.1484375,\n",
       "            0.15625  , 0.15625  , 0.15625  , 0.15625  , 0.1640625, 0.1640625,\n",
       "            0.1640625, 0.171875 , 0.171875 , 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.1953125, 0.203125 , 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.2265625, 0.234375 , 0.2421875, 0.25     , 0.25     ,\n",
       "            0.265625 , 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3125   , 0.3203125, 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.7421875, 0.75     , 0.7578125, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.828125 , 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.9140625, 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.37704918, 0.3852459 , 0.40163934, 0.40983605,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6393443 , 0.647541  ,\n",
       "            0.6639344 , 0.6639344 , 0.6721311 , 0.6721311 , 0.6803279 ,\n",
       "            0.6967213 , 0.6967213 , 0.704918  , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.795082  , 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.852459  , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4688, 0.4578, 0.4565, 0.4563, 0.4502, 0.4468, 0.4465,\n",
       "            0.4412, 0.441 , 0.44  , 0.4333, 0.433 , 0.4329, 0.4312, 0.4304,\n",
       "            0.4265, 0.4263, 0.4255, 0.4233, 0.421 , 0.4202, 0.4175, 0.417 ,\n",
       "            0.4163, 0.4155, 0.4148, 0.4143, 0.413 , 0.4124, 0.409 , 0.4084,\n",
       "            0.4075, 0.4065, 0.4053, 0.404 , 0.4036, 0.4033, 0.4023, 0.3958,\n",
       "            0.3955, 0.395 , 0.3948, 0.394 , 0.393 , 0.3928, 0.392 , 0.391 ,\n",
       "            0.3906, 0.3901, 0.3892, 0.3884, 0.3882, 0.3875, 0.3865, 0.3845,\n",
       "            0.3843, 0.383 , 0.3828, 0.382 , 0.3818, 0.3813, 0.381 , 0.3809,\n",
       "            0.38  , 0.3792, 0.3784, 0.3777, 0.3762, 0.3757, 0.3752, 0.374 ,\n",
       "            0.3735, 0.3733, 0.373 , 0.3723, 0.3708, 0.3706, 0.3691, 0.3687,\n",
       "            0.3682, 0.368 , 0.3677, 0.3674, 0.3657, 0.3647, 0.364 , 0.3638,\n",
       "            0.3635, 0.363 , 0.3628, 0.3623, 0.362 , 0.3616, 0.3599, 0.3594,\n",
       "            0.3591, 0.3582, 0.358 , 0.3572, 0.357 , 0.3567, 0.3562, 0.356 ,\n",
       "            0.3538, 0.3535, 0.3533, 0.3523, 0.3516, 0.3513, 0.3499, 0.3494,\n",
       "            0.349 , 0.3484, 0.3481, 0.3462, 0.346 , 0.3457, 0.3455, 0.3447,\n",
       "            0.344 , 0.3435, 0.3433, 0.3423, 0.3418, 0.3406, 0.337 , 0.3352,\n",
       "            0.3347, 0.3306, 0.3303, 0.3274, 0.327 , 0.3245, 0.3237, 0.3235,\n",
       "            0.3228, 0.321 , 0.3206, 0.3198, 0.3171, 0.317 , 0.3162, 0.315 ,\n",
       "            0.3135, 0.313 , 0.3127, 0.3123, 0.3093, 0.3083, 0.3074, 0.3057,\n",
       "            0.3044, 0.3042, 0.3037, 0.3035, 0.3025, 0.3022, 0.3018, 0.301 ,\n",
       "            0.3008, 0.2993, 0.299 , 0.298 , 0.2976, 0.297 , 0.2966, 0.2961,\n",
       "            0.2954, 0.2932, 0.293 , 0.2927, 0.292 , 0.2917, 0.2915, 0.2896,\n",
       "            0.289 , 0.2886, 0.2854, 0.2852, 0.285 , 0.2844, 0.2837, 0.2832,\n",
       "            0.283 , 0.2825, 0.282 , 0.2815, 0.28  , 0.2788, 0.2776, 0.2751,\n",
       "            0.2722, 0.271 , 0.27  , 0.268 , 0.2666, 0.2654, 0.2625, 0.2622,\n",
       "            0.2605, 0.26  , 0.2583, 0.257 , 0.2554, 0.2546, 0.2471, 0.235 ,\n",
       "            0.2339, 0.218 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.01639344, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.0859375, 0.0859375,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.09375  , 0.1015625,\n",
       "            0.1015625, 0.109375 , 0.109375 , 0.109375 , 0.1171875, 0.1171875,\n",
       "            0.1171875, 0.1171875, 0.1171875, 0.125    , 0.1328125, 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.1640625, 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.25     , 0.2578125,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.4140625, 0.421875 , 0.4296875, 0.4453125,\n",
       "            0.453125 , 0.46875  , 0.4765625, 0.4921875, 0.5078125, 0.515625 ,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8203125, 0.828125 ,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.875    , 0.890625 , 0.8984375,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.352459  , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.4918033 , 0.5       , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.57377046, 0.58196723,\n",
       "            0.59836066, 0.6147541 , 0.6229508 , 0.63114756, 0.63114756,\n",
       "            0.6393443 , 0.6557377 , 0.6721311 , 0.6967213 , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.7295082 , 0.73770493, 0.73770493,\n",
       "            0.73770493, 0.74590164, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5117, 0.5034, 0.4937, 0.4885, 0.483 , 0.4817, 0.4802,\n",
       "            0.4792, 0.4768, 0.4766, 0.469 , 0.4668, 0.4636, 0.4614, 0.4607,\n",
       "            0.4592, 0.4573, 0.4563, 0.456 , 0.454 , 0.4531, 0.4524, 0.4495,\n",
       "            0.4485, 0.447 , 0.4434, 0.4397, 0.4377, 0.4373, 0.436 , 0.4353,\n",
       "            0.4343, 0.4338, 0.433 , 0.432 , 0.43  , 0.4294, 0.4287, 0.427 ,\n",
       "            0.4268, 0.421 , 0.4143, 0.4114, 0.4097, 0.4094, 0.4087, 0.4072,\n",
       "            0.4062, 0.4058, 0.405 , 0.404 , 0.4033, 0.4028, 0.4011, 0.401 ,\n",
       "            0.4004, 0.4001, 0.3997, 0.3987, 0.3982, 0.398 , 0.3977, 0.3972,\n",
       "            0.3962, 0.3958, 0.3953, 0.3948, 0.3943, 0.3933, 0.3918, 0.3914,\n",
       "            0.3909, 0.39  , 0.3894, 0.3887, 0.388 , 0.387 , 0.3867, 0.386 ,\n",
       "            0.3853, 0.3835, 0.3828, 0.381 , 0.3809, 0.3806, 0.3804, 0.3801,\n",
       "            0.38  , 0.3782, 0.3772, 0.377 , 0.376 , 0.3752, 0.375 , 0.3743,\n",
       "            0.3735, 0.373 , 0.3718, 0.3713, 0.371 , 0.3706, 0.37  , 0.3696,\n",
       "            0.3687, 0.3667, 0.3662, 0.3643, 0.364 , 0.3638, 0.363 , 0.3623,\n",
       "            0.362 , 0.3618, 0.3616, 0.361 , 0.3608, 0.3606, 0.3596, 0.3594,\n",
       "            0.357 , 0.3564, 0.3562, 0.356 , 0.3555, 0.3552, 0.355 , 0.354 ,\n",
       "            0.3528, 0.3525, 0.3516, 0.35  , 0.3496, 0.3486, 0.3447, 0.3438,\n",
       "            0.3408, 0.3381, 0.3367, 0.3345, 0.3298, 0.329 , 0.3286, 0.3276,\n",
       "            0.3274, 0.3264, 0.3262, 0.324 , 0.3232, 0.3228, 0.3225, 0.3213,\n",
       "            0.3208, 0.3206, 0.32  , 0.3196, 0.3186, 0.318 , 0.3176, 0.3167,\n",
       "            0.314 , 0.3137, 0.3132, 0.313 , 0.3125, 0.312 , 0.3115, 0.3113,\n",
       "            0.311 , 0.3105, 0.307 , 0.3044, 0.3042, 0.3037, 0.3032, 0.3025,\n",
       "            0.3022, 0.3015, 0.3013, 0.301 , 0.3003, 0.3   , 0.2998, 0.2986,\n",
       "            0.298 , 0.2976, 0.2974, 0.2954, 0.2944, 0.2937, 0.2932, 0.2925,\n",
       "            0.2903, 0.2896, 0.2886, 0.2883, 0.2874, 0.2864, 0.283 , 0.281 ,\n",
       "            0.2795, 0.279 , 0.278 , 0.2764, 0.2756, 0.2754, 0.274 , 0.2732,\n",
       "            0.2573, 0.2527, 0.25  , 0.2483, 0.2405, 0.2249, 0.2239, 0.2119],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.13114753, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.078125 , 0.078125 , 0.0859375, 0.0859375, 0.09375  ,\n",
       "            0.09375  , 0.09375  , 0.09375  , 0.1015625, 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.1171875, 0.1171875, 0.125    , 0.125    , 0.125    ,\n",
       "            0.140625 , 0.140625 , 0.1484375, 0.1484375, 0.15625  , 0.15625  ,\n",
       "            0.1640625, 0.1640625, 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.203125 , 0.2109375, 0.2109375, 0.2109375, 0.21875  , 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.3984375, 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.453125 , 0.4609375, 0.46875  , 0.484375 ,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.5859375, 0.59375  , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.65625  , 0.6640625, 0.6796875,\n",
       "            0.6875   , 0.703125 , 0.7109375, 0.71875  , 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.26229507, 0.2704918 , 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.37704918, 0.37704918,\n",
       "            0.3852459 , 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6557377 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.72131145, 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.76229507, 0.76229507, 0.76229507, 0.76229507,\n",
       "            0.76229507, 0.77868855, 0.78688526, 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.8852459 , 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5674, 0.5615, 0.544 , 0.5337, 0.533 , 0.532 , 0.529 ,\n",
       "            0.5244, 0.523 , 0.518 , 0.5166, 0.515 , 0.5117, 0.5093, 0.5063,\n",
       "            0.505 , 0.499 , 0.4973, 0.494 , 0.4934, 0.4932, 0.492 , 0.4897,\n",
       "            0.488 , 0.4858, 0.4846, 0.4824, 0.4768, 0.4766, 0.475 , 0.4736,\n",
       "            0.4727, 0.4722, 0.4702, 0.4673, 0.4622, 0.4612, 0.4602, 0.4565,\n",
       "            0.4563, 0.4548, 0.441 , 0.4387, 0.4382, 0.4365, 0.4363, 0.4333,\n",
       "            0.4329, 0.4312, 0.426 , 0.4258, 0.4248, 0.4238, 0.423 , 0.4214,\n",
       "            0.4211, 0.4204, 0.42  , 0.4197, 0.4185, 0.4177, 0.4172, 0.417 ,\n",
       "            0.4167, 0.4158, 0.4143, 0.413 , 0.4124, 0.412 , 0.4111, 0.4106,\n",
       "            0.4102, 0.41  , 0.4087, 0.4082, 0.4065, 0.4062, 0.4053, 0.402 ,\n",
       "            0.4019, 0.4014, 0.4006, 0.399 , 0.3958, 0.3945, 0.3943, 0.394 ,\n",
       "            0.3938, 0.3926, 0.3923, 0.392 , 0.3916, 0.3909, 0.3901, 0.39  ,\n",
       "            0.3894, 0.388 , 0.3875, 0.3862, 0.3853, 0.385 , 0.3843, 0.3835,\n",
       "            0.382 , 0.3818, 0.3806, 0.3796, 0.3794, 0.3792, 0.3777, 0.3767,\n",
       "            0.3762, 0.376 , 0.3745, 0.3738, 0.3735, 0.373 , 0.372 , 0.3713,\n",
       "            0.3706, 0.37  , 0.3696, 0.3694, 0.3682, 0.3674, 0.3672, 0.3662,\n",
       "            0.3657, 0.3638, 0.36  , 0.3562, 0.354 , 0.3525, 0.3503, 0.3496,\n",
       "            0.3489, 0.3477, 0.346 , 0.3457, 0.3447, 0.344 , 0.343 , 0.342 ,\n",
       "            0.3416, 0.3408, 0.34  , 0.3367, 0.3364, 0.3352, 0.3345, 0.3337,\n",
       "            0.3335, 0.333 , 0.3325, 0.3323, 0.3313, 0.3298, 0.3296, 0.3281,\n",
       "            0.328 , 0.3276, 0.3264, 0.3252, 0.325 , 0.3235, 0.3228, 0.322 ,\n",
       "            0.3184, 0.318 , 0.3176, 0.317 , 0.3164, 0.3152, 0.3145, 0.3132,\n",
       "            0.3127, 0.3125, 0.3118, 0.3079, 0.3074, 0.3071, 0.3057, 0.305 ,\n",
       "            0.3044, 0.3037, 0.3035, 0.3022, 0.3015, 0.2988, 0.2986, 0.2966,\n",
       "            0.2961, 0.2944, 0.2937, 0.2898, 0.2896, 0.2893, 0.283 , 0.2795,\n",
       "            0.2778, 0.2756, 0.2742, 0.2734, 0.2537, 0.2505, 0.2498, 0.2441,\n",
       "            0.2395, 0.2197, 0.219 , 0.2115], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.28688523, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.0546875, 0.0703125,\n",
       "            0.0703125, 0.0703125, 0.078125 , 0.0859375, 0.0859375, 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.109375 , 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.125    , 0.125    , 0.1328125, 0.1328125, 0.1328125, 0.140625 ,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.15625  , 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.3359375,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.59375  , 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.6484375, 0.65625  , 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.796875 , 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.40983605,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.56557375, 0.57377046,\n",
       "            0.59016395, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.7704918 , 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8442623 ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.609 , 0.6055, 0.583 , 0.574 , 0.5723, 0.568 , 0.564 ,\n",
       "            0.5615, 0.56  , 0.558 , 0.5566, 0.5503, 0.5474, 0.547 , 0.541 ,\n",
       "            0.5376, 0.532 , 0.53  , 0.528 , 0.524 , 0.5234, 0.5225, 0.5215,\n",
       "            0.5195, 0.5166, 0.5127, 0.5107, 0.5103, 0.507 , 0.505 , 0.5044,\n",
       "            0.504 , 0.502 , 0.4995, 0.495 , 0.4937, 0.4895, 0.489 , 0.4858,\n",
       "            0.4817, 0.4802, 0.473 , 0.4678, 0.4675, 0.465 , 0.4648, 0.4639,\n",
       "            0.4626, 0.461 , 0.4578, 0.4575, 0.453 , 0.4524, 0.452 , 0.4517,\n",
       "            0.4504, 0.4495, 0.4492, 0.4468, 0.4465, 0.4463, 0.4456, 0.4448,\n",
       "            0.443 , 0.4426, 0.4421, 0.4417, 0.441 , 0.4404, 0.439 , 0.4377,\n",
       "            0.4365, 0.4363, 0.4348, 0.434 , 0.4324, 0.4316, 0.4297, 0.4294,\n",
       "            0.4275, 0.427 , 0.4268, 0.426 , 0.4258, 0.4253, 0.4246, 0.4243,\n",
       "            0.4236, 0.4219, 0.4214, 0.419 , 0.4172, 0.4167, 0.415 , 0.4143,\n",
       "            0.4138, 0.4133, 0.413 , 0.4126, 0.4111, 0.4094, 0.4092, 0.409 ,\n",
       "            0.4087, 0.4084, 0.4072, 0.4065, 0.406 , 0.4045, 0.4038, 0.4033,\n",
       "            0.402 , 0.3997, 0.3994, 0.3984, 0.398 , 0.3972, 0.396 , 0.3958,\n",
       "            0.3948, 0.3945, 0.3943, 0.3936, 0.393 , 0.3909, 0.3906, 0.3901,\n",
       "            0.3892, 0.3882, 0.388 , 0.3867, 0.3865, 0.3833, 0.3818, 0.381 ,\n",
       "            0.379 , 0.3787, 0.3782, 0.3777, 0.3774, 0.3772, 0.3757, 0.3755,\n",
       "            0.3733, 0.3723, 0.3691, 0.3667, 0.3657, 0.365 , 0.3638, 0.363 ,\n",
       "            0.3618, 0.3606, 0.36  , 0.3594, 0.359 , 0.3572, 0.3564, 0.356 ,\n",
       "            0.354 , 0.353 , 0.3523, 0.352 , 0.3518, 0.351 , 0.3503, 0.3477,\n",
       "            0.3467, 0.346 , 0.3455, 0.3442, 0.344 , 0.3408, 0.3406, 0.34  ,\n",
       "            0.3398, 0.3396, 0.3394, 0.3386, 0.3384, 0.3381, 0.3372, 0.337 ,\n",
       "            0.3364, 0.3362, 0.334 , 0.3337, 0.3333, 0.3328, 0.3325, 0.3303,\n",
       "            0.3284, 0.326 , 0.3235, 0.323 , 0.3223, 0.322 , 0.3218, 0.3213,\n",
       "            0.3074, 0.307 , 0.3066, 0.3054, 0.3052, 0.3035, 0.2957, 0.2903,\n",
       "            0.29  , 0.2869, 0.2793, 0.2776, 0.2751, 0.2742, 0.2727, 0.252 ,\n",
       "            0.249 , 0.2474, 0.2418, 0.2368, 0.2153, 0.2145, 0.209 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.36065573, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.0703125, 0.0703125, 0.078125 , 0.0859375, 0.0859375,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.1015625, 0.109375 , 0.109375 ,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.1328125, 0.1328125,\n",
       "            0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.15625  , 0.1640625,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.2734375, 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.34375  , 0.3515625, 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.578125 , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.7421875, 0.7578125, 0.765625 , 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4180328 , 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.795082  , 0.795082  ,\n",
       "            0.8114754 , 0.8278689 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6553, 0.654 , 0.627 , 0.6187, 0.6167, 0.6074, 0.606 ,\n",
       "            0.604 , 0.602 , 0.594 , 0.5923, 0.5864, 0.586 , 0.5767, 0.573 ,\n",
       "            0.569 , 0.5684, 0.562 , 0.559 , 0.558 , 0.557 , 0.5566, 0.555 ,\n",
       "            0.552 , 0.55  , 0.5493, 0.546 , 0.5444, 0.5415, 0.539 , 0.5366,\n",
       "            0.5356, 0.535 , 0.533 , 0.531 , 0.525 , 0.5234, 0.517 , 0.512 ,\n",
       "            0.5073, 0.506 , 0.505 , 0.499 , 0.4973, 0.496 , 0.4944, 0.494 ,\n",
       "            0.4907, 0.49  , 0.4866, 0.4795, 0.474 , 0.4739, 0.4717, 0.4697,\n",
       "            0.4695, 0.4692, 0.4683, 0.467 , 0.4666, 0.4658, 0.4653, 0.4644,\n",
       "            0.4636, 0.463 , 0.4617, 0.4595, 0.4587, 0.4556, 0.4548, 0.454 ,\n",
       "            0.4534, 0.4531, 0.451 , 0.4507, 0.4497, 0.448 , 0.4468, 0.4458,\n",
       "            0.445 , 0.4446, 0.4436, 0.4417, 0.4404, 0.4397, 0.4392, 0.4387,\n",
       "            0.4385, 0.4373, 0.4365, 0.4355, 0.4336, 0.4326, 0.4314, 0.431 ,\n",
       "            0.4302, 0.43  , 0.4297, 0.429 , 0.4287, 0.4265, 0.4255, 0.4253,\n",
       "            0.4246, 0.4233, 0.423 , 0.422 , 0.4219, 0.4202, 0.4197, 0.4192,\n",
       "            0.4182, 0.416 , 0.4153, 0.4133, 0.4128, 0.4114, 0.411 , 0.41  ,\n",
       "            0.4084, 0.408 , 0.4072, 0.407 , 0.4067, 0.4062, 0.4043, 0.4036,\n",
       "            0.403 , 0.4011, 0.4006, 0.3997, 0.3987, 0.3975, 0.3972, 0.3953,\n",
       "            0.395 , 0.392 , 0.391 , 0.389 , 0.3865, 0.3848, 0.3843, 0.3838,\n",
       "            0.3833, 0.3828, 0.382 , 0.3806, 0.38  , 0.3787, 0.3782, 0.378 ,\n",
       "            0.3767, 0.376 , 0.3743, 0.3733, 0.371 , 0.37  , 0.369 , 0.3687,\n",
       "            0.3684, 0.3665, 0.3652, 0.364 , 0.3638, 0.3625, 0.362 , 0.3618,\n",
       "            0.36  , 0.358 , 0.3574, 0.357 , 0.3564, 0.3542, 0.3535, 0.3528,\n",
       "            0.3525, 0.3523, 0.352 , 0.351 , 0.3508, 0.3506, 0.349 , 0.3486,\n",
       "            0.3464, 0.3447, 0.3433, 0.3428, 0.3413, 0.341 , 0.3398, 0.3394,\n",
       "            0.3389, 0.3376, 0.3347, 0.3345, 0.334 , 0.324 , 0.3237, 0.321 ,\n",
       "            0.3093, 0.307 , 0.3057, 0.3054, 0.3044, 0.3025, 0.2944, 0.2915,\n",
       "            0.2893, 0.2888, 0.2766, 0.275 , 0.2727, 0.2705, 0.27  , 0.2473,\n",
       "            0.2467, 0.2426, 0.2358, 0.2335, 0.2084, 0.2076, 0.2065],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.0078125, dtype=float32),\n",
       "    'tpr': array(0.4180328, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0703125, 0.0703125, 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.0859375, 0.0859375, 0.0859375, 0.09375  , 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.109375 , 0.109375 , 0.109375 , 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.140625 , 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.171875 , 0.171875 , 0.1875   , 0.1953125, 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.3671875, 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.4921875, 0.5      ,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.01639344, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.687 , 0.6562, 0.6494, 0.647 , 0.64  , 0.636 , 0.6323,\n",
       "            0.6313, 0.631 , 0.6235, 0.62  , 0.6133, 0.612 , 0.6006, 0.5986,\n",
       "            0.5957, 0.594 , 0.587 , 0.585 , 0.583 , 0.5825, 0.579 , 0.5776,\n",
       "            0.577 , 0.5747, 0.5728, 0.5713, 0.5664, 0.5654, 0.564 , 0.56  ,\n",
       "            0.5596, 0.557 , 0.556 , 0.5537, 0.5513, 0.551 , 0.543 , 0.5376,\n",
       "            0.531 , 0.529 , 0.526 , 0.524 , 0.522 , 0.521 , 0.5176, 0.517 ,\n",
       "            0.5166, 0.514 , 0.51  , 0.5034, 0.4966, 0.4963, 0.4956, 0.4944,\n",
       "            0.4927, 0.492 , 0.4905, 0.489 , 0.4885, 0.486 , 0.4854, 0.484 ,\n",
       "            0.4817, 0.4802, 0.48  , 0.4795, 0.4788, 0.478 , 0.4775, 0.4753,\n",
       "            0.475 , 0.4749, 0.4746, 0.4695, 0.4688, 0.4646, 0.4639, 0.463 ,\n",
       "            0.4626, 0.462 , 0.4612, 0.4597, 0.4592, 0.4583, 0.4568, 0.456 ,\n",
       "            0.4539, 0.4507, 0.4492, 0.4478, 0.4475, 0.447 , 0.4465, 0.4463,\n",
       "            0.4458, 0.4456, 0.4453, 0.4443, 0.444 , 0.4438, 0.4436, 0.4429,\n",
       "            0.4424, 0.4414, 0.4404, 0.4392, 0.4385, 0.4348, 0.4329, 0.43  ,\n",
       "            0.4287, 0.4285, 0.4272, 0.4268, 0.4263, 0.4253, 0.425 , 0.4236,\n",
       "            0.4229, 0.422 , 0.4214, 0.4207, 0.4197, 0.4192, 0.419 , 0.4177,\n",
       "            0.4172, 0.4143, 0.4128, 0.4126, 0.4124, 0.4114, 0.4102, 0.41  ,\n",
       "            0.4092, 0.4043, 0.4038, 0.3987, 0.3982, 0.3972, 0.3962, 0.3953,\n",
       "            0.395 , 0.3938, 0.3936, 0.3928, 0.3923, 0.391 , 0.3901, 0.3896,\n",
       "            0.3887, 0.3882, 0.3877, 0.387 , 0.384 , 0.3826, 0.3823, 0.3816,\n",
       "            0.3804, 0.3777, 0.3774, 0.3767, 0.376 , 0.3757, 0.3733, 0.3723,\n",
       "            0.3718, 0.3713, 0.371 , 0.3706, 0.3704, 0.3699, 0.3694, 0.369 ,\n",
       "            0.3677, 0.3674, 0.3672, 0.367 , 0.3657, 0.3652, 0.3647, 0.364 ,\n",
       "            0.3633, 0.3604, 0.3586, 0.3542, 0.354 , 0.3533, 0.3525, 0.3518,\n",
       "            0.35  , 0.3489, 0.347 , 0.3442, 0.343 , 0.3425, 0.3408, 0.3386,\n",
       "            0.3362, 0.3354, 0.3242, 0.324 , 0.3215, 0.3076, 0.3044, 0.304 ,\n",
       "            0.3032, 0.3025, 0.3005, 0.2915, 0.2913, 0.286 , 0.2856, 0.273 ,\n",
       "            0.271 , 0.2688, 0.2673, 0.2664, 0.2426, 0.2424, 0.2374, 0.2314,\n",
       "            0.2278, 0.202 , 0.2012], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.015625, dtype=float32),\n",
       "    'tpr': array(0.57377046, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.0546875,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.0859375,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.140625 ,\n",
       "            0.140625 , 0.1484375, 0.1640625, 0.1640625, 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.2890625, 0.3046875, 0.3125   , 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.43442622, 0.44262296, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.47540984, 0.4918033 , 0.5       , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.89344263, 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.719 , 0.718 , 0.6865, 0.68  , 0.6777, 0.673 , 0.6685,\n",
       "            0.6597, 0.659 , 0.655 , 0.647 , 0.641 , 0.638 , 0.6265, 0.625 ,\n",
       "            0.624 , 0.621 , 0.6157, 0.6094, 0.609 , 0.6084, 0.6064, 0.6035,\n",
       "            0.601 , 0.599 , 0.598 , 0.5977, 0.593 , 0.59  , 0.589 , 0.5854,\n",
       "            0.585 , 0.583 , 0.5806, 0.578 , 0.5757, 0.574 , 0.5654, 0.5596,\n",
       "            0.5537, 0.5513, 0.5464, 0.546 , 0.5435, 0.542 , 0.5405, 0.54  ,\n",
       "            0.5396, 0.531 , 0.5264, 0.525 , 0.523 , 0.516 , 0.514 , 0.5137,\n",
       "            0.513 , 0.5127, 0.5117, 0.511 , 0.5107, 0.506 , 0.503 , 0.5024,\n",
       "            0.5005, 0.4995, 0.4985, 0.4983, 0.498 , 0.4978, 0.495 , 0.4946,\n",
       "            0.4934, 0.4907, 0.4905, 0.49  , 0.4893, 0.4866, 0.4824, 0.4814,\n",
       "            0.4812, 0.4805, 0.4802, 0.4792, 0.4773, 0.4756, 0.4753, 0.475 ,\n",
       "            0.474 , 0.4712, 0.471 , 0.4688, 0.4683, 0.4675, 0.4673, 0.4666,\n",
       "            0.4658, 0.4646, 0.464 , 0.4636, 0.4626, 0.4622, 0.462 , 0.4617,\n",
       "            0.461 , 0.4597, 0.4592, 0.4573, 0.4563, 0.4558, 0.454 , 0.4517,\n",
       "            0.4495, 0.4485, 0.445 , 0.4448, 0.4443, 0.4434, 0.4421, 0.4417,\n",
       "            0.4397, 0.4392, 0.4387, 0.4385, 0.4375, 0.4333, 0.4329, 0.4326,\n",
       "            0.4324, 0.431 , 0.4297, 0.429 , 0.4277, 0.426 , 0.4255, 0.4238,\n",
       "            0.423 , 0.422 , 0.416 , 0.4153, 0.4128, 0.4126, 0.4124, 0.4119,\n",
       "            0.4104, 0.4087, 0.4062, 0.4043, 0.404 , 0.4033, 0.403 , 0.4023,\n",
       "            0.4016, 0.4001, 0.399 , 0.3965, 0.3962, 0.396 , 0.3958, 0.3955,\n",
       "            0.3945, 0.393 , 0.3923, 0.392 , 0.3906, 0.3884, 0.3882, 0.388 ,\n",
       "            0.3877, 0.3875, 0.3867, 0.386 , 0.3853, 0.3838, 0.3833, 0.382 ,\n",
       "            0.3818, 0.3813, 0.3809, 0.3806, 0.38  , 0.3796, 0.3782, 0.3777,\n",
       "            0.3738, 0.3723, 0.3704, 0.3691, 0.3687, 0.3677, 0.367 , 0.3645,\n",
       "            0.358 , 0.3538, 0.3533, 0.3477, 0.347 , 0.3457, 0.344 , 0.3418,\n",
       "            0.3394, 0.339 , 0.3264, 0.3262, 0.3235, 0.3079, 0.3042, 0.304 ,\n",
       "            0.3025, 0.3003, 0.293 , 0.2903, 0.2844, 0.2842, 0.271 , 0.2688,\n",
       "            0.2664, 0.2656, 0.2637, 0.2399, 0.2394, 0.2338, 0.2281, 0.2239,\n",
       "            0.1976, 0.197 , 0.1959], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.0390625, dtype=float32),\n",
       "    'tpr': array(0.7295082, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0546875, 0.0546875,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.1484375, 0.1484375,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.21875  , 0.2265625, 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.9296875, 0.9375   , 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13934426, 0.14754099, 0.1557377 , 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.36065573,\n",
       "            0.37704918, 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.44262296, 0.44262296, 0.45081967, 0.47540984,\n",
       "            0.48360655, 0.5       , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.5491803 , 0.55737704, 0.56557375, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.647541  , 0.6557377 , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6803279 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.795082  , 0.8032787 ,\n",
       "            0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7524, 0.75  , 0.719 , 0.7124, 0.71  , 0.7065, 0.7017,\n",
       "            0.6904, 0.69  , 0.6895, 0.6875, 0.6763, 0.671 , 0.6665, 0.655 ,\n",
       "            0.654 , 0.65  , 0.6465, 0.6377, 0.636 , 0.631 , 0.628 , 0.627 ,\n",
       "            0.626 , 0.625 , 0.621 , 0.6177, 0.6147, 0.613 , 0.6123, 0.612 ,\n",
       "            0.6074, 0.6064, 0.6006, 0.5903, 0.584 , 0.581 , 0.5747, 0.573 ,\n",
       "            0.569 , 0.567 , 0.566 , 0.565 , 0.557 , 0.5566, 0.554 , 0.5454,\n",
       "            0.541 , 0.5405, 0.54  , 0.5396, 0.5376, 0.536 , 0.534 , 0.532 ,\n",
       "            0.5317, 0.53  , 0.5283, 0.526 , 0.524 , 0.5234, 0.5225, 0.52  ,\n",
       "            0.5195, 0.519 , 0.5186, 0.5166, 0.513 , 0.512 , 0.5107, 0.506 ,\n",
       "            0.5054, 0.5044, 0.5034, 0.503 , 0.502 , 0.5   , 0.498 , 0.4978,\n",
       "            0.4973, 0.4963, 0.4954, 0.4934, 0.493 , 0.491 , 0.4907, 0.4866,\n",
       "            0.4863, 0.486 , 0.484 , 0.4834, 0.4832, 0.4827, 0.4824, 0.4783,\n",
       "            0.4773, 0.4768, 0.4763, 0.4758, 0.4746, 0.4724, 0.4707, 0.4702,\n",
       "            0.4678, 0.4646, 0.464 , 0.4636, 0.4634, 0.4602, 0.4595, 0.4563,\n",
       "            0.4553, 0.455 , 0.454 , 0.4536, 0.4526, 0.4512, 0.4507, 0.449 ,\n",
       "            0.445 , 0.4448, 0.4446, 0.4426, 0.4414, 0.4402, 0.44  , 0.4363,\n",
       "            0.4336, 0.433 , 0.432 , 0.4294, 0.4292, 0.4275, 0.4268, 0.4255,\n",
       "            0.424 , 0.4233, 0.4226, 0.4224, 0.421 , 0.4207, 0.4202, 0.4192,\n",
       "            0.4187, 0.4143, 0.4136, 0.413 , 0.4124, 0.412 , 0.4116, 0.4114,\n",
       "            0.4104, 0.4102, 0.4094, 0.4092, 0.4087, 0.4084, 0.407 , 0.4058,\n",
       "            0.4053, 0.4043, 0.4038, 0.4036, 0.403 , 0.4023, 0.4014, 0.401 ,\n",
       "            0.4001, 0.3987, 0.3984, 0.398 , 0.3975, 0.3972, 0.3967, 0.3962,\n",
       "            0.3958, 0.3933, 0.3923, 0.39  , 0.3877, 0.387 , 0.3855, 0.3853,\n",
       "            0.3835, 0.3706, 0.3662, 0.362 , 0.361 , 0.3525, 0.3518, 0.3508,\n",
       "            0.3489, 0.3464, 0.3452, 0.3438, 0.33  , 0.3298, 0.3262, 0.31  ,\n",
       "            0.3054, 0.305 , 0.3035, 0.3032, 0.301 , 0.2969, 0.2903, 0.2844,\n",
       "            0.284 , 0.2837, 0.2698, 0.2676, 0.265 , 0.2622, 0.2375, 0.2306,\n",
       "            0.2252, 0.2211, 0.1953, 0.1925, 0.1913], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.0546875, dtype=float32),\n",
       "    'tpr': array(0.852459, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.0546875, 0.0546875,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0546875, 0.0546875, 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.1015625, 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.1171875, 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.125    , 0.1328125, 0.1328125, 0.140625 , 0.1484375, 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.265625 , 0.2734375, 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.515625 , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6803279 , 0.6885246 , 0.704918  , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.73770493, 0.74590164, 0.76229507, 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.90163934, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.779 , 0.775 , 0.7446, 0.738 , 0.7354, 0.734 , 0.7285,\n",
       "            0.715 , 0.714 , 0.713 , 0.6997, 0.6953, 0.6895, 0.678 , 0.6777,\n",
       "            0.677 , 0.6733, 0.6714, 0.662 , 0.6606, 0.6597, 0.659 , 0.653 ,\n",
       "            0.65  , 0.6494, 0.6475, 0.6465, 0.6436, 0.6406, 0.636 , 0.6353,\n",
       "            0.635 , 0.6343, 0.631 , 0.627 , 0.6216, 0.6206, 0.611 , 0.604 ,\n",
       "            0.603 , 0.595 , 0.5947, 0.5933, 0.5903, 0.589 , 0.588 , 0.5874,\n",
       "            0.586 , 0.5854, 0.5845, 0.584 , 0.582 , 0.5728, 0.569 , 0.5684,\n",
       "            0.565 , 0.564 , 0.5635, 0.562 , 0.561 , 0.56  , 0.5586, 0.5576,\n",
       "            0.5566, 0.554 , 0.5537, 0.5503, 0.549 , 0.5483, 0.5474, 0.547 ,\n",
       "            0.5464, 0.5444, 0.543 , 0.5415, 0.535 , 0.5347, 0.532 , 0.5312,\n",
       "            0.528 , 0.5273, 0.526 , 0.524 , 0.5234, 0.523 , 0.5225, 0.5195,\n",
       "            0.5166, 0.516 , 0.5156, 0.515 , 0.5146, 0.51  , 0.5093, 0.506 ,\n",
       "            0.505 , 0.5034, 0.503 , 0.501 , 0.4988, 0.498 , 0.4963, 0.4941,\n",
       "            0.4917, 0.4915, 0.4902, 0.4885, 0.4856, 0.4834, 0.482 , 0.4814,\n",
       "            0.4805, 0.478 , 0.4768, 0.4763, 0.4756, 0.474 , 0.4712, 0.4702,\n",
       "            0.4675, 0.4653, 0.465 , 0.4626, 0.461 , 0.4607, 0.4575, 0.4556,\n",
       "            0.455 , 0.4548, 0.4543, 0.4524, 0.4521, 0.452 , 0.449 , 0.4463,\n",
       "            0.4456, 0.4448, 0.4426, 0.4414, 0.4407, 0.4404, 0.4392, 0.4377,\n",
       "            0.437 , 0.4355, 0.434 , 0.4324, 0.4321, 0.4314, 0.43  , 0.4297,\n",
       "            0.4255, 0.425 , 0.4238, 0.423 , 0.4226, 0.4224, 0.422 , 0.4216,\n",
       "            0.419 , 0.4182, 0.4177, 0.4175, 0.417 , 0.4163, 0.416 , 0.4143,\n",
       "            0.4138, 0.4119, 0.4114, 0.4106, 0.4102, 0.41  , 0.4094, 0.4092,\n",
       "            0.4087, 0.4084, 0.4082, 0.408 , 0.407 , 0.4028, 0.4016, 0.401 ,\n",
       "            0.4006, 0.3992, 0.3965, 0.396 , 0.394 , 0.3918, 0.3914, 0.374 ,\n",
       "            0.3708, 0.3662, 0.3652, 0.3552, 0.353 , 0.3513, 0.3486, 0.348 ,\n",
       "            0.3464, 0.3315, 0.331 , 0.3281, 0.3093, 0.3052, 0.3037, 0.3025,\n",
       "            0.3018, 0.3003, 0.2969, 0.2883, 0.282 , 0.2815, 0.2812, 0.267 ,\n",
       "            0.2646, 0.2634, 0.2617, 0.2588, 0.2347, 0.233 , 0.2263, 0.222 ,\n",
       "            0.2158, 0.1903, 0.1876, 0.1858], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.0859375, dtype=float32),\n",
       "    'tpr': array(0.91803277, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0546875, 0.0546875, 0.0546875, 0.0546875,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.078125 , 0.078125 , 0.078125 , 0.078125 , 0.0859375,\n",
       "            0.0859375, 0.1015625, 0.109375 , 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.125    , 0.125    , 0.125    , 0.1328125, 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.234375 , 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4453125,\n",
       "            0.453125 , 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.5390625, 0.546875 , 0.5546875, 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.71311474, 0.71311474, 0.71311474, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.795082  , 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.809 , 0.804 , 0.775 , 0.7686, 0.7666, 0.766 , 0.7607,\n",
       "            0.746 , 0.7446, 0.743 , 0.741 , 0.7275, 0.724 , 0.7173, 0.708 ,\n",
       "            0.705 , 0.7046, 0.702 , 0.7017, 0.6934, 0.689 , 0.6865, 0.6797,\n",
       "            0.6787, 0.6753, 0.674 , 0.6733, 0.6724, 0.669 , 0.664 , 0.663 ,\n",
       "            0.6616, 0.66  , 0.653 , 0.6475, 0.645 , 0.6357, 0.631 , 0.628 ,\n",
       "            0.6235, 0.622 , 0.618 , 0.6177, 0.616 , 0.6147, 0.6143, 0.613 ,\n",
       "            0.611 , 0.61  , 0.6094, 0.6064, 0.5986, 0.597 , 0.596 , 0.591 ,\n",
       "            0.59  , 0.589 , 0.5884, 0.5874, 0.587 , 0.586 , 0.585 , 0.583 ,\n",
       "            0.5815, 0.5806, 0.577 , 0.5767, 0.576 , 0.5757, 0.5728, 0.5713,\n",
       "            0.571 , 0.5703, 0.569 , 0.5684, 0.568 , 0.567 , 0.5605, 0.556 ,\n",
       "            0.5557, 0.555 , 0.5547, 0.5522, 0.5513, 0.55  , 0.5493, 0.5454,\n",
       "            0.544 , 0.543 , 0.5425, 0.542 , 0.5405, 0.539 , 0.5366, 0.536 ,\n",
       "            0.5356, 0.534 , 0.5337, 0.528 , 0.527 , 0.526 , 0.5244, 0.522 ,\n",
       "            0.5215, 0.519 , 0.518 , 0.512 , 0.5107, 0.5103, 0.51  , 0.5073,\n",
       "            0.5063, 0.5024, 0.5015, 0.5   , 0.498 , 0.4958, 0.4956, 0.4934,\n",
       "            0.49  , 0.4897, 0.4824, 0.4773, 0.4753, 0.474 , 0.4734, 0.4727,\n",
       "            0.4722, 0.4707, 0.4695, 0.468 , 0.4668, 0.4663, 0.4656, 0.4653,\n",
       "            0.4612, 0.4597, 0.459 , 0.4585, 0.4573, 0.4565, 0.4556, 0.455 ,\n",
       "            0.4546, 0.454 , 0.451 , 0.4504, 0.4497, 0.4475, 0.4465, 0.4453,\n",
       "            0.4446, 0.4438, 0.4436, 0.44  , 0.4397, 0.439 , 0.4385, 0.438 ,\n",
       "            0.4377, 0.4375, 0.4368, 0.4353, 0.4316, 0.4312, 0.431 , 0.4297,\n",
       "            0.4282, 0.428 , 0.4275, 0.4272, 0.4265, 0.4263, 0.4248, 0.4246,\n",
       "            0.4236, 0.4233, 0.4211, 0.4207, 0.418 , 0.4175, 0.4165, 0.4155,\n",
       "            0.414 , 0.4128, 0.4116, 0.4111, 0.4077, 0.398 , 0.3975, 0.3787,\n",
       "            0.3784, 0.3748, 0.3718, 0.359 , 0.3586, 0.3564, 0.3545, 0.3528,\n",
       "            0.352 , 0.3496, 0.3337, 0.3335, 0.3296, 0.3103, 0.305 , 0.3032,\n",
       "            0.3018, 0.301 , 0.3003, 0.2993, 0.2869, 0.281 , 0.2798, 0.2795,\n",
       "            0.2644, 0.2622, 0.2612, 0.259 , 0.2563, 0.2314, 0.2302, 0.222 ,\n",
       "            0.2184, 0.2119, 0.1873, 0.1824, 0.1804], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.125, dtype=float32),\n",
       "    'tpr': array(0.9508197, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0546875,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0546875, 0.0546875, 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.078125 , 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.0859375, 0.0859375, 0.0859375, 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.125    , 0.125    , 0.125    , 0.125    ,\n",
       "            0.125    , 0.125    , 0.1328125, 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.25     , 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.515625 , 0.5234375, 0.53125  , 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5327869 , 0.5409836 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.71311474, 0.72131145,\n",
       "            0.73770493, 0.75409836, 0.76229507, 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8296, 0.8247, 0.797 , 0.789 , 0.788 , 0.7866, 0.782 ,\n",
       "            0.767 , 0.765 , 0.7646, 0.7617, 0.7476, 0.7446, 0.7373, 0.728 ,\n",
       "            0.725 , 0.724 , 0.7227, 0.721 , 0.7134, 0.7085, 0.706 , 0.7056,\n",
       "            0.699 , 0.698 , 0.6943, 0.6924, 0.6914, 0.688 , 0.6836, 0.6816,\n",
       "            0.68  , 0.6797, 0.671 , 0.6665, 0.663 , 0.654 , 0.649 , 0.645 ,\n",
       "            0.6416, 0.64  , 0.6377, 0.6357, 0.6353, 0.634 , 0.6323, 0.628 ,\n",
       "            0.626 , 0.6235, 0.6226, 0.6216, 0.613 , 0.6123, 0.612 , 0.6113,\n",
       "            0.61  , 0.6084, 0.6074, 0.603 , 0.6025, 0.6016, 0.601 , 0.5996,\n",
       "            0.599 , 0.5977, 0.597 , 0.5957, 0.5923, 0.591 , 0.59  , 0.5894,\n",
       "            0.5874, 0.584 , 0.5806, 0.575 , 0.5747, 0.573 , 0.5713, 0.5703,\n",
       "            0.57  , 0.569 , 0.568 , 0.564 , 0.5625, 0.5615, 0.5596, 0.559 ,\n",
       "            0.5586, 0.5576, 0.553 , 0.5527, 0.55  , 0.5493, 0.548 , 0.545 ,\n",
       "            0.542 , 0.541 , 0.5405, 0.5386, 0.537 , 0.531 , 0.5303, 0.524 ,\n",
       "            0.5234, 0.5225, 0.521 , 0.5186, 0.518 , 0.5176, 0.516 , 0.5156,\n",
       "            0.515 , 0.512 , 0.5117, 0.509 , 0.505 , 0.503 , 0.4988, 0.495 ,\n",
       "            0.4927, 0.4863, 0.4854, 0.4846, 0.4844, 0.4841, 0.482 , 0.4812,\n",
       "            0.48  , 0.478 , 0.476 , 0.4744, 0.4739, 0.4727, 0.47  , 0.4697,\n",
       "            0.4683, 0.4678, 0.4673, 0.4666, 0.4653, 0.465 , 0.4639, 0.4622,\n",
       "            0.461 , 0.4585, 0.457 , 0.456 , 0.4548, 0.4543, 0.4539, 0.4534,\n",
       "            0.4512, 0.4502, 0.45  , 0.4485, 0.4465, 0.4458, 0.4453, 0.445 ,\n",
       "            0.4446, 0.4443, 0.444 , 0.4438, 0.4436, 0.4421, 0.4417, 0.438 ,\n",
       "            0.4375, 0.4365, 0.4353, 0.4346, 0.434 , 0.4338, 0.4329, 0.432 ,\n",
       "            0.4316, 0.4314, 0.4302, 0.428 , 0.4246, 0.4243, 0.4236, 0.4207,\n",
       "            0.4204, 0.4202, 0.4194, 0.4192, 0.4175, 0.4114, 0.4028, 0.4016,\n",
       "            0.3828, 0.3809, 0.3792, 0.3752, 0.3606, 0.36  , 0.3577, 0.3557,\n",
       "            0.3552, 0.3535, 0.3508, 0.334 , 0.3337, 0.3298, 0.3088, 0.3032,\n",
       "            0.3013, 0.3003, 0.2998, 0.2983, 0.2974, 0.2837, 0.2783, 0.2766,\n",
       "            0.2764, 0.2607, 0.2585, 0.2583, 0.2551, 0.252 , 0.2277, 0.2256,\n",
       "            0.2172, 0.214 , 0.2065, 0.1824, 0.177 , 0.1744], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.125, dtype=float32),\n",
       "    'tpr': array(0.9836066, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.0546875,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.078125 , 0.0859375,\n",
       "            0.0859375, 0.0859375, 0.0859375, 0.0859375, 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.109375 , 0.1171875, 0.125    , 0.125    ,\n",
       "            0.125    , 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.1484375,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.546875 , 0.5546875, 0.5625   , 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.73770493, 0.76229507, 0.77868855,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.848 , 0.843 , 0.818 , 0.808 , 0.8066, 0.8057, 0.8013,\n",
       "            0.786 , 0.785 , 0.784 , 0.7817, 0.7676, 0.7637, 0.757 , 0.747 ,\n",
       "            0.745 , 0.743 , 0.7407, 0.74  , 0.732 , 0.7275, 0.7266, 0.7246,\n",
       "            0.7188, 0.7163, 0.7134, 0.7114, 0.7104, 0.7095, 0.7056, 0.701 ,\n",
       "            0.6997, 0.699 , 0.698 , 0.6973, 0.689 , 0.686 , 0.681 , 0.673 ,\n",
       "            0.669 , 0.6655, 0.6626, 0.6616, 0.6577, 0.6562, 0.652 , 0.6514,\n",
       "            0.651 , 0.6494, 0.648 , 0.6436, 0.6426, 0.6396, 0.6377, 0.6367,\n",
       "            0.6357, 0.6343, 0.6333, 0.632 , 0.6274, 0.627 , 0.6265, 0.6245,\n",
       "            0.624 , 0.621 , 0.6206, 0.6167, 0.6157, 0.6147, 0.6143, 0.614 ,\n",
       "            0.6133, 0.6123, 0.612 , 0.6104, 0.6084, 0.607 , 0.601 , 0.599 ,\n",
       "            0.5967, 0.5957, 0.594 , 0.5913, 0.5903, 0.5845, 0.5835, 0.582 ,\n",
       "            0.5796, 0.579 , 0.576 , 0.573 , 0.5728, 0.5713, 0.5693, 0.5645,\n",
       "            0.564 , 0.5605, 0.5596, 0.559 , 0.5566, 0.5557, 0.542 , 0.5415,\n",
       "            0.535 , 0.5347, 0.533 , 0.5327, 0.532 , 0.5317, 0.531 , 0.528 ,\n",
       "            0.5234, 0.523 , 0.521 , 0.5205, 0.5176, 0.515 , 0.513 , 0.5093,\n",
       "            0.509 , 0.504 , 0.497 , 0.4966, 0.4954, 0.4946, 0.4922, 0.4902,\n",
       "            0.4883, 0.486 , 0.4822, 0.482 , 0.4775, 0.4773, 0.4758, 0.4756,\n",
       "            0.4744, 0.474 , 0.4731, 0.4724, 0.4717, 0.468 , 0.4668, 0.4663,\n",
       "            0.464 , 0.4636, 0.4634, 0.4597, 0.4595, 0.4585, 0.4583, 0.4565,\n",
       "            0.4543, 0.454 , 0.4534, 0.4524, 0.4517, 0.4495, 0.4492, 0.449 ,\n",
       "            0.4475, 0.4473, 0.446 , 0.4453, 0.444 , 0.441 , 0.4404, 0.4402,\n",
       "            0.4397, 0.4387, 0.438 , 0.4377, 0.4365, 0.4353, 0.435 , 0.4348,\n",
       "            0.4338, 0.4326, 0.4302, 0.4275, 0.426 , 0.4253, 0.4248, 0.4216,\n",
       "            0.4214, 0.4192, 0.4172, 0.4116, 0.4087, 0.3882, 0.3845, 0.3843,\n",
       "            0.38  , 0.3647, 0.363 , 0.3604, 0.3591, 0.3584, 0.356 , 0.3542,\n",
       "            0.3347, 0.3345, 0.3328, 0.3083, 0.3037, 0.3005, 0.3003, 0.299 ,\n",
       "            0.2969, 0.2966, 0.282 , 0.2764, 0.2744, 0.2742, 0.2583, 0.258 ,\n",
       "            0.2556, 0.2524, 0.249 , 0.2257, 0.2213, 0.2133, 0.2118, 0.2017,\n",
       "            0.178 , 0.1729, 0.1698], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1875, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0546875,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.0859375, 0.0859375,\n",
       "            0.09375  , 0.109375 , 0.109375 , 0.109375 , 0.1171875, 0.125    ,\n",
       "            0.125    , 0.125    , 0.125    , 0.1328125, 0.140625 , 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.2704918 , 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8696, 0.8643, 0.842 , 0.831 , 0.8306, 0.8286, 0.8247,\n",
       "            0.809 , 0.807 , 0.8047, 0.7905, 0.7866, 0.78  , 0.7705, 0.7686,\n",
       "            0.766 , 0.764 , 0.763 , 0.7554, 0.75  , 0.747 , 0.742 , 0.7393,\n",
       "            0.7363, 0.734 , 0.733 , 0.7324, 0.7285, 0.724 , 0.722 , 0.72  ,\n",
       "            0.711 , 0.7095, 0.7026, 0.701 , 0.6963, 0.696 , 0.6914, 0.6875,\n",
       "            0.6836, 0.6816, 0.6797, 0.678 , 0.6777, 0.674 , 0.67  , 0.6694,\n",
       "            0.667 , 0.6665, 0.6655, 0.6646, 0.663 , 0.6626, 0.6616, 0.6606,\n",
       "            0.66  , 0.6587, 0.656 , 0.654 , 0.652 , 0.649 , 0.6484, 0.647 ,\n",
       "            0.642 , 0.6406, 0.639 , 0.6387, 0.637 , 0.6367, 0.6357, 0.6343,\n",
       "            0.632 , 0.626 , 0.622 , 0.621 , 0.6206, 0.616 , 0.6147, 0.6133,\n",
       "            0.61  , 0.606 , 0.605 , 0.604 , 0.6035, 0.6025, 0.602 , 0.601 ,\n",
       "            0.5996, 0.596 , 0.5947, 0.592 , 0.588 , 0.5874, 0.586 , 0.5845,\n",
       "            0.582 , 0.581 , 0.5786, 0.578 , 0.5767, 0.5757, 0.5615, 0.558 ,\n",
       "            0.5576, 0.555 , 0.553 , 0.5513, 0.5503, 0.5493, 0.548 , 0.547 ,\n",
       "            0.542 , 0.5415, 0.54  , 0.536 , 0.535 , 0.5347, 0.5283, 0.528 ,\n",
       "            0.526 , 0.5205, 0.518 , 0.513 , 0.512 , 0.5073, 0.507 , 0.506 ,\n",
       "            0.504 , 0.5015, 0.501 , 0.4998, 0.4946, 0.4932, 0.493 , 0.4927,\n",
       "            0.4917, 0.4893, 0.4875, 0.4858, 0.4846, 0.4844, 0.483 , 0.4827,\n",
       "            0.4812, 0.4792, 0.4778, 0.4763, 0.4746, 0.4727, 0.471 , 0.4707,\n",
       "            0.4697, 0.4695, 0.4685, 0.4683, 0.4678, 0.4666, 0.4648, 0.462 ,\n",
       "            0.4617, 0.46  , 0.4585, 0.4583, 0.4568, 0.4563, 0.4558, 0.4546,\n",
       "            0.451 , 0.4507, 0.4502, 0.4492, 0.4485, 0.448 , 0.4465, 0.4458,\n",
       "            0.4453, 0.444 , 0.4434, 0.443 , 0.4414, 0.4363, 0.435 , 0.434 ,\n",
       "            0.4338, 0.4312, 0.4297, 0.4292, 0.427 , 0.424 , 0.4214, 0.4165,\n",
       "            0.395 , 0.3916, 0.3887, 0.3855, 0.3696, 0.3662, 0.3638, 0.363 ,\n",
       "            0.3616, 0.3591, 0.358 , 0.3364, 0.3354, 0.335 , 0.3083, 0.3042,\n",
       "            0.3025, 0.2993, 0.2983, 0.2961, 0.2957, 0.2805, 0.2747, 0.2722,\n",
       "            0.2576, 0.2556, 0.253 , 0.2494, 0.246 , 0.2239, 0.2177, 0.2095,\n",
       "            0.2094, 0.1973, 0.1744, 0.1686, 0.1653], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.234375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.0546875,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.0859375, 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.09375  , 0.109375 , 0.109375 , 0.1171875,\n",
       "            0.125    , 0.125    , 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1484375, 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.765625 , 0.7734375,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.2704918 , 0.28688523, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.43442622, 0.44262296,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.63114756,\n",
       "            0.6393443 , 0.6393443 , 0.647541  , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.90163934, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8867, 0.8813, 0.86  , 0.8496, 0.847 , 0.844 , 0.8286,\n",
       "            0.828 , 0.8267, 0.824 , 0.81  , 0.806 , 0.8003, 0.79  , 0.788 ,\n",
       "            0.7856, 0.784 , 0.7827, 0.7754, 0.7695, 0.769 , 0.7666, 0.7617,\n",
       "            0.759 , 0.755 , 0.754 , 0.7524, 0.752 , 0.748 , 0.744 , 0.741 ,\n",
       "            0.7397, 0.73  , 0.7285, 0.725 , 0.722 , 0.7207, 0.715 , 0.7124,\n",
       "            0.708 , 0.7065, 0.702 , 0.6987, 0.6973, 0.697 , 0.696 , 0.6934,\n",
       "            0.693 , 0.69  , 0.6885, 0.688 , 0.687 , 0.685 , 0.684 , 0.6836,\n",
       "            0.6826, 0.6816, 0.681 , 0.6807, 0.6777, 0.6772, 0.676 , 0.6704,\n",
       "            0.667 , 0.666 , 0.664 , 0.6636, 0.6616, 0.6533, 0.652 , 0.6504,\n",
       "            0.6494, 0.649 , 0.6465, 0.6426, 0.6416, 0.64  , 0.6377, 0.636 ,\n",
       "            0.6294, 0.629 , 0.6284, 0.6274, 0.626 , 0.624 , 0.619 , 0.6167,\n",
       "            0.616 , 0.615 , 0.6147, 0.611 , 0.6104, 0.61  , 0.609 , 0.604 ,\n",
       "            0.6035, 0.6016, 0.6   , 0.5957, 0.5938, 0.592 , 0.5815, 0.578 ,\n",
       "            0.576 , 0.572 , 0.5713, 0.57  , 0.5645, 0.563 , 0.5615, 0.561 ,\n",
       "            0.5605, 0.559 , 0.556 , 0.5547, 0.553 , 0.5493, 0.543 , 0.541 ,\n",
       "            0.539 , 0.5317, 0.5312, 0.5293, 0.5283, 0.522 , 0.5195, 0.5166,\n",
       "            0.5146, 0.514 , 0.513 , 0.5117, 0.51  , 0.5083, 0.5054, 0.502 ,\n",
       "            0.498 , 0.497 , 0.4963, 0.4954, 0.4944, 0.4941, 0.494 , 0.492 ,\n",
       "            0.491 , 0.4902, 0.4895, 0.4883, 0.4836, 0.4834, 0.4832, 0.4805,\n",
       "            0.4795, 0.4792, 0.4788, 0.4778, 0.4766, 0.4744, 0.4731, 0.4707,\n",
       "            0.4688, 0.4685, 0.4673, 0.4666, 0.4663, 0.4634, 0.4631, 0.4624,\n",
       "            0.462 , 0.4578, 0.4568, 0.4565, 0.4556, 0.4543, 0.454 , 0.4531,\n",
       "            0.4512, 0.4507, 0.4504, 0.4487, 0.4417, 0.4412, 0.441 , 0.4404,\n",
       "            0.4365, 0.436 , 0.4333, 0.4321, 0.43  , 0.424 , 0.3992, 0.396 ,\n",
       "            0.3914, 0.39  , 0.3735, 0.3684, 0.366 , 0.363 , 0.361 , 0.34  ,\n",
       "            0.3352, 0.3342, 0.3071, 0.3042, 0.3022, 0.2974, 0.2969, 0.2947,\n",
       "            0.2932, 0.2783, 0.2722, 0.2693, 0.2576, 0.2527, 0.2496, 0.246 ,\n",
       "            0.2422, 0.222 , 0.213 , 0.2074, 0.2053, 0.1923, 0.1698, 0.1646,\n",
       "            0.161 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.234375, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.0859375, 0.0859375, 0.0859375, 0.09375  , 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.1171875, 0.1171875, 0.125    , 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.234375 , 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6229508 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.89344263, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8955, 0.891 , 0.8735, 0.859 , 0.8574, 0.8564, 0.852 ,\n",
       "            0.842 , 0.8364, 0.836 , 0.821 , 0.8154, 0.811 , 0.8   , 0.7983,\n",
       "            0.7954, 0.7915, 0.791 , 0.7817, 0.781 , 0.778 , 0.7754, 0.7734,\n",
       "            0.766 , 0.7656, 0.763 , 0.7607, 0.7583, 0.755 , 0.752 , 0.7495,\n",
       "            0.748 , 0.7466, 0.746 , 0.7446, 0.741 , 0.738 , 0.7363, 0.731 ,\n",
       "            0.726 , 0.721 , 0.71  , 0.709 , 0.7085, 0.708 , 0.7056, 0.7036,\n",
       "            0.7017, 0.701 , 0.7   , 0.6997, 0.6987, 0.696 , 0.695 , 0.6943,\n",
       "            0.694 , 0.692 , 0.691 , 0.6904, 0.688 , 0.687 , 0.6865, 0.686 ,\n",
       "            0.6855, 0.679 , 0.6772, 0.6763, 0.6753, 0.675 , 0.6724, 0.668 ,\n",
       "            0.6597, 0.6562, 0.6553, 0.655 , 0.6543, 0.6514, 0.6494, 0.649 ,\n",
       "            0.6475, 0.644 , 0.642 , 0.6377, 0.636 , 0.635 , 0.6343, 0.6333,\n",
       "            0.633 , 0.626 , 0.6245, 0.617 , 0.6167, 0.615 , 0.614 , 0.6123,\n",
       "            0.609 , 0.608 , 0.6064, 0.6045, 0.602 , 0.5894, 0.5845, 0.5835,\n",
       "            0.578 , 0.5776, 0.577 , 0.5728, 0.5713, 0.568 , 0.5674, 0.561 ,\n",
       "            0.5596, 0.5586, 0.5557, 0.553 , 0.5513, 0.551 , 0.542 , 0.538 ,\n",
       "            0.537 , 0.5366, 0.5293, 0.529 , 0.528 , 0.527 , 0.526 , 0.5244,\n",
       "            0.5156, 0.5146, 0.514 , 0.512 , 0.511 , 0.5103, 0.503 , 0.502 ,\n",
       "            0.501 , 0.5005, 0.4934, 0.4924, 0.49  , 0.4846, 0.4822, 0.4814,\n",
       "            0.479 , 0.4785, 0.4775, 0.4768, 0.4763, 0.474 , 0.4734, 0.4714,\n",
       "            0.4702, 0.4673, 0.4663, 0.4653, 0.465 , 0.4648, 0.4646, 0.4624,\n",
       "            0.46  , 0.4585, 0.455 , 0.4539, 0.4524, 0.4504, 0.4495, 0.4485,\n",
       "            0.4482, 0.4453, 0.4443, 0.443 , 0.4426, 0.4407, 0.4395, 0.4392,\n",
       "            0.439 , 0.4387, 0.4375, 0.4355, 0.4353, 0.4343, 0.4336, 0.432 ,\n",
       "            0.4312, 0.4287, 0.4282, 0.427 , 0.4233, 0.419 , 0.4153, 0.4136,\n",
       "            0.4126, 0.4097, 0.3987, 0.3977, 0.3892, 0.3875, 0.371 , 0.3643,\n",
       "            0.3625, 0.3623, 0.3599, 0.358 , 0.3574, 0.3374, 0.3298, 0.3286,\n",
       "            0.3018, 0.301 , 0.2993, 0.2915, 0.291 , 0.289 , 0.2876, 0.2722,\n",
       "            0.2664, 0.263 , 0.2627, 0.254 , 0.2462, 0.243 , 0.2395, 0.2355,\n",
       "            0.2173, 0.207 , 0.2024, 0.1987, 0.1857, 0.1649, 0.1586, 0.155 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3203125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0546875, 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0703125, 0.078125 ,\n",
       "            0.0859375, 0.0859375, 0.0859375, 0.09375  , 0.09375  , 0.09375  ,\n",
       "            0.109375 , 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.1328125,\n",
       "            0.140625 , 0.140625 , 0.1484375, 0.15625  , 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     , 0.25     ,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.765625 , 0.7734375, 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8278689 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9165, 0.9116, 0.895 , 0.8833, 0.881 , 0.878 , 0.865 ,\n",
       "            0.864 , 0.8613, 0.8594, 0.846 , 0.8423, 0.836 , 0.8267, 0.825 ,\n",
       "            0.8223, 0.821 , 0.8193, 0.812 , 0.8066, 0.803 , 0.7993, 0.7954,\n",
       "            0.792 , 0.79  , 0.7886, 0.788 , 0.784 , 0.7803, 0.7783, 0.7773,\n",
       "            0.7764, 0.776 , 0.775 , 0.7695, 0.768 , 0.766 , 0.7646, 0.7573,\n",
       "            0.757 , 0.753 , 0.752 , 0.7417, 0.7397, 0.7393, 0.737 , 0.735 ,\n",
       "            0.734 , 0.732 , 0.7314, 0.7295, 0.7275, 0.727 , 0.7266, 0.726 ,\n",
       "            0.7256, 0.7227, 0.722 , 0.7197, 0.717 , 0.7163, 0.7144, 0.712 ,\n",
       "            0.7114, 0.709 , 0.7065, 0.706 , 0.7026, 0.7007, 0.697 , 0.695 ,\n",
       "            0.6885, 0.685 , 0.684 , 0.6836, 0.683 , 0.6807, 0.679 , 0.6772,\n",
       "            0.6743, 0.6733, 0.6665, 0.666 , 0.6655, 0.665 , 0.663 , 0.6616,\n",
       "            0.6597, 0.6587, 0.654 , 0.651 , 0.6494, 0.646 , 0.6455, 0.6445,\n",
       "            0.643 , 0.637 , 0.6367, 0.6333, 0.6294, 0.6274, 0.6187, 0.616 ,\n",
       "            0.6133, 0.6104, 0.607 , 0.6016, 0.6006, 0.5996, 0.599 , 0.5957,\n",
       "            0.595 , 0.5864, 0.5845, 0.583 , 0.5825, 0.5815, 0.58  , 0.576 ,\n",
       "            0.569 , 0.5684, 0.5596, 0.5586, 0.553 , 0.552 , 0.5513, 0.5493,\n",
       "            0.547 , 0.544 , 0.538 , 0.536 , 0.5347, 0.533 , 0.5327, 0.5312,\n",
       "            0.53  , 0.529 , 0.5273, 0.5205, 0.5195, 0.517 , 0.516 , 0.5146,\n",
       "            0.509 , 0.508 , 0.5073, 0.507 , 0.5063, 0.5054, 0.5034, 0.499 ,\n",
       "            0.4978, 0.4973, 0.497 , 0.494 , 0.4934, 0.493 , 0.4912, 0.49  ,\n",
       "            0.488 , 0.4875, 0.487 , 0.486 , 0.4841, 0.4814, 0.4802, 0.479 ,\n",
       "            0.4778, 0.474 , 0.4736, 0.4731, 0.4724, 0.469 , 0.468 , 0.4636,\n",
       "            0.4634, 0.4624, 0.461 , 0.4607, 0.46  , 0.4597, 0.459 , 0.4573,\n",
       "            0.4548, 0.4546, 0.453 , 0.4504, 0.4487, 0.448 , 0.445 , 0.4438,\n",
       "            0.4421, 0.4387, 0.438 , 0.4375, 0.4348, 0.4346, 0.4102, 0.4062,\n",
       "            0.3994, 0.3955, 0.3784, 0.371 , 0.3694, 0.3667, 0.3643, 0.343 ,\n",
       "            0.333 , 0.3318, 0.3054, 0.304 , 0.3015, 0.293 , 0.2925, 0.2903,\n",
       "            0.2893, 0.273 , 0.2668, 0.2627, 0.2625, 0.2546, 0.2451, 0.2421,\n",
       "            0.2382, 0.234 , 0.2157, 0.2051, 0.2002, 0.1958, 0.1823, 0.1621,\n",
       "            0.1545, 0.151 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.09375  ,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.140625 ,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.171875 , 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.203125 , 0.2109375, 0.21875  , 0.234375 , 0.2421875,\n",
       "            0.25     , 0.25     , 0.265625 , 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4375   , 0.4453125, 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9272, 0.923 , 0.907 , 0.8965, 0.896 , 0.894 , 0.891 ,\n",
       "            0.8784, 0.8774, 0.8755, 0.8726, 0.861 , 0.857 , 0.851 , 0.8413,\n",
       "            0.84  , 0.837 , 0.8354, 0.834 , 0.8267, 0.822 , 0.8213, 0.8184,\n",
       "            0.8145, 0.81  , 0.8066, 0.8057, 0.8037, 0.8027, 0.7993, 0.795 ,\n",
       "            0.7944, 0.7935, 0.7925, 0.791 , 0.789 , 0.7837, 0.7812, 0.776 ,\n",
       "            0.7715, 0.7686, 0.7637, 0.759 , 0.7563, 0.755 , 0.753 , 0.7515,\n",
       "            0.751 , 0.7505, 0.75  , 0.7495, 0.748 , 0.7466, 0.746 , 0.744 ,\n",
       "            0.7417, 0.74  , 0.7397, 0.737 , 0.7354, 0.734 , 0.731 , 0.7295,\n",
       "            0.729 , 0.726 , 0.7256, 0.723 , 0.7197, 0.712 , 0.7104, 0.7065,\n",
       "            0.7007, 0.699 , 0.6987, 0.6973, 0.6963, 0.694 , 0.688 , 0.6875,\n",
       "            0.687 , 0.6865, 0.686 , 0.684 , 0.6826, 0.68  , 0.678 , 0.6743,\n",
       "            0.6714, 0.671 , 0.667 , 0.6665, 0.663 , 0.657 , 0.6567, 0.6562,\n",
       "            0.656 , 0.6523, 0.6475, 0.6465, 0.641 , 0.633 , 0.63  , 0.628 ,\n",
       "            0.6255, 0.625 , 0.618 , 0.617 , 0.6167, 0.606 , 0.605 , 0.6025,\n",
       "            0.597 , 0.5957, 0.595 , 0.593 , 0.5923, 0.5913, 0.586 , 0.583 ,\n",
       "            0.576 , 0.5684, 0.5674, 0.5664, 0.565 , 0.5635, 0.5625, 0.5586,\n",
       "            0.5537, 0.549 , 0.5483, 0.548 , 0.544 , 0.541 , 0.5386, 0.536 ,\n",
       "            0.529 , 0.525 , 0.5244, 0.521 , 0.5176, 0.5156, 0.513 , 0.5107,\n",
       "            0.5103, 0.5093, 0.5083, 0.508 , 0.5073, 0.507 , 0.503 , 0.501 ,\n",
       "            0.5   , 0.4963, 0.4954, 0.4949, 0.4934, 0.4893, 0.487 , 0.484 ,\n",
       "            0.4836, 0.481 , 0.4788, 0.4766, 0.4756, 0.475 , 0.4746, 0.47  ,\n",
       "            0.4697, 0.4668, 0.4666, 0.465 , 0.4646, 0.464 , 0.461 , 0.46  ,\n",
       "            0.459 , 0.458 , 0.4565, 0.4563, 0.4548, 0.4536, 0.4524, 0.4485,\n",
       "            0.4438, 0.443 , 0.4424, 0.441 , 0.4392, 0.4373, 0.4343, 0.4138,\n",
       "            0.4072, 0.4026, 0.3977, 0.3828, 0.3726, 0.3718, 0.3706, 0.3667,\n",
       "            0.3652, 0.3477, 0.332 , 0.3303, 0.3044, 0.301 , 0.3008, 0.2903,\n",
       "            0.288 , 0.2866, 0.27  , 0.263 , 0.259 , 0.2588, 0.2563, 0.2413,\n",
       "            0.2382, 0.234 , 0.2297, 0.2137, 0.1998, 0.1979, 0.1912, 0.1763,\n",
       "            0.1569, 0.1503, 0.1466], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.4140625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.09375  ,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.25     , 0.2578125,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.34375  , 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9404, 0.9365, 0.923 , 0.913 , 0.9126, 0.91  , 0.908 ,\n",
       "            0.8965, 0.8955, 0.893 , 0.89  , 0.879 , 0.8755, 0.8696, 0.861 ,\n",
       "            0.859 , 0.8564, 0.8555, 0.854 , 0.847 , 0.842 , 0.8384, 0.835 ,\n",
       "            0.831 , 0.827 , 0.8257, 0.824 , 0.8237, 0.82  , 0.8193, 0.8164,\n",
       "            0.8145, 0.814 , 0.8135, 0.8125, 0.8115, 0.809 , 0.805 , 0.802 ,\n",
       "            0.8013, 0.7964, 0.792 , 0.79  , 0.784 , 0.7837, 0.7783, 0.778 ,\n",
       "            0.775 , 0.7725, 0.771 , 0.7705, 0.7695, 0.769 , 0.7676, 0.7666,\n",
       "            0.766 , 0.764 , 0.762 , 0.761 , 0.76  , 0.7583, 0.7573, 0.7554,\n",
       "            0.7544, 0.7515, 0.7495, 0.749 , 0.747 , 0.7446, 0.742 , 0.74  ,\n",
       "            0.732 , 0.731 , 0.7256, 0.72  , 0.719 , 0.7188, 0.717 , 0.7163,\n",
       "            0.7144, 0.707 , 0.7065, 0.706 , 0.7046, 0.702 , 0.701 , 0.6987,\n",
       "            0.698 , 0.693 , 0.69  , 0.6895, 0.689 , 0.686 , 0.6855, 0.681 ,\n",
       "            0.676 , 0.675 , 0.674 , 0.6704, 0.6665, 0.6636, 0.659 , 0.65  ,\n",
       "            0.648 , 0.647 , 0.646 , 0.644 , 0.642 , 0.6353, 0.6333, 0.623 ,\n",
       "            0.6216, 0.6187, 0.6123, 0.612 , 0.6094, 0.6084, 0.6074, 0.601 ,\n",
       "            0.598 , 0.593 , 0.5923, 0.582 , 0.5796, 0.5776, 0.5767, 0.572 ,\n",
       "            0.5713, 0.563 , 0.5625, 0.5615, 0.5605, 0.558 , 0.5547, 0.5522,\n",
       "            0.549 , 0.547 , 0.5444, 0.542 , 0.5376, 0.5356, 0.531 , 0.53  ,\n",
       "            0.5293, 0.525 , 0.5244, 0.524 , 0.523 , 0.522 , 0.521 , 0.5205,\n",
       "            0.519 , 0.5186, 0.514 , 0.5137, 0.5127, 0.5117, 0.5073, 0.5044,\n",
       "            0.5034, 0.502 , 0.4978, 0.4963, 0.4956, 0.4937, 0.492 , 0.4912,\n",
       "            0.4902, 0.4875, 0.4863, 0.4858, 0.484 , 0.4795, 0.4775, 0.4744,\n",
       "            0.4739, 0.4727, 0.4722, 0.4712, 0.4695, 0.4673, 0.4648, 0.463 ,\n",
       "            0.4626, 0.4617, 0.46  , 0.459 , 0.4563, 0.4521, 0.4497, 0.4485,\n",
       "            0.4468, 0.445 , 0.4429, 0.44  , 0.424 , 0.4138, 0.4097, 0.4023,\n",
       "            0.3875, 0.3762, 0.3752, 0.3716, 0.37  , 0.3699, 0.3525, 0.3328,\n",
       "            0.3313, 0.3088, 0.3018, 0.3008, 0.29  , 0.2898, 0.2876, 0.2869,\n",
       "            0.269 , 0.2622, 0.2578, 0.2576, 0.2573, 0.239 , 0.2358, 0.2316,\n",
       "            0.2272, 0.2119, 0.1973, 0.196 , 0.1877, 0.1725, 0.1542, 0.1462,\n",
       "            0.1426], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.4765625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.09375  , 0.09375  ,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.1484375, 0.1484375,\n",
       "            0.15625  , 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.265625 ,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.23770492, 0.24590164,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.4180328 , 0.4262295 , 0.44262296,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8032787 , 0.8114754 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9507, 0.9473, 0.9355, 0.926 , 0.9253, 0.924 , 0.922 ,\n",
       "            0.911 , 0.91  , 0.9077, 0.905 , 0.8945, 0.891 , 0.8857, 0.8774,\n",
       "            0.876 , 0.873 , 0.8726, 0.8706, 0.8643, 0.86  , 0.859 , 0.856 ,\n",
       "            0.853 , 0.8486, 0.845 , 0.8438, 0.8423, 0.842 , 0.838 , 0.8345,\n",
       "            0.833 , 0.8325, 0.8315, 0.8306, 0.83  , 0.8257, 0.8247, 0.8203,\n",
       "            0.8105, 0.81  , 0.8086, 0.808 , 0.8022, 0.7983, 0.797 , 0.796 ,\n",
       "            0.7944, 0.7935, 0.7915, 0.791 , 0.7896, 0.7876, 0.7866, 0.784 ,\n",
       "            0.7812, 0.7803, 0.78  , 0.7773, 0.7764, 0.7734, 0.7705, 0.7686,\n",
       "            0.7676, 0.7666, 0.766 , 0.7646, 0.7573, 0.757 , 0.75  , 0.7495,\n",
       "            0.7446, 0.743 , 0.7417, 0.7383, 0.735 , 0.7344, 0.7334, 0.732 ,\n",
       "            0.731 , 0.7305, 0.7275, 0.7256, 0.725 , 0.7246, 0.7217, 0.717 ,\n",
       "            0.7163, 0.7124, 0.712 , 0.711 , 0.7095, 0.7085, 0.7046, 0.6978,\n",
       "            0.694 , 0.6934, 0.692 , 0.6855, 0.684 , 0.677 , 0.672 , 0.6704,\n",
       "            0.665 , 0.6646, 0.6616, 0.6567, 0.6553, 0.654 , 0.639 , 0.6377,\n",
       "            0.6323, 0.6313, 0.6274, 0.626 , 0.624 , 0.6235, 0.618 , 0.6167,\n",
       "            0.608 , 0.601 , 0.6006, 0.598 , 0.597 , 0.5947, 0.5874, 0.5864,\n",
       "            0.5815, 0.5806, 0.5786, 0.578 , 0.576 , 0.5737, 0.5654, 0.5625,\n",
       "            0.5605, 0.56  , 0.5586, 0.551 , 0.5483, 0.547 , 0.546 , 0.5425,\n",
       "            0.5415, 0.539 , 0.5366, 0.536 , 0.5356, 0.5347, 0.534 , 0.5327,\n",
       "            0.5303, 0.53  , 0.5293, 0.5273, 0.525 , 0.52  , 0.518 , 0.514 ,\n",
       "            0.5127, 0.5103, 0.508 , 0.5063, 0.5044, 0.504 , 0.503 , 0.501 ,\n",
       "            0.5005, 0.497 , 0.4966, 0.4937, 0.4934, 0.4893, 0.4866, 0.4846,\n",
       "            0.4841, 0.484 , 0.4834, 0.483 , 0.4817, 0.4805, 0.4763, 0.4758,\n",
       "            0.4734, 0.4717, 0.4714, 0.4697, 0.4683, 0.4666, 0.4644, 0.4639,\n",
       "            0.4575, 0.4563, 0.454 , 0.4534, 0.45  , 0.4478, 0.4333, 0.4194,\n",
       "            0.4155, 0.4075, 0.394 , 0.3806, 0.3801, 0.3796, 0.3757, 0.374 ,\n",
       "            0.3738, 0.3594, 0.334 , 0.3323, 0.3123, 0.302 , 0.3018, 0.2898,\n",
       "            0.2893, 0.287 , 0.2866, 0.268 , 0.2607, 0.2605, 0.256 , 0.2559,\n",
       "            0.2366, 0.2334, 0.229 , 0.2244, 0.2119, 0.1958, 0.194 , 0.1841,\n",
       "            0.1677, 0.1506, 0.1423, 0.1383], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.4765625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.0625   , 0.0625   , 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.1953125, 0.203125 , 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.328125 , 0.3359375,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.8515625,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.36065573,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40983605, 0.4180328 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8114754 , 0.8278689 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9585, 0.9556, 0.9453, 0.9355, 0.9336, 0.9316, 0.9233,\n",
       "            0.921 , 0.919 , 0.917 , 0.907 , 0.9033, 0.899 , 0.89  , 0.886 ,\n",
       "            0.8853, 0.884 , 0.877 , 0.875 , 0.8726, 0.8696, 0.8687, 0.863 ,\n",
       "            0.8604, 0.859 , 0.858 , 0.8564, 0.856 , 0.853 , 0.852 , 0.8486,\n",
       "            0.848 , 0.8467, 0.8457, 0.844 , 0.842 , 0.8413, 0.835 , 0.8296,\n",
       "            0.8267, 0.823 , 0.8193, 0.8174, 0.815 , 0.8145, 0.8125, 0.812 ,\n",
       "            0.8105, 0.8066, 0.805 , 0.8022, 0.802 , 0.8013, 0.8003, 0.795 ,\n",
       "            0.7944, 0.7935, 0.792 , 0.791 , 0.7886, 0.7876, 0.787 , 0.785 ,\n",
       "            0.784 , 0.783 , 0.779 , 0.7783, 0.7705, 0.7656, 0.764 , 0.7637,\n",
       "            0.763 , 0.753 , 0.752 , 0.7515, 0.751 , 0.7485, 0.748 , 0.7466,\n",
       "            0.746 , 0.745 , 0.7417, 0.7393, 0.7363, 0.734 , 0.732 , 0.7314,\n",
       "            0.7295, 0.7246, 0.724 , 0.7173, 0.713 , 0.7075, 0.7056, 0.705 ,\n",
       "            0.6963, 0.6943, 0.6924, 0.692 , 0.6914, 0.6836, 0.675 , 0.6733,\n",
       "            0.6724, 0.656 , 0.6504, 0.649 , 0.638 , 0.635 , 0.6343, 0.6333,\n",
       "            0.6284, 0.6177, 0.6167, 0.616 , 0.6133, 0.6094, 0.605 , 0.602 ,\n",
       "            0.5986, 0.598 , 0.594 , 0.5938, 0.593 , 0.588 , 0.5874, 0.576 ,\n",
       "            0.573 , 0.572 , 0.571 , 0.56  , 0.5586, 0.558 , 0.557 , 0.5566,\n",
       "            0.5527, 0.551 , 0.5503, 0.5464, 0.5454, 0.5444, 0.542 , 0.541 ,\n",
       "            0.54  , 0.5396, 0.5376, 0.536 , 0.5303, 0.5225, 0.5215, 0.5205,\n",
       "            0.518 , 0.512 , 0.5107, 0.5103, 0.509 , 0.5083, 0.5073, 0.507 ,\n",
       "            0.499 , 0.4985, 0.497 , 0.4968, 0.4963, 0.494 , 0.491 , 0.4905,\n",
       "            0.4888, 0.4875, 0.4841, 0.4824, 0.4788, 0.4783, 0.4768, 0.4753,\n",
       "            0.4744, 0.4736, 0.4722, 0.4702, 0.4697, 0.4626, 0.458 , 0.4539,\n",
       "            0.4531, 0.4497, 0.4475, 0.4414, 0.4238, 0.4202, 0.4114, 0.3992,\n",
       "            0.3835, 0.383 , 0.3784, 0.3772, 0.376 , 0.366 , 0.334 , 0.3318,\n",
       "            0.3145, 0.3018, 0.3013, 0.288 , 0.286 , 0.266 , 0.2637, 0.2573,\n",
       "            0.2537, 0.2534, 0.2339, 0.2301, 0.2256, 0.2203, 0.2119, 0.1954,\n",
       "            0.19  , 0.1799, 0.163 , 0.1467, 0.1384, 0.1335], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5390625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.09375  ,\n",
       "            0.09375  , 0.09375  , 0.09375  , 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.1953125,\n",
       "            0.203125 , 0.21875  , 0.2265625, 0.234375 , 0.25     , 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.34375  , 0.3515625,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6803279 ,\n",
       "            0.6885246 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8278689 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.86885244, 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.968 , 0.965 , 0.956 , 0.9478, 0.9463, 0.9443, 0.9365,\n",
       "            0.935 , 0.933 , 0.931 , 0.9224, 0.9194, 0.9146, 0.9077, 0.9062,\n",
       "            0.9033, 0.903 , 0.9014, 0.895 , 0.8926, 0.891 , 0.888 , 0.886 ,\n",
       "            0.882 , 0.8794, 0.879 , 0.8774, 0.8755, 0.875 , 0.872 , 0.87  ,\n",
       "            0.868 , 0.8677, 0.8657, 0.8643, 0.864 , 0.861 , 0.8584, 0.855 ,\n",
       "            0.847 , 0.8467, 0.846 , 0.8403, 0.837 , 0.835 , 0.833 , 0.8325,\n",
       "            0.832 , 0.83  , 0.829 , 0.8286, 0.8276, 0.823 , 0.8228, 0.822 ,\n",
       "            0.82  , 0.8193, 0.8164, 0.8154, 0.8125, 0.807 , 0.8066, 0.806 ,\n",
       "            0.805 , 0.804 , 0.7974, 0.7964, 0.7886, 0.786 , 0.7837, 0.782 ,\n",
       "            0.7817, 0.7734, 0.7715, 0.771 , 0.7705, 0.7695, 0.7686, 0.7666,\n",
       "            0.764 , 0.763 , 0.7617, 0.7603, 0.755 , 0.752 , 0.7505, 0.75  ,\n",
       "            0.748 , 0.7446, 0.743 , 0.736 , 0.7314, 0.729 , 0.727 , 0.723 ,\n",
       "            0.7183, 0.714 , 0.7124, 0.71  , 0.7017, 0.6973, 0.6943, 0.693 ,\n",
       "            0.6914, 0.69  , 0.6733, 0.6704, 0.6694, 0.6665, 0.6655, 0.658 ,\n",
       "            0.6562, 0.655 , 0.654 , 0.6514, 0.6475, 0.6377, 0.637 , 0.6353,\n",
       "            0.633 , 0.63  , 0.627 , 0.626 , 0.622 , 0.615 , 0.614 , 0.6104,\n",
       "            0.6094, 0.6084, 0.604 , 0.602 , 0.59  , 0.5894, 0.586 , 0.5835,\n",
       "            0.5747, 0.5728, 0.5723, 0.5713, 0.569 , 0.565 , 0.5645, 0.56  ,\n",
       "            0.5596, 0.5586, 0.558 , 0.5566, 0.555 , 0.554 , 0.5537, 0.5513,\n",
       "            0.545 , 0.5435, 0.5376, 0.534 , 0.5312, 0.5303, 0.526 , 0.5244,\n",
       "            0.5225, 0.5215, 0.52  , 0.518 , 0.5176, 0.515 , 0.5146, 0.5083,\n",
       "            0.508 , 0.505 , 0.504 , 0.502 , 0.5   , 0.4998, 0.4978, 0.495 ,\n",
       "            0.4924, 0.4878, 0.4875, 0.4873, 0.4856, 0.485 , 0.4832, 0.4807,\n",
       "            0.48  , 0.4797, 0.47  , 0.4675, 0.4626, 0.4617, 0.4587, 0.4556,\n",
       "            0.4546, 0.4316, 0.428 , 0.417 , 0.4028, 0.3887, 0.388 , 0.3877,\n",
       "            0.3833, 0.3818, 0.3782, 0.3706, 0.335 , 0.3328, 0.3198, 0.3025,\n",
       "            0.3013, 0.2876, 0.287 , 0.286 , 0.2847, 0.2644, 0.2556, 0.252 ,\n",
       "            0.2517, 0.2313, 0.2268, 0.2224, 0.2166, 0.2101, 0.1931, 0.1869,\n",
       "            0.1754, 0.1583, 0.1434, 0.1335, 0.128 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5703125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.09375  , 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.1953125, 0.203125 , 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.72131145, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.8032787 , 0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9727, 0.97  , 0.9624, 0.955 , 0.9536, 0.9517, 0.9443,\n",
       "            0.9434, 0.9414, 0.9395, 0.931 , 0.9287, 0.924 , 0.918 , 0.9165,\n",
       "            0.9136, 0.913 , 0.9116, 0.9053, 0.9033, 0.902 , 0.899 , 0.8975,\n",
       "            0.8945, 0.893 , 0.8906, 0.89  , 0.8887, 0.887 , 0.8857, 0.884 ,\n",
       "            0.8804, 0.88  , 0.8794, 0.878 , 0.8765, 0.876 , 0.8755, 0.8716,\n",
       "            0.867 , 0.8643, 0.86  , 0.8584, 0.8574, 0.8535, 0.853 , 0.8516,\n",
       "            0.85  , 0.8496, 0.8486, 0.847 , 0.8467, 0.8447, 0.841 , 0.8403,\n",
       "            0.8394, 0.8384, 0.836 , 0.835 , 0.831 , 0.8296, 0.8286, 0.8257,\n",
       "            0.825 , 0.823 , 0.8228, 0.821 , 0.8184, 0.817 , 0.816 , 0.807 ,\n",
       "            0.8022, 0.8013, 0.801 , 0.8   , 0.7905, 0.7896, 0.7886, 0.787 ,\n",
       "            0.784 , 0.7837, 0.782 , 0.7817, 0.7812, 0.7773, 0.7754, 0.7725,\n",
       "            0.77  , 0.768 , 0.7676, 0.766 , 0.7617, 0.7573, 0.7544, 0.754 ,\n",
       "            0.75  , 0.742 , 0.7397, 0.7324, 0.7314, 0.73  , 0.726 , 0.7246,\n",
       "            0.72  , 0.711 , 0.709 , 0.708 , 0.7046, 0.69  , 0.683 , 0.6816,\n",
       "            0.6797, 0.6704, 0.6694, 0.6675, 0.6665, 0.6597, 0.656 , 0.65  ,\n",
       "            0.6494, 0.649 , 0.6455, 0.6406, 0.6377, 0.637 , 0.633 , 0.6274,\n",
       "            0.6265, 0.6255, 0.625 , 0.62  , 0.6196, 0.6147, 0.607 , 0.5986,\n",
       "            0.5947, 0.5923, 0.5884, 0.588 , 0.5864, 0.5854, 0.582 , 0.579 ,\n",
       "            0.577 , 0.574 , 0.573 , 0.569 , 0.5684, 0.568 , 0.5674, 0.5664,\n",
       "            0.563 , 0.5625, 0.56  , 0.558 , 0.5537, 0.546 , 0.5454, 0.5444,\n",
       "            0.5366, 0.5356, 0.5337, 0.532 , 0.5303, 0.53  , 0.5244, 0.5234,\n",
       "            0.523 , 0.5176, 0.5156, 0.515 , 0.5127, 0.5117, 0.5093, 0.5073,\n",
       "            0.507 , 0.5063, 0.5015, 0.4993, 0.4949, 0.4934, 0.4924, 0.4912,\n",
       "            0.4897, 0.4863, 0.4854, 0.484 , 0.4834, 0.4736, 0.4731, 0.468 ,\n",
       "            0.4675, 0.4639, 0.4612, 0.4597, 0.4329, 0.4287, 0.4185, 0.404 ,\n",
       "            0.3892, 0.3887, 0.3884, 0.3826, 0.3806, 0.3772, 0.3735, 0.3323,\n",
       "            0.3298, 0.3193, 0.299 , 0.2983, 0.2834, 0.2832, 0.282 , 0.2808,\n",
       "            0.264 , 0.26  , 0.2505, 0.2473, 0.2471, 0.2263, 0.2218, 0.217 ,\n",
       "            0.2104, 0.2076, 0.1906, 0.1813, 0.1696, 0.152 , 0.1381, 0.1279,\n",
       "            0.1222], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.609375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.1015625, 0.1015625,\n",
       "            0.109375 , 0.125    , 0.1328125, 0.1328125, 0.1484375, 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1796875, 0.1875   , 0.1953125, 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.484375 , 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.5859375, 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.26229507, 0.2704918 , 0.27868852, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5409836 , 0.55737704,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.978  , 0.9756 , 0.9688 , 0.9624 , 0.962  , 0.961  ,\n",
       "            0.959  , 0.9526 , 0.951  , 0.95   , 0.948  , 0.941  , 0.9385 ,\n",
       "            0.934  , 0.928  , 0.9272 , 0.925  , 0.924  , 0.923  , 0.9165 ,\n",
       "            0.915  , 0.9136 , 0.9106 , 0.91   , 0.9097 , 0.9062 , 0.9053 ,\n",
       "            0.9023 , 0.902  , 0.9014 , 0.8994 , 0.8975 , 0.8965 , 0.8926 ,\n",
       "            0.892  , 0.8906 , 0.8896 , 0.888  , 0.884  , 0.882  , 0.881  ,\n",
       "            0.875  , 0.8726 , 0.872  , 0.8716 , 0.871  , 0.869  , 0.868  ,\n",
       "            0.867  , 0.8667 , 0.866  , 0.8657 , 0.865  , 0.86   , 0.859  ,\n",
       "            0.8584 , 0.8574 , 0.855  , 0.8506 , 0.85   , 0.849  , 0.848  ,\n",
       "            0.8438 , 0.843  , 0.842  , 0.8403 , 0.84   , 0.8374 , 0.836  ,\n",
       "            0.833  , 0.832  , 0.827  , 0.8223 , 0.822  , 0.821  , 0.8145 ,\n",
       "            0.811  , 0.81   , 0.8086 , 0.8037 , 0.8022 , 0.802  , 0.801  ,\n",
       "            0.7993 , 0.798  , 0.7974 , 0.797  , 0.7925 , 0.7915 , 0.791  ,\n",
       "            0.7886 , 0.788  , 0.787  , 0.782  , 0.7812 , 0.775  , 0.774  ,\n",
       "            0.773  , 0.7705 , 0.7593 , 0.758  , 0.7554 , 0.755  , 0.7515 ,\n",
       "            0.747  , 0.7466 , 0.7407 , 0.7397 , 0.7305 , 0.729  , 0.726  ,\n",
       "            0.724  , 0.7227 , 0.709  , 0.7026 , 0.698  , 0.6973 , 0.6963 ,\n",
       "            0.6865 , 0.6846 , 0.6836 , 0.6807 , 0.68   , 0.6772 , 0.674  ,\n",
       "            0.6675 , 0.6636 , 0.663  , 0.6577 , 0.651  , 0.6465 , 0.6455 ,\n",
       "            0.6426 , 0.6396 , 0.638  , 0.636  , 0.63   , 0.626  , 0.611  ,\n",
       "            0.6104 , 0.608  , 0.6074 , 0.606  , 0.6045 , 0.603  , 0.5986 ,\n",
       "            0.5967 , 0.5903 , 0.59   , 0.5894 , 0.589  , 0.5854 , 0.5835 ,\n",
       "            0.583  , 0.5825 , 0.5796 , 0.5776 , 0.577  , 0.576  , 0.5728 ,\n",
       "            0.5703 , 0.564  , 0.5586 , 0.558  , 0.5557 , 0.551  , 0.544  ,\n",
       "            0.543  , 0.5425 , 0.5415 , 0.5386 , 0.5327 , 0.532  , 0.5244 ,\n",
       "            0.524  , 0.5234 , 0.5205 , 0.5195 , 0.517  , 0.5146 , 0.514  ,\n",
       "            0.5093 , 0.507  , 0.503  , 0.5005 , 0.4978 , 0.4973 , 0.493  ,\n",
       "            0.4924 , 0.4905 , 0.49   , 0.4812 , 0.4797 , 0.4744 , 0.4727 ,\n",
       "            0.47   , 0.4668 , 0.4358 , 0.432  , 0.4229 , 0.4114 , 0.3926 ,\n",
       "            0.3923 , 0.3918 , 0.384  , 0.382  , 0.3813 , 0.3801 , 0.3325 ,\n",
       "            0.3296 , 0.32   , 0.2986 , 0.297  , 0.2817 , 0.2815 , 0.2808 ,\n",
       "            0.2798 , 0.2676 , 0.2578 , 0.2467 , 0.2448 , 0.2445 , 0.2234 ,\n",
       "            0.2189 , 0.2134 , 0.2085 , 0.2058 , 0.1906 , 0.1763 , 0.1658 ,\n",
       "            0.1462 , 0.133  , 0.1238 , 0.11755], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.640625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0703125, 0.0703125, 0.078125 , 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.1015625, 0.1015625, 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.1328125, 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.328125 , 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4262295 , 0.43442622,\n",
       "            0.45081967, 0.45901638, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.982 , 0.98  , 0.974 , 0.9683, 0.9673, 0.966 , 0.9595,\n",
       "            0.9585, 0.9575, 0.955 , 0.949 , 0.947 , 0.9424, 0.938 , 0.936 ,\n",
       "            0.934 , 0.9336, 0.9326, 0.927 , 0.925 , 0.9243, 0.924 , 0.9214,\n",
       "            0.9204, 0.92  , 0.9165, 0.916 , 0.913 , 0.912 , 0.911 , 0.9106,\n",
       "            0.908 , 0.904 , 0.9033, 0.903 , 0.9014, 0.9004, 0.899 , 0.8984,\n",
       "            0.894 , 0.893 , 0.891 , 0.889 , 0.8867, 0.8853, 0.885 , 0.8843,\n",
       "            0.884 , 0.8833, 0.883 , 0.882 , 0.878 , 0.876 , 0.8716, 0.8687,\n",
       "            0.868 , 0.865 , 0.864 , 0.863 , 0.861 , 0.859 , 0.8584, 0.858 ,\n",
       "            0.8574, 0.857 , 0.856 , 0.8545, 0.8525, 0.8496, 0.846 , 0.8457,\n",
       "            0.845 , 0.8423, 0.842 , 0.8403, 0.8315, 0.8306, 0.829 , 0.8286,\n",
       "            0.822 , 0.8213, 0.8184, 0.817 , 0.8145, 0.814 , 0.813 , 0.812 ,\n",
       "            0.8105, 0.8086, 0.807 , 0.8057, 0.8047, 0.8022, 0.797 , 0.795 ,\n",
       "            0.794 , 0.7905, 0.7856, 0.7773, 0.777 , 0.774 , 0.7725, 0.7695,\n",
       "            0.7646, 0.763 , 0.7617, 0.753 , 0.751 , 0.7495, 0.7427, 0.7417,\n",
       "            0.7393, 0.728 , 0.722 , 0.715 , 0.712 , 0.711 , 0.7056, 0.7026,\n",
       "            0.7   , 0.699 , 0.696 , 0.695 , 0.6875, 0.686 , 0.682 , 0.6797,\n",
       "            0.679 , 0.675 , 0.667 , 0.6636, 0.662 , 0.6606, 0.6587, 0.658 ,\n",
       "            0.6514, 0.6504, 0.6494, 0.646 , 0.627 , 0.6265, 0.623 , 0.6216,\n",
       "            0.6206, 0.6177, 0.6147, 0.6113, 0.611 , 0.609 , 0.604 , 0.602 ,\n",
       "            0.598 , 0.5977, 0.597 , 0.594 , 0.5923, 0.5913, 0.591 , 0.5874,\n",
       "            0.5854, 0.5825, 0.5767, 0.576 , 0.574 , 0.5713, 0.5684, 0.561 ,\n",
       "            0.558 , 0.5547, 0.553 , 0.551 , 0.5503, 0.5474, 0.5464, 0.546 ,\n",
       "            0.539 , 0.535 , 0.5347, 0.5337, 0.5317, 0.526 , 0.52  , 0.5195,\n",
       "            0.518 , 0.5176, 0.514 , 0.5127, 0.511 , 0.509 , 0.504 , 0.503 ,\n",
       "            0.4944, 0.4907, 0.4863, 0.4856, 0.4834, 0.4807, 0.478 , 0.4717,\n",
       "            0.436 , 0.4326, 0.4246, 0.417 , 0.393 , 0.3928, 0.3923, 0.3877,\n",
       "            0.3828, 0.381 , 0.3809, 0.3303, 0.3267, 0.3186, 0.2979, 0.2925,\n",
       "            0.2778, 0.277 , 0.2766, 0.2703, 0.2537, 0.2411, 0.2402, 0.2401,\n",
       "            0.2189, 0.2142, 0.2085, 0.2081, 0.1995, 0.1898, 0.1699, 0.1609,\n",
       "            0.1395, 0.1272, 0.1186, 0.1122], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.640625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.1015625, 0.1015625, 0.109375 , 0.1171875, 0.1171875, 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.203125 , 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.19672132, 0.20491803,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.3114754 , 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.985  , 0.9834 , 0.978  , 0.973  , 0.9727 , 0.972  ,\n",
       "            0.97   , 0.965  , 0.964  , 0.9634 , 0.961  , 0.9556 , 0.9536 ,\n",
       "            0.949  , 0.9453 , 0.9434 , 0.9414 , 0.941  , 0.94   , 0.935  ,\n",
       "            0.9346 , 0.933  , 0.932  , 0.9297 , 0.928  , 0.926  , 0.9253 ,\n",
       "            0.9214 , 0.921  , 0.92   , 0.9194 , 0.917  , 0.9126 , 0.912  ,\n",
       "            0.9106 , 0.909  , 0.9043 , 0.904  , 0.903  , 0.9023 , 0.9004 ,\n",
       "            0.8994 , 0.899  , 0.8984 , 0.898  , 0.897  , 0.8955 , 0.8936 ,\n",
       "            0.893  , 0.8926 , 0.891  , 0.8843 , 0.8813 , 0.88   , 0.8784 ,\n",
       "            0.8765 , 0.8735 , 0.873  , 0.8726 , 0.872  , 0.8677 , 0.867  ,\n",
       "            0.8643 , 0.863  , 0.8623 , 0.8604 , 0.859  , 0.858  , 0.857  ,\n",
       "            0.8564 , 0.856  , 0.848  , 0.847  , 0.8457 , 0.84   , 0.838  ,\n",
       "            0.8374 , 0.8345 , 0.831  , 0.8306 , 0.8276 , 0.8267 , 0.826  ,\n",
       "            0.8247 , 0.8237 , 0.8228 , 0.821  , 0.8193 , 0.817  , 0.812  ,\n",
       "            0.811  , 0.8076 , 0.807  , 0.797  , 0.793  , 0.792  , 0.783  ,\n",
       "            0.781  , 0.779  , 0.7734 , 0.768  , 0.766  , 0.7637 , 0.758  ,\n",
       "            0.7524 , 0.749  , 0.744  , 0.7383 , 0.7305 , 0.7217 , 0.72   ,\n",
       "            0.709  , 0.7085 , 0.7046 , 0.704  , 0.702  , 0.6978 , 0.697  ,\n",
       "            0.6895 , 0.688  , 0.6875 , 0.684  , 0.6797 , 0.6753 , 0.675  ,\n",
       "            0.671  , 0.6665 , 0.666  , 0.664  , 0.66   , 0.659  , 0.6455 ,\n",
       "            0.642  , 0.64   , 0.6357 , 0.6294 , 0.6284 , 0.627  , 0.625  ,\n",
       "            0.624  , 0.6235 , 0.6187 , 0.6177 , 0.616  , 0.6113 , 0.6064 ,\n",
       "            0.606  , 0.605  , 0.5996 , 0.598  , 0.5967 , 0.596  , 0.591  ,\n",
       "            0.5894 , 0.588  , 0.5854 , 0.584  , 0.581  , 0.5728 , 0.5723 ,\n",
       "            0.5684 , 0.559  , 0.557  , 0.5557 , 0.5547 , 0.5503 , 0.55   ,\n",
       "            0.545  , 0.5444 , 0.543  , 0.54   , 0.5396 , 0.539  , 0.536  ,\n",
       "            0.529  , 0.5283 , 0.5234 , 0.523  , 0.5225 , 0.5215 , 0.5186 ,\n",
       "            0.513  , 0.5127 , 0.5107 , 0.505  , 0.4976 , 0.4973 , 0.4924 ,\n",
       "            0.491  , 0.4897 , 0.4832 , 0.4812 , 0.48   , 0.475  , 0.4353 ,\n",
       "            0.432  , 0.426  , 0.4224 , 0.394  , 0.3938 , 0.3936 , 0.3909 ,\n",
       "            0.3809 , 0.3794 , 0.3281 , 0.3237 , 0.317  , 0.2966 , 0.2876 ,\n",
       "            0.2742 , 0.274  , 0.2734 , 0.2727 , 0.2725 , 0.2494 , 0.2358 ,\n",
       "            0.2356 , 0.2351 , 0.2144 , 0.2096 , 0.2086 , 0.2028 , 0.1935 ,\n",
       "            0.1892 , 0.1637 , 0.1555 , 0.1329 , 0.1217 , 0.11395, 0.10724],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6796875, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.109375 , 0.1171875, 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.203125 , 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.37704918, 0.3852459 , 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8032787 , 0.8114754 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.988  , 0.9863 , 0.982  , 0.9775 , 0.977  , 0.975  ,\n",
       "            0.9707 , 0.9697 , 0.9688 , 0.967  , 0.9624 , 0.9604 , 0.9565 ,\n",
       "            0.9526 , 0.951  , 0.9497 , 0.9487 , 0.948  , 0.947  , 0.944  ,\n",
       "            0.943  , 0.942  , 0.941  , 0.94   , 0.939  , 0.9385 , 0.9375 ,\n",
       "            0.9346 , 0.931  , 0.9307 , 0.9297 , 0.929  , 0.9272 , 0.927  ,\n",
       "            0.9263 , 0.923  , 0.9224 , 0.921  , 0.9194 , 0.919  , 0.9185 ,\n",
       "            0.9146 , 0.914  , 0.9136 , 0.913  , 0.9126 , 0.912  , 0.911  ,\n",
       "            0.91   , 0.9097 , 0.908  , 0.907  , 0.905  , 0.904  , 0.901  ,\n",
       "            0.896  , 0.893  , 0.8926 , 0.8916 , 0.8906 , 0.89   , 0.889  ,\n",
       "            0.886  , 0.885  , 0.8804 , 0.88   , 0.878  , 0.877  , 0.876  ,\n",
       "            0.8755 , 0.875  , 0.873  , 0.869  , 0.867  , 0.866  , 0.8647 ,\n",
       "            0.857  , 0.8555 , 0.8535 , 0.8525 , 0.8516 , 0.8486 , 0.846  ,\n",
       "            0.845  , 0.843  , 0.8413 , 0.84   , 0.8394 , 0.839  , 0.837  ,\n",
       "            0.8345 , 0.832  , 0.831  , 0.8276 , 0.822  , 0.8184 , 0.8145 ,\n",
       "            0.8125 , 0.811  , 0.8003 , 0.8    , 0.799  , 0.796  , 0.789  ,\n",
       "            0.7886 , 0.7876 , 0.7783 , 0.7773 , 0.7676 , 0.7646 , 0.764  ,\n",
       "            0.76   , 0.75   , 0.747  , 0.7427 , 0.737  , 0.736  , 0.7246 ,\n",
       "            0.724  , 0.7236 , 0.7197 , 0.7188 , 0.7124 , 0.7095 , 0.7075 ,\n",
       "            0.703  , 0.7026 , 0.6997 , 0.6973 , 0.6963 , 0.6914 , 0.69   ,\n",
       "            0.6855 , 0.682  , 0.679  , 0.6753 , 0.6665 , 0.665  , 0.657  ,\n",
       "            0.648  , 0.646  , 0.6436 , 0.6426 , 0.642  , 0.6416 , 0.638  ,\n",
       "            0.6377 , 0.6313 , 0.63   , 0.6294 , 0.6216 , 0.619  , 0.6177 ,\n",
       "            0.614  , 0.613  , 0.6104 , 0.61   , 0.6064 , 0.605  , 0.604  ,\n",
       "            0.601  , 0.594  , 0.593  , 0.587  , 0.585  , 0.576  , 0.5713 ,\n",
       "            0.5693 , 0.5664 , 0.5625 , 0.5615 , 0.5605 , 0.5596 , 0.558  ,\n",
       "            0.556  , 0.5537 , 0.5513 , 0.548  , 0.544  , 0.5405 , 0.536  ,\n",
       "            0.535  , 0.5347 , 0.5327 , 0.527  , 0.524  , 0.522  , 0.516  ,\n",
       "            0.5156 , 0.5063 , 0.506  , 0.505  , 0.504  , 0.5005 , 0.4932 ,\n",
       "            0.4922 , 0.4849 , 0.4395 , 0.4363 , 0.432  , 0.4316 , 0.4036 ,\n",
       "            0.3977 , 0.3972 , 0.3938 , 0.3848 , 0.3828 , 0.3818 , 0.3296 ,\n",
       "            0.3245 , 0.32   , 0.2983 , 0.2861 , 0.2773 , 0.2732 , 0.273  ,\n",
       "            0.2708 , 0.2478 , 0.2338 , 0.2313 , 0.2119 , 0.2103 , 0.207  ,\n",
       "            0.199  , 0.1896 , 0.1892 , 0.1597 , 0.1511 , 0.1279 , 0.11755,\n",
       "            0.1097 , 0.1025 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7109375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.046875 , 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0625   , 0.0703125, 0.078125 , 0.078125 ,\n",
       "            0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.109375 ,\n",
       "            0.1171875, 0.1171875, 0.125    , 0.125    , 0.125    , 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.2109375, 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5234375, 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.671875 , 0.6796875, 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.30327868, 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40983605,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8606557 , 0.8606557 ,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9907 , 0.9897 , 0.9863 , 0.9824 , 0.982  , 0.9805 ,\n",
       "            0.9766 , 0.976  , 0.975  , 0.9736 , 0.969  , 0.968  , 0.9644 ,\n",
       "            0.9614 , 0.96   , 0.9585 , 0.958  , 0.9575 , 0.9565 , 0.9536 ,\n",
       "            0.953  , 0.9517 , 0.951  , 0.95   , 0.949  , 0.9478 , 0.9463 ,\n",
       "            0.9453 , 0.942  , 0.9414 , 0.941  , 0.9395 , 0.939  , 0.935  ,\n",
       "            0.9346 , 0.9336 , 0.933  , 0.932  , 0.931  , 0.9287 , 0.928  ,\n",
       "            0.9277 , 0.9272 , 0.9263 , 0.9253 , 0.925  , 0.9243 , 0.923  ,\n",
       "            0.9224 , 0.922  , 0.9185 , 0.917  , 0.916  , 0.911  , 0.9087 ,\n",
       "            0.907  , 0.9062 , 0.9053 , 0.904  , 0.902  , 0.901  , 0.897  ,\n",
       "            0.8965 , 0.896  , 0.894  , 0.8936 , 0.8926 , 0.8916 , 0.8896 ,\n",
       "            0.886  , 0.8853 , 0.884  , 0.8755 , 0.8735 , 0.872  , 0.871  ,\n",
       "            0.8706 , 0.8667 , 0.8643 , 0.8604 , 0.86   , 0.8594 , 0.858  ,\n",
       "            0.856  , 0.8525 , 0.8516 , 0.85   , 0.8486 , 0.8433 , 0.838  ,\n",
       "            0.8364 , 0.832  , 0.8296 , 0.823  , 0.8184 , 0.8154 , 0.812  ,\n",
       "            0.811  , 0.8105 , 0.7974 , 0.7964 , 0.792  , 0.788  , 0.783  ,\n",
       "            0.777  , 0.7705 , 0.7666 , 0.7593 , 0.758  , 0.7505 , 0.748  ,\n",
       "            0.7466 , 0.7437 , 0.743  , 0.7417 , 0.7354 , 0.734  , 0.7324 ,\n",
       "            0.729  , 0.728  , 0.7246 , 0.7217 , 0.721  , 0.7197 , 0.716  ,\n",
       "            0.705  , 0.7026 , 0.7017 , 0.699  , 0.6953 , 0.694  , 0.686  ,\n",
       "            0.684  , 0.6763 , 0.6743 , 0.672  , 0.667  , 0.6626 , 0.662  ,\n",
       "            0.6597 , 0.6587 , 0.657  , 0.655  , 0.6494 , 0.6436 , 0.64   ,\n",
       "            0.6396 , 0.6367 , 0.636  , 0.6353 , 0.635  , 0.6343 , 0.632  ,\n",
       "            0.6313 , 0.6284 , 0.6245 , 0.621  , 0.6177 , 0.6133 , 0.61   ,\n",
       "            0.5947 , 0.594  , 0.593  , 0.592  , 0.59   , 0.589  , 0.588  ,\n",
       "            0.582  , 0.5806 , 0.5767 , 0.5747 , 0.5737 , 0.573  , 0.5635 ,\n",
       "            0.561  , 0.5596 , 0.557  , 0.5566 , 0.552  , 0.551  , 0.548  ,\n",
       "            0.547  , 0.545  , 0.5396 , 0.539  , 0.529  , 0.5283 , 0.519  ,\n",
       "            0.5166 , 0.5156 , 0.5127 , 0.502  , 0.4495 , 0.4448 , 0.4424 ,\n",
       "            0.4417 , 0.4143 , 0.4038 , 0.4033 , 0.4006 , 0.3906 , 0.3892 ,\n",
       "            0.3882 , 0.333  , 0.3289 , 0.3276 , 0.3022 , 0.288  , 0.2822 ,\n",
       "            0.2747 , 0.2744 , 0.272  , 0.2482 , 0.2338 , 0.2335 , 0.2302 ,\n",
       "            0.2123 , 0.2109 , 0.2059 , 0.197  , 0.19   , 0.1863 , 0.1575 ,\n",
       "            0.1478 , 0.12463, 0.11554, 0.1063 , 0.09827], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7109375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0546875,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.078125 , 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.1171875,\n",
       "            0.1171875, 0.125    , 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1953125, 0.2109375, 0.21875  , 0.21875  , 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.328125 ,\n",
       "            0.34375  , 0.3515625, 0.3671875, 0.375    , 0.3828125, 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.453125 ,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.609375 , 0.6171875,\n",
       "            0.625    , 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.27868852, 0.29508197, 0.30327868, 0.3114754 , 0.33606556,\n",
       "            0.3442623 , 0.36065573, 0.36885247, 0.3852459 , 0.40163934,\n",
       "            0.40983605, 0.4262295 , 0.44262296, 0.45081967, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9927 , 0.9917 , 0.9893 , 0.986  , 0.9854 , 0.9844 ,\n",
       "            0.981  , 0.9805 , 0.98   , 0.9785 , 0.9746 , 0.973  , 0.97   ,\n",
       "            0.968  , 0.9663 , 0.965  , 0.9644 , 0.964  , 0.9614 , 0.9604 ,\n",
       "            0.9595 , 0.959  , 0.9585 , 0.9565 , 0.956  , 0.9556 , 0.953  ,\n",
       "            0.9507 , 0.95   , 0.9497 , 0.949  , 0.9478 , 0.9443 , 0.944  ,\n",
       "            0.9424 , 0.9414 , 0.94   , 0.9395 , 0.9375 , 0.937  , 0.936  ,\n",
       "            0.935  , 0.934  , 0.9336 , 0.9287 , 0.928  , 0.9272 , 0.923  ,\n",
       "            0.9224 , 0.9204 , 0.92   , 0.917  , 0.9165 , 0.9155 , 0.914  ,\n",
       "            0.9126 , 0.9106 , 0.909  , 0.9087 , 0.908  , 0.907  , 0.906  ,\n",
       "            0.9033 , 0.9014 , 0.9004 , 0.8984 , 0.898  , 0.8975 , 0.8896 ,\n",
       "            0.888  , 0.887  , 0.8843 , 0.883  , 0.881  , 0.8784 , 0.876  ,\n",
       "            0.8745 , 0.8726 , 0.872  , 0.87   , 0.869  , 0.8677 , 0.8667 ,\n",
       "            0.865  , 0.8643 , 0.8584 , 0.8564 , 0.852  , 0.8477 , 0.844  ,\n",
       "            0.8413 , 0.8335 , 0.8325 , 0.8306 , 0.8296 , 0.8286 , 0.827  ,\n",
       "            0.8115 , 0.811  , 0.8096 , 0.8057 , 0.805  , 0.8013 , 0.799  ,\n",
       "            0.786  , 0.785  , 0.7754 , 0.7744 , 0.769  , 0.7666 , 0.7637 ,\n",
       "            0.7617 , 0.761  , 0.7583 , 0.756  , 0.75   , 0.7476 , 0.7466 ,\n",
       "            0.744  , 0.743  , 0.7393 , 0.736  , 0.7344 , 0.722  , 0.72   ,\n",
       "            0.719  , 0.7163 , 0.714  , 0.7104 , 0.703  , 0.697  , 0.6943 ,\n",
       "            0.693  , 0.6865 , 0.6807 , 0.679  , 0.6753 , 0.674  , 0.67   ,\n",
       "            0.666  , 0.6646 , 0.66   , 0.658  , 0.6577 , 0.652  , 0.6514 ,\n",
       "            0.649  , 0.645  , 0.6445 , 0.64   , 0.639  , 0.634  , 0.6304 ,\n",
       "            0.6265 , 0.6094 , 0.6084 , 0.608  , 0.6064 , 0.6045 , 0.5977 ,\n",
       "            0.591  , 0.5894 , 0.589  , 0.588  , 0.5864 , 0.5786 , 0.574  ,\n",
       "            0.5728 , 0.5713 , 0.5693 , 0.5635 , 0.563  , 0.5586 , 0.5566 ,\n",
       "            0.5527 , 0.543  , 0.541  , 0.53   , 0.529  , 0.5283 , 0.528  ,\n",
       "            0.5264 , 0.5205 , 0.517  , 0.457  , 0.4502 , 0.45   , 0.4468 ,\n",
       "            0.4224 , 0.4062 , 0.4055 , 0.4036 , 0.393  , 0.3923 , 0.3909 ,\n",
       "            0.3364 , 0.333  , 0.3276 , 0.304  , 0.2874 , 0.2864 , 0.2737 ,\n",
       "            0.2732 , 0.273  , 0.2705 , 0.2462 , 0.2311 , 0.2269 , 0.2137 ,\n",
       "            0.208  , 0.2032 , 0.1935 , 0.1903 , 0.1819 , 0.1545 , 0.1436 ,\n",
       "            0.12085, 0.113  , 0.10266, 0.094  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7109375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.1171875, 0.125    , 0.125    , 0.125    ,\n",
       "            0.1328125, 0.140625 , 0.15625  , 0.1640625, 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.8671875, 0.875    , 0.8828125, 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.21311475, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.2704918 , 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.36065573, 0.36885247, 0.3852459 , 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.44262296, 0.46721312, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.59016395, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.8770492 , 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9946 , 0.994  , 0.9917 , 0.9893 , 0.989  , 0.988  ,\n",
       "            0.9854 , 0.9844 , 0.984  , 0.983  , 0.98   , 0.9785 , 0.976  ,\n",
       "            0.9736 , 0.973  , 0.9717 , 0.971  , 0.9707 , 0.969  , 0.968  ,\n",
       "            0.9673 , 0.967  , 0.9663 , 0.9644 , 0.964  , 0.9614 , 0.9595 ,\n",
       "            0.959  , 0.9585 , 0.958  , 0.9565 , 0.954  , 0.9536 , 0.953  ,\n",
       "            0.952  , 0.951  , 0.95   , 0.9497 , 0.9478 , 0.947  , 0.9463 ,\n",
       "            0.946  , 0.945  , 0.94   , 0.9385 , 0.935  , 0.9346 , 0.933  ,\n",
       "            0.9316 , 0.9297 , 0.929  , 0.9287 , 0.928  , 0.9263 , 0.9253 ,\n",
       "            0.9243 , 0.922  , 0.9214 , 0.9204 , 0.919  , 0.917  , 0.9155 ,\n",
       "            0.915  , 0.9146 , 0.913  , 0.912  , 0.9116 , 0.905  , 0.9043 ,\n",
       "            0.903  , 0.9    , 0.899  , 0.8984 , 0.8965 , 0.8945 , 0.892  ,\n",
       "            0.89   , 0.889  , 0.888  , 0.8877 , 0.886  , 0.8857 , 0.8843 ,\n",
       "            0.882  , 0.8804 , 0.8755 , 0.8745 , 0.8706 , 0.8657 , 0.862  ,\n",
       "            0.86   , 0.8516 , 0.85   , 0.8486 , 0.8477 , 0.8457 , 0.83   ,\n",
       "            0.8296 , 0.829  , 0.825  , 0.8213 , 0.821  , 0.8057 , 0.7954 ,\n",
       "            0.7944 , 0.79   , 0.788  , 0.7837 , 0.7827 , 0.7817 , 0.779  ,\n",
       "            0.771  , 0.7705 , 0.769  , 0.7676 , 0.7666 , 0.761  , 0.757  ,\n",
       "            0.756  , 0.747  , 0.7417 , 0.7407 , 0.7393 , 0.7373 , 0.737  ,\n",
       "            0.731  , 0.7256 , 0.72   , 0.718  , 0.717  , 0.71   , 0.7046 ,\n",
       "            0.7036 , 0.6973 , 0.6924 , 0.6875 , 0.686  , 0.6846 , 0.684  ,\n",
       "            0.682  , 0.6797 , 0.6777 , 0.6733 , 0.673  , 0.6724 , 0.6714 ,\n",
       "            0.666  , 0.6646 , 0.663  , 0.662  , 0.6606 , 0.655  , 0.653  ,\n",
       "            0.6475 , 0.6304 , 0.63   , 0.6294 , 0.6284 , 0.628  , 0.6265 ,\n",
       "            0.6196 , 0.6113 , 0.609  , 0.6074 , 0.606  , 0.6055 , 0.599  ,\n",
       "            0.594  , 0.592  , 0.5903 , 0.5884 , 0.583  , 0.5825 , 0.5776 ,\n",
       "            0.5747 , 0.5723 , 0.572  , 0.563  , 0.5596 , 0.5483 , 0.5474 ,\n",
       "            0.547  , 0.545  , 0.543  , 0.5425 , 0.537  , 0.4731 , 0.4644 ,\n",
       "            0.4639 , 0.4592 , 0.437  , 0.4155 , 0.4146 , 0.4136 , 0.4036 ,\n",
       "            0.4028 , 0.4004 , 0.3535 , 0.3394 , 0.3335 , 0.312  , 0.295  ,\n",
       "            0.2937 , 0.2776 , 0.2769 , 0.275  , 0.2487 , 0.2328 , 0.229  ,\n",
       "            0.2185 , 0.209  , 0.204  , 0.1941 , 0.1937 , 0.1815 , 0.1559 ,\n",
       "            0.142  , 0.12054, 0.1142 , 0.1009 , 0.09186], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7109375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.03125  , 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.0703125, 0.0703125, 0.078125 , 0.0859375, 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.109375 , 0.1171875, 0.125    ,\n",
       "            0.125    , 0.1328125, 0.1484375, 0.15625  , 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5078125, 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5625   , 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04918033, 0.05737705, 0.07377049, 0.08196721, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.20491803, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4262295 , 0.44262296, 0.45081967,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.996 , 0.9956, 0.9937, 0.992 , 0.9917, 0.991 , 0.989 ,\n",
       "            0.988 , 0.987 , 0.9844, 0.984 , 0.981 , 0.98  , 0.9785, 0.978 ,\n",
       "            0.9775, 0.977 , 0.9756, 0.975 , 0.9746, 0.9736, 0.973 , 0.972 ,\n",
       "            0.9717, 0.9707, 0.9697, 0.968 , 0.9673, 0.967 , 0.9663, 0.9653,\n",
       "            0.964 , 0.9634, 0.9624, 0.962 , 0.9614, 0.961 , 0.96  , 0.959 ,\n",
       "            0.958 , 0.9575, 0.9565, 0.9556, 0.955 , 0.9546, 0.951 , 0.95  ,\n",
       "            0.948 , 0.9478, 0.9463, 0.945 , 0.9414, 0.941 , 0.9404, 0.9395,\n",
       "            0.939 , 0.9385, 0.9375, 0.9365, 0.9355, 0.9346, 0.9336, 0.9307,\n",
       "            0.93  , 0.9297, 0.928 , 0.9253, 0.9214, 0.92  , 0.9175, 0.916 ,\n",
       "            0.9155, 0.915 , 0.912 , 0.91  , 0.9097, 0.908 , 0.907 , 0.9053,\n",
       "            0.905 , 0.904 , 0.903 , 0.9023, 0.9004, 0.899 , 0.8984, 0.897 ,\n",
       "            0.8955, 0.888 , 0.8843, 0.8813, 0.879 , 0.8726, 0.8706, 0.869 ,\n",
       "            0.8687, 0.868 , 0.8574, 0.8525, 0.851 , 0.849 , 0.848 , 0.845 ,\n",
       "            0.8306, 0.826 , 0.8223, 0.822 , 0.8213, 0.8145, 0.812 , 0.8115,\n",
       "            0.8096, 0.809 , 0.806 , 0.8022, 0.801 , 0.797 , 0.7964, 0.7905,\n",
       "            0.789 , 0.785 , 0.7793, 0.771 , 0.7686, 0.7627, 0.7603, 0.7593,\n",
       "            0.758 , 0.756 , 0.755 , 0.753 , 0.752 , 0.749 , 0.7446, 0.742 ,\n",
       "            0.735 , 0.725 , 0.723 , 0.7217, 0.719 , 0.7144, 0.711 , 0.7095,\n",
       "            0.709 , 0.7085, 0.707 , 0.705 , 0.7026, 0.7007, 0.696 , 0.695 ,\n",
       "            0.691 , 0.6875, 0.687 , 0.686 , 0.6826, 0.674 , 0.672 , 0.6694,\n",
       "            0.6665, 0.6655, 0.6646, 0.6562, 0.654 , 0.6436, 0.643 , 0.639 ,\n",
       "            0.631 , 0.6284, 0.6274, 0.6255, 0.6245, 0.62  , 0.6167, 0.616 ,\n",
       "            0.6143, 0.6113, 0.6035, 0.6025, 0.599 , 0.5938, 0.59  , 0.5884,\n",
       "            0.587 , 0.563 , 0.562 , 0.561 , 0.5566, 0.4868, 0.4807, 0.4758,\n",
       "            0.4734, 0.4531, 0.426 , 0.425 , 0.4238, 0.4146, 0.413 , 0.4104,\n",
       "            0.3645, 0.3467, 0.3398, 0.3208, 0.3042, 0.2979, 0.282 , 0.281 ,\n",
       "            0.2805, 0.2783, 0.2515, 0.2343, 0.2299, 0.2238, 0.2104, 0.2048,\n",
       "            0.1981, 0.1936, 0.1805, 0.1548, 0.1399, 0.1184, 0.1124, 0.0991,\n",
       "            0.0896], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.71875, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0703125, 0.0703125, 0.078125 , 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.1015625, 0.1171875, 0.125    , 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.1640625, 0.171875 , 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.1953125, 0.1953125, 0.203125 , 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.08196721, 0.09016393,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.16393442, 0.17213115, 0.18852459, 0.19672132,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.24590164, 0.25409836,\n",
       "            0.2704918 , 0.27868852, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36885247,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5491803 , 0.55737704, 0.57377046,\n",
       "            0.59016395, 0.60655737, 0.6229508 , 0.63114756, 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9976 , 0.997  , 0.9956 , 0.9946 , 0.994  , 0.992  ,\n",
       "            0.9917 , 0.991  , 0.99   , 0.9883 , 0.986  , 0.9854 , 0.9844 ,\n",
       "            0.984  , 0.9834 , 0.983  , 0.982  , 0.981  , 0.9805 , 0.9795 ,\n",
       "            0.979  , 0.9785 , 0.9775 , 0.9756 , 0.975  , 0.9746 , 0.974  ,\n",
       "            0.9727 , 0.972  , 0.9717 , 0.971  , 0.9707 , 0.97   , 0.969  ,\n",
       "            0.9688 , 0.9673 , 0.9663 , 0.966  , 0.9653 , 0.965  , 0.9644 ,\n",
       "            0.964  , 0.9634 , 0.9614 , 0.9604 , 0.9595 , 0.959  , 0.958  ,\n",
       "            0.9575 , 0.956  , 0.9546 , 0.953  , 0.952  , 0.9517 , 0.951  ,\n",
       "            0.9497 , 0.9487 , 0.9478 , 0.9453 , 0.9443 , 0.9434 , 0.943  ,\n",
       "            0.9395 , 0.939  , 0.938  , 0.934  , 0.932  , 0.9316 , 0.929  ,\n",
       "            0.9277 , 0.927  , 0.9263 , 0.9253 , 0.9243 , 0.9214 , 0.9204 ,\n",
       "            0.92   , 0.9185 , 0.9175 , 0.9165 , 0.9155 , 0.905  , 0.903  ,\n",
       "            0.9014 , 0.898  , 0.897  , 0.8945 , 0.8926 , 0.8916 , 0.89   ,\n",
       "            0.8877 , 0.886  , 0.883  , 0.882  , 0.8706 , 0.8696 , 0.869  ,\n",
       "            0.868  , 0.8584 , 0.8564 , 0.851  , 0.847  , 0.8447 , 0.8433 ,\n",
       "            0.8423 , 0.8403 , 0.8384 , 0.8374 , 0.837  , 0.8296 , 0.826  ,\n",
       "            0.822  , 0.819  , 0.808  , 0.8022 , 0.798  , 0.7935 , 0.793  ,\n",
       "            0.79   , 0.7896 , 0.786  , 0.7837 , 0.783  , 0.7827 , 0.779  ,\n",
       "            0.772  , 0.769  , 0.766  , 0.764  , 0.756  , 0.7524 , 0.752  ,\n",
       "            0.746  , 0.7446 , 0.7437 , 0.741  , 0.7393 , 0.738  , 0.735  ,\n",
       "            0.734  , 0.7324 , 0.732  , 0.7285 , 0.728  , 0.726  , 0.722  ,\n",
       "            0.7188 , 0.7124 , 0.711  , 0.7095 , 0.707  , 0.7065 , 0.7007 ,\n",
       "            0.6895 , 0.689  , 0.6855 , 0.6787 , 0.678  , 0.675  , 0.6733 ,\n",
       "            0.6704 , 0.6685 , 0.6675 , 0.6665 , 0.661  , 0.656  , 0.6533 ,\n",
       "            0.6523 , 0.6504 , 0.649  , 0.6455 , 0.642  , 0.6406 , 0.639  ,\n",
       "            0.6284 , 0.618  , 0.591  , 0.5874 , 0.5845 , 0.58   , 0.508  ,\n",
       "            0.4995 , 0.494  , 0.492  , 0.4712 , 0.44   , 0.4395 , 0.4392 ,\n",
       "            0.4302 , 0.4282 , 0.4248 , 0.3838 , 0.357  , 0.3494 , 0.3315 ,\n",
       "            0.3147 , 0.3064 , 0.2883 , 0.2878 , 0.2869 , 0.2847 , 0.2563 ,\n",
       "            0.2375 , 0.2374 , 0.2335 , 0.2294 , 0.2134 , 0.2064 , 0.2024 ,\n",
       "            0.1946 , 0.181  , 0.1561 , 0.138  , 0.118  , 0.113  , 0.09753,\n",
       "            0.0871 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7421875, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.0234375, 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0546875, 0.0625   , 0.0625   , 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.234375 , 0.234375 , 0.2421875, 0.25     , 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5234375, 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.04098361,\n",
       "            0.05737705, 0.06557377, 0.08196721, 0.09016393, 0.10655738,\n",
       "            0.12295082, 0.13114753, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.21311475, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.28688523,\n",
       "            0.3114754 , 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36885247, 0.3852459 , 0.39344263, 0.40983605, 0.4180328 ,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.60655737, 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.8032787 , 0.8114754 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.8442623 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9985 , 0.998  , 0.997  , 0.9966 , 0.996  , 0.995  ,\n",
       "            0.994  , 0.993  , 0.9917 , 0.9897 , 0.9893 , 0.9883 , 0.988  ,\n",
       "            0.987  , 0.9863 , 0.986  , 0.9854 , 0.985  , 0.9844 , 0.984  ,\n",
       "            0.9834 , 0.9824 , 0.982  , 0.9814 , 0.981  , 0.98   , 0.9795 ,\n",
       "            0.979  , 0.9775 , 0.977  , 0.9766 , 0.9756 , 0.9746 , 0.974  ,\n",
       "            0.9727 , 0.9717 , 0.971  , 0.9707 , 0.97   , 0.9697 , 0.969  ,\n",
       "            0.9683 , 0.968  , 0.9663 , 0.966  , 0.965  , 0.964  , 0.9634 ,\n",
       "            0.963  , 0.961  , 0.96   , 0.9595 , 0.959  , 0.958  , 0.9575 ,\n",
       "            0.957  , 0.956  , 0.9556 , 0.9526 , 0.9517 , 0.9478 , 0.9473 ,\n",
       "            0.9463 , 0.946  , 0.944  , 0.9434 , 0.942  , 0.939  , 0.9385 ,\n",
       "            0.9375 , 0.936  , 0.935  , 0.934  , 0.932  , 0.93   , 0.924  ,\n",
       "            0.923  , 0.9194 , 0.918  , 0.9175 , 0.916  , 0.9136 , 0.913  ,\n",
       "            0.9126 , 0.9116 , 0.91   , 0.902  , 0.896  , 0.893  , 0.8906 ,\n",
       "            0.89   , 0.886  , 0.882  , 0.88   , 0.8794 , 0.878  , 0.876  ,\n",
       "            0.8755 , 0.874  , 0.871  , 0.87   , 0.869  , 0.8687 , 0.8667 ,\n",
       "            0.865  , 0.863  , 0.8564 , 0.849  , 0.8467 , 0.846  , 0.836  ,\n",
       "            0.8335 , 0.831  , 0.83   , 0.8286 , 0.8276 , 0.8247 , 0.8237 ,\n",
       "            0.8193 , 0.819  , 0.8164 , 0.814  , 0.811  , 0.806  , 0.8057 ,\n",
       "            0.801  , 0.7964 , 0.795  , 0.794  , 0.792  , 0.789  , 0.786  ,\n",
       "            0.7856 , 0.785  , 0.7827 , 0.7793 , 0.7764 , 0.774  , 0.769  ,\n",
       "            0.765  , 0.7646 , 0.7627 , 0.7617 , 0.761  , 0.759  , 0.758  ,\n",
       "            0.7524 , 0.752  , 0.748  , 0.7446 , 0.7427 , 0.7373 , 0.735  ,\n",
       "            0.7324 , 0.732  , 0.7314 , 0.7285 , 0.7266 , 0.7236 , 0.723  ,\n",
       "            0.7183 , 0.716  , 0.715  , 0.7104 , 0.706  , 0.703  , 0.681  ,\n",
       "            0.6777 , 0.6743 , 0.6655 , 0.6533 , 0.6465 , 0.6245 , 0.6143 ,\n",
       "            0.611  , 0.605  , 0.5337 , 0.52   , 0.5166 , 0.513  , 0.4907 ,\n",
       "            0.4578 , 0.457  , 0.4565 , 0.4482 , 0.4473 , 0.4429 , 0.409  ,\n",
       "            0.3699 , 0.362  , 0.3445 , 0.3264 , 0.3186 , 0.2969 , 0.2964 ,\n",
       "            0.2954 , 0.294  , 0.263  , 0.2426 , 0.2397 , 0.2363 , 0.218  ,\n",
       "            0.2098 , 0.2079 , 0.197  , 0.183  , 0.1597 , 0.1373 , 0.119  ,\n",
       "            0.11615, 0.0967 , 0.0854 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.75, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.0234375, 0.0234375, 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.078125 ,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.09375  , 0.1015625, 0.1015625,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.1328125, 0.140625 , 0.140625 ,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.234375 , 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.4140625, 0.421875 , 0.4375   , 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.546875 , 0.5546875, 0.5625   , 0.578125 ,\n",
       "            0.5859375, 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01639344, 0.03278688, 0.05737705, 0.06557377,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.16393442, 0.17213115, 0.18852459,\n",
       "            0.20491803, 0.22131148, 0.22950819, 0.24590164, 0.2704918 ,\n",
       "            0.29508197, 0.32786885, 0.3442623 , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.46721312,\n",
       "            0.5       , 0.5163934 , 0.52459013, 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.60655737,\n",
       "            0.6147541 , 0.6393443 , 0.647541  , 0.6557377 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.8606557 , 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.999  , 0.998  , 0.9976 , 0.997  , 0.996  , 0.995  ,\n",
       "            0.9946 , 0.994  , 0.993  , 0.9927 , 0.992  , 0.9917 , 0.99   ,\n",
       "            0.9897 , 0.9893 , 0.989  , 0.9883 , 0.988  , 0.9873 , 0.9863 ,\n",
       "            0.986  , 0.985  , 0.9834 , 0.983  , 0.9824 , 0.982  , 0.981  ,\n",
       "            0.9805 , 0.98   , 0.9795 , 0.979  , 0.9785 , 0.978  , 0.9775 ,\n",
       "            0.977  , 0.9766 , 0.976  , 0.9756 , 0.9736 , 0.9727 , 0.972  ,\n",
       "            0.9717 , 0.9707 , 0.9683 , 0.968  , 0.9673 , 0.967  , 0.966  ,\n",
       "            0.9653 , 0.9644 , 0.963  , 0.962  , 0.9614 , 0.961  , 0.9604 ,\n",
       "            0.9595 , 0.959  , 0.956  , 0.954  , 0.9536 , 0.953  , 0.9517 ,\n",
       "            0.95   , 0.9497 , 0.9487 , 0.948  , 0.947  , 0.9463 , 0.946  ,\n",
       "            0.9453 , 0.9434 , 0.941  , 0.9395 , 0.9385 , 0.9365 , 0.935  ,\n",
       "            0.932  , 0.9316 , 0.9307 , 0.93   , 0.9277 , 0.916  , 0.9146 ,\n",
       "            0.9136 , 0.912  , 0.91   , 0.9097 , 0.909  , 0.9087 , 0.908  ,\n",
       "            0.9077 , 0.9062 , 0.9053 , 0.9043 , 0.902  , 0.8984 , 0.895  ,\n",
       "            0.892  , 0.8906 , 0.885  , 0.884  , 0.882  , 0.877  , 0.875  ,\n",
       "            0.8735 , 0.8706 , 0.8696 , 0.868  , 0.8677 , 0.865  , 0.8643 ,\n",
       "            0.863  , 0.855  , 0.8545 , 0.854  , 0.8516 , 0.8486 , 0.8477 ,\n",
       "            0.844  , 0.8438 , 0.843  , 0.8423 , 0.8403 , 0.838  , 0.8374 ,\n",
       "            0.8335 , 0.8325 , 0.832  , 0.829  , 0.8276 , 0.8267 , 0.8184 ,\n",
       "            0.817  , 0.814  , 0.8125 , 0.8066 , 0.803  , 0.801  , 0.7993 ,\n",
       "            0.796  , 0.792  , 0.7905 , 0.789  , 0.7866 , 0.7856 , 0.784  ,\n",
       "            0.783  , 0.7827 , 0.7817 , 0.78   , 0.7793 , 0.775  , 0.763  ,\n",
       "            0.7583 , 0.728  , 0.7075 , 0.705  , 0.702  , 0.692  , 0.6807 ,\n",
       "            0.677  , 0.665  , 0.645  , 0.64   , 0.633  , 0.5654 , 0.5464 ,\n",
       "            0.5444 , 0.539  , 0.514  , 0.4814 , 0.4783 , 0.4734 , 0.4707 ,\n",
       "            0.466  , 0.4443 , 0.3872 , 0.3792 , 0.3613 , 0.342  , 0.3376 ,\n",
       "            0.31   , 0.3096 , 0.3093 , 0.309  , 0.2742 , 0.2527 , 0.252  ,\n",
       "            0.2467 , 0.2263 , 0.2177 , 0.2166 , 0.2042 , 0.1897 , 0.1683 ,\n",
       "            0.1407 , 0.1241 , 0.09875, 0.0863 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.75, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.0703125, 0.0703125, 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.109375 , 0.1171875, 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.140625 , 0.140625 , 0.140625 ,\n",
       "            0.140625 , 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1796875,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.875    , 0.8828125, 0.890625 , 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.04098361, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.12295082, 0.13934426, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.2704918 , 0.29508197, 0.31967214, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40983605, 0.4262295 , 0.44262296, 0.45081967, 0.46721312,\n",
       "            0.48360655, 0.5       , 0.5163934 , 0.5327869 , 0.5491803 ,\n",
       "            0.55737704, 0.57377046, 0.58196723, 0.59016395, 0.6147541 ,\n",
       "            0.63114756, 0.6557377 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.704918  , 0.7295082 , 0.73770493, 0.75409836, 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.89344263, 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9995, 0.999 , 0.9985, 0.998 , 0.9976, 0.997 , 0.9966,\n",
       "            0.996 , 0.9956, 0.995 , 0.9946, 0.994 , 0.993 , 0.9927, 0.992 ,\n",
       "            0.9917, 0.991 , 0.9907, 0.99  , 0.9897, 0.989 , 0.9883, 0.988 ,\n",
       "            0.9873, 0.9863, 0.986 , 0.9854, 0.985 , 0.984 , 0.9834, 0.983 ,\n",
       "            0.9824, 0.982 , 0.9814, 0.981 , 0.9805, 0.98  , 0.9795, 0.979 ,\n",
       "            0.9785, 0.9766, 0.976 , 0.9746, 0.972 , 0.9717, 0.9707, 0.97  ,\n",
       "            0.969 , 0.9688, 0.9683, 0.967 , 0.9653, 0.961 , 0.96  , 0.9585,\n",
       "            0.9575, 0.957 , 0.9565, 0.955 , 0.9546, 0.9536, 0.953 , 0.9526,\n",
       "            0.9507, 0.95  , 0.948 , 0.9463, 0.9453, 0.9443, 0.94  , 0.9395,\n",
       "            0.9385, 0.9375, 0.9365, 0.9346, 0.932 , 0.929 , 0.9277, 0.927 ,\n",
       "            0.9253, 0.925 , 0.9243, 0.924 , 0.922 , 0.921 , 0.9194, 0.9175,\n",
       "            0.916 , 0.915 , 0.91  , 0.909 , 0.9043, 0.9023, 0.902 , 0.8994,\n",
       "            0.8984, 0.8945, 0.894 , 0.8936, 0.893 , 0.8926, 0.8906, 0.889 ,\n",
       "            0.886 , 0.885 , 0.8843, 0.8813, 0.88  , 0.878 , 0.8755, 0.872 ,\n",
       "            0.871 , 0.87  , 0.869 , 0.8657, 0.8623, 0.858 , 0.857 , 0.856 ,\n",
       "            0.853 , 0.852 , 0.8516, 0.849 , 0.848 , 0.846 , 0.8457, 0.845 ,\n",
       "            0.8423, 0.842 , 0.841 , 0.839 , 0.8374, 0.8354, 0.8315, 0.8306,\n",
       "            0.83  , 0.8286, 0.8276, 0.8267, 0.826 , 0.825 , 0.824 , 0.8237,\n",
       "            0.823 , 0.806 , 0.8022, 0.8003, 0.8   , 0.7964, 0.7793, 0.7754,\n",
       "            0.7446, 0.725 , 0.7227, 0.72  , 0.709 , 0.698 , 0.6963, 0.6865,\n",
       "            0.6655, 0.66  , 0.652 , 0.5864, 0.567 , 0.5625, 0.5576, 0.5317,\n",
       "            0.5   , 0.496 , 0.4922, 0.4885, 0.4841, 0.4648, 0.4028, 0.3945,\n",
       "            0.3762, 0.3562, 0.3528, 0.3235, 0.323 , 0.3228, 0.286 , 0.2634,\n",
       "            0.2632, 0.2573, 0.2358, 0.2268, 0.2257, 0.2128, 0.1978, 0.1764,\n",
       "            0.1462, 0.1304, 0.1296, 0.1025, 0.0895], dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.08474576, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.18644068, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.22033899, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.31355932, 0.31355932, 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.37288135, 0.38135594,\n",
       "            0.3983051 , 0.40677965, 0.43220338, 0.44067797, 0.4661017 ,\n",
       "            0.47457626, 0.4915254 , 0.5084746 , 0.5338983 , 0.5423729 ,\n",
       "            0.55932206, 0.5762712 , 0.6101695 , 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6779661 , 0.69491524, 0.7118644 , 0.720339  ,\n",
       "            0.7372881 , 0.7542373 , 0.7627119 , 0.779661  , 0.7966102 ,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.84745765, 0.8559322 , 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.90677965, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 ,\n",
       "            0.9576271 , 0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.06818182,\n",
       "            0.09848485, 0.11363637, 0.12878788, 0.14393939, 0.15151516,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.20454545, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.42424244, 0.43939394, 0.43939394,\n",
       "            0.45454547, 0.45454547, 0.46212122, 0.46212122, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.50757575, 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.52272725, 0.52272725,\n",
       "            0.52272725, 0.52272725, 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.56060606, 0.56060606, 0.56060606, 0.56060606,\n",
       "            0.56060606, 0.56060606, 0.56060606, 0.56060606, 0.56060606,\n",
       "            0.56060606, 0.56060606, 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.57575756, 0.57575756, 0.57575756,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.59090906, 0.5984849 , 0.5984849 , 0.5984849 , 0.5984849 ,\n",
       "            0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.99242425, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4634, 0.4631, 0.463 , 0.4622, 0.462 , 0.4617, 0.4612,\n",
       "            0.461 , 0.4607, 0.4604, 0.4597, 0.4595, 0.459 , 0.4587, 0.4585,\n",
       "            0.458 , 0.4575, 0.4573, 0.4568, 0.456 , 0.455 , 0.4548, 0.4546,\n",
       "            0.4534, 0.453 , 0.4526, 0.4524, 0.452 , 0.4514, 0.4512, 0.4492,\n",
       "            0.449 , 0.4478, 0.4463, 0.4458, 0.4456, 0.445 , 0.4446, 0.444 ,\n",
       "            0.4436, 0.443 , 0.4424, 0.4421, 0.4417, 0.4412, 0.4407, 0.4404,\n",
       "            0.44  , 0.4392, 0.439 , 0.437 , 0.4368, 0.4365, 0.4346, 0.4343,\n",
       "            0.434 , 0.433 , 0.4324, 0.4316, 0.431 , 0.4307, 0.4304, 0.43  ,\n",
       "            0.4277, 0.427 , 0.4268, 0.4263, 0.426 , 0.4258, 0.4248, 0.4229,\n",
       "            0.4226, 0.4219, 0.4216, 0.4214, 0.421 , 0.4204, 0.4202, 0.4197,\n",
       "            0.4192, 0.4187, 0.4185, 0.4182, 0.418 , 0.4172, 0.417 , 0.4167,\n",
       "            0.4165, 0.4163, 0.416 , 0.4155, 0.4153, 0.415 , 0.4148, 0.4146,\n",
       "            0.4143, 0.414 , 0.4138, 0.4133, 0.4128, 0.4124, 0.4114, 0.4111,\n",
       "            0.411 , 0.4104, 0.41  , 0.409 , 0.4087, 0.4084, 0.4082, 0.408 ,\n",
       "            0.4075, 0.4072, 0.4067, 0.4065, 0.4058, 0.405 , 0.4045, 0.4033,\n",
       "            0.403 , 0.4026, 0.4019, 0.4016, 0.4006, 0.4   , 0.3982, 0.398 ,\n",
       "            0.3977, 0.3965, 0.396 , 0.3958, 0.392 , 0.3896, 0.3877, 0.3872,\n",
       "            0.3867, 0.3865, 0.3855, 0.3853, 0.3845, 0.382 , 0.3818, 0.3816,\n",
       "            0.3809, 0.3806, 0.3801, 0.3784, 0.3782, 0.3777, 0.3774, 0.3765,\n",
       "            0.376 , 0.3745, 0.374 , 0.3713, 0.37  , 0.3694, 0.3687, 0.3662,\n",
       "            0.3643, 0.362 , 0.3616, 0.3604, 0.36  , 0.3555, 0.3547, 0.3542,\n",
       "            0.3528, 0.3516, 0.3503, 0.3489, 0.347 , 0.3452, 0.3286],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.29661018, 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5423729 , 0.5508475 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.59322035, 0.6101695 ,\n",
       "            0.61864406, 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.6694915 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7372881 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.8135593 , 0.8305085 , 0.83898306, 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.88135594, 0.88135594, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.90677965, 0.91525424, 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9661017 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03787879, 0.04545455,\n",
       "            0.0530303 , 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.11363637, 0.12121212, 0.16666667, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.34848484,\n",
       "            0.36363637, 0.36363637, 0.37121212, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.42424244, 0.42424244,\n",
       "            0.42424244, 0.42424244, 0.4318182 , 0.4318182 , 0.4318182 ,\n",
       "            0.4318182 , 0.4469697 , 0.4469697 , 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.46212122, 0.46969697, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.49242425, 0.49242425, 0.49242425, 0.49242425,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.50757575, 0.50757575, 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.52272725, 0.52272725,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.54545456, 0.54545456,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.54545456, 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.56060606, 0.56060606, 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.57575756, 0.57575756, 0.57575756,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.5833333 , 0.59090906,\n",
       "            0.59090906, 0.59090906, 0.59090906, 0.59090906, 0.5984849 ,\n",
       "            0.5984849 , 0.5984849 , 0.5984849 , 0.5984849 , 0.6060606 ,\n",
       "            0.6060606 , 0.6060606 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6363636 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6439394 ,\n",
       "            0.6439394 , 0.6439394 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.68939394, 0.68939394, 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.79545456, 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4475, 0.4473, 0.4463, 0.446 , 0.4458, 0.4443, 0.4436,\n",
       "            0.4434, 0.4429, 0.4426, 0.4421, 0.4414, 0.4412, 0.441 , 0.4407,\n",
       "            0.4404, 0.4397, 0.4387, 0.4385, 0.4382, 0.438 , 0.4373, 0.437 ,\n",
       "            0.4363, 0.4358, 0.4355, 0.4353, 0.435 , 0.434 , 0.4336, 0.4321,\n",
       "            0.432 , 0.4314, 0.4312, 0.431 , 0.43  , 0.4272, 0.427 , 0.4265,\n",
       "            0.426 , 0.4248, 0.4243, 0.4238, 0.4229, 0.4216, 0.4214, 0.421 ,\n",
       "            0.4207, 0.4204, 0.42  , 0.4194, 0.419 , 0.4177, 0.4175, 0.4172,\n",
       "            0.417 , 0.4167, 0.4158, 0.4155, 0.4143, 0.4133, 0.4128, 0.4124,\n",
       "            0.4104, 0.4092, 0.409 , 0.4087, 0.4075, 0.4065, 0.4062, 0.4058,\n",
       "            0.4055, 0.4053, 0.4048, 0.4028, 0.402 , 0.401 , 0.4006, 0.3992,\n",
       "            0.399 , 0.3987, 0.398 , 0.3972, 0.3965, 0.396 , 0.3953, 0.3936,\n",
       "            0.3916, 0.3906, 0.3904, 0.3882, 0.3875, 0.3867, 0.386 , 0.3853,\n",
       "            0.384 , 0.3828, 0.3823, 0.38  , 0.3782, 0.3777, 0.3772, 0.3767,\n",
       "            0.376 , 0.3757, 0.3755, 0.3748, 0.3745, 0.3733, 0.3716, 0.3713,\n",
       "            0.371 , 0.3704, 0.3687, 0.3684, 0.3677, 0.3672, 0.367 , 0.3665,\n",
       "            0.3662, 0.366 , 0.3643, 0.3635, 0.3633, 0.362 , 0.3618, 0.3608,\n",
       "            0.3606, 0.3604, 0.3596, 0.3567, 0.3562, 0.356 , 0.3555, 0.3552,\n",
       "            0.355 , 0.3542, 0.353 , 0.3528, 0.3518, 0.3516, 0.3513, 0.351 ,\n",
       "            0.3506, 0.35  , 0.3499, 0.3496, 0.349 , 0.3489, 0.3484, 0.3477,\n",
       "            0.347 , 0.346 , 0.3455, 0.3452, 0.344 , 0.3435, 0.343 , 0.3423,\n",
       "            0.3408, 0.3403, 0.3389, 0.3386, 0.3367, 0.3364, 0.336 , 0.3357,\n",
       "            0.3323, 0.3318, 0.3315, 0.3313, 0.3308, 0.3254, 0.3252, 0.324 ,\n",
       "            0.3208, 0.32  , 0.3179, 0.317 , 0.3167, 0.3164, 0.3145, 0.3105,\n",
       "            0.31  , 0.3093, 0.308 , 0.3071, 0.3064, 0.3052, 0.305 , 0.304 ,\n",
       "            0.3018, 0.3015, 0.2996, 0.2979, 0.2954, 0.2869, 0.286 , 0.2842,\n",
       "            0.284 , 0.2815, 0.278 , 0.2764, 0.2737, 0.2708, 0.269 , 0.268 ,\n",
       "            0.2445], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.10169491, 0.11016949, 0.11016949, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3559322 , 0.3644068 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.62711865, 0.63559324,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8220339 , 0.8305085 , 0.8305085 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.89830506, 0.89830506, 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9661017 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 ,\n",
       "            0.9915254 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.09090909, 0.09848485, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.1969697 , 0.20454545, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.27272728, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.37878788, 0.37878788,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.40151516,\n",
       "            0.40151516, 0.40151516, 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.41666666, 0.42424244, 0.42424244, 0.42424244, 0.42424244,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.45454547, 0.45454547, 0.45454547, 0.46212122, 0.46212122,\n",
       "            0.46212122, 0.46212122, 0.46969697, 0.46969697, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.4848485 , 0.49242425, 0.49242425, 0.49242425,\n",
       "            0.49242425, 0.49242425, 0.49242425, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5151515 , 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.52272725, 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.54545456, 0.54545456,\n",
       "            0.54545456, 0.54545456, 0.5530303 , 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.5984849 , 0.6060606 , 0.6060606 ,\n",
       "            0.6060606 , 0.6060606 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6287879 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6439394 , 0.6515151 , 0.6515151 ,\n",
       "            0.6515151 , 0.6515151 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.6666667 , 0.67424244, 0.68939394,\n",
       "            0.68939394, 0.68939394, 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.719697  , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.7651515 ,\n",
       "            0.77272725, 0.77272725, 0.780303  , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.432 , 0.4316, 0.431 , 0.4307, 0.4304, 0.4292, 0.4287,\n",
       "            0.4285, 0.4272, 0.424 , 0.4236, 0.423 , 0.422 , 0.4219, 0.4216,\n",
       "            0.4214, 0.4211, 0.421 , 0.4202, 0.42  , 0.419 , 0.4185, 0.4182,\n",
       "            0.4177, 0.4175, 0.417 , 0.4165, 0.4153, 0.4143, 0.4138, 0.4128,\n",
       "            0.412 , 0.4119, 0.4116, 0.4114, 0.4111, 0.4097, 0.4094, 0.4082,\n",
       "            0.408 , 0.4077, 0.4072, 0.4062, 0.404 , 0.4038, 0.402 , 0.4019,\n",
       "            0.4014, 0.3972, 0.3967, 0.396 , 0.3955, 0.3953, 0.395 , 0.3948,\n",
       "            0.3933, 0.3928, 0.3926, 0.3923, 0.3916, 0.3914, 0.391 , 0.39  ,\n",
       "            0.3894, 0.3892, 0.3882, 0.387 , 0.3865, 0.3857, 0.385 , 0.3843,\n",
       "            0.3838, 0.3826, 0.3816, 0.38  , 0.3796, 0.379 , 0.3784, 0.3777,\n",
       "            0.377 , 0.3762, 0.3755, 0.3735, 0.3733, 0.3728, 0.372 , 0.3718,\n",
       "            0.3713, 0.3704, 0.37  , 0.3694, 0.3677, 0.3674, 0.3672, 0.3667,\n",
       "            0.365 , 0.3643, 0.362 , 0.3582, 0.3555, 0.3552, 0.3528, 0.3494,\n",
       "            0.3486, 0.3477, 0.3474, 0.3452, 0.3435, 0.343 , 0.3418, 0.3408,\n",
       "            0.3381, 0.3374, 0.3372, 0.3345, 0.333 , 0.3303, 0.3298, 0.3289,\n",
       "            0.3286, 0.3267, 0.325 , 0.3245, 0.3237, 0.3235, 0.3232, 0.3228,\n",
       "            0.3208, 0.3198, 0.319 , 0.318 , 0.3176, 0.317 , 0.3157, 0.3147,\n",
       "            0.3132, 0.3125, 0.3115, 0.3103, 0.3093, 0.3079, 0.3076, 0.3074,\n",
       "            0.307 , 0.3066, 0.3042, 0.3027, 0.2996, 0.2988, 0.2983, 0.298 ,\n",
       "            0.2974, 0.297 , 0.2969, 0.2966, 0.2957, 0.295 , 0.2937, 0.2935,\n",
       "            0.2925, 0.2908, 0.29  , 0.2893, 0.2886, 0.288 , 0.2876, 0.2869,\n",
       "            0.2866, 0.2864, 0.2837, 0.281 , 0.2805, 0.2793, 0.279 , 0.2773,\n",
       "            0.2766, 0.2754, 0.2747, 0.2744, 0.2742, 0.2732, 0.2722, 0.27  ,\n",
       "            0.269 , 0.2678, 0.266 , 0.2646, 0.264 , 0.263 , 0.2622, 0.2615,\n",
       "            0.26  , 0.2598, 0.2595, 0.259 , 0.258 , 0.2551, 0.2546, 0.252 ,\n",
       "            0.2505, 0.2494, 0.2487, 0.2467, 0.2449, 0.2434, 0.2428, 0.2426,\n",
       "            0.2421, 0.2383, 0.2343, 0.2235, 0.2233, 0.2218, 0.2202, 0.2197,\n",
       "            0.2185, 0.2157, 0.214 , 0.2104, 0.2063, 0.2051, 0.205 , 0.1785],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.11016949, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.23728813, 0.2542373 ,\n",
       "            0.26271185, 0.27966103, 0.2881356 , 0.29661018, 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.3644068 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6779661 , 0.6864407 , 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.80508476, 0.8220339 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.83898306, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.88135594, 0.88135594, 0.88135594, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.90677965, 0.90677965,\n",
       "            0.91525424, 0.91525424, 0.9237288 , 0.9322034 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            0.9915254 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.07575758, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.12121212, 0.12878788, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.1590909 , 0.16666667,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.21212122,\n",
       "            0.22727273, 0.25      , 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.31060606,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.32575756, 0.33333334,\n",
       "            0.34848484, 0.34848484, 0.3560606 , 0.36363637, 0.36363637,\n",
       "            0.36363637, 0.37121212, 0.37121212, 0.37878788, 0.37878788,\n",
       "            0.37878788, 0.37878788, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.42424244, 0.42424244, 0.4318182 , 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.43939394, 0.43939394,\n",
       "            0.4469697 , 0.4469697 , 0.45454547, 0.46212122, 0.46212122,\n",
       "            0.46212122, 0.46212122, 0.46212122, 0.46212122, 0.46969697,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.49242425, 0.5       ,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.52272725, 0.52272725, 0.52272725,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.5530303 , 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.57575756, 0.57575756, 0.57575756, 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.59090906, 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.5984849 , 0.5984849 , 0.5984849 ,\n",
       "            0.5984849 , 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6439394 , 0.6439394 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.6666667 , 0.6666667 , 0.6666667 , 0.6666667 ,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.6969697 , 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.7121212 , 0.719697  , 0.719697  , 0.719697  , 0.72727275,\n",
       "            0.72727275, 0.72727275, 0.7348485 , 0.75      , 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4182, 0.4158, 0.4155, 0.415 , 0.4138, 0.413 , 0.4106,\n",
       "            0.4104, 0.4058, 0.4053, 0.4036, 0.4033, 0.401 , 0.4006, 0.4001,\n",
       "            0.3992, 0.3987, 0.3982, 0.3975, 0.3967, 0.3965, 0.3962, 0.396 ,\n",
       "            0.395 , 0.3936, 0.393 , 0.3926, 0.3923, 0.3916, 0.391 , 0.3904,\n",
       "            0.3894, 0.3872, 0.3843, 0.3838, 0.3833, 0.383 , 0.3826, 0.3813,\n",
       "            0.381 , 0.38  , 0.3792, 0.3767, 0.375 , 0.3745, 0.3735, 0.3728,\n",
       "            0.3718, 0.3704, 0.37  , 0.3694, 0.3687, 0.3682, 0.3672, 0.3665,\n",
       "            0.3652, 0.3643, 0.3638, 0.3635, 0.3628, 0.3625, 0.3606, 0.36  ,\n",
       "            0.3594, 0.3582, 0.358 , 0.357 , 0.355 , 0.3547, 0.3535, 0.353 ,\n",
       "            0.3525, 0.3518, 0.35  , 0.3499, 0.3489, 0.348 , 0.3464, 0.3462,\n",
       "            0.3452, 0.3442, 0.344 , 0.3433, 0.34  , 0.3394, 0.3386, 0.338 ,\n",
       "            0.3354, 0.3333, 0.3308, 0.3281, 0.3264, 0.3228, 0.3218, 0.319 ,\n",
       "            0.3186, 0.3184, 0.3174, 0.3154, 0.3147, 0.312 , 0.311 , 0.3103,\n",
       "            0.307 , 0.3037, 0.2983, 0.298 , 0.2966, 0.2961, 0.294 , 0.2922,\n",
       "            0.2898, 0.2886, 0.288 , 0.287 , 0.2856, 0.283 , 0.2827, 0.282 ,\n",
       "            0.2815, 0.281 , 0.279 , 0.278 , 0.2756, 0.2747, 0.273 , 0.2717,\n",
       "            0.271 , 0.2708, 0.2703, 0.268 , 0.2676, 0.2654, 0.2637, 0.263 ,\n",
       "            0.2622, 0.2583, 0.2573, 0.2556, 0.2546, 0.2537, 0.2532, 0.2527,\n",
       "            0.2524, 0.2493, 0.249 , 0.2489, 0.2483, 0.2473, 0.2466, 0.246 ,\n",
       "            0.2445, 0.243 , 0.2426, 0.2421, 0.2411, 0.241 , 0.2407, 0.2363,\n",
       "            0.2358, 0.2346, 0.2335, 0.233 , 0.2327, 0.2318, 0.231 , 0.2306,\n",
       "            0.2303, 0.2302, 0.229 , 0.2268, 0.2246, 0.2225, 0.2222, 0.2198,\n",
       "            0.2195, 0.2186, 0.2181, 0.2177, 0.2175, 0.217 , 0.2166, 0.2156,\n",
       "            0.2134, 0.2125, 0.2114, 0.2104, 0.2085, 0.2064, 0.2056, 0.2042,\n",
       "            0.2039, 0.2032, 0.2031, 0.2029, 0.2026, 0.1989, 0.1967, 0.1962,\n",
       "            0.1959, 0.1958, 0.1952, 0.1947, 0.1946, 0.1934, 0.1925, 0.1923,\n",
       "            0.1833, 0.1757, 0.1735, 0.1716, 0.1708, 0.1693, 0.1676, 0.1666,\n",
       "            0.165 , 0.1616, 0.1572, 0.157 , 0.1566, 0.1307], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22033899, 0.22033899,\n",
       "            0.22033899, 0.23728813, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.2881356 ,\n",
       "            0.30508474, 0.3220339 , 0.3220339 , 0.3220339 , 0.33050847,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.3644068 , 0.3644068 , 0.3644068 , 0.37288135,\n",
       "            0.3898305 , 0.3898305 , 0.3983051 , 0.40677965, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 ,\n",
       "            0.7033898 , 0.7118644 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7288136 , 0.7372881 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.7711864 , 0.779661  , 0.779661  ,\n",
       "            0.7881356 , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.83898306, 0.83898306, 0.83898306, 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.88135594, 0.88135594, 0.88135594, 0.8898305 ,\n",
       "            0.8898305 , 0.8898305 , 0.89830506, 0.89830506, 0.90677965,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.9322034 ,\n",
       "            0.94067794, 0.94067794, 0.94067794, 0.94067794, 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 ,\n",
       "            0.9915254 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.24242425,\n",
       "            0.25757575, 0.27272728, 0.28030303, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.29545453, 0.3030303 , 0.31060606, 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.34848484, 0.34848484,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.36363637, 0.36363637,\n",
       "            0.36363637, 0.36363637, 0.36363637, 0.37121212, 0.37121212,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.40151516, 0.40151516, 0.40151516,\n",
       "            0.4090909 , 0.4090909 , 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.43939394, 0.43939394,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.46212122, 0.46969697, 0.46969697,\n",
       "            0.47727272, 0.47727272, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.5530303 , 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.57575756, 0.57575756, 0.57575756, 0.57575756, 0.57575756,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.59090906, 0.59090906,\n",
       "            0.59090906, 0.59090906, 0.5984849 , 0.5984849 , 0.5984849 ,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6439394 , 0.6515151 , 0.6515151 , 0.6515151 ,\n",
       "            0.6515151 , 0.6515151 , 0.65909094, 0.65909094, 0.6666667 ,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.67424244, 0.67424244,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.70454544, 0.70454544,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.72727275,\n",
       "            0.7348485 , 0.75      , 0.75      , 0.75757575, 0.75757575,\n",
       "            0.7651515 , 0.7651515 , 0.77272725, 0.77272725, 0.780303  ,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.81060606, 0.8181818 ,\n",
       "            0.8181818 , 0.8181818 , 0.8181818 , 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.9848485 , 0.99242425,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4036 , 0.4014 , 0.4004 , 0.3987 , 0.3972 , 0.396  ,\n",
       "            0.3958 , 0.3953 , 0.393  , 0.3923 , 0.3909 , 0.3892 , 0.3835 ,\n",
       "            0.383  , 0.3818 , 0.381  , 0.3809 , 0.3806 , 0.3804 , 0.3765 ,\n",
       "            0.3762 , 0.376  , 0.3755 , 0.3752 , 0.3743 , 0.374  , 0.3735 ,\n",
       "            0.3728 , 0.3723 , 0.3706 , 0.3704 , 0.3687 , 0.3672 , 0.3665 ,\n",
       "            0.366  , 0.365  , 0.3635 , 0.363  , 0.3623 , 0.3613 , 0.3574 ,\n",
       "            0.3572 , 0.3555 , 0.3552 , 0.355  , 0.353  , 0.3525 , 0.3523 ,\n",
       "            0.3516 , 0.3503 , 0.3489 , 0.348  , 0.3467 , 0.3455 , 0.3452 ,\n",
       "            0.3445 , 0.3438 , 0.3435 , 0.3433 , 0.3408 , 0.34   , 0.3394 ,\n",
       "            0.3386 , 0.3381 , 0.3376 , 0.3374 , 0.3367 , 0.3357 , 0.3354 ,\n",
       "            0.3337 , 0.333  , 0.3328 , 0.3315 , 0.3313 , 0.3306 , 0.3298 ,\n",
       "            0.329  , 0.3281 , 0.327  , 0.3267 , 0.322  , 0.3215 , 0.321  ,\n",
       "            0.3208 , 0.32   , 0.3164 , 0.3157 , 0.3127 , 0.3123 , 0.3103 ,\n",
       "            0.3096 , 0.3088 , 0.3066 , 0.306  , 0.3047 , 0.304  , 0.2974 ,\n",
       "            0.2942 , 0.294  , 0.2908 , 0.2898 , 0.2886 , 0.288  , 0.2874 ,\n",
       "            0.2827 , 0.2825 , 0.2754 , 0.2732 , 0.2727 , 0.267  , 0.2646 ,\n",
       "            0.2612 , 0.2605 , 0.2585 , 0.2573 , 0.255  , 0.2542 , 0.2524 ,\n",
       "            0.2498 , 0.2463 , 0.246  , 0.2455 , 0.2448 , 0.2441 , 0.2428 ,\n",
       "            0.2407 , 0.2405 , 0.2375 , 0.2351 , 0.2343 , 0.2332 , 0.2327 ,\n",
       "            0.2319 , 0.2281 , 0.228  , 0.2269 , 0.2268 , 0.2264 , 0.226  ,\n",
       "            0.2256 , 0.2252 , 0.2251 , 0.2211 , 0.22   , 0.2184 , 0.2172 ,\n",
       "            0.2162 , 0.2158 , 0.2129 , 0.2119 , 0.211  , 0.2098 , 0.2096 ,\n",
       "            0.2091 , 0.2073 , 0.207  , 0.2042 , 0.2035 , 0.2026 , 0.2006 ,\n",
       "            0.2001 , 0.1995 , 0.1991 , 0.199  , 0.1971 , 0.1964 , 0.1956 ,\n",
       "            0.1947 , 0.1946 , 0.1935 , 0.1931 , 0.1912 , 0.1906 , 0.1896 ,\n",
       "            0.1885 , 0.1879 , 0.1859 , 0.185  , 0.1846 , 0.1836 , 0.1826 ,\n",
       "            0.182  , 0.1814 , 0.1807 , 0.1799 , 0.1792 , 0.1779 , 0.1759 ,\n",
       "            0.1752 , 0.1743 , 0.1725 , 0.1718 , 0.1707 , 0.1688 , 0.1685 ,\n",
       "            0.1678 , 0.1677 , 0.1676 , 0.1674 , 0.1671 , 0.1661 , 0.1649 ,\n",
       "            0.1641 , 0.1635 , 0.1609 , 0.1604 , 0.1589 , 0.1587 , 0.1582 ,\n",
       "            0.1575 , 0.1567 , 0.1561 , 0.1556 , 0.1548 , 0.1492 , 0.1462 ,\n",
       "            0.1459 , 0.1415 , 0.1377 , 0.1371 , 0.1337 , 0.1329 , 0.1318 ,\n",
       "            0.1306 , 0.1304 , 0.127  , 0.12317, 0.12274, 0.1225 , 0.0995 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22033899, 0.22033899, 0.22033899, 0.22881356,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.34745762, 0.34745762, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.3644068 , 0.3644068 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.3983051 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.43220338, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 ,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.60169494, 0.60169494, 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.65254235, 0.66101694, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.6864407 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7288136 , 0.7372881 , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7881356 , 0.7966102 ,\n",
       "            0.7966102 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.83898306, 0.84745765, 0.84745765, 0.84745765, 0.84745765,\n",
       "            0.84745765, 0.8559322 , 0.8559322 , 0.86440676, 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.8898305 , 0.8898305 ,\n",
       "            0.8898305 , 0.8898305 , 0.89830506, 0.89830506, 0.89830506,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.9322034 , 0.9322034 ,\n",
       "            0.94067794, 0.94067794, 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9915254 , 0.9915254 , 0.9915254 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.09848485, 0.09848485,\n",
       "            0.10606061, 0.11363637, 0.12121212, 0.12878788, 0.14393939,\n",
       "            0.15151516, 0.16666667, 0.17424242, 0.18939394, 0.1969697 ,\n",
       "            0.21212122, 0.21212122, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28787878, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.3030303 , 0.3030303 , 0.31060606, 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.3409091 , 0.3409091 ,\n",
       "            0.34848484, 0.34848484, 0.34848484, 0.3560606 , 0.3560606 ,\n",
       "            0.36363637, 0.36363637, 0.36363637, 0.36363637, 0.36363637,\n",
       "            0.36363637, 0.37121212, 0.37121212, 0.37121212, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.41666666, 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.43939394, 0.43939394,\n",
       "            0.43939394, 0.4469697 , 0.4469697 , 0.45454547, 0.45454547,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.46969697, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.49242425, 0.49242425,\n",
       "            0.49242425, 0.5       , 0.5       , 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.50757575, 0.5151515 , 0.5151515 , 0.52272725,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.54545456, 0.54545456,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.57575756, 0.57575756, 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.5984849 , 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6136364 , 0.6136364 , 0.6212121 ,\n",
       "            0.6212121 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.6515151 , 0.6515151 ,\n",
       "            0.6515151 , 0.6515151 , 0.65909094, 0.65909094, 0.6666667 ,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.67424244, 0.67424244,\n",
       "            0.6818182 , 0.6818182 , 0.6818182 , 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.70454544, 0.70454544, 0.7121212 ,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75      , 0.75757575, 0.75757575, 0.7651515 ,\n",
       "            0.7651515 , 0.7651515 , 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.79545456, 0.81060606, 0.8181818 ,\n",
       "            0.8181818 , 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8636364 ,\n",
       "            0.8712121 , 0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3887 , 0.387  , 0.3843 , 0.3816 , 0.3809 , 0.379  ,\n",
       "            0.3767 , 0.3762 , 0.373  , 0.3716 , 0.3704 , 0.3684 , 0.3652 ,\n",
       "            0.365  , 0.3596 , 0.3574 , 0.357  , 0.3555 , 0.3552 , 0.3516 ,\n",
       "            0.3506 , 0.3494 , 0.3489 , 0.3481 , 0.3442 , 0.3433 , 0.3425 ,\n",
       "            0.3418 , 0.3403 , 0.34   , 0.339  , 0.3389 , 0.3386 , 0.3384 ,\n",
       "            0.337  , 0.3354 , 0.3347 , 0.3335 , 0.3308 , 0.3303 , 0.3296 ,\n",
       "            0.3284 , 0.3281 , 0.3276 , 0.3262 , 0.3252 , 0.3247 , 0.3245 ,\n",
       "            0.3232 , 0.3218 , 0.32   , 0.3196 , 0.319  , 0.3184 , 0.317  ,\n",
       "            0.3164 , 0.3154 , 0.315  , 0.3147 , 0.3137 , 0.3135 , 0.3127 ,\n",
       "            0.3125 , 0.3115 , 0.31   , 0.3093 , 0.3088 , 0.3086 , 0.3064 ,\n",
       "            0.304  , 0.303  , 0.3025 , 0.3022 , 0.3008 , 0.298  , 0.2976 ,\n",
       "            0.2969 , 0.2947 , 0.2932 , 0.292  , 0.2903 , 0.29   , 0.289  ,\n",
       "            0.2874 , 0.281  , 0.28   , 0.2798 , 0.279  , 0.2788 , 0.2776 ,\n",
       "            0.2727 , 0.27   , 0.2664 , 0.264  , 0.2634 , 0.263  , 0.2617 ,\n",
       "            0.2612 , 0.2595 , 0.2585 , 0.2573 , 0.2546 , 0.2544 , 0.2478 ,\n",
       "            0.2463 , 0.2386 , 0.2372 , 0.2334 , 0.2283 , 0.2256 , 0.2213 ,\n",
       "            0.2207 , 0.2177 , 0.2172 , 0.2167 , 0.2161 , 0.2142 , 0.2137 ,\n",
       "            0.2118 , 0.2084 , 0.2076 , 0.2065 , 0.2054 , 0.2028 , 0.2024 ,\n",
       "            0.2001 , 0.1959 , 0.1948 , 0.1936 , 0.1934 , 0.1923 , 0.1887 ,\n",
       "            0.1884 , 0.1879 , 0.1874 , 0.1871 , 0.1863 , 0.1857 , 0.1852 ,\n",
       "            0.1831 , 0.1816 , 0.1812 , 0.1798 , 0.1772 , 0.1753 , 0.1737 ,\n",
       "            0.1718 , 0.1716 , 0.1709 , 0.1708 , 0.17   , 0.1697 , 0.1694 ,\n",
       "            0.1682 , 0.1671 , 0.1656 , 0.1636 , 0.1625 , 0.16   , 0.1593 ,\n",
       "            0.1592 , 0.1589 , 0.1587 , 0.1569 , 0.1566 , 0.1565 , 0.1564 ,\n",
       "            0.1545 , 0.1543 , 0.1528 , 0.1514 , 0.1508 , 0.1504 , 0.15   ,\n",
       "            0.1497 , 0.1481 , 0.147  , 0.1453 , 0.1451 , 0.1448 , 0.1437 ,\n",
       "            0.1425 , 0.141  , 0.1403 , 0.1399 , 0.1395 , 0.1394 , 0.1392 ,\n",
       "            0.1383 , 0.1355 , 0.135  , 0.1333 , 0.1332 , 0.1327 , 0.1318 ,\n",
       "            0.1317 , 0.1309 , 0.1299 , 0.129  , 0.1278 , 0.1277 , 0.1276 ,\n",
       "            0.126  , 0.119  , 0.1174 , 0.11554, 0.11127, 0.111  , 0.11084,\n",
       "            0.1093 , 0.10614, 0.10596, 0.1047 , 0.1032 , 0.10126, 0.09827,\n",
       "            0.0974 , 0.0775 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.1440678 , 0.15254237, 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22033899, 0.22033899, 0.22881356, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.3644068 , 0.3644068 , 0.3644068 , 0.3644068 , 0.37288135,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.41525424, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.5       , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.58474576, 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6694915 , 0.6694915 , 0.6779661 ,\n",
       "            0.6779661 , 0.6864407 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7288136 ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7457627 , 0.7542373 ,\n",
       "            0.7542373 , 0.7542373 , 0.7542373 , 0.7627119 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.8305085 , 0.84745765, 0.84745765, 0.84745765, 0.84745765,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.86440676, 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.8898305 , 0.8898305 ,\n",
       "            0.89830506, 0.89830506, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.09848485,\n",
       "            0.09848485, 0.09848485, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.1969697 ,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.28787878, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.31060606, 0.3181818 , 0.3181818 ,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.33333334, 0.3409091 ,\n",
       "            0.3409091 , 0.3409091 , 0.3409091 , 0.34848484, 0.34848484,\n",
       "            0.3560606 , 0.3560606 , 0.3560606 , 0.3560606 , 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.40151516, 0.40151516, 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.42424244, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.43939394, 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.45454547, 0.45454547, 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.4848485 ,\n",
       "            0.49242425, 0.49242425, 0.49242425, 0.49242425, 0.49242425,\n",
       "            0.49242425, 0.5       , 0.5       , 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.5378788 , 0.54545456, 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.57575756, 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.59090906,\n",
       "            0.59090906, 0.59090906, 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6212121 , 0.6212121 ,\n",
       "            0.6212121 , 0.6212121 , 0.6287879 , 0.6287879 , 0.6287879 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.6515151 ,\n",
       "            0.65909094, 0.65909094, 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.67424244, 0.67424244, 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.72727275, 0.74242425,\n",
       "            0.74242425, 0.74242425, 0.75      , 0.75757575, 0.75757575,\n",
       "            0.75757575, 0.7651515 , 0.7651515 , 0.7651515 , 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.84090906, 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.99242425, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.374  , 0.373  , 0.3682 , 0.3667 , 0.3652 , 0.3635 ,\n",
       "            0.3613 , 0.3591 , 0.3582 , 0.355  , 0.3542 , 0.3538 , 0.3506 ,\n",
       "            0.3489 , 0.3484 , 0.3396 , 0.3394 , 0.3376 , 0.337  , 0.333  ,\n",
       "            0.3325 , 0.3315 , 0.33   , 0.328  , 0.3276 , 0.3271 , 0.3267 ,\n",
       "            0.3257 , 0.325  , 0.3218 , 0.3186 , 0.3184 , 0.3174 , 0.3162 ,\n",
       "            0.3157 , 0.315  , 0.3147 , 0.314  , 0.3137 , 0.313  , 0.3115 ,\n",
       "            0.311  , 0.3098 , 0.309  , 0.3088 , 0.3064 , 0.3054 , 0.3044 ,\n",
       "            0.3032 , 0.3025 , 0.3018 , 0.3013 , 0.2998 , 0.299  , 0.2974 ,\n",
       "            0.297  , 0.2964 , 0.2961 , 0.2957 , 0.2954 , 0.2944 , 0.294  ,\n",
       "            0.2937 , 0.2927 , 0.29   , 0.289  , 0.2888 , 0.2866 , 0.2852 ,\n",
       "            0.2837 , 0.2834 , 0.2832 , 0.2827 , 0.2815 , 0.2803 , 0.2795 ,\n",
       "            0.2778 , 0.277  , 0.2761 , 0.2747 , 0.2734 , 0.2717 , 0.2708 ,\n",
       "            0.2703 , 0.2673 , 0.2637 , 0.263  , 0.2605 , 0.2588 , 0.254  ,\n",
       "            0.253  , 0.252  , 0.248  , 0.2474 , 0.2448 , 0.2441 , 0.2428 ,\n",
       "            0.2402 , 0.2394 , 0.2391 , 0.2378 , 0.2375 , 0.2374 , 0.2355 ,\n",
       "            0.2295 , 0.229  , 0.2233 , 0.218  , 0.2124 , 0.2119 , 0.2115 ,\n",
       "            0.2106 , 0.2045 , 0.2037 , 0.2032 , 0.2002 , 0.1971 , 0.1959 ,\n",
       "            0.1941 , 0.193  , 0.1924 , 0.1921 , 0.1901 , 0.188  , 0.1838 ,\n",
       "            0.1821 , 0.1815 , 0.1783 , 0.1776 , 0.1774 , 0.1772 , 0.1761 ,\n",
       "            0.1743 , 0.1738 , 0.1724 , 0.171  , 0.1694 , 0.1682 , 0.1647 ,\n",
       "            0.1643 , 0.164  , 0.1636 , 0.163  , 0.1627 , 0.1625 , 0.1617 ,\n",
       "            0.1604 , 0.1603 , 0.1598 , 0.1575 , 0.1572 , 0.157  , 0.1512 ,\n",
       "            0.1493 , 0.1483 , 0.1481 , 0.148  , 0.1477 , 0.1453 , 0.1447 ,\n",
       "            0.1445 , 0.144  , 0.1438 , 0.143  , 0.1415 , 0.1406 , 0.1392 ,\n",
       "            0.1387 , 0.138  , 0.1377 , 0.1373 , 0.1359 , 0.1357 , 0.1351 ,\n",
       "            0.134  , 0.1338 , 0.1327 , 0.1326 , 0.1313 , 0.1306 , 0.13   ,\n",
       "            0.1289 , 0.1285 , 0.1282 , 0.127  , 0.1262 , 0.1241 , 0.1239 ,\n",
       "            0.1238 , 0.12305, 0.1229 , 0.12146, 0.12103, 0.12024, 0.1194 ,\n",
       "            0.1186 , 0.1174 , 0.1172 , 0.11633, 0.11597, 0.11554, 0.115  ,\n",
       "            0.1144 , 0.1134 , 0.1093 , 0.10895, 0.10724, 0.10706, 0.1067 ,\n",
       "            0.103  , 0.1019 , 0.10156, 0.0979 , 0.09705, 0.0967 , 0.0959 ,\n",
       "            0.0935 , 0.0933 , 0.09235, 0.09106, 0.0909 , 0.0898 , 0.0895 ,\n",
       "            0.0715 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.09322034, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.16949153, 0.1779661 ,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22033899, 0.22033899, 0.22881356,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.2542373 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.29661018, 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.3644068 , 0.37288135, 0.37288135,\n",
       "            0.37288135, 0.38135594, 0.38135594, 0.3898305 , 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.58474576, 0.58474576, 0.58474576,\n",
       "            0.58474576, 0.59322035, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6779661 , 0.6864407 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7033898 , 0.7118644 , 0.720339  , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 ,\n",
       "            0.7542373 , 0.7542373 , 0.7542373 , 0.7542373 , 0.7542373 ,\n",
       "            0.7627119 , 0.779661  , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8220339 , 0.8220339 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.84745765,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.9322034 , 0.94067794, 0.94067794, 0.94067794, 0.9491525 ,\n",
       "            0.9491525 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9661017 ,\n",
       "            0.9661017 , 0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01515152, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09090909, 0.09848485, 0.09848485,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.1590909 , 0.1590909 , 0.16666667,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.22727273, 0.22727273, 0.23484848, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25      , 0.25757575, 0.25757575, 0.27272728,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.29545453,\n",
       "            0.29545453, 0.29545453, 0.3030303 , 0.3030303 , 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.3181818 , 0.3181818 , 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.33333334, 0.33333334, 0.34848484, 0.3560606 , 0.3560606 ,\n",
       "            0.36363637, 0.36363637, 0.36363637, 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.37878788, 0.38636363, 0.3939394 , 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.4090909 , 0.4090909 , 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.42424244, 0.42424244, 0.42424244,\n",
       "            0.4318182 , 0.4318182 , 0.4318182 , 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.4469697 , 0.45454547, 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.4848485 , 0.49242425, 0.49242425, 0.49242425,\n",
       "            0.49242425, 0.5       , 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.5681818 , 0.5681818 , 0.57575756, 0.57575756, 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6212121 , 0.6212121 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.6666667 , 0.6666667 , 0.6666667 ,\n",
       "            0.6666667 , 0.6666667 , 0.6666667 , 0.6666667 , 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75      , 0.75      , 0.75757575,\n",
       "            0.75757575, 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8712121 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3606 , 0.3535 , 0.3528 , 0.3525 , 0.348  , 0.3455 ,\n",
       "            0.3423 , 0.3413 , 0.3408 , 0.3396 , 0.3362 , 0.3342 , 0.333  ,\n",
       "            0.3328 , 0.3257 , 0.3242 , 0.3206 , 0.32   , 0.3184 , 0.3176 ,\n",
       "            0.3137 , 0.3127 , 0.3118 , 0.3108 , 0.31   , 0.3096 , 0.3083 ,\n",
       "            0.3071 , 0.3057 , 0.304  , 0.3037 , 0.3035 , 0.3018 , 0.2988 ,\n",
       "            0.2986 , 0.298  , 0.2974 , 0.2969 , 0.2966 , 0.2964 , 0.2961 ,\n",
       "            0.2954 , 0.294  , 0.2937 , 0.2927 , 0.2922 , 0.292  , 0.2917 ,\n",
       "            0.2915 , 0.2903 , 0.2898 , 0.2893 , 0.289  , 0.2886 , 0.288  ,\n",
       "            0.2864 , 0.285  , 0.2847 , 0.2837 , 0.283  , 0.2825 , 0.2822 ,\n",
       "            0.2805 , 0.2803 , 0.2798 , 0.2778 , 0.2773 , 0.2761 , 0.274  ,\n",
       "            0.2737 , 0.272  , 0.2717 , 0.2705 , 0.2703 , 0.2693 , 0.2686 ,\n",
       "            0.268  , 0.2676 , 0.267  , 0.2668 , 0.2664 , 0.266  , 0.2654 ,\n",
       "            0.2637 , 0.2634 , 0.2632 , 0.2627 , 0.2605 , 0.2595 , 0.2576 ,\n",
       "            0.256  , 0.2556 , 0.2537 , 0.252  , 0.2517 , 0.2456 , 0.2451 ,\n",
       "            0.2375 , 0.236  , 0.2352 , 0.2325 , 0.2313 , 0.2311 , 0.2307 ,\n",
       "            0.2301 , 0.2292 , 0.2273 , 0.2257 , 0.2256 , 0.2246 , 0.2244 ,\n",
       "            0.2216 , 0.22   , 0.2118 , 0.2079 , 0.2069 , 0.2048 , 0.2026 ,\n",
       "            0.1998 , 0.1976 , 0.196  , 0.1959 , 0.1943 , 0.1931 , 0.193  ,\n",
       "            0.1919 , 0.19   , 0.1879 , 0.1823 , 0.18   , 0.1783 , 0.178  ,\n",
       "            0.1764 , 0.1757 , 0.1731 , 0.171  , 0.1704 , 0.1696 , 0.1686 ,\n",
       "            0.1674 , 0.1653 , 0.1652 , 0.163  , 0.1617 , 0.1616 , 0.1615 ,\n",
       "            0.1608 , 0.1605 , 0.1604 , 0.1599 , 0.1548 , 0.1547 , 0.1542 ,\n",
       "            0.1536 , 0.1532 , 0.1517 , 0.1514 , 0.1503 , 0.1499 , 0.1481 ,\n",
       "            0.1477 , 0.1473 , 0.1456 , 0.1448 , 0.1447 , 0.1444 , 0.1428 ,\n",
       "            0.1409 , 0.1406 , 0.1395 , 0.1392 , 0.1385 , 0.1372 , 0.1371 ,\n",
       "            0.1367 , 0.1366 , 0.136  , 0.1359 , 0.1348 , 0.1335 , 0.1332 ,\n",
       "            0.1324 , 0.131  , 0.1306 , 0.1302 , 0.1294 , 0.1292 , 0.1289 ,\n",
       "            0.1288 , 0.1277 , 0.127  , 0.1257 , 0.1252 , 0.1251 , 0.12445,\n",
       "            0.12335, 0.12274, 0.1219 , 0.12146, 0.12103, 0.12054, 0.1193 ,\n",
       "            0.1192 , 0.1184 , 0.118  , 0.1166 , 0.11615, 0.11554, 0.11316,\n",
       "            0.113  , 0.1126 , 0.1122 , 0.11127, 0.1105 , 0.1099 , 0.1097 ,\n",
       "            0.10876, 0.1069 , 0.1058 , 0.1036 , 0.1034 , 0.1023 , 0.10126,\n",
       "            0.1009 , 0.0993 , 0.09894, 0.09827, 0.09705, 0.09686, 0.09656,\n",
       "            0.09534, 0.09485, 0.08527, 0.08466, 0.0772 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.09322034, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33050847, 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.34745762, 0.34745762, 0.3559322 ,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.3898305 , 0.3983051 , 0.3983051 ,\n",
       "            0.3983051 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44067797, 0.44915253, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.5762712 , 0.58474576,\n",
       "            0.58474576, 0.58474576, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.66101694, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6779661 , 0.6864407 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 , 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.69491524, 0.7033898 , 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7288136 , 0.7372881 ,\n",
       "            0.7372881 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8220339 , 0.8220339 , 0.8305085 , 0.83898306, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.9322034 , 0.9322034 , 0.9322034 , 0.94067794,\n",
       "            0.94067794, 0.94067794, 0.94067794, 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.09848485,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.12121212, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.18939394,\n",
       "            0.1969697 , 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.22727273, 0.24242425, 0.25      , 0.25      ,\n",
       "            0.25757575, 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.29545453, 0.3030303 ,\n",
       "            0.3030303 , 0.3030303 , 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.33333334, 0.33333334, 0.3409091 ,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.3560606 , 0.36363637,\n",
       "            0.36363637, 0.36363637, 0.36363637, 0.36363637, 0.36363637,\n",
       "            0.37121212, 0.37121212, 0.37878788, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.4090909 , 0.41666666, 0.42424244, 0.42424244,\n",
       "            0.42424244, 0.42424244, 0.42424244, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.45454547, 0.45454547, 0.45454547, 0.46212122, 0.46212122,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.50757575, 0.50757575, 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.5681818 , 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.6060606 , 0.6060606 , 0.6060606 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.6666667 , 0.6666667 , 0.6666667 , 0.6666667 ,\n",
       "            0.6666667 , 0.6666667 , 0.6666667 , 0.67424244, 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.68939394, 0.68939394, 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.719697  , 0.719697  , 0.72727275,\n",
       "            0.72727275, 0.72727275, 0.7348485 , 0.7348485 , 0.7348485 ,\n",
       "            0.74242425, 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.7651515 , 0.7651515 , 0.77272725, 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.84090906, 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.92424244, 0.92424244,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.9318182 ,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3533 , 0.3513 , 0.3442 , 0.3433 , 0.343  , 0.3396 ,\n",
       "            0.337  , 0.334  , 0.3328 , 0.3325 , 0.331  , 0.3276 , 0.3247 ,\n",
       "            0.3223 , 0.321  , 0.32   , 0.313  , 0.312  , 0.3115 , 0.31   ,\n",
       "            0.3098 , 0.3057 , 0.3047 , 0.3044 , 0.3025 , 0.3018 , 0.3005 ,\n",
       "            0.2988 , 0.2986 , 0.297  , 0.2966 , 0.2957 , 0.2954 , 0.294  ,\n",
       "            0.291  , 0.2908 , 0.2888 , 0.2886 , 0.288  , 0.2874 , 0.286  ,\n",
       "            0.2856 , 0.2854 , 0.2847 , 0.2844 , 0.2837 , 0.2832 , 0.2825 ,\n",
       "            0.282  , 0.2812 , 0.2805 , 0.2798 , 0.2795 , 0.279  , 0.2756 ,\n",
       "            0.275  , 0.2747 , 0.2712 , 0.2708 , 0.2703 , 0.27   , 0.2693 ,\n",
       "            0.2686 , 0.2654 , 0.2646 , 0.2644 , 0.2642 , 0.264  , 0.2637 ,\n",
       "            0.2634 , 0.2632 , 0.2627 , 0.2615 , 0.2612 , 0.2605 , 0.2595 ,\n",
       "            0.2568 , 0.2563 , 0.2559 , 0.2556 , 0.2534 , 0.2527 , 0.2524 ,\n",
       "            0.251  , 0.2507 , 0.2477 , 0.2467 , 0.2451 , 0.2429 , 0.239  ,\n",
       "            0.235  , 0.2314 , 0.2307 , 0.2303 , 0.2299 , 0.2297 , 0.2261 ,\n",
       "            0.2255 , 0.2246 , 0.2224 , 0.2213 , 0.2207 , 0.2202 , 0.2181 ,\n",
       "            0.2152 , 0.2147 , 0.2084 , 0.2079 , 0.2074 , 0.2068 , 0.2051 ,\n",
       "            0.2043 , 0.2017 , 0.2006 , 0.197  , 0.1965 , 0.1953 , 0.1947 ,\n",
       "            0.1942 , 0.1929 , 0.1924 , 0.1903 , 0.1887 , 0.1859 , 0.1844 ,\n",
       "            0.1823 , 0.1804 , 0.1771 , 0.177  , 0.1758 , 0.1752 , 0.1736 ,\n",
       "            0.1724 , 0.17   , 0.1694 , 0.1693 , 0.1688 , 0.1685 , 0.167  ,\n",
       "            0.1638 , 0.1626 , 0.1619 , 0.1616 , 0.161  , 0.1602 , 0.1581 ,\n",
       "            0.1577 , 0.1564 , 0.156  , 0.1555 , 0.1554 , 0.155  , 0.1547 ,\n",
       "            0.1534 , 0.1533 , 0.1528 , 0.1525 , 0.1523 , 0.1517 , 0.1511 ,\n",
       "            0.1505 , 0.1504 , 0.1501 , 0.1498 , 0.1497 , 0.1495 , 0.1492 ,\n",
       "            0.1489 , 0.1472 , 0.1464 , 0.1462 , 0.1444 , 0.1442 , 0.1437 ,\n",
       "            0.1434 , 0.1422 , 0.1421 , 0.1406 , 0.1403 , 0.1377 , 0.1373 ,\n",
       "            0.1371 , 0.1345 , 0.1344 , 0.1338 , 0.1334 , 0.1322 , 0.1312 ,\n",
       "            0.131  , 0.1301 , 0.13   , 0.1295 , 0.129  , 0.1279 , 0.126  ,\n",
       "            0.1245 , 0.1243 , 0.1242 , 0.1238 , 0.12335, 0.1219 , 0.1213 ,\n",
       "            0.12054, 0.12024, 0.1201 , 0.1193 , 0.1192 , 0.1186 , 0.1184 ,\n",
       "            0.11816, 0.118  , 0.11597, 0.11536, 0.115  , 0.11475, 0.11456,\n",
       "            0.113  , 0.1128 , 0.1126 , 0.111  , 0.11066, 0.1103 , 0.1082 ,\n",
       "            0.1041 , 0.10175, 0.1005 , 0.0927 , 0.0888 , 0.0887 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.09322034, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.1779661 , 0.18644068, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.21186441, 0.21186441, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2457627 , 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.3644068 , 0.37288135, 0.38135594, 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.3898305 , 0.3898305 , 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.40677965, 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5423729 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.55932206, 0.55932206, 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.6101695 , 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7033898 , 0.7118644 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7542373 , 0.7542373 , 0.7542373 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.8898305 , 0.89830506, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.11363637, 0.12121212, 0.12878788, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.22727273, 0.24242425, 0.25      , 0.25      ,\n",
       "            0.25757575, 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.28787878, 0.29545453, 0.29545453, 0.29545453,\n",
       "            0.3030303 , 0.3030303 , 0.31060606, 0.3181818 , 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.33333334, 0.3409091 , 0.3409091 ,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.3560606 , 0.3560606 ,\n",
       "            0.36363637, 0.36363637, 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.4090909 ,\n",
       "            0.4090909 , 0.4090909 , 0.41666666, 0.42424244, 0.42424244,\n",
       "            0.42424244, 0.42424244, 0.4318182 , 0.4318182 , 0.43939394,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.43939394, 0.4469697 ,\n",
       "            0.4469697 , 0.4469697 , 0.45454547, 0.45454547, 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.46969697, 0.46969697, 0.47727272,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.5       ,\n",
       "            0.50757575, 0.50757575, 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.6666667 , 0.67424244, 0.67424244,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.68939394, 0.6969697 ,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.77272725, 0.77272725, 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.81060606, 0.8181818 , 0.8181818 ,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8636364 , 0.8636364 ,\n",
       "            0.8712121 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3508 , 0.3474 , 0.3425 , 0.3386 , 0.3362 , 0.336  ,\n",
       "            0.3352 , 0.333  , 0.3325 , 0.3323 , 0.3276 , 0.324  , 0.3237 ,\n",
       "            0.3228 , 0.315  , 0.3123 , 0.312  , 0.3113 , 0.311  , 0.3096 ,\n",
       "            0.3074 , 0.3064 , 0.3054 , 0.3032 , 0.3027 , 0.3018 , 0.3015 ,\n",
       "            0.3    , 0.2986 , 0.298  , 0.2974 , 0.297  , 0.2957 , 0.2952 ,\n",
       "            0.293  , 0.291  , 0.2908 , 0.2905 , 0.29   , 0.2898 , 0.289  ,\n",
       "            0.2878 , 0.2876 , 0.2869 , 0.2864 , 0.286  , 0.2856 , 0.285  ,\n",
       "            0.2847 , 0.2842 , 0.2837 , 0.282  , 0.2815 , 0.281  , 0.2786 ,\n",
       "            0.278  , 0.2766 , 0.2747 , 0.2742 , 0.2737 , 0.2732 , 0.2727 ,\n",
       "            0.272  , 0.2717 , 0.269  , 0.2683 , 0.268  , 0.267  , 0.2664 ,\n",
       "            0.266  , 0.2659 , 0.265  , 0.2646 , 0.264  , 0.2632 , 0.2627 ,\n",
       "            0.261  , 0.2607 , 0.2595 , 0.2585 , 0.2568 , 0.2556 , 0.2542 ,\n",
       "            0.2522 , 0.252  , 0.2515 , 0.2512 , 0.251  , 0.2502 , 0.2483 ,\n",
       "            0.2458 , 0.2444 , 0.243  , 0.2411 , 0.2366 , 0.2356 , 0.2355 ,\n",
       "            0.2347 , 0.2322 , 0.2316 , 0.231  , 0.2294 , 0.2289 , 0.2286 ,\n",
       "            0.2249 , 0.2239 , 0.2222 , 0.2213 , 0.2207 , 0.2184 , 0.2168 ,\n",
       "            0.2166 , 0.2148 , 0.2123 , 0.212  , 0.2114 , 0.2108 , 0.2095 ,\n",
       "            0.2086 , 0.208  , 0.205  , 0.2032 , 0.2023 , 0.2007 , 0.2004 ,\n",
       "            0.199  , 0.1971 , 0.197  , 0.1959 , 0.1942 , 0.1929 , 0.1917 ,\n",
       "            0.1913 , 0.1904 , 0.19   , 0.1885 , 0.188  , 0.1864 , 0.1859 ,\n",
       "            0.1855 , 0.1852 , 0.1831 , 0.1819 , 0.1798 , 0.1797 , 0.1792 ,\n",
       "            0.179  , 0.1785 , 0.1776 , 0.1774 , 0.177  , 0.1766 , 0.1765 ,\n",
       "            0.1755 , 0.1746 , 0.1744 , 0.1743 , 0.1741 , 0.1735 , 0.1725 ,\n",
       "            0.1724 , 0.1711 , 0.1707 , 0.1704 , 0.1703 , 0.17   , 0.1692 ,\n",
       "            0.1688 , 0.1687 , 0.1682 , 0.1654 , 0.1648 , 0.1636 , 0.1631 ,\n",
       "            0.1626 , 0.162  , 0.1619 , 0.1616 , 0.1608 , 0.1599 , 0.1598 ,\n",
       "            0.1588 , 0.1581 , 0.1555 , 0.155  , 0.1549 , 0.1521 , 0.1517 ,\n",
       "            0.1514 , 0.1501 , 0.15   , 0.1494 , 0.1492 , 0.1475 , 0.1458 ,\n",
       "            0.1456 , 0.1447 , 0.1445 , 0.1425 , 0.1415 , 0.1412 , 0.141  ,\n",
       "            0.1405 , 0.1394 , 0.139  , 0.1388 , 0.1385 , 0.138  , 0.1375 ,\n",
       "            0.1372 , 0.137  , 0.1359 , 0.1351 , 0.134  , 0.133  , 0.1329 ,\n",
       "            0.1328 , 0.1322 , 0.1283 , 0.1257 , 0.1255 , 0.1238 , 0.12366,\n",
       "            0.1223 , 0.1195 , 0.119  , 0.11456, 0.1045 , 0.10376],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.15254237, 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.19491525, 0.19491525, 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.19491525, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.38135594, 0.38135594, 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.3898305 , 0.3898305 , 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.40677965, 0.40677965, 0.40677965,\n",
       "            0.40677965, 0.40677965, 0.40677965, 0.41525424, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.42372882, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.58474576, 0.58474576,\n",
       "            0.59322035, 0.59322035, 0.60169494, 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.61864406, 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.63559324, 0.6440678 , 0.6440678 , 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.7288136 , 0.7372881 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12878788, 0.13636364, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.21212122, 0.21969697, 0.21969697, 0.21969697, 0.22727273,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.25757575, 0.25757575, 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.3030303 ,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.3560606 , 0.3560606 , 0.3560606 , 0.3560606 ,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.4090909 , 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.43939394, 0.4469697 ,\n",
       "            0.4469697 , 0.4469697 , 0.4469697 , 0.45454547, 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.45454547, 0.46212122, 0.47727272,\n",
       "            0.47727272, 0.4848485 , 0.4848485 , 0.4848485 , 0.4848485 ,\n",
       "            0.4848485 , 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.54545456, 0.5530303 , 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.68939394, 0.68939394, 0.6969697 ,\n",
       "            0.70454544, 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.7878788 , 0.79545456, 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8484849 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.9318182 , 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.35   , 0.3455 , 0.343  , 0.339  , 0.3364 , 0.335  ,\n",
       "            0.3335 , 0.3333 , 0.3318 , 0.33   , 0.3289 , 0.3257 , 0.3252 ,\n",
       "            0.3184 , 0.3174 , 0.3137 , 0.3118 , 0.309  , 0.3076 , 0.3057 ,\n",
       "            0.3052 , 0.304  , 0.3025 , 0.3013 , 0.3    , 0.2986 , 0.297  ,\n",
       "            0.2964 , 0.2961 , 0.2954 , 0.2944 , 0.294  , 0.2937 , 0.293  ,\n",
       "            0.2927 , 0.2922 , 0.2915 , 0.2913 , 0.291  , 0.2908 , 0.2898 ,\n",
       "            0.289  , 0.288  , 0.2874 , 0.2864 , 0.2856 , 0.2854 , 0.2837 ,\n",
       "            0.2825 , 0.282  , 0.2817 , 0.2815 , 0.2803 , 0.2776 , 0.2769 ,\n",
       "            0.2764 , 0.2761 , 0.2756 , 0.2751 , 0.2747 , 0.2732 , 0.2722 ,\n",
       "            0.272  , 0.2717 , 0.2712 , 0.27   , 0.2693 , 0.268  , 0.2673 ,\n",
       "            0.2668 , 0.2664 , 0.2659 , 0.2634 , 0.261  , 0.2588 , 0.2578 ,\n",
       "            0.2568 , 0.2563 , 0.2556 , 0.2546 , 0.254  , 0.2527 , 0.2505 ,\n",
       "            0.2473 , 0.247  , 0.2467 , 0.2456 , 0.2451 , 0.2433 , 0.2428 ,\n",
       "            0.2424 , 0.2415 , 0.2413 , 0.241  , 0.2405 , 0.2399 , 0.2391 ,\n",
       "            0.2386 , 0.2384 , 0.2378 , 0.2375 , 0.2362 , 0.2355 , 0.234  ,\n",
       "            0.2334 , 0.2325 , 0.231  , 0.2299 , 0.2278 , 0.2269 , 0.2263 ,\n",
       "            0.2255 , 0.2247 , 0.2233 , 0.2229 , 0.2222 , 0.2211 , 0.2191 ,\n",
       "            0.2167 , 0.2162 , 0.2144 , 0.2139 , 0.213  , 0.2128 , 0.2124 ,\n",
       "            0.2119 , 0.2114 , 0.2113 , 0.2109 , 0.2104 , 0.2096 , 0.2086 ,\n",
       "            0.2081 , 0.2076 , 0.2074 , 0.2073 , 0.2068 , 0.2064 , 0.206  ,\n",
       "            0.2054 , 0.2051 , 0.2034 , 0.2029 , 0.2021 , 0.2017 , 0.2006 ,\n",
       "            0.1998 , 0.1981 , 0.1979 , 0.1973 , 0.1964 , 0.1958 , 0.1954 ,\n",
       "            0.1953 , 0.1942 , 0.1937 , 0.1923 , 0.1917 , 0.1912 , 0.1906 ,\n",
       "            0.1903 , 0.1896 , 0.1893 , 0.1887 , 0.1884 , 0.1879 , 0.1874 ,\n",
       "            0.1873 , 0.1865 , 0.1863 , 0.1858 , 0.1846 , 0.1833 , 0.1831 ,\n",
       "            0.183  , 0.1827 , 0.182  , 0.1819 , 0.1807 , 0.18   , 0.1797 ,\n",
       "            0.1785 , 0.1783 , 0.1782 , 0.1757 , 0.1741 , 0.1738 , 0.1736 ,\n",
       "            0.1727 , 0.1726 , 0.1721 , 0.1707 , 0.167  , 0.1653 , 0.1635 ,\n",
       "            0.1631 , 0.1627 , 0.1626 , 0.1624 , 0.1611 , 0.16   , 0.1578 ,\n",
       "            0.1559 , 0.1549 , 0.1527 , 0.1526 , 0.1525 , 0.1523 , 0.1515 ,\n",
       "            0.1506 , 0.15   , 0.149  , 0.1473 , 0.1472 , 0.147  , 0.1467 ,\n",
       "            0.1465 , 0.1464 , 0.1448 , 0.1425 , 0.1396 , 0.1393 , 0.1377 ,\n",
       "            0.1355 , 0.1295 , 0.12177, 0.12036, 0.1186 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.18644068, 0.18644068, 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.20338982, 0.20338982,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.27966103, 0.29661018,\n",
       "            0.29661018, 0.29661018, 0.29661018, 0.29661018, 0.29661018,\n",
       "            0.30508474, 0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.33898306, 0.33898306, 0.33898306, 0.33898306,\n",
       "            0.33898306, 0.34745762, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.3644068 , 0.3644068 , 0.3644068 , 0.3644068 , 0.3644068 ,\n",
       "            0.3644068 , 0.37288135, 0.37288135, 0.38135594, 0.38135594,\n",
       "            0.38135594, 0.38135594, 0.3898305 , 0.3898305 , 0.3983051 ,\n",
       "            0.3983051 , 0.3983051 , 0.40677965, 0.40677965, 0.40677965,\n",
       "            0.40677965, 0.40677965, 0.41525424, 0.41525424, 0.41525424,\n",
       "            0.41525424, 0.41525424, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.21212122, 0.21969697, 0.21969697, 0.22727273,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25      ,\n",
       "            0.25757575, 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.29545453, 0.3030303 , 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.3181818 , 0.3181818 , 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.33333334, 0.3409091 , 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.3560606 , 0.3560606 , 0.3560606 ,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.42424244, 0.4318182 , 0.4318182 , 0.43939394,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46212122,\n",
       "            0.46212122, 0.46212122, 0.46969697, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.4848485 , 0.49242425, 0.5       , 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.54545456,\n",
       "            0.54545456, 0.54545456, 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.59090906, 0.5984849 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6818182 , 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.7348485 , 0.7348485 , 0.74242425, 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.7651515 , 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8712121 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.9166667 , 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.353 , 0.3477, 0.3474, 0.3438, 0.3408, 0.3406, 0.3384,\n",
       "            0.338 , 0.3342, 0.3323, 0.3303, 0.3289, 0.324 , 0.3196, 0.319 ,\n",
       "            0.3167, 0.3152, 0.315 , 0.3147, 0.3135, 0.3115, 0.3113, 0.31  ,\n",
       "            0.3088, 0.3079, 0.3062, 0.305 , 0.304 , 0.3025, 0.3013, 0.3008,\n",
       "            0.3005, 0.3003, 0.3   , 0.2998, 0.299 , 0.2983, 0.298 , 0.2974,\n",
       "            0.2969, 0.2961, 0.2952, 0.295 , 0.2935, 0.2927, 0.2925, 0.292 ,\n",
       "            0.2917, 0.2903, 0.2896, 0.289 , 0.2886, 0.2874, 0.2861, 0.2852,\n",
       "            0.2847, 0.2844, 0.2837, 0.282 , 0.2815, 0.281 , 0.28  , 0.2798,\n",
       "            0.2793, 0.2788, 0.2776, 0.277 , 0.2766, 0.2742, 0.2737, 0.2698,\n",
       "            0.269 , 0.268 , 0.267 , 0.2664, 0.2654, 0.2651, 0.264 , 0.2625,\n",
       "            0.2622, 0.262 , 0.2603, 0.2593, 0.259 , 0.2588, 0.2585, 0.2573,\n",
       "            0.2563, 0.2551, 0.253 , 0.2522, 0.2515, 0.2505, 0.2496, 0.2493,\n",
       "            0.2489, 0.2485, 0.2482, 0.2477, 0.2467, 0.2451, 0.2448, 0.2444,\n",
       "            0.2433, 0.243 , 0.2422, 0.2411, 0.2407, 0.2405, 0.2402, 0.2395,\n",
       "            0.2391, 0.239 , 0.2388, 0.2386, 0.2379, 0.2375, 0.2372, 0.2367,\n",
       "            0.2366, 0.236 , 0.235 , 0.2347, 0.2335, 0.2332, 0.2323, 0.2319,\n",
       "            0.2318, 0.2311, 0.2307, 0.2306, 0.2303, 0.2299, 0.2295, 0.2273,\n",
       "            0.2268, 0.226 , 0.2252, 0.2249, 0.2246, 0.2233, 0.223 , 0.2229,\n",
       "            0.2227, 0.2225, 0.222 , 0.2218, 0.2211, 0.2202, 0.22  , 0.2197,\n",
       "            0.2186, 0.2181, 0.2173, 0.217 , 0.2157, 0.2148, 0.2103, 0.2098,\n",
       "            0.2091, 0.2084, 0.2079, 0.207 , 0.2065, 0.2058, 0.2039, 0.2037,\n",
       "            0.2035, 0.2015, 0.2013, 0.2009, 0.2006, 0.1996, 0.1995, 0.1971,\n",
       "            0.197 , 0.1929, 0.1917, 0.1913, 0.191 , 0.1884, 0.1865, 0.186 ,\n",
       "            0.1855, 0.1853, 0.1846, 0.1844, 0.1835, 0.1804, 0.179 , 0.1788,\n",
       "            0.1776, 0.1765, 0.1764, 0.1753, 0.1746, 0.1735, 0.1718, 0.1716,\n",
       "            0.1683, 0.1671, 0.1665, 0.1656, 0.1646, 0.164 , 0.1632, 0.1626,\n",
       "            0.1611, 0.1604, 0.1597, 0.1594, 0.1587, 0.1584, 0.1583, 0.1562,\n",
       "            0.1531, 0.1523, 0.1511, 0.144 , 0.1384, 0.1364, 0.1152],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.15254237, 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.19491525,\n",
       "            0.19491525, 0.19491525, 0.19491525, 0.19491525, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.21186441, 0.21186441, 0.21186441,\n",
       "            0.21186441, 0.21186441, 0.21186441, 0.21186441, 0.22881356,\n",
       "            0.22881356, 0.22881356, 0.22881356, 0.22881356, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.2542373 , 0.2542373 , 0.2542373 , 0.2542373 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.2881356 , 0.29661018,\n",
       "            0.29661018, 0.29661018, 0.29661018, 0.29661018, 0.29661018,\n",
       "            0.30508474, 0.30508474, 0.30508474, 0.30508474, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.20454545, 0.21212122, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.3181818 ,\n",
       "            0.3181818 , 0.3181818 , 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.33333334, 0.33333334, 0.3409091 , 0.3560606 , 0.3560606 ,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.4318182 , 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.49242425, 0.5       ,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.530303  , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.57575756, 0.5833333 , 0.5833333 ,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6287879 , 0.6363636 , 0.6515151 , 0.6515151 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.68939394, 0.70454544, 0.7121212 , 0.719697  , 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.81060606, 0.8181818 ,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.358  , 0.3535 , 0.3518 , 0.3503 , 0.3481 , 0.348  ,\n",
       "            0.3457 , 0.3452 , 0.3418 , 0.34   , 0.3381 , 0.3335 , 0.3306 ,\n",
       "            0.3296 , 0.3284 , 0.3271 , 0.3242 , 0.324  , 0.3223 , 0.3203 ,\n",
       "            0.32   , 0.3196 , 0.3184 , 0.3171 , 0.3154 , 0.314  , 0.3137 ,\n",
       "            0.3132 , 0.312  , 0.3105 , 0.3103 , 0.3098 , 0.3096 , 0.3093 ,\n",
       "            0.3083 , 0.3079 , 0.3071 , 0.3066 , 0.3064 , 0.3052 , 0.305  ,\n",
       "            0.3032 , 0.3025 , 0.302  , 0.3018 , 0.3015 , 0.3003 , 0.2998 ,\n",
       "            0.2996 , 0.2993 , 0.2988 , 0.2974 , 0.2957 , 0.294  , 0.2937 ,\n",
       "            0.2922 , 0.2913 , 0.291  , 0.2908 , 0.2905 , 0.2903 , 0.29   ,\n",
       "            0.2898 , 0.2896 , 0.2893 , 0.289  , 0.2888 , 0.2886 , 0.287  ,\n",
       "            0.2869 , 0.2866 , 0.2856 , 0.2852 , 0.2847 , 0.2837 , 0.2822 ,\n",
       "            0.282  , 0.2817 , 0.281  , 0.2808 , 0.2805 , 0.28   , 0.2795 ,\n",
       "            0.279  , 0.2786 , 0.2783 , 0.2776 , 0.277  , 0.2766 , 0.2761 ,\n",
       "            0.276  , 0.2751 , 0.2747 , 0.2737 , 0.2734 , 0.2732 , 0.272  ,\n",
       "            0.2712 , 0.2708 , 0.2703 , 0.27   , 0.269  , 0.2688 , 0.2686 ,\n",
       "            0.268  , 0.2673 , 0.2659 , 0.265  , 0.2646 , 0.2642 , 0.264  ,\n",
       "            0.2637 , 0.2634 , 0.263  , 0.2627 , 0.262  , 0.261  , 0.2605 ,\n",
       "            0.2595 , 0.2593 , 0.2585 , 0.2583 , 0.258  , 0.2576 , 0.257  ,\n",
       "            0.2563 , 0.2556 , 0.2542 , 0.254  , 0.2534 , 0.253  , 0.2524 ,\n",
       "            0.2522 , 0.2483 , 0.2463 , 0.2456 , 0.2441 , 0.2437 , 0.2417 ,\n",
       "            0.2395 , 0.2394 , 0.2378 , 0.2374 , 0.2372 , 0.2368 , 0.2367 ,\n",
       "            0.2335 , 0.2322 , 0.2313 , 0.2295 , 0.2289 , 0.2286 , 0.2255 ,\n",
       "            0.2238 , 0.2218 , 0.2213 , 0.22   , 0.2197 , 0.2186 , 0.2184 ,\n",
       "            0.2173 , 0.2168 , 0.2163 , 0.2153 , 0.215  , 0.2144 , 0.2142 ,\n",
       "            0.2128 , 0.2089 , 0.208  , 0.2079 , 0.2076 , 0.2073 , 0.2056 ,\n",
       "            0.2042 , 0.2032 , 0.2015 , 0.201  , 0.2007 , 0.1996 , 0.1985 ,\n",
       "            0.1979 , 0.1973 , 0.195  , 0.1941 , 0.1937 , 0.1929 , 0.1925 ,\n",
       "            0.1901 , 0.1882 , 0.1865 , 0.1858 , 0.1853 , 0.1843 , 0.1836 ,\n",
       "            0.182  , 0.1805 , 0.1783 , 0.1781 , 0.1776 , 0.1775 , 0.1772 ,\n",
       "            0.1752 , 0.1746 , 0.1744 , 0.1726 , 0.1725 , 0.1716 , 0.1638 ,\n",
       "            0.163  , 0.1619 , 0.1587 , 0.1355 , 0.11127], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.18644068, 0.18644068, 0.19491525,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22033899, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.2457627 , 0.2457627 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.2881356 , 0.29661018,\n",
       "            0.29661018, 0.29661018, 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5508475 , 0.55932206, 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.69491524, 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7457627 , 0.7542373 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.15151516, 0.1590909 ,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.3030303 , 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3560606 , 0.37121212, 0.37878788,\n",
       "            0.37878788, 0.38636363, 0.4090909 , 0.42424244, 0.42424244,\n",
       "            0.4469697 , 0.45454547, 0.45454547, 0.46212122, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.5378788 , 0.5530303 , 0.5530303 , 0.56060606, 0.59090906,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6515151 , 0.6666667 , 0.67424244, 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.70454544, 0.719697  ,\n",
       "            0.719697  , 0.72727275, 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75      , 0.75757575, 0.7651515 , 0.7651515 ,\n",
       "            0.77272725, 0.77272725, 0.780303  , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.92424244, 0.92424244, 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3596, 0.3567, 0.353 , 0.3525, 0.3503, 0.3481, 0.3477,\n",
       "            0.3455, 0.345 , 0.3408, 0.338 , 0.3313, 0.331 , 0.3306, 0.3284,\n",
       "            0.3281, 0.328 , 0.3274, 0.3271, 0.3267, 0.326 , 0.325 , 0.3247,\n",
       "            0.3245, 0.3242, 0.324 , 0.323 , 0.322 , 0.3218, 0.3213, 0.3208,\n",
       "            0.3206, 0.32  , 0.3196, 0.3193, 0.319 , 0.3188, 0.3176, 0.3167,\n",
       "            0.3164, 0.3162, 0.3154, 0.3152, 0.3147, 0.3145, 0.3142, 0.3137,\n",
       "            0.3135, 0.3123, 0.312 , 0.3115, 0.311 , 0.3108, 0.3103, 0.31  ,\n",
       "            0.3096, 0.3093, 0.3079, 0.3074, 0.3071, 0.306 , 0.3047, 0.3042,\n",
       "            0.304 , 0.3032, 0.3027, 0.3018, 0.3013, 0.301 , 0.3008, 0.3   ,\n",
       "            0.299 , 0.2988, 0.2983, 0.298 , 0.2979, 0.2976, 0.2974, 0.2969,\n",
       "            0.2966, 0.2964, 0.2957, 0.2954, 0.2952, 0.295 , 0.2947, 0.2944,\n",
       "            0.2935, 0.2927, 0.292 , 0.2913, 0.2905, 0.2903, 0.289 , 0.2886,\n",
       "            0.288 , 0.2866, 0.286 , 0.2856, 0.2832, 0.2815, 0.2805, 0.2798,\n",
       "            0.2793, 0.2783, 0.2776, 0.2766, 0.2751, 0.275 , 0.2734, 0.2715,\n",
       "            0.2705, 0.2695, 0.268 , 0.2654, 0.265 , 0.2637, 0.2595, 0.2593,\n",
       "            0.258 , 0.2534, 0.2524, 0.252 , 0.2502, 0.2487, 0.248 , 0.247 ,\n",
       "            0.2462, 0.2452, 0.244 , 0.2433, 0.243 , 0.2418, 0.2405, 0.2397,\n",
       "            0.2374, 0.2362, 0.2339, 0.233 , 0.2328, 0.2318, 0.2314, 0.2313,\n",
       "            0.2311, 0.2303, 0.2295, 0.2289, 0.2273, 0.2269, 0.2268, 0.2249,\n",
       "            0.223 , 0.2229, 0.2217, 0.2216, 0.2212, 0.2202, 0.2194, 0.2185,\n",
       "            0.2181, 0.2172, 0.2166, 0.2152, 0.2147, 0.2134, 0.2123, 0.2115,\n",
       "            0.2094, 0.2089, 0.2076, 0.2069, 0.2065, 0.2058, 0.2053, 0.2031,\n",
       "            0.202 , 0.2006, 0.1998, 0.1968, 0.1959, 0.1954, 0.1953, 0.1929,\n",
       "            0.191 , 0.1906, 0.1904, 0.19  , 0.1896, 0.1882, 0.1877, 0.1852,\n",
       "            0.1848, 0.1813, 0.1794, 0.1768, 0.172 , 0.1528, 0.1257, 0.1063],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.1779661 , 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.18644068, 0.18644068, 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.20338982, 0.21186441,\n",
       "            0.22881356, 0.22881356, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.2881356 , 0.29661018,\n",
       "            0.29661018, 0.30508474, 0.30508474, 0.30508474, 0.31355932,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.34745762, 0.34745762, 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28787878, 0.29545453, 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.38636363,\n",
       "            0.3939394 , 0.4090909 , 0.41666666, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.49242425, 0.50757575, 0.5151515 , 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6212121 , 0.6212121 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6666667 ,\n",
       "            0.6818182 , 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.780303  , 0.780303  , 0.79545456,\n",
       "            0.8030303 , 0.8030303 , 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3887, 0.3882, 0.3877, 0.3867, 0.3862, 0.3835, 0.3833,\n",
       "            0.3816, 0.3804, 0.3801, 0.3782, 0.3772, 0.376 , 0.3755, 0.3728,\n",
       "            0.3726, 0.371 , 0.3708, 0.3691, 0.3687, 0.3652, 0.3645, 0.3633,\n",
       "            0.3625, 0.3616, 0.3613, 0.361 , 0.3599, 0.3584, 0.358 , 0.357 ,\n",
       "            0.3567, 0.3562, 0.3552, 0.355 , 0.3545, 0.3538, 0.3535, 0.3533,\n",
       "            0.353 , 0.3525, 0.3518, 0.3516, 0.3513, 0.351 , 0.3494, 0.3481,\n",
       "            0.3474, 0.346 , 0.3457, 0.3445, 0.3425, 0.3418, 0.3416, 0.3367,\n",
       "            0.3364, 0.3354, 0.3347, 0.333 , 0.3325, 0.331 , 0.3308, 0.3306,\n",
       "            0.3298, 0.329 , 0.3286, 0.328 , 0.3274, 0.3262, 0.326 , 0.3257,\n",
       "            0.3252, 0.3245, 0.3242, 0.3213, 0.321 , 0.3208, 0.3196, 0.3193,\n",
       "            0.3179, 0.3176, 0.3171, 0.3162, 0.316 , 0.3157, 0.3152, 0.3137,\n",
       "            0.3132, 0.313 , 0.3125, 0.3118, 0.3105, 0.3103, 0.3088, 0.3086,\n",
       "            0.3079, 0.3076, 0.3074, 0.3066, 0.3064, 0.306 , 0.3044, 0.3037,\n",
       "            0.3027, 0.3025, 0.3015, 0.3013, 0.301 , 0.3005, 0.3003, 0.3   ,\n",
       "            0.2986, 0.2976, 0.297 , 0.2952, 0.2944, 0.294 , 0.293 , 0.2927,\n",
       "            0.29  , 0.2866, 0.2861, 0.2854, 0.2852, 0.2842, 0.2832, 0.2815,\n",
       "            0.2798, 0.2795, 0.2788, 0.2776, 0.2766, 0.2761, 0.2754, 0.274 ,\n",
       "            0.2732, 0.2727, 0.2703, 0.2683, 0.2673, 0.2659, 0.2656, 0.265 ,\n",
       "            0.2646, 0.2617, 0.2612, 0.2603, 0.2598, 0.2563, 0.255 , 0.2542,\n",
       "            0.2512, 0.2487, 0.2482, 0.2463, 0.246 , 0.2448, 0.2406, 0.2402,\n",
       "            0.2399, 0.239 , 0.2383, 0.2382, 0.2367, 0.2363, 0.236 , 0.2346,\n",
       "            0.234 , 0.2335, 0.2328, 0.2327, 0.2323, 0.2316, 0.2313, 0.2311,\n",
       "            0.2299, 0.2286, 0.2277, 0.2272, 0.2269, 0.2257, 0.2255, 0.2246,\n",
       "            0.224 , 0.2235, 0.2212, 0.2207, 0.2205, 0.2191, 0.2185, 0.2175,\n",
       "            0.217 , 0.2147, 0.2142, 0.2135, 0.2119, 0.211 , 0.2096, 0.2091,\n",
       "            0.2054, 0.2051, 0.2048, 0.2045, 0.2043, 0.2032, 0.2028, 0.1998,\n",
       "            0.1974, 0.1968, 0.1964, 0.1953, 0.1952, 0.1947, 0.1923, 0.1711,\n",
       "            0.146 , 0.1192, 0.1052], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.22881356, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.2881356 , 0.2881356 ,\n",
       "            0.29661018, 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.33898306, 0.34745762, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.6440678 ,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.41666666, 0.42424244,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.5833333 , 0.59090906, 0.59090906, 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6363636 ,\n",
       "            0.6363636 , 0.6515151 , 0.65909094, 0.6666667 , 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.8333333 , 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4526 , 0.4458 , 0.4426 , 0.4414 , 0.4387 , 0.4385 ,\n",
       "            0.4375 , 0.4358 , 0.435  , 0.4326 , 0.428  , 0.4248 , 0.4243 ,\n",
       "            0.4238 , 0.421  , 0.419  , 0.4146 , 0.412  , 0.4106 , 0.4084 ,\n",
       "            0.4062 , 0.4053 , 0.405  , 0.4043 , 0.403  , 0.4023 , 0.4011 ,\n",
       "            0.399  , 0.3982 , 0.3975 , 0.3967 , 0.3962 , 0.3958 , 0.3955 ,\n",
       "            0.3945 , 0.3933 , 0.3894 , 0.3865 , 0.3862 , 0.3823 , 0.3804 ,\n",
       "            0.3777 , 0.3752 , 0.3733 , 0.3718 , 0.3691 , 0.3672 , 0.3667 ,\n",
       "            0.3662 , 0.366  , 0.3655 , 0.3645 , 0.3633 , 0.3613 , 0.3606 ,\n",
       "            0.36   , 0.3599 , 0.3584 , 0.358  , 0.3555 , 0.3525 , 0.3518 ,\n",
       "            0.3516 , 0.3477 , 0.345  , 0.3447 , 0.344  , 0.343  , 0.3418 ,\n",
       "            0.3408 , 0.34   , 0.3398 , 0.3396 , 0.3394 , 0.3384 , 0.3381 ,\n",
       "            0.3374 , 0.337  , 0.3354 , 0.335  , 0.3347 , 0.3335 , 0.333  ,\n",
       "            0.3328 , 0.3315 , 0.3298 , 0.329  , 0.3289 , 0.3284 , 0.3281 ,\n",
       "            0.328  , 0.3267 , 0.3264 , 0.3252 , 0.325  , 0.3245 , 0.324  ,\n",
       "            0.3225 , 0.322  , 0.3218 , 0.3215 , 0.3196 , 0.3193 , 0.3184 ,\n",
       "            0.318  , 0.3176 , 0.3164 , 0.3162 , 0.316  , 0.3154 , 0.3127 ,\n",
       "            0.3125 , 0.3115 , 0.311  , 0.3108 , 0.3105 , 0.3093 , 0.3088 ,\n",
       "            0.3086 , 0.3066 , 0.3052 , 0.305  , 0.3047 , 0.3042 , 0.303  ,\n",
       "            0.3027 , 0.3015 , 0.2969 , 0.2966 , 0.2964 , 0.2961 , 0.2947 ,\n",
       "            0.2932 , 0.2922 , 0.2917 , 0.291  , 0.2908 , 0.2905 , 0.2893 ,\n",
       "            0.288  , 0.2878 , 0.2874 , 0.2866 , 0.2854 , 0.2852 , 0.284  ,\n",
       "            0.2837 , 0.2832 , 0.2827 , 0.2812 , 0.281  , 0.2808 , 0.2788 ,\n",
       "            0.2786 , 0.277  , 0.275  , 0.2744 , 0.2737 , 0.273  , 0.2705 ,\n",
       "            0.2673 , 0.2668 , 0.2637 , 0.2634 , 0.2627 , 0.2617 , 0.2595 ,\n",
       "            0.2593 , 0.2585 , 0.2537 , 0.2527 , 0.2517 , 0.251  , 0.2507 ,\n",
       "            0.249  , 0.2487 , 0.2477 , 0.2456 , 0.2445 , 0.2434 , 0.2433 ,\n",
       "            0.2401 , 0.2395 , 0.2394 , 0.2379 , 0.2375 , 0.2372 , 0.2368 ,\n",
       "            0.2363 , 0.2344 , 0.2328 , 0.2316 , 0.2311 , 0.2306 , 0.2302 ,\n",
       "            0.2297 , 0.2295 , 0.2286 , 0.2272 , 0.2264 , 0.2261 , 0.2256 ,\n",
       "            0.224  , 0.223  , 0.2229 , 0.2222 , 0.2216 , 0.2207 , 0.2205 ,\n",
       "            0.2203 , 0.2202 , 0.2186 , 0.2163 , 0.2152 , 0.2109 , 0.2106 ,\n",
       "            0.2081 , 0.2079 , 0.2056 , 0.2006 , 0.1968 , 0.195  , 0.1917 ,\n",
       "            0.1886 , 0.1674 , 0.138  , 0.11145, 0.10156], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.01515152, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.15254237, 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.18644068, 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.2542373 , 0.2542373 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33898306, 0.34745762, 0.34745762, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.38135594, 0.3898305 ,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.4915254 , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6864407 , 0.69491524, 0.7118644 , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.530303  , 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.77272725, 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.8030303 , 0.81060606, 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8636364 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.9318182 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.521  , 0.5063 , 0.4988 , 0.4985 , 0.4973 , 0.4958 ,\n",
       "            0.4944 , 0.494  , 0.491  , 0.4866 , 0.4783 , 0.4778 , 0.4731 ,\n",
       "            0.472  , 0.4685 , 0.4678 , 0.4673 , 0.461  , 0.4565 , 0.4556 ,\n",
       "            0.4546 , 0.454  , 0.4536 , 0.452  , 0.4495 , 0.4475 , 0.446  ,\n",
       "            0.4453 , 0.4443 , 0.4414 , 0.4412 , 0.441  , 0.4382 , 0.437  ,\n",
       "            0.4363 , 0.4355 , 0.4353 , 0.4336 , 0.4229 , 0.421  , 0.4202 ,\n",
       "            0.42   , 0.4192 , 0.415  , 0.4043 , 0.4033 , 0.4026 , 0.402  ,\n",
       "            0.4001 , 0.3992 , 0.395  , 0.393  , 0.3882 , 0.3855 , 0.3853 ,\n",
       "            0.3762 , 0.375  , 0.3723 , 0.3718 , 0.3713 , 0.3704 , 0.3677 ,\n",
       "            0.3667 , 0.3665 , 0.3662 , 0.3657 , 0.364  , 0.3638 , 0.3635 ,\n",
       "            0.361  , 0.3574 , 0.3552 , 0.355  , 0.3506 , 0.3503 , 0.3496 ,\n",
       "            0.3494 , 0.3477 , 0.3464 , 0.346  , 0.3455 , 0.3452 , 0.345  ,\n",
       "            0.344  , 0.343  , 0.3418 , 0.3416 , 0.3403 , 0.3398 , 0.3389 ,\n",
       "            0.3384 , 0.3381 , 0.338  , 0.3374 , 0.3362 , 0.3357 , 0.3347 ,\n",
       "            0.3335 , 0.333  , 0.3315 , 0.3313 , 0.331  , 0.3306 , 0.3303 ,\n",
       "            0.3298 , 0.3296 , 0.3289 , 0.3286 , 0.3276 , 0.327  , 0.3252 ,\n",
       "            0.3245 , 0.3242 , 0.324  , 0.323  , 0.3218 , 0.3198 , 0.3193 ,\n",
       "            0.318  , 0.317  , 0.3162 , 0.3157 , 0.3154 , 0.3145 , 0.3135 ,\n",
       "            0.3132 , 0.3125 , 0.3105 , 0.31   , 0.3086 , 0.308  , 0.3076 ,\n",
       "            0.3047 , 0.3035 , 0.3032 , 0.303  , 0.3025 , 0.3015 , 0.3005 ,\n",
       "            0.2996 , 0.2993 , 0.2976 , 0.2974 , 0.2944 , 0.2935 , 0.2927 ,\n",
       "            0.2925 , 0.292  , 0.2917 , 0.2908 , 0.2903 , 0.2854 , 0.2852 ,\n",
       "            0.2844 , 0.2837 , 0.2832 , 0.2825 , 0.282  , 0.2815 , 0.2798 ,\n",
       "            0.2795 , 0.278  , 0.2766 , 0.2761 , 0.276  , 0.2751 , 0.2737 ,\n",
       "            0.2734 , 0.272  , 0.2712 , 0.2705 , 0.263  , 0.2605 , 0.2593 ,\n",
       "            0.258  , 0.257  , 0.256  , 0.2551 , 0.2537 , 0.252  , 0.2502 ,\n",
       "            0.248  , 0.2478 , 0.2477 , 0.2473 , 0.2471 , 0.2462 , 0.246  ,\n",
       "            0.2455 , 0.2451 , 0.2449 , 0.2444 , 0.2438 , 0.2428 , 0.2424 ,\n",
       "            0.2413 , 0.2395 , 0.2384 , 0.2382 , 0.2378 , 0.2367 , 0.2356 ,\n",
       "            0.2351 , 0.231  , 0.2307 , 0.2286 , 0.2283 , 0.2274 , 0.2256 ,\n",
       "            0.2235 , 0.2213 , 0.2189 , 0.2185 , 0.218  , 0.2158 , 0.2157 ,\n",
       "            0.2156 , 0.2081 , 0.1989 , 0.1984 , 0.19   , 0.1887 , 0.1879 ,\n",
       "            0.1857 , 0.1641 , 0.1306 , 0.1045 , 0.09827], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.15151516, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.11016949, 0.11016949, 0.11016949, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.12711865, 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.15254237, 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.16949153, 0.1779661 ,\n",
       "            0.1779661 , 0.18644068, 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.21186441, 0.21186441, 0.22033899, 0.22033899,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.2457627 , 0.2457627 ,\n",
       "            0.2542373 , 0.2542373 , 0.27966103, 0.2881356 , 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.34745762, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.38135594, 0.38135594, 0.3898305 ,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6864407 , 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.4318182 , 0.4318182 , 0.43939394,\n",
       "            0.43939394, 0.4469697 , 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.75      ,\n",
       "            0.75757575, 0.77272725, 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.582 , 0.5605, 0.552 , 0.5483, 0.548 , 0.5474, 0.546 ,\n",
       "            0.544 , 0.533 , 0.5264, 0.524 , 0.517 , 0.5166, 0.5156, 0.511 ,\n",
       "            0.505 , 0.503 , 0.502 , 0.4956, 0.4946, 0.4937, 0.4934, 0.4866,\n",
       "            0.4841, 0.483 , 0.4827, 0.4824, 0.48  , 0.4778, 0.4756, 0.4744,\n",
       "            0.4736, 0.4727, 0.4705, 0.4602, 0.4578, 0.4565, 0.4514, 0.4512,\n",
       "            0.4468, 0.4346, 0.4326, 0.4324, 0.4316, 0.4297, 0.4243, 0.418 ,\n",
       "            0.416 , 0.4146, 0.4136, 0.403 , 0.3992, 0.3914, 0.3877, 0.3872,\n",
       "            0.3857, 0.383 , 0.382 , 0.3818, 0.379 , 0.3784, 0.3767, 0.3765,\n",
       "            0.3752, 0.3718, 0.37  , 0.3699, 0.3687, 0.3677, 0.3667, 0.3628,\n",
       "            0.3623, 0.3606, 0.3594, 0.3591, 0.359 , 0.3584, 0.3577, 0.3572,\n",
       "            0.3564, 0.3547, 0.3538, 0.3533, 0.3528, 0.3523, 0.3499, 0.3496,\n",
       "            0.349 , 0.348 , 0.3477, 0.3464, 0.3452, 0.3447, 0.3438, 0.3433,\n",
       "            0.3416, 0.341 , 0.3408, 0.3406, 0.3403, 0.34  , 0.3394, 0.3376,\n",
       "            0.3372, 0.3367, 0.3364, 0.3354, 0.3352, 0.3347, 0.3337, 0.3335,\n",
       "            0.332 , 0.331 , 0.3298, 0.3286, 0.328 , 0.3274, 0.327 , 0.3267,\n",
       "            0.3254, 0.3247, 0.3225, 0.322 , 0.3218, 0.3206, 0.3203, 0.3157,\n",
       "            0.3152, 0.314 , 0.3132, 0.313 , 0.3125, 0.3113, 0.3093, 0.3088,\n",
       "            0.3083, 0.3074, 0.3064, 0.3062, 0.306 , 0.3044, 0.3037, 0.3027,\n",
       "            0.3025, 0.301 , 0.2998, 0.2996, 0.2974, 0.2969, 0.2952, 0.295 ,\n",
       "            0.2947, 0.2937, 0.2922, 0.2917, 0.2913, 0.2905, 0.2896, 0.287 ,\n",
       "            0.2869, 0.2866, 0.285 , 0.2832, 0.2786, 0.278 , 0.2761, 0.2732,\n",
       "            0.2725, 0.272 , 0.2715, 0.2705, 0.27  , 0.268 , 0.2673, 0.2659,\n",
       "            0.2637, 0.2622, 0.262 , 0.2615, 0.2612, 0.261 , 0.26  , 0.2595,\n",
       "            0.2576, 0.2573, 0.2568, 0.2566, 0.256 , 0.2542, 0.253 , 0.251 ,\n",
       "            0.2505, 0.2502, 0.2498, 0.2496, 0.2444, 0.2438, 0.2437, 0.2434,\n",
       "            0.2433, 0.2422, 0.2418, 0.2407, 0.2388, 0.2292, 0.2272, 0.2268,\n",
       "            0.2264, 0.2229, 0.2203, 0.2173, 0.2158, 0.2148, 0.2144, 0.2113,\n",
       "            0.2048, 0.1953, 0.1931, 0.1849, 0.1842, 0.1819, 0.1816, 0.1598,\n",
       "            0.1232, 0.0972, 0.0939], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.3030303, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.16949153, 0.16949153, 0.1779661 ,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.19491525, 0.19491525, 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2457627 , 0.2542373 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3644068 , 0.37288135,\n",
       "            0.37288135, 0.38135594, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.44915253, 0.45762712, 0.47457626, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.0530303 , 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.43939394, 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.5378788 , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6212121 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.82575756, 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.6484 , 0.621  , 0.6123 , 0.606  , 0.605  , 0.604  ,\n",
       "            0.6035 , 0.5864 , 0.582  , 0.5757 , 0.5723 , 0.568  , 0.566  ,\n",
       "            0.562  , 0.561  , 0.5605 , 0.557  , 0.5513 , 0.5454 , 0.5444 ,\n",
       "            0.5425 , 0.542  , 0.5396 , 0.536  , 0.532  , 0.5312 , 0.53   ,\n",
       "            0.526  , 0.5254 , 0.524  , 0.5225 , 0.522  , 0.517  , 0.5166 ,\n",
       "            0.5117 , 0.5044 , 0.5034 , 0.4993 , 0.488  , 0.485  , 0.4734 ,\n",
       "            0.473  , 0.4712 , 0.4678 , 0.4636 , 0.4624 , 0.4597 , 0.4536 ,\n",
       "            0.4478 , 0.4475 , 0.4465 , 0.4358 , 0.4338 , 0.4272 , 0.425  ,\n",
       "            0.412  , 0.4097 , 0.4045 , 0.4026 , 0.4011 , 0.4    , 0.3975 ,\n",
       "            0.3972 , 0.3965 , 0.3926 , 0.3923 , 0.391  , 0.3901 , 0.387  ,\n",
       "            0.3867 , 0.3853 , 0.3848 , 0.3833 , 0.3782 , 0.378  , 0.3755 ,\n",
       "            0.374  , 0.3735 , 0.3733 , 0.3718 , 0.3713 , 0.37   , 0.3699 ,\n",
       "            0.3687 , 0.3682 , 0.3672 , 0.3667 , 0.3665 , 0.3638 , 0.3633 ,\n",
       "            0.363  , 0.3616 , 0.3599 , 0.3591 , 0.3586 , 0.3584 , 0.358  ,\n",
       "            0.3564 , 0.3557 , 0.3552 , 0.3547 , 0.3542 , 0.354  , 0.3538 ,\n",
       "            0.353  , 0.3528 , 0.3513 , 0.3506 , 0.3503 , 0.3496 , 0.349  ,\n",
       "            0.3484 , 0.3474 , 0.3452 , 0.344  , 0.3438 , 0.3435 , 0.342  ,\n",
       "            0.3418 , 0.3416 , 0.3408 , 0.34   , 0.3364 , 0.3354 , 0.3345 ,\n",
       "            0.3335 , 0.331  , 0.33   , 0.3293 , 0.3286 , 0.3284 , 0.3281 ,\n",
       "            0.3271 , 0.327  , 0.3264 , 0.3262 , 0.3247 , 0.3237 , 0.322  ,\n",
       "            0.3215 , 0.3208 , 0.3203 , 0.3186 , 0.3179 , 0.3174 , 0.317  ,\n",
       "            0.3162 , 0.316  , 0.3147 , 0.3118 , 0.311  , 0.3103 , 0.3098 ,\n",
       "            0.3093 , 0.3088 , 0.3074 , 0.3062 , 0.304  , 0.3032 , 0.3022 ,\n",
       "            0.3008 , 0.2986 , 0.2979 , 0.2957 , 0.2925 , 0.29   , 0.2883 ,\n",
       "            0.2876 , 0.285  , 0.2847 , 0.2842 , 0.2822 , 0.282  , 0.2817 ,\n",
       "            0.2815 , 0.28   , 0.2786 , 0.2778 , 0.2776 , 0.2766 , 0.2764 ,\n",
       "            0.2761 , 0.276  , 0.2747 , 0.274  , 0.2734 , 0.273  , 0.2717 ,\n",
       "            0.2712 , 0.2683 , 0.268  , 0.2664 , 0.266  , 0.2651 , 0.2646 ,\n",
       "            0.2637 , 0.26   , 0.2598 , 0.2595 , 0.2585 , 0.258  , 0.2487 ,\n",
       "            0.2477 , 0.244  , 0.2421 , 0.2415 , 0.2411 , 0.2372 , 0.2252 ,\n",
       "            0.2211 , 0.2179 , 0.2142 , 0.214  , 0.2124 , 0.2106 , 0.2073 ,\n",
       "            0.2029 , 0.1937 , 0.188  , 0.1826 , 0.1796 , 0.1788 , 0.1763 ,\n",
       "            0.157  , 0.11694, 0.0914 , 0.0909 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.33333334, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.1440678 , 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.18644068, 0.18644068, 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.18644068, 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.20338982, 0.20338982, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2457627 , 0.2542373 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.33898306, 0.3559322 ,\n",
       "            0.3644068 , 0.3644068 , 0.3644068 , 0.37288135, 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.43220338, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.60169494, 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.4318182 , 0.4318182 , 0.43939394,\n",
       "            0.43939394, 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.54545456, 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6212121 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.7651515 , 0.77272725, 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.84090906, 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.6934 , 0.6626 , 0.6533 , 0.646  , 0.645  , 0.644  ,\n",
       "            0.6436 , 0.643  , 0.6245 , 0.619  , 0.612  , 0.61   , 0.6035 ,\n",
       "            0.6016 , 0.597  , 0.5967 , 0.595  , 0.593  , 0.585  , 0.579  ,\n",
       "            0.5776 , 0.575  , 0.5747 , 0.5713 , 0.569  , 0.5635 , 0.563  ,\n",
       "            0.561  , 0.5566 , 0.556  , 0.5547 , 0.5537 , 0.5522 , 0.5464 ,\n",
       "            0.546  , 0.54   , 0.533  , 0.5317 , 0.527  , 0.514  , 0.5127 ,\n",
       "            0.5103 , 0.4973 , 0.497  , 0.4949 , 0.4902 , 0.4856 , 0.484  ,\n",
       "            0.4814 , 0.475  , 0.4683 , 0.4675 , 0.4663 , 0.4546 , 0.4517 ,\n",
       "            0.4438 , 0.4421 , 0.4275 , 0.424  , 0.4211 , 0.4192 , 0.4111 ,\n",
       "            0.4065 , 0.406  , 0.4048 , 0.402  , 0.3977 , 0.3975 , 0.3962 ,\n",
       "            0.395  , 0.3928 , 0.3914 , 0.39   , 0.3877 , 0.3828 , 0.381  ,\n",
       "            0.3794 , 0.3787 , 0.3782 , 0.3774 , 0.3772 , 0.3755 , 0.3752 ,\n",
       "            0.3748 , 0.3735 , 0.3733 , 0.3718 , 0.3716 , 0.3713 , 0.371  ,\n",
       "            0.3696 , 0.3682 , 0.3662 , 0.366  , 0.3652 , 0.365  , 0.3628 ,\n",
       "            0.3625 , 0.3618 , 0.3608 , 0.3596 , 0.3591 , 0.359  , 0.3586 ,\n",
       "            0.3582 , 0.3567 , 0.3564 , 0.3557 , 0.3547 , 0.3542 , 0.354  ,\n",
       "            0.3533 , 0.353  , 0.3528 , 0.3518 , 0.3506 , 0.3499 , 0.3481 ,\n",
       "            0.3472 , 0.347  , 0.3455 , 0.3445 , 0.3442 , 0.3438 , 0.3435 ,\n",
       "            0.3428 , 0.3418 , 0.3396 , 0.3374 , 0.3367 , 0.3364 , 0.3337 ,\n",
       "            0.3318 , 0.331  , 0.3308 , 0.3306 , 0.3286 , 0.3284 , 0.3274 ,\n",
       "            0.3262 , 0.325  , 0.3232 , 0.323  , 0.322  , 0.3218 , 0.3188 ,\n",
       "            0.3179 , 0.3174 , 0.3164 , 0.3162 , 0.3142 , 0.314  , 0.3135 ,\n",
       "            0.313  , 0.312  , 0.3115 , 0.3113 , 0.3088 , 0.3079 , 0.3062 ,\n",
       "            0.3054 , 0.3044 , 0.3013 , 0.3    , 0.2996 , 0.2957 , 0.2942 ,\n",
       "            0.293  , 0.29   , 0.2893 , 0.2874 , 0.287  , 0.2861 , 0.2856 ,\n",
       "            0.2842 , 0.2837 , 0.2827 , 0.2825 , 0.282  , 0.2803 , 0.2793 ,\n",
       "            0.2788 , 0.278  , 0.2778 , 0.2769 , 0.276  , 0.2756 , 0.2754 ,\n",
       "            0.2751 , 0.2747 , 0.2717 , 0.2715 , 0.2712 , 0.27   , 0.2688 ,\n",
       "            0.2673 , 0.2668 , 0.2659 , 0.2654 , 0.2644 , 0.2605 , 0.26   ,\n",
       "            0.2598 , 0.2585 , 0.2566 , 0.2487 , 0.2448 , 0.2441 , 0.2415 ,\n",
       "            0.241  , 0.2352 , 0.2311 , 0.2185 , 0.2137 , 0.2106 , 0.2076 ,\n",
       "            0.2069 , 0.2051 , 0.2024 , 0.1993 , 0.1964 , 0.1877 , 0.1799 ,\n",
       "            0.1759 , 0.173  , 0.1707 , 0.1678 , 0.1504 , 0.1086 , 0.0856 ,\n",
       "            0.08374], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00847458, dtype=float32),\n",
       "    'tpr': array(0.3939394, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.15254237, 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.16101696, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.1779661 , 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.21186441, 0.21186441, 0.21186441, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.22881356, 0.22881356, 0.23728813,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.26271185, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.29661018, 0.29661018,\n",
       "            0.30508474, 0.30508474, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.38135594, 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5254237 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.59322035, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.4318182 , 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.5984849 , 0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.72727275, 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.77272725, 0.780303  , 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.8181818 , 0.82575756, 0.82575756, 0.82575756,\n",
       "            0.8333333 , 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.92424244, 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.746  , 0.713  , 0.703  , 0.695  , 0.6943 , 0.6924 ,\n",
       "            0.692  , 0.672  , 0.6675 , 0.6577 , 0.649  , 0.6475 , 0.6436 ,\n",
       "            0.642  , 0.64   , 0.639  , 0.6294 , 0.6255 , 0.6226 , 0.6187 ,\n",
       "            0.6177 , 0.6143 , 0.6133 , 0.608  , 0.607  , 0.605  , 0.603  ,\n",
       "            0.598  , 0.597  , 0.5947 , 0.588  , 0.5864 , 0.579  , 0.574  ,\n",
       "            0.5728 , 0.5664 , 0.5503 , 0.5483 , 0.5464 , 0.5347 , 0.5337 ,\n",
       "            0.5312 , 0.524  , 0.5176 , 0.516  , 0.5156 , 0.509  , 0.5005 ,\n",
       "            0.4976 , 0.4973 , 0.4858 , 0.4827 , 0.4731 , 0.4714 , 0.4531 ,\n",
       "            0.4524 , 0.4512 , 0.4495 , 0.4365 , 0.4224 , 0.422  , 0.4207 ,\n",
       "            0.4177 , 0.4133 , 0.4126 , 0.4124 , 0.4104 , 0.4092 , 0.409  ,\n",
       "            0.4087 , 0.4067 , 0.4055 , 0.4053 , 0.404  , 0.403  , 0.3994 ,\n",
       "            0.3958 , 0.3955 , 0.3948 , 0.3933 , 0.39   , 0.3896 , 0.3887 ,\n",
       "            0.3882 , 0.3877 , 0.3875 , 0.387  , 0.3855 , 0.385  , 0.3843 ,\n",
       "            0.3806 , 0.3801 , 0.38   , 0.3794 , 0.3792 , 0.3777 , 0.377  ,\n",
       "            0.3767 , 0.3757 , 0.3755 , 0.3748 , 0.3745 , 0.3733 , 0.373  ,\n",
       "            0.3728 , 0.3718 , 0.3696 , 0.369  , 0.3684 , 0.368  , 0.367  ,\n",
       "            0.3647 , 0.3645 , 0.3638 , 0.3633 , 0.362  , 0.3608 , 0.3604 ,\n",
       "            0.3596 , 0.3586 , 0.3584 , 0.358  , 0.3577 , 0.3555 , 0.3538 ,\n",
       "            0.352  , 0.351  , 0.3503 , 0.3489 , 0.3484 , 0.3442 , 0.3435 ,\n",
       "            0.3425 , 0.3423 , 0.342  , 0.34   , 0.3389 , 0.337  , 0.3362 ,\n",
       "            0.3357 , 0.3325 , 0.3313 , 0.3306 , 0.33   , 0.3289 , 0.3271 ,\n",
       "            0.3257 , 0.3254 , 0.3252 , 0.3245 , 0.323  , 0.3225 , 0.3215 ,\n",
       "            0.3213 , 0.3203 , 0.3186 , 0.3184 , 0.3132 , 0.313  , 0.3127 ,\n",
       "            0.31   , 0.3079 , 0.3054 , 0.3052 , 0.3047 , 0.3037 , 0.3032 ,\n",
       "            0.2996 , 0.2993 , 0.2986 , 0.298  , 0.2976 , 0.2974 , 0.2957 ,\n",
       "            0.2944 , 0.2935 , 0.293  , 0.2915 , 0.2913 , 0.2903 , 0.29   ,\n",
       "            0.289  , 0.2878 , 0.2861 , 0.2847 , 0.284  , 0.2834 , 0.2822 ,\n",
       "            0.282  , 0.281  , 0.2808 , 0.28   , 0.2793 , 0.279  , 0.277  ,\n",
       "            0.2766 , 0.2734 , 0.273  , 0.2725 , 0.2722 , 0.2605 , 0.2566 ,\n",
       "            0.2546 , 0.2534 , 0.2527 , 0.2473 , 0.234  , 0.2295 , 0.2166 ,\n",
       "            0.2108 , 0.2076 , 0.2054 , 0.2032 , 0.2023 , 0.1984 , 0.1954 ,\n",
       "            0.194  , 0.1857 , 0.1752 , 0.1731 , 0.1703 , 0.1656 , 0.1627 ,\n",
       "            0.1475 , 0.10266, 0.0823 , 0.07806], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00847458, dtype=float32),\n",
       "    'tpr': array(0.4090909, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.18644068, 0.19491525, 0.21186441,\n",
       "            0.21186441, 0.21186441, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.23728813, 0.23728813, 0.23728813,\n",
       "            0.2457627 , 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.37288135, 0.38135594, 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.5508475 , 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.65254235, 0.66101694, 0.6694915 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03787879,\n",
       "            0.04545455, 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.4318182 , 0.4318182 , 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.54545456, 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6363636 , 0.6515151 , 0.6515151 ,\n",
       "            0.65909094, 0.67424244, 0.6818182 , 0.68939394, 0.70454544,\n",
       "            0.7121212 , 0.7348485 , 0.7348485 , 0.74242425, 0.74242425,\n",
       "            0.75      , 0.75757575, 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.774  , 0.7397 , 0.73   , 0.721  , 0.7207 , 0.7188 ,\n",
       "            0.7183 , 0.6987 , 0.6924 , 0.683  , 0.6826 , 0.674  , 0.6724 ,\n",
       "            0.666  , 0.6646 , 0.661  , 0.653  , 0.648  , 0.6455 , 0.6416 ,\n",
       "            0.641  , 0.637  , 0.6353 , 0.6294 , 0.6284 , 0.6274 , 0.6245 ,\n",
       "            0.62   , 0.6196 , 0.6187 , 0.6177 , 0.6157 , 0.6084 , 0.6074 ,\n",
       "            0.6    , 0.5933 , 0.5903 , 0.5854 , 0.57   , 0.5674 , 0.5645 ,\n",
       "            0.5503 , 0.55   , 0.547  , 0.5405 , 0.534  , 0.532  , 0.531  ,\n",
       "            0.522  , 0.514  , 0.512  , 0.5117 , 0.4983 , 0.4941 , 0.4836 ,\n",
       "            0.4624 , 0.4622 , 0.4602 , 0.4592 , 0.4443 , 0.437  , 0.435  ,\n",
       "            0.431  , 0.428  , 0.425  , 0.4243 , 0.4226 , 0.4216 , 0.4207 ,\n",
       "            0.419  , 0.4167 , 0.4146 , 0.4143 , 0.4136 , 0.4124 , 0.4116 ,\n",
       "            0.4106 , 0.4084 , 0.4075 , 0.4067 , 0.4014 , 0.4006 , 0.3997 ,\n",
       "            0.3962 , 0.3958 , 0.395  , 0.3938 , 0.3926 , 0.3918 , 0.3901 ,\n",
       "            0.39   , 0.3896 , 0.3892 , 0.3884 , 0.387  , 0.3867 , 0.3865 ,\n",
       "            0.3855 , 0.385  , 0.3845 , 0.3843 , 0.3828 , 0.3818 , 0.381  ,\n",
       "            0.3787 , 0.3772 , 0.3765 , 0.3748 , 0.3743 , 0.374  , 0.3735 ,\n",
       "            0.3728 , 0.372  , 0.3708 , 0.3706 , 0.369  , 0.3674 , 0.3657 ,\n",
       "            0.3655 , 0.3652 , 0.3647 , 0.3638 , 0.3618 , 0.3604 , 0.3582 ,\n",
       "            0.357  , 0.3567 , 0.3542 , 0.3538 , 0.3506 , 0.349  , 0.3484 ,\n",
       "            0.3481 , 0.3455 , 0.3452 , 0.343  , 0.3423 , 0.3418 , 0.3413 ,\n",
       "            0.3386 , 0.338  , 0.3374 , 0.3352 , 0.332  , 0.3315 , 0.3293 ,\n",
       "            0.3289 , 0.3274 , 0.326  , 0.3252 , 0.324  , 0.3235 , 0.322  ,\n",
       "            0.3208 , 0.3206 , 0.3198 , 0.3171 , 0.3167 , 0.3118 , 0.3115 ,\n",
       "            0.308  , 0.3079 , 0.306  , 0.3054 , 0.304  , 0.3035 , 0.3032 ,\n",
       "            0.3027 , 0.302  , 0.2998 , 0.2986 , 0.2979 , 0.2966 , 0.296  ,\n",
       "            0.295  , 0.2937 , 0.2932 , 0.292  , 0.2915 , 0.2903 , 0.29   ,\n",
       "            0.288  , 0.2874 , 0.2866 , 0.2852 , 0.2844 , 0.2827 , 0.282  ,\n",
       "            0.281  , 0.2793 , 0.279  , 0.2786 , 0.2776 , 0.2764 , 0.2742 ,\n",
       "            0.2715 , 0.271  , 0.2705 , 0.2703 , 0.2578 , 0.2568 , 0.253  ,\n",
       "            0.2527 , 0.2517 , 0.2428 , 0.2289 , 0.2244 , 0.21   , 0.204  ,\n",
       "            0.2009 , 0.199  , 0.1964 , 0.1956 , 0.1912 , 0.1897 , 0.1873 ,\n",
       "            0.1791 , 0.169  , 0.1664 , 0.1635 , 0.16   , 0.1567 , 0.1405 ,\n",
       "            0.0955 , 0.07654, 0.0716 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.01694915, dtype=float32),\n",
       "    'tpr': array(0.4318182, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11016949, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.15254237, 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.19491525, 0.20338982, 0.20338982,\n",
       "            0.21186441, 0.21186441, 0.22033899, 0.22033899, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.34745762, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03787879,\n",
       "            0.04545455, 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.4318182 , 0.4318182 , 0.4318182 , 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.54545456, 0.56060606, 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.6666667 , 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.719697  , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.7348485 , 0.74242425, 0.74242425, 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8636364 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.8086 , 0.7744 , 0.7646 , 0.756  , 0.7554 , 0.753  ,\n",
       "            0.7524 , 0.734  , 0.726  , 0.717  , 0.7163 , 0.707  , 0.7056 ,\n",
       "            0.699  , 0.6978 , 0.693  , 0.6855 , 0.6797 , 0.6772 , 0.674  ,\n",
       "            0.6733 , 0.6694 , 0.667  , 0.6606 , 0.6597 , 0.6587 , 0.6562 ,\n",
       "            0.6523 , 0.651  , 0.6494 , 0.6484 , 0.6465 , 0.6387 , 0.6377 ,\n",
       "            0.6304 , 0.623  , 0.6177 , 0.6143 , 0.599  , 0.595  , 0.592  ,\n",
       "            0.576  , 0.5747 , 0.5728 , 0.566  , 0.5605 , 0.557  , 0.5557 ,\n",
       "            0.545  , 0.537  , 0.5366 , 0.535  , 0.52   , 0.5146 , 0.505  ,\n",
       "            0.504  , 0.4822 , 0.481  , 0.479  , 0.4775 , 0.461  , 0.4578 ,\n",
       "            0.4536 , 0.4468 , 0.4438 , 0.4426 , 0.442  , 0.4397 , 0.4385 ,\n",
       "            0.4365 , 0.434  , 0.433  , 0.4304 , 0.4294 , 0.428  , 0.4265 ,\n",
       "            0.4263 , 0.4253 , 0.423  , 0.4229 , 0.4197 , 0.4177 , 0.4146 ,\n",
       "            0.4136 , 0.4124 , 0.4116 , 0.4092 , 0.409  , 0.4087 , 0.4075 ,\n",
       "            0.4055 , 0.4053 , 0.405  , 0.4048 , 0.4043 , 0.4038 , 0.402  ,\n",
       "            0.4019 , 0.4016 , 0.401  , 0.4006 , 0.3984 , 0.3982 , 0.398  ,\n",
       "            0.3972 , 0.397  , 0.3943 , 0.3936 , 0.391  , 0.3909 , 0.3904 ,\n",
       "            0.3887 , 0.388  , 0.3877 , 0.3872 , 0.3862 , 0.3843 , 0.382  ,\n",
       "            0.3818 , 0.3804 , 0.3782 , 0.3777 , 0.376  , 0.3735 , 0.373  ,\n",
       "            0.3726 , 0.3716 , 0.37   , 0.3696 , 0.3662 , 0.3657 , 0.3633 ,\n",
       "            0.3625 , 0.362  , 0.3606 , 0.3596 , 0.3572 , 0.3538 , 0.3533 ,\n",
       "            0.3518 , 0.3516 , 0.349  , 0.3477 , 0.344  , 0.3438 , 0.343  ,\n",
       "            0.3398 , 0.3394 , 0.3386 , 0.3367 , 0.3357 , 0.3323 , 0.33   ,\n",
       "            0.3298 , 0.3293 , 0.3271 , 0.327  , 0.324  , 0.3228 , 0.3193 ,\n",
       "            0.318  , 0.3174 , 0.3154 , 0.3147 , 0.3145 , 0.3123 , 0.311  ,\n",
       "            0.3103 , 0.3096 , 0.3093 , 0.3088 , 0.3071 , 0.3066 , 0.3025 ,\n",
       "            0.3022 , 0.3018 , 0.3005 , 0.3003 , 0.2993 , 0.2976 , 0.2974 ,\n",
       "            0.2961 , 0.2957 , 0.2954 , 0.2935 , 0.2932 , 0.2925 , 0.2917 ,\n",
       "            0.2903 , 0.2893 , 0.289  , 0.2876 , 0.2864 , 0.2856 , 0.2852 ,\n",
       "            0.2837 , 0.2832 , 0.2803 , 0.278  , 0.2761 , 0.276  , 0.2756 ,\n",
       "            0.2751 , 0.2742 , 0.2646 , 0.2595 , 0.2593 , 0.258  , 0.2544 ,\n",
       "            0.243  , 0.2266 , 0.222  , 0.2065 , 0.2001 , 0.1968 , 0.1954 ,\n",
       "            0.1919 , 0.1915 , 0.1865 , 0.1859 , 0.1836 , 0.1755 , 0.1646 ,\n",
       "            0.1622 , 0.1593 , 0.1555 , 0.1519 , 0.1361 , 0.0898 , 0.07275,\n",
       "            0.06647], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04237288, dtype=float32),\n",
       "    'tpr': array(0.4318182, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.16949153, 0.16949153,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.16949153, 0.16949153,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.21186441, 0.21186441,\n",
       "            0.21186441, 0.22881356, 0.22881356, 0.22881356, 0.23728813,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.55932206, 0.5677966 , 0.58474576, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.8898305 , 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.04545455,\n",
       "            0.0530303 , 0.06818182, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.4318182 ,\n",
       "            0.4318182 , 0.4318182 , 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6136364 , 0.6287879 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.719697  , 0.72727275, 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.74242425, 0.75      , 0.75      ,\n",
       "            0.75      , 0.75757575, 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8636364 , 0.8712121 ,\n",
       "            0.8712121 , 0.8712121 , 0.8712121 , 0.8787879 , 0.8939394 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.9166667 , 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.8423 , 0.8086 , 0.8    , 0.7905 , 0.7876 , 0.787  ,\n",
       "            0.7695 , 0.761  , 0.752  , 0.7505 , 0.7417 , 0.7407 , 0.734  ,\n",
       "            0.7324 , 0.732  , 0.727  , 0.7197 , 0.7134 , 0.712  , 0.7075 ,\n",
       "            0.703  , 0.7017 , 0.695  , 0.6943 , 0.6924 , 0.6895 , 0.686  ,\n",
       "            0.684  , 0.683  , 0.681  , 0.68   , 0.672  , 0.6704 , 0.6626 ,\n",
       "            0.656  , 0.6494 , 0.6465 , 0.63   , 0.6255 , 0.622  , 0.606  ,\n",
       "            0.6025 , 0.5947 , 0.588  , 0.5845 , 0.5835 , 0.571  , 0.564  ,\n",
       "            0.5625 , 0.561  , 0.545  , 0.539  , 0.528  , 0.5273 , 0.505  ,\n",
       "            0.503  , 0.5024 , 0.4983 , 0.4802 , 0.4758 , 0.4697 , 0.4604 ,\n",
       "            0.4575 , 0.457  , 0.4568 , 0.4558 , 0.452  , 0.45   , 0.449  ,\n",
       "            0.4463 , 0.4443 , 0.443  , 0.4429 , 0.4417 , 0.4412 , 0.4385 ,\n",
       "            0.436  , 0.4355 , 0.435  , 0.434  , 0.4329 , 0.428  , 0.4263 ,\n",
       "            0.426  , 0.4233 , 0.4204 , 0.4202 , 0.4197 , 0.4192 , 0.4175 ,\n",
       "            0.4172 , 0.417  , 0.4165 , 0.4163 , 0.416  , 0.4155 , 0.413  ,\n",
       "            0.4124 , 0.411  , 0.4106 , 0.4102 , 0.4087 , 0.406  , 0.4058 ,\n",
       "            0.4048 , 0.404  , 0.4033 , 0.4026 , 0.4016 , 0.4004 , 0.3987 ,\n",
       "            0.3982 , 0.398  , 0.3975 , 0.3965 , 0.3938 , 0.3923 , 0.3904 ,\n",
       "            0.3896 , 0.388  , 0.3877 , 0.386  , 0.3845 , 0.3816 , 0.3806 ,\n",
       "            0.3792 , 0.375  , 0.3748 , 0.3723 , 0.371  , 0.3708 , 0.369  ,\n",
       "            0.3687 , 0.3665 , 0.3652 , 0.365  , 0.3645 , 0.3638 , 0.3633 ,\n",
       "            0.362  , 0.3606 , 0.358  , 0.3555 , 0.3542 , 0.351  , 0.3499 ,\n",
       "            0.348  , 0.3477 , 0.3464 , 0.3457 , 0.343  , 0.3406 , 0.338  ,\n",
       "            0.3362 , 0.3354 , 0.3345 , 0.3342 , 0.334  , 0.3276 , 0.3274 ,\n",
       "            0.326  , 0.3257 , 0.3245 , 0.3232 , 0.3225 , 0.3213 , 0.3203 ,\n",
       "            0.319  , 0.3176 , 0.3167 , 0.3157 , 0.3127 , 0.312  , 0.3115 ,\n",
       "            0.311  , 0.3108 , 0.31   , 0.3093 , 0.3088 , 0.3074 , 0.3062 ,\n",
       "            0.3054 , 0.3042 , 0.3032 , 0.302  , 0.3015 , 0.3    , 0.2998 ,\n",
       "            0.2988 , 0.2974 , 0.2954 , 0.2947 , 0.2935 , 0.2917 , 0.2915 ,\n",
       "            0.289  , 0.2874 , 0.284  , 0.2837 , 0.2832 , 0.2822 , 0.2805 ,\n",
       "            0.2786 , 0.275  , 0.2737 , 0.2683 , 0.268  , 0.258  , 0.2573 ,\n",
       "            0.2433 , 0.2233 , 0.2185 , 0.2021 , 0.195  , 0.1918 , 0.191  ,\n",
       "            0.1865 , 0.181  , 0.1791 , 0.1714 , 0.1589 , 0.1577 , 0.1545 ,\n",
       "            0.15   , 0.1462 , 0.1312 , 0.08386, 0.0689 , 0.0611 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04237288, dtype=float32),\n",
       "    'tpr': array(0.43939394, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.10169491, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.16949153, 0.16949153,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.21186441, 0.21186441, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22033899, 0.22033899, 0.22881356, 0.22881356,\n",
       "            0.22881356, 0.23728813, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.04545455,\n",
       "            0.06060606, 0.06818182, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.4318182 , 0.4318182 , 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75      , 0.7651515 , 0.7651515 ,\n",
       "            0.7651515 , 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.79545456, 0.79545456, 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8560606 , 0.8636364 , 0.8636364 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.868  , 0.837  , 0.8276 , 0.819  , 0.816  , 0.8154 ,\n",
       "            0.799  , 0.79   , 0.7817 , 0.779  , 0.771  , 0.77   , 0.763  ,\n",
       "            0.7617 , 0.7603 , 0.755  , 0.749  , 0.741  , 0.7373 , 0.737  ,\n",
       "            0.7324 , 0.7305 , 0.7236 , 0.7227 , 0.721  , 0.7188 , 0.7153 ,\n",
       "            0.713  , 0.7114 , 0.709  , 0.7085 , 0.7    , 0.6987 , 0.691  ,\n",
       "            0.683  , 0.6763 , 0.674  , 0.6577 , 0.6523 , 0.649  , 0.632  ,\n",
       "            0.628  , 0.6274 , 0.6196 , 0.613  , 0.6094 , 0.608  , 0.5933 ,\n",
       "            0.5874 , 0.586  , 0.5845 , 0.5664 , 0.5596 , 0.549  , 0.5474 ,\n",
       "            0.5234 , 0.522  , 0.5215 , 0.5166 , 0.499  , 0.4973 , 0.4895 ,\n",
       "            0.4778 , 0.477  , 0.476  , 0.4746 , 0.474  , 0.469  , 0.468  ,\n",
       "            0.467  , 0.4668 , 0.4644 , 0.4639 , 0.463  , 0.4587 , 0.4578 ,\n",
       "            0.4575 , 0.4558 , 0.4556 , 0.45   , 0.4485 , 0.4482 , 0.4473 ,\n",
       "            0.4468 , 0.4446 , 0.4436 , 0.4417 , 0.4414 , 0.4412 , 0.4404 ,\n",
       "            0.4395 , 0.439  , 0.438  , 0.4373 , 0.4355 , 0.4348 , 0.4336 ,\n",
       "            0.4329 , 0.432  , 0.4304 , 0.429  , 0.4287 , 0.4263 , 0.426  ,\n",
       "            0.4253 , 0.4243 , 0.4226 , 0.4224 , 0.4216 , 0.421  , 0.4207 ,\n",
       "            0.4202 , 0.4175 , 0.4165 , 0.4158 , 0.4138 , 0.4128 , 0.4124 ,\n",
       "            0.412  , 0.4119 , 0.411  , 0.4094 , 0.4087 , 0.4072 , 0.4065 ,\n",
       "            0.4043 , 0.4019 , 0.399  , 0.397  , 0.395  , 0.393  , 0.388  ,\n",
       "            0.387  , 0.3857 , 0.3845 , 0.3838 , 0.3823 , 0.3809 , 0.3801 ,\n",
       "            0.3794 , 0.3787 , 0.3772 , 0.376  , 0.3752 , 0.374  , 0.3733 ,\n",
       "            0.3723 , 0.3677 , 0.3655 , 0.3635 , 0.3608 , 0.3574 , 0.3562 ,\n",
       "            0.3552 , 0.3538 , 0.3525 , 0.35   , 0.3438 , 0.343  , 0.342  ,\n",
       "            0.3389 , 0.3386 , 0.337  , 0.3364 , 0.334  , 0.3337 , 0.3335 ,\n",
       "            0.332  , 0.3306 , 0.3298 , 0.3284 , 0.3271 , 0.327  , 0.326  ,\n",
       "            0.3247 , 0.322  , 0.3208 , 0.3176 , 0.3171 , 0.3164 , 0.3162 ,\n",
       "            0.3154 , 0.314  , 0.3135 , 0.313  , 0.3123 , 0.312  , 0.3118 ,\n",
       "            0.3105 , 0.3103 , 0.31   , 0.309  , 0.3079 , 0.3071 , 0.307  ,\n",
       "            0.3042 , 0.3005 , 0.3003 , 0.2986 , 0.298  , 0.2961 , 0.2903 ,\n",
       "            0.29   , 0.2898 , 0.2893 , 0.2883 , 0.2827 , 0.2812 , 0.2795 ,\n",
       "            0.277  , 0.2766 , 0.2754 , 0.2603 , 0.258  , 0.2437 , 0.2207 ,\n",
       "            0.2157 , 0.1985 , 0.1907 , 0.1876 , 0.1873 , 0.1824 , 0.182  ,\n",
       "            0.1771 , 0.1763 , 0.1753 , 0.1677 , 0.1545 , 0.1536 , 0.1506 ,\n",
       "            0.1458 , 0.1416 , 0.1271 , 0.0788 , 0.06573, 0.05664],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04237288, dtype=float32),\n",
       "    'tpr': array(0.46212122, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.18644068, 0.18644068, 0.18644068,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.20338982, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22033899, 0.22881356, 0.22881356,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2457627 , 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.33050847,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.04545455,\n",
       "            0.0530303 , 0.06818182, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.4318182 , 0.4318182 , 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6060606 , 0.6212121 ,\n",
       "            0.6287879 , 0.6439394 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.8833 , 0.854  , 0.845  , 0.8364 , 0.834  , 0.8335 ,\n",
       "            0.818  , 0.808  , 0.8003 , 0.7954 , 0.79   , 0.7896 , 0.7817 ,\n",
       "            0.781  , 0.777  , 0.7715 , 0.7676 , 0.759  , 0.758  , 0.7563 ,\n",
       "            0.755  , 0.7515 , 0.747  , 0.74   , 0.7397 , 0.737  , 0.7354 ,\n",
       "            0.731  , 0.729  , 0.726  , 0.724  , 0.718  , 0.717  , 0.709  ,\n",
       "            0.6997 , 0.691  , 0.6904 , 0.676  , 0.67   , 0.6655 , 0.6465 ,\n",
       "            0.6426 , 0.6406 , 0.6353 , 0.629  , 0.6255 , 0.622  , 0.6045 ,\n",
       "            0.601  , 0.6    , 0.598  , 0.578  , 0.5693 , 0.5615 , 0.556  ,\n",
       "            0.532  , 0.53   , 0.5273 , 0.527  , 0.523  , 0.51   , 0.5044 ,\n",
       "            0.497  , 0.496  , 0.4949 , 0.4917 , 0.4915 , 0.4873 , 0.4858 ,\n",
       "            0.4854 , 0.484  , 0.4832 , 0.4785 , 0.4768 , 0.4736 , 0.4688 ,\n",
       "            0.4675 , 0.4656 , 0.465  , 0.4617 , 0.4612 , 0.4607 , 0.459  ,\n",
       "            0.4587 , 0.4578 , 0.4575 , 0.4573 , 0.456  , 0.4553 , 0.455  ,\n",
       "            0.454  , 0.4536 , 0.4521 , 0.4495 , 0.4458 , 0.4456 , 0.445  ,\n",
       "            0.4426 , 0.4421 , 0.442  , 0.441  , 0.4385 , 0.4377 , 0.4373 ,\n",
       "            0.436  , 0.4346 , 0.4333 , 0.4285 , 0.4272 , 0.426  , 0.4255 ,\n",
       "            0.4233 , 0.4229 , 0.4224 , 0.422  , 0.4219 , 0.421  , 0.4204 ,\n",
       "            0.4177 , 0.4172 , 0.4148 , 0.4146 , 0.413  , 0.411  , 0.4104 ,\n",
       "            0.4082 , 0.4004 , 0.398  , 0.3948 , 0.394  , 0.3926 , 0.392  ,\n",
       "            0.3918 , 0.39   , 0.3896 , 0.3892 , 0.3872 , 0.3862 , 0.3857 ,\n",
       "            0.385  , 0.3809 , 0.3792 , 0.3767 , 0.3765 , 0.3755 , 0.3752 ,\n",
       "            0.3733 , 0.3726 , 0.3718 , 0.3713 , 0.371  , 0.3635 , 0.3625 ,\n",
       "            0.3591 , 0.3562 , 0.353  , 0.3525 , 0.3442 , 0.344  , 0.3423 ,\n",
       "            0.3386 , 0.3384 , 0.338  , 0.3362 , 0.3352 , 0.3337 , 0.3333 ,\n",
       "            0.3318 , 0.331  , 0.3289 , 0.3274 , 0.3264 , 0.3262 , 0.3257 ,\n",
       "            0.3228 , 0.3206 , 0.3186 , 0.318  , 0.3176 , 0.3174 , 0.317  ,\n",
       "            0.3154 , 0.3147 , 0.3142 , 0.313  , 0.312  , 0.3115 , 0.311  ,\n",
       "            0.3108 , 0.3093 , 0.309  , 0.3079 , 0.3076 , 0.3066 , 0.3    ,\n",
       "            0.2986 , 0.2983 , 0.296  , 0.2925 , 0.291  , 0.2908 , 0.2903 ,\n",
       "            0.2878 , 0.2876 , 0.2815 , 0.281  , 0.2786 , 0.2769 , 0.274  ,\n",
       "            0.2573 , 0.2537 , 0.2394 , 0.2161 , 0.2114 , 0.1924 , 0.1844 ,\n",
       "            0.1814 , 0.1812 , 0.1761 , 0.1759 , 0.1725 , 0.17   , 0.169  ,\n",
       "            0.1615 , 0.1495 , 0.1472 , 0.1443 , 0.1412 , 0.1367 , 0.1207 ,\n",
       "            0.07306, 0.0612 , 0.05176], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04237288, dtype=float32),\n",
       "    'tpr': array(0.54545456, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.16949153, 0.16949153,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.1779661 , 0.1779661 ,\n",
       "            0.1779661 , 0.18644068, 0.19491525, 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22033899, 0.22033899,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.6515151 , 0.65909094, 0.67424244, 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.70454544, 0.70454544, 0.719697  ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.8030303 , 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8636364 ,\n",
       "            0.8636364 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.8984 , 0.8716 , 0.8633 , 0.855  , 0.8545 , 0.8535 ,\n",
       "            0.8525 , 0.8516 , 0.8374 , 0.8267 , 0.82   , 0.813  , 0.8096 ,\n",
       "            0.801  , 0.8003 , 0.7944 , 0.789  , 0.787  , 0.778  , 0.777  ,\n",
       "            0.775  , 0.7744 , 0.771  , 0.764  , 0.7593 , 0.758  , 0.7573 ,\n",
       "            0.7563 , 0.75   , 0.748  , 0.7446 , 0.741  , 0.737  , 0.7363 ,\n",
       "            0.729  , 0.7163 , 0.7085 , 0.707  , 0.695  , 0.689  , 0.6836 ,\n",
       "            0.663  , 0.6587 , 0.6553 , 0.6523 , 0.6465 , 0.6426 , 0.638  ,\n",
       "            0.6167 , 0.6147 , 0.6133 , 0.5913 , 0.5796 , 0.575  , 0.5654 ,\n",
       "            0.5464 , 0.5425 , 0.538  , 0.5366 , 0.5337 , 0.529  , 0.5176 ,\n",
       "            0.513  , 0.512  , 0.511  , 0.509  , 0.5083 , 0.5063 , 0.503  ,\n",
       "            0.5024 , 0.502  , 0.5005 , 0.497  , 0.4956 , 0.4902 , 0.4873 ,\n",
       "            0.485  , 0.4814 , 0.4805 , 0.4785 , 0.4766 , 0.4746 , 0.474  ,\n",
       "            0.4739 , 0.4734 , 0.4731 , 0.4724 , 0.4714 , 0.4707 , 0.4646 ,\n",
       "            0.4644 , 0.4622 , 0.46   , 0.4585 , 0.4565 , 0.4546 , 0.4543 ,\n",
       "            0.4536 , 0.453  , 0.4517 , 0.4512 , 0.451  , 0.4497 , 0.4492 ,\n",
       "            0.4426 , 0.4395 , 0.439  , 0.438  , 0.435  , 0.4343 , 0.434  ,\n",
       "            0.4336 , 0.4326 , 0.432  , 0.4304 , 0.43   , 0.4287 , 0.4265 ,\n",
       "            0.4246 , 0.4238 , 0.4233 , 0.4207 , 0.4167 , 0.4158 , 0.412  ,\n",
       "            0.4072 , 0.407  , 0.4043 , 0.4033 , 0.4004 , 0.4    , 0.3972 ,\n",
       "            0.3962 , 0.396  , 0.3955 , 0.3938 , 0.3906 , 0.389  , 0.3882 ,\n",
       "            0.388  , 0.3848 , 0.381  , 0.3804 , 0.3787 , 0.3772 , 0.3735 ,\n",
       "            0.3706 , 0.369  , 0.3682 , 0.3665 , 0.3538 , 0.3523 , 0.3518 ,\n",
       "            0.3499 , 0.3489 , 0.3442 , 0.3438 , 0.3433 , 0.3418 , 0.341  ,\n",
       "            0.3408 , 0.338  , 0.3376 , 0.3364 , 0.3337 , 0.3325 , 0.3323 ,\n",
       "            0.331  , 0.3281 , 0.327  , 0.3262 , 0.3242 , 0.3237 , 0.3218 ,\n",
       "            0.3215 , 0.3213 , 0.3206 , 0.3203 , 0.3198 , 0.3186 , 0.318  ,\n",
       "            0.3176 , 0.313  , 0.3123 , 0.3118 , 0.3115 , 0.3105 , 0.31   ,\n",
       "            0.309  , 0.3079 , 0.3062 , 0.306  , 0.3052 , 0.3022 , 0.2993 ,\n",
       "            0.2974 , 0.2961 , 0.2932 , 0.2917 , 0.2908 , 0.2905 , 0.2903 ,\n",
       "            0.288  , 0.2861 , 0.2852 , 0.2842 , 0.2832 , 0.2751 , 0.2734 ,\n",
       "            0.273  , 0.2537 , 0.2485 , 0.2346 , 0.2109 , 0.2073 , 0.186  ,\n",
       "            0.1781 , 0.1748 , 0.1747 , 0.1708 , 0.1696 , 0.1683 , 0.1641 ,\n",
       "            0.1624 , 0.1548 , 0.1454 , 0.1406 , 0.1377 , 0.1326 , 0.1142 ,\n",
       "            0.06757, 0.05664, 0.047  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04237288, dtype=float32),\n",
       "    'tpr': array(0.5984849, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.11864407, 0.11864407, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.16949153, 0.16949153,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.19491525, 0.19491525, 0.21186441,\n",
       "            0.21186441, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21969697, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.4469697 , 0.4469697 , 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6287879 , 0.6363636 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.75757575, 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9165 , 0.8936 , 0.8853 , 0.878  , 0.8774 , 0.876  ,\n",
       "            0.8755 , 0.875  , 0.862  , 0.851  , 0.845  , 0.8374 , 0.8354 ,\n",
       "            0.827  , 0.8267 , 0.82   , 0.8145 , 0.814  , 0.8047 , 0.8037 ,\n",
       "            0.802  , 0.801  , 0.7983 , 0.7905 , 0.7866 , 0.784  , 0.7837 ,\n",
       "            0.7773 , 0.7754 , 0.772  , 0.7676 , 0.764  , 0.7637 , 0.7563 ,\n",
       "            0.7427 , 0.736  , 0.7334 , 0.7227 , 0.7163 , 0.7104 , 0.6895 ,\n",
       "            0.6836 , 0.6807 , 0.6787 , 0.673  , 0.6685 , 0.6636 , 0.6406 ,\n",
       "            0.639  , 0.6377 , 0.6147 , 0.6006 , 0.5977 , 0.586  , 0.571  ,\n",
       "            0.563  , 0.5586 , 0.5557 , 0.5522 , 0.5474 , 0.539  , 0.531  ,\n",
       "            0.5293 , 0.5283 , 0.526  , 0.5225 , 0.522  , 0.52   , 0.5195 ,\n",
       "            0.5176 , 0.517  , 0.515  , 0.5073 , 0.506  , 0.5054 , 0.5024 ,\n",
       "            0.501  , 0.4998 , 0.497  , 0.4932 , 0.4927 , 0.4907 , 0.4905 ,\n",
       "            0.4902 , 0.489  , 0.4883 , 0.4878 , 0.4868 , 0.4858 , 0.4856 ,\n",
       "            0.4849 , 0.4778 , 0.4766 , 0.4746 , 0.4739 , 0.4722 , 0.471  ,\n",
       "            0.4702 , 0.4695 , 0.466  , 0.4653 , 0.465  , 0.4636 , 0.463  ,\n",
       "            0.4626 , 0.4607 , 0.458  , 0.4578 , 0.4512 , 0.449  , 0.4478 ,\n",
       "            0.4475 , 0.4453 , 0.445  , 0.444  , 0.4434 , 0.442  , 0.4382 ,\n",
       "            0.4368 , 0.4358 , 0.4353 , 0.4265 , 0.4255 , 0.4224 , 0.4177 ,\n",
       "            0.4172 , 0.417  , 0.413  , 0.4126 , 0.4094 , 0.4053 , 0.404  ,\n",
       "            0.4036 , 0.4023 , 0.402  , 0.398  , 0.3962 , 0.3938 , 0.3936 ,\n",
       "            0.392  , 0.3901 , 0.3894 , 0.3853 , 0.3818 , 0.3809 , 0.379  ,\n",
       "            0.3782 , 0.3777 , 0.377  , 0.3765 , 0.3604 , 0.36   , 0.3599 ,\n",
       "            0.3584 , 0.3555 , 0.353  , 0.352  , 0.3513 , 0.3506 , 0.3472 ,\n",
       "            0.3464 , 0.343  , 0.3418 , 0.3413 , 0.3396 , 0.338  , 0.3347 ,\n",
       "            0.3345 , 0.334  , 0.3306 , 0.3303 , 0.33   , 0.3293 , 0.329  ,\n",
       "            0.3289 , 0.3271 , 0.3252 , 0.323  , 0.322  , 0.3206 , 0.319  ,\n",
       "            0.3188 , 0.3186 , 0.3176 , 0.3171 , 0.315  , 0.3145 , 0.3118 ,\n",
       "            0.311  , 0.3105 , 0.3098 , 0.309  , 0.3074 , 0.306  , 0.304  ,\n",
       "            0.3013 , 0.299  , 0.2966 , 0.2964 , 0.2961 , 0.293  , 0.2927 ,\n",
       "            0.292  , 0.2917 , 0.2915 , 0.2908 , 0.2844 , 0.274  , 0.2732 ,\n",
       "            0.2725 , 0.2559 , 0.2471 , 0.2339 , 0.2065 , 0.2035 , 0.1812 ,\n",
       "            0.1729 , 0.1698 , 0.1696 , 0.1659 , 0.1644 , 0.1636 , 0.1588 ,\n",
       "            0.1577 , 0.1503 , 0.1404 , 0.1359 , 0.1329 , 0.1328 , 0.1276 ,\n",
       "            0.1093 , 0.0627 , 0.0537 , 0.04297], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04237288, dtype=float32),\n",
       "    'tpr': array(0.68939394, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.1779661 , 0.1779661 , 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.31355932, 0.33050847, 0.33898306, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.69491524, 0.7033898 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37121212, 0.37878788, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46212122, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75      , 0.75757575, 0.75757575, 0.7651515 ,\n",
       "            0.7651515 , 0.77272725, 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.8030303 , 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9263 , 0.9053 , 0.8965 , 0.89   , 0.889  , 0.888  ,\n",
       "            0.8877 , 0.887  , 0.877  , 0.8633 , 0.86   , 0.851  , 0.85   ,\n",
       "            0.849  , 0.8423 , 0.842  , 0.831  , 0.829  , 0.826  , 0.8203 ,\n",
       "            0.818  , 0.8164 , 0.814  , 0.8125 , 0.8027 , 0.802  , 0.7983 ,\n",
       "            0.7964 , 0.796  , 0.792  , 0.7896 , 0.7856 , 0.7793 , 0.779  ,\n",
       "            0.7725 , 0.7544 , 0.7495 , 0.744  , 0.739  , 0.7324 , 0.725  ,\n",
       "            0.7    , 0.6943 , 0.6924 , 0.6904 , 0.6885 , 0.683  , 0.676  ,\n",
       "            0.6504 , 0.65   , 0.6484 , 0.623  , 0.609  , 0.6055 , 0.5933 ,\n",
       "            0.5894 , 0.5737 , 0.567  , 0.5654 , 0.5586 , 0.5537 , 0.5503 ,\n",
       "            0.5474 , 0.543  , 0.5425 , 0.542  , 0.5415 , 0.5396 , 0.5386 ,\n",
       "            0.5356 , 0.535  , 0.534  , 0.533  , 0.532  , 0.5317 , 0.523  ,\n",
       "            0.522  , 0.52   , 0.519  , 0.517  , 0.5166 , 0.5127 , 0.5083 ,\n",
       "            0.508  , 0.507  , 0.506  , 0.505  , 0.5044 , 0.504  , 0.5024 ,\n",
       "            0.501  , 0.4998 , 0.4985 , 0.4944 , 0.492  , 0.4897 , 0.4858 ,\n",
       "            0.485  , 0.4824 , 0.4822 , 0.48   , 0.4756 , 0.4744 , 0.473  ,\n",
       "            0.4722 , 0.4717 , 0.4714 , 0.471  , 0.47   , 0.4678 , 0.4583 ,\n",
       "            0.4575 , 0.456  , 0.455  , 0.4524 , 0.4514 , 0.4504 , 0.449  ,\n",
       "            0.4487 , 0.448  , 0.443  , 0.441  , 0.4373 , 0.434  , 0.431  ,\n",
       "            0.4265 , 0.4263 , 0.424  , 0.4238 , 0.4226 , 0.421  , 0.419  ,\n",
       "            0.4165 , 0.415  , 0.4087 , 0.408  , 0.4072 , 0.4062 , 0.4036 ,\n",
       "            0.3987 , 0.3982 , 0.395  , 0.3945 , 0.3943 , 0.3933 , 0.3867 ,\n",
       "            0.384  , 0.3833 , 0.3823 , 0.3804 , 0.38   , 0.3794 , 0.3774 ,\n",
       "            0.3667 , 0.3657 , 0.3613 , 0.3606 , 0.354  , 0.3538 , 0.3525 ,\n",
       "            0.351  , 0.35   , 0.3467 , 0.3462 , 0.3445 , 0.3438 , 0.3408 ,\n",
       "            0.339  , 0.3376 , 0.3325 , 0.332  , 0.3315 , 0.3298 , 0.3284 ,\n",
       "            0.3281 , 0.3276 , 0.3267 , 0.324  , 0.3235 , 0.3225 , 0.322  ,\n",
       "            0.3179 , 0.3174 , 0.316  , 0.315  , 0.3145 , 0.3127 , 0.3123 ,\n",
       "            0.312  , 0.3096 , 0.3083 , 0.3074 , 0.3066 , 0.305  , 0.3005 ,\n",
       "            0.2988 , 0.2969 , 0.2961 , 0.295  , 0.294  , 0.2922 , 0.2893 ,\n",
       "            0.2888 , 0.2886 , 0.2883 , 0.287  , 0.2837 , 0.2805 , 0.2778 ,\n",
       "            0.2695 , 0.2693 , 0.2542 , 0.2421 , 0.2295 , 0.1998 , 0.1991 ,\n",
       "            0.1746 , 0.166  , 0.1635 , 0.1627 , 0.1602 , 0.1583 , 0.1577 ,\n",
       "            0.1523 , 0.1512 , 0.1443 , 0.1353 , 0.1298 , 0.1279 , 0.127  ,\n",
       "            0.12244, 0.1036 , 0.05792, 0.0504 , 0.03912], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.05084746, dtype=float32),\n",
       "    'tpr': array(0.74242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05932203, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.41525424,\n",
       "            0.42372882, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.47727272,\n",
       "            0.4848485 , 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.65909094, 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.7121212 , 0.719697  , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.8030303 , 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.82575756, 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.938  , 0.9194 , 0.91   , 0.9053 , 0.905  , 0.904  ,\n",
       "            0.903  , 0.9014 , 0.8936 , 0.8794 , 0.8774 , 0.8687 , 0.868  ,\n",
       "            0.8657 , 0.8604 , 0.86   , 0.848  , 0.8477 , 0.8433 , 0.84   ,\n",
       "            0.836  , 0.8354 , 0.8335 , 0.83   , 0.822  , 0.8213 , 0.821  ,\n",
       "            0.818  , 0.815  , 0.814  , 0.8115 , 0.809  , 0.804  , 0.7993 ,\n",
       "            0.799  , 0.7974 , 0.793  , 0.7734 , 0.7695 , 0.763  , 0.7554 ,\n",
       "            0.753  , 0.745  , 0.7188 , 0.7124 , 0.7085 , 0.706  , 0.7036 ,\n",
       "            0.6953 , 0.669  , 0.6685 , 0.6655 , 0.6396 , 0.6265 , 0.621  ,\n",
       "            0.62   , 0.6025 , 0.587  , 0.5864 , 0.583  , 0.5825 , 0.5674 ,\n",
       "            0.565  , 0.5645 , 0.562  , 0.561  , 0.5605 , 0.5596 , 0.556  ,\n",
       "            0.5557 , 0.5547 , 0.5537 , 0.5527 , 0.546  , 0.545  , 0.5435 ,\n",
       "            0.543  , 0.541  , 0.5405 , 0.5386 , 0.5356 , 0.5303 , 0.529  ,\n",
       "            0.5283 , 0.5273 , 0.527  , 0.526  , 0.525  , 0.5225 , 0.521  ,\n",
       "            0.5176 , 0.5146 , 0.5137 , 0.507  , 0.5063 , 0.5034 , 0.503  ,\n",
       "            0.4998 , 0.4937 , 0.4932 , 0.4917 , 0.4912 , 0.4866 , 0.4856 ,\n",
       "            0.4854 , 0.484  , 0.4812 , 0.4797 , 0.479  , 0.474  , 0.4736 ,\n",
       "            0.4727 , 0.4678 , 0.4673 , 0.4656 , 0.4639 , 0.4636 , 0.4634 ,\n",
       "            0.4592 , 0.4585 , 0.4575 , 0.4507 , 0.4487 , 0.44   , 0.439  ,\n",
       "            0.4368 , 0.4336 , 0.4302 , 0.43   , 0.4285 , 0.4268 , 0.4263 ,\n",
       "            0.4219 , 0.417  , 0.4165 , 0.4155 , 0.4124 , 0.4084 , 0.4072 ,\n",
       "            0.402  , 0.401  , 0.3967 , 0.3962 , 0.3958 , 0.3955 , 0.3928 ,\n",
       "            0.3904 , 0.39   , 0.3887 , 0.3872 , 0.381  , 0.3794 , 0.373  ,\n",
       "            0.3708 , 0.3684 , 0.3665 , 0.3662 , 0.362  , 0.3594 , 0.3552 ,\n",
       "            0.355  , 0.3545 , 0.3533 , 0.3523 , 0.3508 , 0.3481 , 0.3455 ,\n",
       "            0.34   , 0.3396 , 0.3384 , 0.3381 , 0.3364 , 0.3352 , 0.3347 ,\n",
       "            0.3318 , 0.3271 , 0.3257 , 0.324  , 0.3235 , 0.3218 , 0.3186 ,\n",
       "            0.318  , 0.3179 , 0.3171 , 0.3167 , 0.3162 , 0.316  , 0.313  ,\n",
       "            0.3108 , 0.309  , 0.3079 , 0.3066 , 0.3057 , 0.3044 , 0.303  ,\n",
       "            0.3027 , 0.3005 , 0.2961 , 0.2954 , 0.295  , 0.2944 , 0.294  ,\n",
       "            0.2927 , 0.2925 , 0.292  , 0.2888 , 0.2864 , 0.279  , 0.278  ,\n",
       "            0.269  , 0.2673 , 0.2542 , 0.2384 , 0.2264 , 0.1968 , 0.1953 ,\n",
       "            0.1694 , 0.1605 , 0.1582 , 0.1573 , 0.1559 , 0.1547 , 0.1523 ,\n",
       "            0.1472 , 0.1461 , 0.1392 , 0.1313 , 0.12476, 0.12463, 0.1219 ,\n",
       "            0.1188 , 0.09845, 0.0537 , 0.04724, 0.03568], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.05084746, dtype=float32),\n",
       "    'tpr': array(0.8030303, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.16101696, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.4915254 , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.65254235,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.43939394,\n",
       "            0.45454547, 0.45454547, 0.46212122, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.82575756, 0.8333333 , 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9478 , 0.931  , 0.923  , 0.9185 , 0.9175 , 0.917  ,\n",
       "            0.9165 , 0.9146 , 0.9087 , 0.894  , 0.8936 , 0.8857 , 0.885  ,\n",
       "            0.8813 , 0.8774 , 0.877  , 0.865  , 0.8643 , 0.8594 , 0.858  ,\n",
       "            0.8535 , 0.853  , 0.852  , 0.847  , 0.841  , 0.8403 , 0.8384 ,\n",
       "            0.837  , 0.8325 , 0.8315 , 0.8306 , 0.827  , 0.8223 , 0.8184 ,\n",
       "            0.818  , 0.816  , 0.8125 , 0.792  , 0.788  , 0.7812 , 0.7734 ,\n",
       "            0.773  , 0.765  , 0.7373 , 0.7324 , 0.7314 , 0.727  , 0.7236 ,\n",
       "            0.723  , 0.7144 , 0.688  , 0.6875 , 0.683  , 0.6816 , 0.6567 ,\n",
       "            0.6445 , 0.6426 , 0.6377 , 0.617  , 0.607  , 0.601  , 0.5986 ,\n",
       "            0.5864 , 0.5835 , 0.582  , 0.58   , 0.578  , 0.5776 , 0.5767 ,\n",
       "            0.576  , 0.575  , 0.574  , 0.571  , 0.5703 , 0.57   , 0.568  ,\n",
       "            0.567  , 0.5654 , 0.564  , 0.563  , 0.5576 , 0.5566 , 0.556  ,\n",
       "            0.552  , 0.5513 , 0.5503 , 0.549  , 0.5474 , 0.547  , 0.5464 ,\n",
       "            0.5454 , 0.5405 , 0.539  , 0.5376 , 0.537  , 0.535  , 0.5303 ,\n",
       "            0.5264 , 0.525  , 0.5195 , 0.5166 , 0.515  , 0.514  , 0.512  ,\n",
       "            0.508  , 0.501  , 0.5005 , 0.4954 , 0.4937 , 0.4905 , 0.489  ,\n",
       "            0.488  , 0.4875 , 0.4873 , 0.484  , 0.4814 , 0.4797 , 0.4792 ,\n",
       "            0.4785 , 0.476  , 0.472  , 0.4717 , 0.4697 , 0.4688 , 0.4678 ,\n",
       "            0.4666 , 0.4573 , 0.4563 , 0.454  , 0.4485 , 0.445  , 0.4434 ,\n",
       "            0.4407 , 0.4368 , 0.4343 , 0.4336 , 0.432  , 0.4294 , 0.427  ,\n",
       "            0.4246 , 0.4243 , 0.423  , 0.42   , 0.4111 , 0.4082 , 0.4075 ,\n",
       "            0.4058 , 0.4006 , 0.3992 , 0.3984 , 0.3982 , 0.3953 , 0.3945 ,\n",
       "            0.3914 , 0.3855 , 0.382  , 0.3818 , 0.3813 , 0.3792 , 0.372  ,\n",
       "            0.3704 , 0.3696 , 0.3674 , 0.367  , 0.365  , 0.3616 , 0.3604 ,\n",
       "            0.3596 , 0.356  , 0.3545 , 0.3503 , 0.3499 , 0.3489 , 0.3484 ,\n",
       "            0.3464 , 0.3457 , 0.3452 , 0.3435 , 0.3396 , 0.3384 , 0.3342 ,\n",
       "            0.332  , 0.3298 , 0.3245 , 0.3237 , 0.3235 , 0.323  , 0.3218 ,\n",
       "            0.3208 , 0.3186 , 0.3157 , 0.3147 , 0.314  , 0.3135 , 0.3123 ,\n",
       "            0.3079 , 0.3076 , 0.3064 , 0.305  , 0.3042 , 0.3027 , 0.2983 ,\n",
       "            0.297  , 0.2964 , 0.2961 , 0.2957 , 0.2944 , 0.292  , 0.2888 ,\n",
       "            0.2874 , 0.2786 , 0.2769 , 0.2678 , 0.265  , 0.264  , 0.2544 ,\n",
       "            0.2346 , 0.2233 , 0.1927 , 0.19   , 0.1636 , 0.1544 , 0.1525 ,\n",
       "            0.1514 , 0.151  , 0.15   , 0.1464 , 0.1414 , 0.1404 , 0.1337 ,\n",
       "            0.1267 , 0.1204 , 0.1192 , 0.11633, 0.1142 , 0.0932 , 0.04932,\n",
       "            0.0441 , 0.0323 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.06779661, dtype=float32),\n",
       "    'tpr': array(0.8484849, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.1440678 , 0.15254237, 0.15254237,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.1779661 , 0.18644068, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.30508474, 0.31355932, 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.959  , 0.945  , 0.9375 , 0.934  , 0.9336 , 0.933  ,\n",
       "            0.932  , 0.9316 , 0.9307 , 0.9253 , 0.912  , 0.9116 , 0.905  ,\n",
       "            0.904  , 0.901  , 0.8975 , 0.897  , 0.886  , 0.8857 , 0.8813 ,\n",
       "            0.8794 , 0.8755 , 0.875  , 0.8735 , 0.8696 , 0.8633 , 0.863  ,\n",
       "            0.8613 , 0.8604 , 0.856  , 0.855  , 0.8545 , 0.8506 , 0.846  ,\n",
       "            0.8423 , 0.84   , 0.837  , 0.8174 , 0.8135 , 0.807  , 0.799  ,\n",
       "            0.796  , 0.7915 , 0.764  , 0.759  , 0.7583 , 0.7544 , 0.7495 ,\n",
       "            0.7456 , 0.7417 , 0.7144 , 0.711  , 0.7046 , 0.6836 , 0.67   ,\n",
       "            0.6655 , 0.664  , 0.6445 , 0.6313 , 0.6274 , 0.623  , 0.6226 ,\n",
       "            0.607  , 0.6064 , 0.6055 , 0.6045 , 0.6    , 0.5996 , 0.5986 ,\n",
       "            0.598  , 0.5957 , 0.5947 , 0.5933 , 0.5903 , 0.59   , 0.589  ,\n",
       "            0.588  , 0.587  , 0.586  , 0.5806 , 0.5786 , 0.576  , 0.5747 ,\n",
       "            0.574  , 0.5737 , 0.5728 , 0.5703 , 0.5674 , 0.567  , 0.566  ,\n",
       "            0.5635 , 0.5615 , 0.56   , 0.5586 , 0.5537 , 0.5483 , 0.5474 ,\n",
       "            0.545  , 0.5396 , 0.538  , 0.5376 , 0.537  , 0.536  , 0.5356 ,\n",
       "            0.526  , 0.525  , 0.5195 , 0.5186 , 0.515  , 0.511  , 0.5107 ,\n",
       "            0.5103 , 0.51   , 0.508  , 0.507  , 0.503  , 0.4983 , 0.4944 ,\n",
       "            0.494  , 0.4917 , 0.49   , 0.4897 , 0.4888 , 0.487  , 0.4802 ,\n",
       "            0.478  , 0.4763 , 0.4739 , 0.4731 , 0.4675 , 0.4644 , 0.4612 ,\n",
       "            0.4575 , 0.4558 , 0.4526 , 0.449  , 0.4458 , 0.4402 , 0.4377 ,\n",
       "            0.4355 , 0.4329 , 0.4314 , 0.4292 , 0.429  , 0.4246 , 0.4236 ,\n",
       "            0.4219 , 0.4165 , 0.4148 , 0.414  , 0.4097 , 0.4092 , 0.4055 ,\n",
       "            0.4045 , 0.4033 , 0.3987 , 0.3977 , 0.3882 , 0.387  , 0.3867 ,\n",
       "            0.3855 , 0.3833 , 0.3809 , 0.3782 , 0.3752 , 0.3733 , 0.368  ,\n",
       "            0.3672 , 0.3655 , 0.3633 , 0.3608 , 0.3606 , 0.3599 , 0.359  ,\n",
       "            0.3584 , 0.3562 , 0.3496 , 0.3477 , 0.343  , 0.3423 , 0.3384 ,\n",
       "            0.3376 , 0.3357 , 0.3347 , 0.3342 , 0.3328 , 0.328  , 0.3267 ,\n",
       "            0.3254 , 0.3247 , 0.3245 , 0.3232 , 0.3223 , 0.3196 , 0.3193 ,\n",
       "            0.319  , 0.3184 , 0.3179 , 0.3171 , 0.3167 , 0.3096 , 0.3088 ,\n",
       "            0.3079 , 0.3076 , 0.306  , 0.3057 , 0.3054 , 0.3035 , 0.2998 ,\n",
       "            0.2974 , 0.2896 , 0.2878 , 0.2761 , 0.2683 , 0.2651 , 0.2634 ,\n",
       "            0.259  , 0.2338 , 0.2229 , 0.1896 , 0.1858 , 0.1592 , 0.1498 ,\n",
       "            0.1482 , 0.147  , 0.1467 , 0.1458 , 0.1417 , 0.1365 , 0.1361 ,\n",
       "            0.1298 , 0.1223 , 0.11615, 0.115  , 0.1122 , 0.1097 , 0.0891 ,\n",
       "            0.0457 , 0.04184, 0.02937], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.07627118, dtype=float32),\n",
       "    'tpr': array(0.8863636, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.36363637, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.6060606 , 0.6212121 , 0.6287879 ,\n",
       "            0.6439394 , 0.6515151 , 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.77272725, 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9653 , 0.9526 , 0.9463 , 0.944  , 0.943  , 0.9424 ,\n",
       "            0.9414 , 0.941  , 0.9395 , 0.936  , 0.924  , 0.923  , 0.917  ,\n",
       "            0.916  , 0.9116 , 0.91   , 0.9097 , 0.9    , 0.8975 , 0.8936 ,\n",
       "            0.893  , 0.8896 , 0.888  , 0.8877 , 0.882  , 0.878  , 0.877  ,\n",
       "            0.875  , 0.8745 , 0.869  , 0.8687 , 0.8647 , 0.861  , 0.8584 ,\n",
       "            0.858  , 0.8535 , 0.853  , 0.832  , 0.829  , 0.822  , 0.8164 ,\n",
       "            0.809  , 0.8086 , 0.78   , 0.7764 , 0.774  , 0.7695 , 0.768  ,\n",
       "            0.759  , 0.732  , 0.7305 , 0.726  , 0.7173 , 0.6987 , 0.6895 ,\n",
       "            0.687  , 0.6787 , 0.657  , 0.6567 , 0.649  , 0.6387 , 0.634  ,\n",
       "            0.63   , 0.6284 , 0.6265 , 0.626  , 0.6235 , 0.622  , 0.6177 ,\n",
       "            0.615  , 0.6143 , 0.614  , 0.613  , 0.6123 , 0.612  , 0.609  ,\n",
       "            0.608  , 0.6064 , 0.606  , 0.6045 , 0.6035 , 0.601  , 0.5986 ,\n",
       "            0.597  , 0.593  , 0.5913 , 0.589  , 0.5884 , 0.587  , 0.585  ,\n",
       "            0.5806 , 0.579  , 0.573  , 0.571  , 0.5703 , 0.563  , 0.5625 ,\n",
       "            0.56   , 0.557  , 0.5557 , 0.552  , 0.5483 , 0.545  , 0.5386 ,\n",
       "            0.537  , 0.533  , 0.5327 , 0.5312 , 0.526  , 0.5215 , 0.5195 ,\n",
       "            0.513  , 0.509  , 0.5083 , 0.5063 , 0.504  , 0.4973 , 0.4968 ,\n",
       "            0.494  , 0.4932 , 0.4917 , 0.4902 , 0.488  , 0.4841 , 0.4834 ,\n",
       "            0.4812 , 0.4727 , 0.4714 , 0.4668 , 0.462  , 0.454  , 0.4539 ,\n",
       "            0.4521 , 0.4478 , 0.4453 , 0.443  , 0.4392 , 0.439  , 0.4382 ,\n",
       "            0.438  , 0.4287 , 0.4282 , 0.4277 , 0.4177 , 0.4175 , 0.4167 ,\n",
       "            0.4148 , 0.4143 , 0.4124 , 0.4119 , 0.4111 , 0.4104 , 0.4075 ,\n",
       "            0.3992 , 0.399  , 0.3965 , 0.3914 , 0.39   , 0.3894 , 0.3892 ,\n",
       "            0.3843 , 0.3828 , 0.3794 , 0.3784 , 0.3782 , 0.3765 , 0.372  ,\n",
       "            0.3699 , 0.3696 , 0.3694 , 0.368  , 0.3672 , 0.3616 , 0.3582 ,\n",
       "            0.3574 , 0.3496 , 0.345  , 0.3442 , 0.344  , 0.3433 , 0.3428 ,\n",
       "            0.339  , 0.3381 , 0.3362 , 0.3357 , 0.335  , 0.3296 , 0.329  ,\n",
       "            0.3281 , 0.326  , 0.3252 , 0.3242 , 0.3232 , 0.3225 , 0.3218 ,\n",
       "            0.3203 , 0.32   , 0.318  , 0.317  , 0.3147 , 0.312  , 0.3115 ,\n",
       "            0.306  , 0.3052 , 0.305  , 0.3015 , 0.301  , 0.2998 , 0.2903 ,\n",
       "            0.288  , 0.2747 , 0.27   , 0.2632 , 0.2615 , 0.258  , 0.2302 ,\n",
       "            0.2194 , 0.1871 , 0.1819 , 0.1545 , 0.1451 , 0.1437 , 0.1434 ,\n",
       "            0.1431 , 0.142  , 0.137  , 0.1321 , 0.1313 , 0.1249 , 0.1196 ,\n",
       "            0.1142 , 0.1103 , 0.1074 , 0.10706, 0.0845 , 0.04248, 0.03897,\n",
       "            0.02681], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.11016949, dtype=float32),\n",
       "    'tpr': array(0.90909094, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.10169491, 0.11016949, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.1440678 , 0.1440678 , 0.1440678 , 0.15254237, 0.15254237,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.27272728, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6515151 , 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9727 , 0.9614 , 0.956  , 0.9546 , 0.9536 , 0.9526 ,\n",
       "            0.9517 , 0.951  , 0.95   , 0.9478 , 0.9365 , 0.9355 , 0.9307 ,\n",
       "            0.93   , 0.926  , 0.925  , 0.9243 , 0.9155 , 0.9126 , 0.9097 ,\n",
       "            0.9087 , 0.9062 , 0.905  , 0.904  , 0.8984 , 0.8955 , 0.8936 ,\n",
       "            0.8926 , 0.8916 , 0.887  , 0.8867 , 0.8857 , 0.8823 , 0.8784 ,\n",
       "            0.877  , 0.872  , 0.8516 , 0.8486 , 0.8413 , 0.8364 , 0.83   ,\n",
       "            0.8276 , 0.802  , 0.799  , 0.796  , 0.791  , 0.79   , 0.7817 ,\n",
       "            0.778  , 0.755  , 0.7524 , 0.7476 , 0.737  , 0.721  , 0.7124 ,\n",
       "            0.71   , 0.7007 , 0.6787 , 0.678  , 0.6685 , 0.6606 , 0.653  ,\n",
       "            0.651  , 0.649  , 0.6475 , 0.646  , 0.645  , 0.644  , 0.636  ,\n",
       "            0.635  , 0.6343 , 0.6333 , 0.633  , 0.6323 , 0.632  , 0.631  ,\n",
       "            0.626  , 0.625  , 0.6245 , 0.6235 , 0.621  , 0.62   , 0.619  ,\n",
       "            0.614  , 0.6113 , 0.6094 , 0.6084 , 0.608  , 0.6064 , 0.6006 ,\n",
       "            0.599  , 0.592  , 0.5913 , 0.5854 , 0.582  , 0.5815 , 0.5767 ,\n",
       "            0.575  , 0.5747 , 0.5703 , 0.5693 , 0.5635 , 0.5576 , 0.556  ,\n",
       "            0.554  , 0.5527 , 0.5513 , 0.542  , 0.5415 , 0.534  , 0.527  ,\n",
       "            0.524  , 0.5225 , 0.521  , 0.5195 , 0.5176 , 0.5137 , 0.5073 ,\n",
       "            0.507  , 0.5063 , 0.505  , 0.5005 , 0.4978 , 0.497  , 0.489  ,\n",
       "            0.4863 , 0.479  , 0.478  , 0.4673 , 0.465  , 0.4592 , 0.453  ,\n",
       "            0.4526 , 0.4521 , 0.4517 , 0.4463 , 0.4448 , 0.4414 , 0.4402 ,\n",
       "            0.4382 , 0.4312 , 0.429  , 0.4265 , 0.4248 , 0.4246 , 0.4238 ,\n",
       "            0.423  , 0.4214 , 0.4207 , 0.413  , 0.412  , 0.4116 , 0.4092 ,\n",
       "            0.4033 , 0.4023 , 0.3958 , 0.3943 , 0.393  , 0.39   , 0.3894 ,\n",
       "            0.388  , 0.3872 , 0.386  , 0.3823 , 0.3804 , 0.3796 , 0.3782 ,\n",
       "            0.377  , 0.3762 , 0.3684 , 0.3652 , 0.3633 , 0.3538 , 0.3533 ,\n",
       "            0.353  , 0.3513 , 0.347  , 0.3467 , 0.3464 , 0.3462 , 0.3423 ,\n",
       "            0.34   , 0.3376 , 0.3364 , 0.3354 , 0.3335 , 0.3315 , 0.328  ,\n",
       "            0.327  , 0.3267 , 0.3262 , 0.3237 , 0.3232 , 0.323  , 0.321  ,\n",
       "            0.3206 , 0.3203 , 0.3196 , 0.3179 , 0.3113 , 0.308  , 0.3066 ,\n",
       "            0.306  , 0.3037 , 0.3032 , 0.2957 , 0.2886 , 0.274  , 0.2712 ,\n",
       "            0.263  , 0.2622 , 0.2605 , 0.2294 , 0.2185 , 0.1844 , 0.1781 ,\n",
       "            0.1505 , 0.1409 , 0.1404 , 0.1398 , 0.1395 , 0.1377 , 0.1327 ,\n",
       "            0.1283 , 0.1273 , 0.12115, 0.11615, 0.111  , 0.1063 , 0.10376,\n",
       "            0.1036 , 0.0808 , 0.0395 , 0.037  , 0.02452], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.11864407, dtype=float32),\n",
       "    'tpr': array(0.9318182, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.18644068, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.61864406, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6287879 , 0.6287879 , 0.6439394 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.780303  , 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8560606 , 0.8712121 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.9166667 , 0.9166667 , 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.977  , 0.968  , 0.963  , 0.9614 , 0.9604 , 0.96   ,\n",
       "            0.959  , 0.9585 , 0.9575 , 0.955  , 0.946  , 0.944  , 0.941  ,\n",
       "            0.94   , 0.935  , 0.9346 , 0.9263 , 0.923  , 0.921  , 0.9194 ,\n",
       "            0.918  , 0.9165 , 0.9146 , 0.9097 , 0.9077 , 0.9053 , 0.905  ,\n",
       "            0.9033 , 0.9    , 0.8984 , 0.898  , 0.895  , 0.8906 , 0.89   ,\n",
       "            0.886  , 0.885  , 0.865  , 0.863  , 0.8555 , 0.851  , 0.8457 ,\n",
       "            0.8384 , 0.817  , 0.8154 , 0.8105 , 0.806  , 0.8057 , 0.798  ,\n",
       "            0.789  , 0.772  , 0.7686 , 0.763  , 0.7476 , 0.737  , 0.734  ,\n",
       "            0.7266 , 0.7153 , 0.701  , 0.6924 , 0.6885 , 0.677  , 0.672  ,\n",
       "            0.67   , 0.6685 , 0.667  , 0.6655 , 0.664  , 0.6626 , 0.6577 ,\n",
       "            0.657  , 0.655  , 0.6533 , 0.6523 , 0.652  , 0.6514 , 0.651  ,\n",
       "            0.648  , 0.6445 , 0.6436 , 0.6426 , 0.6416 , 0.636  , 0.635  ,\n",
       "            0.632  , 0.631  , 0.6304 , 0.6294 , 0.6284 , 0.628  , 0.6255 ,\n",
       "            0.621  , 0.6196 , 0.614  , 0.612  , 0.61   , 0.6084 , 0.605  ,\n",
       "            0.6035 , 0.594  , 0.5938 , 0.593  , 0.5825 , 0.5815 , 0.5786 ,\n",
       "            0.576  , 0.5747 , 0.573  , 0.5723 , 0.562  , 0.557  , 0.5557 ,\n",
       "            0.541  , 0.5386 , 0.535  , 0.5347 , 0.534  , 0.524  , 0.518  ,\n",
       "            0.5176 , 0.5166 , 0.515  , 0.513  , 0.512  , 0.5117 , 0.507  ,\n",
       "            0.5063 , 0.506  , 0.5    , 0.4946 , 0.485  , 0.4822 , 0.4775 ,\n",
       "            0.4705 , 0.4692 , 0.4678 , 0.467  , 0.4658 , 0.4565 , 0.4563 ,\n",
       "            0.4536 , 0.4475 , 0.4453 , 0.4443 , 0.441  , 0.4407 , 0.4385 ,\n",
       "            0.4377 , 0.4272 , 0.4268 , 0.4263 , 0.4253 , 0.4248 , 0.4233 ,\n",
       "            0.421  , 0.415  , 0.4143 , 0.414  , 0.405  , 0.4016 , 0.3994 ,\n",
       "            0.3958 , 0.3945 , 0.393  , 0.391  , 0.3906 , 0.3884 , 0.3882 ,\n",
       "            0.387  , 0.3857 , 0.3794 , 0.3784 , 0.3657 , 0.3635 , 0.362  ,\n",
       "            0.3613 , 0.3608 , 0.3564 , 0.3542 , 0.353  , 0.3481 , 0.3462 ,\n",
       "            0.3455 , 0.3452 , 0.343  , 0.342  , 0.3418 , 0.3408 , 0.3389 ,\n",
       "            0.3386 , 0.337  , 0.3352 , 0.331  , 0.3281 , 0.3262 , 0.326  ,\n",
       "            0.325  , 0.3235 , 0.3228 , 0.3215 , 0.32   , 0.3147 , 0.3135 ,\n",
       "            0.3076 , 0.306  , 0.3042 , 0.3037 , 0.299  , 0.288  , 0.273  ,\n",
       "            0.2715 , 0.26   , 0.2595 , 0.258  , 0.2249 , 0.2137 , 0.1819 ,\n",
       "            0.1736 , 0.1453 , 0.1371 , 0.1368 , 0.1357 , 0.134  , 0.1326 ,\n",
       "            0.1276 , 0.1241 , 0.122  , 0.1158 , 0.1136 , 0.10913, 0.10126,\n",
       "            0.1009 , 0.0981 , 0.076  , 0.03635, 0.03403, 0.02208],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.11864407, dtype=float32),\n",
       "    'tpr': array(0.9469697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11016949, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3644068 , 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44915253, 0.45762712, 0.4661017 , 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.9015151 , 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.92424244, 0.92424244,\n",
       "            0.92424244, 0.92424244, 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9805 , 0.9717 , 0.9673 , 0.967  , 0.9653 , 0.965  ,\n",
       "            0.964  , 0.9624 , 0.961  , 0.9526 , 0.95   , 0.9478 , 0.9473 ,\n",
       "            0.943  , 0.942  , 0.9414 , 0.9346 , 0.9297 , 0.929  , 0.9263 ,\n",
       "            0.926  , 0.9224 , 0.9175 , 0.917  , 0.9146 , 0.913  , 0.911  ,\n",
       "            0.909  , 0.9067 , 0.906  , 0.9033 , 0.901  , 0.9    , 0.8994 ,\n",
       "            0.897  , 0.893  , 0.8745 , 0.872  , 0.8643 , 0.8623 , 0.8574 ,\n",
       "            0.8467 , 0.8276 , 0.8267 , 0.821  , 0.8174 , 0.8154 , 0.809  ,\n",
       "            0.798  , 0.784  , 0.7793 , 0.772  , 0.7563 , 0.7544 , 0.747  ,\n",
       "            0.7397 , 0.7236 , 0.723  , 0.708  , 0.699  , 0.693  , 0.6904 ,\n",
       "            0.689  , 0.688  , 0.686  , 0.6826 , 0.6807 , 0.68   , 0.679  ,\n",
       "            0.6753 , 0.673  , 0.6724 , 0.672  , 0.67   , 0.6694 , 0.669  ,\n",
       "            0.667  , 0.663  , 0.6616 , 0.661  , 0.6577 , 0.6553 , 0.6514 ,\n",
       "            0.651  , 0.6494 , 0.647  , 0.64   , 0.6396 , 0.6377 , 0.6343 ,\n",
       "            0.633  , 0.6323 , 0.6313 , 0.628  , 0.627  , 0.6245 , 0.6167 ,\n",
       "            0.6133 , 0.6104 , 0.609  , 0.602  , 0.5986 , 0.5977 , 0.5947 ,\n",
       "            0.593  , 0.5923 , 0.592  , 0.5815 , 0.576  , 0.5723 , 0.5586 ,\n",
       "            0.552  , 0.5493 , 0.548  , 0.5474 , 0.5396 , 0.538  , 0.5327 ,\n",
       "            0.532  , 0.5303 , 0.5273 , 0.521  , 0.52   , 0.5166 , 0.514  ,\n",
       "            0.5137 , 0.5117 , 0.509  , 0.508  , 0.4956 , 0.4946 , 0.4832 ,\n",
       "            0.48   , 0.4792 , 0.4785 , 0.4678 , 0.467  , 0.463  , 0.4622 ,\n",
       "            0.4592 , 0.4556 , 0.4517 , 0.4485 , 0.4468 , 0.4443 , 0.4355 ,\n",
       "            0.432  , 0.4312 , 0.4285 , 0.4275 , 0.4265 , 0.422  , 0.4214 ,\n",
       "            0.421  , 0.419  , 0.4163 , 0.4148 , 0.4097 , 0.4092 , 0.407  ,\n",
       "            0.3965 , 0.3955 , 0.395  , 0.3943 , 0.392  , 0.39   , 0.384  ,\n",
       "            0.3833 , 0.3777 , 0.376  , 0.365  , 0.3647 , 0.3638 , 0.362  ,\n",
       "            0.3567 , 0.3542 , 0.354  , 0.35   , 0.3477 , 0.344  , 0.343  ,\n",
       "            0.3423 , 0.3416 , 0.339  , 0.3386 , 0.338  , 0.3374 , 0.3335 ,\n",
       "            0.3306 , 0.3286 , 0.326  , 0.3245 , 0.322  , 0.3198 , 0.3196 ,\n",
       "            0.3164 , 0.3157 , 0.3127 , 0.3115 , 0.311  , 0.304  , 0.301  ,\n",
       "            0.2957 , 0.2954 , 0.2869 , 0.2744 , 0.268  , 0.2559 , 0.2556 ,\n",
       "            0.2542 , 0.2191 , 0.2076 , 0.1794 , 0.1688 , 0.1398 , 0.1348 ,\n",
       "            0.1337 , 0.1304 , 0.1287 , 0.1272 , 0.1222 , 0.1201 , 0.1166 ,\n",
       "            0.11145, 0.1099 , 0.1078 , 0.0993 , 0.09534, 0.0925 , 0.0712 ,\n",
       "            0.0336 , 0.03137, 0.01991], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.11864407, dtype=float32),\n",
       "    'tpr': array(0.9621212, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.82575756, 0.8333333 , 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.92424244, 0.92424244,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.984  , 0.976  , 0.972  , 0.9707 , 0.9697 , 0.969  ,\n",
       "            0.9688 , 0.968  , 0.967  , 0.9595 , 0.9565 , 0.955  , 0.9546 ,\n",
       "            0.9507 , 0.949  , 0.9487 , 0.943  , 0.938  , 0.9375 , 0.935  ,\n",
       "            0.9346 , 0.931  , 0.9272 , 0.9263 , 0.9243 , 0.923  , 0.9204 ,\n",
       "            0.919  , 0.9165 , 0.9155 , 0.9136 , 0.912  , 0.91   , 0.9097 ,\n",
       "            0.9077 , 0.9033 , 0.8853 , 0.884  , 0.8755 , 0.875  , 0.8706 ,\n",
       "            0.857  , 0.8423 , 0.8394 , 0.8335 , 0.8315 , 0.828  , 0.8228 ,\n",
       "            0.8096 , 0.8    , 0.793  , 0.7847 , 0.776  , 0.7676 , 0.7607 ,\n",
       "            0.756  , 0.7466 , 0.7363 , 0.729  , 0.716  , 0.7134 , 0.712  ,\n",
       "            0.711  , 0.709  , 0.705  , 0.7046 , 0.703  , 0.6987 , 0.6963 ,\n",
       "            0.6943 , 0.693  , 0.6924 , 0.691  , 0.69   , 0.6895 , 0.6885 ,\n",
       "            0.685  , 0.6836 , 0.6816 , 0.6807 , 0.6772 , 0.676  , 0.674  ,\n",
       "            0.6733 , 0.6724 , 0.6675 , 0.6616 , 0.661  , 0.6577 , 0.656  ,\n",
       "            0.6553 , 0.65   , 0.649  , 0.6484 , 0.646  , 0.644  , 0.6406 ,\n",
       "            0.64   , 0.6357 , 0.631  , 0.6265 , 0.626  , 0.6206 , 0.6187 ,\n",
       "            0.6157 , 0.614  , 0.6133 , 0.6064 , 0.6035 , 0.5986 , 0.59   ,\n",
       "            0.58   , 0.5674 , 0.566  , 0.5635 , 0.5615 , 0.5566 , 0.5493 ,\n",
       "            0.549  , 0.54   , 0.5386 , 0.537  , 0.535  , 0.5254 , 0.5244 ,\n",
       "            0.5234 , 0.523  , 0.5195 , 0.5186 , 0.5156 , 0.5083 , 0.4946 ,\n",
       "            0.4927 , 0.491  , 0.486  , 0.4795 , 0.472  , 0.4697 , 0.467  ,\n",
       "            0.4644 , 0.4636 , 0.4612 , 0.4568 , 0.4521 , 0.4517 , 0.4485 ,\n",
       "            0.4463 , 0.4397 , 0.4373 , 0.431  , 0.4307 , 0.4304 , 0.4294 ,\n",
       "            0.4277 , 0.4204 , 0.4177 , 0.4175 , 0.416  , 0.4155 , 0.415  ,\n",
       "            0.4124 , 0.4033 , 0.4006 , 0.3994 , 0.3972 , 0.3967 , 0.3965 ,\n",
       "            0.3955 , 0.3901 , 0.3806 , 0.3755 , 0.3735 , 0.3694 , 0.3691 ,\n",
       "            0.3682 , 0.3674 , 0.3662 , 0.3635 , 0.3613 , 0.3594 , 0.3572 ,\n",
       "            0.3552 , 0.3525 , 0.3494 , 0.3462 , 0.3447 , 0.344  , 0.3428 ,\n",
       "            0.3408 , 0.3406 , 0.3386 , 0.3367 , 0.3335 , 0.3284 , 0.3274 ,\n",
       "            0.325  , 0.3228 , 0.3208 , 0.3193 , 0.3174 , 0.3145 , 0.3108 ,\n",
       "            0.3086 , 0.3076 , 0.304  , 0.2998 , 0.2925 , 0.289  , 0.2874 ,\n",
       "            0.277  , 0.2666 , 0.2542 , 0.2534 , 0.2522 , 0.2156 , 0.2039 ,\n",
       "            0.178  , 0.1653 , 0.1356 , 0.1332 , 0.1313 , 0.1262 , 0.1242 ,\n",
       "            0.12317, 0.118  , 0.11694, 0.1122 , 0.1099 , 0.10724, 0.1052 ,\n",
       "            0.0977 , 0.0909 , 0.088  , 0.06744, 0.0312 , 0.02925, 0.01813],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.12711865, dtype=float32),\n",
       "    'tpr': array(0.97727275, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.18644068, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.10606061, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.15151516, 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.5681818 , 0.57575756, 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.6969697 , 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.75      ,\n",
       "            0.75757575, 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9873 , 0.981  , 0.9775 , 0.976  , 0.9756 , 0.9746 ,\n",
       "            0.9736 , 0.9727 , 0.967  , 0.964  , 0.9624 , 0.959  , 0.9575 ,\n",
       "            0.957  , 0.952  , 0.9473 , 0.9453 , 0.945  , 0.9443 , 0.941  ,\n",
       "            0.938  , 0.9365 , 0.9355 , 0.933  , 0.9316 , 0.93   , 0.9277 ,\n",
       "            0.9272 , 0.9253 , 0.924  , 0.9224 , 0.922  , 0.92   , 0.916  ,\n",
       "            0.899  , 0.8975 , 0.89   , 0.8896 , 0.8857 , 0.869  , 0.859  ,\n",
       "            0.8555 , 0.8496 , 0.8477 , 0.8447 , 0.84   , 0.8237 , 0.818  ,\n",
       "            0.8105 , 0.8027 , 0.7964 , 0.782  , 0.779  , 0.775  , 0.7686 ,\n",
       "            0.7544 , 0.7495 , 0.738  , 0.735  , 0.7334 , 0.7324 , 0.731  ,\n",
       "            0.7295 , 0.728  , 0.727  , 0.725  , 0.7227 , 0.721  , 0.72   ,\n",
       "            0.716  , 0.7144 , 0.712  , 0.709  , 0.708  , 0.7065 , 0.705  ,\n",
       "            0.7046 , 0.7    , 0.6997 , 0.698  , 0.6973 , 0.6953 , 0.695  ,\n",
       "            0.6943 , 0.693  , 0.6865 , 0.681  , 0.679  , 0.6772 , 0.673  ,\n",
       "            0.6704 , 0.6685 , 0.665  , 0.664  , 0.6616 , 0.658  , 0.6562 ,\n",
       "            0.652  , 0.65   , 0.6436 , 0.6426 , 0.6377 , 0.636  , 0.6357 ,\n",
       "            0.6353 , 0.6323 , 0.6255 , 0.6226 , 0.6216 , 0.607  , 0.603  ,\n",
       "            0.584  , 0.5835 , 0.5796 , 0.5776 , 0.576  , 0.5703 , 0.5674 ,\n",
       "            0.558  , 0.553  , 0.552  , 0.548  , 0.542  , 0.5405 , 0.5347 ,\n",
       "            0.534  , 0.5337 , 0.533  , 0.5264 , 0.525  , 0.52   , 0.509  ,\n",
       "            0.5063 , 0.4968 , 0.4912 , 0.4858 , 0.483  , 0.4802 , 0.48   ,\n",
       "            0.4717 , 0.471  , 0.4648 , 0.4622 , 0.4578 , 0.4553 , 0.454  ,\n",
       "            0.4514 , 0.4456 , 0.4436 , 0.4414 , 0.436  , 0.4358 , 0.4324 ,\n",
       "            0.43   , 0.4285 , 0.4272 , 0.4236 , 0.4224 , 0.42   , 0.4165 ,\n",
       "            0.4136 , 0.4126 , 0.4111 , 0.4087 , 0.4082 , 0.403  , 0.4014 ,\n",
       "            0.4006 , 0.3877 , 0.3848 , 0.381  , 0.3809 , 0.38   , 0.379  ,\n",
       "            0.3708 , 0.3694 , 0.368  , 0.3672 , 0.3652 , 0.3608 , 0.357  ,\n",
       "            0.3555 , 0.3516 , 0.3477 , 0.3474 , 0.3462 , 0.3442 , 0.344  ,\n",
       "            0.343  , 0.3403 , 0.3357 , 0.3313 , 0.3274 , 0.3264 , 0.3245 ,\n",
       "            0.3242 , 0.3228 , 0.322  , 0.3162 , 0.3157 , 0.3125 , 0.3047 ,\n",
       "            0.3    , 0.2988 , 0.2935 , 0.288  , 0.2798 , 0.2656 , 0.255  ,\n",
       "            0.2507 , 0.2129 , 0.2006 , 0.1763 , 0.1617 , 0.1313 , 0.1312 ,\n",
       "            0.1288 , 0.1222 , 0.1201 , 0.119  , 0.11395, 0.1136 , 0.1082 ,\n",
       "            0.1076 , 0.1058 , 0.1009 , 0.0957 , 0.0869 , 0.08405, 0.06396,\n",
       "            0.02887, 0.02744, 0.0164 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.13559322, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.59090906, 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.75      ,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8484849 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9897 , 0.9844 , 0.9814 , 0.98   , 0.9795 , 0.979  ,\n",
       "            0.978  , 0.9775 , 0.9727 , 0.9697 , 0.9688 , 0.9683 , 0.9653 ,\n",
       "            0.964  , 0.9634 , 0.9595 , 0.955  , 0.9546 , 0.953  , 0.9526 ,\n",
       "            0.9517 , 0.949  , 0.947  , 0.9453 , 0.9443 , 0.9424 , 0.9404 ,\n",
       "            0.939  , 0.937  , 0.9365 , 0.9346 , 0.934  , 0.932  , 0.931  ,\n",
       "            0.9307 , 0.926  , 0.9106 , 0.909  , 0.903  , 0.9014 , 0.899  ,\n",
       "            0.882  , 0.874  , 0.869  , 0.864  , 0.8633 , 0.8584 , 0.854  ,\n",
       "            0.838  , 0.8345 , 0.8257 , 0.818  , 0.815  , 0.7974 , 0.7944 ,\n",
       "            0.793  , 0.788  , 0.7705 , 0.768  , 0.7583 , 0.7534 , 0.753  ,\n",
       "            0.7515 , 0.7495 , 0.7485 , 0.746  , 0.745  , 0.742  , 0.7417 ,\n",
       "            0.741  , 0.7407 , 0.7363 , 0.736  , 0.735  , 0.7305 , 0.727  ,\n",
       "            0.7266 , 0.726  , 0.7246 , 0.7183 , 0.718  , 0.7173 , 0.7144 ,\n",
       "            0.7124 , 0.7114 , 0.711  , 0.706  , 0.701  , 0.7    , 0.699  ,\n",
       "            0.698  , 0.6943 , 0.6914 , 0.687  , 0.678  , 0.6772 , 0.675  ,\n",
       "            0.674  , 0.672  , 0.6685 , 0.6646 , 0.6597 , 0.6562 , 0.656  ,\n",
       "            0.655  , 0.651  , 0.6455 , 0.642  , 0.639  , 0.6235 , 0.6    ,\n",
       "            0.5996 , 0.5977 , 0.594  , 0.5903 , 0.59   , 0.5864 , 0.5767 ,\n",
       "            0.5645 , 0.562  , 0.558  , 0.5576 , 0.5547 , 0.5537 , 0.547  ,\n",
       "            0.5464 , 0.544  , 0.539  , 0.5356 , 0.528  , 0.524  , 0.5225 ,\n",
       "            0.5195 , 0.506  , 0.504  , 0.4973 , 0.4958 , 0.4937 , 0.4878 ,\n",
       "            0.4836 , 0.479  , 0.4768 , 0.4749 , 0.4746 , 0.465  , 0.4648 ,\n",
       "            0.4624 , 0.4565 , 0.4539 , 0.4495 , 0.443  , 0.4426 , 0.4407 ,\n",
       "            0.4397 , 0.436  , 0.434  , 0.4287 , 0.4277 , 0.4258 , 0.4233 ,\n",
       "            0.423  , 0.421  , 0.419  , 0.4167 , 0.4165 , 0.4119 , 0.4072 ,\n",
       "            0.4062 , 0.391  , 0.39   , 0.3887 , 0.3884 , 0.3865 , 0.3823 ,\n",
       "            0.3777 , 0.3757 , 0.3748 , 0.3738 , 0.3728 , 0.3655 , 0.3633 ,\n",
       "            0.3625 , 0.362  , 0.358  , 0.3538 , 0.3518 , 0.3503 , 0.35   ,\n",
       "            0.3474 , 0.3467 , 0.3433 , 0.3396 , 0.3354 , 0.3308 , 0.3296 ,\n",
       "            0.3293 , 0.3274 , 0.327  , 0.3257 , 0.3179 , 0.317  , 0.3125 ,\n",
       "            0.3064 , 0.3013 , 0.3    , 0.2927 , 0.2898 , 0.2832 , 0.2659 ,\n",
       "            0.2576 , 0.2505 , 0.2493 , 0.211  , 0.199  , 0.1741 , 0.1584 ,\n",
       "            0.1288 , 0.1278 , 0.126  , 0.1186 , 0.11633, 0.11536, 0.1105 ,\n",
       "            0.1103 , 0.1052 , 0.1045 , 0.10376, 0.0972 , 0.0933 , 0.0831 ,\n",
       "            0.0804 , 0.06097, 0.0267 , 0.02596, 0.01484], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.16949153, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.10606061, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.4848485 ,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.67424244,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.77272725, 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.9318182 , 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9917  , 0.9873  , 0.985   , 0.984   , 0.9834  ,\n",
       "            0.983   , 0.9824  , 0.982   , 0.9775  , 0.975   , 0.974   ,\n",
       "            0.9717  , 0.97    , 0.9697  , 0.9663  , 0.9624  , 0.962   ,\n",
       "            0.961   , 0.96    , 0.9595  , 0.957   , 0.955   , 0.9536  ,\n",
       "            0.9526  , 0.9507  , 0.949   , 0.948   , 0.9463  , 0.946   ,\n",
       "            0.944   , 0.942   , 0.9414  , 0.9404  , 0.9365  , 0.9224  ,\n",
       "            0.921   , 0.915   , 0.914   , 0.9116  , 0.894   , 0.8887  ,\n",
       "            0.8843  , 0.879   , 0.878   , 0.874   , 0.8696  , 0.852   ,\n",
       "            0.851   , 0.843   , 0.835   , 0.833   , 0.8125  , 0.811   ,\n",
       "            0.806   , 0.7886  , 0.786   , 0.777   , 0.773   , 0.772   ,\n",
       "            0.7715  , 0.77    , 0.7666  , 0.766   , 0.764   , 0.763   ,\n",
       "            0.76    , 0.7593  , 0.7583  , 0.755   , 0.7544  , 0.7505  ,\n",
       "            0.7485  , 0.746   , 0.7446  , 0.744   , 0.7437  , 0.7383  ,\n",
       "            0.7373  , 0.736   , 0.7354  , 0.733   , 0.7305  , 0.729   ,\n",
       "            0.7275  , 0.724   , 0.7207  , 0.7183  , 0.7173  , 0.712   ,\n",
       "            0.7114  , 0.7046  , 0.699   , 0.6978  , 0.6963  , 0.694   ,\n",
       "            0.6914  , 0.688   , 0.687   , 0.6772  , 0.6763  , 0.676   ,\n",
       "            0.6743  , 0.6733  , 0.6694  , 0.668   , 0.666   , 0.6562  ,\n",
       "            0.6475  , 0.64    , 0.6206  , 0.618   , 0.6143  , 0.6133  ,\n",
       "            0.609   , 0.6084  , 0.605   , 0.6006  , 0.5815  , 0.5776  ,\n",
       "            0.577   , 0.573   , 0.5713  , 0.5703  , 0.5635  , 0.5596  ,\n",
       "            0.557   , 0.5566  , 0.5547  , 0.5454  , 0.5425  , 0.541   ,\n",
       "            0.5376  , 0.537   , 0.519   , 0.5146  , 0.514   , 0.5127  ,\n",
       "            0.501   , 0.5005  , 0.494   , 0.4893  , 0.489   , 0.4863  ,\n",
       "            0.4812  , 0.4785  , 0.4736  , 0.4734  , 0.4722  , 0.4697  ,\n",
       "            0.4626  , 0.46    , 0.4578  , 0.4502  , 0.4497  , 0.4443  ,\n",
       "            0.441   , 0.4382  , 0.438   , 0.435   , 0.4348  , 0.4329  ,\n",
       "            0.432   , 0.431   , 0.43    , 0.427   , 0.4128  , 0.4114  ,\n",
       "            0.4055  , 0.402   , 0.4016  , 0.4001  , 0.3997  , 0.3992  ,\n",
       "            0.3909  , 0.3904  , 0.3901  , 0.388   , 0.3804  , 0.3787  ,\n",
       "            0.3772  , 0.3757  , 0.3748  , 0.3706  , 0.3694  , 0.3682  ,\n",
       "            0.3665  , 0.3628  , 0.362   , 0.3538  , 0.3513  , 0.35    ,\n",
       "            0.3496  , 0.3489  , 0.3418  , 0.341   , 0.3394  , 0.3315  ,\n",
       "            0.3313  , 0.329   , 0.328   , 0.3257  , 0.323   , 0.3179  ,\n",
       "            0.3079  , 0.3071  , 0.302   , 0.2974  , 0.2898  , 0.2852  ,\n",
       "            0.2651  , 0.2595  , 0.2494  , 0.2471  , 0.209   , 0.1968  ,\n",
       "            0.1718  , 0.1547  , 0.126   , 0.1238  , 0.12274 , 0.1144  ,\n",
       "            0.1124  , 0.11127 , 0.1069  , 0.10614 , 0.1025  , 0.10144 ,\n",
       "            0.1005  , 0.093   , 0.0906  , 0.0792  , 0.0764  , 0.0578  ,\n",
       "            0.02452 , 0.02448 , 0.013374], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1779661, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.06060606, 0.07575758, 0.08333334, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.5681818 , 0.57575756, 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.7878788 , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.82575756, 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 , 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.993   , 0.9893  , 0.9873  , 0.9863  , 0.986   ,\n",
       "            0.9854  , 0.985   , 0.981   , 0.978   , 0.9756  , 0.974   ,\n",
       "            0.973   , 0.9707  , 0.9673  , 0.966   , 0.965   , 0.964   ,\n",
       "            0.962   , 0.961   , 0.9585  , 0.958   , 0.9565  , 0.9546  ,\n",
       "            0.9536  , 0.952   , 0.951   , 0.95    , 0.9497  , 0.9478  ,\n",
       "            0.9473  , 0.9424  , 0.929   , 0.928   , 0.9233  , 0.9214  ,\n",
       "            0.9204  , 0.902   , 0.898   , 0.8926  , 0.888   , 0.8877  ,\n",
       "            0.883   , 0.879   , 0.862   , 0.861   , 0.8525  , 0.85    ,\n",
       "            0.844   , 0.8237  , 0.823   , 0.8228  , 0.822   , 0.8037  ,\n",
       "            0.7983  , 0.795   , 0.7935  , 0.7915  , 0.791   , 0.79    ,\n",
       "            0.789   , 0.7866  , 0.7837  , 0.781   , 0.7773  , 0.7744  ,\n",
       "            0.7734  , 0.7715  , 0.766   , 0.764   , 0.7627  , 0.762   ,\n",
       "            0.761   , 0.76    , 0.7563  , 0.7534  , 0.753   , 0.751   ,\n",
       "            0.7485  , 0.7466  , 0.742   , 0.7407  , 0.7397  , 0.739   ,\n",
       "            0.7383  , 0.7354  , 0.735   , 0.7344  , 0.7324  , 0.723   ,\n",
       "            0.722   , 0.7124  , 0.7104  , 0.7056  , 0.7036  , 0.6978  ,\n",
       "            0.697   , 0.6924  , 0.692   , 0.6885  , 0.6875  , 0.67    ,\n",
       "            0.6685  , 0.6567  , 0.642   , 0.6353  , 0.6343  , 0.6304  ,\n",
       "            0.6284  , 0.622   , 0.6177  , 0.603   , 0.5884  , 0.585   ,\n",
       "            0.579   , 0.576   , 0.5737  , 0.5723  , 0.567   , 0.5654  ,\n",
       "            0.56    , 0.5566  , 0.552   , 0.55    , 0.541   , 0.529   ,\n",
       "            0.528   , 0.527   , 0.5234  , 0.521   , 0.5137  , 0.5083  ,\n",
       "            0.5015  , 0.4983  , 0.4927  , 0.491   , 0.49    , 0.4858  ,\n",
       "            0.4856  , 0.4807  , 0.477   , 0.4753  , 0.4722  , 0.4695  ,\n",
       "            0.4683  , 0.4573  , 0.452   , 0.4504  , 0.4475  , 0.446   ,\n",
       "            0.4443  , 0.4429  , 0.4392  , 0.4382  , 0.4375  , 0.4368  ,\n",
       "            0.436   , 0.4336  , 0.4272  , 0.4153  , 0.414   , 0.413   ,\n",
       "            0.4092  , 0.4084  , 0.4062  , 0.4023  , 0.3997  , 0.3965  ,\n",
       "            0.3962  , 0.3958  , 0.3867  , 0.3843  , 0.381   , 0.3806  ,\n",
       "            0.3774  , 0.376   , 0.3745  , 0.3723  , 0.3718  , 0.3684  ,\n",
       "            0.3665  , 0.3538  , 0.3518  , 0.3506  , 0.35    , 0.3496  ,\n",
       "            0.3455  , 0.3452  , 0.343   , 0.3357  , 0.3315  , 0.3298  ,\n",
       "            0.3286  , 0.3252  , 0.3184  , 0.3105  , 0.3066  , 0.3054  ,\n",
       "            0.3005  , 0.29    , 0.2888  , 0.2869  , 0.263   , 0.258   ,\n",
       "            0.247   , 0.243   , 0.2048  , 0.1927  , 0.1696  , 0.1506  ,\n",
       "            0.1239  , 0.1198  , 0.1193  , 0.1101  , 0.108   , 0.10706 ,\n",
       "            0.1036  , 0.1019  , 0.10034 , 0.1     , 0.0962  , 0.0887  ,\n",
       "            0.075   , 0.0724  , 0.0544  , 0.02298 , 0.02254 , 0.012054],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.22033899, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.06060606, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.10606061, 0.11363637, 0.12121212, 0.12878788, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.50757575, 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9946 , 0.9917 , 0.9897 , 0.9893 , 0.989  , 0.9883 ,\n",
       "            0.988  , 0.9844 , 0.9824 , 0.982  , 0.98   , 0.9785 , 0.978  ,\n",
       "            0.976  , 0.973  , 0.972  , 0.9717 , 0.9707 , 0.97   , 0.9688 ,\n",
       "            0.968  , 0.966  , 0.9653 , 0.9634 , 0.9624 , 0.9614 , 0.96   ,\n",
       "            0.9595 , 0.9585 , 0.958  , 0.956  , 0.9556 , 0.955  , 0.9517 ,\n",
       "            0.94   , 0.9385 , 0.9336 , 0.9326 , 0.9316 , 0.9136 , 0.911  ,\n",
       "            0.9062 , 0.902  , 0.9014 , 0.8975 , 0.8936 , 0.878  , 0.875  ,\n",
       "            0.869  , 0.8657 , 0.862  , 0.841  , 0.8374 , 0.821  , 0.818  ,\n",
       "            0.8135 , 0.8125 , 0.8115 , 0.81   , 0.8086 , 0.8076 , 0.807  ,\n",
       "            0.8057 , 0.8027 , 0.8013 , 0.795  , 0.7944 , 0.794  , 0.7935 ,\n",
       "            0.7915 , 0.791  , 0.785  , 0.783  , 0.7817 , 0.78   , 0.7793 ,\n",
       "            0.779  , 0.7783 , 0.774  , 0.7705 , 0.77   , 0.7686 , 0.768  ,\n",
       "            0.7656 , 0.764  , 0.7607 , 0.7603 , 0.759  , 0.7573 , 0.757  ,\n",
       "            0.7563 , 0.753  , 0.7524 , 0.752  , 0.7476 , 0.7397 , 0.7334 ,\n",
       "            0.7314 , 0.727  , 0.7236 , 0.72   , 0.719  , 0.7183 , 0.712  ,\n",
       "            0.711  , 0.71   , 0.7075 , 0.7065 , 0.694  , 0.686  , 0.674  ,\n",
       "            0.666  , 0.6597 , 0.6543 , 0.653  , 0.647  , 0.6445 , 0.6377 ,\n",
       "            0.6333 , 0.628  , 0.6035 , 0.603  , 0.6025 , 0.602  , 0.5986 ,\n",
       "            0.593  , 0.592  , 0.583  , 0.577  , 0.5767 , 0.5728 , 0.5713 ,\n",
       "            0.564  , 0.562  , 0.5615 , 0.5513 , 0.5493 , 0.5415 , 0.54   ,\n",
       "            0.538  , 0.5327 , 0.529  , 0.52   , 0.515  , 0.511  , 0.509  ,\n",
       "            0.505  , 0.4998 , 0.499  , 0.4915 , 0.49   , 0.4888 , 0.4846 ,\n",
       "            0.4841 , 0.4736 , 0.4685 , 0.465  , 0.4624 , 0.4617 , 0.4612 ,\n",
       "            0.4597 , 0.4563 , 0.4543 , 0.4539 , 0.4531 , 0.4504 , 0.446  ,\n",
       "            0.4446 , 0.4338 , 0.4258 , 0.4248 , 0.4224 , 0.4207 , 0.4197 ,\n",
       "            0.4177 , 0.4163 , 0.4143 , 0.4124 , 0.4094 , 0.399  , 0.3965 ,\n",
       "            0.3962 , 0.3926 , 0.3916 , 0.3884 , 0.388  , 0.384  , 0.3823 ,\n",
       "            0.381  , 0.3804 , 0.3767 , 0.366  , 0.3623 , 0.36   , 0.3599 ,\n",
       "            0.3547 , 0.354  , 0.3481 , 0.3398 , 0.3372 , 0.3352 , 0.333  ,\n",
       "            0.3318 , 0.3296 , 0.322  , 0.318  , 0.3074 , 0.3027 , 0.3003 ,\n",
       "            0.29   , 0.2888 , 0.2634 , 0.263  , 0.2471 , 0.2424 , 0.2042 ,\n",
       "            0.1924 , 0.1672 , 0.1473 , 0.121  , 0.11694, 0.11597, 0.1067 ,\n",
       "            0.10486, 0.1036 , 0.10034, 0.0986 , 0.0974 , 0.0972 , 0.093  ,\n",
       "            0.0857 , 0.0854 , 0.07196, 0.0693 , 0.05203, 0.02187, 0.02077,\n",
       "            0.01086], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.26271185, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.04545455,\n",
       "            0.06060606, 0.07575758, 0.08333334, 0.09090909, 0.10606061,\n",
       "            0.11363637, 0.12878788, 0.13636364, 0.15151516, 0.1590909 ,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.24242425, 0.25757575,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.5378788 , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.996  , 0.9937 , 0.9927 , 0.9917 , 0.991  , 0.9907 ,\n",
       "            0.9883 , 0.9863 , 0.986  , 0.9844 , 0.9834 , 0.981  , 0.9785 ,\n",
       "            0.9775 , 0.977  , 0.975  , 0.974  , 0.973  , 0.972  , 0.97   ,\n",
       "            0.969  , 0.9688 , 0.968  , 0.9663 , 0.9644 , 0.9634 , 0.961  ,\n",
       "            0.9507 , 0.9497 , 0.945  , 0.9434 , 0.9253 , 0.924  , 0.9214 ,\n",
       "            0.9175 , 0.914  , 0.9136 , 0.9097 , 0.895  , 0.8877 , 0.887  ,\n",
       "            0.8813 , 0.88   , 0.8613 , 0.861  , 0.8564 , 0.8516 , 0.841  ,\n",
       "            0.837  , 0.832  , 0.83   , 0.8296 , 0.8286 , 0.825  , 0.824  ,\n",
       "            0.8237 , 0.8228 , 0.821  , 0.8184 , 0.8154 , 0.814  , 0.8105 ,\n",
       "            0.8076 , 0.8022 , 0.8    , 0.799  , 0.7974 , 0.7964 , 0.7954 ,\n",
       "            0.795  , 0.7905 , 0.7886 , 0.787  , 0.7866 , 0.7856 , 0.7827 ,\n",
       "            0.7812 , 0.7803 , 0.7783 , 0.7764 , 0.7744 , 0.7734 , 0.772  ,\n",
       "            0.771  , 0.769  , 0.7563 , 0.756  , 0.753  , 0.751  , 0.7495 ,\n",
       "            0.7417 , 0.7397 , 0.739  , 0.7354 , 0.731  , 0.729  , 0.7246 ,\n",
       "            0.7236 , 0.718  , 0.7046 , 0.6904 , 0.69   , 0.6846 , 0.6787 ,\n",
       "            0.673  , 0.6724 , 0.6606 , 0.654  , 0.6533 , 0.649  , 0.6343 ,\n",
       "            0.6294 , 0.624  , 0.622  , 0.6167 , 0.615  , 0.613  , 0.599  ,\n",
       "            0.598  , 0.593  , 0.5923 , 0.5884 , 0.5854 , 0.579  , 0.5723 ,\n",
       "            0.5713 , 0.5674 , 0.5605 , 0.5537 , 0.551  , 0.545  , 0.5337 ,\n",
       "            0.533  , 0.5317 , 0.5293 , 0.526  , 0.519  , 0.513  , 0.5107 ,\n",
       "            0.508  , 0.5044 , 0.501  , 0.4927 , 0.4924 , 0.4902 , 0.4885 ,\n",
       "            0.4854 , 0.4824 , 0.4788 , 0.476  , 0.4756 , 0.474  , 0.4724 ,\n",
       "            0.472  , 0.471  , 0.4697 , 0.455  , 0.4539 , 0.4446 , 0.4436 ,\n",
       "            0.4412 , 0.4385 , 0.4348 , 0.434  , 0.4307 , 0.4302 , 0.4263 ,\n",
       "            0.426  , 0.4211 , 0.4148 , 0.4146 , 0.4102 , 0.4067 , 0.4026 ,\n",
       "            0.4023 , 0.3997 , 0.399  , 0.3945 , 0.3877 , 0.3865 , 0.3833 ,\n",
       "            0.3809 , 0.3796 , 0.378  , 0.3772 , 0.365  , 0.3582 , 0.3572 ,\n",
       "            0.3535 , 0.3528 , 0.3464 , 0.345  , 0.3408 , 0.3386 , 0.336  ,\n",
       "            0.3347 , 0.3342 , 0.3174 , 0.309  , 0.3044 , 0.291  , 0.2908 ,\n",
       "            0.2666 , 0.2637 , 0.247  , 0.241  , 0.2029 , 0.191  , 0.1653 ,\n",
       "            0.1444 , 0.119  , 0.1142 , 0.1128 , 0.1034 , 0.10144, 0.10034,\n",
       "            0.0974 , 0.096  , 0.0955 , 0.09534, 0.0896 , 0.08386, 0.0821 ,\n",
       "            0.06866, 0.0661 , 0.0495 , 0.02072, 0.01912, 0.00982],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.29661018, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.4915254 , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.04545455,\n",
       "            0.06060606, 0.07575758, 0.08333334, 0.09090909, 0.10606061,\n",
       "            0.11363637, 0.12878788, 0.13636364, 0.15151516, 0.1590909 ,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.23484848, 0.24242425, 0.25757575,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.7348485 , 0.75      , 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.997  , 0.995  , 0.994  , 0.9937 , 0.993  , 0.9927 ,\n",
       "            0.99   , 0.9893 , 0.989  , 0.9873 , 0.9863 , 0.9844 , 0.9824 ,\n",
       "            0.9814 , 0.981  , 0.9795 , 0.9785 , 0.9775 , 0.977  , 0.975  ,\n",
       "            0.974  , 0.9736 , 0.973  , 0.972  , 0.97   , 0.969  , 0.9673 ,\n",
       "            0.9585 , 0.9575 , 0.953  , 0.9517 , 0.9507 , 0.9355 , 0.932  ,\n",
       "            0.931  , 0.928  , 0.925  , 0.924  , 0.921  , 0.908  , 0.901  ,\n",
       "            0.897  , 0.8955 , 0.894  , 0.8765 , 0.876  , 0.8716 , 0.863  ,\n",
       "            0.857  , 0.8525 , 0.849  , 0.847  , 0.845  , 0.842  , 0.841  ,\n",
       "            0.8403 , 0.8394 , 0.839  , 0.8374 , 0.836  , 0.8335 , 0.832  ,\n",
       "            0.8276 , 0.827  , 0.8247 , 0.82   , 0.8164 , 0.816  , 0.8154 ,\n",
       "            0.8135 , 0.812  , 0.811  , 0.808  , 0.807  , 0.8037 , 0.803  ,\n",
       "            0.8027 , 0.8    , 0.7983 , 0.7974 , 0.796  , 0.793  , 0.792  ,\n",
       "            0.791  , 0.7905 , 0.787  , 0.786  , 0.777  , 0.7754 , 0.774  ,\n",
       "            0.7725 , 0.771  , 0.768  , 0.76   , 0.7593 , 0.759  , 0.756  ,\n",
       "            0.7515 , 0.748  , 0.7476 , 0.7437 , 0.7393 , 0.721  , 0.7114 ,\n",
       "            0.707  , 0.706  , 0.7    , 0.694  , 0.6934 , 0.679  , 0.676  ,\n",
       "            0.6694 , 0.6646 , 0.656  , 0.6504 , 0.644  , 0.6387 , 0.6343 ,\n",
       "            0.6304 , 0.63   , 0.6157 , 0.6143 , 0.6123 , 0.6094 , 0.602  ,\n",
       "            0.5986 , 0.596  , 0.594  , 0.589  , 0.5874 , 0.5815 , 0.5767 ,\n",
       "            0.571  , 0.5693 , 0.5645 , 0.564  , 0.5513 , 0.5493 , 0.548  ,\n",
       "            0.546  , 0.543  , 0.5356 , 0.53   , 0.5273 , 0.5195 , 0.515  ,\n",
       "            0.51   , 0.5073 , 0.507  , 0.5044 , 0.501  , 0.5    , 0.4978 ,\n",
       "            0.4937 , 0.4924 , 0.4905 , 0.4895 , 0.4873 , 0.4866 , 0.4768 ,\n",
       "            0.471  , 0.4602 , 0.459  , 0.4578 , 0.455  , 0.4539 , 0.45   ,\n",
       "            0.4465 , 0.4443 , 0.444  , 0.435  , 0.432  , 0.4316 , 0.428  ,\n",
       "            0.4233 , 0.4202 , 0.4158 , 0.4155 , 0.4114 , 0.4075 , 0.3992 ,\n",
       "            0.3955 , 0.3953 , 0.3904 , 0.3894 , 0.3853 , 0.3691 , 0.3638 ,\n",
       "            0.362  , 0.3604 , 0.3584 , 0.356  , 0.351  , 0.3506 , 0.3438 ,\n",
       "            0.3418 , 0.339  , 0.3376 , 0.3267 , 0.3108 , 0.306  , 0.2942 ,\n",
       "            0.2917 , 0.2686 , 0.2642 , 0.2471 , 0.2391 , 0.2012 , 0.1892 ,\n",
       "            0.1641 , 0.1423 , 0.1178 , 0.1122 , 0.1099 , 0.1007 , 0.0986 ,\n",
       "            0.09753, 0.0957 , 0.09515, 0.09436, 0.0925 , 0.0868 , 0.0828 ,\n",
       "            0.0789 , 0.06586, 0.0631 , 0.0471 , 0.01964, 0.01778, 0.00895],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.37288135, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.04545455,\n",
       "            0.06818182, 0.07575758, 0.08333334, 0.09090909, 0.10606061,\n",
       "            0.11363637, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.23484848, 0.25757575,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.50757575, 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.70454544,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75757575, 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.998  , 0.996  , 0.9956 , 0.995  , 0.9946 , 0.994  ,\n",
       "            0.992  , 0.991  , 0.9907 , 0.9897 , 0.9893 , 0.9873 , 0.986  ,\n",
       "            0.9854 , 0.985  , 0.9844 , 0.9834 , 0.9824 , 0.982  , 0.981  ,\n",
       "            0.9795 , 0.9785 , 0.978  , 0.9766 , 0.9756 , 0.9736 , 0.973  ,\n",
       "            0.9653 , 0.964  , 0.961  , 0.959  , 0.957  , 0.945  , 0.942  ,\n",
       "            0.9385 , 0.938  , 0.9355 , 0.932  , 0.9316 , 0.9194 , 0.913  ,\n",
       "            0.9087 , 0.9062 , 0.9053 , 0.8906 , 0.888  , 0.8853 , 0.873  ,\n",
       "            0.8726 , 0.8667 , 0.866  , 0.865  , 0.8633 , 0.86   , 0.857  ,\n",
       "            0.856  , 0.8555 , 0.855  , 0.8545 , 0.8535 , 0.8525 , 0.852  ,\n",
       "            0.8486 , 0.8433 , 0.8423 , 0.8403 , 0.8354 , 0.832  , 0.8315 ,\n",
       "            0.8286 , 0.827  , 0.8267 , 0.8237 , 0.819  , 0.8184 , 0.818  ,\n",
       "            0.8164 , 0.816  , 0.814  , 0.8115 , 0.808  , 0.8066 , 0.8022 ,\n",
       "            0.802  , 0.7983 , 0.797  , 0.793  , 0.7925 , 0.7896 , 0.7847 ,\n",
       "            0.779  , 0.7783 , 0.7773 , 0.776  , 0.771  , 0.7656 , 0.765  ,\n",
       "            0.7627 , 0.761  , 0.7563 , 0.737  , 0.735  , 0.73   , 0.724  ,\n",
       "            0.7236 , 0.7183 , 0.7134 , 0.7007 , 0.6973 , 0.685  , 0.68   ,\n",
       "            0.6797 , 0.6743 , 0.668  , 0.6577 , 0.655  , 0.651  , 0.6426 ,\n",
       "            0.6387 , 0.6377 , 0.6304 , 0.623  , 0.6123 , 0.6113 , 0.6094 ,\n",
       "            0.605  , 0.5977 , 0.596  , 0.5923 , 0.59   , 0.5864 , 0.5786 ,\n",
       "            0.573  , 0.569  , 0.568  , 0.5664 , 0.5645 , 0.556  , 0.5522 ,\n",
       "            0.55   , 0.5386 , 0.5293 , 0.5254 , 0.525  , 0.5225 , 0.5215 ,\n",
       "            0.5166 , 0.516  , 0.513  , 0.5127 , 0.5103 , 0.508  , 0.5073 ,\n",
       "            0.5054 , 0.505  , 0.4932 , 0.4824 , 0.4785 , 0.477  , 0.4756 ,\n",
       "            0.474  , 0.4717 , 0.4648 , 0.4631 , 0.4617 , 0.453  , 0.447  ,\n",
       "            0.4465 , 0.4421 , 0.4392 , 0.437  , 0.4355 , 0.4348 , 0.4292 ,\n",
       "            0.4165 , 0.413  , 0.4087 , 0.407  , 0.4058 , 0.405  , 0.4019 ,\n",
       "            0.393  , 0.3896 , 0.3792 , 0.3716 , 0.3706 , 0.366  , 0.3655 ,\n",
       "            0.364  , 0.362  , 0.359  , 0.3572 , 0.3435 , 0.3408 , 0.3406 ,\n",
       "            0.3403 , 0.312  , 0.3064 , 0.297  , 0.2925 , 0.2683 , 0.264  ,\n",
       "            0.2463 , 0.2367 , 0.1981 , 0.1858 , 0.1622 , 0.1396 , 0.11633,\n",
       "            0.1097 , 0.1065 , 0.0977 , 0.09503, 0.09485, 0.0942 , 0.0927 ,\n",
       "            0.0922 , 0.0891 , 0.083  , 0.08136, 0.0752 , 0.06232, 0.05975,\n",
       "            0.0442 , 0.01826, 0.01634, 0.008  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.38135594, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.29661018, 0.31355932,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.34745762, 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.06060606,\n",
       "            0.06818182, 0.07575758, 0.08333334, 0.09090909, 0.10606061,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.5       , 0.50757575, 0.52272725, 0.530303  ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9985  , 0.997   , 0.9966  , 0.996   , 0.9956  ,\n",
       "            0.995   , 0.994   , 0.993   , 0.9927  , 0.9917  , 0.99    ,\n",
       "            0.989   , 0.9883  , 0.988   , 0.987   , 0.986   , 0.9854  ,\n",
       "            0.985   , 0.9834  , 0.983   , 0.9824  , 0.982   , 0.9814  ,\n",
       "            0.981   , 0.9805  , 0.98    , 0.9785  , 0.978   , 0.971   ,\n",
       "            0.97    , 0.968   , 0.966   , 0.964   , 0.953   , 0.9507  ,\n",
       "            0.9478  , 0.9463  , 0.9453  , 0.942   , 0.931   , 0.9253  ,\n",
       "            0.9214  , 0.9175  , 0.916   , 0.905   , 0.9023  , 0.898   ,\n",
       "            0.889   , 0.8857  , 0.8804  , 0.88    , 0.8794  , 0.877   ,\n",
       "            0.8735  , 0.871   , 0.8706  , 0.8696  , 0.869   , 0.8687  ,\n",
       "            0.8667  , 0.8657  , 0.8574  , 0.8564  , 0.8545  , 0.8496  ,\n",
       "            0.8467  , 0.846   , 0.8457  , 0.8433  , 0.842   , 0.841   ,\n",
       "            0.8384  , 0.8335  , 0.833   , 0.8325  , 0.8306  , 0.829   ,\n",
       "            0.8276  , 0.8267  , 0.823   , 0.8223  , 0.82    , 0.8174  ,\n",
       "            0.817   , 0.816   , 0.8145  , 0.813   , 0.8125  , 0.8047  ,\n",
       "            0.8     , 0.796   , 0.7954  , 0.794   , 0.7915  , 0.7886  ,\n",
       "            0.782   , 0.7817  , 0.7803  , 0.778   , 0.772   , 0.7554  ,\n",
       "            0.7534  , 0.7485  , 0.743   , 0.7397  , 0.7373  , 0.732   ,\n",
       "            0.7207  , 0.7153  , 0.705   , 0.7017  , 0.6987  , 0.696   ,\n",
       "            0.6875  , 0.676   , 0.6743  , 0.668   , 0.6636  , 0.658   ,\n",
       "            0.6577  , 0.652   , 0.6475  , 0.642   , 0.633   , 0.63    ,\n",
       "            0.629   , 0.6226  , 0.621   , 0.619   , 0.6133  , 0.61    ,\n",
       "            0.6094  , 0.6045  , 0.5977  , 0.5933  , 0.586   , 0.585   ,\n",
       "            0.5835  , 0.5815  , 0.573   , 0.5693  , 0.567   , 0.558   ,\n",
       "            0.5513  , 0.5425  , 0.5415  , 0.538   , 0.5356  , 0.534   ,\n",
       "            0.5327  , 0.53    , 0.5293  , 0.527   , 0.5215  , 0.5195  ,\n",
       "            0.51    , 0.495   , 0.4944  , 0.493   , 0.492   , 0.49    ,\n",
       "            0.4878  , 0.4802  , 0.4788  , 0.4785  , 0.4756  , 0.4722  ,\n",
       "            0.4624  , 0.462   , 0.4575  , 0.4546  , 0.4502  , 0.45    ,\n",
       "            0.4475  , 0.445   , 0.444   , 0.4277  , 0.4258  , 0.4233  ,\n",
       "            0.4214  , 0.4194  , 0.4143  , 0.4136  , 0.4011  , 0.3967  ,\n",
       "            0.392   , 0.3828  , 0.3804  , 0.379   , 0.3726  , 0.3718  ,\n",
       "            0.3713  , 0.3691  , 0.3645  , 0.352   , 0.3496  , 0.3467  ,\n",
       "            0.3464  , 0.3167  , 0.3115  , 0.3013  , 0.296   , 0.2764  ,\n",
       "            0.2673  , 0.249   , 0.2382  , 0.1993  , 0.1874  , 0.1615  ,\n",
       "            0.1385  , 0.11475 , 0.108   , 0.1047  , 0.0962  , 0.0937  ,\n",
       "            0.0933  , 0.0922  , 0.09125 , 0.0904  , 0.0874  , 0.08105 ,\n",
       "            0.0799  , 0.0732  , 0.06042 , 0.0578  , 0.04272 , 0.01772 ,\n",
       "            0.01525 , 0.007317], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.47457626, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.33050847,\n",
       "            0.33898306, 0.3559322 , 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03787879, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09848485, 0.10606061, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.17424242, 0.18181819, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.4469697 , 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.999  , 0.998  , 0.9976 , 0.997  , 0.9966 , 0.9956 ,\n",
       "            0.995  , 0.9946 , 0.994  , 0.9937 , 0.9927 , 0.992  , 0.9917 ,\n",
       "            0.991  , 0.9907 , 0.99   , 0.9897 , 0.989  , 0.9883 , 0.9873 ,\n",
       "            0.987  , 0.9863 , 0.986  , 0.9854 , 0.985  , 0.984  , 0.9834 ,\n",
       "            0.9785 , 0.9775 , 0.976  , 0.9736 , 0.971  , 0.963  , 0.962  ,\n",
       "            0.96   , 0.958  , 0.9556 , 0.954  , 0.952  , 0.9443 , 0.9404 ,\n",
       "            0.9385 , 0.929  , 0.9277 , 0.9233 , 0.9185 , 0.911  , 0.9097 ,\n",
       "            0.9014 , 0.897  , 0.895  , 0.8926 , 0.89   , 0.8877 , 0.8867 ,\n",
       "            0.8843 , 0.884  , 0.883  , 0.8823 , 0.882  , 0.8804 , 0.8716 ,\n",
       "            0.87   , 0.8687 , 0.8643 , 0.861  , 0.8604 , 0.86   , 0.8574 ,\n",
       "            0.857  , 0.8555 , 0.855  , 0.854  , 0.8535 , 0.853  , 0.8496 ,\n",
       "            0.848  , 0.8477 , 0.847  , 0.845  , 0.8438 , 0.842  , 0.841  ,\n",
       "            0.8384 , 0.8374 , 0.833  , 0.832  , 0.8315 , 0.82   , 0.819  ,\n",
       "            0.8154 , 0.812  , 0.8105 , 0.8066 , 0.806  , 0.8057 , 0.7993 ,\n",
       "            0.798  , 0.795  , 0.7866 , 0.78   , 0.779  , 0.7754 , 0.7695 ,\n",
       "            0.7656 , 0.757  , 0.7515 , 0.75   , 0.748  , 0.735  , 0.721  ,\n",
       "            0.719  , 0.715  , 0.711  , 0.7026 , 0.6997 , 0.696  , 0.691  ,\n",
       "            0.689  , 0.6807 , 0.677  , 0.6763 , 0.6675 , 0.6655 , 0.659  ,\n",
       "            0.658  , 0.6577 , 0.644  , 0.6426 , 0.642  , 0.6416 , 0.638  ,\n",
       "            0.6245 , 0.6187 , 0.6167 , 0.616  , 0.6157 , 0.6143 , 0.6064 ,\n",
       "            0.6055 , 0.603  , 0.597  , 0.5913 , 0.5903 , 0.581  , 0.5767 ,\n",
       "            0.5757 , 0.5737 , 0.5635 , 0.5615 , 0.5557 , 0.555  , 0.5493 ,\n",
       "            0.549  , 0.536  , 0.5337 , 0.5317 , 0.5312 , 0.53   , 0.5293 ,\n",
       "            0.5283 , 0.5264 , 0.516  , 0.515  , 0.5146 , 0.5005 , 0.4993 ,\n",
       "            0.4956 , 0.4934 , 0.4917 , 0.4888 , 0.4885 , 0.4814 , 0.4656 ,\n",
       "            0.4624 , 0.4622 , 0.4597 , 0.4595 , 0.4348 , 0.432  , 0.431  ,\n",
       "            0.4297 , 0.4265 , 0.423  , 0.4136 , 0.4114 , 0.4058 , 0.4006 ,\n",
       "            0.3943 , 0.3816 , 0.3806 , 0.3804 , 0.3716 , 0.3586 , 0.355  ,\n",
       "            0.3547 , 0.3245 , 0.3196 , 0.306  , 0.3008 , 0.2886 , 0.2727 ,\n",
       "            0.2527 , 0.2418 , 0.2029 , 0.1923 , 0.161  , 0.1382 , 0.1134 ,\n",
       "            0.1065 , 0.10376, 0.09534, 0.0922 , 0.0909 , 0.0895 , 0.089  ,\n",
       "            0.086  , 0.0798 , 0.07825, 0.0721 , 0.0591 , 0.05655, 0.04163,\n",
       "            0.01724, 0.01423, 0.00669], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5338983, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3644068 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.06818182, 0.07575758,\n",
       "            0.09090909, 0.10606061, 0.11363637, 0.12878788, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.2651515 , 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.6969697 , 0.70454544, 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.9985  , 0.998   , 0.9976  , 0.9966  ,\n",
       "            0.996   , 0.9956  , 0.995   , 0.994   , 0.9937  , 0.993   ,\n",
       "            0.9927  , 0.992   , 0.9917  , 0.991   , 0.9907  , 0.9897  ,\n",
       "            0.9893  , 0.989   , 0.9883  , 0.9873  , 0.987   , 0.983   ,\n",
       "            0.982   , 0.981   , 0.9785  , 0.9756  , 0.969   , 0.9688  ,\n",
       "            0.9673  , 0.966   , 0.962   , 0.9614  , 0.959   , 0.953   ,\n",
       "            0.95    , 0.949   , 0.9375  , 0.936   , 0.9355  , 0.9287  ,\n",
       "            0.9253  , 0.9194  , 0.913   , 0.912   , 0.9087  , 0.906   ,\n",
       "            0.9033  , 0.902   , 0.9014  , 0.9004  , 0.898   , 0.895   ,\n",
       "            0.8945  , 0.894   , 0.8936  , 0.892   , 0.8833  , 0.882   ,\n",
       "            0.8804  , 0.88    , 0.8765  , 0.876   , 0.8735  , 0.873   ,\n",
       "            0.8716  , 0.871   , 0.869   , 0.867   , 0.8667  , 0.8657  ,\n",
       "            0.864   , 0.8633  , 0.861   , 0.86    , 0.858   , 0.8564  ,\n",
       "            0.855   , 0.8516  , 0.8506  , 0.8496  , 0.845   , 0.8447  ,\n",
       "            0.8384  , 0.833   , 0.8286  , 0.8267  , 0.825   , 0.821   ,\n",
       "            0.8203  , 0.814   , 0.8115  , 0.8096  , 0.802   , 0.801   ,\n",
       "            0.7983  , 0.7974  , 0.792   , 0.7896  , 0.7876  , 0.7783  ,\n",
       "            0.7754  , 0.772   , 0.769   , 0.7524  , 0.7515  , 0.738   ,\n",
       "            0.735   , 0.731   , 0.7266  , 0.722   , 0.7207  , 0.72    ,\n",
       "            0.7188  , 0.711   , 0.7007  , 0.6953  , 0.6943  , 0.6914  ,\n",
       "            0.6904  , 0.69    , 0.6865  , 0.667   , 0.666   , 0.6626  ,\n",
       "            0.661   , 0.653   , 0.6523  , 0.6445  , 0.6436  , 0.643   ,\n",
       "            0.639   , 0.634   , 0.633   , 0.6313  , 0.627   , 0.6265  ,\n",
       "            0.6245  , 0.623   , 0.611   , 0.6045  , 0.601   , 0.592   ,\n",
       "            0.59    , 0.589   , 0.582   , 0.5815  , 0.579   , 0.572   ,\n",
       "            0.567   , 0.565   , 0.5625  , 0.559   , 0.5586  , 0.557   ,\n",
       "            0.554   , 0.55    , 0.5435  , 0.543   , 0.5293  , 0.529   ,\n",
       "            0.5273  , 0.5244  , 0.523   , 0.518   , 0.5093  , 0.5034  ,\n",
       "            0.494   , 0.492   , 0.4888  , 0.474   , 0.4705  , 0.465   ,\n",
       "            0.4612  , 0.4587  , 0.4487  , 0.4443  , 0.441   , 0.4373  ,\n",
       "            0.4346  , 0.4233  , 0.417   , 0.4048  , 0.3916  , 0.391   ,\n",
       "            0.3896  , 0.3833  , 0.3667  , 0.363   , 0.3628  , 0.3315  ,\n",
       "            0.3267  , 0.314   , 0.3071  , 0.2974  , 0.2778  , 0.2563  ,\n",
       "            0.2452  , 0.206   , 0.1958  , 0.1635  , 0.1393  , 0.1152  ,\n",
       "            0.10706 , 0.1036  , 0.09534 , 0.09436 , 0.09186 , 0.0909  ,\n",
       "            0.09076 , 0.089   , 0.0854  , 0.0792  , 0.07904 , 0.0712  ,\n",
       "            0.05814 , 0.0556  , 0.04092 , 0.01692 , 0.01363 , 0.006313],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.60169494, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.27966103, 0.2881356 , 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.4915254 , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5423729 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.06818182, 0.07575758,\n",
       "            0.09090909, 0.11363637, 0.12878788, 0.14393939, 0.15151516,\n",
       "            0.18939394, 0.20454545, 0.21212122, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.5833333 , 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6666667 , 0.67424244, 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.999   , 0.9985  , 0.998   , 0.9976  ,\n",
       "            0.997   , 0.9966  , 0.996   , 0.9956  , 0.9946  , 0.9937  ,\n",
       "            0.993   , 0.9927  , 0.992   , 0.9917  , 0.991   , 0.99    ,\n",
       "            0.9897  , 0.9873  , 0.987   , 0.9863  , 0.983   , 0.9805  ,\n",
       "            0.9766  , 0.9756  , 0.975   , 0.9746  , 0.9707  , 0.9688  ,\n",
       "            0.967   , 0.9624  , 0.962   , 0.9614  , 0.9497  , 0.948   ,\n",
       "            0.943   , 0.9424  , 0.942   , 0.934   , 0.9272  , 0.9263  ,\n",
       "            0.92    , 0.9194  , 0.915   , 0.9116  , 0.911   , 0.9106  ,\n",
       "            0.91    , 0.9097  , 0.907   , 0.905   , 0.904   , 0.9033  ,\n",
       "            0.903   , 0.902   , 0.8936  , 0.891   , 0.8906  , 0.889   ,\n",
       "            0.887   , 0.8867  , 0.8843  , 0.8833  , 0.8813  , 0.8794  ,\n",
       "            0.877   , 0.8765  , 0.8745  , 0.872   , 0.8716  , 0.87    ,\n",
       "            0.8696  , 0.869   , 0.8677  , 0.866   , 0.864   , 0.863   ,\n",
       "            0.862   , 0.8564  , 0.856   , 0.8467  , 0.844   , 0.8403  ,\n",
       "            0.84    , 0.839   , 0.8384  , 0.8345  , 0.832   , 0.8276  ,\n",
       "            0.826   , 0.8237  , 0.8228  , 0.8223  , 0.8213  , 0.8174  ,\n",
       "            0.815   , 0.814   , 0.8096  , 0.802   , 0.7876  , 0.785   ,\n",
       "            0.7695  , 0.7666  , 0.762   , 0.7607  , 0.756   , 0.754   ,\n",
       "            0.7515  , 0.75    , 0.747   , 0.7466  , 0.744   , 0.742   ,\n",
       "            0.7305  , 0.7295  , 0.729   , 0.7163  , 0.711   , 0.703   ,\n",
       "            0.7     , 0.698   , 0.697   , 0.6904  , 0.6826  , 0.68    ,\n",
       "            0.679   , 0.6777  , 0.6733  , 0.672   , 0.67    , 0.6685  ,\n",
       "            0.6665  , 0.6445  , 0.6436  , 0.64    , 0.6396  , 0.638   ,\n",
       "            0.6353  , 0.633   , 0.628   , 0.6274  , 0.6245  , 0.621   ,\n",
       "            0.62    , 0.609   , 0.605   , 0.6016  , 0.601   , 0.599   ,\n",
       "            0.596   , 0.594   , 0.586   , 0.5854  , 0.5757  , 0.574   ,\n",
       "            0.572   , 0.57    , 0.5693  , 0.565   , 0.5586  , 0.554   ,\n",
       "            0.544   , 0.5405  , 0.5366  , 0.5293  , 0.525   , 0.515   ,\n",
       "            0.507   , 0.4983  , 0.4966  , 0.495   , 0.4714  , 0.4673  ,\n",
       "            0.4553  , 0.446   , 0.4365  , 0.4287  , 0.412   , 0.41    ,\n",
       "            0.4097  , 0.3994  , 0.3862  , 0.382   , 0.38    , 0.349   ,\n",
       "            0.3447  , 0.3276  , 0.3215  , 0.3176  , 0.2925  , 0.2693  ,\n",
       "            0.258   , 0.218   , 0.2079  , 0.1696  , 0.145   , 0.1188  ,\n",
       "            0.11066 , 0.1076  , 0.0991  , 0.0974  , 0.09534 , 0.09436 ,\n",
       "            0.0935  , 0.09186 , 0.0885  , 0.0818  , 0.08154 , 0.07385 ,\n",
       "            0.05997 , 0.05737 , 0.04208 , 0.01724 , 0.01359 , 0.006218],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.62711865, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.11016949, 0.11016949,\n",
       "            0.11016949, 0.11016949, 0.11016949, 0.11016949, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01515152, 0.06818182, 0.07575758, 0.09090909,\n",
       "            0.11363637, 0.13636364, 0.15151516, 0.18939394, 0.21212122,\n",
       "            0.22727273, 0.24242425, 0.25      , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3560606 , 0.36363637, 0.37121212, 0.37121212,\n",
       "            0.37878788, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.45454547, 0.46212122, 0.46969697, 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.8181818 , 0.82575756, 0.82575756, 0.8333333 , 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.999   , 0.9985  , 0.998   , 0.9976  ,\n",
       "            0.997   , 0.9966  , 0.9956  , 0.9946  , 0.994   , 0.9937  ,\n",
       "            0.993   , 0.9927  , 0.9917  , 0.991   , 0.9897  , 0.989   ,\n",
       "            0.9854  , 0.9834  , 0.9805  , 0.979   , 0.975   , 0.973   ,\n",
       "            0.9707  , 0.968   , 0.967   , 0.9565  , 0.955   , 0.951   ,\n",
       "            0.9478  , 0.9463  , 0.9443  , 0.9355  , 0.9316  , 0.9287  ,\n",
       "            0.9272  , 0.9253  , 0.92    , 0.916   , 0.9155  , 0.912   ,\n",
       "            0.9097  , 0.909   , 0.908   , 0.9077  , 0.907   , 0.9043  ,\n",
       "            0.899   , 0.898   , 0.8965  , 0.896   , 0.894   , 0.8926  ,\n",
       "            0.89    , 0.889   , 0.887   , 0.8867  , 0.885   , 0.8823  ,\n",
       "            0.8804  , 0.878   , 0.876   , 0.8755  , 0.875   , 0.8735  ,\n",
       "            0.8726  , 0.8706  , 0.8687  , 0.868   , 0.8643  , 0.8623  ,\n",
       "            0.862   , 0.8564  , 0.8525  , 0.85    , 0.8467  , 0.846   ,\n",
       "            0.8447  , 0.8413  , 0.839   , 0.8384  , 0.835   , 0.8335  ,\n",
       "            0.833   , 0.8306  , 0.829   , 0.8267  , 0.8247  , 0.815   ,\n",
       "            0.796   , 0.7954  , 0.7935  , 0.7896  , 0.788   , 0.7754  ,\n",
       "            0.7744  , 0.773   , 0.7705  , 0.7666  , 0.766   , 0.7627  ,\n",
       "            0.7573  , 0.756   , 0.7534  , 0.7495  , 0.749   , 0.7446  ,\n",
       "            0.7407  , 0.737   , 0.722   , 0.718   , 0.7134  , 0.7114  ,\n",
       "            0.701   , 0.6997  , 0.6978  , 0.697   , 0.696   , 0.6943  ,\n",
       "            0.6934  , 0.693   , 0.691   , 0.688   , 0.6855  , 0.6846  ,\n",
       "            0.6816  , 0.674   , 0.665   , 0.6626  , 0.659   , 0.657   ,\n",
       "            0.656   , 0.6494  , 0.6436  , 0.642   , 0.6353  , 0.632   ,\n",
       "            0.6304  , 0.629   , 0.6255  , 0.6235  , 0.6206  , 0.6104  ,\n",
       "            0.601   , 0.6006  , 0.5977  , 0.5967  , 0.5938  , 0.5933  ,\n",
       "            0.593   , 0.5923  , 0.582   , 0.581   , 0.5693  , 0.5684  ,\n",
       "            0.565   , 0.552   , 0.5513  , 0.549   , 0.531   , 0.517   ,\n",
       "            0.516   , 0.4973  , 0.4807  , 0.4688  , 0.4658  , 0.452   ,\n",
       "            0.4517  , 0.4336  , 0.425   , 0.424   , 0.4126  , 0.4028  ,\n",
       "            0.3987  , 0.3948  , 0.3652  , 0.3628  , 0.3433  , 0.34    ,\n",
       "            0.3352  , 0.3071  , 0.283   , 0.2727  , 0.2335  , 0.2238  ,\n",
       "            0.1776  , 0.1528  , 0.1245  , 0.11597 , 0.1138  , 0.10486 ,\n",
       "            0.1021  , 0.10126 , 0.1     , 0.0981  , 0.0967  , 0.0937  ,\n",
       "            0.0874  , 0.0856  , 0.0792  , 0.0642  , 0.06152 , 0.04553 ,\n",
       "            0.01909 , 0.01439 , 0.006588], dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.05      , 0.06666667, 0.075     , 0.08333334, 0.1       ,\n",
       "            0.11666667, 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.15833333, 0.175     , 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.25833333, 0.25833333, 0.26666668, 0.26666668,\n",
       "            0.26666668, 0.28333333, 0.28333333, 0.28333333, 0.29166666,\n",
       "            0.3       , 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.325     , 0.325     , 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.4       , 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.425     , 0.425     ,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45      , 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.51666665, 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.575     , 0.575     , 0.5833333 , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.6       , 0.60833335, 0.60833335,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.6333333 ,\n",
       "            0.6333333 , 0.6333333 , 0.64166665, 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.675     , 0.68333334, 0.68333334, 0.68333334,\n",
       "            0.68333334, 0.68333334, 0.69166666, 0.7       , 0.7       ,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.71666664, 0.725     ,\n",
       "            0.725     , 0.725     , 0.7416667 , 0.75      , 0.75      ,\n",
       "            0.7583333 , 0.7583333 , 0.76666665, 0.775     , 0.775     ,\n",
       "            0.775     , 0.78333336, 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.8       , 0.80833334, 0.80833334, 0.80833334, 0.80833334,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.8333333 ,\n",
       "            0.84166664, 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.8666667 , 0.8666667 , 0.8666667 , 0.875     , 0.875     ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.89166665, 0.89166665,\n",
       "            0.89166665, 0.89166665, 0.89166665, 0.89166665, 0.89166665,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.90833336, 0.90833336,\n",
       "            0.9166667 , 0.9166667 , 0.925     , 0.925     , 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.93333334, 0.94166666, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.975     , 0.975     , 0.98333335, 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.03076923, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.04615385, 0.05384615, 0.06153846, 0.08461539,\n",
       "            0.08461539, 0.08461539, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.14615385, 0.14615385, 0.15384616, 0.16153847, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.24615385,\n",
       "            0.24615385, 0.24615385, 0.25384617, 0.26153848, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.2923077 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33076924, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.3923077 , 0.4       , 0.4076923 , 0.4076923 ,\n",
       "            0.4076923 , 0.4076923 , 0.4076923 , 0.4076923 , 0.42307693,\n",
       "            0.42307693, 0.42307693, 0.43076923, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.44615385, 0.44615385, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46153846, 0.46153846, 0.46153846, 0.46923077,\n",
       "            0.4846154 , 0.4923077 , 0.4923077 , 0.4923077 , 0.4923077 ,\n",
       "            0.4923077 , 0.5       , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.5307692 , 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.54615384, 0.54615384, 0.5538462 , 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5769231 , 0.5923077 ,\n",
       "            0.5923077 , 0.6       , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.63846153, 0.63846153,\n",
       "            0.64615387, 0.64615387, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6846154 , 0.6846154 , 0.6923077 ,\n",
       "            0.6923077 , 0.7       , 0.7       , 0.7       , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.72307694, 0.73846155,\n",
       "            0.74615383, 0.76153845, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.484 , 0.4832, 0.4814, 0.48  , 0.4768, 0.4734, 0.473 ,\n",
       "            0.472 , 0.47  , 0.469 , 0.4688, 0.465 , 0.4646, 0.4636, 0.4617,\n",
       "            0.461 , 0.4607, 0.4604, 0.4597, 0.4595, 0.459 , 0.4587, 0.4563,\n",
       "            0.456 , 0.4548, 0.454 , 0.4539, 0.4536, 0.4534, 0.4524, 0.4521,\n",
       "            0.4514, 0.4512, 0.451 , 0.4507, 0.4504, 0.4497, 0.4495, 0.449 ,\n",
       "            0.4478, 0.4475, 0.4473, 0.4465, 0.4436, 0.443 , 0.4421, 0.4414,\n",
       "            0.4404, 0.4402, 0.4387, 0.4385, 0.4377, 0.4375, 0.4363, 0.4355,\n",
       "            0.4353, 0.435 , 0.4343, 0.4338, 0.4329, 0.4302, 0.4297, 0.4294,\n",
       "            0.429 , 0.4287, 0.4285, 0.4282, 0.4277, 0.427 , 0.4268, 0.426 ,\n",
       "            0.4253, 0.425 , 0.4248, 0.4246, 0.4238, 0.4224, 0.422 , 0.4216,\n",
       "            0.4214, 0.421 , 0.4194, 0.4182, 0.4172, 0.4165, 0.4155, 0.4106,\n",
       "            0.4104, 0.4075, 0.402 , 0.4016, 0.3928, 0.3926, 0.3923, 0.392 ,\n",
       "            0.3906, 0.388 , 0.3865, 0.3818, 0.3816, 0.379 , 0.3755, 0.3733,\n",
       "            0.3726, 0.3718, 0.3716, 0.3706, 0.3694, 0.3687, 0.368 , 0.3674,\n",
       "            0.3652, 0.3645, 0.3635, 0.3628, 0.3625, 0.3623, 0.361 , 0.359 ,\n",
       "            0.3582, 0.3562, 0.3552, 0.355 , 0.3545, 0.3542, 0.354 , 0.3528,\n",
       "            0.3518, 0.3516, 0.3474, 0.3467, 0.3457, 0.345 , 0.3447, 0.3438,\n",
       "            0.3435, 0.341 , 0.3408, 0.3403, 0.34  , 0.338 , 0.3376, 0.337 ,\n",
       "            0.3367, 0.3364, 0.3362, 0.3325, 0.332 , 0.3318, 0.331 , 0.3308,\n",
       "            0.3284, 0.3276, 0.3274, 0.3257, 0.3242, 0.323 , 0.3225, 0.322 ,\n",
       "            0.3218, 0.3213, 0.321 , 0.3208, 0.3206, 0.3203, 0.3193, 0.319 ,\n",
       "            0.3184, 0.318 , 0.3179, 0.3174, 0.3171, 0.3162, 0.3157, 0.3152,\n",
       "            0.315 , 0.3147, 0.3142, 0.313 , 0.3127, 0.3123, 0.312 , 0.3118,\n",
       "            0.3115, 0.3105, 0.31  , 0.3096, 0.3086, 0.3079, 0.3074, 0.307 ,\n",
       "            0.3064, 0.3054, 0.3037, 0.3025, 0.3015, 0.2993, 0.2976, 0.2974,\n",
       "            0.293 , 0.2917, 0.2908, 0.2874, 0.2793, 0.2786, 0.255 , 0.2355],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.025     , 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.375     , 0.375     , 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.425     , 0.425     , 0.425     ,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.45      , 0.45      ,\n",
       "            0.45      , 0.45833334, 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.49166667, 0.49166667, 0.49166667,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.5083333 , 0.5083333 ,\n",
       "            0.5083333 , 0.5083333 , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.525     , 0.525     , 0.525     , 0.525     , 0.525     ,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.55      , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.59166664, 0.59166664, 0.6       , 0.6       , 0.60833335,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.625     , 0.625     ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65      , 0.65833336, 0.6666667 , 0.6666667 ,\n",
       "            0.68333334, 0.68333334, 0.68333334, 0.68333334, 0.69166666,\n",
       "            0.69166666, 0.69166666, 0.7       , 0.71666664, 0.725     ,\n",
       "            0.725     , 0.73333335, 0.73333335, 0.7416667 , 0.7416667 ,\n",
       "            0.7416667 , 0.7416667 , 0.75      , 0.7583333 , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.775     , 0.78333336, 0.8       ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.8333333 , 0.8333333 ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85      , 0.85      ,\n",
       "            0.85      , 0.85      , 0.85      , 0.85      , 0.85      ,\n",
       "            0.85833335, 0.85833335, 0.85833335, 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.9       , 0.90833336, 0.90833336, 0.9166667 , 0.9166667 ,\n",
       "            0.925     , 0.925     , 0.93333334, 0.93333334, 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.96666664, 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.02307692, 0.02307692, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.03846154, 0.04615385, 0.04615385,\n",
       "            0.05384615, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.13076924, 0.13076924,\n",
       "            0.14615385, 0.14615385, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.2       , 0.2       , 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.23846154, 0.24615385, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.31538463, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3846154 , 0.3846154 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.42307693, 0.43076923,\n",
       "            0.43076923, 0.43846154, 0.43846154, 0.43846154, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4846154 , 0.4923077 , 0.4923077 ,\n",
       "            0.50769234, 0.5153846 , 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.5538462 , 0.56153846, 0.56153846, 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.61538464, 0.61538464, 0.61538464,\n",
       "            0.63076925, 0.63076925, 0.63846153, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.6769231 , 0.6769231 , 0.6846154 ,\n",
       "            0.6846154 , 0.6846154 , 0.6923077 , 0.6923077 , 0.6923077 ,\n",
       "            0.7       , 0.7       , 0.7       , 0.7       , 0.7153846 ,\n",
       "            0.7307692 , 0.7307692 , 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.83076924, 0.8384615 , 0.8384615 ,\n",
       "            0.8384615 , 0.86153847, 0.86923075, 0.86923075, 0.86923075,\n",
       "            0.88461536, 0.8923077 , 0.9076923 , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4546, 0.4526, 0.4512, 0.4495, 0.4465, 0.4456, 0.4443,\n",
       "            0.4438, 0.4426, 0.4404, 0.44  , 0.4397, 0.437 , 0.4355, 0.4353,\n",
       "            0.4348, 0.4333, 0.4326, 0.432 , 0.4314, 0.4307, 0.4294, 0.428 ,\n",
       "            0.4277, 0.4272, 0.426 , 0.4238, 0.4226, 0.4211, 0.421 , 0.4204,\n",
       "            0.4194, 0.419 , 0.4187, 0.4167, 0.4165, 0.4158, 0.4148, 0.4124,\n",
       "            0.4114, 0.4111, 0.4097, 0.408 , 0.4072, 0.4067, 0.406 , 0.4058,\n",
       "            0.4053, 0.4043, 0.4036, 0.403 , 0.4028, 0.4016, 0.401 , 0.4001,\n",
       "            0.3994, 0.3992, 0.3977, 0.3967, 0.3965, 0.3962, 0.3955, 0.395 ,\n",
       "            0.3945, 0.393 , 0.3923, 0.3918, 0.391 , 0.39  , 0.3887, 0.388 ,\n",
       "            0.3877, 0.387 , 0.3867, 0.3865, 0.386 , 0.3857, 0.3853, 0.3848,\n",
       "            0.3845, 0.384 , 0.383 , 0.3823, 0.382 , 0.3818, 0.3806, 0.3804,\n",
       "            0.3796, 0.3792, 0.3784, 0.3782, 0.377 , 0.3752, 0.374 , 0.3733,\n",
       "            0.3728, 0.3708, 0.3694, 0.3687, 0.367 , 0.3665, 0.3652, 0.3638,\n",
       "            0.358 , 0.354 , 0.3508, 0.3489, 0.3464, 0.3462, 0.3438, 0.3403,\n",
       "            0.3347, 0.3345, 0.332 , 0.3308, 0.3293, 0.3284, 0.3271, 0.327 ,\n",
       "            0.326 , 0.3252, 0.3247, 0.3215, 0.321 , 0.318 , 0.3162, 0.3147,\n",
       "            0.311 , 0.3098, 0.309 , 0.3066, 0.3064, 0.306 , 0.304 , 0.303 ,\n",
       "            0.302 , 0.3018, 0.3015, 0.3005, 0.2993, 0.299 , 0.2964, 0.2954,\n",
       "            0.2947, 0.2942, 0.294 , 0.293 , 0.292 , 0.2915, 0.2908, 0.2903,\n",
       "            0.2896, 0.2869, 0.2854, 0.2852, 0.2847, 0.2842, 0.2837, 0.2832,\n",
       "            0.2825, 0.28  , 0.2766, 0.2756, 0.2754, 0.2751, 0.2742, 0.2737,\n",
       "            0.2732, 0.273 , 0.2727, 0.2722, 0.2715, 0.2712, 0.271 , 0.2703,\n",
       "            0.2698, 0.2695, 0.2693, 0.269 , 0.2668, 0.2664, 0.2654, 0.265 ,\n",
       "            0.2642, 0.2637, 0.2605, 0.26  , 0.2598, 0.2595, 0.2588, 0.2578,\n",
       "            0.2573, 0.2563, 0.2554, 0.2542, 0.2537, 0.2524, 0.2522, 0.252 ,\n",
       "            0.2512, 0.2487, 0.2478, 0.2474, 0.2458, 0.2445, 0.2413, 0.2399,\n",
       "            0.2382, 0.2366, 0.2302, 0.2252, 0.2222, 0.2   , 0.1791],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.10833333, 0.11666667, 0.125     , 0.14166667,\n",
       "            0.15833333, 0.175     , 0.18333334, 0.2       , 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.425     , 0.425     ,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.45      , 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.49166667, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.5083333 , 0.5083333 , 0.5083333 , 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.525     ,\n",
       "            0.525     , 0.525     , 0.525     , 0.525     , 0.525     ,\n",
       "            0.525     , 0.525     , 0.525     , 0.525     , 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.55      , 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.56666666,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.60833335, 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.625     , 0.625     , 0.625     ,\n",
       "            0.625     , 0.625     , 0.625     , 0.625     , 0.6333333 ,\n",
       "            0.6333333 , 0.6333333 , 0.64166665, 0.65      , 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.675     , 0.675     ,\n",
       "            0.68333334, 0.68333334, 0.69166666, 0.69166666, 0.69166666,\n",
       "            0.7       , 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.7583333 , 0.7583333 , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.775     , 0.775     , 0.775     , 0.775     , 0.78333336,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8       , 0.80833334, 0.81666666, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.84166664, 0.84166664, 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.8666667 , 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.8833333 , 0.89166665, 0.89166665, 0.9       , 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.925     , 0.925     , 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.94166666, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.96666664, 0.975     , 0.975     ,\n",
       "            0.98333335, 0.9916667 , 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.02307692, 0.02307692, 0.03076923,\n",
       "            0.03076923, 0.04615385, 0.05384615, 0.05384615, 0.05384615,\n",
       "            0.05384615, 0.06153846, 0.06923077, 0.07692308, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.1       ,\n",
       "            0.10769231, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.17692308, 0.1923077 , 0.1923077 ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.26923078,\n",
       "            0.2846154 , 0.3       , 0.31538463, 0.31538463, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.42307693, 0.43076923, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4846154 , 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.5153846 , 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.6230769 , 0.6230769 , 0.63846153,\n",
       "            0.63846153, 0.63846153, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.6615385 , 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6769231 , 0.6846154 , 0.6846154 , 0.6846154 , 0.6846154 ,\n",
       "            0.6923077 , 0.6923077 , 0.6923077 , 0.7       , 0.7153846 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.7307692 , 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.77692306, 0.7846154 , 0.7846154 ,\n",
       "            0.7923077 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.8769231 , 0.8923077 ,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.424 , 0.423 , 0.4216, 0.4214, 0.4185, 0.4163, 0.4158,\n",
       "            0.4138, 0.4126, 0.4124, 0.4114, 0.4102, 0.4087, 0.4058, 0.405 ,\n",
       "            0.404 , 0.403 , 0.4026, 0.4023, 0.4019, 0.4001, 0.3997, 0.3994,\n",
       "            0.3992, 0.399 , 0.3958, 0.3948, 0.392 , 0.3918, 0.391 , 0.3909,\n",
       "            0.3904, 0.3872, 0.385 , 0.3835, 0.3828, 0.3792, 0.3774, 0.3752,\n",
       "            0.3748, 0.3745, 0.3743, 0.3713, 0.371 , 0.3706, 0.37  , 0.369 ,\n",
       "            0.3667, 0.366 , 0.3657, 0.3635, 0.3594, 0.359 , 0.3577, 0.3574,\n",
       "            0.3564, 0.356 , 0.3557, 0.3555, 0.355 , 0.3545, 0.3535, 0.351 ,\n",
       "            0.3506, 0.3494, 0.349 , 0.3474, 0.3447, 0.3445, 0.3442, 0.344 ,\n",
       "            0.3423, 0.342 , 0.3408, 0.3396, 0.3389, 0.3381, 0.338 , 0.3372,\n",
       "            0.337 , 0.3354, 0.3342, 0.3337, 0.3328, 0.3315, 0.331 , 0.3306,\n",
       "            0.33  , 0.3293, 0.3276, 0.327 , 0.3267, 0.3218, 0.3196, 0.3186,\n",
       "            0.3147, 0.313 , 0.31  , 0.3093, 0.3079, 0.3062, 0.3025, 0.2979,\n",
       "            0.292 , 0.2903, 0.29  , 0.2883, 0.2876, 0.286 , 0.2856, 0.2817,\n",
       "            0.281 , 0.2805, 0.279 , 0.2783, 0.2776, 0.2764, 0.2754, 0.2725,\n",
       "            0.2715, 0.2712, 0.2673, 0.266 , 0.2632, 0.2622, 0.262 , 0.2612,\n",
       "            0.2607, 0.2595, 0.257 , 0.2554, 0.2544, 0.2532, 0.251 , 0.2507,\n",
       "            0.2498, 0.2493, 0.2489, 0.2474, 0.2463, 0.2456, 0.2451, 0.2444,\n",
       "            0.2441, 0.244 , 0.2433, 0.243 , 0.2426, 0.2418, 0.241 , 0.2401,\n",
       "            0.2399, 0.2384, 0.2346, 0.234 , 0.2334, 0.2323, 0.2319, 0.2313,\n",
       "            0.231 , 0.2306, 0.2301, 0.2299, 0.229 , 0.2285, 0.2281, 0.2277,\n",
       "            0.2272, 0.226 , 0.2256, 0.2255, 0.2247, 0.2242, 0.2239, 0.223 ,\n",
       "            0.2212, 0.2208, 0.2203, 0.2181, 0.2179, 0.2175, 0.217 , 0.2167,\n",
       "            0.2166, 0.2163, 0.2161, 0.2156, 0.2152, 0.215 , 0.2142, 0.2137,\n",
       "            0.2129, 0.2124, 0.2119, 0.2115, 0.2094, 0.2091, 0.2081, 0.2079,\n",
       "            0.2069, 0.2043, 0.2042, 0.2037, 0.2035, 0.2023, 0.2004, 0.1985,\n",
       "            0.1978, 0.1974, 0.1967, 0.1964, 0.1941, 0.1821, 0.1813, 0.1776,\n",
       "            0.1744, 0.1564, 0.1355], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.16666667, 0.175     , 0.19166666, 0.2       ,\n",
       "            0.21666667, 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.525     , 0.525     ,\n",
       "            0.525     , 0.525     , 0.525     , 0.525     , 0.525     ,\n",
       "            0.525     , 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.60833335, 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.625     , 0.625     ,\n",
       "            0.625     , 0.625     , 0.625     , 0.625     , 0.625     ,\n",
       "            0.625     , 0.6333333 , 0.65      , 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.68333334, 0.68333334,\n",
       "            0.68333334, 0.68333334, 0.69166666, 0.69166666, 0.69166666,\n",
       "            0.7       , 0.7       , 0.7       , 0.7083333 , 0.7083333 ,\n",
       "            0.7083333 , 0.7083333 , 0.725     , 0.725     , 0.7416667 ,\n",
       "            0.75      , 0.75      , 0.75      , 0.75      , 0.76666665,\n",
       "            0.775     , 0.775     , 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 ,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 , 0.8       ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.81666666, 0.81666666,\n",
       "            0.8333333 , 0.84166664, 0.84166664, 0.85      , 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.8833333 , 0.89166665, 0.89166665,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.93333334, 0.94166666, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.04615385, 0.04615385, 0.05384615, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.21538462, 0.23076923, 0.24615385, 0.26153848,\n",
       "            0.26923078, 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.47692308, 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.52307695, 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.6230769 , 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6769231 , 0.6769231 , 0.6846154 , 0.6846154 ,\n",
       "            0.6846154 , 0.6846154 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.75384617, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.83076924, 0.83076924,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3953 , 0.3948 , 0.3945 , 0.3933 , 0.392  , 0.3916 ,\n",
       "            0.389  , 0.3865 , 0.3853 , 0.385  , 0.383  , 0.382  , 0.3816 ,\n",
       "            0.3792 , 0.379  , 0.3782 , 0.3755 , 0.3748 , 0.374  , 0.3738 ,\n",
       "            0.3733 , 0.373  , 0.3726 , 0.3723 , 0.371  , 0.369  , 0.368  ,\n",
       "            0.3652 , 0.3643 , 0.364  , 0.362  , 0.3606 , 0.3564 , 0.3557 ,\n",
       "            0.353  , 0.3518 , 0.3503 , 0.3474 , 0.346  , 0.345  , 0.3447 ,\n",
       "            0.3435 , 0.3396 , 0.3381 , 0.3376 , 0.3357 , 0.3342 , 0.3333 ,\n",
       "            0.3289 , 0.328  , 0.3267 , 0.3264 , 0.3257 , 0.3252 , 0.325  ,\n",
       "            0.3247 , 0.3215 , 0.3206 , 0.3196 , 0.3193 , 0.3167 , 0.3164 ,\n",
       "            0.314  , 0.3127 , 0.3123 , 0.3113 , 0.3098 , 0.3096 , 0.3086 ,\n",
       "            0.3083 , 0.3052 , 0.3044 , 0.3037 , 0.3027 , 0.3018 , 0.301  ,\n",
       "            0.2998 , 0.2993 , 0.2986 , 0.2983 , 0.2966 , 0.2964 , 0.2957 ,\n",
       "            0.2932 , 0.292  , 0.2903 , 0.29   , 0.2898 , 0.2893 , 0.289  ,\n",
       "            0.286  , 0.2856 , 0.2852 , 0.282  , 0.2815 , 0.281  , 0.2793 ,\n",
       "            0.2786 , 0.2761 , 0.2737 , 0.2715 , 0.2712 , 0.268  , 0.266  ,\n",
       "            0.262  , 0.2598 , 0.2556 , 0.2554 , 0.2551 , 0.253  , 0.2524 ,\n",
       "            0.2507 , 0.2448 , 0.2437 , 0.243  , 0.2428 , 0.2421 , 0.2418 ,\n",
       "            0.2378 , 0.2356 , 0.2347 , 0.2339 , 0.231  , 0.2303 , 0.228  ,\n",
       "            0.2266 , 0.2264 , 0.2261 , 0.226  , 0.2255 , 0.2251 , 0.2238 ,\n",
       "            0.2205 , 0.2191 , 0.2177 , 0.2161 , 0.2135 , 0.213  , 0.2108 ,\n",
       "            0.2101 , 0.2084 , 0.2081 , 0.2073 , 0.2063 , 0.2054 , 0.2047 ,\n",
       "            0.2035 , 0.2028 , 0.2021 , 0.2    , 0.1989 , 0.197  , 0.196  ,\n",
       "            0.1958 , 0.1948 , 0.1947 , 0.1936 , 0.1935 , 0.1934 , 0.1927 ,\n",
       "            0.1923 , 0.1919 , 0.1915 , 0.1912 , 0.1909 , 0.1906 , 0.1904 ,\n",
       "            0.1885 , 0.1882 , 0.1876 , 0.1874 , 0.1863 , 0.186  , 0.1858 ,\n",
       "            0.1852 , 0.1844 , 0.1842 , 0.1829 , 0.1826 , 0.1799 , 0.1796 ,\n",
       "            0.179  , 0.1787 , 0.1785 , 0.1783 , 0.1772 , 0.1763 , 0.1757 ,\n",
       "            0.1755 , 0.1747 , 0.1737 , 0.1733 , 0.1724 , 0.1705 , 0.1704 ,\n",
       "            0.1703 , 0.1696 , 0.1685 , 0.1682 , 0.1681 , 0.1677 , 0.1672 ,\n",
       "            0.1663 , 0.166  , 0.1656 , 0.1637 , 0.1636 , 0.1631 , 0.162  ,\n",
       "            0.1619 , 0.161  , 0.1592 , 0.1575 , 0.1567 , 0.1539 , 0.1509 ,\n",
       "            0.145  , 0.1418 , 0.135  , 0.1304 , 0.12103, 0.10156],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.025     , 0.03333334, 0.04166667,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.08333334, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.49166667, 0.5       , 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.525     ,\n",
       "            0.525     , 0.525     , 0.525     , 0.525     , 0.525     ,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.56666666, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.59166664, 0.59166664,\n",
       "            0.59166664, 0.6       , 0.6       , 0.6       , 0.6       ,\n",
       "            0.60833335, 0.60833335, 0.60833335, 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65      , 0.65      ,\n",
       "            0.65      , 0.65      , 0.65      , 0.65      , 0.65833336,\n",
       "            0.65833336, 0.6666667 , 0.6666667 , 0.6666667 , 0.6666667 ,\n",
       "            0.6666667 , 0.675     , 0.675     , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.69166666, 0.69166666, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.73333335,\n",
       "            0.73333335, 0.73333335, 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.75      , 0.7583333 , 0.7583333 , 0.7583333 , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.775     , 0.775     , 0.775     ,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.78333336, 0.7916667 ,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.80833334, 0.80833334,\n",
       "            0.81666666, 0.81666666, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.89166665, 0.9       , 0.90833336,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00769231, 0.01538462, 0.02307692, 0.02307692, 0.03076923,\n",
       "            0.03076923, 0.03076923, 0.03846154, 0.03846154, 0.04615385,\n",
       "            0.04615385, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.14615385, 0.15384616, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.20769231, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.2923077 , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.46923077, 0.47692308, 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.56153846, 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6       , 0.6076923 ,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.6846154 ,\n",
       "            0.6846154 , 0.6846154 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.7846154 , 0.7923077 , 0.7923077 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.8230769 , 0.8230769 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3691 , 0.366  , 0.3655 , 0.365  , 0.362  , 0.3613 ,\n",
       "            0.361  , 0.3596 , 0.3577 , 0.3567 , 0.3547 , 0.3538 , 0.3533 ,\n",
       "            0.353  , 0.3528 , 0.352  , 0.3513 , 0.3499 , 0.348  , 0.3477 ,\n",
       "            0.3472 , 0.347  , 0.3467 , 0.3462 , 0.3447 , 0.344  , 0.3428 ,\n",
       "            0.3416 , 0.3396 , 0.3381 , 0.338  , 0.3376 , 0.3352 , 0.3347 ,\n",
       "            0.3303 , 0.33   , 0.3296 , 0.326  , 0.3252 , 0.324  , 0.321  ,\n",
       "            0.3188 , 0.3174 , 0.317  , 0.3164 , 0.3125 , 0.3108 , 0.31   ,\n",
       "            0.309  , 0.306  , 0.304  , 0.3035 , 0.3    , 0.2976 , 0.2974 ,\n",
       "            0.2969 , 0.2957 , 0.2952 , 0.295  , 0.2942 , 0.2925 , 0.2903 ,\n",
       "            0.288  , 0.2878 , 0.2847 , 0.2827 , 0.2812 , 0.281  , 0.2805 ,\n",
       "            0.279  , 0.2773 , 0.2769 , 0.2761 , 0.273  , 0.272  , 0.2715 ,\n",
       "            0.2708 , 0.2695 , 0.269  , 0.2683 , 0.268  , 0.2678 , 0.2654 ,\n",
       "            0.265  , 0.2646 , 0.2625 , 0.2622 , 0.261  , 0.2588 , 0.2585 ,\n",
       "            0.2563 , 0.256  , 0.2559 , 0.2551 , 0.255  , 0.2507 , 0.2502 ,\n",
       "            0.2498 , 0.2496 , 0.2462 , 0.2456 , 0.2441 , 0.2434 , 0.2418 ,\n",
       "            0.2407 , 0.2378 , 0.2356 , 0.2297 , 0.2252 , 0.2246 , 0.223  ,\n",
       "            0.2229 , 0.2208 , 0.2203 , 0.2186 , 0.215  , 0.2128 , 0.211  ,\n",
       "            0.2058 , 0.2053 , 0.2045 , 0.2039 , 0.2009 , 0.2    , 0.1971 ,\n",
       "            0.197  , 0.1962 , 0.1958 , 0.1953 , 0.1947 , 0.1943 , 0.1935 ,\n",
       "            0.1909 , 0.1904 , 0.1885 , 0.1882 , 0.1876 , 0.1864 , 0.1841 ,\n",
       "            0.1836 , 0.181  , 0.1803 , 0.1783 , 0.1781 , 0.1771 , 0.1764 ,\n",
       "            0.1757 , 0.1735 , 0.1726 , 0.1681 , 0.1675 , 0.1666 , 0.1656 ,\n",
       "            0.1648 , 0.1647 , 0.1641 , 0.1638 , 0.1637 , 0.1633 , 0.1621 ,\n",
       "            0.1619 , 0.1617 , 0.1614 , 0.1611 , 0.1608 , 0.1604 , 0.1593 ,\n",
       "            0.159  , 0.1577 , 0.1567 , 0.1565 , 0.1558 , 0.1548 , 0.1544 ,\n",
       "            0.1539 , 0.1531 , 0.1527 , 0.1523 , 0.1515 , 0.1506 , 0.1505 ,\n",
       "            0.1501 , 0.15   , 0.1499 , 0.1498 , 0.1497 , 0.1493 , 0.1489 ,\n",
       "            0.1488 , 0.1478 , 0.1475 , 0.1473 , 0.1467 , 0.1456 , 0.1455 ,\n",
       "            0.1434 , 0.143  , 0.1422 , 0.1416 , 0.1407 , 0.139  , 0.1388 ,\n",
       "            0.1384 , 0.1368 , 0.1365 , 0.135  , 0.1345 , 0.1344 , 0.1339 ,\n",
       "            0.1335 , 0.1326 , 0.1324 , 0.1322 , 0.1299 , 0.1296 , 0.1294 ,\n",
       "            0.1292 , 0.1285 , 0.1283 , 0.1278 , 0.1276 , 0.1236 , 0.12335,\n",
       "            0.1195 , 0.11694, 0.115  , 0.1099 , 0.1045 , 0.09534, 0.09467,\n",
       "            0.07697], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.05      , 0.05833333, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.11666667, 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.175     , 0.18333334, 0.2       , 0.21666667,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.49166667,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.525     , 0.525     , 0.525     , 0.525     ,\n",
       "            0.525     , 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.56666666, 0.56666666, 0.56666666, 0.575     ,\n",
       "            0.575     , 0.5833333 , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.6       , 0.6       , 0.6       , 0.6       , 0.6       ,\n",
       "            0.60833335, 0.60833335, 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.625     , 0.625     , 0.625     , 0.625     ,\n",
       "            0.625     , 0.625     , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.64166665, 0.64166665, 0.64166665, 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65      , 0.65833336, 0.6666667 , 0.6666667 ,\n",
       "            0.6666667 , 0.6666667 , 0.675     , 0.675     , 0.675     ,\n",
       "            0.675     , 0.675     , 0.68333334, 0.68333334, 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.7083333 , 0.71666664,\n",
       "            0.71666664, 0.71666664, 0.71666664, 0.725     , 0.73333335,\n",
       "            0.75      , 0.75      , 0.7583333 , 0.76666665, 0.76666665,\n",
       "            0.76666665, 0.775     , 0.775     , 0.775     , 0.78333336,\n",
       "            0.78333336, 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.81666666, 0.825     , 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.03076923, 0.03076923, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.04615385, 0.04615385, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23846154, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.56153846,\n",
       "            0.5692308 , 0.5692308 , 0.5769231 , 0.5769231 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.72307694, 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.77692306,\n",
       "            0.77692306, 0.7846154 , 0.7846154 , 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.86923075, 0.86923075,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3423 , 0.3403 , 0.338  , 0.3372 , 0.337  , 0.3367 ,\n",
       "            0.3354 , 0.3333 , 0.3328 , 0.3298 , 0.3293 , 0.329  , 0.328  ,\n",
       "            0.3271 , 0.3257 , 0.3254 , 0.3232 , 0.3228 , 0.3225 , 0.322  ,\n",
       "            0.3215 , 0.3213 , 0.3188 , 0.3184 , 0.3176 , 0.3171 , 0.3154 ,\n",
       "            0.3145 , 0.3137 , 0.3132 , 0.3113 , 0.3108 , 0.3066 , 0.3057 ,\n",
       "            0.3022 , 0.3003 , 0.3    , 0.2976 , 0.2947 , 0.2937 , 0.2917 ,\n",
       "            0.2913 , 0.2886 , 0.2861 , 0.286  , 0.2852 , 0.282  , 0.2817 ,\n",
       "            0.2786 , 0.2756 , 0.2727 , 0.2725 , 0.2722 , 0.2717 , 0.27   ,\n",
       "            0.2695 , 0.2688 , 0.268  , 0.2656 , 0.263  , 0.2627 , 0.2612 ,\n",
       "            0.2595 , 0.258  , 0.2573 , 0.2554 , 0.254  , 0.2537 , 0.2524 ,\n",
       "            0.251  , 0.2474 , 0.2473 , 0.2467 , 0.2466 , 0.2463 , 0.2455 ,\n",
       "            0.2444 , 0.2434 , 0.2433 , 0.2422 , 0.2399 , 0.2395 , 0.2386 ,\n",
       "            0.2379 , 0.2367 , 0.2363 , 0.234  , 0.2334 , 0.2323 , 0.2313 ,\n",
       "            0.231  , 0.2307 , 0.2306 , 0.2297 , 0.229  , 0.2283 , 0.226  ,\n",
       "            0.2257 , 0.2252 , 0.2212 , 0.2207 , 0.22   , 0.219  , 0.2181 ,\n",
       "            0.2152 , 0.2133 , 0.2096 , 0.202  , 0.2002 , 0.2001 , 0.1996 ,\n",
       "            0.1985 , 0.196  , 0.1947 , 0.1921 , 0.1897 , 0.189  , 0.1882 ,\n",
       "            0.1864 , 0.18   , 0.1785 , 0.1779 , 0.1755 , 0.1747 , 0.1741 ,\n",
       "            0.1725 , 0.1721 , 0.1708 , 0.1704 , 0.1696 , 0.1681 , 0.1676 ,\n",
       "            0.1675 , 0.166  , 0.1649 , 0.1638 , 0.1632 , 0.1614 , 0.1609 ,\n",
       "            0.1603 , 0.159  , 0.1583 , 0.1581 , 0.1567 , 0.1558 , 0.1554 ,\n",
       "            0.154  , 0.1539 , 0.1532 , 0.1519 , 0.1433 , 0.1425 , 0.1422 ,\n",
       "            0.1421 , 0.142  , 0.1417 , 0.1409 , 0.14   , 0.1396 , 0.1395 ,\n",
       "            0.1393 , 0.1387 , 0.1384 , 0.1383 , 0.1382 , 0.1376 , 0.1357 ,\n",
       "            0.1354 , 0.1353 , 0.1343 , 0.1333 , 0.133  , 0.132  , 0.1305 ,\n",
       "            0.1294 , 0.1292 , 0.129  , 0.1289 , 0.1287 , 0.1282 , 0.1279 ,\n",
       "            0.1274 , 0.1273 , 0.1272 , 0.1268 , 0.1267 , 0.1257 , 0.12463,\n",
       "            0.1245 , 0.1225 , 0.1222 , 0.12177, 0.1217 , 0.12146, 0.12024,\n",
       "            0.1194 , 0.11816, 0.118  , 0.11755, 0.11615, 0.11456, 0.11395,\n",
       "            0.1138 , 0.1122 , 0.11145, 0.11084, 0.10913, 0.10895, 0.1084 ,\n",
       "            0.1082 , 0.1078 , 0.1065 , 0.1056 , 0.1041 , 0.1034 , 0.103  ,\n",
       "            0.10284, 0.10266, 0.1019 , 0.1011 , 0.0993 , 0.0974 , 0.09503,\n",
       "            0.0901 , 0.0873 , 0.0825 , 0.07654, 0.0725 , 0.06064],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.11666667, 0.125     , 0.13333334,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.19166666,\n",
       "            0.21666667, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.49166667, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.525     , 0.525     , 0.525     , 0.525     ,\n",
       "            0.525     , 0.525     , 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.56666666, 0.56666666, 0.575     , 0.575     ,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.6       ,\n",
       "            0.6       , 0.6       , 0.6       , 0.60833335, 0.60833335,\n",
       "            0.60833335, 0.60833335, 0.60833335, 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.6333333 , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.65833336, 0.65833336, 0.65833336, 0.65833336, 0.6666667 ,\n",
       "            0.6666667 , 0.6666667 , 0.6666667 , 0.6666667 , 0.675     ,\n",
       "            0.675     , 0.675     , 0.675     , 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.71666664, 0.725     , 0.73333335,\n",
       "            0.73333335, 0.7583333 , 0.76666665, 0.76666665, 0.775     ,\n",
       "            0.775     , 0.78333336, 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.8833333 ,\n",
       "            0.89166665, 0.89166665, 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.03076923, 0.03076923, 0.03846154, 0.04615385,\n",
       "            0.04615385, 0.04615385, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.15384616, 0.16153847, 0.16153847, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5769231 , 0.5846154 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8       , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.84615386, 0.84615386,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3157 , 0.3142 , 0.3137 , 0.3135 , 0.3123 , 0.31   ,\n",
       "            0.3093 , 0.3088 , 0.3086 , 0.307  , 0.3066 , 0.3052 , 0.305  ,\n",
       "            0.304  , 0.3032 , 0.3022 , 0.302  , 0.3005 , 0.3    , 0.2998 ,\n",
       "            0.2996 , 0.2988 , 0.2969 , 0.2966 , 0.2952 , 0.2944 , 0.2935 ,\n",
       "            0.2925 , 0.2922 , 0.2915 , 0.291  , 0.289  , 0.2876 , 0.287  ,\n",
       "            0.2852 , 0.2827 , 0.28   , 0.2786 , 0.278  , 0.276  , 0.2742 ,\n",
       "            0.2703 , 0.27   , 0.2673 , 0.2664 , 0.2654 , 0.2651 , 0.263  ,\n",
       "            0.2588 , 0.2573 , 0.2534 , 0.2532 , 0.253  , 0.251  , 0.25   ,\n",
       "            0.2493 , 0.2487 , 0.247  , 0.2451 , 0.2434 , 0.2433 , 0.2421 ,\n",
       "            0.2405 , 0.2379 , 0.2378 , 0.2363 , 0.236  , 0.2355 , 0.235  ,\n",
       "            0.2322 , 0.2316 , 0.2302 , 0.2292 , 0.2283 , 0.2281 , 0.2269 ,\n",
       "            0.2263 , 0.2242 , 0.2233 , 0.2217 , 0.2216 , 0.219  , 0.2185 ,\n",
       "            0.2175 , 0.2172 , 0.2153 , 0.2148 , 0.2135 , 0.2133 , 0.213  ,\n",
       "            0.212  , 0.2113 , 0.2108 , 0.2096 , 0.2084 , 0.206  , 0.2056 ,\n",
       "            0.2047 , 0.2045 , 0.2009 , 0.1981 , 0.1978 , 0.1919 , 0.1863 ,\n",
       "            0.1855 , 0.1848 , 0.1836 , 0.1831 , 0.182  , 0.1797 , 0.177  ,\n",
       "            0.1752 , 0.1733 , 0.1711 , 0.1696 , 0.1658 , 0.1656 , 0.1632 ,\n",
       "            0.161  , 0.1605 , 0.1588 , 0.1572 , 0.1561 , 0.1559 , 0.1558 ,\n",
       "            0.1545 , 0.1533 , 0.1509 , 0.1503 , 0.1494 , 0.1493 , 0.1488 ,\n",
       "            0.1472 , 0.1469 , 0.145  , 0.1438 , 0.1437 , 0.1426 , 0.1422 ,\n",
       "            0.1416 , 0.1415 , 0.1411 , 0.1381 , 0.1326 , 0.1307 , 0.1304 ,\n",
       "            0.13   , 0.1289 , 0.1273 , 0.1271 , 0.1265 , 0.1254 , 0.1252 ,\n",
       "            0.1251 , 0.1236 , 0.12317, 0.12305, 0.12274, 0.1216 , 0.1204 ,\n",
       "            0.1192 , 0.119  , 0.1188 , 0.1184 , 0.1178 , 0.1172 , 0.11633,\n",
       "            0.11597, 0.11554, 0.11536, 0.11456, 0.1136 , 0.1124 , 0.112  ,\n",
       "            0.111  , 0.11084, 0.1084 , 0.1078 , 0.1076 , 0.10614, 0.10596,\n",
       "            0.10504, 0.1034 , 0.103  , 0.10126, 0.1011 , 0.0995 , 0.09875,\n",
       "            0.0979 , 0.09753, 0.09705, 0.09686, 0.0964 , 0.0945 , 0.0935 ,\n",
       "            0.0927 , 0.09125, 0.0909 , 0.0901 , 0.0887 , 0.0883 , 0.0879 ,\n",
       "            0.0874 , 0.0869 , 0.086  , 0.0857 , 0.0825 , 0.08093, 0.076  ,\n",
       "            0.07477, 0.0707 , 0.06805, 0.0602 , 0.0531 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.06666667, 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.14166667, 0.15      ,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.21666667, 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.275     , 0.28333333, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.33333334, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.45      , 0.45      , 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.475     , 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.5       , 0.5       , 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.525     , 0.525     , 0.525     , 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.56666666, 0.56666666,\n",
       "            0.56666666, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.59166664, 0.59166664, 0.59166664, 0.6       , 0.6       ,\n",
       "            0.6       , 0.60833335, 0.60833335, 0.60833335, 0.60833335,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.625     , 0.625     , 0.625     , 0.625     ,\n",
       "            0.625     , 0.6333333 , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65      , 0.65833336, 0.65833336, 0.65833336,\n",
       "            0.65833336, 0.6666667 , 0.6666667 , 0.675     , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.7083333 , 0.71666664, 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.76666665, 0.775     , 0.775     ,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.02307692, 0.02307692, 0.03846154, 0.03846154,\n",
       "            0.03846154, 0.04615385, 0.04615385, 0.06153846, 0.06153846,\n",
       "            0.06923077, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.15384616,\n",
       "            0.15384616, 0.16923077, 0.17692308, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.32307693, 0.33076924, 0.33076924, 0.33846155,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.6230769 , 0.6230769 , 0.6230769 , 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9076923 , 0.9076923 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.295  , 0.2947 , 0.2937 , 0.292  , 0.2917 , 0.2903 ,\n",
       "            0.289  , 0.288  , 0.2874 , 0.2869 , 0.2866 , 0.2847 , 0.2844 ,\n",
       "            0.2842 , 0.284  , 0.2837 , 0.2834 , 0.283  , 0.2822 , 0.282  ,\n",
       "            0.281  , 0.2808 , 0.2805 , 0.28   , 0.279  , 0.2788 , 0.2786 ,\n",
       "            0.2783 , 0.2776 , 0.2769 , 0.2756 , 0.2742 , 0.2732 , 0.272  ,\n",
       "            0.269  , 0.2676 , 0.2668 , 0.2646 , 0.2625 , 0.2595 , 0.2593 ,\n",
       "            0.258  , 0.2578 , 0.2566 , 0.2556 , 0.2515 , 0.2502 , 0.2471 ,\n",
       "            0.2463 , 0.2458 , 0.2452 , 0.2437 , 0.2422 , 0.2418 , 0.2397 ,\n",
       "            0.2378 , 0.2363 , 0.2358 , 0.2338 , 0.2327 , 0.2319 , 0.2314 ,\n",
       "            0.231  , 0.2307 , 0.2302 , 0.2295 , 0.2277 , 0.2257 , 0.2256 ,\n",
       "            0.2252 , 0.2246 , 0.2239 , 0.2238 , 0.2211 , 0.22   , 0.2197 ,\n",
       "            0.2194 , 0.2184 , 0.2179 , 0.2168 , 0.2145 , 0.2124 , 0.2123 ,\n",
       "            0.212  , 0.2118 , 0.2114 , 0.2109 , 0.2106 , 0.2096 , 0.2094 ,\n",
       "            0.2073 , 0.2064 , 0.206  , 0.2043 , 0.2015 , 0.1985 , 0.1967 ,\n",
       "            0.1921 , 0.1915 , 0.1891 , 0.1864 , 0.185  , 0.183  , 0.182  ,\n",
       "            0.1812 , 0.1757 , 0.174  , 0.173  , 0.1707 , 0.1678 , 0.167  ,\n",
       "            0.1659 , 0.1658 , 0.1637 , 0.1631 , 0.16   , 0.1586 , 0.1584 ,\n",
       "            0.1575 , 0.1561 , 0.1534 , 0.1532 , 0.1531 , 0.151  , 0.1504 ,\n",
       "            0.1498 , 0.1494 , 0.1484 , 0.1464 , 0.1461 , 0.1454 , 0.1453 ,\n",
       "            0.1447 , 0.1445 , 0.1444 , 0.1437 , 0.143  , 0.1427 , 0.1426 ,\n",
       "            0.1377 , 0.1366 , 0.1343 , 0.1329 , 0.1328 , 0.1323 , 0.1312 ,\n",
       "            0.1307 , 0.1304 , 0.1288 , 0.1284 , 0.1272 , 0.1271 , 0.127  ,\n",
       "            0.1263 , 0.1255 , 0.1251 , 0.1232 , 0.12305, 0.1229 , 0.12274,\n",
       "            0.1223 , 0.12177, 0.1213 , 0.1204 , 0.12036, 0.1201 , 0.1192 ,\n",
       "            0.1188 , 0.1186 , 0.1184 , 0.11694, 0.11554, 0.11536, 0.1144 ,\n",
       "            0.1128 , 0.1122 , 0.1118 , 0.11163, 0.111  , 0.1101 , 0.1099 ,\n",
       "            0.1095 , 0.1082 , 0.10706, 0.1056 , 0.1054 , 0.1052 , 0.1047 ,\n",
       "            0.10376, 0.103  , 0.10126, 0.0995 , 0.0991 , 0.09845, 0.09686,\n",
       "            0.096  , 0.09467, 0.0935 , 0.0925 , 0.09204, 0.09106, 0.0903 ,\n",
       "            0.0888 , 0.0883 , 0.0879 , 0.0877 , 0.0876 , 0.0869 , 0.086  ,\n",
       "            0.08374, 0.08124, 0.0764 , 0.07556, 0.07184, 0.0716 , 0.0613 ,\n",
       "            0.05594], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.01666667, 0.025     , 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.08333334, 0.09166667,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.19166666, 0.2       , 0.20833333, 0.225     ,\n",
       "            0.23333333, 0.25      , 0.25833333, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5       ,\n",
       "            0.5083333 , 0.5083333 , 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.525     , 0.525     , 0.525     , 0.525     , 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.5416667 , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.56666666,\n",
       "            0.56666666, 0.56666666, 0.575     , 0.575     , 0.575     ,\n",
       "            0.575     , 0.575     , 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.60833335, 0.60833335, 0.60833335,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.625     ,\n",
       "            0.625     , 0.625     , 0.625     , 0.625     , 0.625     ,\n",
       "            0.625     , 0.625     , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65      , 0.65833336, 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.675     , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.725     , 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.8       , 0.80833334, 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00769231, 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.03076923, 0.03846154, 0.04615385,\n",
       "            0.04615385, 0.05384615, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.06923077, 0.07692308, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.11538462, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.17692308, 0.1923077 , 0.2       , 0.21538462, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.36923078, 0.36923078, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.6615385 , 0.66923076,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6923077 , 0.7       ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.288  , 0.287  , 0.2866 , 0.285  , 0.2842 , 0.2837 ,\n",
       "            0.2827 , 0.282  , 0.2817 , 0.2815 , 0.2812 , 0.2808 , 0.28   ,\n",
       "            0.2795 , 0.2786 , 0.2783 , 0.278  , 0.2778 , 0.2776 , 0.2773 ,\n",
       "            0.277  , 0.2766 , 0.276  , 0.2747 , 0.2744 , 0.2742 , 0.2715 ,\n",
       "            0.271  , 0.2708 , 0.2705 , 0.2703 , 0.2688 , 0.2686 , 0.2683 ,\n",
       "            0.268  , 0.2678 , 0.266  , 0.2651 , 0.265  , 0.2646 , 0.2634 ,\n",
       "            0.2632 , 0.2622 , 0.2617 , 0.258  , 0.257  , 0.2554 , 0.255  ,\n",
       "            0.2537 , 0.2534 , 0.253  , 0.2527 , 0.2515 , 0.2512 , 0.2493 ,\n",
       "            0.2489 , 0.2485 , 0.2467 , 0.2466 , 0.2463 , 0.2456 , 0.2455 ,\n",
       "            0.244  , 0.2438 , 0.2437 , 0.2418 , 0.2413 , 0.2411 , 0.2401 ,\n",
       "            0.2386 , 0.2379 , 0.2372 , 0.236  , 0.2356 , 0.2355 , 0.2352 ,\n",
       "            0.2343 , 0.233  , 0.2318 , 0.2306 , 0.2297 , 0.2292 , 0.2264 ,\n",
       "            0.226  , 0.2257 , 0.2256 , 0.2255 , 0.2239 , 0.223  , 0.2227 ,\n",
       "            0.2217 , 0.219  , 0.2189 , 0.217  , 0.2142 , 0.214  , 0.2103 ,\n",
       "            0.2095 , 0.2069 , 0.2004 , 0.1987 , 0.1976 , 0.1964 , 0.196  ,\n",
       "            0.1948 , 0.1903 , 0.187  , 0.185  , 0.1844 , 0.1838 , 0.1814 ,\n",
       "            0.1813 , 0.1803 , 0.1792 , 0.1788 , 0.1754 , 0.1748 , 0.1738 ,\n",
       "            0.1726 , 0.1699 , 0.1672 , 0.1671 , 0.1665 , 0.1656 , 0.1646 ,\n",
       "            0.1641 , 0.1635 , 0.162  , 0.1619 , 0.1617 , 0.1611 , 0.1602 ,\n",
       "            0.1599 , 0.1586 , 0.1575 , 0.1558 , 0.1556 , 0.1538 , 0.1515 ,\n",
       "            0.1511 , 0.15   , 0.1489 , 0.1486 , 0.1481 , 0.1472 , 0.146  ,\n",
       "            0.1445 , 0.1444 , 0.1438 , 0.1432 , 0.1425 , 0.1418 , 0.1407 ,\n",
       "            0.1405 , 0.1404 , 0.1401 , 0.1398 , 0.1392 , 0.1382 , 0.138  ,\n",
       "            0.137  , 0.1366 , 0.1361 , 0.1355 , 0.1349 , 0.1343 , 0.134  ,\n",
       "            0.1334 , 0.1328 , 0.1327 , 0.1322 , 0.1311 , 0.1302 , 0.1287 ,\n",
       "            0.1282 , 0.127  , 0.1268 , 0.1266 , 0.12463, 0.12445, 0.124  ,\n",
       "            0.1235 , 0.1217 , 0.1216 , 0.1214 , 0.12067, 0.1193 , 0.1188 ,\n",
       "            0.1172 , 0.11694, 0.11676, 0.115  , 0.11395, 0.1138 , 0.1128 ,\n",
       "            0.11163, 0.1103 , 0.10895, 0.1086 , 0.1076 , 0.1063 , 0.1052 ,\n",
       "            0.10394, 0.1023 , 0.1021 , 0.1019 , 0.1011 , 0.10034, 0.10016,\n",
       "            0.0991 , 0.09827, 0.09753, 0.0964 , 0.0925 , 0.0877 , 0.0871 ,\n",
       "            0.0862 , 0.08344, 0.07196, 0.0682 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.01666667, 0.025     , 0.03333334, 0.04166667,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.1       , 0.10833333,\n",
       "            0.11666667, 0.13333334, 0.14166667, 0.16666667, 0.175     ,\n",
       "            0.19166666, 0.2       , 0.21666667, 0.23333333, 0.24166666,\n",
       "            0.25      , 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.325     , 0.33333334,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.39166668, 0.39166668, 0.4       , 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.46666667, 0.475     , 0.475     , 0.48333332, 0.49166667,\n",
       "            0.49166667, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5083333 , 0.5083333 , 0.5083333 , 0.5083333 , 0.5083333 ,\n",
       "            0.51666665, 0.51666665, 0.525     , 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.5416667 , 0.5416667 , 0.5416667 , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.575     , 0.575     , 0.575     , 0.575     , 0.575     ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.59166664, 0.59166664,\n",
       "            0.6       , 0.6       , 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.625     , 0.625     ,\n",
       "            0.625     , 0.625     , 0.625     , 0.625     , 0.625     ,\n",
       "            0.6333333 , 0.6333333 , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.68333334, 0.68333334, 0.69166666, 0.7       , 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.7916667 , 0.8       , 0.8       , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.04615385, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.12307692, 0.12307692, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.14615385, 0.15384616, 0.16923077,\n",
       "            0.16923077, 0.16923077, 0.17692308, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.1923077 , 0.2       , 0.20769231, 0.22307692,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.25384617, 0.26153848,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.3923077 , 0.4       , 0.4076923 , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7076923 , 0.7153846 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.278  , 0.2766 , 0.2764 , 0.276  , 0.2756 , 0.2754 ,\n",
       "            0.2747 , 0.2744 , 0.2742 , 0.274  , 0.2737 , 0.2734 , 0.2732 ,\n",
       "            0.2722 , 0.272  , 0.2717 , 0.2712 , 0.2705 , 0.2703 , 0.2698 ,\n",
       "            0.2695 , 0.2688 , 0.2683 , 0.268  , 0.2678 , 0.267  , 0.2668 ,\n",
       "            0.2664 , 0.266  , 0.2654 , 0.265  , 0.2642 , 0.2637 , 0.263  ,\n",
       "            0.2622 , 0.2615 , 0.2607 , 0.2605 , 0.2603 , 0.26   , 0.2595 ,\n",
       "            0.2593 , 0.2588 , 0.2585 , 0.2578 , 0.2576 , 0.257  , 0.2563 ,\n",
       "            0.256  , 0.2556 , 0.255  , 0.2542 , 0.254  , 0.2534 , 0.2524 ,\n",
       "            0.252  , 0.2515 , 0.2512 , 0.2502 , 0.249  , 0.2483 , 0.2482 ,\n",
       "            0.248  , 0.2474 , 0.2471 , 0.2462 , 0.2458 , 0.2456 , 0.2445 ,\n",
       "            0.2438 , 0.2434 , 0.2433 , 0.2429 , 0.2417 , 0.2405 , 0.2402 ,\n",
       "            0.2401 , 0.2394 , 0.2368 , 0.2355 , 0.234  , 0.2338 , 0.2328 ,\n",
       "            0.2322 , 0.2319 , 0.2303 , 0.2297 , 0.2277 , 0.2246 , 0.222  ,\n",
       "            0.2205 , 0.213  , 0.2123 , 0.211  , 0.2104 , 0.2089 , 0.2058 ,\n",
       "            0.2037 , 0.2006 , 0.1996 , 0.199  , 0.1968 , 0.1967 , 0.1947 ,\n",
       "            0.1942 , 0.1935 , 0.1907 , 0.1901 , 0.19   , 0.1886 , 0.1884 ,\n",
       "            0.1873 , 0.1863 , 0.1836 , 0.183  , 0.1827 , 0.1783 , 0.178  ,\n",
       "            0.1779 , 0.1776 , 0.1775 , 0.1772 , 0.1755 , 0.1752 , 0.1744 ,\n",
       "            0.1738 , 0.171  , 0.1705 , 0.1688 , 0.1677 , 0.1675 , 0.166  ,\n",
       "            0.1658 , 0.1648 , 0.1637 , 0.1622 , 0.161  , 0.1602 , 0.16   ,\n",
       "            0.1592 , 0.1586 , 0.1583 , 0.158  , 0.1578 , 0.1577 , 0.157  ,\n",
       "            0.1567 , 0.1559 , 0.1543 , 0.1542 , 0.1533 , 0.1525 , 0.1519 ,\n",
       "            0.1511 , 0.1505 , 0.1501 , 0.1488 , 0.1486 , 0.1483 , 0.1464 ,\n",
       "            0.146  , 0.1451 , 0.1449 , 0.1448 , 0.1437 , 0.1426 , 0.1417 ,\n",
       "            0.1416 , 0.1399 , 0.139  , 0.1384 , 0.1377 , 0.1366 , 0.1365 ,\n",
       "            0.136  , 0.1359 , 0.1349 , 0.1332 , 0.1326 , 0.1318 , 0.1288 ,\n",
       "            0.1285 , 0.1284 , 0.128  , 0.1271 , 0.127  , 0.1265 , 0.1252 ,\n",
       "            0.12177, 0.1201 , 0.11993, 0.1194 , 0.118  , 0.11676, 0.1166 ,\n",
       "            0.1158 , 0.11475, 0.1142 , 0.1138 , 0.1134 , 0.11316, 0.112  ,\n",
       "            0.11084, 0.1105 , 0.1101 , 0.10913, 0.1043 , 0.1019 , 0.0998 ,\n",
       "            0.0993 , 0.0959 , 0.08417, 0.0818 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05      , 0.05      , 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.06666667, 0.075     , 0.09166667,\n",
       "            0.1       , 0.10833333, 0.125     , 0.13333334, 0.15      ,\n",
       "            0.16666667, 0.19166666, 0.2       , 0.2       , 0.20833333,\n",
       "            0.21666667, 0.21666667, 0.23333333, 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.325     , 0.33333334, 0.35      , 0.35      , 0.35      ,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.38333333, 0.38333333,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.45      , 0.45      ,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.525     ,\n",
       "            0.525     , 0.53333336, 0.53333336, 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.56666666, 0.56666666, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.59166664, 0.59166664, 0.59166664,\n",
       "            0.59166664, 0.6       , 0.6       , 0.6       , 0.60833335,\n",
       "            0.60833335, 0.60833335, 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.625     , 0.625     , 0.625     , 0.625     , 0.6333333 ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.78333336,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00769231, 0.01538462, 0.02307692, 0.03076923, 0.03846154,\n",
       "            0.06153846, 0.08461539, 0.08461539, 0.08461539, 0.08461539,\n",
       "            0.08461539, 0.08461539, 0.09230769, 0.10769231, 0.11538462,\n",
       "            0.11538462, 0.13076924, 0.13076924, 0.13846155, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.16153847, 0.17692308, 0.17692308,\n",
       "            0.17692308, 0.17692308, 0.17692308, 0.17692308, 0.17692308,\n",
       "            0.18461539, 0.18461539, 0.18461539, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.2       , 0.2       , 0.20769231, 0.21538462,\n",
       "            0.21538462, 0.22307692, 0.23846154, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.25384617, 0.26923078, 0.2769231 , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.33846155, 0.33846155, 0.33846155, 0.34615386, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3923077 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.4076923 , 0.4076923 ,\n",
       "            0.41538462, 0.41538462, 0.42307693, 0.42307693, 0.42307693,\n",
       "            0.43076923, 0.43076923, 0.43846154, 0.44615385, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.53846157, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9307692 , 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2822 , 0.2815 , 0.2812 , 0.281  , 0.2805 , 0.2803 ,\n",
       "            0.28   , 0.2798 , 0.279  , 0.2788 , 0.2786 , 0.2783 , 0.278  ,\n",
       "            0.2778 , 0.2773 , 0.2764 , 0.2761 , 0.276  , 0.2756 , 0.2754 ,\n",
       "            0.275  , 0.2747 , 0.2744 , 0.274  , 0.2737 , 0.2734 , 0.2732 ,\n",
       "            0.2727 , 0.2722 , 0.272  , 0.2712 , 0.271  , 0.2708 , 0.2705 ,\n",
       "            0.2703 , 0.27   , 0.2698 , 0.2695 , 0.269  , 0.2686 , 0.268  ,\n",
       "            0.2678 , 0.2676 , 0.2673 , 0.267  , 0.2666 , 0.2664 , 0.266  ,\n",
       "            0.2659 , 0.2654 , 0.2637 , 0.2634 , 0.2627 , 0.2622 , 0.262  ,\n",
       "            0.2617 , 0.2612 , 0.261  , 0.2605 , 0.2595 , 0.259  , 0.258  ,\n",
       "            0.257  , 0.2566 , 0.2563 , 0.2556 , 0.255  , 0.2534 , 0.252  ,\n",
       "            0.2512 , 0.2507 , 0.2487 , 0.2485 , 0.2466 , 0.2448 , 0.2426 ,\n",
       "            0.2413 , 0.2395 , 0.2383 , 0.236  , 0.2358 , 0.2347 , 0.2343 ,\n",
       "            0.2334 , 0.2332 , 0.2318 , 0.229  , 0.2283 , 0.2273 , 0.2263 ,\n",
       "            0.2239 , 0.2222 , 0.222  , 0.2207 , 0.2186 , 0.2166 , 0.2148 ,\n",
       "            0.213  , 0.2128 , 0.2119 , 0.2118 , 0.2106 , 0.2095 , 0.2089 ,\n",
       "            0.2085 , 0.2054 , 0.2043 , 0.2037 , 0.2032 , 0.2009 , 0.2006 ,\n",
       "            0.2004 , 0.199  , 0.1987 , 0.1981 , 0.1978 , 0.1965 , 0.1954 ,\n",
       "            0.1942 , 0.1934 , 0.1907 , 0.1904 , 0.1903 , 0.1893 , 0.189  ,\n",
       "            0.1887 , 0.187  , 0.1869 , 0.1866 , 0.1864 , 0.186  , 0.1858 ,\n",
       "            0.1857 , 0.1855 , 0.1846 , 0.1843 , 0.1833 , 0.1827 , 0.1823 ,\n",
       "            0.182  , 0.1816 , 0.1814 , 0.1812 , 0.18   , 0.1775 , 0.1764 ,\n",
       "            0.1755 , 0.1744 , 0.1741 , 0.1731 , 0.1727 , 0.1716 , 0.1687 ,\n",
       "            0.1681 , 0.1666 , 0.1646 , 0.1633 , 0.1625 , 0.1621 , 0.1615 ,\n",
       "            0.1605 , 0.1587 , 0.1584 , 0.1578 , 0.1572 , 0.1566 , 0.155  ,\n",
       "            0.1544 , 0.1543 , 0.1525 , 0.1516 , 0.1512 , 0.151  , 0.1477 ,\n",
       "            0.1476 , 0.1475 , 0.1472 , 0.1469 , 0.1421 , 0.1409 , 0.14   ,\n",
       "            0.1396 , 0.1384 , 0.1376 , 0.1365 , 0.1346 , 0.1345 , 0.1339 ,\n",
       "            0.1335 , 0.1332 , 0.1329 , 0.132  , 0.1311 , 0.1296 , 0.129  ,\n",
       "            0.1288 , 0.1263 , 0.12305, 0.119  , 0.1188 , 0.11615, 0.1041 ,\n",
       "            0.1034 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.09166667, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.10833333, 0.11666667, 0.13333334, 0.14166667, 0.14166667,\n",
       "            0.14166667, 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.175     , 0.175     , 0.18333334, 0.2       , 0.20833333,\n",
       "            0.20833333, 0.225     , 0.25      , 0.25      , 0.26666668,\n",
       "            0.275     , 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.35833332, 0.35833332, 0.35833332, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.49166667,\n",
       "            0.49166667, 0.49166667, 0.49166667, 0.49166667, 0.49166667,\n",
       "            0.49166667, 0.5       , 0.5       , 0.5083333 , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.51666665, 0.51666665, 0.525     ,\n",
       "            0.525     , 0.525     , 0.53333336, 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55833334, 0.56666666, 0.56666666,\n",
       "            0.575     , 0.575     , 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.6       , 0.6       , 0.6       , 0.6       ,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 , 0.625     ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.90833336, 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.05384615, 0.06153846, 0.07692308, 0.08461539,\n",
       "            0.1       , 0.10769231, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.16153847, 0.16153847, 0.16923077,\n",
       "            0.16923077, 0.17692308, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.1923077 , 0.1923077 , 0.1923077 , 0.1923077 , 0.2       ,\n",
       "            0.2       , 0.20769231, 0.23076923, 0.23076923, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.25384617, 0.26923078,\n",
       "            0.2769231 , 0.3       , 0.30769232, 0.30769232, 0.30769232,\n",
       "            0.30769232, 0.31538463, 0.31538463, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33076924, 0.34615386, 0.35384616, 0.35384616,\n",
       "            0.36153847, 0.36153847, 0.36153847, 0.36153847, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3846154 , 0.3846154 ,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.4076923 ,\n",
       "            0.4076923 , 0.41538462, 0.41538462, 0.41538462, 0.41538462,\n",
       "            0.42307693, 0.42307693, 0.43076923, 0.43846154, 0.43846154,\n",
       "            0.45384616, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.4923077 , 0.5       ,\n",
       "            0.5       , 0.50769234, 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.5692308 ,\n",
       "            0.5769231 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.6076923 , 0.61538464, 0.6230769 , 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.63846153, 0.64615387, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.6923077 , 0.6923077 , 0.7       ,\n",
       "            0.7       , 0.7076923 , 0.72307694, 0.74615383, 0.74615383,\n",
       "            0.76153845, 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.86923075,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.311 , 0.3096, 0.3076, 0.3066, 0.3037, 0.3032, 0.3025,\n",
       "            0.3022, 0.302 , 0.2998, 0.2988, 0.2983, 0.2974, 0.2961, 0.2952,\n",
       "            0.2935, 0.2922, 0.2905, 0.2898, 0.2896, 0.2893, 0.288 , 0.2878,\n",
       "            0.2876, 0.2874, 0.2869, 0.2864, 0.2861, 0.286 , 0.2854, 0.2852,\n",
       "            0.285 , 0.2847, 0.2842, 0.284 , 0.2837, 0.2834, 0.283 , 0.2822,\n",
       "            0.282 , 0.2815, 0.281 , 0.2808, 0.28  , 0.2798, 0.2795, 0.2788,\n",
       "            0.2786, 0.2778, 0.277 , 0.2769, 0.2766, 0.2764, 0.2756, 0.2754,\n",
       "            0.2751, 0.2747, 0.2744, 0.274 , 0.273 , 0.2722, 0.272 , 0.2712,\n",
       "            0.2708, 0.2703, 0.2695, 0.2693, 0.2686, 0.268 , 0.2678, 0.2666,\n",
       "            0.2664, 0.2659, 0.265 , 0.2617, 0.2603, 0.2588, 0.2578, 0.2559,\n",
       "            0.2556, 0.2554, 0.255 , 0.2542, 0.2505, 0.2502, 0.2489, 0.2483,\n",
       "            0.2466, 0.2463, 0.2456, 0.2452, 0.2449, 0.2433, 0.2421, 0.2411,\n",
       "            0.2405, 0.2394, 0.2384, 0.2383, 0.2363, 0.236 , 0.2356, 0.2352,\n",
       "            0.2339, 0.2335, 0.231 , 0.2302, 0.2297, 0.2292, 0.2283, 0.2281,\n",
       "            0.228 , 0.2274, 0.2256, 0.2255, 0.2242, 0.2238, 0.2234, 0.223 ,\n",
       "            0.2229, 0.2222, 0.2208, 0.2198, 0.2194, 0.2191, 0.2163, 0.2162,\n",
       "            0.2158, 0.2153, 0.2142, 0.214 , 0.2129, 0.2125, 0.2119, 0.2104,\n",
       "            0.2103, 0.2095, 0.2094, 0.2091, 0.2085, 0.2081, 0.2074, 0.206 ,\n",
       "            0.2053, 0.205 , 0.204 , 0.2039, 0.2026, 0.2018, 0.201 , 0.2009,\n",
       "            0.1985, 0.1967, 0.1954, 0.1952, 0.1942, 0.194 , 0.1934, 0.1924,\n",
       "            0.1901, 0.1884, 0.1855, 0.1837, 0.183 , 0.1813, 0.1796, 0.1782,\n",
       "            0.178 , 0.1779, 0.1768, 0.1757, 0.1753, 0.1752, 0.1747, 0.1724,\n",
       "            0.1719, 0.1694, 0.1687, 0.1678, 0.1663, 0.1649, 0.1647, 0.1643,\n",
       "            0.1638, 0.1627, 0.1615, 0.1581, 0.1556, 0.1555, 0.1545, 0.1527,\n",
       "            0.1526, 0.152 , 0.1517, 0.1516, 0.1512, 0.15  , 0.1483, 0.147 ,\n",
       "            0.1467, 0.1462, 0.1404, 0.1383, 0.1364, 0.1362, 0.1271, 0.1214],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.1       , 0.11666667,\n",
       "            0.11666667, 0.11666667, 0.125     , 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.15833333, 0.15833333,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.2       , 0.21666667, 0.225     , 0.23333333,\n",
       "            0.23333333, 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.29166666, 0.30833334, 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.325     , 0.325     , 0.325     , 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.35833332, 0.375     , 0.375     , 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.425     , 0.425     ,\n",
       "            0.425     , 0.425     , 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.525     , 0.525     ,\n",
       "            0.525     , 0.525     , 0.53333336, 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.55      , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.7916667 , 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.22307692, 0.23846154, 0.26153848,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.30769232, 0.31538463, 0.31538463,\n",
       "            0.32307693, 0.32307693, 0.33076924, 0.33076924, 0.33076924,\n",
       "            0.33076924, 0.33076924, 0.33076924, 0.33076924, 0.33076924,\n",
       "            0.33846155, 0.35384616, 0.35384616, 0.36153847, 0.36153847,\n",
       "            0.36153847, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.4       , 0.4       , 0.4       , 0.41538462, 0.42307693,\n",
       "            0.42307693, 0.42307693, 0.42307693, 0.42307693, 0.42307693,\n",
       "            0.43076923, 0.44615385, 0.44615385, 0.44615385, 0.44615385,\n",
       "            0.44615385, 0.44615385, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.4923077 , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.54615384, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5692308 , 0.5769231 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63076925, 0.63846153, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.66923076, 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8076923 , 0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.9461538 , 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3525, 0.344 , 0.3396, 0.3374, 0.336 , 0.3345, 0.3342,\n",
       "            0.3328, 0.3325, 0.332 , 0.331 , 0.3306, 0.3303, 0.3254, 0.3252,\n",
       "            0.325 , 0.3245, 0.323 , 0.3203, 0.3145, 0.3118, 0.3108, 0.309 ,\n",
       "            0.3083, 0.3076, 0.3071, 0.3062, 0.306 , 0.3044, 0.3042, 0.304 ,\n",
       "            0.3037, 0.303 , 0.3027, 0.302 , 0.3015, 0.3013, 0.2993, 0.2988,\n",
       "            0.2986, 0.2979, 0.2976, 0.2974, 0.297 , 0.2969, 0.2964, 0.2961,\n",
       "            0.296 , 0.2954, 0.295 , 0.2947, 0.2942, 0.2937, 0.2935, 0.293 ,\n",
       "            0.2927, 0.2925, 0.2917, 0.2915, 0.291 , 0.2908, 0.2886, 0.288 ,\n",
       "            0.2878, 0.2866, 0.2861, 0.2852, 0.285 , 0.2842, 0.2837, 0.2834,\n",
       "            0.2832, 0.2827, 0.2825, 0.2803, 0.28  , 0.2798, 0.2793, 0.2786,\n",
       "            0.2783, 0.278 , 0.2766, 0.276 , 0.2756, 0.2754, 0.274 , 0.2732,\n",
       "            0.2727, 0.2712, 0.27  , 0.2695, 0.2683, 0.2673, 0.267 , 0.2666,\n",
       "            0.2664, 0.2654, 0.2651, 0.2646, 0.2644, 0.2642, 0.2634, 0.2622,\n",
       "            0.262 , 0.2617, 0.2612, 0.2595, 0.2593, 0.2588, 0.258 , 0.2578,\n",
       "            0.2556, 0.255 , 0.2544, 0.2524, 0.2522, 0.252 , 0.2515, 0.2502,\n",
       "            0.25  , 0.2489, 0.2483, 0.248 , 0.2474, 0.247 , 0.2467, 0.2458,\n",
       "            0.2455, 0.2452, 0.2451, 0.2445, 0.2444, 0.2441, 0.2438, 0.2418,\n",
       "            0.2417, 0.241 , 0.2407, 0.2397, 0.2379, 0.237 , 0.236 , 0.2352,\n",
       "            0.2332, 0.2328, 0.2325, 0.2307, 0.2306, 0.2302, 0.2297, 0.2289,\n",
       "            0.228 , 0.2272, 0.2256, 0.224 , 0.2229, 0.2218, 0.2217, 0.2184,\n",
       "            0.2181, 0.2177, 0.2158, 0.2153, 0.2145, 0.214 , 0.2135, 0.211 ,\n",
       "            0.2109, 0.2103, 0.2095, 0.2026, 0.2015, 0.2006, 0.1996, 0.199 ,\n",
       "            0.1979, 0.1974, 0.1973, 0.197 , 0.1968, 0.1964, 0.193 , 0.1929,\n",
       "            0.1917, 0.1896, 0.1876, 0.1866, 0.1865, 0.1855, 0.1837, 0.1831,\n",
       "            0.1826, 0.1804, 0.1783, 0.1781, 0.1759, 0.1752, 0.1748, 0.1743,\n",
       "            0.1731, 0.1726, 0.1724, 0.1709, 0.1693, 0.1678, 0.1676, 0.1661,\n",
       "            0.1658, 0.1611, 0.16  , 0.1599, 0.1564, 0.1549, 0.1426],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.03333334, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.06666667, 0.06666667, 0.06666667, 0.06666667, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.075     , 0.075     , 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.10833333, 0.11666667, 0.11666667,\n",
       "            0.125     , 0.125     , 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.16666667, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.18333334, 0.18333334, 0.18333334, 0.18333334, 0.18333334,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.2       , 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.20833333, 0.20833333, 0.20833333,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.225     , 0.23333333,\n",
       "            0.24166666, 0.24166666, 0.24166666, 0.24166666, 0.24166666,\n",
       "            0.25      , 0.25      , 0.25833333, 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.275     , 0.275     , 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.5       , 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.3923077 , 0.4       , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.43846154, 0.45384616, 0.46153846, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4923077 , 0.5       , 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.53846157, 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.5538462 , 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6923077 , 0.7       , 0.7       , 0.7153846 , 0.7153846 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.7692308 , 0.7692308 , 0.77692306, 0.77692306, 0.77692306,\n",
       "            0.77692306, 0.7846154 , 0.8       , 0.8076923 , 0.8076923 ,\n",
       "            0.8153846 , 0.83076924, 0.83076924, 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.84615386, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.8923077 , 0.8923077 , 0.9       , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3972, 0.3806, 0.3738, 0.373 , 0.3716, 0.3694, 0.3682,\n",
       "            0.365 , 0.3633, 0.3628, 0.3599, 0.3591, 0.3582, 0.3528, 0.3516,\n",
       "            0.3508, 0.3474, 0.3435, 0.3374, 0.3372, 0.3364, 0.336 , 0.3357,\n",
       "            0.3333, 0.3325, 0.3315, 0.331 , 0.33  , 0.3284, 0.3274, 0.3254,\n",
       "            0.3247, 0.3242, 0.324 , 0.3235, 0.3223, 0.3218, 0.3203, 0.3196,\n",
       "            0.319 , 0.3179, 0.3176, 0.3171, 0.3162, 0.3157, 0.315 , 0.3145,\n",
       "            0.3142, 0.3137, 0.3132, 0.3127, 0.3125, 0.3118, 0.3115, 0.311 ,\n",
       "            0.3108, 0.3103, 0.31  , 0.3098, 0.3093, 0.309 , 0.3079, 0.3076,\n",
       "            0.3066, 0.306 , 0.3057, 0.3044, 0.3032, 0.302 , 0.3015, 0.3013,\n",
       "            0.3008, 0.2988, 0.2986, 0.2979, 0.2976, 0.2966, 0.2961, 0.296 ,\n",
       "            0.2954, 0.295 , 0.2944, 0.2942, 0.2937, 0.2935, 0.293 , 0.2925,\n",
       "            0.2922, 0.292 , 0.2915, 0.2913, 0.291 , 0.2908, 0.2903, 0.2898,\n",
       "            0.2893, 0.288 , 0.2878, 0.2876, 0.2874, 0.2869, 0.2864, 0.2861,\n",
       "            0.2854, 0.2847, 0.2834, 0.2832, 0.2827, 0.2825, 0.282 , 0.2815,\n",
       "            0.2805, 0.2803, 0.279 , 0.278 , 0.276 , 0.2756, 0.2742, 0.274 ,\n",
       "            0.2737, 0.2734, 0.2725, 0.2715, 0.2712, 0.271 , 0.2705, 0.2703,\n",
       "            0.27  , 0.2698, 0.268 , 0.267 , 0.2664, 0.2644, 0.2637, 0.2622,\n",
       "            0.262 , 0.261 , 0.259 , 0.258 , 0.2578, 0.2534, 0.2502, 0.2493,\n",
       "            0.2489, 0.2487, 0.2474, 0.2463, 0.2448, 0.243 , 0.2424, 0.2413,\n",
       "            0.2406, 0.2391, 0.239 , 0.2375, 0.2372, 0.2363, 0.2351, 0.235 ,\n",
       "            0.229 , 0.2289, 0.2283, 0.2274, 0.2266, 0.2264, 0.226 , 0.2257,\n",
       "            0.2242, 0.2238, 0.2217, 0.2207, 0.2205, 0.2195, 0.2189, 0.2175,\n",
       "            0.2166, 0.2162, 0.215 , 0.2148, 0.2144, 0.214 , 0.2135, 0.2125,\n",
       "            0.2104, 0.2084, 0.208 , 0.2068, 0.2064, 0.205 , 0.2045, 0.204 ,\n",
       "            0.2037, 0.2034, 0.202 , 0.2015, 0.2006, 0.2   , 0.1998, 0.1996,\n",
       "            0.1968, 0.1962, 0.1954, 0.195 , 0.1946, 0.1927, 0.1925, 0.1918,\n",
       "            0.1912, 0.1863, 0.1831, 0.171 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05      , 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.075     , 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.09166667, 0.09166667, 0.09166667,\n",
       "            0.09166667, 0.09166667, 0.1       , 0.10833333, 0.125     ,\n",
       "            0.125     , 0.125     , 0.125     , 0.13333334, 0.13333334,\n",
       "            0.14166667, 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.15833333, 0.15833333, 0.15833333, 0.16666667, 0.16666667,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.19166666,\n",
       "            0.2       , 0.2       , 0.2       , 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.21666667, 0.225     , 0.225     , 0.23333333,\n",
       "            0.24166666, 0.24166666, 0.25      , 0.25      , 0.25833333,\n",
       "            0.26666668, 0.26666668, 0.275     , 0.275     , 0.275     ,\n",
       "            0.275     , 0.28333333, 0.3       , 0.30833334, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.38333333, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.56666666, 0.575     , 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.6       , 0.60833335, 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.4       , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.46153846, 0.47692308, 0.4846154 ,\n",
       "            0.4846154 , 0.5       , 0.5153846 , 0.52307695, 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5692308 , 0.5846154 , 0.5846154 , 0.5923077 , 0.5923077 ,\n",
       "            0.6076923 , 0.61538464, 0.63076925, 0.63846153, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.66923076, 0.6769231 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7076923 , 0.72307694,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.86153847, 0.86153847,\n",
       "            0.86153847, 0.86923075, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.435 , 0.4172, 0.405 , 0.4043, 0.4019, 0.4006, 0.3972,\n",
       "            0.3943, 0.3938, 0.3909, 0.3894, 0.3882, 0.3857, 0.385 , 0.3762,\n",
       "            0.376 , 0.372 , 0.3672, 0.3584, 0.3582, 0.358 , 0.3564, 0.3552,\n",
       "            0.3535, 0.352 , 0.3508, 0.35  , 0.3499, 0.3494, 0.346 , 0.3455,\n",
       "            0.3447, 0.3425, 0.3406, 0.3398, 0.3396, 0.3384, 0.3376, 0.3352,\n",
       "            0.3342, 0.3337, 0.3335, 0.3325, 0.3315, 0.331 , 0.3298, 0.3293,\n",
       "            0.3289, 0.328 , 0.3276, 0.3257, 0.3254, 0.3252, 0.325 , 0.3247,\n",
       "            0.3245, 0.324 , 0.323 , 0.3228, 0.3215, 0.3213, 0.321 , 0.3203,\n",
       "            0.3198, 0.3196, 0.319 , 0.3186, 0.3171, 0.3167, 0.3164, 0.3162,\n",
       "            0.3152, 0.315 , 0.3145, 0.314 , 0.3137, 0.313 , 0.3125, 0.3123,\n",
       "            0.3115, 0.3113, 0.3108, 0.3103, 0.31  , 0.3093, 0.3088, 0.308 ,\n",
       "            0.3076, 0.3057, 0.3054, 0.3052, 0.3047, 0.3044, 0.303 , 0.3027,\n",
       "            0.3013, 0.3008, 0.3003, 0.3   , 0.2998, 0.299 , 0.2986, 0.2961,\n",
       "            0.296 , 0.2957, 0.2942, 0.2925, 0.2922, 0.291 , 0.2908, 0.29  ,\n",
       "            0.2896, 0.2893, 0.2878, 0.2874, 0.287 , 0.2866, 0.2864, 0.286 ,\n",
       "            0.285 , 0.2847, 0.2844, 0.2842, 0.2825, 0.282 , 0.2798, 0.277 ,\n",
       "            0.2769, 0.276 , 0.274 , 0.2722, 0.2712, 0.27  , 0.2693, 0.2688,\n",
       "            0.268 , 0.265 , 0.2646, 0.2632, 0.2627, 0.2622, 0.2612, 0.2605,\n",
       "            0.26  , 0.259 , 0.2566, 0.2546, 0.2542, 0.2534, 0.2527, 0.2524,\n",
       "            0.252 , 0.2462, 0.2433, 0.243 , 0.2428, 0.2418, 0.2417, 0.2411,\n",
       "            0.241 , 0.2401, 0.2395, 0.2384, 0.2375, 0.2332, 0.233 , 0.2327,\n",
       "            0.2297, 0.2294, 0.2285, 0.2281, 0.228 , 0.2269, 0.2252, 0.2246,\n",
       "            0.2239, 0.2238, 0.2184, 0.2181, 0.2175, 0.2173, 0.217 , 0.2168,\n",
       "            0.2166, 0.2152, 0.2147, 0.214 , 0.213 , 0.2123, 0.2095, 0.2091,\n",
       "            0.2084, 0.2081, 0.2076, 0.2064, 0.206 , 0.2054, 0.205 , 0.2043,\n",
       "            0.2031, 0.2002, 0.1996, 0.1954, 0.1952, 0.1924, 0.1921, 0.1813],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.06666667, 0.06666667,\n",
       "            0.075     , 0.08333334, 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.1       , 0.1       , 0.1       , 0.10833333, 0.11666667,\n",
       "            0.11666667, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15833333, 0.15833333,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.225     , 0.23333333,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.28333333, 0.29166666, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.43333334, 0.44166666,\n",
       "            0.45      , 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.49166667, 0.5       , 0.51666665, 0.51666665, 0.525     ,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.81666666, 0.825     , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06923077, 0.07692308,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.3       , 0.30769232, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.37692308, 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.44615385, 0.45384616, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5846154 , 0.5923077 ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.6615385 , 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.7307692 ,\n",
       "            0.7307692 , 0.7307692 , 0.73846155, 0.74615383, 0.76153845,\n",
       "            0.7692308 , 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8076923 , 0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.86923075, 0.8769231 , 0.8769231 , 0.8923077 ,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.9307692 , 0.9307692 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4802, 0.4597, 0.4443, 0.4414, 0.4395, 0.4377, 0.433 ,\n",
       "            0.4307, 0.4297, 0.4248, 0.4233, 0.422 , 0.4187, 0.4062, 0.406 ,\n",
       "            0.4019, 0.3953, 0.3877, 0.3855, 0.3853, 0.385 , 0.384 , 0.3838,\n",
       "            0.3804, 0.3792, 0.3774, 0.376 , 0.3755, 0.3718, 0.3699, 0.3691,\n",
       "            0.3682, 0.3655, 0.365 , 0.3628, 0.3625, 0.3623, 0.3613, 0.3608,\n",
       "            0.3606, 0.3604, 0.36  , 0.3596, 0.3591, 0.3572, 0.357 , 0.3564,\n",
       "            0.3562, 0.356 , 0.3552, 0.3545, 0.3538, 0.3525, 0.3523, 0.352 ,\n",
       "            0.3516, 0.3513, 0.351 , 0.3508, 0.35  , 0.3496, 0.3494, 0.3489,\n",
       "            0.3486, 0.3481, 0.347 , 0.3464, 0.346 , 0.3457, 0.3445, 0.3442,\n",
       "            0.3438, 0.3433, 0.343 , 0.3428, 0.342 , 0.3418, 0.3416, 0.341 ,\n",
       "            0.3408, 0.3403, 0.338 , 0.3376, 0.3372, 0.3347, 0.3345, 0.3333,\n",
       "            0.333 , 0.3328, 0.3325, 0.3315, 0.3306, 0.3303, 0.328 , 0.3274,\n",
       "            0.327 , 0.3267, 0.3262, 0.3254, 0.325 , 0.3245, 0.324 , 0.323 ,\n",
       "            0.322 , 0.3215, 0.3203, 0.32  , 0.3193, 0.3154, 0.315 , 0.3147,\n",
       "            0.3137, 0.313 , 0.3118, 0.3103, 0.31  , 0.3088, 0.3079, 0.3076,\n",
       "            0.3057, 0.3042, 0.3035, 0.3022, 0.2983, 0.2966, 0.296 , 0.2947,\n",
       "            0.2937, 0.2935, 0.293 , 0.2925, 0.2908, 0.2898, 0.289 , 0.2888,\n",
       "            0.2886, 0.2878, 0.287 , 0.2869, 0.2864, 0.2852, 0.2847, 0.2837,\n",
       "            0.2825, 0.2805, 0.28  , 0.277 , 0.2766, 0.2754, 0.275 , 0.2732,\n",
       "            0.272 , 0.2717, 0.2703, 0.268 , 0.2678, 0.2668, 0.2654, 0.265 ,\n",
       "            0.2646, 0.2637, 0.2622, 0.2615, 0.2603, 0.26  , 0.2595, 0.259 ,\n",
       "            0.2583, 0.258 , 0.2576, 0.2566, 0.2556, 0.2522, 0.252 , 0.2478,\n",
       "            0.2473, 0.2458, 0.2445, 0.2441, 0.244 , 0.2437, 0.2422, 0.2415,\n",
       "            0.2397, 0.2391, 0.2384, 0.2379, 0.2358, 0.2355, 0.2343, 0.2338,\n",
       "            0.2332, 0.2322, 0.2311, 0.2306, 0.2297, 0.229 , 0.2285, 0.2277,\n",
       "            0.2249, 0.2246, 0.224 , 0.2212, 0.22  , 0.2175, 0.2168, 0.2129,\n",
       "            0.212 , 0.2109, 0.2103, 0.2015, 0.2002, 0.1991, 0.1973, 0.187 ,\n",
       "            0.1838], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.01538462, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.04166667, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.075     , 0.09166667,\n",
       "            0.1       , 0.1       , 0.10833333, 0.11666667, 0.11666667,\n",
       "            0.11666667, 0.13333334, 0.14166667, 0.15      , 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.225     , 0.225     , 0.23333333, 0.23333333,\n",
       "            0.24166666, 0.25      , 0.275     , 0.28333333, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.38333333,\n",
       "            0.4       , 0.41666666, 0.425     , 0.43333334, 0.43333334,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.55      , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.5833333 , 0.59166664, 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4076923 , 0.41538462, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.83076924, 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.84615386, 0.85384613, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.86923075, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.8769231 , 0.88461536, 0.88461536, 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.527 , 0.506 , 0.4863, 0.4817, 0.48  , 0.4783, 0.4724,\n",
       "            0.4707, 0.4705, 0.4688, 0.4648, 0.4634, 0.462 , 0.4592, 0.4553,\n",
       "            0.44  , 0.439 , 0.4346, 0.4268, 0.422 , 0.4192, 0.4155, 0.415 ,\n",
       "            0.4136, 0.4097, 0.4065, 0.4055, 0.4045, 0.403 , 0.3972, 0.3962,\n",
       "            0.3958, 0.3955, 0.3948, 0.3943, 0.3938, 0.3933, 0.3928, 0.3916,\n",
       "            0.391 , 0.3909, 0.39  , 0.3894, 0.3882, 0.388 , 0.3877, 0.3875,\n",
       "            0.387 , 0.3865, 0.3855, 0.385 , 0.3848, 0.3845, 0.3838, 0.383 ,\n",
       "            0.382 , 0.3801, 0.38  , 0.3796, 0.3792, 0.378 , 0.3772, 0.3767,\n",
       "            0.3757, 0.3748, 0.3743, 0.374 , 0.3735, 0.373 , 0.3723, 0.372 ,\n",
       "            0.3718, 0.3713, 0.3704, 0.3687, 0.3677, 0.3667, 0.3657, 0.3655,\n",
       "            0.3652, 0.365 , 0.3635, 0.363 , 0.3625, 0.362 , 0.3618, 0.3604,\n",
       "            0.36  , 0.3599, 0.3594, 0.3574, 0.3572, 0.357 , 0.3567, 0.3557,\n",
       "            0.3555, 0.3545, 0.352 , 0.3513, 0.348 , 0.3472, 0.3467, 0.3438,\n",
       "            0.3433, 0.3425, 0.3413, 0.3408, 0.3394, 0.3386, 0.3372, 0.3367,\n",
       "            0.336 , 0.3345, 0.3335, 0.3328, 0.3315, 0.3284, 0.327 , 0.3262,\n",
       "            0.322 , 0.3213, 0.3196, 0.3193, 0.3164, 0.3154, 0.315 , 0.314 ,\n",
       "            0.313 , 0.3125, 0.3115, 0.3108, 0.3098, 0.3096, 0.3079, 0.3074,\n",
       "            0.3071, 0.3054, 0.3022, 0.2998, 0.2986, 0.298 , 0.2974, 0.2969,\n",
       "            0.294 , 0.2925, 0.2917, 0.291 , 0.2886, 0.287 , 0.286 , 0.2834,\n",
       "            0.2832, 0.283 , 0.282 , 0.2812, 0.2803, 0.2786, 0.278 , 0.277 ,\n",
       "            0.275 , 0.2742, 0.274 , 0.272 , 0.2715, 0.27  , 0.2695, 0.268 ,\n",
       "            0.2676, 0.2668, 0.2654, 0.2651, 0.2632, 0.263 , 0.2612, 0.261 ,\n",
       "            0.2603, 0.2598, 0.2585, 0.2573, 0.2568, 0.2566, 0.2554, 0.255 ,\n",
       "            0.2544, 0.2542, 0.254 , 0.2524, 0.2515, 0.251 , 0.2507, 0.2502,\n",
       "            0.25  , 0.2494, 0.2489, 0.247 , 0.2467, 0.246 , 0.2452, 0.2429,\n",
       "            0.2407, 0.2374, 0.2372, 0.2362, 0.2351, 0.2338, 0.2332, 0.2306,\n",
       "            0.2303, 0.2277, 0.2257, 0.2211, 0.2207, 0.2069, 0.2051, 0.1937,\n",
       "            0.1925, 0.1904, 0.1794, 0.1763], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.08461539, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.16666667, 0.175     , 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.19166666, 0.19166666, 0.2       , 0.2       ,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.64166665, 0.65      , 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.71666664, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.31538463, 0.32307693,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.53846157,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.6615385 , 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.8769231 , 0.88461536, 0.88461536, 0.88461536,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.9461538 , 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5654, 0.547 , 0.521 , 0.5166, 0.514 , 0.5063, 0.506 ,\n",
       "            0.5054, 0.503 , 0.501 , 0.498 , 0.493 , 0.4917, 0.4858, 0.4688,\n",
       "            0.467 , 0.4631, 0.4539, 0.451 , 0.4434, 0.4392, 0.439 , 0.437 ,\n",
       "            0.4324, 0.4287, 0.4277, 0.4263, 0.4258, 0.425 , 0.4233, 0.4202,\n",
       "            0.4197, 0.4177, 0.4172, 0.4165, 0.4163, 0.4155, 0.4146, 0.414 ,\n",
       "            0.4128, 0.4124, 0.4116, 0.4106, 0.4104, 0.41  , 0.4094, 0.408 ,\n",
       "            0.407 , 0.4067, 0.4065, 0.4058, 0.4055, 0.405 , 0.4043, 0.4038,\n",
       "            0.4036, 0.4026, 0.4019, 0.4014, 0.401 , 0.3982, 0.3972, 0.3965,\n",
       "            0.3955, 0.3938, 0.392 , 0.3918, 0.3914, 0.391 , 0.3906, 0.3904,\n",
       "            0.3901, 0.39  , 0.3887, 0.3865, 0.3845, 0.3843, 0.3835, 0.3826,\n",
       "            0.382 , 0.3813, 0.38  , 0.3796, 0.3794, 0.379 , 0.3784, 0.378 ,\n",
       "            0.3777, 0.3752, 0.375 , 0.3745, 0.3743, 0.372 , 0.3718, 0.3699,\n",
       "            0.3696, 0.3694, 0.3667, 0.366 , 0.3633, 0.3608, 0.3599, 0.358 ,\n",
       "            0.3552, 0.355 , 0.3538, 0.3518, 0.3494, 0.349 , 0.3489, 0.3481,\n",
       "            0.3467, 0.3462, 0.346 , 0.3455, 0.3452, 0.344 , 0.3408, 0.3403,\n",
       "            0.3386, 0.3354, 0.332 , 0.3315, 0.3293, 0.328 , 0.3262, 0.3252,\n",
       "            0.3242, 0.323 , 0.3228, 0.3218, 0.3213, 0.321 , 0.3193, 0.3186,\n",
       "            0.3174, 0.3171, 0.317 , 0.3152, 0.3123, 0.312 , 0.3098, 0.3093,\n",
       "            0.3074, 0.3025, 0.3022, 0.302 , 0.3018, 0.3015, 0.3005, 0.2988,\n",
       "            0.2974, 0.296 , 0.2957, 0.295 , 0.294 , 0.2937, 0.293 , 0.2925,\n",
       "            0.2915, 0.2908, 0.2896, 0.2893, 0.2878, 0.2869, 0.2864, 0.286 ,\n",
       "            0.2832, 0.28  , 0.2795, 0.2786, 0.2756, 0.2747, 0.2744, 0.2742,\n",
       "            0.274 , 0.271 , 0.2703, 0.2683, 0.2664, 0.2656, 0.2654, 0.2651,\n",
       "            0.2646, 0.2644, 0.2642, 0.2637, 0.263 , 0.2622, 0.2617, 0.2607,\n",
       "            0.2605, 0.2595, 0.2588, 0.258 , 0.2576, 0.2546, 0.2542, 0.252 ,\n",
       "            0.2515, 0.2512, 0.2466, 0.2462, 0.2451, 0.2428, 0.2417, 0.2394,\n",
       "            0.2388, 0.2383, 0.2335, 0.2314, 0.2285, 0.2281, 0.2272, 0.22  ,\n",
       "            0.2139, 0.1991, 0.1968, 0.1848, 0.1838, 0.1813, 0.1698, 0.1666],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.13076924, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.1       ,\n",
       "            0.10833333, 0.10833333, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.125     , 0.13333334, 0.13333334, 0.15      , 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.21666667, 0.225     , 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.28333333, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.46666667, 0.475     , 0.49166667, 0.5       , 0.5       ,\n",
       "            0.5083333 , 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.56153846, 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.86923075, 0.8769231 , 0.88461536, 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6157, 0.595 , 0.5684, 0.5605, 0.56  , 0.558 , 0.55  ,\n",
       "            0.5493, 0.5464, 0.546 , 0.54  , 0.535 , 0.5327, 0.5283, 0.506 ,\n",
       "            0.504 , 0.4993, 0.4973, 0.4885, 0.4814, 0.48  , 0.4773, 0.4758,\n",
       "            0.4753, 0.4744, 0.473 , 0.47  , 0.4685, 0.4675, 0.4666, 0.4656,\n",
       "            0.4634, 0.4626, 0.4612, 0.4604, 0.4602, 0.46  , 0.4597, 0.4592,\n",
       "            0.4587, 0.4578, 0.4575, 0.4548, 0.4546, 0.4539, 0.4536, 0.4526,\n",
       "            0.4524, 0.449 , 0.4487, 0.4468, 0.4458, 0.4453, 0.4436, 0.4434,\n",
       "            0.4429, 0.4421, 0.4414, 0.4395, 0.439 , 0.4387, 0.438 , 0.4377,\n",
       "            0.436 , 0.4346, 0.4329, 0.4326, 0.432 , 0.4304, 0.4302, 0.4297,\n",
       "            0.4277, 0.4263, 0.4246, 0.4243, 0.4236, 0.4233, 0.4226, 0.4216,\n",
       "            0.4214, 0.4197, 0.4172, 0.417 , 0.4167, 0.4165, 0.4148, 0.4136,\n",
       "            0.413 , 0.4126, 0.4124, 0.409 , 0.405 , 0.4045, 0.4033, 0.403 ,\n",
       "            0.4023, 0.4016, 0.3997, 0.3984, 0.3982, 0.3958, 0.395 , 0.3936,\n",
       "            0.3916, 0.3894, 0.3892, 0.3877, 0.386 , 0.3855, 0.3826, 0.3794,\n",
       "            0.379 , 0.3784, 0.3777, 0.3726, 0.3716, 0.3657, 0.3655, 0.3638,\n",
       "            0.3635, 0.3623, 0.3606, 0.3604, 0.358 , 0.357 , 0.3535, 0.3533,\n",
       "            0.3525, 0.3523, 0.349 , 0.3474, 0.3467, 0.3464, 0.344 , 0.3438,\n",
       "            0.3433, 0.342 , 0.3406, 0.339 , 0.3386, 0.3384, 0.3362, 0.3345,\n",
       "            0.3315, 0.3306, 0.3262, 0.3254, 0.3247, 0.324 , 0.3208, 0.3193,\n",
       "            0.3164, 0.316 , 0.3157, 0.3142, 0.3118, 0.3105, 0.3093, 0.3052,\n",
       "            0.305 , 0.3044, 0.304 , 0.3025, 0.301 , 0.3005, 0.3   , 0.298 ,\n",
       "            0.2976, 0.2966, 0.2961, 0.2957, 0.2952, 0.295 , 0.2932, 0.2922,\n",
       "            0.2915, 0.2903, 0.2898, 0.2893, 0.288 , 0.2864, 0.2861, 0.286 ,\n",
       "            0.2852, 0.283 , 0.282 , 0.2817, 0.281 , 0.28  , 0.2793, 0.2783,\n",
       "            0.277 , 0.2761, 0.2717, 0.271 , 0.27  , 0.2693, 0.2688, 0.2683,\n",
       "            0.2664, 0.266 , 0.2656, 0.264 , 0.2634, 0.262 , 0.2612, 0.2598,\n",
       "            0.2595, 0.2578, 0.2505, 0.2477, 0.2441, 0.2283, 0.2256, 0.2252,\n",
       "            0.2179, 0.2091, 0.1943, 0.1912, 0.178 , 0.1775, 0.1743, 0.162 ,\n",
       "            0.1588], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.24615385, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.075     , 0.075     , 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.1       , 0.10833333, 0.11666667, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15833333, 0.15833333,\n",
       "            0.16666667, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.475     , 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.625     , 0.6333333 , 0.65      , 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.73333335, 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.23076923, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.654 , 0.6357, 0.6035, 0.5967, 0.5957, 0.5947, 0.587 ,\n",
       "            0.586 , 0.584 , 0.58  , 0.576 , 0.568 , 0.567 , 0.561 , 0.537 ,\n",
       "            0.5347, 0.5303, 0.5293, 0.524 , 0.518 , 0.5117, 0.5093, 0.508 ,\n",
       "            0.5054, 0.505 , 0.5044, 0.5024, 0.5015, 0.4995, 0.4976, 0.4973,\n",
       "            0.496 , 0.4954, 0.4932, 0.492 , 0.491 , 0.4905, 0.4902, 0.489 ,\n",
       "            0.4868, 0.4866, 0.4856, 0.4846, 0.483 , 0.4802, 0.4797, 0.478 ,\n",
       "            0.4773, 0.4763, 0.4756, 0.4753, 0.475 , 0.4734, 0.4731, 0.4724,\n",
       "            0.4722, 0.472 , 0.47  , 0.464 , 0.4636, 0.4631, 0.463 , 0.4622,\n",
       "            0.4614, 0.461 , 0.4602, 0.46  , 0.4595, 0.4592, 0.459 , 0.4585,\n",
       "            0.4556, 0.4553, 0.4546, 0.4543, 0.453 , 0.452 , 0.4507, 0.4485,\n",
       "            0.4465, 0.4458, 0.445 , 0.4436, 0.4434, 0.442 , 0.4414, 0.441 ,\n",
       "            0.437 , 0.4368, 0.4355, 0.4324, 0.4307, 0.4304, 0.4272, 0.4258,\n",
       "            0.424 , 0.4236, 0.421 , 0.4202, 0.42  , 0.4175, 0.4172, 0.4163,\n",
       "            0.4153, 0.4136, 0.4133, 0.4128, 0.4116, 0.405 , 0.4026, 0.4023,\n",
       "            0.4019, 0.4016, 0.4014, 0.3984, 0.3982, 0.391 , 0.388 , 0.3862,\n",
       "            0.3835, 0.3809, 0.3804, 0.3765, 0.3762, 0.3752, 0.375 , 0.3748,\n",
       "            0.3745, 0.3718, 0.3708, 0.3706, 0.3662, 0.3643, 0.363 , 0.3625,\n",
       "            0.362 , 0.361 , 0.3586, 0.358 , 0.3574, 0.3572, 0.352 , 0.3508,\n",
       "            0.3477, 0.3472, 0.3464, 0.3452, 0.3438, 0.3416, 0.3403, 0.3396,\n",
       "            0.3384, 0.3376, 0.3362, 0.3325, 0.331 , 0.3308, 0.3303, 0.33  ,\n",
       "            0.3276, 0.326 , 0.3252, 0.323 , 0.3225, 0.3218, 0.3188, 0.3186,\n",
       "            0.3179, 0.315 , 0.3147, 0.3145, 0.314 , 0.313 , 0.3105, 0.3103,\n",
       "            0.3074, 0.3064, 0.306 , 0.3047, 0.3044, 0.304 , 0.3032, 0.3025,\n",
       "            0.302 , 0.3005, 0.3003, 0.3   , 0.298 , 0.2969, 0.2961, 0.2937,\n",
       "            0.2932, 0.2908, 0.2878, 0.2864, 0.2861, 0.2844, 0.2837, 0.2815,\n",
       "            0.281 , 0.2808, 0.2793, 0.2786, 0.2761, 0.2747, 0.2744, 0.2693,\n",
       "            0.269 , 0.2659, 0.2632, 0.2627, 0.2612, 0.26  , 0.2595, 0.258 ,\n",
       "            0.2563, 0.2482, 0.2474, 0.2411, 0.224 , 0.2234, 0.2205, 0.2144,\n",
       "            0.2037, 0.1885, 0.1844, 0.1707, 0.1666, 0.1542, 0.151 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.52307695, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.06666667, 0.06666667, 0.075     , 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.125     , 0.13333334, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35      , 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.40833333, 0.41666666,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.5833333 , 0.59166664, 0.6       , 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.24615385, 0.25384617, 0.26923078, 0.2846154 , 0.2923077 ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.3846154 ,\n",
       "            0.3923077 , 0.4076923 , 0.41538462, 0.42307693, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.88461536, 0.8923077 , 0.8923077 , 0.9       , 0.9       ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9230769 , 0.93846154, 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6997, 0.6826, 0.6475, 0.64  , 0.6396, 0.6387, 0.6313,\n",
       "            0.631 , 0.63  , 0.6274, 0.622 , 0.619 , 0.61  , 0.6084, 0.602 ,\n",
       "            0.576 , 0.575 , 0.5728, 0.5684, 0.568 , 0.5605, 0.5547, 0.554 ,\n",
       "            0.5527, 0.55  , 0.5493, 0.5483, 0.5464, 0.5425, 0.542 , 0.541 ,\n",
       "            0.5376, 0.537 , 0.5347, 0.534 , 0.5337, 0.533 , 0.5283, 0.5273,\n",
       "            0.526 , 0.5234, 0.521 , 0.52  , 0.519 , 0.5186, 0.5176, 0.5166,\n",
       "            0.516 , 0.5156, 0.5146, 0.512 , 0.5117, 0.509 , 0.506 , 0.505 ,\n",
       "            0.504 , 0.5024, 0.5015, 0.501 , 0.5005, 0.4966, 0.495 , 0.4944,\n",
       "            0.4941, 0.4937, 0.493 , 0.4927, 0.4922, 0.491 , 0.4902, 0.49  ,\n",
       "            0.4893, 0.4885, 0.4844, 0.4814, 0.4812, 0.4805, 0.48  , 0.4795,\n",
       "            0.478 , 0.4758, 0.475 , 0.4739, 0.473 , 0.4683, 0.4668, 0.4656,\n",
       "            0.4646, 0.4595, 0.4585, 0.4583, 0.458 , 0.456 , 0.4556, 0.4553,\n",
       "            0.4514, 0.4512, 0.4492, 0.4487, 0.446 , 0.4436, 0.4421, 0.4414,\n",
       "            0.4387, 0.4373, 0.4358, 0.434 , 0.4314, 0.431 , 0.428 , 0.4277,\n",
       "            0.4268, 0.4263, 0.425 , 0.4187, 0.4124, 0.4053, 0.4011, 0.3992,\n",
       "            0.3965, 0.3962, 0.394 , 0.3928, 0.3926, 0.3923, 0.3909, 0.3901,\n",
       "            0.39  , 0.3862, 0.386 , 0.3848, 0.3809, 0.3804, 0.376 , 0.3752,\n",
       "            0.3738, 0.3716, 0.3704, 0.3694, 0.3691, 0.3674, 0.366 , 0.363 ,\n",
       "            0.3599, 0.3586, 0.358 , 0.3567, 0.3552, 0.351 , 0.3499, 0.3489,\n",
       "            0.3484, 0.347 , 0.3464, 0.3425, 0.342 , 0.3408, 0.3406, 0.3394,\n",
       "            0.3389, 0.3381, 0.3372, 0.3337, 0.3308, 0.3289, 0.3281, 0.3254,\n",
       "            0.3252, 0.3237, 0.3232, 0.3215, 0.321 , 0.3206, 0.32  , 0.3198,\n",
       "            0.3154, 0.312 , 0.3113, 0.3108, 0.31  , 0.3088, 0.3076, 0.307 ,\n",
       "            0.3062, 0.3042, 0.3022, 0.3018, 0.3013, 0.3005, 0.2998, 0.2993,\n",
       "            0.2979, 0.2966, 0.2898, 0.289 , 0.2869, 0.2842, 0.283 , 0.2783,\n",
       "            0.2712, 0.2705, 0.2686, 0.2644, 0.2637, 0.2622, 0.2595, 0.2585,\n",
       "            0.251 , 0.2467, 0.2407, 0.223 , 0.2217, 0.2177, 0.2133, 0.1996,\n",
       "            0.1844, 0.1798, 0.1652, 0.1647, 0.1605, 0.1476, 0.1443],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00833333, dtype=float32),\n",
       "    'tpr': array(0.66923076, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.06666667, 0.06666667,\n",
       "            0.06666667, 0.06666667, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.25      , 0.25833333, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.5083333 , 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.80833334, 0.81666666, 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.3       , 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.5       ,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.56153846, 0.5692308 , 0.5846154 , 0.5923077 , 0.6076923 ,\n",
       "            0.61538464, 0.63076925, 0.63076925, 0.63846153, 0.65384614,\n",
       "            0.66923076, 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.734 , 0.7207, 0.6807, 0.6753, 0.6743, 0.671 , 0.668 ,\n",
       "            0.667 , 0.661 , 0.656 , 0.6543, 0.643 , 0.6426, 0.6333, 0.611 ,\n",
       "            0.6084, 0.604 , 0.603 , 0.602 , 0.6   , 0.5938, 0.586 , 0.5854,\n",
       "            0.585 , 0.581 , 0.5806, 0.5796, 0.573 , 0.5723, 0.5713, 0.571 ,\n",
       "            0.569 , 0.568 , 0.5664, 0.565 , 0.564 , 0.5625, 0.562 , 0.5605,\n",
       "            0.555 , 0.554 , 0.5537, 0.551 , 0.5483, 0.547 , 0.5464, 0.545 ,\n",
       "            0.544 , 0.5435, 0.542 , 0.5415, 0.5405, 0.54  , 0.5386, 0.5366,\n",
       "            0.5327, 0.5303, 0.5293, 0.529 , 0.5254, 0.5244, 0.521 , 0.5205,\n",
       "            0.52  , 0.518 , 0.517 , 0.5156, 0.515 , 0.513 , 0.5127, 0.5117,\n",
       "            0.509 , 0.506 , 0.503 , 0.5024, 0.4993, 0.4985, 0.4973, 0.495 ,\n",
       "            0.494 , 0.4934, 0.491 , 0.4895, 0.4885, 0.4858, 0.485 , 0.4841,\n",
       "            0.4792, 0.4788, 0.478 , 0.4763, 0.476 , 0.4739, 0.47  , 0.4697,\n",
       "            0.4695, 0.4673, 0.4663, 0.4622, 0.4612, 0.4597, 0.4583, 0.458 ,\n",
       "            0.4558, 0.4553, 0.4507, 0.4487, 0.4485, 0.4429, 0.4421, 0.4412,\n",
       "            0.4377, 0.4373, 0.4307, 0.43  , 0.422 , 0.4143, 0.414 , 0.412 ,\n",
       "            0.4102, 0.4092, 0.4067, 0.4055, 0.4048, 0.403 , 0.4001, 0.4   ,\n",
       "            0.3992, 0.3967, 0.3962, 0.393 , 0.3923, 0.392 , 0.3918, 0.3887,\n",
       "            0.3865, 0.3845, 0.383 , 0.3823, 0.3801, 0.3774, 0.375 , 0.3684,\n",
       "            0.367 , 0.3665, 0.3662, 0.3635, 0.362 , 0.3616, 0.3608, 0.3555,\n",
       "            0.355 , 0.3538, 0.3533, 0.353 , 0.3525, 0.3518, 0.3513, 0.3508,\n",
       "            0.35  , 0.3499, 0.348 , 0.3477, 0.3418, 0.3416, 0.3396, 0.3384,\n",
       "            0.3345, 0.334 , 0.3333, 0.3328, 0.3323, 0.3289, 0.3274, 0.3271,\n",
       "            0.3267, 0.3247, 0.3235, 0.3228, 0.3203, 0.3188, 0.3186, 0.3184,\n",
       "            0.3176, 0.3145, 0.3127, 0.311 , 0.31  , 0.3096, 0.3093, 0.308 ,\n",
       "            0.3071, 0.3064, 0.306 , 0.3052, 0.304 , 0.298 , 0.2947, 0.2898,\n",
       "            0.2869, 0.2852, 0.28  , 0.2783, 0.2754, 0.2664, 0.2642, 0.2612,\n",
       "            0.2593, 0.258 , 0.2573, 0.2566, 0.2544, 0.2515, 0.2402, 0.2343,\n",
       "            0.2203, 0.2157, 0.2103, 0.2063, 0.1929, 0.1758, 0.1709, 0.156 ,\n",
       "            0.1554, 0.1511, 0.1385, 0.1349], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.025, dtype=float32),\n",
       "    'tpr': array(0.7923077, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05833333, 0.05833333, 0.06666667, 0.06666667, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.36666667, 0.38333333,\n",
       "            0.38333333, 0.39166668, 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.81666666,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.74615383, 0.76153845,\n",
       "            0.77692306, 0.7846154 , 0.7846154 , 0.7923077 , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7646, 0.7563, 0.7114, 0.709 , 0.7085, 0.706 , 0.7036,\n",
       "            0.7026, 0.694 , 0.691 , 0.6846, 0.677 , 0.6743, 0.664 , 0.6577,\n",
       "            0.6475, 0.64  , 0.638 , 0.6343, 0.633 , 0.632 , 0.629 , 0.628 ,\n",
       "            0.623 , 0.622 , 0.6167, 0.613 , 0.6113, 0.611 , 0.6094, 0.606 ,\n",
       "            0.602 , 0.6016, 0.601 , 0.6006, 0.5957, 0.595 , 0.5923, 0.591 ,\n",
       "            0.5894, 0.589 , 0.5874, 0.5845, 0.584 , 0.5806, 0.58  , 0.578 ,\n",
       "            0.576 , 0.5747, 0.573 , 0.5723, 0.5703, 0.57  , 0.5684, 0.5664,\n",
       "            0.566 , 0.565 , 0.56  , 0.559 , 0.5557, 0.555 , 0.5537, 0.552 ,\n",
       "            0.5513, 0.5503, 0.5493, 0.548 , 0.546 , 0.545 , 0.543 , 0.54  ,\n",
       "            0.539 , 0.5376, 0.537 , 0.5366, 0.536 , 0.535 , 0.5347, 0.5337,\n",
       "            0.53  , 0.5283, 0.5273, 0.527 , 0.5264, 0.525 , 0.524 , 0.523 ,\n",
       "            0.52  , 0.5117, 0.507 , 0.5034, 0.502 , 0.5005, 0.5   , 0.499 ,\n",
       "            0.4958, 0.4902, 0.4878, 0.4846, 0.4836, 0.483 , 0.4805, 0.4792,\n",
       "            0.4749, 0.474 , 0.4722, 0.465 , 0.4644, 0.46  , 0.4587, 0.457 ,\n",
       "            0.456 , 0.447 , 0.441 , 0.4368, 0.434 , 0.4312, 0.4272, 0.4238,\n",
       "            0.423 , 0.4207, 0.4155, 0.4143, 0.4136, 0.4126, 0.4124, 0.411 ,\n",
       "            0.41  , 0.4075, 0.4053, 0.4045, 0.4038, 0.4014, 0.4011, 0.4006,\n",
       "            0.4001, 0.3994, 0.398 , 0.3906, 0.3904, 0.389 , 0.3867, 0.3843,\n",
       "            0.382 , 0.3809, 0.38  , 0.3774, 0.3772, 0.374 , 0.3718, 0.3708,\n",
       "            0.37  , 0.3694, 0.3684, 0.3662, 0.363 , 0.3604, 0.3596, 0.3594,\n",
       "            0.3582, 0.355 , 0.3503, 0.35  , 0.3484, 0.3474, 0.344 , 0.3438,\n",
       "            0.3433, 0.3418, 0.3398, 0.339 , 0.3364, 0.3362, 0.3345, 0.3337,\n",
       "            0.332 , 0.3306, 0.329 , 0.3286, 0.3271, 0.3252, 0.325 , 0.324 ,\n",
       "            0.3218, 0.3215, 0.3203, 0.3198, 0.3186, 0.3164, 0.3145, 0.312 ,\n",
       "            0.3086, 0.3071, 0.3064, 0.2988, 0.2952, 0.2935, 0.2869, 0.2844,\n",
       "            0.28  , 0.2769, 0.2744, 0.2654, 0.2642, 0.2612, 0.258 , 0.2566,\n",
       "            0.2556, 0.2546, 0.253 , 0.2527, 0.2367, 0.2311, 0.2185, 0.2114,\n",
       "            0.2051, 0.2029, 0.1874, 0.1698, 0.1644, 0.149 , 0.1481, 0.1437,\n",
       "            0.131 , 0.1271], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04166667, dtype=float32),\n",
       "    'tpr': array(0.86153847, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.06666667, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.11666667,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.35      , 0.36666667, 0.375     , 0.38333333,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.65      , 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.18461539, 0.2       , 0.20769231,\n",
       "            0.21538462, 0.23076923, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.4846154 , 0.4923077 , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6076923 , 0.61538464,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.66923076, 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.7307692 , 0.73846155, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.7886 , 0.7847 , 0.739  , 0.7363 , 0.736  , 0.7354 ,\n",
       "            0.7324 , 0.731  , 0.7305 , 0.72   , 0.719  , 0.709  , 0.704  ,\n",
       "            0.7    , 0.6973 , 0.6875 , 0.686  , 0.6763 , 0.6655 , 0.665  ,\n",
       "            0.659  , 0.658  , 0.657  , 0.6553 , 0.6475 , 0.6445 , 0.644  ,\n",
       "            0.641  , 0.639  , 0.635  , 0.634  , 0.6284 , 0.624  , 0.623  ,\n",
       "            0.622  , 0.621  , 0.6167 , 0.616  , 0.614  , 0.612  , 0.611  ,\n",
       "            0.609  , 0.6084 , 0.608  , 0.6064 , 0.6055 , 0.6016 , 0.6    ,\n",
       "            0.597  , 0.595  , 0.594  , 0.5938 , 0.591  , 0.59   , 0.589  ,\n",
       "            0.588  , 0.586  , 0.5815 , 0.5806 , 0.58   , 0.5737 , 0.573  ,\n",
       "            0.5728 , 0.5713 , 0.571  , 0.57   , 0.562  , 0.5615 , 0.561  ,\n",
       "            0.56   , 0.5596 , 0.5586 , 0.557  , 0.5566 , 0.555  , 0.5547 ,\n",
       "            0.554  , 0.553  , 0.5513 , 0.55   , 0.5464 , 0.544  , 0.5405 ,\n",
       "            0.536  , 0.5327 , 0.5317 , 0.5283 , 0.5254 , 0.5234 , 0.5215 ,\n",
       "            0.52   , 0.5186 , 0.5166 , 0.5156 , 0.507  , 0.5054 , 0.505  ,\n",
       "            0.5044 , 0.503  , 0.5024 , 0.502  , 0.4973 , 0.495  , 0.4946 ,\n",
       "            0.4934 , 0.4885 , 0.487  , 0.486  , 0.4827 , 0.4785 , 0.4768 ,\n",
       "            0.4727 , 0.4714 , 0.4688 , 0.4668 , 0.4624 , 0.4543 , 0.453  ,\n",
       "            0.4443 , 0.4412 , 0.437  , 0.432  , 0.4307 , 0.4282 , 0.4277 ,\n",
       "            0.4246 , 0.422  , 0.421  , 0.4202 , 0.4197 , 0.4172 , 0.4165 ,\n",
       "            0.4158 , 0.4136 , 0.4114 , 0.4106 , 0.41   , 0.4092 , 0.407  ,\n",
       "            0.405  , 0.3955 , 0.3953 , 0.3945 , 0.39   , 0.3892 , 0.3872 ,\n",
       "            0.3865 , 0.3857 , 0.3843 , 0.3838 , 0.383  , 0.382  , 0.377  ,\n",
       "            0.3718 , 0.3716 , 0.3691 , 0.366  , 0.3655 , 0.3652 , 0.3633 ,\n",
       "            0.362  , 0.3616 , 0.357  , 0.3564 , 0.3562 , 0.3499 , 0.3494 ,\n",
       "            0.349  , 0.3489 , 0.347  , 0.3457 , 0.3445 , 0.344  , 0.3408 ,\n",
       "            0.3406 , 0.3403 , 0.339  , 0.3386 , 0.338  , 0.3337 , 0.3335 ,\n",
       "            0.3323 , 0.3315 , 0.3306 , 0.3296 , 0.328  , 0.327  , 0.3257 ,\n",
       "            0.3242 , 0.32   , 0.315  , 0.3088 , 0.3057 , 0.3032 , 0.3025 ,\n",
       "            0.2942 , 0.2922 , 0.2903 , 0.2805 , 0.278  , 0.2742 , 0.27   ,\n",
       "            0.2686 , 0.259  , 0.2588 , 0.2573 , 0.2563 , 0.256  , 0.2515 ,\n",
       "            0.2512 , 0.249  , 0.2478 , 0.2474 , 0.2462 , 0.2281 , 0.223  ,\n",
       "            0.2123 , 0.2028 , 0.1953 , 0.1947 , 0.178  , 0.1598 , 0.1539 ,\n",
       "            0.1384 , 0.1371 , 0.1327 , 0.12024, 0.11633], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.05, dtype=float32),\n",
       "    'tpr': array(0.9307692, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.075     , 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.10833333, 0.11666667, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25      , 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.625     , 0.6333333 , 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.80833334, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.23076923, 0.23846154, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.3846154 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.56153846, 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.6615385 , 0.66923076, 0.6846154 , 0.6923077 ,\n",
       "            0.7076923 , 0.7153846 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.82   , 0.8193 , 0.7773 , 0.7715 , 0.769  , 0.768  ,\n",
       "            0.7676 , 0.763  , 0.7563 , 0.755  , 0.7417 , 0.74   , 0.738  ,\n",
       "            0.7354 , 0.7266 , 0.7207 , 0.716  , 0.7046 , 0.704  , 0.701  ,\n",
       "            0.697  , 0.6963 , 0.693  , 0.6924 , 0.6895 , 0.6855 , 0.682  ,\n",
       "            0.6816 , 0.6763 , 0.673  , 0.672  , 0.6714 , 0.6704 , 0.6665 ,\n",
       "            0.663  , 0.658  , 0.6567 , 0.6533 , 0.653  , 0.652  , 0.6484 ,\n",
       "            0.6465 , 0.6455 , 0.6445 , 0.643  , 0.641  , 0.639  , 0.6357 ,\n",
       "            0.635  , 0.631  , 0.6304 , 0.626  , 0.6255 , 0.623  , 0.6226 ,\n",
       "            0.622  , 0.6216 , 0.62   , 0.6196 , 0.6167 , 0.615  , 0.6147 ,\n",
       "            0.6055 , 0.604  , 0.6035 , 0.603  , 0.6006 , 0.5967 , 0.595  ,\n",
       "            0.5933 , 0.593  , 0.5913 , 0.591  , 0.5884 , 0.5864 , 0.586  ,\n",
       "            0.5854 , 0.585  , 0.584  , 0.5835 , 0.579  , 0.5776 , 0.576  ,\n",
       "            0.5757 , 0.5728 , 0.5654 , 0.5635 , 0.5596 , 0.5557 , 0.5547 ,\n",
       "            0.554  , 0.5513 , 0.5503 , 0.5493 , 0.5483 , 0.543  , 0.542  ,\n",
       "            0.538  , 0.5376 , 0.533  , 0.531  , 0.5303 , 0.53   , 0.5273 ,\n",
       "            0.5225 , 0.5205 , 0.519  , 0.518  , 0.5156 , 0.514  , 0.512  ,\n",
       "            0.508  , 0.5073 , 0.506  , 0.4954 , 0.4944 , 0.494  , 0.4927 ,\n",
       "            0.4875 , 0.4797 , 0.4795 , 0.4712 , 0.47   , 0.4644 , 0.454  ,\n",
       "            0.4539 , 0.4512 , 0.4485 , 0.4465 , 0.4426 , 0.442  , 0.437  ,\n",
       "            0.4348 , 0.4336 , 0.433  , 0.432  , 0.4316 , 0.4307 , 0.4302 ,\n",
       "            0.4282 , 0.4238 , 0.4233 , 0.4192 , 0.411  , 0.4106 , 0.4094 ,\n",
       "            0.4077 , 0.407  , 0.4067 , 0.406  , 0.4058 , 0.4055 , 0.4043 ,\n",
       "            0.3997 , 0.397  , 0.3901 , 0.3867 , 0.3855 , 0.3838 , 0.3828 ,\n",
       "            0.3801 , 0.38   , 0.3765 , 0.3757 , 0.3745 , 0.3743 , 0.369  ,\n",
       "            0.3662 , 0.3652 , 0.365  , 0.3643 , 0.3625 , 0.3623 , 0.3596 ,\n",
       "            0.3567 , 0.355  , 0.3547 , 0.3542 , 0.3533 , 0.3508 , 0.35   ,\n",
       "            0.3477 , 0.3474 , 0.346  , 0.3457 , 0.3438 , 0.3435 , 0.3428 ,\n",
       "            0.342  , 0.336  , 0.331  , 0.3276 , 0.3206 , 0.3115 , 0.3093 ,\n",
       "            0.3052 , 0.3044 , 0.298  , 0.2954 , 0.2908 , 0.28   , 0.277  ,\n",
       "            0.2737 , 0.2688 , 0.2686 , 0.2576 , 0.2573 , 0.2554 , 0.2524 ,\n",
       "            0.2515 , 0.2493 , 0.2455 , 0.2451 , 0.244  , 0.2246 , 0.2194 ,\n",
       "            0.2114 , 0.1987 , 0.19   , 0.1897 , 0.1729 , 0.1533 , 0.1475 ,\n",
       "            0.1313 , 0.1298 , 0.1255 , 0.11316, 0.10876], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.05833333, dtype=float32),\n",
       "    'tpr': array(0.95384616, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.10833333, 0.11666667,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25      , 0.25833333, 0.26666668, 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.61538464, 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6846154 , 0.7       ,\n",
       "            0.7076923 , 0.7076923 , 0.7153846 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8230769 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.845  , 0.842  , 0.8076 , 0.799  , 0.798  , 0.796  ,\n",
       "            0.791  , 0.7876 , 0.785  , 0.7803 , 0.768  , 0.766  , 0.7617 ,\n",
       "            0.7603 , 0.7485 , 0.7446 , 0.737  , 0.7285 , 0.726  , 0.7246 ,\n",
       "            0.7207 , 0.7188 , 0.717  , 0.716  , 0.7153 , 0.711  , 0.705  ,\n",
       "            0.703  , 0.7007 , 0.7    , 0.696  , 0.691  , 0.69   , 0.6895 ,\n",
       "            0.684  , 0.6807 , 0.6753 , 0.674  , 0.6704 , 0.669  , 0.6685 ,\n",
       "            0.6646 , 0.664  , 0.6626 , 0.6606 , 0.66   , 0.659  , 0.657  ,\n",
       "            0.653  , 0.651  , 0.6484 , 0.647  , 0.646  , 0.6426 , 0.641  ,\n",
       "            0.6396 , 0.6387 , 0.637  , 0.6357 , 0.631  , 0.6304 , 0.63   ,\n",
       "            0.624  , 0.6235 , 0.623  , 0.62   , 0.618  , 0.617  , 0.6133 ,\n",
       "            0.612  , 0.6094 , 0.607  , 0.6045 , 0.604  , 0.6035 , 0.603  ,\n",
       "            0.6006 , 0.5996 , 0.599  , 0.5986 , 0.598  , 0.5933 , 0.593  ,\n",
       "            0.5923 , 0.5894 , 0.5864 , 0.576  , 0.575  , 0.571  , 0.5684 ,\n",
       "            0.5664 , 0.566  , 0.563  , 0.5605 , 0.5493 , 0.5483 , 0.5464 ,\n",
       "            0.546  , 0.545  , 0.542  , 0.54   , 0.533  , 0.5327 , 0.532  ,\n",
       "            0.5273 , 0.527  , 0.5264 , 0.5254 , 0.517  , 0.5156 , 0.5146 ,\n",
       "            0.509  , 0.508  , 0.503  , 0.501  , 0.4922 , 0.4873 , 0.4866 ,\n",
       "            0.4795 , 0.4778 , 0.472  , 0.462  , 0.4595 , 0.4575 , 0.4534 ,\n",
       "            0.4514 , 0.4482 , 0.447  , 0.4397 , 0.4387 , 0.4382 , 0.4363 ,\n",
       "            0.4358 , 0.4346 , 0.4338 , 0.4336 , 0.4314 , 0.4272 , 0.4238 ,\n",
       "            0.423  , 0.4229 , 0.4185 , 0.4143 , 0.4106 , 0.41   , 0.4097 ,\n",
       "            0.4084 , 0.4082 , 0.4075 , 0.4072 , 0.4055 , 0.4028 , 0.4016 ,\n",
       "            0.3987 , 0.3914 , 0.3872 , 0.3833 , 0.3826 , 0.3823 , 0.3804 ,\n",
       "            0.3801 , 0.376  , 0.3752 , 0.375  , 0.372  , 0.365  , 0.3645 ,\n",
       "            0.3638 , 0.3635 , 0.362  , 0.3594 , 0.3577 , 0.3574 , 0.355  ,\n",
       "            0.3525 , 0.3513 , 0.351  , 0.3503 , 0.3486 , 0.3481 , 0.3452 ,\n",
       "            0.345  , 0.3447 , 0.3445 , 0.343  , 0.342  , 0.3408 , 0.34   ,\n",
       "            0.338  , 0.3313 , 0.3235 , 0.32   , 0.306  , 0.3052 , 0.2993 ,\n",
       "            0.298  , 0.2976 , 0.2874 , 0.2815 , 0.271  , 0.268  , 0.2637 ,\n",
       "            0.2622 , 0.2588 , 0.2537 , 0.2534 , 0.2496 , 0.2482 , 0.2473 ,\n",
       "            0.2388 , 0.2352 , 0.2346 , 0.2332 , 0.2139 , 0.2081 , 0.2064 ,\n",
       "            0.1901 , 0.1792 , 0.1782 , 0.1641 , 0.1417 , 0.1361 , 0.12036,\n",
       "            0.1192 , 0.1152 , 0.1034 , 0.0986 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.075, dtype=float32),\n",
       "    'tpr': array(0.96153843, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.1       , 0.10833333, 0.11666667,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.46666667, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.52307695,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6769231 , 0.6846154 , 0.7       , 0.7076923 ,\n",
       "            0.7076923 , 0.7076923 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8       , 0.8076923 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.869  , 0.8623 , 0.8335 , 0.824  , 0.823  , 0.8228 ,\n",
       "            0.822  , 0.8135 , 0.811  , 0.8105 , 0.803  , 0.794  , 0.79   ,\n",
       "            0.789  , 0.787  , 0.7783 , 0.768  , 0.766  , 0.755  , 0.7544 ,\n",
       "            0.7534 , 0.7466 , 0.7456 , 0.744  , 0.743  , 0.734  , 0.7334 ,\n",
       "            0.729  , 0.7285 , 0.7275 , 0.727  , 0.724  , 0.718  , 0.7173 ,\n",
       "            0.717  , 0.711  , 0.7085 , 0.7017 , 0.701  , 0.697  , 0.6963 ,\n",
       "            0.695  , 0.6924 , 0.6914 , 0.691  , 0.6885 , 0.6875 , 0.6865 ,\n",
       "            0.6855 , 0.6826 , 0.682  , 0.6787 , 0.6772 , 0.6724 , 0.6714 ,\n",
       "            0.6694 , 0.667  , 0.666  , 0.663  , 0.6626 , 0.6616 , 0.661  ,\n",
       "            0.6567 , 0.655  , 0.6543 , 0.6465 , 0.6455 , 0.6445 , 0.6436 ,\n",
       "            0.6426 , 0.641  , 0.6387 , 0.6353 , 0.6333 , 0.631  , 0.6304 ,\n",
       "            0.63   , 0.627  , 0.6255 , 0.625  , 0.623  , 0.6226 , 0.6216 ,\n",
       "            0.6206 , 0.6196 , 0.619  , 0.6157 , 0.6143 , 0.612  , 0.6064 ,\n",
       "            0.598  , 0.5957 , 0.595  , 0.5913 , 0.588  , 0.5864 , 0.585  ,\n",
       "            0.581  , 0.5806 , 0.5796 , 0.5713 , 0.5693 , 0.565  , 0.5635 ,\n",
       "            0.5625 , 0.559  , 0.552  , 0.5503 , 0.55   , 0.5454 , 0.5435 ,\n",
       "            0.543  , 0.5425 , 0.536  , 0.5337 , 0.533  , 0.5244 , 0.523  ,\n",
       "            0.521  , 0.5205 , 0.505  , 0.5044 , 0.503  , 0.4932 , 0.4912 ,\n",
       "            0.485  , 0.4753 , 0.475  , 0.474  , 0.4663 , 0.4626 , 0.4617 ,\n",
       "            0.457  , 0.454  , 0.4502 , 0.4475 , 0.4473 , 0.4453 , 0.445  ,\n",
       "            0.444  , 0.4421 , 0.442  , 0.4417 , 0.436  , 0.4336 , 0.431  ,\n",
       "            0.429  , 0.4275 , 0.4272 , 0.4233 , 0.4229 , 0.4224 , 0.421  ,\n",
       "            0.42   , 0.4175 , 0.414  , 0.4138 , 0.4111 , 0.4104 , 0.4058 ,\n",
       "            0.4036 , 0.4023 , 0.3923 , 0.3918 , 0.388  , 0.386  , 0.385  ,\n",
       "            0.3848 , 0.383  , 0.3794 , 0.3784 , 0.3765 , 0.3713 , 0.3696 ,\n",
       "            0.366  , 0.3655 , 0.363  , 0.3606 , 0.3604 , 0.3586 , 0.3584 ,\n",
       "            0.355  , 0.3545 , 0.354  , 0.3538 , 0.351  , 0.3484 , 0.3481 ,\n",
       "            0.3477 , 0.3464 , 0.3457 , 0.3452 , 0.3447 , 0.3413 , 0.3403 ,\n",
       "            0.3374 , 0.3352 , 0.3218 , 0.3193 , 0.3186 , 0.3035 , 0.3018 ,\n",
       "            0.2993 , 0.2942 , 0.2937 , 0.2832 , 0.2766 , 0.2646 , 0.262  ,\n",
       "            0.258  , 0.2566 , 0.2527 , 0.2496 , 0.2489 , 0.2463 , 0.2437 ,\n",
       "            0.2415 , 0.2407 , 0.2402 , 0.2322 , 0.2277 , 0.2274 , 0.2268 ,\n",
       "            0.206  , 0.2009 , 0.2004 , 0.1824 , 0.1704 , 0.1565 , 0.1328 ,\n",
       "            0.1271 , 0.11145, 0.1097 , 0.10614, 0.0945 , 0.0896 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.09166667, dtype=float32),\n",
       "    'tpr': array(0.96153843, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.10833333, 0.11666667, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.475     , 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26923078, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.66923076, 0.6769231 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.891  , 0.8813 , 0.8594 , 0.849  , 0.8486 , 0.847  ,\n",
       "            0.8467 , 0.837  , 0.835  , 0.833  , 0.826  , 0.82   , 0.8193 ,\n",
       "            0.812  , 0.807  , 0.795  , 0.7915 , 0.784  , 0.7812 , 0.781  ,\n",
       "            0.774  , 0.7734 , 0.772  , 0.771  , 0.7705 , 0.7617 , 0.757  ,\n",
       "            0.7563 , 0.7554 , 0.755  , 0.7524 , 0.7456 , 0.745  , 0.744  ,\n",
       "            0.739  , 0.737  , 0.7285 , 0.7246 , 0.7217 , 0.7188 , 0.717  ,\n",
       "            0.7153 , 0.7144 , 0.714  , 0.713  , 0.7095 , 0.709  , 0.705  ,\n",
       "            0.7046 , 0.699  , 0.696  , 0.6953 , 0.695  , 0.693  , 0.691  ,\n",
       "            0.6895 , 0.689  , 0.6875 , 0.6836 , 0.682  , 0.6807 , 0.68   ,\n",
       "            0.679  , 0.67   , 0.669  , 0.6675 , 0.667  , 0.6665 , 0.6655 ,\n",
       "            0.659  , 0.658  , 0.655  , 0.6543 , 0.6514 , 0.649  , 0.648  ,\n",
       "            0.6475 , 0.6455 , 0.644  , 0.641  , 0.64   , 0.6377 , 0.635  ,\n",
       "            0.627  , 0.622  , 0.618  , 0.615  , 0.6123 , 0.6113 , 0.6094 ,\n",
       "            0.6084 , 0.608  , 0.602  , 0.601  , 0.6006 , 0.5996 , 0.595  ,\n",
       "            0.592  , 0.5845 , 0.581  , 0.579  , 0.577  , 0.5723 , 0.5693 ,\n",
       "            0.5684 , 0.567  , 0.562  , 0.559  , 0.557  , 0.554  , 0.552  ,\n",
       "            0.542  , 0.541  , 0.5405 , 0.523  , 0.5205 , 0.5186 , 0.507  ,\n",
       "            0.505  , 0.4983 , 0.4941 , 0.4922 , 0.4868 , 0.4802 , 0.4775 ,\n",
       "            0.4756 , 0.4712 , 0.466  , 0.4617 , 0.458  , 0.4573 , 0.4565 ,\n",
       "            0.4558 , 0.455  , 0.4524 , 0.4504 , 0.45   , 0.4495 , 0.4417 ,\n",
       "            0.439  , 0.4385 , 0.4382 , 0.437  , 0.4368 , 0.4363 , 0.4346 ,\n",
       "            0.4343 , 0.4326 , 0.4248 , 0.421  , 0.4194 , 0.4163 , 0.4143 ,\n",
       "            0.4092 , 0.4084 , 0.4033 , 0.398  , 0.3933 , 0.3928 , 0.39   ,\n",
       "            0.3875 , 0.3845 , 0.3809 , 0.3801 , 0.3796 , 0.3782 , 0.3767 ,\n",
       "            0.3694 , 0.3667 , 0.3647 , 0.3635 , 0.3616 , 0.3586 , 0.3577 ,\n",
       "            0.3572 , 0.357  , 0.3538 , 0.3523 , 0.3518 , 0.3481 , 0.3472 ,\n",
       "            0.3455 , 0.344  , 0.3428 , 0.3394 , 0.336  , 0.3203 , 0.3188 ,\n",
       "            0.3157 , 0.3022 , 0.3015 , 0.298  , 0.29   , 0.2896 , 0.2776 ,\n",
       "            0.2705 , 0.258  , 0.2551 , 0.2532 , 0.2512 , 0.2466 , 0.2458 ,\n",
       "            0.2456 , 0.2448 , 0.2402 , 0.2347 , 0.234  , 0.2335 , 0.2244 ,\n",
       "            0.2197 , 0.2191 , 0.1978 , 0.1962 , 0.1918 , 0.1761 , 0.1615 ,\n",
       "            0.1495 , 0.1232 , 0.1178 , 0.1023 , 0.1007 , 0.09705, 0.086  ,\n",
       "            0.08093], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.09166667, dtype=float32),\n",
       "    'tpr': array(0.96153843, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.10833333, 0.11666667, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.2       , 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.35384616, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.66923076,\n",
       "            0.6769231 , 0.6769231 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9087 , 0.8955 , 0.881  , 0.869  , 0.8677 , 0.866  ,\n",
       "            0.858  , 0.851  , 0.8496 , 0.8438 , 0.8413 , 0.8384 , 0.832  ,\n",
       "            0.8296 , 0.8267 , 0.814  , 0.809  , 0.803  , 0.799  , 0.7964 ,\n",
       "            0.7925 , 0.792  , 0.79   , 0.7886 , 0.7803 , 0.779  , 0.774  ,\n",
       "            0.773  , 0.7725 , 0.772  , 0.771  , 0.7637 , 0.762  , 0.7617 ,\n",
       "            0.7554 , 0.753  , 0.746  , 0.745  , 0.7407 , 0.7383 , 0.737  ,\n",
       "            0.736  , 0.7354 , 0.7324 , 0.7305 , 0.73   , 0.726  , 0.7256 ,\n",
       "            0.722  , 0.7217 , 0.72   , 0.7153 , 0.715  , 0.7114 , 0.71   ,\n",
       "            0.7095 , 0.7065 , 0.7046 , 0.703  , 0.6997 , 0.696  , 0.6953 ,\n",
       "            0.694  , 0.6904 , 0.6855 , 0.684  , 0.683  , 0.682  , 0.681  ,\n",
       "            0.68   , 0.679  , 0.6733 , 0.673  , 0.6694 , 0.669  , 0.667  ,\n",
       "            0.6655 , 0.665  , 0.6616 , 0.661  , 0.66   , 0.6597 , 0.6587 ,\n",
       "            0.6562 , 0.655  , 0.654  , 0.649  , 0.639  , 0.637  , 0.635  ,\n",
       "            0.627  , 0.626  , 0.625  , 0.6235 , 0.6206 , 0.6196 , 0.6187 ,\n",
       "            0.6167 , 0.6143 , 0.609  , 0.606  , 0.6025 , 0.598  , 0.5933 ,\n",
       "            0.59   , 0.589  , 0.5874 , 0.5825 , 0.58   , 0.576  , 0.575  ,\n",
       "            0.5674 , 0.566  , 0.563  , 0.561  , 0.5537 , 0.553  , 0.5483 ,\n",
       "            0.53   , 0.5273 , 0.5244 , 0.51   , 0.5063 , 0.5    , 0.498  ,\n",
       "            0.4968 , 0.4902 , 0.485  , 0.4832 , 0.4812 , 0.4736 , 0.4688 ,\n",
       "            0.464  , 0.4597 , 0.4595 , 0.457  , 0.4558 , 0.4521 , 0.452  ,\n",
       "            0.4517 , 0.4512 , 0.4456 , 0.4426 , 0.44   , 0.4382 , 0.4375 ,\n",
       "            0.4368 , 0.435  , 0.4336 , 0.4333 , 0.4246 , 0.422  , 0.417  ,\n",
       "            0.4146 , 0.4136 , 0.408  , 0.407  , 0.4016 , 0.3962 , 0.3953 ,\n",
       "            0.3909 , 0.3875 , 0.3865 , 0.3843 , 0.383  , 0.3767 , 0.3757 ,\n",
       "            0.3748 , 0.3745 , 0.3733 , 0.3628 , 0.3625 , 0.3623 , 0.3599 ,\n",
       "            0.3584 , 0.3582 , 0.3557 , 0.3538 , 0.3535 , 0.3525 , 0.3513 ,\n",
       "            0.35   , 0.349  , 0.348  , 0.3467 , 0.346  , 0.3452 , 0.341  ,\n",
       "            0.3408 , 0.3386 , 0.3313 , 0.3306 , 0.33   , 0.319  , 0.3115 ,\n",
       "            0.3083 , 0.3018 , 0.2979 , 0.2908 , 0.2822 , 0.282  , 0.2686 ,\n",
       "            0.2612 , 0.2487 , 0.2473 , 0.2455 , 0.2424 , 0.2422 , 0.2415 ,\n",
       "            0.241  , 0.2363 , 0.2355 , 0.2255 , 0.2249 , 0.2234 , 0.2142 ,\n",
       "            0.2094 , 0.2091 , 0.191  , 0.1874 , 0.1813 , 0.1686 , 0.1514 ,\n",
       "            0.1509 , 0.1418 , 0.11316, 0.108  , 0.09283, 0.09174, 0.088  ,\n",
       "            0.07794, 0.0724 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.14166667, dtype=float32),\n",
       "    'tpr': array(0.97692305, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.125     , 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45833334, 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.46153846, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.7692308 ,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9272 , 0.9146 , 0.9033 , 0.8926 , 0.892  , 0.8906 ,\n",
       "            0.889  , 0.8823 , 0.874  , 0.873  , 0.867  , 0.8667 , 0.8647 ,\n",
       "            0.8574 , 0.854  , 0.8535 , 0.8413 , 0.835  , 0.831  , 0.8306 ,\n",
       "            0.827  , 0.824  , 0.8203 , 0.82   , 0.8184 , 0.8174 , 0.81   ,\n",
       "            0.8076 , 0.8037 , 0.8022 , 0.802  , 0.8013 , 0.8    , 0.7925 ,\n",
       "            0.7915 , 0.7866 , 0.785  , 0.7754 , 0.775  , 0.772  , 0.7686 ,\n",
       "            0.766  , 0.7646 , 0.764  , 0.762  , 0.761  , 0.7603 , 0.759  ,\n",
       "            0.756  , 0.7544 , 0.7524 , 0.751  , 0.75   , 0.746  , 0.745  ,\n",
       "            0.7446 , 0.7397 , 0.737  , 0.7363 , 0.7344 , 0.733  , 0.728  ,\n",
       "            0.727  , 0.7266 , 0.725  , 0.7236 , 0.7197 , 0.717  , 0.714  ,\n",
       "            0.7124 , 0.7104 , 0.709  , 0.7085 , 0.7036 , 0.703  , 0.699  ,\n",
       "            0.6973 , 0.697  , 0.695  , 0.6943 , 0.694  , 0.693  , 0.6914 ,\n",
       "            0.689  , 0.6875 , 0.6855 , 0.685  , 0.6846 , 0.679  , 0.6763 ,\n",
       "            0.666  , 0.6655 , 0.6646 , 0.6543 , 0.6514 , 0.651  , 0.649  ,\n",
       "            0.6465 , 0.6445 , 0.642  , 0.6396 , 0.639  , 0.6333 , 0.626  ,\n",
       "            0.62   , 0.6196 , 0.617  , 0.6157 , 0.611  , 0.6094 , 0.607  ,\n",
       "            0.606  , 0.602  , 0.5967 , 0.596  , 0.593  , 0.59   , 0.5864 ,\n",
       "            0.5806 , 0.5796 , 0.578  , 0.577  , 0.5586 , 0.554  , 0.544  ,\n",
       "            0.5386 , 0.5366 , 0.531  , 0.5293 , 0.525  , 0.516  , 0.5083 ,\n",
       "            0.5073 , 0.5044 , 0.4875 , 0.4841 , 0.4836 , 0.4817 , 0.4802 ,\n",
       "            0.4785 , 0.4778 , 0.4758 , 0.4697 , 0.4656 , 0.4648 , 0.4636 ,\n",
       "            0.4634 , 0.4631 , 0.4612 , 0.4575 , 0.4534 , 0.4487 , 0.4453 ,\n",
       "            0.4438 , 0.4421 , 0.4407 , 0.4395 , 0.4377 , 0.4263 , 0.4246 ,\n",
       "            0.4182 , 0.4155 , 0.4128 , 0.4116 , 0.4102 , 0.4062 , 0.4023 ,\n",
       "            0.3972 , 0.3955 , 0.395  , 0.392  , 0.3918 , 0.3835 , 0.38   ,\n",
       "            0.379  , 0.3782 , 0.376  , 0.3757 , 0.3716 , 0.3708 , 0.3684 ,\n",
       "            0.3662 , 0.366  , 0.3655 , 0.3652 , 0.365  , 0.3645 , 0.3635 ,\n",
       "            0.362  , 0.3586 , 0.356  , 0.3555 , 0.3494 , 0.3489 , 0.344  ,\n",
       "            0.3435 , 0.334  , 0.3245 , 0.3125 , 0.309  , 0.3062 , 0.3018 ,\n",
       "            0.2917 , 0.2827 , 0.282  , 0.2676 , 0.2595 , 0.247  , 0.246  ,\n",
       "            0.2433 , 0.2426 , 0.2422 , 0.2407 , 0.2386 , 0.2351 , 0.2338 ,\n",
       "            0.2224 , 0.2216 , 0.2197 , 0.2101 , 0.2051 , 0.205  , 0.2048 ,\n",
       "            0.1887 , 0.1826 , 0.1759 , 0.1646 , 0.1453 , 0.1447 , 0.1371 ,\n",
       "            0.1065 , 0.10144, 0.0865 , 0.0851 , 0.08167, 0.07196, 0.0661 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.14166667, dtype=float32),\n",
       "    'tpr': array(0.97692305, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05      , 0.05      , 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.15833333, 0.16666667, 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33846155,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9404 , 0.9263 , 0.9204 , 0.9097 , 0.909  , 0.908  ,\n",
       "            0.9053 , 0.9004 , 0.888  , 0.8857 , 0.8853 , 0.883  , 0.875  ,\n",
       "            0.8745 , 0.8696 , 0.8613 , 0.853  , 0.8516 , 0.8477 , 0.8457 ,\n",
       "            0.8423 , 0.841  , 0.839  , 0.8384 , 0.831  , 0.83   , 0.824  ,\n",
       "            0.8237 , 0.8223 , 0.817  , 0.815  , 0.813  , 0.8125 , 0.807  ,\n",
       "            0.8057 , 0.798  , 0.7964 , 0.793  , 0.7896 , 0.784  , 0.783  ,\n",
       "            0.7812 , 0.777  , 0.776  , 0.774  , 0.7734 , 0.772  , 0.7676 ,\n",
       "            0.764  , 0.7617 , 0.76   , 0.758  , 0.7573 , 0.756  , 0.7544 ,\n",
       "            0.748  , 0.7476 , 0.746  , 0.7456 , 0.7427 , 0.7397 , 0.7373 ,\n",
       "            0.735  , 0.7344 , 0.7314 , 0.731  , 0.73   , 0.728  , 0.7246 ,\n",
       "            0.724  , 0.72   , 0.7188 , 0.718  , 0.7153 , 0.7144 , 0.714  ,\n",
       "            0.7134 , 0.712  , 0.7095 , 0.709  , 0.7075 , 0.705  , 0.704  ,\n",
       "            0.6997 , 0.6973 , 0.6875 , 0.6855 , 0.6846 , 0.675  , 0.674  ,\n",
       "            0.671  , 0.6704 , 0.6685 , 0.6675 , 0.6646 , 0.661  , 0.6577 ,\n",
       "            0.652  , 0.6514 , 0.642  , 0.6353 , 0.635  , 0.6304 , 0.6284 ,\n",
       "            0.6265 , 0.624  , 0.6206 , 0.619  , 0.6133 , 0.61   , 0.6064 ,\n",
       "            0.6035 , 0.596  , 0.595  , 0.5947 , 0.5933 , 0.5737 , 0.569  ,\n",
       "            0.5576 , 0.544  , 0.5435 , 0.54   , 0.5376 , 0.533  , 0.522  ,\n",
       "            0.52   , 0.5195 , 0.5166 , 0.5156 , 0.494  , 0.4932 , 0.4883 ,\n",
       "            0.4875 , 0.4856 , 0.4841 , 0.484  , 0.4797 , 0.479  , 0.4753 ,\n",
       "            0.4744 , 0.4739 , 0.4736 , 0.4727 , 0.4722 , 0.4697 , 0.466  ,\n",
       "            0.4614 , 0.4558 , 0.4507 , 0.4504 , 0.446  , 0.4448 , 0.4407 ,\n",
       "            0.4404 , 0.4324 , 0.43   , 0.4233 , 0.4204 , 0.4185 , 0.4177 ,\n",
       "            0.4111 , 0.4023 , 0.4014 , 0.4006 , 0.3994 , 0.3984 , 0.3962 ,\n",
       "            0.3955 , 0.3867 , 0.3865 , 0.3826 , 0.3796 , 0.3765 , 0.374  ,\n",
       "            0.371  , 0.3708 , 0.3694 , 0.3687 , 0.3665 , 0.3662 , 0.3655 ,\n",
       "            0.365  , 0.3645 , 0.3638 , 0.3604 , 0.3594 , 0.3591 , 0.3547 ,\n",
       "            0.3516 , 0.345  , 0.344  , 0.3403 , 0.334  , 0.3264 , 0.3113 ,\n",
       "            0.3093 , 0.308  , 0.3025 , 0.2888 , 0.2798 , 0.2788 , 0.2634 ,\n",
       "            0.2554 , 0.244  , 0.2434 , 0.2406 , 0.2402 , 0.239  , 0.2368 ,\n",
       "            0.2338 , 0.233  , 0.2285 , 0.2167 , 0.2166 , 0.2142 , 0.2043 ,\n",
       "            0.1995 , 0.199  , 0.1987 , 0.1858 , 0.1761 , 0.1694 , 0.1597 ,\n",
       "            0.1382 , 0.1381 , 0.1318 , 0.0995 , 0.0945 , 0.0798 , 0.0785 ,\n",
       "            0.0752 , 0.066  , 0.05988], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.14166667, dtype=float32),\n",
       "    'tpr': array(0.97692305, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.05      ,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.4       , 0.40833333, 0.41666666,\n",
       "            0.425     , 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.51666665, 0.525     , 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.23076923,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9497 , 0.934  , 0.933  , 0.9224 , 0.921  , 0.9204 ,\n",
       "            0.9165 , 0.9136 , 0.9    , 0.8994 , 0.8984 , 0.8975 , 0.8936 ,\n",
       "            0.8896 , 0.8867 , 0.8804 , 0.8765 , 0.868  , 0.8667 , 0.8633 ,\n",
       "            0.8623 , 0.862  , 0.8574 , 0.856  , 0.854  , 0.8535 , 0.8467 ,\n",
       "            0.846  , 0.8394 , 0.8374 , 0.83   , 0.8286 , 0.8276 , 0.8257 ,\n",
       "            0.8223 , 0.821  , 0.8135 , 0.8115 , 0.808  , 0.805  , 0.8047 ,\n",
       "            0.8    , 0.7993 , 0.7964 , 0.792  , 0.7915 , 0.789  , 0.7886 ,\n",
       "            0.786  , 0.783  , 0.7827 , 0.7803 , 0.7783 , 0.7773 , 0.773  ,\n",
       "            0.7725 , 0.7715 , 0.771  , 0.769  , 0.768  , 0.7627 , 0.762  ,\n",
       "            0.761  , 0.7583 , 0.756  , 0.7515 , 0.7495 , 0.749  , 0.746  ,\n",
       "            0.7427 , 0.742  , 0.739  , 0.7383 , 0.7344 , 0.733  , 0.7324 ,\n",
       "            0.7314 , 0.7295 , 0.728  , 0.7275 , 0.726  , 0.7256 , 0.7236 ,\n",
       "            0.722  , 0.7188 , 0.7134 , 0.7114 , 0.711  , 0.7075 , 0.7026 ,\n",
       "            0.6987 , 0.6963 , 0.687  , 0.6865 , 0.6826 , 0.682  , 0.6816 ,\n",
       "            0.681  , 0.6807 , 0.677  , 0.674  , 0.6694 , 0.6636 , 0.6543 ,\n",
       "            0.651  , 0.647  , 0.642  , 0.639  , 0.637  , 0.6353 , 0.635  ,\n",
       "            0.6284 , 0.628  , 0.627  , 0.623  , 0.6196 , 0.6143 , 0.6133 ,\n",
       "            0.608  , 0.605  , 0.6045 , 0.603  , 0.6025 , 0.5815 , 0.5767 ,\n",
       "            0.5625 , 0.549  , 0.5435 , 0.539  , 0.5327 , 0.527  , 0.525  ,\n",
       "            0.521  , 0.52   , 0.5186 , 0.4954 , 0.491  , 0.4895 , 0.487  ,\n",
       "            0.4849 , 0.481  , 0.4802 , 0.4775 , 0.4763 , 0.476  , 0.475  ,\n",
       "            0.4746 , 0.474  , 0.4739 , 0.4736 , 0.4714 , 0.4712 , 0.4675 ,\n",
       "            0.4612 , 0.4531 , 0.453  , 0.4478 , 0.4448 , 0.437  , 0.4316 ,\n",
       "            0.4287 , 0.4265 , 0.42   , 0.418  , 0.4167 , 0.4163 , 0.4036 ,\n",
       "            0.3977 , 0.397  , 0.395  , 0.3938 , 0.393  , 0.3906 , 0.3904 ,\n",
       "            0.3813 , 0.3792 , 0.3755 , 0.374  , 0.3704 , 0.3647 , 0.3645 ,\n",
       "            0.3633 , 0.36   , 0.359  , 0.3584 , 0.358  , 0.357  , 0.3513 ,\n",
       "            0.3508 , 0.3477 , 0.3472 , 0.3416 , 0.3367 , 0.3364 , 0.3357 ,\n",
       "            0.3262 , 0.3257 , 0.322  , 0.3074 , 0.3018 , 0.2986 , 0.2961 ,\n",
       "            0.2795 , 0.2703 , 0.2693 , 0.2527 , 0.2445 , 0.2397 , 0.2358 ,\n",
       "            0.2343 , 0.2322 , 0.2292 , 0.2263 , 0.2256 , 0.2224 , 0.2175 ,\n",
       "            0.2063 , 0.2053 , 0.2028 , 0.193  , 0.188  , 0.1877 , 0.1873 ,\n",
       "            0.1794 , 0.1649 , 0.1582 , 0.151  , 0.1279 , 0.1273 , 0.1235 ,\n",
       "            0.0899 , 0.0854 , 0.07135, 0.0703 , 0.0672 , 0.05933, 0.0527 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.2, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05      , 0.05      , 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.125     , 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.4       , 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.575     , 0.5833333 , 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.31538463, 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6076923 , 0.61538464, 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9614 , 0.948  , 0.9473 , 0.9385 , 0.937  , 0.933  ,\n",
       "            0.931  , 0.918  , 0.917  , 0.9155 , 0.9116 , 0.9077 , 0.9053 ,\n",
       "            0.8994 , 0.895  , 0.889  , 0.888  , 0.8843 , 0.8833 , 0.883  ,\n",
       "            0.879  , 0.8774 , 0.8745 , 0.874  , 0.87   , 0.867  , 0.861  ,\n",
       "            0.8594 , 0.859  , 0.8525 , 0.851  , 0.8506 , 0.8496 , 0.8457 ,\n",
       "            0.8447 , 0.835  , 0.832  , 0.8286 , 0.828  , 0.8228 , 0.8223 ,\n",
       "            0.822  , 0.817  , 0.8154 , 0.8135 , 0.8125 , 0.812  , 0.8105 ,\n",
       "            0.8086 , 0.8076 , 0.807  , 0.804  , 0.8037 , 0.7993 , 0.798  ,\n",
       "            0.795  , 0.7944 , 0.7935 , 0.788  , 0.7876 , 0.786  , 0.785  ,\n",
       "            0.7827 , 0.78   , 0.7764 , 0.7744 , 0.773  , 0.769  , 0.7666 ,\n",
       "            0.765  , 0.764  , 0.763  , 0.76   , 0.7593 , 0.757  , 0.7544 ,\n",
       "            0.754  , 0.753  , 0.7524 , 0.7515 , 0.7505 , 0.748  , 0.7476 ,\n",
       "            0.745  , 0.7407 , 0.7354 , 0.735  , 0.732  , 0.7314 , 0.725  ,\n",
       "            0.718  , 0.7153 , 0.7124 , 0.71   , 0.709  , 0.7056 , 0.7046 ,\n",
       "            0.703  , 0.7026 , 0.698  , 0.6978 , 0.69   , 0.6836 , 0.6772 ,\n",
       "            0.671  , 0.669  , 0.6646 , 0.664  , 0.662  , 0.661  , 0.6567 ,\n",
       "            0.6553 , 0.654  , 0.65   , 0.6455 , 0.636  , 0.6343 , 0.633  ,\n",
       "            0.6304 , 0.629  , 0.628  , 0.607  , 0.6006 , 0.579  , 0.5776 ,\n",
       "            0.568  , 0.5664 , 0.5605 , 0.5537 , 0.549  , 0.547  , 0.5454 ,\n",
       "            0.5435 , 0.5425 , 0.514  , 0.5117 , 0.5083 , 0.507  , 0.505  ,\n",
       "            0.5015 , 0.501  , 0.5005 , 0.5    , 0.4998 , 0.499  , 0.497  ,\n",
       "            0.4968 , 0.495  , 0.4941 , 0.489  , 0.4868 , 0.4841 , 0.473  ,\n",
       "            0.4702 , 0.466  , 0.4607 , 0.4583 , 0.4553 , 0.453  , 0.4521 ,\n",
       "            0.451  , 0.4358 , 0.4338 , 0.4329 , 0.4275 , 0.4219 , 0.4187 ,\n",
       "            0.4177 , 0.4136 , 0.409  , 0.4077 , 0.4075 , 0.407  , 0.396  ,\n",
       "            0.3948 , 0.3918 , 0.3892 , 0.3877 , 0.3857 , 0.381  , 0.3767 ,\n",
       "            0.3752 , 0.3743 , 0.374  , 0.372  , 0.3716 , 0.371  , 0.3677 ,\n",
       "            0.3625 , 0.3604 , 0.3538 , 0.3523 , 0.3506 , 0.3396 , 0.3394 ,\n",
       "            0.3367 , 0.3276 , 0.3274 , 0.3142 , 0.3    , 0.2998 , 0.2969 ,\n",
       "            0.279  , 0.2695 , 0.268  , 0.2502 , 0.2424 , 0.241  , 0.2352 ,\n",
       "            0.2351 , 0.2327 , 0.2266 , 0.2257 , 0.2216 , 0.2179 , 0.2134 ,\n",
       "            0.2026 , 0.2001 , 0.1976 , 0.1876 , 0.1826 , 0.1824 , 0.182  ,\n",
       "            0.1782 , 0.1593 , 0.152  , 0.1473 , 0.1222 , 0.12054, 0.1192 ,\n",
       "            0.0836 , 0.07935, 0.06573, 0.06476, 0.0621 , 0.0547 , 0.0476 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.26666668, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.2769231 , 0.2846154 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5769231 , 0.5846154 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9683 , 0.9575 , 0.9546 , 0.948  , 0.9473 , 0.947  ,\n",
       "            0.9434 , 0.942  , 0.9307 , 0.93   , 0.9263 , 0.926  , 0.923  ,\n",
       "            0.9224 , 0.917  , 0.911  , 0.91   , 0.904  , 0.9033 , 0.8994 ,\n",
       "            0.899  , 0.896  , 0.8936 , 0.8916 , 0.8906 , 0.8857 , 0.885  ,\n",
       "            0.8784 , 0.877  , 0.8765 , 0.87   , 0.869  , 0.868  , 0.8643 ,\n",
       "            0.864  , 0.854  , 0.852  , 0.8516 , 0.848  , 0.8477 , 0.8423 ,\n",
       "            0.842  , 0.8374 , 0.8354 , 0.834  , 0.832  , 0.8315 , 0.828  ,\n",
       "            0.8276 , 0.827  , 0.8257 , 0.824  , 0.8203 , 0.82   , 0.819  ,\n",
       "            0.8164 , 0.815  , 0.814  , 0.812  , 0.81   , 0.8086 , 0.808  ,\n",
       "            0.8057 , 0.8047 , 0.8027 , 0.7983 , 0.7954 , 0.7935 , 0.793  ,\n",
       "            0.792  , 0.7866 , 0.7856 , 0.785  , 0.784  , 0.7817 , 0.781  ,\n",
       "            0.7783 , 0.7773 , 0.777  , 0.775  , 0.7744 , 0.7725 , 0.77   ,\n",
       "            0.769  , 0.7666 , 0.757  , 0.755  , 0.751  , 0.75   , 0.7495 ,\n",
       "            0.747  , 0.7363 , 0.735  , 0.734  , 0.731  , 0.7285 , 0.7266 ,\n",
       "            0.723  , 0.7217 , 0.7207 , 0.72   , 0.7188 , 0.712  , 0.698  ,\n",
       "            0.694  , 0.6914 , 0.6855 , 0.685  , 0.683  , 0.6797 , 0.679  ,\n",
       "            0.673  , 0.6714 , 0.67   , 0.669  , 0.667  , 0.656  , 0.655  ,\n",
       "            0.6514 , 0.65   , 0.649  , 0.6475 , 0.6455 , 0.6274 , 0.6206 ,\n",
       "            0.599  , 0.5938 , 0.588  , 0.576  , 0.569  , 0.568  , 0.5674 ,\n",
       "            0.5625 , 0.562  , 0.556  , 0.553  , 0.5317 , 0.5225 , 0.5215 ,\n",
       "            0.5195 , 0.517  , 0.5166 , 0.514  , 0.513  , 0.5117 , 0.511  ,\n",
       "            0.509  , 0.5073 , 0.5054 , 0.5024 , 0.4966 , 0.492  , 0.4824 ,\n",
       "            0.4817 , 0.4805 , 0.468  , 0.4658 , 0.464  , 0.4607 , 0.4578 ,\n",
       "            0.455  , 0.4495 , 0.441  , 0.4392 , 0.4329 , 0.4314 , 0.4253 ,\n",
       "            0.424  , 0.42   , 0.4146 , 0.4124 , 0.4102 , 0.4055 , 0.4028 ,\n",
       "            0.3992 , 0.3926 , 0.3914 , 0.388  , 0.384  , 0.3833 , 0.383  ,\n",
       "            0.3804 , 0.3801 , 0.3792 , 0.3782 , 0.3765 , 0.3735 , 0.3706 ,\n",
       "            0.3687 , 0.3672 , 0.3633 , 0.3604 , 0.3582 , 0.351  , 0.3428 ,\n",
       "            0.3396 , 0.3345 , 0.3271 , 0.327  , 0.3145 , 0.299  , 0.2964 ,\n",
       "            0.293  , 0.2761 , 0.2664 , 0.2646 , 0.2452 , 0.2399 , 0.2355 ,\n",
       "            0.2316 , 0.2313 , 0.229  , 0.2229 , 0.22   , 0.2156 , 0.2115 ,\n",
       "            0.2074 , 0.197  , 0.1934 , 0.1907 , 0.1804 , 0.1757 , 0.1753 ,\n",
       "            0.1752 , 0.1735 , 0.1523 , 0.1447 , 0.1415 , 0.11536, 0.11316,\n",
       "            0.1128 , 0.07666, 0.0729 , 0.05966, 0.059  , 0.05634, 0.04968,\n",
       "            0.0424 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.275, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.07692308, 0.08461539,\n",
       "            0.09230769, 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.23076923, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5769231 , 0.5846154 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.86153847, 0.86923075, 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.975  , 0.9663 , 0.9624 , 0.958  , 0.957  , 0.953  ,\n",
       "            0.9526 , 0.942  , 0.937  , 0.9365 , 0.934  , 0.929  , 0.9233 ,\n",
       "            0.923  , 0.918  , 0.917  , 0.914  , 0.9126 , 0.9097 , 0.909  ,\n",
       "            0.9077 , 0.9053 , 0.9043 , 0.902  , 0.899  , 0.8926 , 0.8916 ,\n",
       "            0.891  , 0.8853 , 0.884  , 0.8833 , 0.883  , 0.88   , 0.8794 ,\n",
       "            0.8784 , 0.8696 , 0.8677 , 0.867  , 0.8643 , 0.864  , 0.859  ,\n",
       "            0.858  , 0.8545 , 0.852  , 0.851  , 0.849  , 0.848  , 0.847  ,\n",
       "            0.846  , 0.8447 , 0.8438 , 0.8413 , 0.839  , 0.8374 , 0.8364 ,\n",
       "            0.835  , 0.832  , 0.831  , 0.828  , 0.8276 , 0.8267 , 0.8257 ,\n",
       "            0.824  , 0.823  , 0.8213 , 0.8164 , 0.813  , 0.8125 , 0.8105 ,\n",
       "            0.8096 , 0.8066 , 0.8047 , 0.8037 , 0.8003 , 0.8    , 0.799  ,\n",
       "            0.798  , 0.795  , 0.7944 , 0.793  , 0.791  , 0.7896 , 0.789  ,\n",
       "            0.787  , 0.785  , 0.7754 , 0.7725 , 0.771  , 0.7695 , 0.7656 ,\n",
       "            0.7646 , 0.7534 , 0.753  , 0.7515 , 0.75   , 0.749  , 0.7446 ,\n",
       "            0.7427 , 0.7397 , 0.7373 , 0.7363 , 0.7354 , 0.7305 , 0.7153 ,\n",
       "            0.7124 , 0.709  , 0.703  , 0.7017 , 0.698  , 0.692  , 0.69   ,\n",
       "            0.6885 , 0.6855 , 0.684  , 0.6733 , 0.6724 , 0.667  , 0.666  ,\n",
       "            0.6655 , 0.664  , 0.645  , 0.637  , 0.6177 , 0.605  , 0.604  ,\n",
       "            0.5884 , 0.584  , 0.5835 , 0.5806 , 0.576  , 0.574  , 0.5703 ,\n",
       "            0.566  , 0.5464 , 0.537  , 0.533  , 0.5312 , 0.529  , 0.5283 ,\n",
       "            0.5273 , 0.526  , 0.5254 , 0.5215 , 0.5186 , 0.5166 , 0.516  ,\n",
       "            0.511  , 0.503  , 0.496  , 0.4941 , 0.492  , 0.4888 , 0.4802 ,\n",
       "            0.4714 , 0.468  , 0.465  , 0.463  , 0.4612 , 0.4602 , 0.45   ,\n",
       "            0.442  , 0.441  , 0.4346 , 0.4343 , 0.4294 , 0.428  , 0.4258 ,\n",
       "            0.421  , 0.417  , 0.4146 , 0.4133 , 0.411  , 0.4077 , 0.3994 ,\n",
       "            0.3992 , 0.3948 , 0.3914 , 0.3901 , 0.39   , 0.3872 , 0.3845 ,\n",
       "            0.3828 , 0.382  , 0.379  , 0.3762 , 0.3752 , 0.3694 , 0.3667 ,\n",
       "            0.3643 , 0.3635 , 0.347  , 0.3435 , 0.3372 , 0.3298 , 0.3281 ,\n",
       "            0.3235 , 0.3176 , 0.2979 , 0.2903 , 0.2866 , 0.271  , 0.2612 ,\n",
       "            0.2595 , 0.2399 , 0.2386 , 0.2294 , 0.228  , 0.2272 , 0.2266 ,\n",
       "            0.2202 , 0.2129 , 0.2079 , 0.2035 , 0.2    , 0.1912 , 0.1849 ,\n",
       "            0.1824 , 0.172  , 0.17   , 0.1677 , 0.1674 , 0.1669 , 0.1443 ,\n",
       "            0.1364 , 0.1359 , 0.1082 , 0.1076 , 0.1047 , 0.0698 , 0.06647,\n",
       "            0.0538 , 0.0535 , 0.0511 , 0.0451 , 0.03754], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.28333333, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5769231 ,\n",
       "            0.5846154 , 0.6       , 0.61538464, 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.98   , 0.9727 , 0.9683 , 0.9653 , 0.9644 , 0.964  ,\n",
       "            0.9604 , 0.951  , 0.95   , 0.9453 , 0.9443 , 0.9434 , 0.9424 ,\n",
       "            0.9385 , 0.9326 , 0.929  , 0.927  , 0.926  , 0.923  , 0.921  ,\n",
       "            0.9194 , 0.918  , 0.916  , 0.915  , 0.9146 , 0.91   , 0.904  ,\n",
       "            0.9033 , 0.903  , 0.897  , 0.8955 , 0.895  , 0.892  , 0.8916 ,\n",
       "            0.8896 , 0.8823 , 0.88   , 0.8784 , 0.877  , 0.8765 , 0.8716 ,\n",
       "            0.87   , 0.867  , 0.8647 , 0.8643 , 0.863  , 0.8623 , 0.862  ,\n",
       "            0.861  , 0.858  , 0.857  , 0.8545 , 0.853  , 0.8506 , 0.8496 ,\n",
       "            0.8457 , 0.8447 , 0.8413 , 0.8403 , 0.84   , 0.8394 , 0.837  ,\n",
       "            0.836  , 0.83   , 0.829  , 0.8267 , 0.8237 , 0.823  , 0.8213 ,\n",
       "            0.8203 , 0.818  , 0.814  , 0.8125 , 0.8096 , 0.807  , 0.8066 ,\n",
       "            0.806  , 0.805  , 0.803  , 0.8013 , 0.801  , 0.8    , 0.7896 ,\n",
       "            0.788  , 0.7856 , 0.7827 , 0.7803 , 0.776  , 0.7695 , 0.7676 ,\n",
       "            0.766  , 0.764  , 0.763  , 0.759  , 0.755  , 0.7505 , 0.7495 ,\n",
       "            0.7466 , 0.745  , 0.727  , 0.7266 , 0.7227 , 0.7173 , 0.717  ,\n",
       "            0.716  , 0.713  , 0.7114 , 0.7065 , 0.704  , 0.7017 , 0.699  ,\n",
       "            0.694  , 0.687  , 0.6855 , 0.68   , 0.678  , 0.6772 , 0.676  ,\n",
       "            0.6577 , 0.65   , 0.6304 , 0.616  , 0.613  , 0.596  , 0.595  ,\n",
       "            0.5947 , 0.5864 , 0.5854 , 0.581  , 0.5796 , 0.573  , 0.5566 ,\n",
       "            0.547  , 0.541  , 0.54   , 0.5376 , 0.536  , 0.5356 , 0.5347 ,\n",
       "            0.5312 , 0.5273 , 0.527  , 0.523  , 0.5205 , 0.519  , 0.5146 ,\n",
       "            0.505  , 0.502  , 0.5    , 0.4968 , 0.492  , 0.4878 , 0.4734 ,\n",
       "            0.467  , 0.4666 , 0.4663 , 0.4617 , 0.4612 , 0.4556 , 0.448  ,\n",
       "            0.4395 , 0.439  , 0.4333 , 0.4321 , 0.4304 , 0.4236 , 0.4229 ,\n",
       "            0.4172 , 0.4148 , 0.4138 , 0.412  , 0.403  , 0.396  , 0.3943 ,\n",
       "            0.3936 , 0.3928 , 0.39   , 0.3867 , 0.3845 , 0.3833 , 0.3804 ,\n",
       "            0.3787 , 0.3774 , 0.3726 , 0.3684 , 0.3643 , 0.362  , 0.3618 ,\n",
       "            0.3406 , 0.3396 , 0.332  , 0.3262 , 0.3218 , 0.3176 , 0.3174 ,\n",
       "            0.2935 , 0.2815 , 0.2776 , 0.264  , 0.2542 , 0.252  , 0.2368 ,\n",
       "            0.2297 , 0.2246 , 0.2216 , 0.2207 , 0.2185 , 0.2148 , 0.2043 ,\n",
       "            0.1985 , 0.1936 , 0.1907 , 0.1835 , 0.1748 , 0.1726 , 0.1648 ,\n",
       "            0.1622 , 0.1583 , 0.1581 , 0.157  , 0.1351 , 0.1289 , 0.1271 ,\n",
       "            0.1009 , 0.10034, 0.0957 , 0.0628 , 0.05975, 0.04794, 0.0478 ,\n",
       "            0.04596, 0.04037, 0.03284], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.29166666, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.36153847, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.65384614, 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.84615386, 0.86153847, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9230769 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.984  , 0.9785 , 0.9727 , 0.9717 , 0.971  , 0.97   ,\n",
       "            0.968  , 0.967  , 0.9595 , 0.958  , 0.952  , 0.9517 , 0.951  ,\n",
       "            0.9497 , 0.9463 , 0.941  , 0.9404 , 0.9395 , 0.9365 , 0.932  ,\n",
       "            0.9316 , 0.9287 , 0.928  , 0.927  , 0.9253 , 0.9243 , 0.9204 ,\n",
       "            0.914  , 0.913  , 0.9087 , 0.906  , 0.9053 , 0.902  , 0.9014 ,\n",
       "            0.8984 , 0.893  , 0.891  , 0.8906 , 0.8896 , 0.887  , 0.885  ,\n",
       "            0.8833 , 0.879  , 0.877  , 0.8765 , 0.875  , 0.874  , 0.8726 ,\n",
       "            0.869  , 0.867  , 0.8657 , 0.863  , 0.862  , 0.8613 , 0.858  ,\n",
       "            0.8564 , 0.856  , 0.854  , 0.853  , 0.852  , 0.8516 , 0.849  ,\n",
       "            0.846  , 0.8447 , 0.8423 , 0.839  , 0.838  , 0.836  , 0.8335 ,\n",
       "            0.831  , 0.83   , 0.8296 , 0.8286 , 0.8267 , 0.826  , 0.825  ,\n",
       "            0.8228 , 0.821  , 0.8193 , 0.817  , 0.8164 , 0.814  , 0.8135 ,\n",
       "            0.8115 , 0.8057 , 0.8013 , 0.7993 , 0.793  , 0.792  , 0.7915 ,\n",
       "            0.7856 , 0.783  , 0.7793 , 0.7773 , 0.776  , 0.775  , 0.771  ,\n",
       "            0.765  , 0.7637 , 0.763  , 0.761  , 0.7563 , 0.7393 , 0.735  ,\n",
       "            0.734  , 0.7285 , 0.726  , 0.7227 , 0.721  , 0.714  , 0.7134 ,\n",
       "            0.709  , 0.697  , 0.6963 , 0.696  , 0.6953 , 0.692  , 0.6895 ,\n",
       "            0.688  , 0.683  , 0.666  , 0.6587 , 0.6353 , 0.6226 , 0.622  ,\n",
       "            0.5996 , 0.599  , 0.5938 , 0.5923 , 0.5806 , 0.5757 , 0.574  ,\n",
       "            0.5596 , 0.549  , 0.5483 , 0.5425 , 0.541  , 0.5396 , 0.539  ,\n",
       "            0.538  , 0.536  , 0.5356 , 0.5337 , 0.529  , 0.52   , 0.5156 ,\n",
       "            0.5117 , 0.5093 , 0.509  , 0.508  , 0.502  , 0.4995 , 0.4956 ,\n",
       "            0.4863 , 0.4668 , 0.4648 , 0.4631 , 0.4622 , 0.4607 , 0.4504 ,\n",
       "            0.444  , 0.4395 , 0.4368 , 0.4329 , 0.4307 , 0.4265 , 0.4233 ,\n",
       "            0.4226 , 0.414  , 0.4114 , 0.411  , 0.4067 , 0.4038 , 0.3977 ,\n",
       "            0.3943 , 0.3892 , 0.3877 , 0.3875 , 0.3872 , 0.385  , 0.3828 ,\n",
       "            0.381  , 0.38   , 0.3713 , 0.3708 , 0.3696 , 0.3594 , 0.359  ,\n",
       "            0.3555 , 0.354  , 0.3494 , 0.3347 , 0.3276 , 0.3257 , 0.3242 ,\n",
       "            0.3196 , 0.3174 , 0.313  , 0.2898 , 0.2751 , 0.2717 , 0.2573 ,\n",
       "            0.248  , 0.2452 , 0.2363 , 0.2222 , 0.2217 , 0.2181 , 0.2158 ,\n",
       "            0.2115 , 0.2106 , 0.197  , 0.1901 , 0.1858 , 0.1829 , 0.177  ,\n",
       "            0.1671 , 0.1647 , 0.1615 , 0.1543 , 0.1504 , 0.1501 , 0.1492 ,\n",
       "            0.1274 , 0.1232 , 0.1194 , 0.0955 , 0.0939 , 0.0891 , 0.0572 ,\n",
       "            0.0544 , 0.04352, 0.04303, 0.0417 , 0.0365 , 0.02898],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.31666666, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.05      ,\n",
       "            0.05      , 0.05      , 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.075     , 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.17692308, 0.1923077 , 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.2769231 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.3846154 , 0.3923077 ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.61538464, 0.6230769 ,\n",
       "            0.63846153, 0.65384614, 0.66923076, 0.6769231 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.988  , 0.983  , 0.978  , 0.9775 , 0.977  , 0.976  ,\n",
       "            0.974  , 0.973  , 0.968  , 0.967  , 0.9624 , 0.96   , 0.959  ,\n",
       "            0.958  , 0.955  , 0.9526 , 0.9497 , 0.949  , 0.9473 , 0.945  ,\n",
       "            0.9424 , 0.939  , 0.9385 , 0.9346 , 0.9297 , 0.929  , 0.9287 ,\n",
       "            0.928  , 0.925  , 0.922  , 0.9214 , 0.919  , 0.9185 , 0.911  ,\n",
       "            0.91   , 0.9087 , 0.9077 , 0.9053 , 0.903  , 0.902  , 0.9014 ,\n",
       "            0.895  , 0.8945 , 0.8936 , 0.893  , 0.889  , 0.887  , 0.883  ,\n",
       "            0.882  , 0.8813 , 0.879  , 0.878  , 0.877  , 0.874  , 0.873  ,\n",
       "            0.872  , 0.8696 , 0.869  , 0.863  , 0.8604 , 0.8594 , 0.859  ,\n",
       "            0.856  , 0.8545 , 0.852  , 0.851  , 0.848  , 0.8477 , 0.8467 ,\n",
       "            0.844  , 0.8423 , 0.842  , 0.8403 , 0.8364 , 0.835  , 0.8345 ,\n",
       "            0.825  , 0.822  , 0.82   , 0.8164 , 0.814  , 0.8115 , 0.8057 ,\n",
       "            0.804  , 0.803  , 0.801  , 0.8003 , 0.7954 , 0.795  , 0.792  ,\n",
       "            0.787  , 0.7866 , 0.784  , 0.782  , 0.76   , 0.7593 , 0.754  ,\n",
       "            0.753  , 0.7485 , 0.7466 , 0.7427 , 0.742  , 0.7407 , 0.736  ,\n",
       "            0.734  , 0.7236 , 0.7217 , 0.7163 , 0.716  , 0.7124 , 0.711  ,\n",
       "            0.703  , 0.6934 , 0.6846 , 0.6646 , 0.649  , 0.6436 , 0.628  ,\n",
       "            0.6265 , 0.617  , 0.6123 , 0.611  , 0.5977 , 0.5933 , 0.5923 ,\n",
       "            0.585  , 0.5747 , 0.5684 , 0.5654 , 0.5645 , 0.561  , 0.558  ,\n",
       "            0.5547 , 0.5527 , 0.552  , 0.551  , 0.536  , 0.5312 , 0.5273 ,\n",
       "            0.5254 , 0.5244 , 0.5215 , 0.5127 , 0.51   , 0.5083 , 0.4858 ,\n",
       "            0.4805 , 0.477  , 0.475  , 0.474  , 0.4653 , 0.4631 , 0.4553 ,\n",
       "            0.4492 , 0.4475 , 0.442  , 0.4387 , 0.4343 , 0.4314 , 0.4312 ,\n",
       "            0.4285 , 0.4255 , 0.4214 , 0.4155 , 0.4146 , 0.4055 , 0.4048 ,\n",
       "            0.4045 , 0.4011 , 0.4006 , 0.3967 , 0.3936 , 0.3884 , 0.3875 ,\n",
       "            0.3865 , 0.3796 , 0.3777 , 0.3684 , 0.3682 , 0.3672 , 0.367  ,\n",
       "            0.3635 , 0.357  , 0.3372 , 0.3318 , 0.3308 , 0.328  , 0.323  ,\n",
       "            0.3206 , 0.3154 , 0.2896 , 0.2754 , 0.2725 , 0.2559 , 0.246  ,\n",
       "            0.2437 , 0.2362 , 0.22   , 0.2194 , 0.2166 , 0.2135 , 0.2096 ,\n",
       "            0.2073 , 0.193  , 0.1857 , 0.1819 , 0.1788 , 0.1727 , 0.1632 ,\n",
       "            0.1603 , 0.1583 , 0.1498 , 0.1458 , 0.1454 , 0.1447 , 0.12244,\n",
       "            0.1186 , 0.1144 , 0.0909 , 0.0891 , 0.08466, 0.05292, 0.05014,\n",
       "            0.03986, 0.03912, 0.03812, 0.03314, 0.02576], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.325, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.1       , 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.4       , 0.4       , 0.40833333, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.24615385, 0.25384617, 0.26923078, 0.2769231 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.45384616, 0.46153846, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.56153846, 0.5692308 , 0.5846154 , 0.5923077 , 0.6076923 ,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.6615385 , 0.6769231 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.73846155, 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9907 , 0.9873 , 0.9824 , 0.982  , 0.9814 , 0.9795 ,\n",
       "            0.9785 , 0.975  , 0.9736 , 0.9707 , 0.967  , 0.966  , 0.965  ,\n",
       "            0.963  , 0.962  , 0.9595 , 0.9585 , 0.9575 , 0.9565 , 0.9546 ,\n",
       "            0.9526 , 0.952  , 0.9497 , 0.949  , 0.9487 , 0.948  , 0.9463 ,\n",
       "            0.9424 , 0.9414 , 0.941  , 0.938  , 0.9346 , 0.934  , 0.932  ,\n",
       "            0.9243 , 0.9233 , 0.923  , 0.9204 , 0.918  , 0.917  , 0.916  ,\n",
       "            0.9106 , 0.9097 , 0.908  , 0.9077 , 0.907  , 0.9053 , 0.9014 ,\n",
       "            0.899  , 0.897  , 0.896  , 0.895  , 0.894  , 0.8926 , 0.891  ,\n",
       "            0.8906 , 0.89   , 0.889  , 0.8877 , 0.887  , 0.8843 , 0.8794 ,\n",
       "            0.8784 , 0.8774 , 0.876  , 0.8745 , 0.871  , 0.867  , 0.8667 ,\n",
       "            0.8643 , 0.864  , 0.862  , 0.861  , 0.8594 , 0.856  , 0.855  ,\n",
       "            0.8516 , 0.844  , 0.841  , 0.8374 , 0.833  , 0.8296 , 0.8257 ,\n",
       "            0.8247 , 0.8228 , 0.82   , 0.8164 , 0.8145 , 0.8086 , 0.8066 ,\n",
       "            0.804  , 0.8037 , 0.7817 , 0.779  , 0.7764 , 0.776  , 0.7725 ,\n",
       "            0.768  , 0.767  , 0.764  , 0.762  , 0.7593 , 0.7534 , 0.7476 ,\n",
       "            0.7437 , 0.7397 , 0.737  , 0.7344 , 0.733  , 0.7305 , 0.722  ,\n",
       "            0.7163 , 0.7075 , 0.6895 , 0.6724 , 0.6616 , 0.652  , 0.649  ,\n",
       "            0.6377 , 0.63   , 0.6294 , 0.614  , 0.61   , 0.6094 , 0.6064 ,\n",
       "            0.5967 , 0.5903 , 0.586  , 0.5835 , 0.5825 , 0.575  , 0.573  ,\n",
       "            0.572  , 0.567  , 0.563  , 0.552  , 0.546  , 0.545  , 0.5415 ,\n",
       "            0.5405 , 0.5386 , 0.5317 , 0.529  , 0.523  , 0.518  , 0.5034 ,\n",
       "            0.4934 , 0.4888 , 0.4868 , 0.4849 , 0.483  , 0.4827 , 0.4749 ,\n",
       "            0.4705 , 0.4617 , 0.4558 , 0.451  , 0.4482 , 0.446  , 0.445  ,\n",
       "            0.4426 , 0.4402 , 0.438  , 0.4324 , 0.4294 , 0.4246 , 0.4187 ,\n",
       "            0.4182 , 0.4126 , 0.408  , 0.4058 , 0.4    , 0.3987 , 0.3962 ,\n",
       "            0.3914 , 0.387  , 0.3845 , 0.38   , 0.3784 , 0.3745 , 0.373  ,\n",
       "            0.3662 , 0.3633 , 0.3376 , 0.3374 , 0.3318 , 0.3306 , 0.3271 ,\n",
       "            0.3218 , 0.3157 , 0.2896 , 0.2734 , 0.2715 , 0.2542 , 0.2428 ,\n",
       "            0.2406 , 0.237  , 0.219  , 0.2156 , 0.2152 , 0.2118 , 0.2081 ,\n",
       "            0.2026 , 0.1886 , 0.1805 , 0.177  , 0.1738 , 0.1687 , 0.1583 ,\n",
       "            0.1561 , 0.155  , 0.1444 , 0.1405 , 0.1399 , 0.1394 , 0.11694,\n",
       "            0.1144 , 0.10876, 0.0866 , 0.0845 , 0.07965, 0.04858, 0.04602,\n",
       "            0.0365 , 0.03555, 0.03482, 0.03004, 0.02293], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.325, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.04166667, 0.05      ,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.1       , 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.2769231 , 0.2923077 ,\n",
       "            0.3       , 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.47692308,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.63076925, 0.63846153, 0.65384614, 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.73846155, 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9927 , 0.9897 , 0.986  , 0.9854 , 0.985  , 0.983  ,\n",
       "            0.982  , 0.9795 , 0.9775 , 0.9756 , 0.9717 , 0.9707 , 0.97   ,\n",
       "            0.9683 , 0.968  , 0.9663 , 0.9644 , 0.9634 , 0.963  , 0.9614 ,\n",
       "            0.96   , 0.959  , 0.957  , 0.9565 , 0.9556 , 0.955  , 0.9536 ,\n",
       "            0.9507 , 0.949  , 0.9487 , 0.947  , 0.9434 , 0.943  , 0.941  ,\n",
       "            0.9336 , 0.9326 , 0.931  , 0.9297 , 0.9287 , 0.9272 , 0.9263 ,\n",
       "            0.921  , 0.9204 , 0.9194 , 0.9175 , 0.917  , 0.9155 , 0.911  ,\n",
       "            0.9097 , 0.907  , 0.9067 , 0.9062 , 0.906  , 0.9053 , 0.9033 ,\n",
       "            0.902  , 0.9014 , 0.901  , 0.899  , 0.8955 , 0.891  , 0.8906 ,\n",
       "            0.8896 , 0.887  , 0.886  , 0.8833 , 0.883  , 0.88   , 0.879  ,\n",
       "            0.8784 , 0.8765 , 0.8745 , 0.8735 , 0.8726 , 0.872  , 0.869  ,\n",
       "            0.8687 , 0.8677 , 0.8643 , 0.8574 , 0.8535 , 0.8506 , 0.8467 ,\n",
       "            0.842  , 0.8394 , 0.8384 , 0.837  , 0.836  , 0.8345 , 0.8306 ,\n",
       "            0.828  , 0.8276 , 0.8228 , 0.821  , 0.819  , 0.8184 , 0.796  ,\n",
       "            0.7935 , 0.7905 , 0.7896 , 0.7847 , 0.782  , 0.7817 , 0.778  ,\n",
       "            0.777  , 0.7764 , 0.7734 , 0.768  , 0.761  , 0.7583 , 0.7534 ,\n",
       "            0.7505 , 0.7476 , 0.745  , 0.7437 , 0.735  , 0.73   , 0.721  ,\n",
       "            0.702  , 0.685  , 0.674  , 0.6636 , 0.661  , 0.6504 , 0.6416 ,\n",
       "            0.639  , 0.621  , 0.62   , 0.617  , 0.6064 , 0.5996 , 0.5957 ,\n",
       "            0.592  , 0.5845 , 0.5825 , 0.582  , 0.5757 , 0.569  , 0.5596 ,\n",
       "            0.553  , 0.552  , 0.551  , 0.5464 , 0.5444 , 0.5366 , 0.536  ,\n",
       "            0.528  , 0.522  , 0.51   , 0.4978 , 0.4966 , 0.4915 , 0.4888 ,\n",
       "            0.4878 , 0.4866 , 0.477  , 0.4756 , 0.4668 , 0.4575 , 0.4565 ,\n",
       "            0.4521 , 0.4492 , 0.449  , 0.446  , 0.4434 , 0.44   , 0.4365 ,\n",
       "            0.4321 , 0.426  , 0.421  , 0.4202 , 0.415  , 0.4104 , 0.4053 ,\n",
       "            0.4004 , 0.4    , 0.3953 , 0.3906 , 0.3887 , 0.3843 , 0.38   ,\n",
       "            0.379  , 0.374  , 0.3713 , 0.3647 , 0.362  , 0.3345 , 0.3335 ,\n",
       "            0.3296 , 0.3286 , 0.3274 , 0.321  , 0.3123 , 0.2861 , 0.2695 ,\n",
       "            0.2688 , 0.2493 , 0.2366 , 0.235  , 0.234  , 0.2153 , 0.2113 ,\n",
       "            0.209  , 0.2073 , 0.2042 , 0.196  , 0.182  , 0.1735 , 0.1707 ,\n",
       "            0.1672 , 0.1632 , 0.1527 , 0.152  , 0.1488 , 0.1383 , 0.134  ,\n",
       "            0.1333 , 0.1332 , 0.11084, 0.10913, 0.10284, 0.082  , 0.07947,\n",
       "            0.0752 , 0.04468, 0.04208, 0.03333, 0.0323 , 0.03174, 0.02718,\n",
       "            0.0205 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.35833332, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.05      ,\n",
       "            0.05      , 0.05      , 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.075     , 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.21538462, 0.22307692, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.2769231 , 0.2923077 , 0.3       , 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.37692308, 0.3846154 , 0.4076923 , 0.41538462,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.50769234, 0.5153846 ,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.54615384, 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.6       , 0.61538464,\n",
       "            0.6230769 , 0.63846153, 0.64615387, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.7923077 , 0.8       , 0.8076923 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.85384613, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.994  , 0.9917 , 0.989  , 0.9883 , 0.988  , 0.9863 ,\n",
       "            0.9854 , 0.9844 , 0.982  , 0.981  , 0.9766 , 0.976  , 0.9756 ,\n",
       "            0.974  , 0.9736 , 0.973  , 0.9707 , 0.9697 , 0.969  , 0.9688 ,\n",
       "            0.968  , 0.966  , 0.965  , 0.9644 , 0.963  , 0.962  , 0.9595 ,\n",
       "            0.958  , 0.956  , 0.953  , 0.9526 , 0.951  , 0.945  , 0.944  ,\n",
       "            0.9434 , 0.942  , 0.9414 , 0.94   , 0.9385 , 0.9375 , 0.9336 ,\n",
       "            0.931  , 0.9287 , 0.928  , 0.9233 , 0.92   , 0.9194 , 0.919  ,\n",
       "            0.9185 , 0.9175 , 0.917  , 0.916  , 0.9155 , 0.915  , 0.913  ,\n",
       "            0.9087 , 0.906  , 0.9053 , 0.9043 , 0.9    , 0.8994 , 0.897  ,\n",
       "            0.895  , 0.893  , 0.891  , 0.8906 , 0.89   , 0.889  , 0.8877 ,\n",
       "            0.886  , 0.8857 , 0.8853 , 0.8794 , 0.872  , 0.87   , 0.869  ,\n",
       "            0.8667 , 0.8623 , 0.8594 , 0.8584 , 0.856  , 0.854  , 0.852  ,\n",
       "            0.8516 , 0.849  , 0.8486 , 0.844  , 0.842  , 0.839  , 0.837  ,\n",
       "            0.816  , 0.812  , 0.8115 , 0.8057 , 0.8013 , 0.801  , 0.8003 ,\n",
       "            0.796  , 0.7944 , 0.787  , 0.785  , 0.7793 , 0.777  , 0.7686 ,\n",
       "            0.7666 , 0.762  , 0.7563 , 0.754  , 0.744  , 0.729  , 0.7095 ,\n",
       "            0.692  , 0.6904 , 0.6855 , 0.6724 , 0.663  , 0.659  , 0.6455 ,\n",
       "            0.6426 , 0.642  , 0.6323 , 0.6255 , 0.6206 , 0.62   , 0.6167 ,\n",
       "            0.611  , 0.606  , 0.603  , 0.5923 , 0.5815 , 0.5767 , 0.574  ,\n",
       "            0.5693 , 0.5664 , 0.565  , 0.56   , 0.548  , 0.5386 , 0.532  ,\n",
       "            0.5312 , 0.518  , 0.511  , 0.5103 , 0.509  , 0.498  , 0.4973 ,\n",
       "            0.4956 , 0.4949 , 0.4844 , 0.4734 , 0.4668 , 0.4653 , 0.4648 ,\n",
       "            0.4646 , 0.4634 , 0.456  , 0.4526 , 0.4514 , 0.4468 , 0.4438 ,\n",
       "            0.4392 , 0.4387 , 0.4385 , 0.4316 , 0.4253 , 0.417  , 0.4114 ,\n",
       "            0.4102 , 0.402  , 0.4    , 0.3975 , 0.3948 , 0.394  , 0.3862 ,\n",
       "            0.3848 , 0.3748 , 0.3672 , 0.3464 , 0.3347 , 0.3298 , 0.3281 ,\n",
       "            0.3254 , 0.3228 , 0.3127 , 0.284  , 0.2686 , 0.2683 , 0.2473 ,\n",
       "            0.2327 , 0.2303 , 0.2302 , 0.2106 , 0.2065 , 0.2045 , 0.2026 ,\n",
       "            0.1993 , 0.1915 , 0.1766 , 0.1683 , 0.1658 , 0.162  , 0.1577 ,\n",
       "            0.1481 , 0.1462 , 0.1437 , 0.133  , 0.1285 , 0.1283 , 0.1277 ,\n",
       "            0.1052 , 0.1036 , 0.09753, 0.07684, 0.07434, 0.0708 , 0.04083,\n",
       "            0.0384 , 0.03004, 0.02908, 0.02855, 0.02423, 0.01816],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.39166668, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05      , 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.075     , 0.075     ,\n",
       "            0.08333334, 0.1       , 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.39166668, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.2       , 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.24615385, 0.25384617, 0.26923078, 0.2769231 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3923077 , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.46153846, 0.47692308, 0.4846154 , 0.4923077 , 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5846154 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.63076925, 0.63846153, 0.65384614, 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.996  , 0.994  , 0.9917 , 0.991  , 0.9907 , 0.9897 ,\n",
       "            0.989  , 0.988  , 0.9863 , 0.985  , 0.9814 , 0.981  , 0.9805 ,\n",
       "            0.979  , 0.9775 , 0.977  , 0.976  , 0.974  , 0.973  , 0.9727 ,\n",
       "            0.971  , 0.9707 , 0.969  , 0.9683 , 0.966  , 0.9653 , 0.9624 ,\n",
       "            0.961  , 0.9604 , 0.9595 , 0.9536 , 0.9526 , 0.952  , 0.9517 ,\n",
       "            0.951  , 0.9507 , 0.948  , 0.9473 , 0.947  , 0.944  , 0.9434 ,\n",
       "            0.9424 , 0.9414 , 0.94   , 0.9395 , 0.9355 , 0.9346 , 0.932  ,\n",
       "            0.9316 , 0.931  , 0.93   , 0.9287 , 0.928  , 0.9277 , 0.927  ,\n",
       "            0.9253 , 0.9224 , 0.9194 , 0.9185 , 0.915  , 0.9146 , 0.9126 ,\n",
       "            0.9087 , 0.907  , 0.9067 , 0.9062 , 0.9053 , 0.904  , 0.9033 ,\n",
       "            0.901  , 0.9    , 0.8994 , 0.896  , 0.8906 , 0.885  , 0.8843 ,\n",
       "            0.8833 , 0.8774 , 0.8745 , 0.8735 , 0.8726 , 0.872  , 0.866  ,\n",
       "            0.8657 , 0.8647 , 0.8643 , 0.858  , 0.8564 , 0.853  , 0.8506 ,\n",
       "            0.8335 , 0.8325 , 0.8306 , 0.83   , 0.8276 , 0.8228 , 0.822  ,\n",
       "            0.82   , 0.8174 , 0.817  , 0.8154 , 0.809  , 0.8057 , 0.798  ,\n",
       "            0.7964 , 0.793  , 0.792  , 0.7896 , 0.7803 , 0.7773 , 0.7744 ,\n",
       "            0.764  , 0.752  , 0.731  , 0.714  , 0.707  , 0.692  , 0.689  ,\n",
       "            0.683  , 0.6714 , 0.6675 , 0.6636 , 0.6543 , 0.648  , 0.6426 ,\n",
       "            0.642  , 0.6387 , 0.635  , 0.63   , 0.627  , 0.6265 , 0.607  ,\n",
       "            0.6055 , 0.598  , 0.5977 , 0.5933 , 0.592  , 0.5903 , 0.5874 ,\n",
       "            0.581  , 0.557  , 0.5503 , 0.5474 , 0.5415 , 0.54   , 0.5327 ,\n",
       "            0.5303 , 0.529  , 0.52   , 0.5117 , 0.503  , 0.5024 , 0.5    ,\n",
       "            0.4927 , 0.4827 , 0.4812 , 0.481  , 0.4807 , 0.4712 , 0.471  ,\n",
       "            0.468  , 0.4626 , 0.4622 , 0.4556 , 0.4546 , 0.4539 , 0.452  ,\n",
       "            0.446  , 0.4382 , 0.4316 , 0.4275 , 0.4146 , 0.414  , 0.4124 ,\n",
       "            0.4111 , 0.4072 , 0.3987 , 0.3982 , 0.398  , 0.3875 , 0.3691 ,\n",
       "            0.3586 , 0.3398 , 0.3384 , 0.3342 , 0.332  , 0.3223 , 0.3132 ,\n",
       "            0.289  , 0.2664 , 0.266  , 0.248  , 0.2394 , 0.2306 , 0.2281 ,\n",
       "            0.2152 , 0.2104 , 0.2048 , 0.2031 , 0.2017 , 0.1874 , 0.1749 ,\n",
       "            0.1658 , 0.1611 , 0.1582 , 0.1566 , 0.1489 , 0.1432 , 0.139  ,\n",
       "            0.1284 , 0.1243 , 0.1236 , 0.1235 , 0.1025 , 0.1011 , 0.093  ,\n",
       "            0.0753 , 0.0716 , 0.0666 , 0.03775, 0.03555, 0.02802, 0.02661,\n",
       "            0.02258, 0.01653], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.39166668, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.075     , 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.24615385, 0.25384617,\n",
       "            0.26923078, 0.2769231 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.36153847, 0.3846154 , 0.3923077 , 0.4       , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4923077 , 0.5       , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.66923076, 0.6769231 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86153847, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.997  , 0.9956 , 0.9937 , 0.993  , 0.9927 , 0.992  ,\n",
       "            0.991  , 0.99   , 0.9893 , 0.988  , 0.985  , 0.9844 , 0.984  ,\n",
       "            0.983  , 0.9824 , 0.982  , 0.9814 , 0.9805 , 0.98   , 0.9785 ,\n",
       "            0.978  , 0.9775 , 0.976  , 0.9756 , 0.974  , 0.9736 , 0.9717 ,\n",
       "            0.9707 , 0.9688 , 0.967  , 0.9663 , 0.966  , 0.9653 , 0.9604 ,\n",
       "            0.9595 , 0.959  , 0.9585 , 0.9575 , 0.956  , 0.9546 , 0.951  ,\n",
       "            0.9497 , 0.9487 , 0.9478 , 0.944  , 0.9434 , 0.941  , 0.9404 ,\n",
       "            0.94   , 0.9395 , 0.939  , 0.9375 , 0.937  , 0.9365 , 0.9346 ,\n",
       "            0.932  , 0.93   , 0.9287 , 0.928  , 0.926  , 0.925  , 0.924  ,\n",
       "            0.923  , 0.9194 , 0.919  , 0.918  , 0.917  , 0.916  , 0.9155 ,\n",
       "            0.9146 , 0.914  , 0.9126 , 0.9106 , 0.9077 , 0.904  , 0.897  ,\n",
       "            0.8965 , 0.896  , 0.8896 , 0.887  , 0.886  , 0.885  , 0.879  ,\n",
       "            0.8784 , 0.8716 , 0.8696 , 0.867  , 0.865  , 0.848  , 0.847  ,\n",
       "            0.8447 , 0.844  , 0.841  , 0.8374 , 0.8345 , 0.8325 , 0.832  ,\n",
       "            0.8296 , 0.824  , 0.8203 , 0.813  , 0.8115 , 0.8086 , 0.8057 ,\n",
       "            0.805  , 0.7944 , 0.7935 , 0.7896 , 0.78   , 0.7666 , 0.746  ,\n",
       "            0.7285 , 0.723  , 0.722  , 0.707  , 0.701  , 0.699  , 0.6826 ,\n",
       "            0.6807 , 0.679  , 0.678  , 0.6685 , 0.662  , 0.6562 , 0.656  ,\n",
       "            0.6523 , 0.6504 , 0.643  , 0.6406 , 0.64   , 0.621  , 0.6167 ,\n",
       "            0.6104 , 0.609  , 0.604  , 0.603  , 0.602  , 0.6006 , 0.5933 ,\n",
       "            0.568  , 0.562  , 0.5586 , 0.5513 , 0.548  , 0.5425 , 0.541  ,\n",
       "            0.5405 , 0.5254 , 0.522  , 0.513  , 0.512  , 0.51   , 0.5015 ,\n",
       "            0.4915 , 0.4905 , 0.4897 , 0.489  , 0.479  , 0.4785 , 0.476  ,\n",
       "            0.4688 , 0.4673 , 0.463  , 0.4622 , 0.4614 , 0.46   , 0.4531 ,\n",
       "            0.4453 , 0.438  , 0.4302 , 0.421  , 0.4192 , 0.4175 , 0.4133 ,\n",
       "            0.4126 , 0.4028 , 0.4014 , 0.3992 , 0.3892 , 0.3728 , 0.358  ,\n",
       "            0.3477 , 0.343  , 0.3367 , 0.334  , 0.3271 , 0.3147 , 0.2908 ,\n",
       "            0.2688 , 0.2676 , 0.2473 , 0.2434 , 0.2285 , 0.226  , 0.2166 ,\n",
       "            0.2113 , 0.2045 , 0.2037 , 0.1991 , 0.1846 , 0.1726 , 0.1627 ,\n",
       "            0.1584 , 0.1548 , 0.1543 , 0.1488 , 0.1409 , 0.1359 , 0.1254 ,\n",
       "            0.12085, 0.1204 , 0.11993, 0.10034, 0.09753, 0.0896 , 0.0732 ,\n",
       "            0.06866, 0.0642 , 0.03534, 0.03314, 0.02611, 0.02475, 0.02466,\n",
       "            0.02101, 0.01513], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.425, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16923077,\n",
       "            0.17692308, 0.1923077 , 0.2       , 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.24615385, 0.25384617, 0.26923078, 0.2769231 ,\n",
       "            0.2923077 , 0.3       , 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.43846154, 0.45384616,\n",
       "            0.46923077, 0.5       , 0.50769234, 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.75384617, 0.75384617,\n",
       "            0.7692308 , 0.77692306, 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9976 , 0.9966 , 0.995  , 0.9946 , 0.994  , 0.9937 ,\n",
       "            0.993  , 0.9927 , 0.991  , 0.9907 , 0.988  , 0.9873 , 0.987  ,\n",
       "            0.9863 , 0.986  , 0.985  , 0.984  , 0.9834 , 0.983  , 0.982  ,\n",
       "            0.9805 , 0.98   , 0.979  , 0.9785 , 0.9775 , 0.9766 , 0.975  ,\n",
       "            0.973  , 0.9727 , 0.972  , 0.968  , 0.9673 , 0.967  , 0.9653 ,\n",
       "            0.965  , 0.9644 , 0.9634 , 0.9624 , 0.9604 , 0.9595 , 0.9585 ,\n",
       "            0.958  , 0.9575 , 0.9565 , 0.9556 , 0.953  , 0.952  , 0.9497 ,\n",
       "            0.949  , 0.9487 , 0.9478 , 0.9473 , 0.9463 , 0.945  , 0.9414 ,\n",
       "            0.94   , 0.9395 , 0.938  , 0.935  , 0.934  , 0.9316 , 0.931  ,\n",
       "            0.9307 , 0.9297 , 0.9287 , 0.9277 , 0.9272 , 0.927  , 0.9263 ,\n",
       "            0.9253 , 0.9243 , 0.924  , 0.919  , 0.9155 , 0.9116 , 0.9106 ,\n",
       "            0.9087 , 0.903  , 0.9014 , 0.9004 , 0.8994 , 0.896  , 0.8955 ,\n",
       "            0.894  , 0.8926 , 0.8877 , 0.886  , 0.8843 , 0.8823 , 0.8657 ,\n",
       "            0.864  , 0.863  , 0.8623 , 0.8574 , 0.8545 , 0.8535 , 0.8496 ,\n",
       "            0.849  , 0.8486 , 0.842  , 0.8413 , 0.8325 , 0.832  , 0.826  ,\n",
       "            0.824  , 0.8237 , 0.814  , 0.8135 , 0.8115 , 0.8013 , 0.792  ,\n",
       "            0.77   , 0.755  , 0.7466 , 0.7446 , 0.7295 , 0.7236 , 0.7197 ,\n",
       "            0.7056 , 0.7036 , 0.702  , 0.7017 , 0.695  , 0.6885 , 0.682  ,\n",
       "            0.6816 , 0.678  , 0.6675 , 0.6655 , 0.6646 , 0.661  , 0.642  ,\n",
       "            0.6387 , 0.6357 , 0.631  , 0.624  , 0.6226 , 0.622  , 0.6187 ,\n",
       "            0.586  , 0.585  , 0.5757 , 0.5693 , 0.5674 , 0.5654 , 0.5615 ,\n",
       "            0.56   , 0.5464 , 0.5435 , 0.5303 , 0.529  , 0.528  , 0.5205 ,\n",
       "            0.512  , 0.5117 , 0.5107 , 0.507  , 0.498  , 0.497  , 0.4922 ,\n",
       "            0.486  , 0.4846 , 0.4834 , 0.4817 , 0.4814 , 0.4736 , 0.4724 ,\n",
       "            0.4626 , 0.458  , 0.4475 , 0.4377 , 0.4312 , 0.4307 , 0.4297 ,\n",
       "            0.4292 , 0.4282 , 0.4155 , 0.4143 , 0.4126 , 0.4036 , 0.3813 ,\n",
       "            0.3726 , 0.3525 , 0.348  , 0.343  , 0.3406 , 0.3357 , 0.3203 ,\n",
       "            0.2944 , 0.2742 , 0.2717 , 0.2498 , 0.2441 , 0.2292 , 0.2266 ,\n",
       "            0.2166 , 0.2113 , 0.2047 , 0.2035 , 0.1987 , 0.1837 , 0.1718 ,\n",
       "            0.1616 , 0.1571 , 0.1531 , 0.1527 , 0.1469 , 0.1396 , 0.1342 ,\n",
       "            0.1235 , 0.1186 , 0.1174 , 0.0979 , 0.09485, 0.0871 , 0.07056,\n",
       "            0.066  , 0.06223, 0.0332 , 0.03102, 0.02423, 0.02293, 0.0228 ,\n",
       "            0.01935, 0.01385], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.48333332, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03076923, 0.04615385,\n",
       "            0.05384615, 0.06923077, 0.08461539, 0.1       , 0.10769231,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16923077, 0.17692308, 0.2       , 0.21538462, 0.22307692,\n",
       "            0.24615385, 0.25384617, 0.2769231 , 0.2923077 , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.44615385, 0.46153846, 0.47692308, 0.4846154 ,\n",
       "            0.5       , 0.5153846 , 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5846154 ,\n",
       "            0.5923077 , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.76153845,\n",
       "            0.77692306, 0.77692306, 0.7846154 , 0.8       , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.84615386, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.998  , 0.9976 , 0.996  , 0.9956 , 0.995  , 0.9946 ,\n",
       "            0.993  , 0.99   , 0.9897 , 0.9893 , 0.989  , 0.9883 , 0.9873 ,\n",
       "            0.987  , 0.9863 , 0.986  , 0.9844 , 0.983  , 0.982  , 0.981  ,\n",
       "            0.98   , 0.978  , 0.9775 , 0.9736 , 0.973  , 0.9727 , 0.9717 ,\n",
       "            0.971  , 0.9707 , 0.97   , 0.9688 , 0.9673 , 0.9663 , 0.966  ,\n",
       "            0.9653 , 0.965  , 0.9644 , 0.963  , 0.961  , 0.9604 , 0.958  ,\n",
       "            0.9575 , 0.957  , 0.9565 , 0.956  , 0.9556 , 0.955  , 0.9536 ,\n",
       "            0.952  , 0.9507 , 0.9497 , 0.9487 , 0.9478 , 0.945  , 0.942  ,\n",
       "            0.9414 , 0.941  , 0.94   , 0.9395 , 0.9385 , 0.938  , 0.9375 ,\n",
       "            0.9365 , 0.9355 , 0.9346 , 0.9307 , 0.928  , 0.9243 , 0.9233 ,\n",
       "            0.922  , 0.917  , 0.916  , 0.915  , 0.9146 , 0.914  , 0.911  ,\n",
       "            0.9097 , 0.9077 , 0.9014 , 0.899  , 0.897  , 0.881  , 0.879  ,\n",
       "            0.877  , 0.872  , 0.871  , 0.87   , 0.8677 , 0.8667 , 0.8613 ,\n",
       "            0.8594 , 0.8516 , 0.849  , 0.8486 , 0.8467 , 0.8438 , 0.836  ,\n",
       "            0.833  , 0.832  , 0.8213 , 0.8164 , 0.793  , 0.781  , 0.7705 ,\n",
       "            0.7656 , 0.7524 , 0.7505 , 0.744  , 0.737  , 0.7324 , 0.73   ,\n",
       "            0.729  , 0.721  , 0.716  , 0.709  , 0.708  , 0.705  , 0.692  ,\n",
       "            0.691  , 0.6904 , 0.6875 , 0.6685 , 0.6636 , 0.6626 , 0.662  ,\n",
       "            0.6567 , 0.654  , 0.6465 , 0.6426 , 0.612  , 0.6045 , 0.5996 ,\n",
       "            0.5947 , 0.5938 , 0.5913 , 0.586  , 0.5835 , 0.579  , 0.5674 ,\n",
       "            0.5522 , 0.5474 , 0.5464 , 0.546  , 0.538  , 0.5356 , 0.535  ,\n",
       "            0.5273 , 0.5234 , 0.5225 , 0.5146 , 0.5103 , 0.509  , 0.5083 ,\n",
       "            0.5054 , 0.4973 , 0.4949 , 0.4902 , 0.4824 , 0.4817 , 0.4749 ,\n",
       "            0.463  , 0.4524 , 0.4502 , 0.449  , 0.4448 , 0.4434 , 0.4373 ,\n",
       "            0.434  , 0.4255 , 0.424  , 0.395  , 0.3933 , 0.3657 , 0.3606 ,\n",
       "            0.3533 , 0.3513 , 0.348  , 0.3293 , 0.3037 , 0.2827 , 0.2798 ,\n",
       "            0.2568 , 0.2522 , 0.2335 , 0.2314 , 0.2224 , 0.2168 , 0.2098 ,\n",
       "            0.2089 , 0.202  , 0.1864 , 0.1748 , 0.1641 , 0.1587 , 0.1547 ,\n",
       "            0.1543 , 0.1497 , 0.1409 , 0.135  , 0.1239 , 0.1188 , 0.11755,\n",
       "            0.09827, 0.09436, 0.0865 , 0.0702 , 0.06525, 0.0619 , 0.03204,\n",
       "            0.02982, 0.0232 , 0.02194, 0.02174, 0.01848, 0.01312],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5416667, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05      , 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.075     , 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.10833333,\n",
       "            0.11666667, 0.125     , 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03846154, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.10769231,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.22307692, 0.23846154, 0.25384617, 0.2923077 , 0.3       ,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.42307693, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46923077, 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.5307692 , 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5846154 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.64615387, 0.65384614, 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.76153845,\n",
       "            0.76153845, 0.7692308 , 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9985 , 0.998  , 0.997  , 0.9966 , 0.996  , 0.9956 ,\n",
       "            0.995  , 0.9946 , 0.992  , 0.9917 , 0.991  , 0.9907 , 0.99   ,\n",
       "            0.9897 , 0.989  , 0.9883 , 0.988  , 0.9873 , 0.987  , 0.9863 ,\n",
       "            0.9854 , 0.985  , 0.983  , 0.9795 , 0.979  , 0.9785 , 0.9775 ,\n",
       "            0.977  , 0.9766 , 0.975  , 0.9746 , 0.9736 , 0.9727 , 0.9717 ,\n",
       "            0.971  , 0.9707 , 0.969  , 0.967  , 0.9663 , 0.966  , 0.965  ,\n",
       "            0.9644 , 0.964  , 0.9634 , 0.963  , 0.9624 , 0.9585 , 0.958  ,\n",
       "            0.9575 , 0.9556 , 0.9536 , 0.9526 , 0.9517 , 0.9507 , 0.95   ,\n",
       "            0.949  , 0.9487 , 0.948  , 0.9478 , 0.9473 , 0.9463 , 0.946  ,\n",
       "            0.9404 , 0.939  , 0.938  , 0.936  , 0.933  , 0.931  , 0.929  ,\n",
       "            0.9277 , 0.9272 , 0.927  , 0.9263 , 0.9233 , 0.9224 , 0.9204 ,\n",
       "            0.9185 , 0.9165 , 0.9136 , 0.911  , 0.9004 , 0.8984 , 0.897  ,\n",
       "            0.894  , 0.8936 , 0.8926 , 0.8887 , 0.8867 , 0.8853 , 0.8843 ,\n",
       "            0.884  , 0.883  , 0.8755 , 0.874  , 0.869  , 0.868  , 0.864  ,\n",
       "            0.861  , 0.857  , 0.8555 , 0.8525 , 0.846  , 0.845  , 0.8213 ,\n",
       "            0.8135 , 0.8003 , 0.7866 , 0.7773 , 0.777  , 0.7656 , 0.7637 ,\n",
       "            0.7617 , 0.7583 , 0.7563 , 0.7544 , 0.751  , 0.744  , 0.7427 ,\n",
       "            0.7397 , 0.7246 , 0.717  , 0.712  , 0.7095 , 0.698  , 0.6943 ,\n",
       "            0.689  , 0.6875 , 0.6846 , 0.684  , 0.681  , 0.668  , 0.6636 ,\n",
       "            0.6475 , 0.6333 , 0.6265 , 0.625  , 0.6177 , 0.6143 , 0.6074 ,\n",
       "            0.6064 , 0.6035 , 0.601  , 0.5835 , 0.576  , 0.57   , 0.569  ,\n",
       "            0.5654 , 0.5645 , 0.561  , 0.5483 , 0.548  , 0.5454 , 0.545  ,\n",
       "            0.5405 , 0.54   , 0.528  , 0.5264 , 0.517  , 0.5137 , 0.5117 ,\n",
       "            0.506  , 0.501  , 0.5005 , 0.4854 , 0.473  , 0.4712 , 0.461  ,\n",
       "            0.4573 , 0.4553 , 0.4473 , 0.4385 , 0.4255 , 0.4038 , 0.3728 ,\n",
       "            0.3674 , 0.362  , 0.3608 , 0.3577 , 0.3372 , 0.3086 , 0.2888 ,\n",
       "            0.2852 , 0.262  , 0.255  , 0.236  , 0.2343 , 0.2235 , 0.218  ,\n",
       "            0.2108 , 0.2095 , 0.2029 , 0.1869 , 0.1754 , 0.1644 , 0.158  ,\n",
       "            0.1536 , 0.1534 , 0.1484 , 0.1401 , 0.1337 , 0.1222 , 0.11694,\n",
       "            0.11597, 0.0962 , 0.09204, 0.08417, 0.0678 , 0.0627 , 0.05966,\n",
       "            0.02998, 0.0278 , 0.02148, 0.02025, 0.02007, 0.01698, 0.01196],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.575, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.075     ,\n",
       "            0.075     , 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.11666667, 0.11666667, 0.125     , 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03076923, 0.05384615,\n",
       "            0.06923077, 0.08461539, 0.10769231, 0.12307692, 0.13846155,\n",
       "            0.14615385, 0.16153847, 0.17692308, 0.2       , 0.21538462,\n",
       "            0.22307692, 0.23846154, 0.24615385, 0.25384617, 0.2846154 ,\n",
       "            0.2923077 , 0.30769232, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36923078, 0.37692308, 0.4       , 0.4076923 ,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.46153846, 0.46923077,\n",
       "            0.4846154 , 0.4923077 , 0.50769234, 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.5538462 , 0.5692308 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.61538464, 0.63076925, 0.63846153, 0.65384614,\n",
       "            0.66923076, 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.73846155, 0.75384617, 0.76153845,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.85384613, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.999  , 0.9985 , 0.998  , 0.9976 , 0.997  , 0.996  ,\n",
       "            0.994  , 0.9937 , 0.993  , 0.9927 , 0.992  , 0.9917 , 0.9907 ,\n",
       "            0.9897 , 0.9893 , 0.989  , 0.9883 , 0.988  , 0.987  , 0.9863 ,\n",
       "            0.984  , 0.983  , 0.9824 , 0.9814 , 0.981  , 0.98   , 0.979  ,\n",
       "            0.9775 , 0.9766 , 0.9756 , 0.975  , 0.974  , 0.9727 , 0.972  ,\n",
       "            0.9717 , 0.971  , 0.9707 , 0.97   , 0.9697 , 0.9673 , 0.9663 ,\n",
       "            0.9644 , 0.963  , 0.9624 , 0.9614 , 0.9604 , 0.959  , 0.9585 ,\n",
       "            0.958  , 0.9575 , 0.9565 , 0.956  , 0.9556 , 0.9517 , 0.95   ,\n",
       "            0.9497 , 0.946  , 0.9434 , 0.9424 , 0.942  , 0.94   , 0.939  ,\n",
       "            0.935  , 0.9346 , 0.933  , 0.9297 , 0.9253 , 0.921  , 0.918  ,\n",
       "            0.914  , 0.911  , 0.9077 , 0.9053 , 0.905  , 0.903  , 0.902  ,\n",
       "            0.895  , 0.894  , 0.887  , 0.884  , 0.881  , 0.8794 , 0.874  ,\n",
       "            0.8687 , 0.868  , 0.848  , 0.8447 , 0.829  , 0.8135 , 0.804  ,\n",
       "            0.8027 , 0.7983 , 0.795  , 0.792  , 0.791  , 0.79   , 0.787  ,\n",
       "            0.78   , 0.778  , 0.776  , 0.7593 , 0.753  , 0.747  , 0.7363 ,\n",
       "            0.735  , 0.7314 , 0.73   , 0.7246 , 0.724  , 0.7114 , 0.6953 ,\n",
       "            0.6865 , 0.6816 , 0.677  , 0.6704 , 0.6616 , 0.6567 , 0.643  ,\n",
       "            0.6387 , 0.6313 , 0.629  , 0.625  , 0.62   , 0.618  , 0.6094 ,\n",
       "            0.6084 , 0.6064 , 0.604  , 0.592  , 0.588  , 0.587  , 0.5845 ,\n",
       "            0.581  , 0.5806 , 0.5796 , 0.5776 , 0.566  , 0.559  , 0.547  ,\n",
       "            0.5464 , 0.546  , 0.542  , 0.53   , 0.525  , 0.5176 , 0.513  ,\n",
       "            0.5063 , 0.5005 , 0.4907 , 0.483  , 0.4727 , 0.4702 , 0.4695 ,\n",
       "            0.45   , 0.4119 , 0.387  , 0.3806 , 0.372  , 0.3682 , 0.3618 ,\n",
       "            0.3445 , 0.3184 , 0.2905 , 0.2874 , 0.2703 , 0.2627 , 0.2391 ,\n",
       "            0.2386 , 0.2289 , 0.223  , 0.215  , 0.214  , 0.2042 , 0.187  ,\n",
       "            0.1775 , 0.1664 , 0.1562 , 0.1544 , 0.1527 , 0.15   , 0.1376 ,\n",
       "            0.1312 , 0.1196 , 0.1152 , 0.11475, 0.1138 , 0.09534, 0.0898 ,\n",
       "            0.08167, 0.06647, 0.06085, 0.05634, 0.02774, 0.0258 , 0.01999,\n",
       "            0.0188 , 0.01837, 0.01572, 0.0109 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.59166664, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.04166667, 0.05      ,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.075     , 0.075     ,\n",
       "            0.075     , 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.24166666, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03846154, 0.05384615,\n",
       "            0.06923077, 0.08461539, 0.1       , 0.12307692, 0.13846155,\n",
       "            0.14615385, 0.16923077, 0.17692308, 0.2       , 0.22307692,\n",
       "            0.23076923, 0.24615385, 0.25384617, 0.2769231 , 0.2923077 ,\n",
       "            0.30769232, 0.33076924, 0.33846155, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3923077 , 0.4       , 0.41538462,\n",
       "            0.43076923, 0.43846154, 0.43846154, 0.46153846, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.63846153,\n",
       "            0.65384614, 0.66923076, 0.6769231 , 0.6846154 , 0.7       ,\n",
       "            0.7076923 , 0.72307694, 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9995 , 0.999  , 0.9985 , 0.998  , 0.9976 , 0.997  ,\n",
       "            0.9956 , 0.995  , 0.9946 , 0.994  , 0.9937 , 0.993  , 0.9927 ,\n",
       "            0.9917 , 0.991  , 0.9907 , 0.99   , 0.9897 , 0.9893 , 0.9873 ,\n",
       "            0.9863 , 0.986  , 0.985  , 0.9844 , 0.984  , 0.983  , 0.982  ,\n",
       "            0.9814 , 0.9805 , 0.98   , 0.979  , 0.9785 , 0.9775 , 0.977  ,\n",
       "            0.9766 , 0.976  , 0.9756 , 0.975  , 0.9727 , 0.972  , 0.9707 ,\n",
       "            0.97   , 0.969  , 0.9688 , 0.968  , 0.9673 , 0.967  , 0.966  ,\n",
       "            0.9653 , 0.965  , 0.9644 , 0.964  , 0.9634 , 0.963  , 0.959  ,\n",
       "            0.9575 , 0.954  , 0.9526 , 0.952  , 0.9517 , 0.9487 , 0.9478 ,\n",
       "            0.9443 , 0.944  , 0.9434 , 0.9424 , 0.9395 , 0.9355 , 0.931  ,\n",
       "            0.93   , 0.9277 , 0.926  , 0.9253 , 0.9243 , 0.923  , 0.921  ,\n",
       "            0.919  , 0.918  , 0.915  , 0.9146 , 0.911  , 0.9087 , 0.901  ,\n",
       "            0.8975 , 0.897  , 0.8955 , 0.895  , 0.8926 , 0.8843 , 0.8833 ,\n",
       "            0.867  , 0.866  , 0.849  , 0.8364 , 0.829  , 0.8228 , 0.8213 ,\n",
       "            0.82   , 0.818  , 0.8154 , 0.813  , 0.812  , 0.8105 , 0.804  ,\n",
       "            0.8027 , 0.8003 , 0.783  , 0.777  , 0.7705 , 0.762  , 0.7607 ,\n",
       "            0.759  , 0.752  , 0.7305 , 0.7144 , 0.714  , 0.707  , 0.6987 ,\n",
       "            0.69   , 0.6875 , 0.6646 , 0.6597 , 0.65   , 0.648  , 0.6475 ,\n",
       "            0.6426 , 0.641  , 0.6367 , 0.634  , 0.6333 , 0.633  , 0.622  ,\n",
       "            0.617  , 0.6157 , 0.61   , 0.6084 , 0.604  , 0.595  , 0.5933 ,\n",
       "            0.5923 , 0.588  , 0.578  , 0.5757 , 0.5693 , 0.556  , 0.552  ,\n",
       "            0.5435 , 0.5396 , 0.5312 , 0.531  , 0.5273 , 0.516  , 0.508  ,\n",
       "            0.4983 , 0.4841 , 0.4817 , 0.4607 , 0.42   , 0.396  , 0.389  ,\n",
       "            0.3796 , 0.3752 , 0.371  , 0.3503 , 0.324  , 0.2966 , 0.292  ,\n",
       "            0.2756 , 0.2668 , 0.2405 , 0.2314 , 0.2252 , 0.217  , 0.2158 ,\n",
       "            0.2035 , 0.1864 , 0.1775 , 0.1664 , 0.1549 , 0.1538 , 0.151  ,\n",
       "            0.15   , 0.1367 , 0.1295 , 0.11755, 0.1128 , 0.112  , 0.0939 ,\n",
       "            0.0873 , 0.0792 , 0.06476, 0.05865, 0.0548 , 0.026  , 0.02414,\n",
       "            0.01862, 0.01752, 0.01698, 0.01456, 0.01001], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6166667, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.06666667, 0.075     , 0.075     , 0.075     , 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.14166667, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.375     , 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01538462, 0.04615385, 0.06923077, 0.08461539,\n",
       "            0.1       , 0.12307692, 0.13846155, 0.16923077, 0.17692308,\n",
       "            0.2       , 0.20769231, 0.23076923, 0.24615385, 0.26923078,\n",
       "            0.2846154 , 0.2923077 , 0.30769232, 0.31538463, 0.33076924,\n",
       "            0.33846155, 0.36153847, 0.37692308, 0.3846154 , 0.4076923 ,\n",
       "            0.41538462, 0.43846154, 0.44615385, 0.46923077, 0.4846154 ,\n",
       "            0.5       , 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5769231 , 0.5923077 ,\n",
       "            0.6       , 0.61538464, 0.65384614, 0.6615385 , 0.6769231 ,\n",
       "            0.6846154 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9995  , 0.999   , 0.9985  , 0.998   , 0.997   ,\n",
       "            0.9966  , 0.996   , 0.9956  , 0.995   , 0.9946  , 0.994   ,\n",
       "            0.9937  , 0.993   , 0.9927  , 0.992   , 0.9917  , 0.9907  ,\n",
       "            0.99    , 0.9897  , 0.9893  , 0.9883  , 0.9873  , 0.987   ,\n",
       "            0.9863  , 0.9854  , 0.985   , 0.984   , 0.983   , 0.9824  ,\n",
       "            0.982   , 0.9814  , 0.981   , 0.9805  , 0.9795  , 0.979   ,\n",
       "            0.9785  , 0.9775  , 0.977   , 0.9766  , 0.976   , 0.975   ,\n",
       "            0.973   , 0.9727  , 0.972   , 0.971   , 0.9707  , 0.9683  ,\n",
       "            0.968   , 0.967   , 0.965   , 0.9644  , 0.9634  , 0.963   ,\n",
       "            0.9604  , 0.959   , 0.9565  , 0.956   , 0.9556  , 0.9536  ,\n",
       "            0.953   , 0.951   , 0.9478  , 0.9473  , 0.9463  , 0.9434  ,\n",
       "            0.942   , 0.941   , 0.9395  , 0.939   , 0.9385  , 0.938   ,\n",
       "            0.9375  , 0.935   , 0.933   , 0.931   , 0.9287  , 0.927   ,\n",
       "            0.923   , 0.9214  , 0.918   , 0.9175  , 0.914   , 0.9067  ,\n",
       "            0.902   , 0.9004  , 0.896   , 0.881   , 0.878   , 0.8765  ,\n",
       "            0.8687  , 0.8564  , 0.8545  , 0.8496  , 0.8467  , 0.8447  ,\n",
       "            0.844   , 0.843   , 0.842   , 0.825   , 0.82    , 0.817   ,\n",
       "            0.813   , 0.812   , 0.811   , 0.8096  , 0.808   , 0.8027  ,\n",
       "            0.7837  , 0.766   , 0.7656  , 0.762   , 0.76    , 0.759   ,\n",
       "            0.75    , 0.7495  , 0.73    , 0.717   , 0.713   , 0.697   ,\n",
       "            0.6943  , 0.693   , 0.6914  , 0.6875  , 0.687   , 0.6855  ,\n",
       "            0.681   , 0.68    , 0.6753  , 0.669   , 0.6655  , 0.654   ,\n",
       "            0.653   , 0.6523  , 0.651   , 0.6504  , 0.6265  , 0.6235  ,\n",
       "            0.6206  , 0.615   , 0.6123  , 0.603   , 0.598   , 0.5894  ,\n",
       "            0.5835  , 0.581   , 0.577   , 0.5737  , 0.5605  , 0.5166  ,\n",
       "            0.513   , 0.49    , 0.4463  , 0.4219  , 0.4163  , 0.4082  ,\n",
       "            0.399   , 0.3936  , 0.3743  , 0.3486  , 0.3142  , 0.31    ,\n",
       "            0.3     , 0.2837  , 0.2595  , 0.2583  , 0.247   , 0.2405  ,\n",
       "            0.2323  , 0.2301  , 0.2172  , 0.1979  , 0.1906  , 0.1788  ,\n",
       "            0.1638  , 0.1632  , 0.1598  , 0.1581  , 0.1431  , 0.1356  ,\n",
       "            0.12286 , 0.1193  , 0.1184  , 0.1166  , 0.09845 , 0.0909  ,\n",
       "            0.0821  , 0.06696 , 0.06076 , 0.0556  , 0.0258  , 0.02396 ,\n",
       "            0.01843 , 0.0173  , 0.01666 , 0.014336, 0.009674], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05833333, 0.06666667, 0.075     , 0.075     ,\n",
       "            0.075     , 0.075     , 0.08333334, 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.16666667, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.25      , 0.25833333,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01538462, 0.05384615, 0.07692308, 0.08461539,\n",
       "            0.1       , 0.13846155, 0.15384616, 0.17692308, 0.2       ,\n",
       "            0.20769231, 0.23076923, 0.26153848, 0.2769231 , 0.2923077 ,\n",
       "            0.3       , 0.31538463, 0.33076924, 0.33846155, 0.35384616,\n",
       "            0.36153847, 0.3846154 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.4846154 , 0.4923077 ,\n",
       "            0.50769234, 0.5153846 , 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.64615387, 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.7       , 0.7153846 , 0.72307694, 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7923077 , 0.8       , 0.8       , 0.8076923 , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.9307692 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9995 , 0.999  , 0.9985 , 0.998  , 0.9976 , 0.997  ,\n",
       "            0.9966 , 0.996  , 0.9956 , 0.995  , 0.9946 , 0.994  , 0.9937 ,\n",
       "            0.993  , 0.9927 , 0.992  , 0.991  , 0.9907 , 0.99   , 0.9897 ,\n",
       "            0.9893 , 0.989  , 0.9883 , 0.988  , 0.9873 , 0.987  , 0.986  ,\n",
       "            0.9854 , 0.985  , 0.9844 , 0.984  , 0.9834 , 0.983  , 0.982  ,\n",
       "            0.9814 , 0.981  , 0.9805 , 0.98   , 0.979  , 0.9785 , 0.9775 ,\n",
       "            0.977  , 0.9766 , 0.976  , 0.975  , 0.9746 , 0.9727 , 0.9717 ,\n",
       "            0.9707 , 0.969  , 0.9688 , 0.968  , 0.9663 , 0.965  , 0.963  ,\n",
       "            0.961  , 0.9595 , 0.9585 , 0.9575 , 0.957  , 0.9546 , 0.954  ,\n",
       "            0.951  , 0.9507 , 0.9497 , 0.949  , 0.9487 , 0.9478 , 0.947  ,\n",
       "            0.9463 , 0.9443 , 0.9424 , 0.94   , 0.9395 , 0.939  , 0.9365 ,\n",
       "            0.93   , 0.9287 , 0.927  , 0.9243 , 0.919  , 0.918  , 0.9126 ,\n",
       "            0.911  , 0.903  , 0.9014 , 0.8984 , 0.8955 , 0.8794 , 0.8784 ,\n",
       "            0.878  , 0.8774 , 0.87   , 0.8677 , 0.867  , 0.865  , 0.86   ,\n",
       "            0.853  , 0.849  , 0.846  , 0.8423 , 0.842  , 0.8374 , 0.833  ,\n",
       "            0.8047 , 0.8013 , 0.7993 , 0.7964 , 0.7896 , 0.7812 , 0.7734 ,\n",
       "            0.752  , 0.7515 , 0.749  , 0.737  , 0.735  , 0.7305 , 0.729  ,\n",
       "            0.723  , 0.722  , 0.7217 , 0.716  , 0.7114 , 0.708  , 0.7075 ,\n",
       "            0.7046 , 0.7036 , 0.6987 , 0.6978 , 0.6943 , 0.6875 , 0.6855 ,\n",
       "            0.6665 , 0.6606 , 0.659  , 0.656  , 0.6514 , 0.65   , 0.649  ,\n",
       "            0.6455 , 0.6357 , 0.6323 , 0.6147 , 0.6025 , 0.586  , 0.545  ,\n",
       "            0.538  , 0.515  , 0.4712 , 0.4495 , 0.443  , 0.4333 , 0.4226 ,\n",
       "            0.4185 , 0.3967 , 0.3726 , 0.3362 , 0.3313 , 0.3235 , 0.306  ,\n",
       "            0.2805 , 0.2776 , 0.266  , 0.259  , 0.2502 , 0.2482 , 0.2338 ,\n",
       "            0.2128 , 0.2059 , 0.1937 , 0.1772 , 0.1754 , 0.172  , 0.1714 ,\n",
       "            0.1543 , 0.146  , 0.1323 , 0.1289 , 0.1274 , 0.1254 , 0.1063 ,\n",
       "            0.0979 , 0.0883 , 0.0724 , 0.0656 , 0.0601 , 0.02763, 0.02562,\n",
       "            0.01968, 0.01848, 0.01778, 0.01525, 0.01025], dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.09701493, 0.10447761, 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.1641791 ,\n",
       "            0.17910448, 0.18656716, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.31343284, 0.32089552,\n",
       "            0.32089552, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.54477614, 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5597015 , 0.5597015 , 0.5597015 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.57462686, 0.58208954, 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5970149 , 0.5970149 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.6119403 , 0.6119403 , 0.6119403 , 0.6119403 , 0.6119403 ,\n",
       "            0.619403  , 0.619403  , 0.619403  , 0.619403  , 0.6268657 ,\n",
       "            0.6268657 , 0.6268657 , 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6567164 , 0.6567164 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.67164177, 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.69402987, 0.70149255, 0.70149255, 0.7089552 , 0.7089552 ,\n",
       "            0.7164179 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.7910448 , 0.79850745, 0.80597013, 0.80597013,\n",
       "            0.8134328 , 0.8134328 , 0.8208955 , 0.82835823, 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.8731343 ,\n",
       "            0.8731343 , 0.880597  , 0.880597  , 0.8880597 , 0.8880597 ,\n",
       "            0.8880597 , 0.8955224 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.92537314, 0.9328358 , 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.9477612 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00862069, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.03448276, 0.03448276, 0.03448276, 0.03448276,\n",
       "            0.03448276, 0.04310345, 0.06034483, 0.06034483, 0.06034483,\n",
       "            0.06896552, 0.0775862 , 0.0862069 , 0.09482758, 0.09482758,\n",
       "            0.10344828, 0.10344828, 0.11206897, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.18965517, 0.19827586, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.5086207 , 0.51724136, 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5862069 , 0.5948276 , 0.6034483 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62068963, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.63793105, 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.69827586, 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.7586207 , 0.76724136, 0.7758621 , 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.79310346, 0.79310346, 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.8189655 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8362069 , 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.86206895, 0.86206895, 0.86206895, 0.86206895, 0.86206895,\n",
       "            0.86206895, 0.86206895, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4675, 0.4668, 0.4666, 0.466 , 0.4648, 0.4639, 0.4634,\n",
       "            0.4622, 0.462 , 0.4614, 0.4602, 0.4587, 0.4575, 0.457 , 0.4568,\n",
       "            0.4565, 0.456 , 0.4558, 0.4556, 0.455 , 0.4548, 0.4546, 0.4524,\n",
       "            0.4514, 0.451 , 0.45  , 0.4492, 0.4485, 0.448 , 0.4473, 0.446 ,\n",
       "            0.4412, 0.4377, 0.4375, 0.4358, 0.4353, 0.4336, 0.433 , 0.4326,\n",
       "            0.4297, 0.429 , 0.425 , 0.423 , 0.4224, 0.416 , 0.4133, 0.4106,\n",
       "            0.4104, 0.4087, 0.4084, 0.4082, 0.408 , 0.4072, 0.4016, 0.401 ,\n",
       "            0.4004, 0.3977, 0.3958, 0.391 , 0.3896, 0.3882, 0.3853, 0.3845,\n",
       "            0.3835, 0.3833, 0.3828, 0.3816, 0.377 , 0.376 , 0.375 , 0.3735,\n",
       "            0.3726, 0.3706, 0.37  , 0.3645, 0.364 , 0.3635, 0.3628, 0.362 ,\n",
       "            0.3604, 0.359 , 0.3586, 0.357 , 0.3552, 0.355 , 0.354 , 0.3523,\n",
       "            0.3494, 0.3467, 0.3462, 0.3442, 0.3433, 0.3428, 0.3423, 0.3413,\n",
       "            0.3374, 0.3367, 0.3357, 0.3354, 0.3342, 0.3337, 0.333 , 0.332 ,\n",
       "            0.3308, 0.3281, 0.328 , 0.3262, 0.3254, 0.3228, 0.321 , 0.3147,\n",
       "            0.3137, 0.311 , 0.3098, 0.3086, 0.3074, 0.3054, 0.3052, 0.305 ,\n",
       "            0.3044, 0.3018, 0.2993, 0.2935, 0.2908, 0.2893, 0.2869, 0.2856,\n",
       "            0.2786, 0.2766, 0.276 , 0.2756, 0.2722, 0.2717, 0.2693, 0.2683,\n",
       "            0.268 , 0.2646, 0.2637, 0.2632, 0.2612, 0.2593, 0.258 , 0.2546,\n",
       "            0.2534, 0.2532, 0.2522, 0.2515, 0.2512, 0.2505, 0.2502, 0.2477,\n",
       "            0.2462, 0.246 , 0.2455, 0.2452, 0.2438, 0.243 , 0.2429, 0.2402,\n",
       "            0.2399, 0.2394, 0.2386, 0.2379, 0.2363, 0.2358, 0.2352, 0.2339,\n",
       "            0.2338, 0.2322, 0.2313, 0.2302, 0.2297, 0.2294, 0.2289, 0.2277,\n",
       "            0.2274, 0.2251, 0.2224, 0.2217, 0.2213, 0.2212, 0.2205, 0.2194,\n",
       "            0.2191, 0.2185, 0.2166, 0.2148, 0.2144, 0.2142, 0.2125, 0.2123,\n",
       "            0.2119, 0.2118, 0.2106, 0.2096, 0.209 , 0.2075, 0.2037, 0.2028,\n",
       "            0.2024, 0.1996, 0.1989, 0.1971, 0.1962, 0.1958, 0.1952, 0.195 ,\n",
       "            0.193 , 0.1915, 0.1893, 0.1891, 0.1882, 0.1846, 0.1836, 0.1833,\n",
       "            0.1819, 0.1779, 0.1764, 0.1704, 0.1674, 0.1633, 0.1602, 0.1561,\n",
       "            0.15  , 0.1471, 0.147 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14925373, 0.1641791 , 0.17910448,\n",
       "            0.19402985, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35074627, 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5       , 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5597015 , 0.5597015 , 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5597015 , 0.5597015 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.57462686, 0.57462686, 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5970149 , 0.5970149 , 0.5970149 , 0.5970149 ,\n",
       "            0.5970149 , 0.5970149 , 0.6044776 , 0.6119403 , 0.6119403 ,\n",
       "            0.619403  , 0.619403  , 0.6268657 , 0.63432837, 0.63432837,\n",
       "            0.63432837, 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.7238806 , 0.7238806 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.8208955 , 0.8208955 ,\n",
       "            0.82835823, 0.82835823, 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8880597 , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.91791046, 0.92537314,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00862069, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.02586207, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.04310345, 0.05172414,\n",
       "            0.06034483, 0.06034483, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0775862 , 0.0862069 , 0.09482758, 0.10344828, 0.11206897,\n",
       "            0.12068965, 0.12068965, 0.13793103, 0.14655173, 0.1637931 ,\n",
       "            0.1724138 , 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.28448275,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.51724136, 0.5258621 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.6896552 , 0.69827586, 0.69827586, 0.69827586, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8103448 , 0.8103448 , 0.82758623,\n",
       "            0.82758623, 0.8362069 , 0.8362069 , 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.86206895, 0.86206895, 0.86206895,\n",
       "            0.86206895, 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.87931037, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4473 , 0.446  , 0.4456 , 0.4436 , 0.4429 , 0.4426 ,\n",
       "            0.4417 , 0.4412 , 0.4397 , 0.438  , 0.4373 , 0.437  , 0.4358 ,\n",
       "            0.4353 , 0.4338 , 0.4336 , 0.4333 , 0.4329 , 0.4326 , 0.4316 ,\n",
       "            0.4304 , 0.4287 , 0.4277 , 0.4268 , 0.4265 , 0.4255 , 0.425  ,\n",
       "            0.4219 , 0.4211 , 0.421  , 0.4202 , 0.4182 , 0.4126 , 0.4119 ,\n",
       "            0.411  , 0.4087 , 0.406  , 0.4055 , 0.4053 , 0.403  , 0.4028 ,\n",
       "            0.4026 , 0.3984 , 0.3982 , 0.395  , 0.3906 , 0.385  , 0.3848 ,\n",
       "            0.38   , 0.3792 , 0.3787 , 0.3782 , 0.3777 , 0.371  , 0.37   ,\n",
       "            0.3699 , 0.3613 , 0.3606 , 0.3599 , 0.3586 , 0.3557 , 0.3538 ,\n",
       "            0.35   , 0.3486 , 0.3481 , 0.345  , 0.3447 , 0.3423 , 0.3413 ,\n",
       "            0.3362 , 0.3335 , 0.3313 , 0.3308 , 0.3298 , 0.3296 , 0.327  ,\n",
       "            0.3198 , 0.318  , 0.3167 , 0.3162 , 0.313  , 0.3115 , 0.311  ,\n",
       "            0.309  , 0.306  , 0.3057 , 0.305  , 0.3032 , 0.3025 , 0.3013 ,\n",
       "            0.2998 , 0.297  , 0.2969 , 0.296  , 0.2954 , 0.2922 , 0.2908 ,\n",
       "            0.2878 , 0.2864 , 0.2847 , 0.2837 , 0.2822 , 0.2817 , 0.2812 ,\n",
       "            0.281  , 0.2805 , 0.2778 , 0.2747 , 0.2742 , 0.273  , 0.2727 ,\n",
       "            0.272  , 0.2678 , 0.2676 , 0.2673 , 0.2656 , 0.2615 , 0.2595 ,\n",
       "            0.2556 , 0.255  , 0.2534 , 0.2477 , 0.247  , 0.2463 , 0.2456 ,\n",
       "            0.2406 , 0.2405 , 0.239  , 0.2384 , 0.235  , 0.2274 , 0.2273 ,\n",
       "            0.2272 , 0.2264 , 0.2263 , 0.2246 , 0.2235 , 0.2234 , 0.2207 ,\n",
       "            0.2203 , 0.22   , 0.2157 , 0.2156 , 0.2137 , 0.2134 , 0.2113 ,\n",
       "            0.2094 , 0.2091 , 0.2076 , 0.2069 , 0.2065 , 0.2056 , 0.2029 ,\n",
       "            0.2023 , 0.2012 , 0.1998 , 0.1989 , 0.1959 , 0.1953 , 0.1937 ,\n",
       "            0.1936 , 0.1912 , 0.1898 , 0.1887 , 0.1866 , 0.1841 , 0.1831 ,\n",
       "            0.183  , 0.1826 , 0.1823 , 0.1804 , 0.1797 , 0.1796 , 0.1771 ,\n",
       "            0.1765 , 0.1761 , 0.1755 , 0.1753 , 0.1744 , 0.1727 , 0.1726 ,\n",
       "            0.172  , 0.1719 , 0.1715 , 0.1714 , 0.1685 , 0.1656 , 0.1652 ,\n",
       "            0.1643 , 0.164  , 0.1633 , 0.1615 , 0.1614 , 0.1593 , 0.1588 ,\n",
       "            0.1573 , 0.1566 , 0.1564 , 0.1559 , 0.1554 , 0.1548 , 0.1539 ,\n",
       "            0.153  , 0.1497 , 0.1488 , 0.147  , 0.1466 , 0.1462 , 0.1461 ,\n",
       "            0.1453 , 0.1451 , 0.1447 , 0.1417 , 0.1416 , 0.1384 , 0.1375 ,\n",
       "            0.137  , 0.1367 , 0.136  , 0.1355 , 0.134  , 0.1292 , 0.1279 ,\n",
       "            0.1235 , 0.11676, 0.11536, 0.1093 , 0.10376, 0.0995 , 0.0986 ,\n",
       "            0.09705], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.36567163, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5597015 , 0.5597015 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.58208954, 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.619403  , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.63432837, 0.63432837, 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.73880595, 0.73880595, 0.74626863, 0.75373137, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.8208955 ,\n",
       "            0.8208955 , 0.82835823, 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00862069, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.04310345, 0.05172414,\n",
       "            0.06034483, 0.06034483, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.11206897,\n",
       "            0.12068965, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.20689656, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.6896552 , 0.69827586, 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.82758623, 0.8362069 , 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.427  , 0.4255 , 0.425  , 0.4246 , 0.4233 , 0.4216 ,\n",
       "            0.421  , 0.4204 , 0.4177 , 0.4158 , 0.4155 , 0.4153 , 0.4143 ,\n",
       "            0.4138 , 0.4136 , 0.412  , 0.4114 , 0.411  , 0.4104 , 0.41   ,\n",
       "            0.409  , 0.4087 , 0.4084 , 0.4082 , 0.4058 , 0.405  , 0.4045 ,\n",
       "            0.4038 , 0.4026 , 0.402  , 0.4    , 0.3965 , 0.3958 , 0.395  ,\n",
       "            0.3948 , 0.3936 , 0.3875 , 0.386  , 0.3853 , 0.3843 , 0.382  ,\n",
       "            0.3787 , 0.3774 , 0.3765 , 0.3743 , 0.3735 , 0.3733 , 0.371  ,\n",
       "            0.3677 , 0.366  , 0.3599 , 0.3596 , 0.3523 , 0.3506 , 0.35   ,\n",
       "            0.3481 , 0.345  , 0.3396 , 0.3386 , 0.3367 , 0.3276 , 0.3262 ,\n",
       "            0.3257 , 0.3247 , 0.3242 , 0.3208 , 0.3203 , 0.3142 , 0.3113 ,\n",
       "            0.309  , 0.3079 , 0.3054 , 0.3047 , 0.3037 , 0.2983 , 0.2974 ,\n",
       "            0.2932 , 0.2925 , 0.2915 , 0.2908 , 0.29   , 0.2898 , 0.2874 ,\n",
       "            0.287  , 0.281  , 0.277  , 0.2766 , 0.275  , 0.2708 , 0.2703 ,\n",
       "            0.2695 , 0.269  , 0.2668 , 0.265  , 0.2637 , 0.263  , 0.2627 ,\n",
       "            0.2622 , 0.2603 , 0.2588 , 0.2573 , 0.253  , 0.2515 , 0.249  ,\n",
       "            0.248  , 0.2422 , 0.2417 , 0.2413 , 0.2386 , 0.2367 , 0.2363 ,\n",
       "            0.236  , 0.2352 , 0.2351 , 0.234  , 0.2339 , 0.2332 , 0.2289 ,\n",
       "            0.228  , 0.2264 , 0.2229 , 0.2222 , 0.2198 , 0.2194 , 0.2156 ,\n",
       "            0.2108 , 0.2085 , 0.2075 , 0.2073 , 0.207  , 0.2069 , 0.2068 ,\n",
       "            0.2054 , 0.2042 , 0.2001 , 0.1987 , 0.1947 , 0.1942 , 0.1941 ,\n",
       "            0.1937 , 0.1927 , 0.1903 , 0.19   , 0.1893 , 0.1869 , 0.1855 ,\n",
       "            0.181  , 0.1807 , 0.1805 , 0.1798 , 0.1775 , 0.1766 , 0.1757 ,\n",
       "            0.1752 , 0.1736 , 0.1727 , 0.1724 , 0.1703 , 0.1682 , 0.1669 ,\n",
       "            0.1658 , 0.1656 , 0.1652 , 0.161  , 0.1586 , 0.1584 , 0.1575 ,\n",
       "            0.1552 , 0.154  , 0.1486 , 0.148  , 0.1477 , 0.1469 , 0.1459 ,\n",
       "            0.1454 , 0.1451 , 0.1426 , 0.14   , 0.1399 , 0.1393 , 0.1377 ,\n",
       "            0.1371 , 0.1357 , 0.1339 , 0.1337 , 0.1327 , 0.1326 , 0.1324 ,\n",
       "            0.1312 , 0.1305 , 0.1298 , 0.1289 , 0.1279 , 0.1272 , 0.1261 ,\n",
       "            0.1241 , 0.1219 , 0.12177, 0.1216 , 0.121  , 0.12054, 0.1201 ,\n",
       "            0.1193 , 0.1178 , 0.11755, 0.1166 , 0.1152 , 0.11456, 0.1142 ,\n",
       "            0.1138 , 0.1099 , 0.1086 , 0.1063 , 0.1054 , 0.10486, 0.1047 ,\n",
       "            0.1036 , 0.1032 , 0.1023 , 0.1019 , 0.10144, 0.1007 , 0.0964 ,\n",
       "            0.0959 , 0.09503, 0.0927 , 0.0925 , 0.0898 , 0.0871 , 0.07825,\n",
       "            0.0778 , 0.07306, 0.0673 , 0.066  , 0.06323, 0.06256],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.19402985, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.36567163, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.4402985 , 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.54477614,\n",
       "            0.54477614, 0.54477614, 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5597015 , 0.5597015 , 0.5597015 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6119403 , 0.6268657 ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7164179 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.73880595, 0.75373137,\n",
       "            0.75373137, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8134328 , 0.8208955 , 0.8208955 , 0.82835823, 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.8880597 , 0.8955224 , 0.9029851 , 0.9029851 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.96268654, 0.9701493 , 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00862069, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.03448276, 0.03448276, 0.03448276,\n",
       "            0.04310345, 0.04310345, 0.05172414, 0.06034483, 0.06034483,\n",
       "            0.06896552, 0.06896552, 0.0775862 , 0.0862069 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.21551724, 0.22413793, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.4224138 , 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.54310346, 0.55172414, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.5689655 , 0.57758623, 0.5948276 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.79310346, 0.8103448 ,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.407  , 0.4053 , 0.405  , 0.4043 , 0.4036 , 0.4011 ,\n",
       "            0.4004 , 0.4001 , 0.3997 , 0.3962 , 0.3943 , 0.3938 , 0.3936 ,\n",
       "            0.393  , 0.3923 , 0.392  , 0.3906 , 0.39   , 0.3896 , 0.3894 ,\n",
       "            0.3882 , 0.388  , 0.3875 , 0.3855 , 0.3853 , 0.3826 , 0.3823 ,\n",
       "            0.3816 , 0.3809 , 0.3796 , 0.379  , 0.3755 , 0.3728 , 0.372  ,\n",
       "            0.3713 , 0.3699 , 0.3684 , 0.3635 , 0.3633 , 0.3616 , 0.361  ,\n",
       "            0.3599 , 0.3591 , 0.3528 , 0.3518 , 0.3516 , 0.3513 , 0.3477 ,\n",
       "            0.3464 , 0.3452 , 0.343  , 0.3418 , 0.3362 , 0.3354 , 0.3262 ,\n",
       "            0.3232 , 0.3228 , 0.32   , 0.3164 , 0.3108 , 0.309  , 0.3076 ,\n",
       "            0.3005 , 0.2966 , 0.2954 , 0.295  , 0.2942 , 0.294  , 0.289  ,\n",
       "            0.2837 , 0.283  , 0.278  , 0.2766 , 0.276  , 0.2751 , 0.274  ,\n",
       "            0.2732 , 0.2673 , 0.2646 , 0.261  , 0.2593 , 0.2583 , 0.2563 ,\n",
       "            0.2554 , 0.2551 , 0.2546 , 0.2542 , 0.2522 , 0.2466 , 0.2434 ,\n",
       "            0.2426 , 0.2411 , 0.2407 , 0.2395 , 0.2346 , 0.2335 , 0.2314 ,\n",
       "            0.2295 , 0.228  , 0.2273 , 0.2272 , 0.2266 , 0.2247 , 0.2246 ,\n",
       "            0.2173 , 0.2156 , 0.215  , 0.2148 , 0.2147 , 0.2114 , 0.2098 ,\n",
       "            0.2045 , 0.2034 , 0.2015 , 0.199  , 0.1987 , 0.1973 , 0.197  ,\n",
       "            0.1968 , 0.1953 , 0.1915 , 0.1897 , 0.1887 , 0.188  , 0.1816 ,\n",
       "            0.1814 , 0.1799 , 0.1788 , 0.1782 , 0.1774 , 0.1755 , 0.1692 ,\n",
       "            0.1685 , 0.1681 , 0.167  , 0.1666 , 0.1653 , 0.1626 , 0.1622 ,\n",
       "            0.1605 , 0.1597 , 0.1587 , 0.1542 , 0.154  , 0.1531 , 0.153  ,\n",
       "            0.152  , 0.1515 , 0.1499 , 0.1495 , 0.1483 , 0.1482 , 0.1461 ,\n",
       "            0.1438 , 0.142  , 0.1416 , 0.1404 , 0.1396 , 0.1346 , 0.134  ,\n",
       "            0.1335 , 0.1299 , 0.1277 , 0.1268 , 0.1261 , 0.12115, 0.12085,\n",
       "            0.12036, 0.118  , 0.11633, 0.11554, 0.11475, 0.11395, 0.111  ,\n",
       "            0.1093 , 0.10876, 0.1058 , 0.1052 , 0.1011 , 0.1007 , 0.0997 ,\n",
       "            0.09894, 0.09845, 0.09827, 0.0979 , 0.09753, 0.0964 , 0.0962 ,\n",
       "            0.0957 , 0.09534, 0.09467, 0.0935 , 0.0904 , 0.0898 , 0.0893 ,\n",
       "            0.0891 , 0.0882 , 0.088  , 0.0879 , 0.0866 , 0.0865 , 0.0848 ,\n",
       "            0.0845 , 0.08405, 0.0836 , 0.0833 , 0.0821 , 0.07764, 0.0775 ,\n",
       "            0.07544, 0.0752 , 0.075  , 0.0742 , 0.074  , 0.0732 , 0.0717 ,\n",
       "            0.0715 , 0.0708 , 0.0702 , 0.06757, 0.06586, 0.06396, 0.06244,\n",
       "            0.05933, 0.05243, 0.04886, 0.04376, 0.04068, 0.04037],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.02238806, 0.03731343, 0.04477612,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.19402985, 0.20149253, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.36567163,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.5298507 , 0.5298507 , 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5597015 , 0.5597015 , 0.5597015 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.57462686, 0.57462686, 0.57462686, 0.57462686,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6044776 , 0.6119403 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.6268657 , 0.63432837, 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6492537 , 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7238806 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.75373137, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.8507463 , 0.85820895, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00862069,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.02586207, 0.02586207, 0.03448276, 0.03448276,\n",
       "            0.03448276, 0.04310345, 0.05172414, 0.06034483, 0.06034483,\n",
       "            0.06896552, 0.06896552, 0.0775862 , 0.0775862 , 0.09482758,\n",
       "            0.11206897, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.21551724, 0.22413793,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.27586207, 0.29310346, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.7758621 , 0.7844828 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3843 , 0.3823 , 0.3809 , 0.3787 , 0.3777 , 0.377  ,\n",
       "            0.3762 , 0.373  , 0.3716 , 0.371  , 0.3708 , 0.37   , 0.3696 ,\n",
       "            0.3687 , 0.3667 , 0.366  , 0.3655 , 0.3652 , 0.3645 , 0.3635 ,\n",
       "            0.3618 , 0.361  , 0.3599 , 0.3591 , 0.359  , 0.358  , 0.3574 ,\n",
       "            0.3528 , 0.3516 , 0.351  , 0.3494 , 0.3486 , 0.3474 , 0.3462 ,\n",
       "            0.3418 , 0.341  , 0.3389 , 0.3386 , 0.3364 , 0.3315 , 0.3303 ,\n",
       "            0.329  , 0.3286 , 0.3274 , 0.326  , 0.3228 , 0.3223 , 0.3193 ,\n",
       "            0.3154 , 0.3147 , 0.3044 , 0.3008 , 0.3    , 0.2993 , 0.2974 ,\n",
       "            0.2957 , 0.288  , 0.2878 , 0.2864 , 0.2803 , 0.2754 , 0.2747 ,\n",
       "            0.2734 , 0.266  , 0.2632 , 0.26   , 0.2566 , 0.256  , 0.2542 ,\n",
       "            0.2534 , 0.2467 , 0.2415 , 0.2405 , 0.2394 , 0.2383 , 0.237  ,\n",
       "            0.234  , 0.2339 , 0.2334 , 0.2303 , 0.228  , 0.2233 , 0.2218 ,\n",
       "            0.2198 , 0.2194 , 0.2181 , 0.2134 , 0.2123 , 0.2113 , 0.2081 ,\n",
       "            0.2073 , 0.2064 , 0.2059 , 0.2056 , 0.2037 , 0.2029 , 0.2    ,\n",
       "            0.1979 , 0.1947 , 0.1943 , 0.1941 , 0.1925 , 0.19   , 0.187  ,\n",
       "            0.1837 , 0.1805 , 0.18   , 0.1799 , 0.1783 , 0.178  , 0.1768 ,\n",
       "            0.1763 , 0.1746 , 0.174  , 0.1709 , 0.1688 , 0.1682 , 0.1676 ,\n",
       "            0.1665 , 0.1635 , 0.1627 , 0.1626 , 0.1611 , 0.1608 , 0.1564 ,\n",
       "            0.1562 , 0.1552 , 0.1537 , 0.1532 , 0.1527 , 0.1489 , 0.1471 ,\n",
       "            0.1465 , 0.1462 , 0.146  , 0.1451 , 0.1443 , 0.142  , 0.1418 ,\n",
       "            0.1417 , 0.1396 , 0.1383 , 0.1373 , 0.1367 , 0.1365 , 0.1356 ,\n",
       "            0.1353 , 0.135  , 0.1321 , 0.1312 , 0.1289 , 0.1277 , 0.127  ,\n",
       "            0.1267 , 0.1204 , 0.12   , 0.1194 , 0.1192 , 0.11536, 0.11475,\n",
       "            0.1126 , 0.11145, 0.1086 , 0.1084 , 0.1045 , 0.10394, 0.1036 ,\n",
       "            0.103  , 0.10144, 0.1007 , 0.0967 , 0.096  , 0.0935 , 0.09235,\n",
       "            0.0906 , 0.0903 , 0.0893 , 0.089  , 0.0888 , 0.0851 , 0.08466,\n",
       "            0.0836 , 0.083  , 0.0824 , 0.0823 , 0.0808 , 0.0804 , 0.0799 ,\n",
       "            0.07935, 0.0786 , 0.07764, 0.07697, 0.0753 , 0.0749 , 0.0742 ,\n",
       "            0.07275, 0.07263, 0.0724 , 0.07227, 0.07184, 0.0715 , 0.0707 ,\n",
       "            0.06995, 0.06903, 0.0684 , 0.0683 , 0.06647, 0.06323, 0.06244,\n",
       "            0.06198, 0.0613 , 0.0612 , 0.05954, 0.0591 , 0.058  , 0.0575 ,\n",
       "            0.05728, 0.05664, 0.0546 , 0.0545 , 0.0526 , 0.0511 , 0.05023,\n",
       "            0.047  , 0.04153, 0.04132, 0.03854, 0.03476, 0.03397, 0.03137,\n",
       "            0.0313 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.17910448, 0.20149253, 0.20895523,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5       , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.54477614, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.54477614, 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5597015 , 0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.58208954, 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 , 0.6119403 ,\n",
       "            0.6119403 , 0.619403  , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6492537 , 0.6492537 , 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.6865672 , 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.73880595, 0.73880595, 0.74626863,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00862069, 0.00862069, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.03448276, 0.03448276, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.05172414, 0.06034483, 0.06034483, 0.06034483,\n",
       "            0.06896552, 0.06896552, 0.0775862 , 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.10344828, 0.11206897, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.30172414, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.38793105, 0.39655173,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3606 , 0.3594 , 0.3586 , 0.3577 , 0.357  , 0.3567 ,\n",
       "            0.355  , 0.3545 , 0.3508 , 0.3506 , 0.3503 , 0.35   , 0.3489 ,\n",
       "            0.348  , 0.346  , 0.3452 , 0.3428 , 0.3416 , 0.3413 , 0.341  ,\n",
       "            0.3408 , 0.34   , 0.3396 , 0.3394 , 0.339  , 0.3389 , 0.338  ,\n",
       "            0.3357 , 0.335  , 0.333  , 0.3325 , 0.3323 , 0.3262 , 0.3257 ,\n",
       "            0.324  , 0.3237 , 0.3235 , 0.3228 , 0.322  , 0.3193 , 0.3171 ,\n",
       "            0.317  , 0.316  , 0.3152 , 0.3098 , 0.3086 , 0.3066 , 0.3027 ,\n",
       "            0.302  , 0.2935 , 0.2908 , 0.29   , 0.2893 , 0.2886 , 0.2874 ,\n",
       "            0.2847 , 0.2795 , 0.2783 , 0.2742 , 0.2732 , 0.272  , 0.2712 ,\n",
       "            0.267  , 0.2666 , 0.2622 , 0.2598 , 0.2554 , 0.2551 , 0.2546 ,\n",
       "            0.2537 , 0.251  , 0.2485 , 0.2424 , 0.2422 , 0.2417 , 0.2407 ,\n",
       "            0.2386 , 0.237  , 0.235  , 0.2347 , 0.2344 , 0.2311 , 0.2303 ,\n",
       "            0.2273 , 0.2217 , 0.2208 , 0.2203 , 0.2202 , 0.2179 , 0.2173 ,\n",
       "            0.2156 , 0.2134 , 0.2106 , 0.2104 , 0.2089 , 0.2079 , 0.207  ,\n",
       "            0.205  , 0.2043 , 0.2023 , 0.202  , 0.1998 , 0.1987 , 0.1985 ,\n",
       "            0.1971 , 0.194  , 0.1935 , 0.1892 , 0.1838 , 0.1836 , 0.1831 ,\n",
       "            0.1826 , 0.1821 , 0.1807 , 0.1792 , 0.1765 , 0.1759 , 0.1754 ,\n",
       "            0.1752 , 0.174  , 0.1718 , 0.1692 , 0.1677 , 0.1674 , 0.167  ,\n",
       "            0.1664 , 0.1614 , 0.1597 , 0.1588 , 0.1587 , 0.1582 , 0.158  ,\n",
       "            0.1544 , 0.1525 , 0.1516 , 0.1515 , 0.1505 , 0.1498 , 0.1489 ,\n",
       "            0.1484 , 0.1482 , 0.1466 , 0.1458 , 0.1439 , 0.1431 , 0.1417 ,\n",
       "            0.1416 , 0.1411 , 0.1388 , 0.1355 , 0.135  , 0.1348 , 0.1343 ,\n",
       "            0.1342 , 0.1326 , 0.1305 , 0.1272 , 0.1254 , 0.1251 , 0.1236 ,\n",
       "            0.1219 , 0.1194 , 0.1184 , 0.11755, 0.1158 , 0.11456, 0.112  ,\n",
       "            0.111  , 0.10913, 0.10724, 0.1069 , 0.1054 , 0.10284, 0.1011 ,\n",
       "            0.09845, 0.0979 , 0.09705, 0.09656, 0.0945 , 0.0937 , 0.0932 ,\n",
       "            0.0927 , 0.0922 , 0.089  , 0.0882 , 0.0873 , 0.0871 , 0.0869 ,\n",
       "            0.0866 , 0.086  , 0.08527, 0.08466, 0.08405, 0.0836 , 0.0818 ,\n",
       "            0.08136, 0.08105, 0.0805 , 0.0801 , 0.0799 , 0.0788 , 0.07684,\n",
       "            0.07666, 0.07654, 0.076  , 0.075  , 0.07465, 0.0734 , 0.0733 ,\n",
       "            0.0729 , 0.07275, 0.0693 , 0.06854, 0.06696, 0.0667 , 0.066  ,\n",
       "            0.0643 , 0.06396, 0.0636 , 0.0627 , 0.0619 , 0.06177, 0.0611 ,\n",
       "            0.0592 , 0.0591 , 0.05698, 0.05542, 0.0547 , 0.05127, 0.04578,\n",
       "            0.04553, 0.04288, 0.03934, 0.0379 , 0.03522], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.19402985, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.2238806 , 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35820895, 0.36567163, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.5298507 , 0.5298507 , 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.54477614, 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.58208954, 0.58208954,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6119403 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.63432837, 0.63432837, 0.64179105, 0.6492537 , 0.6492537 ,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7238806 , 0.7238806 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8208955 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.02586207, 0.02586207, 0.03448276, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.04310345, 0.05172414,\n",
       "            0.06034483, 0.06034483, 0.06034483, 0.06896552, 0.06896552,\n",
       "            0.06896552, 0.0775862 , 0.0862069 , 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.10344828, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.25862068, 0.27586207,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.31896552, 0.3275862 , 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.67241377, 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.79310346, 0.79310346,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3384 , 0.3376 , 0.3372 , 0.3354 , 0.335  , 0.3342 ,\n",
       "            0.334  , 0.333  , 0.3328 , 0.3313 , 0.331  , 0.3306 , 0.3296 ,\n",
       "            0.3293 , 0.3276 , 0.3267 , 0.3264 , 0.3262 , 0.326  , 0.325  ,\n",
       "            0.3237 , 0.323  , 0.3228 , 0.3223 , 0.3215 , 0.321  , 0.32   ,\n",
       "            0.3198 , 0.3184 , 0.3179 , 0.317  , 0.3164 , 0.3157 , 0.3154 ,\n",
       "            0.3147 , 0.3145 , 0.3142 , 0.314  , 0.3123 , 0.3103 , 0.3096 ,\n",
       "            0.3066 , 0.3027 , 0.3    , 0.2952 , 0.295  , 0.2944 , 0.292  ,\n",
       "            0.288  , 0.2854 , 0.285  , 0.2847 , 0.2837 , 0.2822 , 0.279  ,\n",
       "            0.2776 , 0.277  , 0.2717 , 0.2693 , 0.268  , 0.2673 , 0.2664 ,\n",
       "            0.2651 , 0.2646 , 0.2637 , 0.2622 , 0.257  , 0.2556 , 0.2551 ,\n",
       "            0.255  , 0.2522 , 0.2517 , 0.251  , 0.2467 , 0.2458 , 0.2455 ,\n",
       "            0.2448 , 0.241  , 0.239  , 0.2384 , 0.2346 , 0.2344 , 0.2334 ,\n",
       "            0.2332 , 0.2314 , 0.2274 , 0.2269 , 0.226  , 0.2252 , 0.2242 ,\n",
       "            0.2229 , 0.2217 , 0.2175 , 0.215  , 0.2148 , 0.2123 , 0.2114 ,\n",
       "            0.2113 , 0.2089 , 0.2081 , 0.2073 , 0.2068 , 0.206  , 0.2059 ,\n",
       "            0.2009 , 0.2007 , 0.2002 , 0.1991 , 0.1989 , 0.1958 , 0.1956 ,\n",
       "            0.195  , 0.1942 , 0.1923 , 0.1917 , 0.1897 , 0.1876 , 0.1866 ,\n",
       "            0.1855 , 0.1843 , 0.1842 , 0.1794 , 0.1791 , 0.1782 , 0.1776 ,\n",
       "            0.1749 , 0.173  , 0.1724 , 0.1715 , 0.1705 , 0.169  , 0.1687 ,\n",
       "            0.1672 , 0.1669 , 0.1659 , 0.1653 , 0.1647 , 0.1626 , 0.1608 ,\n",
       "            0.1592 , 0.1589 , 0.1588 , 0.1567 , 0.1564 , 0.1555 , 0.1554 ,\n",
       "            0.1538 , 0.1505 , 0.1495 , 0.1486 , 0.1484 , 0.147  , 0.1459 ,\n",
       "            0.1458 , 0.1417 , 0.1414 , 0.1389 , 0.1385 , 0.1359 , 0.1353 ,\n",
       "            0.1337 , 0.1312 , 0.1309 , 0.1305 , 0.1301 , 0.1273 , 0.1268 ,\n",
       "            0.126  , 0.1229 , 0.12067, 0.119  , 0.118  , 0.1172 , 0.1134 ,\n",
       "            0.113  , 0.1122 , 0.1099 , 0.1095 , 0.1078 , 0.1074 , 0.1069 ,\n",
       "            0.1056 , 0.1052 , 0.1043 , 0.1007 , 0.1    , 0.0997 , 0.0995 ,\n",
       "            0.09894, 0.09875, 0.0986 , 0.09686, 0.0957 , 0.09515, 0.0942 ,\n",
       "            0.094  , 0.0933 , 0.09204, 0.0906 , 0.0887 , 0.0885 , 0.0883 ,\n",
       "            0.088  , 0.0873 , 0.0869 , 0.0862 , 0.0851 , 0.0845 , 0.0827 ,\n",
       "            0.082  , 0.0788 , 0.07806, 0.0774 , 0.0772 , 0.0753 , 0.07477,\n",
       "            0.0745 , 0.07385, 0.07306, 0.07227, 0.0702 , 0.07007, 0.06793,\n",
       "            0.0662 , 0.06525, 0.06177, 0.05573, 0.05542, 0.05283, 0.04932,\n",
       "            0.0471 , 0.0442 , 0.0441 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.02238806, 0.03731343, 0.05223881, 0.05970149, 0.07462686,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26119402,\n",
       "            0.26119402, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.37313432, 0.37313432,\n",
       "            0.38059703, 0.3955224 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41044775, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.54477614, 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6119403 , 0.619403  , 0.619403  ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6492537 , 0.6567164 , 0.6641791 , 0.6791045 ,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.00862069, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.04310345, 0.04310345,\n",
       "            0.05172414, 0.05172414, 0.05172414, 0.05172414, 0.06034483,\n",
       "            0.06034483, 0.06034483, 0.06896552, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.0862069 , 0.0862069 , 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.12931034,\n",
       "            0.13793103, 0.13793103, 0.13793103, 0.13793103, 0.13793103,\n",
       "            0.14655173, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.22413793, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.2672414 , 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31034482, 0.31034482, 0.31896552, 0.3275862 , 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3262 , 0.3237 , 0.3203 , 0.3196 , 0.3179 , 0.3176 ,\n",
       "            0.3167 , 0.3162 , 0.316  , 0.3152 , 0.3147 , 0.3145 , 0.3142 ,\n",
       "            0.3137 , 0.3135 , 0.3125 , 0.3113 , 0.311  , 0.3108 , 0.3105 ,\n",
       "            0.31   , 0.3093 , 0.3086 , 0.308  , 0.3066 , 0.3064 , 0.3054 ,\n",
       "            0.3047 , 0.3044 , 0.304  , 0.3027 , 0.302  , 0.3013 , 0.3005 ,\n",
       "            0.2993 , 0.299  , 0.2986 , 0.298  , 0.2979 , 0.2961 , 0.296  ,\n",
       "            0.295  , 0.2935 , 0.2915 , 0.2908 , 0.2898 , 0.286  , 0.2854 ,\n",
       "            0.285  , 0.2837 , 0.2832 , 0.2805 , 0.2786 , 0.2783 , 0.2778 ,\n",
       "            0.2751 , 0.2747 , 0.2727 , 0.2722 , 0.2708 , 0.269  , 0.2686 ,\n",
       "            0.2676 , 0.2651 , 0.2627 , 0.2622 , 0.2605 , 0.2588 , 0.2576 ,\n",
       "            0.2573 , 0.2556 , 0.255  , 0.2532 , 0.2515 , 0.2505 , 0.2498 ,\n",
       "            0.2487 , 0.2452 , 0.2444 , 0.2415 , 0.2413 , 0.241  , 0.2374 ,\n",
       "            0.2362 , 0.2344 , 0.234  , 0.2306 , 0.2277 , 0.2249 , 0.2234 ,\n",
       "            0.223  , 0.2225 , 0.2224 , 0.222  , 0.2211 , 0.2205 , 0.2191 ,\n",
       "            0.219  , 0.2185 , 0.2161 , 0.2156 , 0.2145 , 0.2135 , 0.2124 ,\n",
       "            0.2118 , 0.211  , 0.2074 , 0.2065 , 0.2002 , 0.1995 , 0.1991 ,\n",
       "            0.1982 , 0.1941 , 0.194  , 0.1921 , 0.1907 , 0.1896 , 0.1891 ,\n",
       "            0.1874 , 0.1864 , 0.1844 , 0.1835 , 0.1826 , 0.1821 , 0.181  ,\n",
       "            0.1805 , 0.179  , 0.1779 , 0.1766 , 0.1761 , 0.1747 , 0.1738 ,\n",
       "            0.173  , 0.1726 , 0.1724 , 0.1711 , 0.1671 , 0.166  , 0.1656 ,\n",
       "            0.1654 , 0.1631 , 0.1627 , 0.1608 , 0.1593 , 0.1562 , 0.1558 ,\n",
       "            0.1534 , 0.1516 , 0.1504 , 0.1492 , 0.1486 , 0.1471 , 0.1455 ,\n",
       "            0.145  , 0.1404 , 0.138  , 0.1355 , 0.1346 , 0.1342 , 0.1326 ,\n",
       "            0.1315 , 0.1282 , 0.1268 , 0.1265 , 0.126  , 0.1256 , 0.1252 ,\n",
       "            0.1243 , 0.12067, 0.12054, 0.1197 , 0.1184 , 0.11694, 0.11536,\n",
       "            0.11456, 0.1144 , 0.1142 , 0.11395, 0.11316, 0.113  , 0.11145,\n",
       "            0.11127, 0.11084, 0.1099 , 0.10913, 0.1076 , 0.10596, 0.1056 ,\n",
       "            0.1052 , 0.1041 , 0.10394, 0.103  , 0.1025 , 0.10144, 0.1011 ,\n",
       "            0.1007 , 0.1    , 0.0997 , 0.0986 , 0.09534, 0.09503, 0.093  ,\n",
       "            0.09186, 0.09155, 0.0906 , 0.0898 , 0.0883 , 0.0882 , 0.0874 ,\n",
       "            0.0845 , 0.0825 , 0.0808 , 0.07935, 0.076  , 0.06915, 0.06903,\n",
       "            0.0662 , 0.06335, 0.05975, 0.05676, 0.05646], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.06716418, 0.09701493, 0.1119403 , 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.20895523, 0.20895523, 0.21641791, 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.26119402, 0.26865673, 0.26865673, 0.2761194 ,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.3283582 , 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.42537314, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.4402985 , 0.4477612 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.47761193, 0.48507464, 0.48507464,\n",
       "            0.48507464, 0.48507464, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 , 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5970149 , 0.5970149 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.6641791 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.03448276, 0.04310345, 0.05172414, 0.05172414, 0.05172414,\n",
       "            0.05172414, 0.05172414, 0.05172414, 0.06034483, 0.06896552,\n",
       "            0.06896552, 0.06896552, 0.06896552, 0.06896552, 0.0775862 ,\n",
       "            0.0775862 , 0.0775862 , 0.0862069 , 0.0862069 , 0.0862069 ,\n",
       "            0.0862069 , 0.0862069 , 0.0862069 , 0.0862069 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.10344828, 0.10344828, 0.10344828,\n",
       "            0.10344828, 0.10344828, 0.11206897, 0.12068965, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.13793103, 0.13793103, 0.13793103,\n",
       "            0.13793103, 0.13793103, 0.13793103, 0.14655173, 0.14655173,\n",
       "            0.14655173, 0.14655173, 0.14655173, 0.14655173, 0.14655173,\n",
       "            0.14655173, 0.14655173, 0.15517241, 0.15517241, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.1724138 , 0.1724138 , 0.18103448,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.22413793, 0.23275863, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.35344827, 0.36206895, 0.36206895,\n",
       "            0.36206895, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.6637931 ,\n",
       "            0.6810345 , 0.6810345 , 0.6896552 , 0.69827586, 0.7155172 ,\n",
       "            0.7241379 , 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.80172414,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3396 , 0.33   , 0.3267 , 0.3235 , 0.3193 , 0.3186 ,\n",
       "            0.3162 , 0.3157 , 0.3115 , 0.311  , 0.3105 , 0.309  , 0.3088 ,\n",
       "            0.3086 , 0.3079 , 0.3074 , 0.3071 , 0.307  , 0.3064 , 0.3054 ,\n",
       "            0.3052 , 0.3047 , 0.3044 , 0.3042 , 0.3037 , 0.3032 , 0.303  ,\n",
       "            0.3022 , 0.3018 , 0.3013 , 0.301  , 0.3    , 0.2993 , 0.2988 ,\n",
       "            0.2986 , 0.298  , 0.2976 , 0.2964 , 0.2961 , 0.296  , 0.2957 ,\n",
       "            0.2944 , 0.2937 , 0.291  , 0.289  , 0.2886 , 0.2883 , 0.2869 ,\n",
       "            0.2866 , 0.2864 , 0.2854 , 0.2852 , 0.285  , 0.2847 , 0.2842 ,\n",
       "            0.2834 , 0.2827 , 0.2812 , 0.2808 , 0.2805 , 0.28   , 0.278  ,\n",
       "            0.277  , 0.2761 , 0.276  , 0.2747 , 0.2732 , 0.2727 , 0.272  ,\n",
       "            0.2717 , 0.271  , 0.2693 , 0.269  , 0.2678 , 0.2664 , 0.2644 ,\n",
       "            0.264  , 0.2625 , 0.2612 , 0.2595 , 0.2573 , 0.255  , 0.2542 ,\n",
       "            0.2527 , 0.2522 , 0.251  , 0.2502 , 0.2483 , 0.2478 , 0.2474 ,\n",
       "            0.2449 , 0.243  , 0.2428 , 0.2422 , 0.2421 , 0.239  , 0.2388 ,\n",
       "            0.2379 , 0.237  , 0.2352 , 0.2335 , 0.2334 , 0.2332 , 0.2327 ,\n",
       "            0.2303 , 0.2302 , 0.2278 , 0.2268 , 0.2255 , 0.2225 , 0.2186 ,\n",
       "            0.2163 , 0.2161 , 0.2125 , 0.2118 , 0.2106 , 0.2104 , 0.2091 ,\n",
       "            0.2086 , 0.2081 , 0.2065 , 0.2054 , 0.2047 , 0.2043 , 0.2017 ,\n",
       "            0.201  , 0.1995 , 0.1993 , 0.1984 , 0.197  , 0.1958 , 0.195  ,\n",
       "            0.193  , 0.1919 , 0.1913 , 0.1909 , 0.1866 , 0.1858 , 0.1842 ,\n",
       "            0.1819 , 0.1816 , 0.1812 , 0.179  , 0.1774 , 0.1755 , 0.1748 ,\n",
       "            0.1743 , 0.1727 , 0.1719 , 0.1711 , 0.1698 , 0.1693 , 0.1675 ,\n",
       "            0.1669 , 0.1664 , 0.1663 , 0.1622 , 0.1587 , 0.1565 , 0.1555 ,\n",
       "            0.1543 , 0.1539 , 0.1533 , 0.1506 , 0.1477 , 0.1473 , 0.1464 ,\n",
       "            0.1455 , 0.1447 , 0.1421 , 0.1409 , 0.1399 , 0.1378 , 0.1373 ,\n",
       "            0.1372 , 0.1361 , 0.1338 , 0.133  , 0.1318 , 0.1317 , 0.1315 ,\n",
       "            0.1312 , 0.1305 , 0.1292 , 0.1289 , 0.1279 , 0.1278 , 0.1263 ,\n",
       "            0.1259 , 0.1249 , 0.1241 , 0.1226 , 0.1225 , 0.12115, 0.1207 ,\n",
       "            0.1196 , 0.1193 , 0.118  , 0.1172 , 0.11676, 0.11615, 0.1152 ,\n",
       "            0.11395, 0.11084, 0.1093 , 0.108  , 0.1076 , 0.1063 , 0.10504,\n",
       "            0.1043 , 0.1041 , 0.1005 , 0.10034, 0.09875, 0.0967 , 0.09503,\n",
       "            0.09186, 0.08435, 0.08417, 0.08124, 0.07935, 0.0742 , 0.0709 ,\n",
       "            0.07043], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02985075, 0.03731343, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.1119403 , 0.12686567,\n",
       "            0.13432837, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.18656716, 0.18656716, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.23880596, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.2835821 ,\n",
       "            0.2835821 , 0.29850745, 0.33582088, 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.37313432, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3880597 , 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.47761193, 0.48507464, 0.48507464, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5597015 , 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 , 0.57462686,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5970149 , 0.5970149 , 0.5970149 ,\n",
       "            0.6119403 , 0.619403  , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.70149255, 0.7164179 , 0.7238806 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.06896552,\n",
       "            0.0775862 , 0.0862069 , 0.09482758, 0.10344828, 0.11206897,\n",
       "            0.12068965, 0.12931034, 0.13793103, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.15517241, 0.15517241, 0.15517241, 0.15517241,\n",
       "            0.15517241, 0.1637931 , 0.1637931 , 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18103448, 0.18103448, 0.18103448, 0.18965517,\n",
       "            0.18965517, 0.18965517, 0.18965517, 0.18965517, 0.18965517,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.21551724,\n",
       "            0.21551724, 0.21551724, 0.22413793, 0.22413793, 0.22413793,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.2413793 , 0.25      ,\n",
       "            0.25      , 0.25862068, 0.25862068, 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.27586207, 0.27586207, 0.28448275, 0.28448275,\n",
       "            0.28448275, 0.28448275, 0.29310346, 0.30172414, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.31896552, 0.31896552, 0.33620688,\n",
       "            0.3448276 , 0.3448276 , 0.3448276 , 0.3448276 , 0.3448276 ,\n",
       "            0.35344827, 0.35344827, 0.35344827, 0.36206895, 0.36206895,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.37931034, 0.38793105,\n",
       "            0.4051724 , 0.41379312, 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43103448, 0.43103448, 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.4827586 , 0.49137932, 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6637931 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.9310345 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3538 , 0.344  , 0.3418 , 0.3406 , 0.3364 , 0.3337 ,\n",
       "            0.3335 , 0.3306 , 0.33   , 0.329  , 0.3286 , 0.327  , 0.3242 ,\n",
       "            0.3237 , 0.3186 , 0.3184 , 0.3174 , 0.3157 , 0.3137 , 0.3093 ,\n",
       "            0.3086 , 0.3083 , 0.3079 , 0.3074 , 0.3064 , 0.3052 , 0.305  ,\n",
       "            0.3042 , 0.304  , 0.3032 , 0.3022 , 0.3008 , 0.2998 , 0.2996 ,\n",
       "            0.2983 , 0.297  , 0.2966 , 0.2957 , 0.2954 , 0.295  , 0.2944 ,\n",
       "            0.294  , 0.2937 , 0.2935 , 0.2932 , 0.2925 , 0.2917 , 0.2915 ,\n",
       "            0.2908 , 0.2903 , 0.29   , 0.2898 , 0.2893 , 0.289  , 0.2888 ,\n",
       "            0.2883 , 0.2876 , 0.2874 , 0.287  , 0.2869 , 0.2866 , 0.2864 ,\n",
       "            0.286  , 0.2856 , 0.285  , 0.283  , 0.2822 , 0.2815 , 0.2808 ,\n",
       "            0.2788 , 0.2786 , 0.2776 , 0.2773 , 0.2756 , 0.2751 , 0.2734 ,\n",
       "            0.2722 , 0.272  , 0.2715 , 0.271  , 0.2686 , 0.2676 , 0.2673 ,\n",
       "            0.2668 , 0.2651 , 0.265  , 0.2646 , 0.2637 , 0.2632 , 0.263  ,\n",
       "            0.2622 , 0.2617 , 0.2615 , 0.2612 , 0.2598 , 0.2595 , 0.2554 ,\n",
       "            0.2544 , 0.253  , 0.2512 , 0.248  , 0.2471 , 0.247  , 0.2463 ,\n",
       "            0.2451 , 0.2441 , 0.2406 , 0.2384 , 0.2366 , 0.2363 , 0.2328 ,\n",
       "            0.2323 , 0.231  , 0.2289 , 0.2285 , 0.2272 , 0.2263 , 0.226  ,\n",
       "            0.2247 , 0.223  , 0.2229 , 0.2213 , 0.2211 , 0.2207 , 0.2191 ,\n",
       "            0.2175 , 0.2144 , 0.2139 , 0.2134 , 0.213  , 0.2115 , 0.211  ,\n",
       "            0.2108 , 0.2106 , 0.2089 , 0.2085 , 0.2084 , 0.2063 , 0.2053 ,\n",
       "            0.202  , 0.2002 , 0.1987 , 0.1979 , 0.1973 , 0.1931 , 0.1927 ,\n",
       "            0.1921 , 0.1915 , 0.1912 , 0.1904 , 0.1903 , 0.1874 , 0.1871 ,\n",
       "            0.1864 , 0.1853 , 0.1824 , 0.1782 , 0.1765 , 0.1761 , 0.1752 ,\n",
       "            0.1743 , 0.1733 , 0.1693 , 0.1688 , 0.1661 , 0.1659 , 0.1626 ,\n",
       "            0.1621 , 0.1603 , 0.1583 , 0.1582 , 0.1545 , 0.1544 , 0.1533 ,\n",
       "            0.1515 , 0.1509 , 0.1484 , 0.1477 , 0.1475 , 0.1473 , 0.1466 ,\n",
       "            0.1462 , 0.1445 , 0.1439 , 0.1437 , 0.1434 , 0.142  , 0.1387 ,\n",
       "            0.1381 , 0.1372 , 0.1367 , 0.1366 , 0.1362 , 0.1353 , 0.1351 ,\n",
       "            0.1343 , 0.1333 , 0.1332 , 0.1324 , 0.1312 , 0.1259 , 0.1255 ,\n",
       "            0.124  , 0.12305, 0.1223 , 0.12177, 0.12024, 0.1166 , 0.11597,\n",
       "            0.11536, 0.11316, 0.111  , 0.108  , 0.1    , 0.0998 , 0.0967 ,\n",
       "            0.0962 , 0.0893 , 0.086  , 0.08527], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.05970149, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.11940298, 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.18656716, 0.19402985, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26865673, 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.36567163, 0.37313432, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.47014925, 0.48507464, 0.48507464,\n",
       "            0.48507464, 0.48507464, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5597015 , 0.5671642 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.58208954, 0.58208954, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.5970149 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.619403  , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6791045 , 0.6791045 ,\n",
       "            0.6865672 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.25      ,\n",
       "            0.25862068, 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.29310346, 0.29310346, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.31896552, 0.31896552, 0.33620688,\n",
       "            0.33620688, 0.3448276 , 0.3448276 , 0.3448276 , 0.35344827,\n",
       "            0.35344827, 0.35344827, 0.35344827, 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37068966, 0.37068966, 0.37068966, 0.37931034,\n",
       "            0.37931034, 0.37931034, 0.37931034, 0.38793105, 0.38793105,\n",
       "            0.39655173, 0.39655173, 0.39655173, 0.39655173, 0.39655173,\n",
       "            0.39655173, 0.39655173, 0.39655173, 0.39655173, 0.4051724 ,\n",
       "            0.4051724 , 0.4051724 , 0.4051724 , 0.4051724 , 0.4051724 ,\n",
       "            0.4224138 , 0.4224138 , 0.4224138 , 0.4224138 , 0.43103448,\n",
       "            0.43103448, 0.43103448, 0.43965518, 0.43965518, 0.43965518,\n",
       "            0.43965518, 0.43965518, 0.44827586, 0.45689654, 0.45689654,\n",
       "            0.46551725, 0.46551725, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.4827586 , 0.49137932, 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.5258621 , 0.5344828 , 0.55172414, 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.70689654, 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8448276 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3728 , 0.3706 , 0.37   , 0.366  , 0.365  , 0.3635 ,\n",
       "            0.3623 , 0.3613 , 0.359  , 0.358  , 0.3552 , 0.3542 , 0.351  ,\n",
       "            0.35   , 0.348  , 0.3464 , 0.3452 , 0.3433 , 0.342  , 0.338  ,\n",
       "            0.3374 , 0.3306 , 0.3293 , 0.329  , 0.328  , 0.3257 , 0.3247 ,\n",
       "            0.323  , 0.3228 , 0.3198 , 0.3193 , 0.319  , 0.318  , 0.3176 ,\n",
       "            0.3147 , 0.3132 , 0.3123 , 0.3118 , 0.311  , 0.3105 , 0.309  ,\n",
       "            0.3088 , 0.3083 , 0.308  , 0.307  , 0.3066 , 0.3057 , 0.3047 ,\n",
       "            0.304  , 0.3027 , 0.3005 , 0.3003 , 0.3    , 0.2996 , 0.299  ,\n",
       "            0.2986 , 0.2979 , 0.2976 , 0.2974 , 0.2961 , 0.2954 , 0.295  ,\n",
       "            0.2944 , 0.2942 , 0.2932 , 0.2925 , 0.2917 , 0.2913 , 0.2908 ,\n",
       "            0.2905 , 0.2898 , 0.289  , 0.288  , 0.2878 , 0.287  , 0.2861 ,\n",
       "            0.2854 , 0.2852 , 0.2842 , 0.282  , 0.2812 , 0.2805 , 0.2803 ,\n",
       "            0.2798 , 0.2795 , 0.2786 , 0.2783 , 0.2776 , 0.277  , 0.2766 ,\n",
       "            0.2747 , 0.2742 , 0.2737 , 0.2727 , 0.27   , 0.2695 , 0.2686 ,\n",
       "            0.2642 , 0.2637 , 0.2634 , 0.263  , 0.2612 , 0.2598 , 0.2588 ,\n",
       "            0.2563 , 0.256  , 0.2559 , 0.2556 , 0.254  , 0.2527 , 0.252  ,\n",
       "            0.2517 , 0.2487 , 0.2474 , 0.2473 , 0.2467 , 0.2458 , 0.2449 ,\n",
       "            0.2438 , 0.2433 , 0.2418 , 0.2417 , 0.2406 , 0.2399 , 0.2397 ,\n",
       "            0.2374 , 0.2372 , 0.2366 , 0.2362 , 0.2355 , 0.2352 , 0.2334 ,\n",
       "            0.2319 , 0.2318 , 0.2311 , 0.2301 , 0.2299 , 0.2257 , 0.2256 ,\n",
       "            0.2229 , 0.222  , 0.2207 , 0.2184 , 0.2173 , 0.2166 , 0.2158 ,\n",
       "            0.2156 , 0.2153 , 0.2147 , 0.2145 , 0.211  , 0.2086 , 0.2063 ,\n",
       "            0.2043 , 0.2037 , 0.2035 , 0.2012 , 0.2    , 0.1998 , 0.1995 ,\n",
       "            0.1987 , 0.1979 , 0.1974 , 0.1971 , 0.1936 , 0.1934 , 0.1925 ,\n",
       "            0.191  , 0.1876 , 0.1871 , 0.187  , 0.1823 , 0.1813 , 0.18   ,\n",
       "            0.1771 , 0.177  , 0.1748 , 0.1738 , 0.1736 , 0.1724 , 0.1716 ,\n",
       "            0.171  , 0.1705 , 0.1703 , 0.17   , 0.1687 , 0.1681 , 0.1665 ,\n",
       "            0.1664 , 0.1658 , 0.1649 , 0.1616 , 0.1609 , 0.1608 , 0.1602 ,\n",
       "            0.1599 , 0.1598 , 0.1594 , 0.158  , 0.1571 , 0.1556 , 0.1545 ,\n",
       "            0.1506 , 0.1487 , 0.1467 , 0.1466 , 0.1459 , 0.1456 , 0.142  ,\n",
       "            0.1384 , 0.138  , 0.1356 , 0.1328 , 0.1305 , 0.1217 , 0.12146,\n",
       "            0.1195 , 0.1186 , 0.1103 , 0.10706, 0.10596], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.07462686, 0.08208955, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.15671642, 0.1641791 , 0.1641791 ,\n",
       "            0.1641791 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23134328,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.2761194 , 0.30597016,\n",
       "            0.31343284, 0.31343284, 0.31343284, 0.32089552, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.3432836 , 0.35820895, 0.36567163, 0.36567163, 0.37313432,\n",
       "            0.37313432, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.40298507, 0.41044775,\n",
       "            0.41044775, 0.41044775, 0.41791046, 0.41791046, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.53731346, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.619403  , 0.619403  ,\n",
       "            0.6268657 , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.37931034, 0.38793105,\n",
       "            0.38793105, 0.38793105, 0.38793105, 0.39655173, 0.39655173,\n",
       "            0.39655173, 0.4051724 , 0.4051724 , 0.4051724 , 0.4051724 ,\n",
       "            0.41379312, 0.41379312, 0.4224138 , 0.4224138 , 0.4224138 ,\n",
       "            0.4224138 , 0.4224138 , 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.44827586, 0.44827586, 0.44827586, 0.44827586,\n",
       "            0.44827586, 0.44827586, 0.45689654, 0.45689654, 0.46551725,\n",
       "            0.46551725, 0.46551725, 0.46551725, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.49137932, 0.5086207 ,\n",
       "            0.5086207 , 0.5086207 , 0.51724136, 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.5344828 , 0.54310346, 0.55172414, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.5689655 , 0.5689655 , 0.5689655 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.6034483 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6637931 , 0.67241377, 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.6810345 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.7758621 , 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.88793105, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.394 , 0.3938, 0.392 , 0.3918, 0.3914, 0.3867, 0.3865,\n",
       "            0.3857, 0.3833, 0.379 , 0.3767, 0.3726, 0.3718, 0.371 , 0.3708,\n",
       "            0.3706, 0.3665, 0.365 , 0.364 , 0.3616, 0.3574, 0.3535, 0.353 ,\n",
       "            0.3525, 0.3486, 0.3472, 0.3464, 0.3462, 0.3455, 0.3447, 0.3428,\n",
       "            0.342 , 0.34  , 0.3398, 0.339 , 0.3325, 0.3303, 0.3284, 0.3274,\n",
       "            0.3271, 0.3264, 0.322 , 0.321 , 0.3206, 0.3164, 0.3152, 0.3137,\n",
       "            0.3132, 0.3115, 0.31  , 0.3098, 0.3079, 0.3076, 0.3064, 0.3052,\n",
       "            0.303 , 0.3025, 0.3018, 0.3015, 0.3013, 0.301 , 0.2983, 0.2969,\n",
       "            0.2966, 0.2957, 0.2952, 0.2947, 0.2935, 0.293 , 0.2915, 0.2908,\n",
       "            0.29  , 0.2893, 0.289 , 0.2888, 0.2886, 0.2883, 0.2878, 0.2874,\n",
       "            0.2869, 0.2866, 0.2854, 0.2852, 0.284 , 0.2837, 0.2832, 0.2812,\n",
       "            0.2805, 0.2803, 0.2793, 0.2786, 0.2776, 0.277 , 0.2761, 0.276 ,\n",
       "            0.2756, 0.2742, 0.2737, 0.272 , 0.271 , 0.2708, 0.2703, 0.27  ,\n",
       "            0.2695, 0.269 , 0.2683, 0.2673, 0.267 , 0.2664, 0.2642, 0.2637,\n",
       "            0.2634, 0.2622, 0.2617, 0.2612, 0.2607, 0.2605, 0.2598, 0.258 ,\n",
       "            0.2578, 0.2573, 0.2568, 0.2542, 0.2524, 0.2517, 0.251 , 0.2507,\n",
       "            0.25  , 0.2498, 0.2496, 0.2493, 0.2478, 0.2474, 0.2473, 0.2466,\n",
       "            0.2463, 0.2448, 0.2426, 0.2418, 0.2411, 0.2397, 0.2395, 0.2391,\n",
       "            0.2386, 0.2363, 0.2362, 0.2338, 0.2332, 0.233 , 0.2327, 0.2303,\n",
       "            0.2289, 0.2285, 0.2281, 0.2255, 0.2247, 0.224 , 0.223 , 0.2229,\n",
       "            0.2224, 0.222 , 0.2216, 0.22  , 0.2195, 0.2185, 0.2175, 0.2129,\n",
       "            0.2119, 0.2073, 0.2068, 0.2023, 0.2012, 0.2009, 0.2004, 0.2002,\n",
       "            0.1989, 0.1965, 0.1959, 0.1953, 0.1952, 0.1942, 0.194 , 0.1934,\n",
       "            0.1925, 0.191 , 0.1891, 0.1886, 0.1884, 0.188 , 0.1864, 0.1859,\n",
       "            0.1858, 0.185 , 0.1848, 0.1823, 0.182 , 0.1816, 0.181 , 0.1803,\n",
       "            0.1791, 0.1776, 0.1757, 0.1743, 0.1714, 0.17  , 0.1699, 0.1675,\n",
       "            0.1666, 0.163 , 0.1598, 0.1597, 0.1594, 0.1572, 0.1544, 0.1521,\n",
       "            0.1436, 0.1432, 0.1427, 0.1406, 0.1312, 0.1277, 0.1263],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.06716418, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.1119403 , 0.12686567, 0.13432837, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1641791 , 0.1716418 ,\n",
       "            0.18656716, 0.20149253, 0.20149253, 0.20895523, 0.20895523,\n",
       "            0.21641791, 0.21641791, 0.2238806 , 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26865673, 0.26865673,\n",
       "            0.26865673, 0.2761194 , 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.3283582 , 0.3283582 , 0.3283582 , 0.3283582 ,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.35820895, 0.35820895,\n",
       "            0.35820895, 0.36567163, 0.36567163, 0.36567163, 0.37313432,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.3880597 , 0.3880597 ,\n",
       "            0.3880597 , 0.3880597 , 0.3955224 , 0.3955224 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.42537314, 0.42537314, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4402985 , 0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.6268657 , 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.41379312, 0.41379312, 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43103448, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.4827586 , 0.4827586 ,\n",
       "            0.49137932, 0.49137932, 0.5086207 , 0.5086207 , 0.51724136,\n",
       "            0.51724136, 0.51724136, 0.51724136, 0.5258621 , 0.5258621 ,\n",
       "            0.5258621 , 0.5258621 , 0.5258621 , 0.5344828 , 0.5344828 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5948276 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.63793105, 0.63793105, 0.6465517 , 0.6465517 , 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.67241377, 0.6810345 , 0.69827586, 0.70689654,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8189655 , 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.88793105, 0.8965517 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4268, 0.4253, 0.4229, 0.4204, 0.4194, 0.4158, 0.415 ,\n",
       "            0.4146, 0.4133, 0.409 , 0.4055, 0.4048, 0.403 , 0.4016, 0.397 ,\n",
       "            0.3967, 0.3953, 0.3928, 0.391 , 0.39  , 0.3887, 0.3857, 0.3853,\n",
       "            0.3826, 0.3782, 0.376 , 0.3755, 0.375 , 0.3718, 0.371 , 0.3708,\n",
       "            0.3704, 0.3694, 0.3684, 0.3616, 0.3591, 0.3574, 0.3562, 0.3535,\n",
       "            0.353 , 0.3474, 0.347 , 0.3447, 0.3408, 0.3323, 0.3257, 0.325 ,\n",
       "            0.323 , 0.32  , 0.3193, 0.3184, 0.3176, 0.316 , 0.3154, 0.3152,\n",
       "            0.3147, 0.3142, 0.3127, 0.312 , 0.311 , 0.31  , 0.3093, 0.3088,\n",
       "            0.308 , 0.3074, 0.3066, 0.305 , 0.3044, 0.304 , 0.3037, 0.3032,\n",
       "            0.3022, 0.3013, 0.3   , 0.299 , 0.2986, 0.297 , 0.2966, 0.2964,\n",
       "            0.296 , 0.2957, 0.2952, 0.2937, 0.2932, 0.293 , 0.2927, 0.2925,\n",
       "            0.2922, 0.292 , 0.2917, 0.2915, 0.2908, 0.2898, 0.2896, 0.2893,\n",
       "            0.289 , 0.2886, 0.2883, 0.2876, 0.287 , 0.2869, 0.286 , 0.2854,\n",
       "            0.284 , 0.2837, 0.2834, 0.2832, 0.282 , 0.279 , 0.2778, 0.277 ,\n",
       "            0.2764, 0.2751, 0.2742, 0.2732, 0.2715, 0.2708, 0.2703, 0.2698,\n",
       "            0.2693, 0.269 , 0.2686, 0.2683, 0.268 , 0.2678, 0.2676, 0.2654,\n",
       "            0.2632, 0.263 , 0.2622, 0.2607, 0.2605, 0.258 , 0.2573, 0.2568,\n",
       "            0.2563, 0.2556, 0.255 , 0.2534, 0.2524, 0.2512, 0.2494, 0.2478,\n",
       "            0.2477, 0.2463, 0.246 , 0.2441, 0.2434, 0.2424, 0.2422, 0.2417,\n",
       "            0.2415, 0.241 , 0.2388, 0.2384, 0.2372, 0.2352, 0.2318, 0.2301,\n",
       "            0.2283, 0.226 , 0.2257, 0.2247, 0.2234, 0.2218, 0.2216, 0.2205,\n",
       "            0.2202, 0.2198, 0.2195, 0.2194, 0.2166, 0.2153, 0.215 , 0.2144,\n",
       "            0.2125, 0.2113, 0.211 , 0.2104, 0.21  , 0.2096, 0.2091, 0.2085,\n",
       "            0.2065, 0.2039, 0.2032, 0.2023, 0.202 , 0.2015, 0.2007, 0.1995,\n",
       "            0.1979, 0.1962, 0.1937, 0.1935, 0.1931, 0.1886, 0.1873, 0.1838,\n",
       "            0.1813, 0.1807, 0.1805, 0.1785, 0.1783, 0.1755, 0.174 , 0.1683,\n",
       "            0.1638, 0.1632, 0.1624, 0.1512, 0.1484, 0.1467], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08208955, 0.08208955,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.09701493, 0.09701493,\n",
       "            0.09701493, 0.09701493, 0.10447761, 0.10447761, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.12686567, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.15671642, 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20895523, 0.21641791, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.2238806 , 0.23134328, 0.23134328, 0.23134328,\n",
       "            0.23880596, 0.23880596, 0.24626866, 0.24626866, 0.24626866,\n",
       "            0.25373134, 0.25373134, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2835821 , 0.2835821 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.29850745, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.33582088, 0.33582088,\n",
       "            0.3432836 , 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.36567163, 0.36567163, 0.36567163, 0.37313432, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3880597 , 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.43283582, 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.46551725, 0.47413793,\n",
       "            0.49137932, 0.5086207 , 0.51724136, 0.51724136, 0.51724136,\n",
       "            0.5258621 , 0.5258621 , 0.5258621 , 0.5258621 , 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.5862069 , 0.5948276 , 0.5948276 , 0.6034483 ,\n",
       "            0.62931037, 0.63793105, 0.63793105, 0.6465517 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.6896552 , 0.69827586,\n",
       "            0.69827586, 0.69827586, 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4553, 0.451 , 0.4482, 0.4438, 0.4404, 0.4397, 0.435 ,\n",
       "            0.4348, 0.4336, 0.4329, 0.4304, 0.4248, 0.424 , 0.4219, 0.4187,\n",
       "            0.4172, 0.4158, 0.4138, 0.4106, 0.4077, 0.4055, 0.4036, 0.403 ,\n",
       "            0.4   , 0.3958, 0.395 , 0.394 , 0.3928, 0.3926, 0.3901, 0.3894,\n",
       "            0.3887, 0.3875, 0.387 , 0.381 , 0.38  , 0.3787, 0.3748, 0.3706,\n",
       "            0.369 , 0.368 , 0.3613, 0.3552, 0.3499, 0.349 , 0.3438, 0.3428,\n",
       "            0.3403, 0.3367, 0.3364, 0.3347, 0.3345, 0.334 , 0.331 , 0.3281,\n",
       "            0.3276, 0.3274, 0.3232, 0.322 , 0.3203, 0.32  , 0.3186, 0.3184,\n",
       "            0.3171, 0.3167, 0.3162, 0.3154, 0.3152, 0.3137, 0.3135, 0.3132,\n",
       "            0.3127, 0.3118, 0.3115, 0.3113, 0.311 , 0.3103, 0.3098, 0.3096,\n",
       "            0.3088, 0.3076, 0.3064, 0.3052, 0.3047, 0.3044, 0.3042, 0.304 ,\n",
       "            0.3032, 0.303 , 0.3027, 0.3022, 0.3015, 0.3013, 0.301 , 0.3008,\n",
       "            0.3005, 0.3003, 0.2996, 0.2993, 0.299 , 0.2983, 0.2974, 0.2969,\n",
       "            0.2964, 0.2961, 0.2957, 0.2952, 0.2942, 0.2937, 0.2932, 0.291 ,\n",
       "            0.289 , 0.2886, 0.2883, 0.2878, 0.2852, 0.285 , 0.2847, 0.284 ,\n",
       "            0.283 , 0.2822, 0.2812, 0.2808, 0.2803, 0.2798, 0.279 , 0.2786,\n",
       "            0.278 , 0.277 , 0.2769, 0.2761, 0.2734, 0.2695, 0.2686, 0.267 ,\n",
       "            0.266 , 0.265 , 0.2646, 0.2642, 0.263 , 0.2622, 0.262 , 0.2605,\n",
       "            0.258 , 0.2566, 0.2563, 0.2534, 0.2522, 0.2507, 0.2505, 0.2478,\n",
       "            0.2448, 0.2444, 0.2411, 0.2406, 0.2397, 0.2386, 0.2383, 0.2379,\n",
       "            0.2375, 0.2366, 0.2355, 0.235 , 0.2334, 0.2325, 0.2313, 0.231 ,\n",
       "            0.2307, 0.2289, 0.2285, 0.2274, 0.2268, 0.2263, 0.2242, 0.2239,\n",
       "            0.223 , 0.2227, 0.2211, 0.2191, 0.218 , 0.2173, 0.2168, 0.2166,\n",
       "            0.215 , 0.2148, 0.2147, 0.2139, 0.2135, 0.2123, 0.2091, 0.209 ,\n",
       "            0.2085, 0.2084, 0.2054, 0.2023, 0.2004, 0.1968, 0.1959, 0.195 ,\n",
       "            0.1941, 0.1929, 0.1913, 0.1893, 0.1871, 0.1853, 0.1772, 0.1771,\n",
       "            0.1755, 0.1636, 0.163 , 0.1622, 0.1594], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.05223881, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.07462686, 0.08208955, 0.08955224, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.1119403 ,\n",
       "            0.11940298, 0.11940298, 0.12686567, 0.12686567, 0.12686567,\n",
       "            0.13432837, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.15671642, 0.1641791 , 0.1641791 , 0.1716418 , 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.20895523, 0.20895523, 0.21641791,\n",
       "            0.21641791, 0.2238806 , 0.23880596, 0.24626866, 0.24626866,\n",
       "            0.25373134, 0.25373134, 0.26119402, 0.26119402, 0.26865673,\n",
       "            0.26865673, 0.2761194 , 0.2761194 , 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.33582088, 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.3880597 , 0.40298507, 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.57462686, 0.58208954,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.7089552 ,\n",
       "            0.7164179 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.54310346, 0.54310346, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.73275864, 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.8103448 , 0.8103448 , 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8362069 , 0.8362069 ,\n",
       "            0.8362069 , 0.8362069 , 0.8448276 , 0.8534483 , 0.8534483 ,\n",
       "            0.86206895, 0.86206895, 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4883, 0.482 , 0.4783, 0.4773, 0.4717, 0.4683, 0.4668,\n",
       "            0.4666, 0.4646, 0.4602, 0.46  , 0.4578, 0.456 , 0.452 , 0.451 ,\n",
       "            0.4492, 0.4465, 0.4402, 0.4314, 0.4307, 0.4302, 0.4277, 0.426 ,\n",
       "            0.4238, 0.4224, 0.4202, 0.4187, 0.4175, 0.4155, 0.4146, 0.4138,\n",
       "            0.4116, 0.4106, 0.4067, 0.4062, 0.4023, 0.402 , 0.4001, 0.3977,\n",
       "            0.397 , 0.3945, 0.39  , 0.3896, 0.3772, 0.371 , 0.3708, 0.3667,\n",
       "            0.3638, 0.3606, 0.3582, 0.358 , 0.3552, 0.3542, 0.3538, 0.3528,\n",
       "            0.3462, 0.344 , 0.3435, 0.3418, 0.3413, 0.3403, 0.3389, 0.3354,\n",
       "            0.3352, 0.3347, 0.3337, 0.3335, 0.3318, 0.3315, 0.3313, 0.331 ,\n",
       "            0.3303, 0.33  , 0.328 , 0.3264, 0.325 , 0.3242, 0.3235, 0.323 ,\n",
       "            0.3228, 0.3213, 0.321 , 0.3208, 0.3206, 0.3203, 0.32  , 0.3196,\n",
       "            0.3188, 0.3184, 0.3179, 0.3154, 0.3152, 0.314 , 0.3137, 0.3132,\n",
       "            0.3125, 0.3118, 0.3093, 0.3088, 0.3086, 0.3076, 0.3074, 0.3066,\n",
       "            0.3064, 0.3062, 0.3057, 0.3052, 0.305 , 0.3047, 0.3044, 0.3037,\n",
       "            0.3035, 0.3027, 0.3022, 0.302 , 0.3018, 0.3013, 0.2998, 0.2993,\n",
       "            0.2986, 0.2979, 0.2947, 0.2944, 0.2942, 0.2935, 0.2932, 0.2915,\n",
       "            0.2913, 0.29  , 0.2896, 0.2888, 0.2876, 0.2874, 0.2852, 0.2837,\n",
       "            0.2834, 0.283 , 0.2812, 0.2795, 0.2788, 0.2769, 0.2764, 0.2754,\n",
       "            0.275 , 0.2744, 0.2734, 0.271 , 0.2705, 0.266 , 0.263 , 0.262 ,\n",
       "            0.2605, 0.2588, 0.258 , 0.2551, 0.255 , 0.2534, 0.2527, 0.2515,\n",
       "            0.249 , 0.2487, 0.248 , 0.2474, 0.247 , 0.244 , 0.2434, 0.2426,\n",
       "            0.2424, 0.2422, 0.2418, 0.241 , 0.2384, 0.2383, 0.2378, 0.2375,\n",
       "            0.2372, 0.2358, 0.2346, 0.2334, 0.2332, 0.2303, 0.2297, 0.2286,\n",
       "            0.2283, 0.2274, 0.2263, 0.2252, 0.2244, 0.2242, 0.224 , 0.223 ,\n",
       "            0.2212, 0.2205, 0.2195, 0.2181, 0.217 , 0.2123, 0.2115, 0.211 ,\n",
       "            0.2096, 0.206 , 0.2059, 0.2053, 0.205 , 0.204 , 0.2015, 0.2006,\n",
       "            0.1993, 0.199 , 0.1984, 0.197 , 0.1924, 0.1891, 0.188 , 0.1871,\n",
       "            0.1842, 0.1821, 0.1724, 0.1683, 0.1484], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.12931034, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.05970149, 0.05970149, 0.05970149, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.07462686, 0.08208955,\n",
       "            0.08208955, 0.08955224, 0.08955224, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.13432837, 0.14179105, 0.14179105, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.15671642, 0.15671642, 0.15671642, 0.1641791 ,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.20895523, 0.21641791, 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.43283582, 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.6268657 , 0.63432837,\n",
       "            0.6492537 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.5603448 ,\n",
       "            0.5689655 , 0.5689655 , 0.57758623, 0.5862069 , 0.6034483 ,\n",
       "            0.62068963, 0.62068963, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.8534483 , 0.8534483 , 0.86206895, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5396, 0.5303, 0.529 , 0.5244, 0.5225, 0.5146, 0.513 ,\n",
       "            0.5127, 0.5083, 0.5073, 0.507 , 0.5063, 0.5054, 0.5024, 0.5005,\n",
       "            0.4932, 0.4827, 0.4795, 0.4756, 0.4727, 0.4707, 0.4666, 0.4634,\n",
       "            0.461 , 0.4602, 0.4595, 0.4573, 0.4563, 0.4534, 0.4517, 0.4514,\n",
       "            0.4504, 0.4492, 0.449 , 0.4478, 0.4475, 0.444 , 0.4438, 0.4426,\n",
       "            0.44  , 0.4326, 0.432 , 0.4265, 0.423 , 0.4177, 0.4082, 0.4048,\n",
       "            0.4026, 0.4019, 0.4004, 0.3975, 0.3962, 0.3958, 0.3926, 0.3906,\n",
       "            0.3877, 0.3865, 0.3809, 0.3733, 0.373 , 0.3728, 0.3726, 0.372 ,\n",
       "            0.371 , 0.3694, 0.369 , 0.3684, 0.3682, 0.368 , 0.3674, 0.3667,\n",
       "            0.3647, 0.3633, 0.3625, 0.3623, 0.362 , 0.3618, 0.359 , 0.358 ,\n",
       "            0.3572, 0.3567, 0.3562, 0.356 , 0.3552, 0.3525, 0.352 , 0.3508,\n",
       "            0.3503, 0.3494, 0.3477, 0.3452, 0.345 , 0.3445, 0.344 , 0.3435,\n",
       "            0.3423, 0.3416, 0.341 , 0.3384, 0.3364, 0.336 , 0.3357, 0.335 ,\n",
       "            0.3345, 0.3335, 0.333 , 0.3325, 0.3323, 0.3313, 0.331 , 0.3298,\n",
       "            0.329 , 0.3289, 0.3281, 0.3274, 0.3264, 0.3254, 0.3245, 0.3235,\n",
       "            0.3223, 0.3218, 0.321 , 0.3203, 0.3188, 0.3186, 0.3179, 0.3171,\n",
       "            0.317 , 0.315 , 0.3147, 0.3145, 0.314 , 0.3132, 0.313 , 0.3127,\n",
       "            0.3118, 0.3115, 0.3113, 0.311 , 0.31  , 0.3096, 0.3057, 0.3054,\n",
       "            0.3052, 0.3047, 0.3035, 0.303 , 0.3025, 0.3005, 0.295 , 0.2932,\n",
       "            0.2925, 0.2903, 0.2898, 0.289 , 0.2883, 0.2876, 0.2874, 0.2856,\n",
       "            0.2852, 0.2803, 0.2798, 0.2795, 0.2776, 0.2773, 0.277 , 0.2766,\n",
       "            0.276 , 0.2756, 0.2734, 0.2732, 0.2725, 0.2722, 0.2698, 0.2688,\n",
       "            0.2664, 0.265 , 0.2642, 0.2627, 0.2625, 0.2622, 0.2603, 0.2595,\n",
       "            0.258 , 0.2573, 0.2563, 0.2556, 0.255 , 0.2546, 0.2542, 0.2534,\n",
       "            0.252 , 0.2502, 0.2483, 0.2449, 0.244 , 0.2417, 0.2394, 0.2383,\n",
       "            0.2379, 0.2375, 0.2374, 0.2367, 0.235 , 0.2334, 0.2332, 0.2325,\n",
       "            0.2323, 0.2302, 0.2263, 0.2233, 0.2211, 0.2207, 0.2186, 0.2185,\n",
       "            0.2158, 0.2128, 0.2114, 0.207 , 0.2048, 0.2037, 0.2017, 0.2012,\n",
       "            0.1989, 0.1964, 0.1896, 0.1824, 0.179 , 0.1716, 0.1368],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.15517241, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05970149, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.13432837,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.17910448, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.35074627, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.5522388 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.6492537 , 0.6567164 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.69827586, 0.70689654,\n",
       "            0.7241379 , 0.7241379 , 0.73275864, 0.7413793 , 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.76724136, 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.87068963, 0.87931037, 0.87931037, 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9396552 , 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5674, 0.5586, 0.555 , 0.5513, 0.5503, 0.539 , 0.5386,\n",
       "            0.5376, 0.536 , 0.5356, 0.5337, 0.533 , 0.529 , 0.5283, 0.523 ,\n",
       "            0.5127, 0.503 , 0.501 , 0.4988, 0.4963, 0.4946, 0.4866, 0.4858,\n",
       "            0.4817, 0.4795, 0.4788, 0.4768, 0.4722, 0.4712, 0.471 , 0.4702,\n",
       "            0.47  , 0.4692, 0.4675, 0.4658, 0.465 , 0.4646, 0.4614, 0.4612,\n",
       "            0.4526, 0.4521, 0.451 , 0.4453, 0.4346, 0.4338, 0.4302, 0.4243,\n",
       "            0.423 , 0.4207, 0.4204, 0.42  , 0.4175, 0.415 , 0.4148, 0.408 ,\n",
       "            0.4067, 0.405 , 0.4016, 0.401 , 0.3987, 0.398 , 0.3975, 0.3972,\n",
       "            0.397 , 0.395 , 0.3945, 0.393 , 0.392 , 0.391 , 0.3901, 0.39  ,\n",
       "            0.3887, 0.386 , 0.3845, 0.3843, 0.383 , 0.382 , 0.3804, 0.379 ,\n",
       "            0.3782, 0.3774, 0.3772, 0.377 , 0.376 , 0.374 , 0.3735, 0.3726,\n",
       "            0.3718, 0.3706, 0.3704, 0.37  , 0.3691, 0.366 , 0.365 , 0.3628,\n",
       "            0.3625, 0.3596, 0.3584, 0.3567, 0.3552, 0.3538, 0.352 , 0.3513,\n",
       "            0.35  , 0.348 , 0.3467, 0.3464, 0.3423, 0.342 , 0.3408, 0.339 ,\n",
       "            0.3381, 0.337 , 0.3367, 0.3364, 0.336 , 0.3345, 0.334 , 0.3337,\n",
       "            0.3328, 0.3313, 0.3308, 0.33  , 0.329 , 0.3289, 0.3284, 0.327 ,\n",
       "            0.3247, 0.3223, 0.3186, 0.3184, 0.3171, 0.3157, 0.3154, 0.315 ,\n",
       "            0.3132, 0.311 , 0.3108, 0.3076, 0.3071, 0.307 , 0.3057, 0.3047,\n",
       "            0.3044, 0.304 , 0.3037, 0.3035, 0.3032, 0.3018, 0.3013, 0.2986,\n",
       "            0.2979, 0.2947, 0.294 , 0.293 , 0.2898, 0.2893, 0.2886, 0.2878,\n",
       "            0.287 , 0.286 , 0.2852, 0.2847, 0.2825, 0.2822, 0.2795, 0.277 ,\n",
       "            0.2764, 0.276 , 0.275 , 0.274 , 0.2737, 0.2734, 0.2732, 0.2722,\n",
       "            0.271 , 0.27  , 0.2698, 0.2695, 0.268 , 0.2673, 0.265 , 0.264 ,\n",
       "            0.2583, 0.2554, 0.2544, 0.2542, 0.2532, 0.2496, 0.2494, 0.2485,\n",
       "            0.2483, 0.2455, 0.2448, 0.2437, 0.2433, 0.2426, 0.2406, 0.2368,\n",
       "            0.233 , 0.2322, 0.2301, 0.2297, 0.2283, 0.2257, 0.2252, 0.22  ,\n",
       "            0.2173, 0.215 , 0.2115, 0.2114, 0.2108, 0.2091, 0.2034, 0.2028,\n",
       "            0.194 , 0.1912, 0.1904, 0.1858, 0.1788, 0.1711, 0.1676, 0.16  ,\n",
       "            0.1249], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.27586207, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.05970149, 0.05970149, 0.05970149, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.07462686, 0.08208955, 0.08208955, 0.08955224,\n",
       "            0.10447761, 0.10447761, 0.10447761, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.3432836 , 0.35074627, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.54310346,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.92241377, 0.9310345 , 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6055, 0.597 , 0.592 , 0.5913, 0.5864, 0.577 , 0.574 ,\n",
       "            0.5737, 0.573 , 0.5723, 0.572 , 0.5684, 0.5654, 0.56  , 0.554 ,\n",
       "            0.5405, 0.5317, 0.5312, 0.531 , 0.53  , 0.52  , 0.5137, 0.5127,\n",
       "            0.511 , 0.51  , 0.507 , 0.506 , 0.503 , 0.5005, 0.5   , 0.4988,\n",
       "            0.4966, 0.4963, 0.493 , 0.4927, 0.4905, 0.4895, 0.488 , 0.4836,\n",
       "            0.4783, 0.4731, 0.4724, 0.4697, 0.4639, 0.4585, 0.4565, 0.453 ,\n",
       "            0.4524, 0.4485, 0.4473, 0.4448, 0.4424, 0.4417, 0.4407, 0.4402,\n",
       "            0.4363, 0.435 , 0.4343, 0.433 , 0.4326, 0.4324, 0.4321, 0.4307,\n",
       "            0.427 , 0.4263, 0.426 , 0.4255, 0.424 , 0.4233, 0.4229, 0.4163,\n",
       "            0.415 , 0.414 , 0.4136, 0.4126, 0.4124, 0.412 , 0.411 , 0.4094,\n",
       "            0.408 , 0.4072, 0.4038, 0.4023, 0.4011, 0.3972, 0.396 , 0.3958,\n",
       "            0.3953, 0.3943, 0.3926, 0.3923, 0.3904, 0.3887, 0.388 , 0.3843,\n",
       "            0.3838, 0.383 , 0.382 , 0.3818, 0.3796, 0.3792, 0.3772, 0.3752,\n",
       "            0.3745, 0.373 , 0.37  , 0.3657, 0.3655, 0.3652, 0.3647, 0.3608,\n",
       "            0.359 , 0.357 , 0.3567, 0.3564, 0.3557, 0.3555, 0.3552, 0.355 ,\n",
       "            0.3538, 0.353 , 0.3525, 0.3516, 0.3489, 0.3484, 0.3467, 0.3452,\n",
       "            0.3447, 0.3425, 0.3413, 0.3398, 0.3372, 0.3367, 0.332 , 0.331 ,\n",
       "            0.3303, 0.33  , 0.3296, 0.3284, 0.3271, 0.327 , 0.3267, 0.326 ,\n",
       "            0.3247, 0.3237, 0.322 , 0.3218, 0.3208, 0.3198, 0.3176, 0.3171,\n",
       "            0.3157, 0.3152, 0.3147, 0.3142, 0.314 , 0.312 , 0.3108, 0.31  ,\n",
       "            0.309 , 0.3079, 0.307 , 0.3057, 0.3054, 0.3052, 0.3008, 0.3   ,\n",
       "            0.2998, 0.298 , 0.2974, 0.2954, 0.2944, 0.294 , 0.2932, 0.293 ,\n",
       "            0.2925, 0.2917, 0.2915, 0.291 , 0.29  , 0.2893, 0.2883, 0.287 ,\n",
       "            0.2842, 0.2832, 0.283 , 0.2827, 0.2773, 0.2766, 0.2756, 0.2747,\n",
       "            0.2737, 0.2732, 0.273 , 0.2712, 0.271 , 0.269 , 0.268 , 0.2634,\n",
       "            0.2627, 0.2625, 0.2615, 0.261 , 0.2563, 0.251 , 0.2466, 0.2458,\n",
       "            0.2438, 0.2413, 0.2394, 0.2355, 0.2319, 0.2316, 0.2268, 0.2246,\n",
       "            0.2239, 0.2238, 0.2191, 0.2098, 0.205 , 0.2035, 0.2012, 0.197 ,\n",
       "            0.1942, 0.1852, 0.1836, 0.182 , 0.1765, 0.1696, 0.1614, 0.1577,\n",
       "            0.1498, 0.1144], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.39655173, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.05970149, 0.05970149,\n",
       "            0.05970149, 0.05970149, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.12686567, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.46268657, 0.47014925,\n",
       "            0.48507464, 0.49253732, 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.5895522 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06896552, 0.0775862 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8103448 , 0.8189655 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6396, 0.6323, 0.628 , 0.6245, 0.618 , 0.6147, 0.609 ,\n",
       "            0.606 , 0.6025, 0.601 , 0.599 , 0.588 , 0.5825, 0.5664, 0.563 ,\n",
       "            0.5625, 0.5596, 0.558 , 0.552 , 0.5435, 0.542 , 0.5396, 0.539 ,\n",
       "            0.536 , 0.534 , 0.5327, 0.5312, 0.53  , 0.5283, 0.527 , 0.5264,\n",
       "            0.5254, 0.5225, 0.5176, 0.5156, 0.513 , 0.5103, 0.51  , 0.5063,\n",
       "            0.505 , 0.5034, 0.503 , 0.4993, 0.4941, 0.49  , 0.4895, 0.4783,\n",
       "            0.4775, 0.4734, 0.473 , 0.4724, 0.472 , 0.471 , 0.47  , 0.4683,\n",
       "            0.4663, 0.4658, 0.4653, 0.4644, 0.4639, 0.462 , 0.4614, 0.4607,\n",
       "            0.4602, 0.4563, 0.456 , 0.453 , 0.4524, 0.452 , 0.4517, 0.4504,\n",
       "            0.45  , 0.4465, 0.4456, 0.4417, 0.441 , 0.4385, 0.4377, 0.4375,\n",
       "            0.4365, 0.4343, 0.4329, 0.4321, 0.4294, 0.4236, 0.4219, 0.4197,\n",
       "            0.4194, 0.4192, 0.4167, 0.4165, 0.4138, 0.4133, 0.412 , 0.4116,\n",
       "            0.4094, 0.4092, 0.4036, 0.4026, 0.402 , 0.4019, 0.3982, 0.3977,\n",
       "            0.3972, 0.397 , 0.3923, 0.3918, 0.391 , 0.3901, 0.3867, 0.3833,\n",
       "            0.3823, 0.3818, 0.3813, 0.381 , 0.3809, 0.378 , 0.3762, 0.3757,\n",
       "            0.375 , 0.3743, 0.3726, 0.3716, 0.3674, 0.3672, 0.3635, 0.3584,\n",
       "            0.3567, 0.3564, 0.356 , 0.3552, 0.3542, 0.354 , 0.3523, 0.352 ,\n",
       "            0.3506, 0.3477, 0.3474, 0.3467, 0.346 , 0.3442, 0.342 , 0.3418,\n",
       "            0.3403, 0.3386, 0.3381, 0.3372, 0.337 , 0.336 , 0.3352, 0.3337,\n",
       "            0.3335, 0.3315, 0.3313, 0.3298, 0.3271, 0.3267, 0.325 , 0.3247,\n",
       "            0.3218, 0.321 , 0.3206, 0.3203, 0.3196, 0.3193, 0.3186, 0.3174,\n",
       "            0.317 , 0.3162, 0.3152, 0.315 , 0.3147, 0.3145, 0.3137, 0.313 ,\n",
       "            0.3123, 0.3115, 0.3113, 0.3093, 0.3076, 0.306 , 0.3057, 0.3025,\n",
       "            0.301 , 0.2957, 0.2952, 0.295 , 0.2932, 0.293 , 0.2917, 0.2903,\n",
       "            0.2898, 0.2886, 0.288 , 0.2856, 0.2827, 0.282 , 0.281 , 0.2788,\n",
       "            0.2747, 0.273 , 0.272 , 0.271 , 0.2688, 0.2673, 0.2654, 0.259 ,\n",
       "            0.2556, 0.2522, 0.2467, 0.2437, 0.241 , 0.236 , 0.2346, 0.2256,\n",
       "            0.2207, 0.2191, 0.2186, 0.2184, 0.2125, 0.2015, 0.1991, 0.1952,\n",
       "            0.1934, 0.1907, 0.1852, 0.1764, 0.1757, 0.1725, 0.1674, 0.1598,\n",
       "            0.1516, 0.1478, 0.1398, 0.1043], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.45689654, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.05970149, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.24626866, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.42537314, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.8448276 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.661  , 0.6533 , 0.649  , 0.6465 , 0.639  , 0.6353 ,\n",
       "            0.6294 , 0.629  , 0.626  , 0.6235 , 0.622  , 0.62   , 0.6187 ,\n",
       "            0.608  , 0.6016 , 0.585  , 0.5806 , 0.58   , 0.5776 , 0.576  ,\n",
       "            0.5703 , 0.569  , 0.56   , 0.559  , 0.5566 , 0.5557 , 0.551  ,\n",
       "            0.5503 , 0.5493 , 0.548  , 0.546  , 0.5444 , 0.543  , 0.5425 ,\n",
       "            0.5415 , 0.5386 , 0.536  , 0.535  , 0.533  , 0.5312 , 0.5283 ,\n",
       "            0.526  , 0.525  , 0.524  , 0.519  , 0.517  , 0.5166 , 0.514  ,\n",
       "            0.506  , 0.5054 , 0.5005 , 0.4998 , 0.4912 , 0.4905 , 0.49   ,\n",
       "            0.4888 , 0.4863 , 0.4858 , 0.4854 , 0.4846 , 0.4844 , 0.4841 ,\n",
       "            0.4814 , 0.4812 , 0.4795 , 0.479  , 0.477  , 0.4756 , 0.475  ,\n",
       "            0.474  , 0.4739 , 0.473  , 0.4724 , 0.4717 , 0.4714 , 0.4705 ,\n",
       "            0.467  , 0.4626 , 0.461  , 0.458  , 0.4575 , 0.4565 , 0.4543 ,\n",
       "            0.4517 , 0.4512 , 0.4468 , 0.442  , 0.436  , 0.4355 , 0.4343 ,\n",
       "            0.43   , 0.428  , 0.4275 , 0.427  , 0.4268 , 0.424  , 0.4224 ,\n",
       "            0.421  , 0.419  , 0.4175 , 0.4172 , 0.416  , 0.4124 , 0.411  ,\n",
       "            0.409  , 0.4062 , 0.4053 , 0.4048 , 0.4045 , 0.4033 , 0.3987 ,\n",
       "            0.396  , 0.3953 , 0.3936 , 0.3884 , 0.388  , 0.3875 , 0.3872 ,\n",
       "            0.387  , 0.3835 , 0.3828 , 0.3818 , 0.381  , 0.38   , 0.3796 ,\n",
       "            0.3767 , 0.3728 , 0.3699 , 0.368  , 0.3657 , 0.3652 , 0.3608 ,\n",
       "            0.3599 , 0.3596 , 0.3586 , 0.358  , 0.357  , 0.3567 , 0.353  ,\n",
       "            0.3513 , 0.349  , 0.3489 , 0.3486 , 0.3457 , 0.3455 , 0.3447 ,\n",
       "            0.3438 , 0.3425 , 0.3416 , 0.3406 , 0.3396 , 0.337  , 0.3362 ,\n",
       "            0.3354 , 0.3347 , 0.333  , 0.3323 , 0.3303 , 0.3289 , 0.327  ,\n",
       "            0.3264 , 0.3254 , 0.3235 , 0.322  , 0.3218 , 0.321  , 0.3203 ,\n",
       "            0.32   , 0.3193 , 0.3184 , 0.3179 , 0.3176 , 0.3174 , 0.3171 ,\n",
       "            0.3164 , 0.316  , 0.3154 , 0.3142 , 0.3113 , 0.309  , 0.3057 ,\n",
       "            0.3047 , 0.3042 , 0.3035 , 0.303  , 0.3027 , 0.2998 , 0.298  ,\n",
       "            0.297  , 0.2964 , 0.2961 , 0.2954 , 0.2944 , 0.2908 , 0.2903 ,\n",
       "            0.2893 , 0.2844 , 0.2842 , 0.2834 , 0.2832 , 0.281  , 0.278  ,\n",
       "            0.2715 , 0.2712 , 0.2698 , 0.269  , 0.2673 , 0.2664 , 0.2651 ,\n",
       "            0.2556 , 0.254  , 0.2524 , 0.2415 , 0.2388 , 0.2355 , 0.2299 ,\n",
       "            0.2286 , 0.2191 , 0.214  , 0.2134 , 0.212  , 0.2114 , 0.205  ,\n",
       "            0.1934 , 0.1927 , 0.1866 , 0.1848 , 0.1838 , 0.1765 , 0.1685 ,\n",
       "            0.1674 , 0.1632 , 0.158  , 0.1504 , 0.1418 , 0.138  , 0.1299 ,\n",
       "            0.09485], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.5603448, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05970149, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08955224, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.29310346, 0.30172414, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.86206895, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.684 , 0.676 , 0.672 , 0.6685, 0.6606, 0.6567, 0.652 ,\n",
       "            0.6514, 0.647 , 0.6445, 0.6426, 0.6416, 0.6406, 0.628 , 0.6216,\n",
       "            0.6035, 0.601 , 0.6006, 0.5996, 0.597 , 0.5947, 0.589 , 0.5786,\n",
       "            0.5776, 0.5747, 0.574 , 0.5693, 0.5684, 0.567 , 0.5664, 0.5635,\n",
       "            0.5625, 0.5615, 0.561 , 0.5605, 0.56  , 0.557 , 0.554 , 0.5503,\n",
       "            0.549 , 0.5464, 0.541 , 0.54  , 0.5396, 0.536 , 0.5356, 0.5312,\n",
       "            0.531 , 0.527 , 0.5244, 0.5146, 0.5137, 0.513 , 0.511 , 0.509 ,\n",
       "            0.508 , 0.506 , 0.5044, 0.5015, 0.501 , 0.5005, 0.499 , 0.4988,\n",
       "            0.4968, 0.4966, 0.496 , 0.4946, 0.4934, 0.4917, 0.4912, 0.4893,\n",
       "            0.4875, 0.487 , 0.4866, 0.4863, 0.483 , 0.48  , 0.4768, 0.4763,\n",
       "            0.4753, 0.4705, 0.47  , 0.4695, 0.4644, 0.4626, 0.4534, 0.4512,\n",
       "            0.4478, 0.4463, 0.443 , 0.44  , 0.4397, 0.4387, 0.4382, 0.4377,\n",
       "            0.4333, 0.4329, 0.4321, 0.4307, 0.4292, 0.429 , 0.4275, 0.4229,\n",
       "            0.4211, 0.4197, 0.4175, 0.4165, 0.415 , 0.4138, 0.4114, 0.41  ,\n",
       "            0.4084, 0.3997, 0.3992, 0.399 , 0.3977, 0.3972, 0.3916, 0.391 ,\n",
       "            0.3909, 0.3901, 0.3894, 0.3882, 0.3857, 0.384 , 0.3806, 0.3804,\n",
       "            0.3723, 0.3718, 0.371 , 0.367 , 0.366 , 0.3643, 0.363 , 0.3628,\n",
       "            0.3613, 0.3604, 0.3599, 0.3572, 0.357 , 0.3567, 0.3547, 0.3506,\n",
       "            0.3499, 0.349 , 0.3472, 0.3445, 0.344 , 0.3433, 0.343 , 0.3428,\n",
       "            0.3408, 0.3396, 0.339 , 0.3362, 0.3347, 0.3335, 0.3333, 0.3328,\n",
       "            0.3323, 0.3318, 0.331 , 0.3306, 0.3298, 0.3293, 0.328 , 0.3271,\n",
       "            0.327 , 0.3262, 0.3247, 0.3245, 0.3242, 0.3228, 0.3206, 0.3203,\n",
       "            0.3186, 0.3171, 0.317 , 0.3162, 0.315 , 0.3127, 0.31  , 0.3093,\n",
       "            0.3086, 0.3074, 0.3052, 0.3047, 0.3044, 0.3035, 0.3022, 0.3018,\n",
       "            0.301 , 0.3   , 0.2998, 0.2947, 0.2932, 0.2925, 0.2915, 0.2886,\n",
       "            0.2864, 0.2805, 0.2803, 0.2734, 0.2722, 0.2666, 0.2656, 0.2646,\n",
       "            0.2622, 0.2615, 0.26  , 0.2585, 0.2477, 0.235 , 0.2332, 0.2289,\n",
       "            0.2229, 0.2218, 0.2113, 0.2065, 0.2063, 0.2047, 0.2035, 0.1967,\n",
       "            0.1849, 0.1838, 0.1772, 0.1759, 0.1753, 0.1666, 0.1597, 0.158 ,\n",
       "            0.1532, 0.1482, 0.1404, 0.1318, 0.1279, 0.1198, 0.0854],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00746269, dtype=float32),\n",
       "    'tpr': array(0.7413793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.08955224, 0.09701493,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41791046,\n",
       "            0.42537314, 0.4477612 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.86206895, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.715  , 0.707  , 0.7036 , 0.6978 , 0.69   , 0.688  ,\n",
       "            0.6826 , 0.682  , 0.677  , 0.6733 , 0.6714 , 0.6553 , 0.6494 ,\n",
       "            0.641  , 0.6304 , 0.63   , 0.6294 , 0.629  , 0.6245 , 0.62   ,\n",
       "            0.6177 , 0.607  , 0.606  , 0.6045 , 0.6025 , 0.6    , 0.5996 ,\n",
       "            0.598  , 0.597  , 0.596  , 0.5938 , 0.593  , 0.5894 , 0.588  ,\n",
       "            0.5874 , 0.587  , 0.5864 , 0.5845 , 0.5767 , 0.5747 , 0.574  ,\n",
       "            0.573  , 0.5703 , 0.5684 , 0.5674 , 0.5625 , 0.562  , 0.561  ,\n",
       "            0.556  , 0.5547 , 0.55   , 0.549  , 0.5474 , 0.546  , 0.5444 ,\n",
       "            0.544  , 0.5435 , 0.538  , 0.535  , 0.534  , 0.533  , 0.5327 ,\n",
       "            0.5303 , 0.528  , 0.526  , 0.5244 , 0.5215 , 0.5205 , 0.519  ,\n",
       "            0.5166 , 0.5146 , 0.5137 , 0.511  , 0.5107 , 0.5093 , 0.508  ,\n",
       "            0.5073 , 0.507  , 0.5044 , 0.502  , 0.5005 , 0.498  , 0.4963 ,\n",
       "            0.4937 , 0.493  , 0.482  , 0.4775 , 0.4758 , 0.4702 , 0.4685 ,\n",
       "            0.4666 , 0.466  , 0.4622 , 0.4595 , 0.459  , 0.4583 , 0.457  ,\n",
       "            0.455  , 0.4536 , 0.4507 , 0.447  , 0.4463 , 0.446  , 0.4458 ,\n",
       "            0.4424 , 0.4375 , 0.4363 , 0.436  , 0.4346 , 0.4336 , 0.432  ,\n",
       "            0.4287 , 0.4224 , 0.4204 , 0.42   , 0.4194 , 0.4158 , 0.413  ,\n",
       "            0.4126 , 0.4104 , 0.4082 , 0.408  , 0.4055 , 0.4038 , 0.403  ,\n",
       "            0.4011 , 0.3972 , 0.3945 , 0.3877 , 0.387  , 0.384  , 0.3828 ,\n",
       "            0.3826 , 0.3813 , 0.3801 , 0.3796 , 0.3777 , 0.3762 , 0.3755 ,\n",
       "            0.3699 , 0.3691 , 0.3647 , 0.363  , 0.3628 , 0.3623 , 0.3606 ,\n",
       "            0.3591 , 0.3557 , 0.3552 , 0.3545 , 0.3538 , 0.3535 , 0.353  ,\n",
       "            0.3516 , 0.351  , 0.3503 , 0.3494 , 0.3489 , 0.3452 , 0.3445 ,\n",
       "            0.343  , 0.3423 , 0.3403 , 0.3398 , 0.3364 , 0.335  , 0.3345 ,\n",
       "            0.3342 , 0.3337 , 0.331  , 0.3286 , 0.3281 , 0.327  , 0.3262 ,\n",
       "            0.326  , 0.3252 , 0.3237 , 0.3235 , 0.3228 , 0.321  , 0.3186 ,\n",
       "            0.3167 , 0.3164 , 0.3135 , 0.313  , 0.3118 , 0.3093 , 0.307  ,\n",
       "            0.3052 , 0.3032 , 0.302  , 0.2998 , 0.2993 , 0.2944 , 0.289  ,\n",
       "            0.2888 , 0.279  , 0.2786 , 0.2769 , 0.2705 , 0.264  , 0.2637 ,\n",
       "            0.263  , 0.2593 , 0.2566 , 0.243  , 0.2295 , 0.2292 , 0.2235 ,\n",
       "            0.2173 , 0.2161 , 0.2043 , 0.2013 , 0.1993 , 0.1985 , 0.1965 ,\n",
       "            0.1898 , 0.1787 , 0.1752 , 0.1687 , 0.1682 , 0.1665 , 0.1575 ,\n",
       "            0.1517 , 0.1495 , 0.1436 , 0.1393 , 0.1307 , 0.1223 , 0.1184 ,\n",
       "            0.1103 , 0.07654], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00746269, dtype=float32),\n",
       "    'tpr': array(0.80172414, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.40298507, 0.41044775, 0.42537314, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5671642 ,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.6465517 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.87931037, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.744  , 0.737  , 0.7324 , 0.726  , 0.7183 , 0.7173 ,\n",
       "            0.711  , 0.7056 , 0.7017 , 0.7    , 0.6997 , 0.6826 , 0.677  ,\n",
       "            0.6587 , 0.658  , 0.657  , 0.6553 , 0.652  , 0.6465 , 0.645  ,\n",
       "            0.6416 , 0.635  , 0.6343 , 0.6333 , 0.6304 , 0.63   , 0.626  ,\n",
       "            0.6255 , 0.6245 , 0.621  , 0.6187 , 0.6157 , 0.6147 , 0.614  ,\n",
       "            0.6113 , 0.611  , 0.6084 , 0.606  , 0.605  , 0.6045 , 0.602  ,\n",
       "            0.6    , 0.599  , 0.597  , 0.586  , 0.585  , 0.5825 , 0.5815 ,\n",
       "            0.5796 , 0.577  , 0.576  , 0.5757 , 0.5747 , 0.569  , 0.5684 ,\n",
       "            0.567  , 0.565  , 0.564  , 0.563  , 0.5576 , 0.555  , 0.5503 ,\n",
       "            0.55   , 0.549  , 0.5444 , 0.544  , 0.5405 , 0.5366 , 0.536  ,\n",
       "            0.5356 , 0.5347 , 0.534  , 0.5303 , 0.5293 , 0.5283 , 0.526  ,\n",
       "            0.5254 , 0.5244 , 0.52   , 0.514  , 0.5093 , 0.5063 , 0.5015 ,\n",
       "            0.499  , 0.493  , 0.4922 , 0.4863 , 0.485  , 0.4846 , 0.4812 ,\n",
       "            0.4795 , 0.479  , 0.4778 , 0.4766 , 0.4712 , 0.471  , 0.4707 ,\n",
       "            0.464  , 0.4634 , 0.4612 , 0.4604 , 0.4597 , 0.4583 , 0.4573 ,\n",
       "            0.4553 , 0.4548 , 0.4524 , 0.4456 , 0.444  , 0.4429 , 0.4407 ,\n",
       "            0.44   , 0.4395 , 0.436  , 0.4353 , 0.4348 , 0.434  , 0.429  ,\n",
       "            0.4219 , 0.4202 , 0.419  , 0.418  , 0.4177 , 0.416  , 0.4136 ,\n",
       "            0.4092 , 0.4077 , 0.405  , 0.4033 , 0.4023 , 0.402  , 0.4006 ,\n",
       "            0.4001 , 0.398  , 0.3977 , 0.3948 , 0.3909 , 0.388  , 0.3855 ,\n",
       "            0.3828 , 0.3813 , 0.3804 , 0.379  , 0.3787 , 0.3782 , 0.3777 ,\n",
       "            0.3772 , 0.3752 , 0.3743 , 0.3735 , 0.3708 , 0.367  , 0.3638 ,\n",
       "            0.3635 , 0.3623 , 0.3616 , 0.3613 , 0.36   , 0.3591 , 0.3564 ,\n",
       "            0.3542 , 0.353  , 0.3523 , 0.3513 , 0.351  , 0.3489 , 0.3474 ,\n",
       "            0.3472 , 0.3464 , 0.3455 , 0.345  , 0.3442 , 0.342  , 0.339  ,\n",
       "            0.3389 , 0.3354 , 0.3352 , 0.3347 , 0.3286 , 0.3281 , 0.327  ,\n",
       "            0.326  , 0.3242 , 0.3215 , 0.3198 , 0.3196 , 0.3171 , 0.3132 ,\n",
       "            0.3083 , 0.3062 , 0.302  , 0.3003 , 0.2996 , 0.2961 , 0.294  ,\n",
       "            0.288  , 0.278  , 0.268  , 0.2634 , 0.2622 , 0.261  , 0.256  ,\n",
       "            0.2534 , 0.239  , 0.2266 , 0.2246 , 0.2186 , 0.212  , 0.2108 ,\n",
       "            0.1978 , 0.1973 , 0.1934 , 0.193  , 0.1901 , 0.1841 , 0.1731 ,\n",
       "            0.167  , 0.1627 , 0.1599 , 0.1584 , 0.1488 , 0.1437 , 0.1422 ,\n",
       "            0.1348 , 0.1317 , 0.1217 , 0.1138 , 0.1099 , 0.10175, 0.06903],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00746269, dtype=float32),\n",
       "    'tpr': array(0.87931037, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.08208955, 0.08208955, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5970149 , 0.6044776 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.67241377, 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.772  , 0.7646 , 0.7603 , 0.7534 , 0.7466 , 0.7456 ,\n",
       "            0.7393 , 0.739  , 0.734  , 0.729  , 0.7285 , 0.7275 , 0.727  ,\n",
       "            0.71   , 0.709  , 0.7036 , 0.686  , 0.6855 , 0.685  , 0.68   ,\n",
       "            0.6787 , 0.676  , 0.673  , 0.672  , 0.67   , 0.6646 , 0.6626 ,\n",
       "            0.661  , 0.6577 , 0.654  , 0.652  , 0.6514 , 0.6484 , 0.6445 ,\n",
       "            0.643  , 0.6416 , 0.6406 , 0.64   , 0.6396 , 0.639  , 0.638  ,\n",
       "            0.6377 , 0.6353 , 0.6343 , 0.6333 , 0.63   , 0.626  , 0.625  ,\n",
       "            0.6167 , 0.614  , 0.6123 , 0.612  , 0.61   , 0.6074 , 0.607  ,\n",
       "            0.601  , 0.599  , 0.597  , 0.5967 , 0.594  , 0.5938 , 0.5923 ,\n",
       "            0.586  , 0.5835 , 0.5776 , 0.5757 , 0.574  , 0.5713 , 0.5684 ,\n",
       "            0.568  , 0.565  , 0.563  , 0.561  , 0.5596 , 0.559  , 0.558  ,\n",
       "            0.557  , 0.5557 , 0.55   , 0.5493 , 0.5464 , 0.542  , 0.536  ,\n",
       "            0.5356 , 0.534  , 0.5312 , 0.522  , 0.517  , 0.5166 , 0.5103 ,\n",
       "            0.508  , 0.5073 , 0.505  , 0.5034 , 0.501  , 0.499  , 0.4983 ,\n",
       "            0.497  , 0.4958 , 0.4907 , 0.4858 , 0.4846 , 0.4812 , 0.481  ,\n",
       "            0.4792 , 0.479  , 0.4788 , 0.4773 , 0.4768 , 0.4697 , 0.4695 ,\n",
       "            0.4663 , 0.466  , 0.4617 , 0.4612 , 0.46   , 0.4597 , 0.459  ,\n",
       "            0.4573 , 0.456  , 0.446  , 0.4421 , 0.4382 , 0.4363 , 0.4326 ,\n",
       "            0.4314 , 0.431  , 0.4307 , 0.4292 , 0.427  , 0.4268 , 0.426  ,\n",
       "            0.4243 , 0.4214 , 0.421  , 0.4202 , 0.419  , 0.418  , 0.4143 ,\n",
       "            0.406  , 0.4033 , 0.4011 , 0.4001 , 0.4    , 0.398  , 0.397  ,\n",
       "            0.3965 , 0.3962 , 0.396  , 0.3953 , 0.395  , 0.3936 , 0.3914 ,\n",
       "            0.386  , 0.3855 , 0.3843 , 0.3828 , 0.3816 , 0.3813 , 0.3804 ,\n",
       "            0.3777 , 0.3755 , 0.3706 , 0.3694 , 0.3687 , 0.3684 , 0.368  ,\n",
       "            0.3672 , 0.367  , 0.3652 , 0.3628 , 0.362  , 0.3591 , 0.3582 ,\n",
       "            0.3572 , 0.3564 , 0.3555 , 0.3545 , 0.3525 , 0.3477 , 0.3467 ,\n",
       "            0.3457 , 0.344  , 0.3433 , 0.339  , 0.3381 , 0.337  , 0.3298 ,\n",
       "            0.329  , 0.3235 , 0.322  , 0.3174 , 0.3152 , 0.3145 , 0.3135 ,\n",
       "            0.3103 , 0.3018 , 0.3005 , 0.2996 , 0.2937 , 0.2874 , 0.2766 ,\n",
       "            0.2664 , 0.2622 , 0.2607 , 0.258  , 0.253  , 0.25   , 0.2344 ,\n",
       "            0.2233 , 0.2194 , 0.2135 , 0.2065 , 0.2051 , 0.1925 , 0.191  ,\n",
       "            0.1876 , 0.1864 , 0.1835 , 0.178  , 0.1669 , 0.1587 , 0.1561 ,\n",
       "            0.1515 , 0.1503 , 0.1403 , 0.1359 , 0.1344 , 0.126  , 0.1239 ,\n",
       "            0.113  , 0.1054 , 0.10156, 0.0935 , 0.06177], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.02238806, dtype=float32),\n",
       "    'tpr': array(0.8965517, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.46268657, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.6810345 , 0.6896552 , 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.86206895, 0.87068963, 0.87931037, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.7905 , 0.7812 , 0.7764 , 0.7725 , 0.7646 , 0.7617 ,\n",
       "            0.755  , 0.7515 , 0.7476 , 0.7456 , 0.745  , 0.7437 , 0.7314 ,\n",
       "            0.729  , 0.722  , 0.701  , 0.7    , 0.6997 , 0.697  , 0.6963 ,\n",
       "            0.691  , 0.6885 , 0.687  , 0.685  , 0.6807 , 0.6763 , 0.6724 ,\n",
       "            0.669  , 0.666  , 0.6655 , 0.663  , 0.6616 , 0.6587 , 0.657  ,\n",
       "            0.6567 , 0.6562 , 0.6553 , 0.652  , 0.6514 , 0.651  , 0.647  ,\n",
       "            0.642  , 0.6416 , 0.6387 , 0.632  , 0.631  , 0.63   , 0.6274 ,\n",
       "            0.627  , 0.625  , 0.624  , 0.6226 , 0.622  , 0.6157 , 0.6143 ,\n",
       "            0.6133 , 0.611  , 0.6104 , 0.609  , 0.6084 , 0.6025 , 0.5996 ,\n",
       "            0.5913 , 0.586  , 0.5854 , 0.5815 , 0.579  , 0.5786 , 0.578  ,\n",
       "            0.5767 , 0.5757 , 0.5737 , 0.5728 , 0.5703 , 0.5693 , 0.569  ,\n",
       "            0.5684 , 0.5635 , 0.563  , 0.5576 , 0.554  , 0.548  , 0.5464 ,\n",
       "            0.544  , 0.5396 , 0.534  , 0.5283 , 0.527  , 0.5195 , 0.5176 ,\n",
       "            0.514  , 0.512  , 0.5083 , 0.508  , 0.5054 , 0.504  , 0.5005 ,\n",
       "            0.4998 , 0.493  , 0.4915 , 0.4905 , 0.4902 , 0.4885 , 0.4878 ,\n",
       "            0.4849 , 0.4846 , 0.484  , 0.4778 , 0.4714 , 0.468  , 0.4678 ,\n",
       "            0.4675 , 0.4666 , 0.466  , 0.4656 , 0.4653 , 0.4592 , 0.4585 ,\n",
       "            0.4512 , 0.4434 , 0.4414 , 0.441  , 0.4385 , 0.4373 , 0.4343 ,\n",
       "            0.4329 , 0.4324 , 0.4307 , 0.4297 , 0.429  , 0.4285 , 0.4268 ,\n",
       "            0.425  , 0.4204 , 0.4187 , 0.418  , 0.4133 , 0.4104 , 0.4023 ,\n",
       "            0.4011 , 0.4    , 0.3997 , 0.3994 , 0.3984 , 0.3965 , 0.3955 ,\n",
       "            0.3953 , 0.394  , 0.3938 , 0.388  , 0.3865 , 0.385  , 0.3833 ,\n",
       "            0.381  , 0.3801 , 0.3794 , 0.3774 , 0.3772 , 0.3765 , 0.3733 ,\n",
       "            0.3696 , 0.3691 , 0.3684 , 0.3672 , 0.3667 , 0.3652 , 0.3647 ,\n",
       "            0.3638 , 0.363  , 0.3625 , 0.3591 , 0.3586 , 0.3584 , 0.356  ,\n",
       "            0.3535 , 0.3528 , 0.3516 , 0.3464 , 0.3462 , 0.3435 , 0.3433 ,\n",
       "            0.3428 , 0.342  , 0.3403 , 0.3389 , 0.3376 , 0.331  , 0.3293 ,\n",
       "            0.328  , 0.3276 , 0.3213 , 0.3174 , 0.3132 , 0.309  , 0.3083 ,\n",
       "            0.3074 , 0.297  , 0.2966 , 0.2957 , 0.2896 , 0.283  , 0.272  ,\n",
       "            0.2612 , 0.2585 , 0.2573 , 0.2512 , 0.2462 , 0.243  , 0.2272 ,\n",
       "            0.2185 , 0.2114 , 0.2058 , 0.1989 , 0.1973 , 0.187  , 0.1824 ,\n",
       "            0.1804 , 0.1781 , 0.1752 , 0.1705 , 0.16   , 0.149  , 0.1421 ,\n",
       "            0.141  , 0.1307 , 0.1271 , 0.1263 , 0.1166 , 0.1158 , 0.10376,\n",
       "            0.09686, 0.093  , 0.0851 , 0.0549 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04477612, dtype=float32),\n",
       "    'tpr': array(0.9310345, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.05223881, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6551724 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.86206895,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.9310345 , 0.9310345 ,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.812  , 0.8027 , 0.798  , 0.795  , 0.7866 , 0.7837 ,\n",
       "            0.777  , 0.773  , 0.77   , 0.768  , 0.7666 , 0.7656 , 0.757  ,\n",
       "            0.7495 , 0.7446 , 0.7227 , 0.722  , 0.7217 , 0.7197 , 0.719  ,\n",
       "            0.7188 , 0.713  , 0.7104 , 0.7085 , 0.705  , 0.6978 , 0.6973 ,\n",
       "            0.694  , 0.69   , 0.6875 , 0.6865 , 0.684  , 0.683  , 0.6807 ,\n",
       "            0.68   , 0.6797 , 0.679  , 0.678  , 0.6777 , 0.6763 , 0.6753 ,\n",
       "            0.674  , 0.672  , 0.671  , 0.6694 , 0.6636 , 0.662  , 0.659  ,\n",
       "            0.6543 , 0.653  , 0.652  , 0.6494 , 0.648  , 0.647  , 0.6436 ,\n",
       "            0.643  , 0.642  , 0.6367 , 0.6357 , 0.6343 , 0.6323 , 0.6313 ,\n",
       "            0.63   , 0.6235 , 0.622  , 0.6206 , 0.6113 , 0.6045 , 0.604  ,\n",
       "            0.6006 , 0.598  , 0.5977 , 0.595  , 0.5947 , 0.5923 , 0.5913 ,\n",
       "            0.5894 , 0.5884 , 0.5874 , 0.5864 , 0.582  , 0.581  , 0.5757 ,\n",
       "            0.566  , 0.5654 , 0.564  , 0.5615 , 0.5576 , 0.5513 , 0.5454 ,\n",
       "            0.5435 , 0.5356 , 0.533  , 0.53   , 0.5283 , 0.5234 , 0.523  ,\n",
       "            0.5205 , 0.5195 , 0.515  , 0.5083 , 0.507  , 0.503  , 0.5015 ,\n",
       "            0.499  , 0.498  , 0.4907 , 0.4854 , 0.4817 , 0.4807 , 0.4802 ,\n",
       "            0.48   , 0.4797 , 0.479  , 0.4722 , 0.4714 , 0.462  , 0.4539 ,\n",
       "            0.4534 , 0.4517 , 0.4482 , 0.4478 , 0.4429 , 0.4426 , 0.4424 ,\n",
       "            0.4417 , 0.4404 , 0.4387 , 0.4375 , 0.4363 , 0.4312 , 0.4292 ,\n",
       "            0.4287 , 0.428  , 0.4258 , 0.4185 , 0.411  , 0.4104 , 0.4094 ,\n",
       "            0.409  , 0.4082 , 0.4072 , 0.407  , 0.4067 , 0.4055 , 0.4038 ,\n",
       "            0.4026 , 0.401  , 0.397  , 0.3918 , 0.3904 , 0.3887 , 0.388  ,\n",
       "            0.3877 , 0.386  , 0.3853 , 0.3804 , 0.3782 , 0.376  , 0.3752 ,\n",
       "            0.3745 , 0.3743 , 0.374  , 0.3713 , 0.371  , 0.3706 , 0.3682 ,\n",
       "            0.3667 , 0.3652 , 0.3625 , 0.3604 , 0.36   , 0.3599 , 0.3596 ,\n",
       "            0.359  , 0.3523 , 0.3506 , 0.3484 , 0.346  , 0.3455 , 0.345  ,\n",
       "            0.3445 , 0.343  , 0.3384 , 0.3362 , 0.3345 , 0.3296 , 0.3274 ,\n",
       "            0.3235 , 0.3206 , 0.3142 , 0.313  , 0.31   , 0.307  , 0.3057 ,\n",
       "            0.294  , 0.2937 , 0.2927 , 0.288  , 0.281  , 0.268  , 0.258  ,\n",
       "            0.255  , 0.254  , 0.2463 , 0.2411 , 0.2379 , 0.2207 , 0.2137 ,\n",
       "            0.205  , 0.1995 , 0.1923 , 0.1907 , 0.1814 , 0.1748 , 0.1737 ,\n",
       "            0.1709 , 0.1678 , 0.1636 , 0.1532 , 0.142  , 0.1409 , 0.1339 ,\n",
       "            0.1329 , 0.1226 , 0.12024, 0.1186 , 0.1086 , 0.1082 , 0.0959 ,\n",
       "            0.0891 , 0.08527, 0.07764, 0.04877], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04477612, dtype=float32),\n",
       "    'tpr': array(0.9655172, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.05970149, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.6044776 , 0.6119403 , 0.619403  , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5948276 , 0.6034483 , 0.61206895, 0.62931037,\n",
       "            0.6465517 , 0.6637931 , 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.7758621 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.8315 , 0.8223 , 0.8174 , 0.8154 , 0.8076 , 0.8037 ,\n",
       "            0.797  , 0.7964 , 0.793  , 0.7915 , 0.789  , 0.787  , 0.785  ,\n",
       "            0.7812 , 0.7725 , 0.766  , 0.744  , 0.743  , 0.7427 , 0.7417 ,\n",
       "            0.7407 , 0.7383 , 0.734  , 0.7334 , 0.729  , 0.7285 , 0.718  ,\n",
       "            0.7144 , 0.7114 , 0.7075 , 0.7065 , 0.7046 , 0.7036 , 0.7007 ,\n",
       "            0.6997 , 0.698  , 0.6978 , 0.6973 , 0.6963 , 0.6934 , 0.693  ,\n",
       "            0.692  , 0.6846 , 0.6836 , 0.679  , 0.678  , 0.6763 , 0.6753 ,\n",
       "            0.674  , 0.6714 , 0.669  , 0.6665 , 0.6636 , 0.6616 , 0.6597 ,\n",
       "            0.657  , 0.6562 , 0.6543 , 0.654  , 0.6465 , 0.6436 , 0.633  ,\n",
       "            0.6255 , 0.623  , 0.62   , 0.6167 , 0.616  , 0.6133 , 0.613  ,\n",
       "            0.6113 , 0.61   , 0.608  , 0.6064 , 0.6045 , 0.6035 , 0.6006 ,\n",
       "            0.5957 , 0.584  , 0.5815 , 0.5776 , 0.5703 , 0.5645 , 0.5625 ,\n",
       "            0.554  , 0.551  , 0.5483 , 0.5464 , 0.546  , 0.5405 , 0.539  ,\n",
       "            0.537  , 0.5356 , 0.5317 , 0.5303 , 0.526  , 0.524  , 0.521  ,\n",
       "            0.519  , 0.517  , 0.5156 , 0.5127 , 0.504  , 0.4988 , 0.4963 ,\n",
       "            0.496  , 0.4956 , 0.495  , 0.4937 , 0.4932 , 0.485  , 0.4844 ,\n",
       "            0.4744 , 0.4668 , 0.465  , 0.464  , 0.4604 , 0.4592 , 0.4556 ,\n",
       "            0.4543 , 0.454  , 0.4539 , 0.4536 , 0.4524 , 0.4517 , 0.4495 ,\n",
       "            0.4487 , 0.4421 , 0.4397 , 0.4395 , 0.4392 , 0.4385 , 0.4275 ,\n",
       "            0.4229 , 0.4214 , 0.4207 , 0.42   , 0.4187 , 0.4185 , 0.4172 ,\n",
       "            0.4155 , 0.4153 , 0.4114 , 0.4097 , 0.4058 , 0.4011 , 0.4006 ,\n",
       "            0.3972 , 0.397  , 0.3962 , 0.3958 , 0.394  , 0.3936 , 0.3887 ,\n",
       "            0.388  , 0.3862 , 0.3853 , 0.3848 , 0.384  , 0.3813 , 0.3804 ,\n",
       "            0.3777 , 0.3774 , 0.3772 , 0.3762 , 0.3743 , 0.3699 , 0.3691 ,\n",
       "            0.3687 , 0.3657 , 0.3652 , 0.3638 , 0.3591 , 0.3582 , 0.357  ,\n",
       "            0.35   , 0.3484 , 0.3474 , 0.3462 , 0.341  , 0.3394 , 0.3308 ,\n",
       "            0.3303 , 0.3286 , 0.3242 , 0.3208 , 0.3193 , 0.3093 , 0.3054 ,\n",
       "            0.3047 , 0.2935 , 0.2925 , 0.2922 , 0.2856 , 0.2783 , 0.2664 ,\n",
       "            0.2551 , 0.2546 , 0.2534 , 0.2422 , 0.2368 , 0.2335 , 0.2158 ,\n",
       "            0.2115 , 0.199  , 0.194  , 0.1865 , 0.1849 , 0.178  , 0.169  ,\n",
       "            0.1672 , 0.1646 , 0.1614 , 0.1582 , 0.1481 , 0.1366 , 0.1328 ,\n",
       "            0.1259 , 0.1254 , 0.11456, 0.1122 , 0.10156, 0.1007 , 0.0882 ,\n",
       "            0.0825 , 0.0788 , 0.0708 , 0.04337], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.08208955, dtype=float32),\n",
       "    'tpr': array(0.9913793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.05223881, 0.05970149,\n",
       "            0.05970149, 0.07462686, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.10447761, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.1637931 , 0.1724138 ,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.5258621 , 0.54310346, 0.55172414,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.8477 , 0.8384 , 0.834  , 0.833  , 0.825  , 0.8203 ,\n",
       "            0.814  , 0.8135 , 0.81   , 0.8096 , 0.807  , 0.805  , 0.8037 ,\n",
       "            0.8022 , 0.7915 , 0.7847 , 0.767  , 0.762  , 0.7607 , 0.76   ,\n",
       "            0.7593 , 0.757  , 0.753  , 0.7524 , 0.7466 , 0.736  , 0.7354 ,\n",
       "            0.732  , 0.7305 , 0.728  , 0.727  , 0.7246 , 0.724  , 0.7236 ,\n",
       "            0.722  , 0.721  , 0.7207 , 0.7188 , 0.7183 , 0.7163 , 0.716  ,\n",
       "            0.714  , 0.7114 , 0.709  , 0.7036 , 0.702  , 0.701  , 0.6987 ,\n",
       "            0.6973 , 0.697  , 0.6963 , 0.6943 , 0.689  , 0.6885 , 0.6875 ,\n",
       "            0.6826 , 0.6816 , 0.679  , 0.678  , 0.6763 , 0.669  , 0.666  ,\n",
       "            0.659  , 0.654  , 0.646  , 0.641  , 0.639  , 0.6387 , 0.6377 ,\n",
       "            0.637  , 0.636  , 0.633  , 0.632  , 0.63   , 0.6284 , 0.628  ,\n",
       "            0.6235 , 0.622  , 0.62   , 0.6147 , 0.6025 , 0.6016 , 0.6    ,\n",
       "            0.597  , 0.596  , 0.59   , 0.582  , 0.58   , 0.5713 , 0.566  ,\n",
       "            0.565  , 0.5635 , 0.559  , 0.5547 , 0.5537 , 0.5522 , 0.549  ,\n",
       "            0.542  , 0.541  , 0.5396 , 0.5366 , 0.533  , 0.5327 , 0.531  ,\n",
       "            0.5303 , 0.5244 , 0.519  , 0.5103 , 0.51   , 0.5093 , 0.506  ,\n",
       "            0.5034 , 0.4956 , 0.4946 , 0.4844 , 0.4775 , 0.4739 , 0.4736 ,\n",
       "            0.473  , 0.4712 , 0.467  , 0.4658 , 0.4636 , 0.4626 , 0.4622 ,\n",
       "            0.4602 , 0.4558 , 0.4504 , 0.45   , 0.4475 , 0.4473 , 0.4463 ,\n",
       "            0.4375 , 0.432  , 0.4302 , 0.4287 , 0.4277 , 0.4275 , 0.4263 ,\n",
       "            0.4255 , 0.4246 , 0.424  , 0.4211 , 0.4175 , 0.416  , 0.4119 ,\n",
       "            0.4087 , 0.4067 , 0.403  , 0.4028 , 0.402  , 0.4019 , 0.3994 ,\n",
       "            0.3992 , 0.3977 , 0.3948 , 0.394  , 0.3928 , 0.392  , 0.3918 ,\n",
       "            0.3909 , 0.3877 , 0.3867 , 0.382  , 0.3816 , 0.3809 , 0.3774 ,\n",
       "            0.375  , 0.3748 , 0.374  , 0.3735 , 0.371  , 0.3687 , 0.3667 ,\n",
       "            0.364  , 0.362  , 0.3613 , 0.3525 , 0.3516 , 0.3503 , 0.3496 ,\n",
       "            0.348  , 0.3433 , 0.3425 , 0.3413 , 0.3335 , 0.333  , 0.3284 ,\n",
       "            0.3247 , 0.3235 , 0.322  , 0.3071 , 0.3047 , 0.302  , 0.2913 ,\n",
       "            0.29   , 0.2898 , 0.2842 , 0.2766 , 0.263  , 0.2522 , 0.252  ,\n",
       "            0.251  , 0.2375 , 0.2322 , 0.2286 , 0.2101 , 0.2075 , 0.1931 ,\n",
       "            0.1879 , 0.1804 , 0.1787 , 0.1729 , 0.1636 , 0.1599 , 0.158  ,\n",
       "            0.1547 , 0.1517 , 0.1421 , 0.1304 , 0.1251 , 0.1184 , 0.1178 ,\n",
       "            0.10706, 0.1058 , 0.1052 , 0.09485, 0.0935 , 0.0818 , 0.076  ,\n",
       "            0.0724 , 0.0644 , 0.0386 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.10447761, dtype=float32),\n",
       "    'tpr': array(0.9913793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.05970149, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.1119403 ,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.29104477, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.18103448, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.35344827,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.4051724 , 0.41379312,\n",
       "            0.43103448, 0.43965518, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.6810345 , 0.6896552 , 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.8667 , 0.859  , 0.855  , 0.853  , 0.8457 , 0.843  ,\n",
       "            0.836  , 0.8354 , 0.831  , 0.8306 , 0.828  , 0.8257 , 0.8247 ,\n",
       "            0.8125 , 0.806  , 0.795  , 0.792  , 0.784  , 0.7837 , 0.782  ,\n",
       "            0.779  , 0.7734 , 0.771  , 0.7603 , 0.7593 , 0.757  , 0.756  ,\n",
       "            0.755  , 0.7524 , 0.7505 , 0.75   , 0.749  , 0.7466 , 0.746  ,\n",
       "            0.7417 , 0.7393 , 0.7383 , 0.734  , 0.733  , 0.727  , 0.7256 ,\n",
       "            0.7246 , 0.722  , 0.721  , 0.7183 , 0.7124 , 0.711  , 0.7104 ,\n",
       "            0.71   , 0.7075 , 0.7056 , 0.704  , 0.703  , 0.7026 , 0.697  ,\n",
       "            0.6934 , 0.682  , 0.678  , 0.6733 , 0.668  , 0.6646 , 0.6636 ,\n",
       "            0.663  , 0.6616 , 0.6606 , 0.66   , 0.657  , 0.6562 , 0.656  ,\n",
       "            0.6514 , 0.65   , 0.6475 , 0.646  , 0.6445 , 0.6426 , 0.631  ,\n",
       "            0.6294 , 0.6284 , 0.623  , 0.6143 , 0.614  , 0.607  , 0.5986 ,\n",
       "            0.591  , 0.5903 , 0.5874 , 0.5835 , 0.581  , 0.5757 , 0.575  ,\n",
       "            0.5723 , 0.57   , 0.5693 , 0.569  , 0.5674 , 0.559  , 0.5557 ,\n",
       "            0.554  , 0.553  , 0.551  , 0.5503 , 0.548  , 0.54   , 0.5386 ,\n",
       "            0.537  , 0.5356 , 0.532  , 0.531  , 0.5215 , 0.52   , 0.5186 ,\n",
       "            0.5015 , 0.5    , 0.4956 , 0.4922 , 0.491  , 0.4893 , 0.489  ,\n",
       "            0.4866 , 0.486  , 0.4836 , 0.4824 , 0.4812 , 0.4773 , 0.4731 ,\n",
       "            0.4717 , 0.4702 , 0.466  , 0.4658 , 0.4578 , 0.453  , 0.4524 ,\n",
       "            0.451  , 0.4507 , 0.45   , 0.4473 , 0.436  , 0.4355 , 0.4343 ,\n",
       "            0.434  , 0.4312 , 0.4304 , 0.4272 , 0.425  , 0.4243 , 0.4233 ,\n",
       "            0.4214 , 0.42   , 0.4182 , 0.4172 , 0.4165 , 0.4155 , 0.4153 ,\n",
       "            0.4138 , 0.4111 , 0.4102 , 0.4053 , 0.4036 , 0.4006 , 0.4001 ,\n",
       "            0.4    , 0.3962 , 0.3953 , 0.3877 , 0.3872 , 0.3862 , 0.3828 ,\n",
       "            0.3823 , 0.3801 , 0.38   , 0.379  , 0.3718 , 0.3616 , 0.36   ,\n",
       "            0.3562 , 0.3552 , 0.3547 , 0.3533 , 0.352  , 0.3462 , 0.346  ,\n",
       "            0.344  , 0.3345 , 0.3293 , 0.3271 , 0.3064 , 0.305  , 0.3013 ,\n",
       "            0.2905 , 0.2893 , 0.289  , 0.2832 , 0.2754 , 0.2612 , 0.251  ,\n",
       "            0.2502 , 0.2496 , 0.234  , 0.2283 , 0.2247 , 0.2053 , 0.2048 ,\n",
       "            0.188  , 0.1827 , 0.1749 , 0.1733 , 0.1683 , 0.159  , 0.1531 ,\n",
       "            0.1519 , 0.1484 , 0.1464 , 0.1368 , 0.12494, 0.118  , 0.11127,\n",
       "            0.111  , 0.10016, 0.0993 , 0.0991 , 0.0888 , 0.0868 , 0.07587,\n",
       "            0.0702 , 0.0667 , 0.05865, 0.03442], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.14179105, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.10447761, 0.1119403 , 0.12686567, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6810345 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.877  , 0.868  , 0.8643 , 0.864  , 0.857  , 0.8555 ,\n",
       "            0.851  , 0.845  , 0.8447 , 0.843  , 0.842  , 0.839  , 0.836  ,\n",
       "            0.8345 , 0.8257 , 0.82   , 0.8193 , 0.817  , 0.81   , 0.8047 ,\n",
       "            0.7974 , 0.7954 , 0.795  , 0.7944 , 0.7935 , 0.7866 , 0.7847 ,\n",
       "            0.782  , 0.7817 , 0.7812 , 0.7754 , 0.772  , 0.7715 , 0.771  ,\n",
       "            0.7695 , 0.767  , 0.766  , 0.7603 , 0.7593 , 0.759  , 0.7583 ,\n",
       "            0.7573 , 0.755  , 0.754  , 0.752  , 0.7515 , 0.751  , 0.75   ,\n",
       "            0.7495 , 0.7476 , 0.746  , 0.7446 , 0.742  , 0.7397 , 0.7383 ,\n",
       "            0.737  , 0.7363 , 0.7334 , 0.7314 , 0.731  , 0.7305 , 0.7295 ,\n",
       "            0.724  , 0.7227 , 0.719  , 0.7163 , 0.715  , 0.705  , 0.6963 ,\n",
       "            0.6924 , 0.6895 , 0.686  , 0.684  , 0.6826 , 0.682  , 0.681  ,\n",
       "            0.678  , 0.6743 , 0.674  , 0.6733 , 0.6704 , 0.6665 , 0.6646 ,\n",
       "            0.664  , 0.661  , 0.6562 , 0.6543 , 0.6514 , 0.65   , 0.6475 ,\n",
       "            0.6465 , 0.6367 , 0.6274 , 0.6265 , 0.6235 , 0.6177 , 0.61   ,\n",
       "            0.609  , 0.599  , 0.5986 , 0.5903 , 0.59   , 0.5874 , 0.5854 ,\n",
       "            0.584  , 0.5835 , 0.58   , 0.578  , 0.5723 , 0.5713 , 0.562  ,\n",
       "            0.561  , 0.5557 , 0.5537 , 0.553  , 0.5522 , 0.548  , 0.547  ,\n",
       "            0.5366 , 0.533  , 0.5317 , 0.5293 , 0.5225 , 0.5215 , 0.5107 ,\n",
       "            0.5083 , 0.504  , 0.5024 , 0.5015 , 0.4993 , 0.498  , 0.4934 ,\n",
       "            0.488  , 0.4868 , 0.486  , 0.4858 , 0.4841 , 0.4734 , 0.4702 ,\n",
       "            0.47   , 0.4697 , 0.4646 , 0.4636 , 0.4604 , 0.4592 , 0.4585 ,\n",
       "            0.4575 , 0.454  , 0.4487 , 0.4485 , 0.4468 , 0.4397 , 0.4368 ,\n",
       "            0.4363 , 0.4355 , 0.4312 , 0.4294 , 0.426  , 0.4211 , 0.421  ,\n",
       "            0.4207 , 0.4204 , 0.4187 , 0.4185 , 0.4177 , 0.417  , 0.4158 ,\n",
       "            0.414  , 0.4094 , 0.4065 , 0.4048 , 0.401  , 0.3997 , 0.3982 ,\n",
       "            0.39   , 0.3896 , 0.3872 , 0.387  , 0.3862 , 0.3853 , 0.3848 ,\n",
       "            0.3838 , 0.376  , 0.3733 , 0.3667 , 0.3623 , 0.3604 , 0.3562 ,\n",
       "            0.3545 , 0.3538 , 0.3533 , 0.3528 , 0.348  , 0.342  , 0.3403 ,\n",
       "            0.3376 , 0.3289 , 0.326  , 0.3066 , 0.3042 , 0.2983 , 0.2874 ,\n",
       "            0.2866 , 0.2861 , 0.2837 , 0.2751 , 0.257  , 0.2489 , 0.2471 ,\n",
       "            0.2458 , 0.2302 , 0.224  , 0.2205 , 0.1998 , 0.1995 , 0.183  ,\n",
       "            0.1772 , 0.1693 , 0.1675 , 0.1621 , 0.1534 , 0.1465 , 0.1458 ,\n",
       "            0.142  , 0.14   , 0.1302 , 0.1186 , 0.11127, 0.1045 , 0.1043 ,\n",
       "            0.0937 , 0.0935 , 0.0925 , 0.0824 , 0.0804 , 0.0702 , 0.0643 ,\n",
       "            0.06085, 0.0532 , 0.03044], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.18656716, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.10447761, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.0775862 , 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.35344827, 0.36206895, 0.37931034,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.45689654, 0.46551725, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.63793105,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6810345 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.892  , 0.8843 , 0.8804 , 0.875  , 0.8735 , 0.868  ,\n",
       "            0.8623 , 0.861  , 0.859  , 0.857  , 0.854  , 0.8525 , 0.844  ,\n",
       "            0.841  , 0.839  , 0.8384 , 0.832  , 0.826  , 0.8164 , 0.8145 ,\n",
       "            0.8135 , 0.8125 , 0.8076 , 0.8057 , 0.805  , 0.8047 , 0.801  ,\n",
       "            0.798  , 0.7944 , 0.794  , 0.791  , 0.79   , 0.7876 , 0.7866 ,\n",
       "            0.782  , 0.7812 , 0.7793 , 0.778  , 0.7754 , 0.7744 , 0.7734 ,\n",
       "            0.772  , 0.771  , 0.7695 , 0.766  , 0.7656 , 0.765  , 0.7607 ,\n",
       "            0.76   , 0.7593 , 0.7573 , 0.7544 , 0.7534 , 0.7524 , 0.746  ,\n",
       "            0.745  , 0.743  , 0.7363 , 0.736  , 0.7285 , 0.719  , 0.7163 ,\n",
       "            0.7095 , 0.7065 , 0.706  , 0.704  , 0.7017 , 0.6973 , 0.6953 ,\n",
       "            0.6943 , 0.6934 , 0.6875 , 0.687  , 0.686  , 0.682  , 0.677  ,\n",
       "            0.6753 , 0.6743 , 0.673  , 0.6714 , 0.6685 , 0.659  , 0.65   ,\n",
       "            0.649  , 0.6396 , 0.639  , 0.632  , 0.631  , 0.6206 , 0.619  ,\n",
       "            0.6104 , 0.61   , 0.607  , 0.6055 , 0.6035 , 0.5996 , 0.599  ,\n",
       "            0.5933 , 0.592  , 0.591  , 0.58   , 0.579  , 0.5747 , 0.5737 ,\n",
       "            0.573  , 0.5723 , 0.5674 , 0.5664 , 0.555  , 0.5513 , 0.548  ,\n",
       "            0.5474 , 0.5396 , 0.539  , 0.5273 , 0.526  , 0.5215 , 0.521  ,\n",
       "            0.52   , 0.518  , 0.517  , 0.5146 , 0.511  , 0.5073 , 0.502  ,\n",
       "            0.5    , 0.4998 , 0.489  , 0.4854 , 0.4849 , 0.482  , 0.4802 ,\n",
       "            0.477  , 0.476  , 0.4749 , 0.474  , 0.4705 , 0.4626 , 0.4612 ,\n",
       "            0.461  , 0.4531 , 0.452  , 0.4492 , 0.4448 , 0.4446 , 0.4443 ,\n",
       "            0.4392 , 0.436  , 0.4353 , 0.434  , 0.4338 , 0.4336 , 0.4333 ,\n",
       "            0.4307 , 0.4304 , 0.4302 , 0.4285 , 0.424  , 0.4204 , 0.4172 ,\n",
       "            0.415  , 0.4143 , 0.4116 , 0.4106 , 0.4094 , 0.401  , 0.4    ,\n",
       "            0.3984 , 0.396  , 0.3958 , 0.3945 , 0.391  , 0.3894 , 0.3857 ,\n",
       "            0.378  , 0.3765 , 0.3684 , 0.3652 , 0.365  , 0.364  , 0.3628 ,\n",
       "            0.359  , 0.357  , 0.353  , 0.3508 , 0.34   , 0.3298 , 0.3286 ,\n",
       "            0.3074 , 0.3044 , 0.2974 , 0.287  , 0.2856 , 0.2834 , 0.2747 ,\n",
       "            0.2554 , 0.2477 , 0.246  , 0.2448 , 0.2268 , 0.2205 , 0.2167 ,\n",
       "            0.197  , 0.1948 , 0.1781 , 0.1724 , 0.1641 , 0.1624 , 0.1577 ,\n",
       "            0.1492 , 0.1399 , 0.1396 , 0.1359 , 0.1344 , 0.1252 , 0.1134 ,\n",
       "            0.1047 , 0.0981 , 0.0979 , 0.088  , 0.0873 , 0.0869 , 0.07684,\n",
       "            0.07434, 0.0649 , 0.0591 , 0.05582, 0.0484 , 0.02701],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.20149253, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.73275864, 0.7413793 , 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.88793105, 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.9741379 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.906  , 0.8984 , 0.895  , 0.894  , 0.891  , 0.888  ,\n",
       "            0.882  , 0.877  , 0.8745 , 0.8726 , 0.8696 , 0.8677 , 0.8613 ,\n",
       "            0.858  , 0.856  , 0.8506 , 0.8438 , 0.835  , 0.832  , 0.8315 ,\n",
       "            0.83   , 0.829  , 0.8247 , 0.824  , 0.8237 , 0.8228 , 0.8184 ,\n",
       "            0.816  , 0.8125 , 0.8086 , 0.8066 , 0.8057 , 0.805  , 0.8003 ,\n",
       "            0.7993 , 0.7964 , 0.796  , 0.7944 , 0.794  , 0.793  , 0.792  ,\n",
       "            0.7905 , 0.79   , 0.7876 , 0.785  , 0.7837 , 0.7827 , 0.7803 ,\n",
       "            0.78   , 0.779  , 0.7773 , 0.7744 , 0.7734 , 0.7725 , 0.7715 ,\n",
       "            0.77   , 0.7656 , 0.764  , 0.763  , 0.7563 , 0.755  , 0.746  ,\n",
       "            0.738  , 0.736  , 0.7285 , 0.7266 , 0.7246 , 0.724  , 0.723  ,\n",
       "            0.722  , 0.719  , 0.717  , 0.7153 , 0.714  , 0.712  , 0.711  ,\n",
       "            0.7056 , 0.705  , 0.6973 , 0.6934 , 0.693  , 0.692  , 0.6895 ,\n",
       "            0.6865 , 0.6777 , 0.6685 , 0.666  , 0.6567 , 0.6562 , 0.649  ,\n",
       "            0.6475 , 0.6377 , 0.636  , 0.628  , 0.625  , 0.6245 , 0.622  ,\n",
       "            0.62   , 0.6196 , 0.617  , 0.6143 , 0.609  , 0.6084 , 0.608  ,\n",
       "            0.602  , 0.597  , 0.596  , 0.589  , 0.5864 , 0.586  , 0.583  ,\n",
       "            0.5654 , 0.5635 , 0.562  , 0.5557 , 0.5503 , 0.55   , 0.5405 ,\n",
       "            0.533  , 0.532  , 0.5312 , 0.5303 , 0.5283 , 0.523  , 0.5215 ,\n",
       "            0.5137 , 0.5127 , 0.512  , 0.51   , 0.5083 , 0.4968 , 0.4954 ,\n",
       "            0.4927 , 0.4922 , 0.491  , 0.4897 , 0.488  , 0.486  , 0.4841 ,\n",
       "            0.484  , 0.482  , 0.4788 , 0.4714 , 0.4683 , 0.4673 , 0.4602 ,\n",
       "            0.4592 , 0.4558 , 0.4531 , 0.4517 , 0.4487 , 0.4443 , 0.4414 ,\n",
       "            0.4402 , 0.4395 , 0.4387 , 0.4382 , 0.4377 , 0.4375 , 0.4363 ,\n",
       "            0.435  , 0.4338 , 0.4333 , 0.431  , 0.4255 , 0.4243 , 0.422  ,\n",
       "            0.4177 , 0.4163 , 0.4133 , 0.412  , 0.4053 , 0.403  , 0.4019 ,\n",
       "            0.4014 , 0.3975 , 0.3972 , 0.396  , 0.3865 , 0.3828 , 0.377  ,\n",
       "            0.3718 , 0.3677 , 0.3643 , 0.364  , 0.3623 , 0.362  , 0.361  ,\n",
       "            0.353  , 0.3516 , 0.3499 , 0.3416 , 0.3328 , 0.3298 , 0.3079 ,\n",
       "            0.3042 , 0.296  , 0.2866 , 0.2852 , 0.2842 , 0.2827 , 0.2737 ,\n",
       "            0.2537 , 0.2462 , 0.246  , 0.2449 , 0.223  , 0.2167 , 0.2128 ,\n",
       "            0.1956 , 0.1903 , 0.1733 , 0.1676 , 0.1593 , 0.1575 , 0.1545 ,\n",
       "            0.1459 , 0.134  , 0.1335 , 0.1301 , 0.1295 , 0.1214 , 0.10913,\n",
       "            0.0986 , 0.0922 , 0.09204, 0.0828 , 0.082  , 0.08136, 0.0721 ,\n",
       "            0.06903, 0.0601 , 0.0546 , 0.05145, 0.04428, 0.0241 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.26119402, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.09701493, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.12686567, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.13793103, 0.14655173, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.69827586, 0.70689654, 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.88793105, 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9165 , 0.9097 , 0.907  , 0.9062 , 0.906  , 0.9004 ,\n",
       "            0.894  , 0.89   , 0.8896 , 0.889  , 0.887  , 0.8857 , 0.8823 ,\n",
       "            0.8804 , 0.877  , 0.8755 , 0.87   , 0.8623 , 0.8516 , 0.8467 ,\n",
       "            0.846  , 0.8457 , 0.8447 , 0.8438 , 0.8403 , 0.837  , 0.8335 ,\n",
       "            0.833  , 0.8325 , 0.824  , 0.8223 , 0.822  , 0.821  , 0.817  ,\n",
       "            0.8164 , 0.815  , 0.814  , 0.812  , 0.811  , 0.81   , 0.8086 ,\n",
       "            0.8066 , 0.806  , 0.8057 , 0.8037 , 0.803  , 0.8022 , 0.7993 ,\n",
       "            0.799  , 0.7964 , 0.796  , 0.795  , 0.7935 , 0.788  , 0.786  ,\n",
       "            0.7856 , 0.7812 , 0.7734 , 0.7715 , 0.7686 , 0.7603 , 0.7593 ,\n",
       "            0.751  , 0.7466 , 0.745  , 0.7446 , 0.7427 , 0.7417 , 0.7393 ,\n",
       "            0.7334 , 0.7305 , 0.7275 , 0.7236 , 0.7227 , 0.714  , 0.7134 ,\n",
       "            0.712  , 0.71   , 0.7095 , 0.709  , 0.7065 , 0.699  , 0.6904 ,\n",
       "            0.688  , 0.678  , 0.672  , 0.67   , 0.6685 , 0.657  , 0.655  ,\n",
       "            0.6484 , 0.6426 , 0.642  , 0.6406 , 0.638  , 0.6357 , 0.63   ,\n",
       "            0.629  , 0.628  , 0.6274 , 0.616  , 0.614  , 0.6123 , 0.607  ,\n",
       "            0.606  , 0.6055 , 0.602  , 0.601  , 0.5786 , 0.5757 , 0.5684 ,\n",
       "            0.5635 , 0.5576 , 0.5547 , 0.5493 , 0.5483 , 0.5454 , 0.5444 ,\n",
       "            0.5396 , 0.5327 , 0.5303 , 0.526  , 0.5244 , 0.5215 , 0.52   ,\n",
       "            0.5083 , 0.508  , 0.5044 , 0.504  , 0.502  , 0.501  , 0.5005 ,\n",
       "            0.4983 , 0.496  , 0.4927 , 0.483  , 0.4788 , 0.4778 , 0.472  ,\n",
       "            0.471  , 0.466  , 0.4639 , 0.4614 , 0.458  , 0.454  , 0.4531 ,\n",
       "            0.452  , 0.4517 , 0.4504 , 0.4495 , 0.4475 , 0.4473 , 0.4463 ,\n",
       "            0.4446 , 0.444  , 0.4424 , 0.4385 , 0.436  , 0.4312 , 0.431  ,\n",
       "            0.4282 , 0.4263 , 0.4211 , 0.4204 , 0.4133 , 0.4124 , 0.4116 ,\n",
       "            0.4092 , 0.4062 , 0.4043 , 0.404  , 0.401  , 0.3926 , 0.3865 ,\n",
       "            0.3833 , 0.3752 , 0.371  , 0.3704 , 0.3694 , 0.3677 , 0.3647 ,\n",
       "            0.3635 , 0.358  , 0.356  , 0.3547 , 0.343  , 0.3345 , 0.3296 ,\n",
       "            0.3074 , 0.303  , 0.2935 , 0.2847 , 0.2832 , 0.2817 , 0.2815 ,\n",
       "            0.272  , 0.2507 , 0.2441 , 0.244  , 0.243  , 0.2185 , 0.212  ,\n",
       "            0.208  , 0.1924 , 0.1846 , 0.1676 , 0.162  , 0.1536 , 0.1517 ,\n",
       "            0.1497 , 0.1411 , 0.1274 , 0.127  , 0.12366, 0.12335, 0.11615,\n",
       "            0.10394, 0.09204, 0.0859 , 0.0857 , 0.0771 , 0.07684, 0.0753 ,\n",
       "            0.0667 , 0.06323, 0.0552 , 0.04977, 0.04672, 0.03995, 0.02116],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.29104477, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.07462686, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.4224138 , 0.43103448, 0.44827586, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5344828 ,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9243 , 0.9233 , 0.917  , 0.9146 , 0.913  , 0.909  ,\n",
       "            0.901  , 0.9    , 0.8975 , 0.897  , 0.896  , 0.8955 , 0.895  ,\n",
       "            0.894  , 0.891  , 0.889  , 0.8867 , 0.8823 , 0.8804 , 0.866  ,\n",
       "            0.8643 , 0.8623 , 0.858  , 0.8574 , 0.856  , 0.8545 , 0.854  ,\n",
       "            0.8535 , 0.853  , 0.851  , 0.843  , 0.8423 , 0.838  , 0.837  ,\n",
       "            0.8364 , 0.8354 , 0.834  , 0.832  , 0.8315 , 0.8296 , 0.828  ,\n",
       "            0.8276 , 0.8267 , 0.823  , 0.8223 , 0.821  , 0.8203 , 0.8184 ,\n",
       "            0.8174 , 0.8154 , 0.8145 , 0.814  , 0.8105 , 0.809  , 0.8086 ,\n",
       "            0.797  , 0.794  , 0.791  , 0.7847 , 0.784  , 0.7827 , 0.7744 ,\n",
       "            0.7695 , 0.769  , 0.7686 , 0.767  , 0.764  , 0.762  , 0.758  ,\n",
       "            0.7534 , 0.75   , 0.7476 , 0.743  , 0.738  , 0.7373 , 0.736  ,\n",
       "            0.7344 , 0.734  , 0.7314 , 0.73   , 0.7227 , 0.721  , 0.72   ,\n",
       "            0.713  , 0.7095 , 0.699  , 0.6914 , 0.6895 , 0.6816 , 0.6777 ,\n",
       "            0.6704 , 0.669  , 0.6626 , 0.6606 , 0.659  , 0.656  , 0.6504 ,\n",
       "            0.649  , 0.6484 , 0.648  , 0.6475 , 0.64   , 0.6294 , 0.627  ,\n",
       "            0.6245 , 0.6235 , 0.623  , 0.6216 , 0.621  , 0.6206 , 0.6104 ,\n",
       "            0.591  , 0.5835 , 0.581  , 0.5747 , 0.5703 , 0.5693 , 0.567  ,\n",
       "            0.566  , 0.565  , 0.564  , 0.563  , 0.5596 , 0.558  , 0.554  ,\n",
       "            0.543  , 0.535  , 0.5347 , 0.534  , 0.5244 , 0.524  , 0.5176 ,\n",
       "            0.516  , 0.5156 , 0.512  , 0.51   , 0.5093 , 0.5073 , 0.507  ,\n",
       "            0.504  , 0.5034 , 0.4985 , 0.4817 , 0.4807 , 0.4805 , 0.4783 ,\n",
       "            0.473  , 0.4714 , 0.4685 , 0.4614 , 0.4597 , 0.4585 , 0.4583 ,\n",
       "            0.458  , 0.4568 , 0.4563 , 0.4556 , 0.4517 , 0.4485 , 0.446  ,\n",
       "            0.4458 , 0.4456 , 0.4438 , 0.4429 , 0.4421 , 0.4363 , 0.4338 ,\n",
       "            0.4324 , 0.4233 , 0.423  , 0.4216 , 0.4192 , 0.4172 , 0.4155 ,\n",
       "            0.4124 , 0.409  , 0.407  , 0.4026 , 0.3914 , 0.3884 , 0.382  ,\n",
       "            0.3813 , 0.3772 , 0.3726 , 0.3677 , 0.3674 , 0.3647 , 0.3645 ,\n",
       "            0.3582 , 0.3564 , 0.356  , 0.3481 , 0.334  , 0.3298 , 0.311  ,\n",
       "            0.3013 , 0.2917 , 0.2837 , 0.282  , 0.2805 , 0.28   , 0.2734 ,\n",
       "            0.2471 , 0.2441 , 0.2411 , 0.2399 , 0.2156 , 0.2086 , 0.2045 ,\n",
       "            0.188  , 0.1803 , 0.1635 , 0.1572 , 0.1488 , 0.147  , 0.1442 ,\n",
       "            0.136  , 0.1222 , 0.122  , 0.11816, 0.11755, 0.11066, 0.0986 ,\n",
       "            0.0866 , 0.0806 , 0.0805 , 0.07306, 0.07196, 0.0703 , 0.0619 ,\n",
       "            0.05856, 0.05127, 0.04553, 0.04257, 0.03616, 0.01865],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.29850745, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.1119403 ,\n",
       "            0.11940298, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.48507464,\n",
       "            0.49253732, 0.5074627 , 0.51492536, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.934  , 0.9336 , 0.9272 , 0.9253 , 0.9233 , 0.92   ,\n",
       "            0.912  , 0.9116 , 0.909  , 0.9087 , 0.908  , 0.9077 , 0.9067 ,\n",
       "            0.9033 , 0.9023 , 0.9014 , 0.9004 , 0.8955 , 0.8936 , 0.8813 ,\n",
       "            0.8794 , 0.879  , 0.878  , 0.8735 , 0.8716 , 0.8706 , 0.8696 ,\n",
       "            0.868  , 0.8667 , 0.866  , 0.8584 , 0.857  , 0.8545 , 0.8535 ,\n",
       "            0.8525 , 0.8506 , 0.85   , 0.8467 , 0.846  , 0.8447 , 0.844  ,\n",
       "            0.8433 , 0.8384 , 0.838  , 0.8374 , 0.837  , 0.836  , 0.8354 ,\n",
       "            0.8345 , 0.834  , 0.8325 , 0.831  , 0.8296 , 0.8276 , 0.8257 ,\n",
       "            0.825  , 0.8247 , 0.8125 , 0.81   , 0.8086 , 0.8027 , 0.801  ,\n",
       "            0.8003 , 0.792  , 0.787  , 0.7866 , 0.786  , 0.785  , 0.782  ,\n",
       "            0.7803 , 0.775  , 0.7725 , 0.768  , 0.764  , 0.76   , 0.7544 ,\n",
       "            0.752  , 0.751  , 0.7485 , 0.7476 , 0.7407 , 0.7383 , 0.738  ,\n",
       "            0.7373 , 0.731  , 0.728  , 0.718  , 0.7095 , 0.708  , 0.6997 ,\n",
       "            0.6963 , 0.688  , 0.6855 , 0.6807 , 0.678  , 0.6763 , 0.6724 ,\n",
       "            0.667  , 0.666  , 0.6655 , 0.665  , 0.664  , 0.6562 , 0.645  ,\n",
       "            0.6445 , 0.6416 , 0.641  , 0.6406 , 0.6377 , 0.6367 , 0.6255 ,\n",
       "            0.6064 , 0.598  , 0.5957 , 0.59   , 0.5845 , 0.584  , 0.5835 ,\n",
       "            0.5806 , 0.5796 , 0.5786 , 0.575  , 0.5713 , 0.569  , 0.558  ,\n",
       "            0.549  , 0.548  , 0.547  , 0.5366 , 0.53   , 0.5293 , 0.5283 ,\n",
       "            0.5254 , 0.5244 , 0.5234 , 0.523  , 0.5205 , 0.5195 , 0.517  ,\n",
       "            0.515  , 0.5093 , 0.4937 , 0.4917 , 0.4915 , 0.489  , 0.4846 ,\n",
       "            0.4817 , 0.4783 , 0.4727 , 0.471  , 0.4702 , 0.469  , 0.4683 ,\n",
       "            0.468  , 0.4666 , 0.4626 , 0.4583 , 0.4553 , 0.455  , 0.4539 ,\n",
       "            0.4534 , 0.4517 , 0.4514 , 0.444  , 0.4424 , 0.4312 , 0.4302 ,\n",
       "            0.4265 , 0.425  , 0.4197 , 0.4155 , 0.415  , 0.4102 , 0.3987 ,\n",
       "            0.3938 , 0.388  , 0.3843 , 0.38   , 0.3792 , 0.373  , 0.3706 ,\n",
       "            0.3704 , 0.3691 , 0.3647 , 0.3623 , 0.358  , 0.3484 , 0.3386 ,\n",
       "            0.33   , 0.3098 , 0.3013 , 0.2917 , 0.2817 , 0.2815 , 0.28   ,\n",
       "            0.2786 , 0.2712 , 0.2463 , 0.2415 , 0.2413 , 0.2402 , 0.2114 ,\n",
       "            0.2045 , 0.2002 , 0.1866 , 0.1765 , 0.1583 , 0.1525 , 0.1438 ,\n",
       "            0.1418 , 0.141  , 0.1321 , 0.11633, 0.11615, 0.1126 , 0.1124 ,\n",
       "            0.1069 , 0.0945 , 0.08124, 0.07544, 0.0749 , 0.06793, 0.0677 ,\n",
       "            0.0649 , 0.0577 , 0.0537 , 0.0469 , 0.0417 , 0.0389 , 0.03278,\n",
       "            0.01646], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.30597016, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.07462686, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.4224138 , 0.43965518, 0.44827586, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.7413793 , 0.75      , 0.7586207 , 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.943  , 0.941  , 0.9346 , 0.933  , 0.9307 , 0.928  ,\n",
       "            0.921  , 0.9204 , 0.92   , 0.9194 , 0.9175 , 0.9165 , 0.916  ,\n",
       "            0.914  , 0.912  , 0.911  , 0.9097 , 0.9077 , 0.904  , 0.8945 ,\n",
       "            0.8926 , 0.892  , 0.8896 , 0.887  , 0.884  , 0.8823 , 0.882  ,\n",
       "            0.88   , 0.8784 , 0.878  , 0.8765 , 0.8726 , 0.8687 , 0.8677 ,\n",
       "            0.867  , 0.865  , 0.8623 , 0.861  , 0.8594 , 0.859  , 0.858  ,\n",
       "            0.8574 , 0.857  , 0.8564 , 0.8525 , 0.85   , 0.8496 , 0.849  ,\n",
       "            0.8477 , 0.847  , 0.8457 , 0.845  , 0.844  , 0.843  , 0.841  ,\n",
       "            0.8384 , 0.837  , 0.836  , 0.824  , 0.8228 , 0.8164 , 0.816  ,\n",
       "            0.8125 , 0.8076 , 0.803  , 0.8022 , 0.8003 , 0.798  , 0.7964 ,\n",
       "            0.7915 , 0.785  , 0.784  , 0.7783 , 0.772  , 0.7705 , 0.7676 ,\n",
       "            0.7656 , 0.7637 , 0.763  , 0.7573 , 0.75   , 0.7485 , 0.748  ,\n",
       "            0.747  , 0.7437 , 0.7334 , 0.725  , 0.723  , 0.712  , 0.711  ,\n",
       "            0.704  , 0.699  , 0.695  , 0.693  , 0.692  , 0.6855 , 0.6807 ,\n",
       "            0.6797 , 0.6777 , 0.676  , 0.6675 , 0.6606 , 0.658  , 0.6553 ,\n",
       "            0.654  , 0.6533 , 0.6523 , 0.6514 , 0.645  , 0.6357 , 0.6187 ,\n",
       "            0.6055 , 0.6035 , 0.6025 , 0.5938 , 0.5923 , 0.5913 , 0.591  ,\n",
       "            0.5903 , 0.59   , 0.589  , 0.5854 , 0.5815 , 0.5796 , 0.5664 ,\n",
       "            0.558  , 0.5576 , 0.5513 , 0.5425 , 0.542  , 0.54   , 0.5376 ,\n",
       "            0.536  , 0.534  , 0.5317 , 0.531  , 0.5303 , 0.5283 , 0.528  ,\n",
       "            0.525  , 0.5244 , 0.519  , 0.5005 , 0.496  , 0.495  , 0.4946 ,\n",
       "            0.491  , 0.4866 , 0.4846 , 0.478  , 0.4758 , 0.474  , 0.4739 ,\n",
       "            0.4724 , 0.472  , 0.4707 , 0.47   , 0.467  , 0.461  , 0.4587 ,\n",
       "            0.458  , 0.4578 , 0.4573 , 0.4531 , 0.4487 , 0.447  , 0.4458 ,\n",
       "            0.437  , 0.4333 , 0.4326 , 0.4321 , 0.4287 , 0.4265 , 0.4243 ,\n",
       "            0.418  , 0.4165 , 0.4128 , 0.399  , 0.3953 , 0.3875 , 0.386  ,\n",
       "            0.3806 , 0.3794 , 0.3716 , 0.3706 , 0.3699 , 0.369  , 0.363  ,\n",
       "            0.3608 , 0.3564 , 0.3481 , 0.3386 , 0.3274 , 0.3083 , 0.298  ,\n",
       "            0.2888 , 0.279  , 0.2764 , 0.2744 , 0.268  , 0.2429 , 0.2382 ,\n",
       "            0.2379 , 0.2368 , 0.2058 , 0.1987 , 0.1943 , 0.1823 , 0.171  ,\n",
       "            0.152  , 0.1461 , 0.1376 , 0.1357 , 0.1354 , 0.1262 , 0.1101 ,\n",
       "            0.1095 , 0.1069 , 0.1058 , 0.10144, 0.0891 , 0.07556, 0.06964,\n",
       "            0.06903, 0.0631 , 0.0627 , 0.05942, 0.0532 , 0.04886, 0.04272,\n",
       "            0.0377 , 0.035  , 0.02925, 0.01428], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.33582088, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.09701493, 0.1119403 ,\n",
       "            0.11940298, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.4224138 , 0.43965518, 0.44827586, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7758621 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9517 , 0.9497 , 0.944  , 0.9424 , 0.94   , 0.938  ,\n",
       "            0.931  , 0.9307 , 0.93   , 0.9277 , 0.9272 , 0.927  , 0.9263 ,\n",
       "            0.9253 , 0.924  , 0.923  , 0.921  , 0.9194 , 0.915  , 0.907  ,\n",
       "            0.9053 , 0.904  , 0.9    , 0.897  , 0.8955 , 0.895  , 0.893  ,\n",
       "            0.8926 , 0.8906 , 0.8896 , 0.886  , 0.883  , 0.882  , 0.881  ,\n",
       "            0.879  , 0.877  , 0.875  , 0.8735 , 0.873  , 0.872  , 0.8716 ,\n",
       "            0.871  , 0.8706 , 0.8667 , 0.8647 , 0.8643 , 0.864  , 0.8623 ,\n",
       "            0.862  , 0.861  , 0.8604 , 0.86   , 0.858  , 0.856  , 0.854  ,\n",
       "            0.852  , 0.851  , 0.84   , 0.8394 , 0.8384 , 0.8335 , 0.8325 ,\n",
       "            0.832  , 0.8286 , 0.8237 , 0.8203 , 0.8193 , 0.819  , 0.817  ,\n",
       "            0.814  , 0.813  , 0.809  , 0.804  , 0.801  , 0.795  , 0.789  ,\n",
       "            0.787  , 0.785  , 0.7847 , 0.782  , 0.7803 , 0.776  , 0.7676 ,\n",
       "            0.765  , 0.7646 , 0.764  , 0.7607 , 0.75   , 0.742  , 0.74   ,\n",
       "            0.7305 , 0.728  , 0.7227 , 0.717  , 0.712  , 0.71   , 0.7095 ,\n",
       "            0.703  , 0.699  , 0.6978 , 0.697  , 0.6943 , 0.693  , 0.684  ,\n",
       "            0.6777 , 0.6743 , 0.67   , 0.6694 , 0.669  , 0.6685 , 0.66   ,\n",
       "            0.652  , 0.6367 , 0.6196 , 0.6187 , 0.618  , 0.6104 , 0.607  ,\n",
       "            0.6055 , 0.605  , 0.6035 , 0.6    , 0.5957 , 0.5947 , 0.58   ,\n",
       "            0.573  , 0.5723 , 0.564  , 0.555  , 0.5547 , 0.5537 , 0.5503 ,\n",
       "            0.55   , 0.5474 , 0.545  , 0.5435 , 0.543  , 0.5425 , 0.541  ,\n",
       "            0.537  , 0.5366 , 0.5327 , 0.531  , 0.512  , 0.5073 , 0.506  ,\n",
       "            0.505  , 0.5024 , 0.4968 , 0.4963 , 0.4888 , 0.486  , 0.4844 ,\n",
       "            0.4827 , 0.4824 , 0.4805 , 0.4802 , 0.4773 , 0.4705 , 0.469  ,\n",
       "            0.4675 , 0.4673 , 0.4663 , 0.4622 , 0.459  , 0.456  , 0.455  ,\n",
       "            0.4473 , 0.4424 , 0.441  , 0.4407 , 0.4373 , 0.4343 , 0.434  ,\n",
       "            0.4263 , 0.4243 , 0.4226 , 0.4058 , 0.4028 , 0.3936 , 0.3904 ,\n",
       "            0.3853 , 0.385  , 0.377  , 0.3762 , 0.3743 , 0.3738 , 0.368  ,\n",
       "            0.3657 , 0.3591 , 0.3508 , 0.345  , 0.329  , 0.309  , 0.2993 ,\n",
       "            0.2903 , 0.2812 , 0.2788 , 0.277  , 0.2742 , 0.2678 , 0.2438 ,\n",
       "            0.2397 , 0.2386 , 0.2372 , 0.2037 , 0.1958 , 0.1913 , 0.1823 ,\n",
       "            0.1687 , 0.1481 , 0.1422 , 0.1337 , 0.1333 , 0.1317 , 0.12335,\n",
       "            0.1056 , 0.10486, 0.1036 , 0.1011 , 0.09845, 0.086  , 0.07135,\n",
       "            0.0655 , 0.06464, 0.05997, 0.05856, 0.05542, 0.05023, 0.045  ,\n",
       "            0.03943, 0.03476, 0.03217, 0.02666, 0.01267], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3880597, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.07462686, 0.08208955, 0.08955224, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.95689654, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9595 , 0.957  , 0.9517 , 0.95   , 0.9487 , 0.9463 ,\n",
       "            0.9414 , 0.941  , 0.94   , 0.9375 , 0.937  , 0.9365 , 0.936  ,\n",
       "            0.933  , 0.9326 , 0.931  , 0.93   , 0.926  , 0.92   , 0.9185 ,\n",
       "            0.917  , 0.9146 , 0.913  , 0.9106 , 0.9077 , 0.907  , 0.9053 ,\n",
       "            0.9043 , 0.904  , 0.9023 , 0.901  , 0.8965 , 0.8955 , 0.895  ,\n",
       "            0.894  , 0.893  , 0.8896 , 0.8887 , 0.886  , 0.8857 , 0.885  ,\n",
       "            0.8843 , 0.883  , 0.881  , 0.88   , 0.8794 , 0.8784 , 0.878  ,\n",
       "            0.877  , 0.8765 , 0.875  , 0.874  , 0.8735 , 0.8716 , 0.871  ,\n",
       "            0.868  , 0.867  , 0.866  , 0.857  , 0.8555 , 0.854  , 0.8496 ,\n",
       "            0.848  , 0.847  , 0.8447 , 0.8413 , 0.8374 , 0.8364 , 0.836  ,\n",
       "            0.8354 , 0.833  , 0.83   , 0.8257 , 0.8193 , 0.8184 , 0.8115 ,\n",
       "            0.807  , 0.8066 , 0.804  , 0.8022 , 0.8013 , 0.799  , 0.7974 ,\n",
       "            0.794  , 0.786  , 0.7847 , 0.783  , 0.781  , 0.7705 , 0.762  ,\n",
       "            0.761  , 0.749  , 0.7446 , 0.74   , 0.735  , 0.7334 , 0.7314 ,\n",
       "            0.728  , 0.7217 , 0.7183 , 0.7173 , 0.7163 , 0.715  , 0.7124 ,\n",
       "            0.704  , 0.695  , 0.693  , 0.692  , 0.691  , 0.6885 , 0.682  ,\n",
       "            0.6724 , 0.6514 , 0.6416 , 0.6396 , 0.6367 , 0.628  , 0.627  ,\n",
       "            0.6265 , 0.626  , 0.6255 , 0.6226 , 0.622  , 0.6147 , 0.6123 ,\n",
       "            0.604  , 0.5913 , 0.588  , 0.586  , 0.576  , 0.5757 , 0.572  ,\n",
       "            0.569  , 0.5674 , 0.567  , 0.5645 , 0.564  , 0.563  , 0.5615 ,\n",
       "            0.557  , 0.554  , 0.552  , 0.5454 , 0.5312 , 0.527  , 0.526  ,\n",
       "            0.5215 , 0.521  , 0.5137 , 0.5073 , 0.506  , 0.505  , 0.5034 ,\n",
       "            0.5024 , 0.5    , 0.4998 , 0.4988 , 0.4963 , 0.489  , 0.4856 ,\n",
       "            0.4854 , 0.481  , 0.4773 , 0.4753 , 0.4736 , 0.4727 , 0.467  ,\n",
       "            0.4578 , 0.457  , 0.4563 , 0.4546 , 0.4536 , 0.4512 , 0.4424 ,\n",
       "            0.44   , 0.4321 , 0.429  , 0.4219 , 0.4094 , 0.4075 , 0.401  ,\n",
       "            0.394  , 0.3916 , 0.3892 , 0.3884 , 0.3838 , 0.381  , 0.38   ,\n",
       "            0.376  , 0.3604 , 0.3525 , 0.3484 , 0.3293 , 0.3096 , 0.299  ,\n",
       "            0.2903 , 0.2815 , 0.278  , 0.2761 , 0.2727 , 0.2668 , 0.2428 ,\n",
       "            0.2391 , 0.2379 , 0.2355 , 0.201  , 0.1921 , 0.1876 , 0.1799 ,\n",
       "            0.1653 , 0.1433 , 0.138  , 0.1296 , 0.1292 , 0.1267 , 0.1193 ,\n",
       "            0.1009 , 0.0998 , 0.0993 , 0.096  , 0.09467, 0.0823 , 0.0672 ,\n",
       "            0.0612 , 0.0603 , 0.05646, 0.0548 , 0.05176, 0.0469 , 0.04138,\n",
       "            0.0363 , 0.03186, 0.02937, 0.02414, 0.0112 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.43283582, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06896552, 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.12068965, 0.12931034, 0.13793103, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.3448276 , 0.35344827, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.47413793, 0.4827586 , 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.80172414, 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9663 , 0.963  , 0.9585 , 0.9575 , 0.9556 , 0.9536 ,\n",
       "            0.9507 , 0.9478 , 0.946  , 0.9453 , 0.945  , 0.9443 , 0.9414 ,\n",
       "            0.941  , 0.9395 , 0.9346 , 0.932  , 0.9307 , 0.9287 , 0.926  ,\n",
       "            0.924  , 0.9233 , 0.9204 , 0.918  , 0.916  , 0.915  , 0.9146 ,\n",
       "            0.914  , 0.913  , 0.91   , 0.9097 , 0.909  , 0.907  , 0.9053 ,\n",
       "            0.903  , 0.9014 , 0.9004 , 0.898  , 0.8975 , 0.8965 , 0.8955 ,\n",
       "            0.895  , 0.894  , 0.8936 , 0.8906 , 0.89   , 0.889  , 0.8887 ,\n",
       "            0.887  , 0.8867 , 0.886  , 0.8833 , 0.8804 , 0.88   , 0.8794 ,\n",
       "            0.8735 , 0.869  , 0.8677 , 0.866  , 0.8643 , 0.86   , 0.859  ,\n",
       "            0.858  , 0.8545 , 0.854  , 0.8525 , 0.8506 , 0.8477 , 0.8433 ,\n",
       "            0.8374 , 0.8306 , 0.8267 , 0.8257 , 0.8237 , 0.8223 , 0.8213 ,\n",
       "            0.818  , 0.817  , 0.816  , 0.814  , 0.8125 , 0.8022 , 0.8003 ,\n",
       "            0.7905 , 0.782  , 0.781  , 0.7695 , 0.7603 , 0.758  , 0.7544 ,\n",
       "            0.752  , 0.747  , 0.7393 , 0.739  , 0.7373 , 0.736  , 0.732  ,\n",
       "            0.73   , 0.7217 , 0.715  , 0.714  , 0.7134 , 0.7114 , 0.7085 ,\n",
       "            0.708  , 0.707  , 0.699  , 0.6895 , 0.6665 , 0.658  , 0.6567 ,\n",
       "            0.6553 , 0.647  , 0.6465 , 0.645  , 0.6445 , 0.6436 , 0.6426 ,\n",
       "            0.642  , 0.6396 , 0.6387 , 0.6343 , 0.629  , 0.6255 , 0.608  ,\n",
       "            0.6035 , 0.602  , 0.592  , 0.5913 , 0.5854 , 0.585  , 0.5835 ,\n",
       "            0.583  , 0.5806 , 0.5786 , 0.576  , 0.5728 , 0.567  , 0.564  ,\n",
       "            0.5605 , 0.5493 , 0.5415 , 0.5405 , 0.538  , 0.537  , 0.528  ,\n",
       "            0.5244 , 0.5234 , 0.523  , 0.521  , 0.52   , 0.5166 , 0.516  ,\n",
       "            0.5137 , 0.513  , 0.5127 , 0.5024 , 0.5015 , 0.499  , 0.4985 ,\n",
       "            0.494  , 0.492  , 0.4885 , 0.487  , 0.483  , 0.4756 , 0.4705 ,\n",
       "            0.4702 , 0.47   , 0.4697 , 0.4673 , 0.462  , 0.4539 , 0.4524 ,\n",
       "            0.4375 , 0.4338 , 0.4329 , 0.42   , 0.414  , 0.4119 , 0.4026 ,\n",
       "            0.4    , 0.399  , 0.3962 , 0.394  , 0.3933 , 0.383  , 0.3787 ,\n",
       "            0.3623 , 0.3564 , 0.3503 , 0.33   , 0.3115 , 0.2983 , 0.29   ,\n",
       "            0.281  , 0.2788 , 0.2747 , 0.2712 , 0.267  , 0.2411 , 0.2374 ,\n",
       "            0.2362 , 0.2347 , 0.199  , 0.1885 , 0.1838 , 0.1757 , 0.1616 ,\n",
       "            0.1392 , 0.1334 , 0.1249 , 0.1241 , 0.12146, 0.11475, 0.09656,\n",
       "            0.09467, 0.09106, 0.0901 , 0.07794, 0.0631 , 0.05698, 0.05603,\n",
       "            0.0526 , 0.05136, 0.04803, 0.04352, 0.03812, 0.03333, 0.02887,\n",
       "            0.02655, 0.02165, 0.00978], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.4552239, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.05970149, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20895523,\n",
       "            0.21641791, 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.11206897, 0.12931034, 0.13793103,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.45689654, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.94827586, 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.972  , 0.9688 , 0.965  , 0.964  , 0.962  , 0.9604 ,\n",
       "            0.958  , 0.9575 , 0.9556 , 0.9546 , 0.9536 , 0.9526 , 0.952  ,\n",
       "            0.9497 , 0.949  , 0.9478 , 0.944  , 0.9404 , 0.9395 , 0.938  ,\n",
       "            0.935  , 0.934  , 0.9326 , 0.9307 , 0.928  , 0.926  , 0.9253 ,\n",
       "            0.9243 , 0.923  , 0.921  , 0.9204 , 0.92   , 0.918  , 0.916  ,\n",
       "            0.914  , 0.9136 , 0.9126 , 0.912  , 0.9116 , 0.9087 , 0.908  ,\n",
       "            0.9077 , 0.9067 , 0.906  , 0.9043 , 0.9023 , 0.901  , 0.8994 ,\n",
       "            0.899  , 0.8984 , 0.8955 , 0.8936 , 0.8926 , 0.891  , 0.8857 ,\n",
       "            0.882  , 0.881  , 0.8794 , 0.878  , 0.8735 , 0.8726 , 0.872  ,\n",
       "            0.868  , 0.8677 , 0.866  , 0.864  , 0.8623 , 0.858  , 0.8516 ,\n",
       "            0.8477 , 0.842  , 0.84   , 0.8374 , 0.837  , 0.8345 , 0.8335 ,\n",
       "            0.8315 , 0.8306 , 0.829  , 0.828  , 0.818  , 0.817  , 0.8154 ,\n",
       "            0.815  , 0.814  , 0.8057 , 0.798  , 0.796  , 0.7847 , 0.777  ,\n",
       "            0.7754 , 0.769  , 0.7666 , 0.764  , 0.7563 , 0.7544 , 0.7534 ,\n",
       "            0.7524 , 0.747  , 0.7456 , 0.737  , 0.73   , 0.728  , 0.7275 ,\n",
       "            0.725  , 0.7246 , 0.7236 , 0.7124 , 0.704  , 0.682  , 0.672  ,\n",
       "            0.671  , 0.6694 , 0.66   , 0.6597 , 0.659  , 0.658  , 0.6562 ,\n",
       "            0.6553 , 0.654  , 0.6533 , 0.6484 , 0.644  , 0.635  , 0.622  ,\n",
       "            0.618  , 0.612  , 0.6025 , 0.602  , 0.598  , 0.5977 , 0.5947 ,\n",
       "            0.594  , 0.5913 , 0.5894 , 0.587  , 0.5825 , 0.5806 , 0.576  ,\n",
       "            0.574  , 0.559  , 0.551  , 0.5493 , 0.548  , 0.5464 , 0.5376 ,\n",
       "            0.533  , 0.531  , 0.5293 , 0.529  , 0.5273 , 0.5264 , 0.526  ,\n",
       "            0.5205 , 0.51   , 0.5093 , 0.5063 , 0.505  , 0.5005 , 0.4973 ,\n",
       "            0.4958 , 0.4954 , 0.4905 , 0.4846 , 0.4778 , 0.4768 , 0.4753 ,\n",
       "            0.4731 , 0.4707 , 0.4617 , 0.4595 , 0.4458 , 0.4446 , 0.437  ,\n",
       "            0.423  , 0.419  , 0.416  , 0.4048 , 0.4006 , 0.3987 , 0.3965 ,\n",
       "            0.3938 , 0.3894 , 0.381  , 0.3645 , 0.3596 , 0.358  , 0.3313 ,\n",
       "            0.3132 , 0.2993 , 0.2913 , 0.2834 , 0.2795 , 0.2764 , 0.2708 ,\n",
       "            0.2673 , 0.2422 , 0.2397 , 0.2388 , 0.2343 , 0.1974 , 0.1858 ,\n",
       "            0.1819 , 0.1759 , 0.1593 , 0.1359 , 0.1301 , 0.1236 , 0.12024,\n",
       "            0.11755, 0.1124 , 0.09283, 0.09204, 0.09076, 0.088  , 0.0871 ,\n",
       "            0.07574, 0.05988, 0.0537 , 0.0526 , 0.05023, 0.0485 , 0.0452 ,\n",
       "            0.04123, 0.03555, 0.03102, 0.02676, 0.02457, 0.01979, 0.00874],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.48507464, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.1119403 , 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.11206897, 0.12931034, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.41379312, 0.43103448, 0.43965518,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.7586207 , 0.76724136, 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9766 , 0.9736 , 0.9697 , 0.969  , 0.9673 , 0.9663 ,\n",
       "            0.9644 , 0.962  , 0.9604 , 0.96   , 0.959  , 0.9585 , 0.9565 ,\n",
       "            0.956  , 0.954  , 0.951  , 0.9487 , 0.9473 , 0.9463 , 0.944  ,\n",
       "            0.9434 , 0.9414 , 0.94   , 0.9365 , 0.935  , 0.9346 , 0.9336 ,\n",
       "            0.9326 , 0.9316 , 0.9307 , 0.93   , 0.9297 , 0.928  , 0.9253 ,\n",
       "            0.924  , 0.923  , 0.9224 , 0.921  , 0.9194 , 0.9185 , 0.918  ,\n",
       "            0.9175 , 0.917  , 0.9155 , 0.9126 , 0.912  , 0.911  , 0.9106 ,\n",
       "            0.91   , 0.9097 , 0.9087 , 0.906  , 0.9043 , 0.9033 , 0.902  ,\n",
       "            0.898  , 0.893  , 0.8926 , 0.8916 , 0.89   , 0.8877 , 0.885  ,\n",
       "            0.8843 , 0.8813 , 0.88   , 0.8794 , 0.877  , 0.875  , 0.8726 ,\n",
       "            0.8657 , 0.8633 , 0.8555 , 0.854  , 0.852  , 0.8506 , 0.8486 ,\n",
       "            0.847  , 0.844  , 0.843  , 0.833  , 0.831  , 0.83   , 0.8286 ,\n",
       "            0.8276 , 0.821  , 0.813  , 0.8115 , 0.8003 , 0.794  , 0.7935 ,\n",
       "            0.785  , 0.7847 , 0.783  , 0.78   , 0.772  , 0.7705 , 0.77   ,\n",
       "            0.7695 , 0.762  , 0.761  , 0.752  , 0.7476 , 0.7456 , 0.744  ,\n",
       "            0.7437 , 0.7417 , 0.741  , 0.7407 , 0.7266 , 0.719  , 0.7007 ,\n",
       "            0.6875 , 0.685  , 0.6836 , 0.6772 , 0.6763 , 0.675  , 0.6724 ,\n",
       "            0.671  , 0.669  , 0.667  , 0.664  , 0.6587 , 0.6504 , 0.637  ,\n",
       "            0.636  , 0.6245 , 0.6167 , 0.616  , 0.615  , 0.6143 , 0.612  ,\n",
       "            0.6094 , 0.6084 , 0.606  , 0.6025 , 0.601  , 0.5986 , 0.5957 ,\n",
       "            0.5903 , 0.5884 , 0.5723 , 0.563  , 0.561  , 0.559  , 0.55   ,\n",
       "            0.546  , 0.5435 , 0.542  , 0.541  , 0.54   , 0.5396 , 0.538  ,\n",
       "            0.5327 , 0.532  , 0.5312 , 0.521  , 0.5205 , 0.517  , 0.515  ,\n",
       "            0.5103 , 0.509  , 0.5083 , 0.5063 , 0.501  , 0.497  , 0.4902 ,\n",
       "            0.487  , 0.4866 , 0.4856 , 0.4832 , 0.4814 , 0.474  , 0.4692 ,\n",
       "            0.4573 , 0.457  , 0.445  , 0.4304 , 0.4292 , 0.4238 , 0.4124 ,\n",
       "            0.4114 , 0.4072 , 0.406  , 0.4036 , 0.4006 , 0.3984 , 0.3872 ,\n",
       "            0.3699 , 0.3674 , 0.3657 , 0.3354 , 0.317  , 0.303  , 0.2952 ,\n",
       "            0.288  , 0.2817 , 0.2805 , 0.2727 , 0.2693 , 0.2452 , 0.244  ,\n",
       "            0.243  , 0.2356 , 0.1978 , 0.185  , 0.1816 , 0.1771 , 0.1587 ,\n",
       "            0.1339 , 0.1279 , 0.12305, 0.11755, 0.11475, 0.11084, 0.0901 ,\n",
       "            0.0877 , 0.0866 , 0.08417, 0.074  , 0.05728, 0.051  , 0.05005,\n",
       "            0.04822, 0.04602, 0.04282, 0.03934, 0.0334 , 0.02898, 0.02493,\n",
       "            0.02284, 0.01823, 0.00784], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.51492536, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.05970149, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.2238806 , 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.28448275,\n",
       "            0.29310346, 0.31034482, 0.31896552, 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.46551725, 0.47413793, 0.4827586 , 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.981  , 0.9775 , 0.9746 , 0.9736 , 0.9717 , 0.971  ,\n",
       "            0.9707 , 0.9673 , 0.967  , 0.9663 , 0.965  , 0.9644 , 0.9634 ,\n",
       "            0.963  , 0.9624 , 0.9604 , 0.9575 , 0.957  , 0.956  , 0.9546 ,\n",
       "            0.9526 , 0.951  , 0.9507 , 0.9487 , 0.945  , 0.944  , 0.9434 ,\n",
       "            0.9424 , 0.941  , 0.9404 , 0.94   , 0.9385 , 0.935  , 0.934  ,\n",
       "            0.933  , 0.9316 , 0.9307 , 0.93   , 0.929  , 0.9287 , 0.928  ,\n",
       "            0.9277 , 0.9272 , 0.9263 , 0.924  , 0.9224 , 0.922  , 0.921  ,\n",
       "            0.9204 , 0.92   , 0.9185 , 0.916  , 0.9146 , 0.914  , 0.9126 ,\n",
       "            0.911  , 0.9053 , 0.904  , 0.9033 , 0.8994 , 0.899  , 0.896  ,\n",
       "            0.8955 , 0.895  , 0.8945 , 0.893  , 0.8916 , 0.889  , 0.886  ,\n",
       "            0.881  , 0.8774 , 0.87   , 0.868  , 0.8657 , 0.864  , 0.862  ,\n",
       "            0.861  , 0.8584 , 0.8574 , 0.8564 , 0.8496 , 0.8477 , 0.845  ,\n",
       "            0.843  , 0.8413 , 0.8384 , 0.831  , 0.8296 , 0.819  , 0.811  ,\n",
       "            0.809  , 0.8037 , 0.802  , 0.801  , 0.798  , 0.7896 , 0.7886 ,\n",
       "            0.788  , 0.787  , 0.7783 , 0.778  , 0.7686 , 0.7646 , 0.7637 ,\n",
       "            0.762  , 0.7603 , 0.7583 , 0.743  , 0.7363 , 0.7163 , 0.7056 ,\n",
       "            0.7017 , 0.7    , 0.6963 , 0.6953 , 0.6943 , 0.691  , 0.69   ,\n",
       "            0.6895 , 0.6875 , 0.6855 , 0.6836 , 0.683  , 0.6753 , 0.6714 ,\n",
       "            0.6543 , 0.6523 , 0.6406 , 0.636  , 0.6323 , 0.6313 , 0.631  ,\n",
       "            0.6284 , 0.628  , 0.625  , 0.62   , 0.6187 , 0.615  , 0.6113 ,\n",
       "            0.6064 , 0.6035 , 0.591  , 0.5786 , 0.578  , 0.576  , 0.5757 ,\n",
       "            0.5654 , 0.563  , 0.561  , 0.5605 , 0.559  , 0.5576 , 0.5547 ,\n",
       "            0.5527 , 0.5503 , 0.5464 , 0.546  , 0.5376 , 0.535  , 0.5312 ,\n",
       "            0.529  , 0.5254 , 0.524  , 0.523  , 0.52   , 0.511  , 0.508  ,\n",
       "            0.502  , 0.5015 , 0.5    , 0.4998 , 0.4927 , 0.486  , 0.4836 ,\n",
       "            0.4685 , 0.4663 , 0.457  , 0.4417 , 0.4375 , 0.437  , 0.4229 ,\n",
       "            0.4197 , 0.4172 , 0.4163 , 0.4133 , 0.4128 , 0.4058 , 0.3918 ,\n",
       "            0.3755 , 0.374  , 0.3716 , 0.3381 , 0.3206 , 0.3057 , 0.2976 ,\n",
       "            0.2913 , 0.2834 , 0.2827 , 0.2737 , 0.2703 , 0.247  , 0.246  ,\n",
       "            0.2367 , 0.1974 , 0.1833 , 0.181  , 0.1774 , 0.1572 , 0.1312 ,\n",
       "            0.1245 , 0.1217 , 0.1142 , 0.11145, 0.10895, 0.0876 , 0.0871 ,\n",
       "            0.0848 , 0.08435, 0.0808 , 0.07184, 0.0545 , 0.04822, 0.04742,\n",
       "            0.04602, 0.04352, 0.04037, 0.03732, 0.0312 , 0.02701, 0.0231 ,\n",
       "            0.02109, 0.01672, 0.00701], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5522388, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.36567163, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.06896552, 0.09482758, 0.11206897, 0.12931034,\n",
       "            0.13793103, 0.15517241, 0.1637931 , 0.1724138 , 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.28448275,\n",
       "            0.29310346, 0.31034482, 0.31896552, 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.38793105, 0.39655173,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.47413793, 0.4827586 , 0.49137932, 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.95689654, 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.985  , 0.982  , 0.9795 , 0.9785 , 0.9775 , 0.9766 ,\n",
       "            0.9727 , 0.971  , 0.9707 , 0.97   , 0.9688 , 0.968  , 0.9653 ,\n",
       "            0.9644 , 0.9624 , 0.961  , 0.9595 , 0.9585 , 0.9575 , 0.954  ,\n",
       "            0.9536 , 0.952  , 0.9517 , 0.9507 , 0.95   , 0.9497 , 0.9487 ,\n",
       "            0.946  , 0.945  , 0.9434 , 0.9424 , 0.9414 , 0.941  , 0.94   ,\n",
       "            0.9395 , 0.939  , 0.938  , 0.9375 , 0.9355 , 0.934  , 0.9336 ,\n",
       "            0.933  , 0.9326 , 0.9316 , 0.931  , 0.9287 , 0.9263 , 0.926  ,\n",
       "            0.9243 , 0.9194 , 0.918  , 0.917  , 0.913  , 0.911  , 0.9106 ,\n",
       "            0.91   , 0.9097 , 0.9087 , 0.9077 , 0.904  , 0.902  , 0.897  ,\n",
       "            0.8926 , 0.8877 , 0.886  , 0.8853 , 0.8833 , 0.8813 , 0.8794 ,\n",
       "            0.877  , 0.8765 , 0.875  , 0.8745 , 0.868  , 0.8667 , 0.8647 ,\n",
       "            0.8633 , 0.863  , 0.8584 , 0.851  , 0.8506 , 0.8403 , 0.8315 ,\n",
       "            0.8276 , 0.827  , 0.825  , 0.821  , 0.8174 , 0.8125 , 0.8105 ,\n",
       "            0.809  , 0.8086 , 0.8027 , 0.801  , 0.793  , 0.792  , 0.7905 ,\n",
       "            0.787  , 0.783  , 0.7827 , 0.779  , 0.7715 , 0.7627 , 0.738  ,\n",
       "            0.732  , 0.73   , 0.7285 , 0.7246 , 0.72   , 0.7183 , 0.7173 ,\n",
       "            0.717  , 0.716  , 0.7134 , 0.7104 , 0.7085 , 0.706  , 0.6973 ,\n",
       "            0.6807 , 0.6753 , 0.674  , 0.6685 , 0.6636 , 0.663  , 0.66   ,\n",
       "            0.659  , 0.6567 , 0.656  , 0.655  , 0.6504 , 0.65   , 0.643  ,\n",
       "            0.637  , 0.6367 , 0.63   , 0.6206 , 0.6094 , 0.6084 , 0.6035 ,\n",
       "            0.595  , 0.5938 , 0.5933 , 0.5903 , 0.584  , 0.582  , 0.5786 ,\n",
       "            0.5776 , 0.5723 , 0.568  , 0.5664 , 0.5625 , 0.562  , 0.559  ,\n",
       "            0.5566 , 0.553  , 0.5386 , 0.534  , 0.5327 , 0.5317 , 0.5303 ,\n",
       "            0.5293 , 0.5264 , 0.5205 , 0.513  , 0.511  , 0.505  , 0.487  ,\n",
       "            0.4868 , 0.4834 , 0.4717 , 0.4678 , 0.4536 , 0.4514 , 0.4475 ,\n",
       "            0.447  , 0.4436 , 0.4353 , 0.4285 , 0.4204 , 0.404  , 0.3904 ,\n",
       "            0.3855 , 0.3853 , 0.3481 , 0.3315 , 0.3154 , 0.307  , 0.3008 ,\n",
       "            0.2925 , 0.2908 , 0.2808 , 0.2778 , 0.2551 , 0.2546 , 0.2544 ,\n",
       "            0.2434 , 0.2023 , 0.1871 , 0.185  , 0.1815 , 0.1599 , 0.1326 ,\n",
       "            0.12476, 0.12366, 0.11395, 0.11127, 0.1095 , 0.0876 , 0.0869 ,\n",
       "            0.0851 , 0.08344, 0.0798 , 0.0717 , 0.0536 , 0.0469 , 0.04648,\n",
       "            0.04526, 0.04282, 0.03934, 0.0365 , 0.03021, 0.02606, 0.02211,\n",
       "            0.02014, 0.01584, 0.00651], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5597015, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.18656716, 0.19402985,\n",
       "            0.20895523, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.58208954, 0.5895522 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.09482758,\n",
       "            0.10344828, 0.12068965, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25862068, 0.2672414 , 0.28448275, 0.31034482, 0.31896552,\n",
       "            0.33620688, 0.35344827, 0.36206895, 0.37068966, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.47413793, 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9883  , 0.985   , 0.9824  , 0.982   , 0.9814  ,\n",
       "            0.9805  , 0.98    , 0.9775  , 0.9766  , 0.9756  , 0.975   ,\n",
       "            0.9746  , 0.973   , 0.9727  , 0.972   , 0.9717  , 0.971   ,\n",
       "            0.969   , 0.9688  , 0.9683  , 0.967   , 0.9644  , 0.963   ,\n",
       "            0.9624  , 0.959   , 0.9585  , 0.958   , 0.957   , 0.956   ,\n",
       "            0.955   , 0.952   , 0.951   , 0.9507  , 0.9497  , 0.9487  ,\n",
       "            0.948   , 0.9478  , 0.946   , 0.9453  , 0.945   , 0.9434  ,\n",
       "            0.9414  , 0.9404  , 0.9395  , 0.939   , 0.938   , 0.9365  ,\n",
       "            0.936   , 0.934   , 0.9336  , 0.931   , 0.928   , 0.927   ,\n",
       "            0.926   , 0.9253  , 0.9243  , 0.9233  , 0.9214  , 0.921   ,\n",
       "            0.9204  , 0.9194  , 0.918   , 0.9165  , 0.914   , 0.911   ,\n",
       "            0.903   , 0.902   , 0.9014  , 0.899   , 0.8945  , 0.8936  ,\n",
       "            0.8926  , 0.8896  , 0.888   , 0.8867  , 0.884   , 0.8833  ,\n",
       "            0.877   , 0.876   , 0.8755  , 0.868   , 0.859   , 0.848   ,\n",
       "            0.8467  , 0.8447  , 0.8354  , 0.835   , 0.832   , 0.83    ,\n",
       "            0.8247  , 0.824   , 0.8184  , 0.8164  , 0.8145  , 0.8125  ,\n",
       "            0.809   , 0.804   , 0.803   , 0.8027  , 0.7964  , 0.7915  ,\n",
       "            0.788   , 0.78    , 0.75    , 0.7495  , 0.748   , 0.7476  ,\n",
       "            0.7437  , 0.7363  , 0.735   , 0.734   , 0.7334  , 0.7324  ,\n",
       "            0.7314  , 0.727   , 0.716   , 0.6997  , 0.693   , 0.689   ,\n",
       "            0.683   , 0.682   , 0.68    , 0.6797  , 0.676   , 0.674   ,\n",
       "            0.6724  , 0.6685  , 0.662   , 0.656   , 0.6465  , 0.6445  ,\n",
       "            0.644   , 0.6313  , 0.6284  , 0.6274  , 0.625   , 0.6206  ,\n",
       "            0.618   , 0.616   , 0.615   , 0.6143  , 0.6133  , 0.606   ,\n",
       "            0.597   , 0.5967  , 0.5903  , 0.585   , 0.584   , 0.5825  ,\n",
       "            0.581   , 0.5806  , 0.5757  , 0.575   , 0.5596  , 0.5557  ,\n",
       "            0.552   , 0.55    , 0.5483  , 0.543   , 0.5366  , 0.5337  ,\n",
       "            0.5327  , 0.5225  , 0.516   , 0.5044  , 0.491   , 0.489   ,\n",
       "            0.4885  , 0.469   , 0.4644  , 0.464   , 0.458   , 0.4456  ,\n",
       "            0.439   , 0.424   , 0.4084  , 0.3943  , 0.392   , 0.3892  ,\n",
       "            0.3508  , 0.337   , 0.3164  , 0.308   , 0.301   , 0.2947  ,\n",
       "            0.2925  , 0.2812  , 0.281   , 0.2537  , 0.2534  , 0.2527  ,\n",
       "            0.2456  , 0.2023  , 0.1864  , 0.1844  , 0.1775  , 0.1573  ,\n",
       "            0.1301  , 0.12103 , 0.1194  , 0.1103  , 0.1076  , 0.1056  ,\n",
       "            0.08435 , 0.08386 , 0.08124 , 0.0801  , 0.0764  , 0.0682  ,\n",
       "            0.05118 , 0.0441  , 0.04257 , 0.04108 , 0.0372  , 0.0341  ,\n",
       "            0.02834 , 0.02443 , 0.02025 , 0.01837 , 0.01445 , 0.005753],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5895522, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23880596, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5074627 ,\n",
       "            0.51492536, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.04310345, 0.05172414,\n",
       "            0.06034483, 0.06896552, 0.0775862 , 0.0862069 , 0.10344828,\n",
       "            0.12068965, 0.13793103, 0.14655173, 0.15517241, 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.31034482,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.38793105, 0.39655173, 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.44827586, 0.45689654, 0.47413793, 0.49137932,\n",
       "            0.5086207 , 0.5258621 , 0.5344828 , 0.55172414, 0.5689655 ,\n",
       "            0.57758623, 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.9907 , 0.9873 , 0.9854 , 0.985  , 0.984  , 0.983  ,\n",
       "            0.982  , 0.9805 , 0.98   , 0.979  , 0.9785 , 0.9775 , 0.977  ,\n",
       "            0.9766 , 0.976  , 0.9746 , 0.974  , 0.9736 , 0.973  , 0.971  ,\n",
       "            0.9697 , 0.968  , 0.9663 , 0.966  , 0.9653 , 0.965  , 0.9644 ,\n",
       "            0.9634 , 0.963  , 0.9624 , 0.962  , 0.9604 , 0.9595 , 0.959  ,\n",
       "            0.958  , 0.9575 , 0.957  , 0.9546 , 0.9536 , 0.9526 , 0.952  ,\n",
       "            0.951  , 0.9487 , 0.9478 , 0.947  , 0.946  , 0.9443 , 0.942  ,\n",
       "            0.9414 , 0.9385 , 0.936  , 0.9355 , 0.9346 , 0.934  , 0.933  ,\n",
       "            0.932  , 0.9287 , 0.928  , 0.9277 , 0.927  , 0.9233 , 0.916  ,\n",
       "            0.9155 , 0.915  , 0.909  , 0.9087 , 0.9053 , 0.9043 , 0.903  ,\n",
       "            0.9    , 0.8994 , 0.8984 , 0.898  , 0.8975 , 0.8906 , 0.889  ,\n",
       "            0.888  , 0.884  , 0.8755 , 0.8657 , 0.864  , 0.8623 , 0.851  ,\n",
       "            0.849  , 0.847  , 0.844  , 0.8394 , 0.834  , 0.832  , 0.825  ,\n",
       "            0.8247 , 0.8213 , 0.8203 , 0.814  , 0.8086 , 0.805  , 0.797  ,\n",
       "            0.77   , 0.769  , 0.768  , 0.7666 , 0.766  , 0.765  , 0.7563 ,\n",
       "            0.756  , 0.755  , 0.754  , 0.7534 , 0.753  , 0.7524 , 0.745  ,\n",
       "            0.7344 , 0.7188 , 0.716  , 0.712  , 0.7085 , 0.7056 , 0.705  ,\n",
       "            0.7026 , 0.7017 , 0.701  , 0.696  , 0.695  , 0.688  , 0.6816 ,\n",
       "            0.6753 , 0.668  , 0.666  , 0.6606 , 0.653  , 0.6484 , 0.647  ,\n",
       "            0.645  , 0.6445 , 0.6406 , 0.638  , 0.6377 , 0.6367 , 0.633  ,\n",
       "            0.6284 , 0.627  , 0.617  , 0.616  , 0.612  , 0.607  , 0.6045 ,\n",
       "            0.6006 , 0.6    , 0.5967 , 0.5947 , 0.583  , 0.5767 , 0.5723 ,\n",
       "            0.5674 , 0.561  , 0.554  , 0.5513 , 0.5396 , 0.534  , 0.5225 ,\n",
       "            0.5093 , 0.507  , 0.504  , 0.5024 , 0.489  , 0.4866 , 0.4844 ,\n",
       "            0.4822 , 0.471  , 0.4607 , 0.454  , 0.4353 , 0.419  , 0.4077 ,\n",
       "            0.4016 , 0.3987 , 0.3586 , 0.3467 , 0.3235 , 0.3147 , 0.3074 ,\n",
       "            0.3025 , 0.2986 , 0.2886 , 0.2866 , 0.2578 , 0.2573 , 0.2566 ,\n",
       "            0.251  , 0.2056 , 0.1887 , 0.1869 , 0.1776 , 0.158  , 0.13   ,\n",
       "            0.1196 , 0.118  , 0.10895, 0.1058 , 0.1043 , 0.0831 , 0.0821 ,\n",
       "            0.07935, 0.07794, 0.07434, 0.06635, 0.0495 , 0.0424 , 0.04208,\n",
       "            0.04077, 0.0398 , 0.0356 , 0.0324 , 0.02692, 0.0231 , 0.01888,\n",
       "            0.01704, 0.01333, 0.00514], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.619403, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.03448276, 0.05172414,\n",
       "            0.06034483, 0.06896552, 0.0775862 , 0.09482758, 0.10344828,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.43103448, 0.43965518, 0.45689654, 0.46551725, 0.4827586 ,\n",
       "            0.5       , 0.5086207 , 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5689655 , 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9927  , 0.99    , 0.989   , 0.9883  , 0.9873  ,\n",
       "            0.987   , 0.9854  , 0.985   , 0.984   , 0.9834  , 0.983   ,\n",
       "            0.9824  , 0.982   , 0.9814  , 0.9795  , 0.979   , 0.9785  ,\n",
       "            0.977   , 0.976   , 0.974   , 0.9727  , 0.972   , 0.9717  ,\n",
       "            0.971   , 0.9707  , 0.97    , 0.9697  , 0.9683  , 0.9673  ,\n",
       "            0.9663  , 0.9653  , 0.9644  , 0.9634  , 0.9624  , 0.962   ,\n",
       "            0.9614  , 0.96    , 0.9585  , 0.958   , 0.9575  , 0.9565  ,\n",
       "            0.9556  , 0.955   , 0.9526  , 0.952   , 0.951   , 0.9478  ,\n",
       "            0.9473  , 0.947   , 0.9453  , 0.945   , 0.9443  , 0.944   ,\n",
       "            0.9434  , 0.941   , 0.9395  , 0.939   , 0.936   , 0.93    ,\n",
       "            0.929   , 0.924   , 0.923   , 0.9194  , 0.919   , 0.917   ,\n",
       "            0.916   , 0.9146  , 0.914   , 0.913   , 0.9126  , 0.9077  ,\n",
       "            0.907   , 0.9067  , 0.901   , 0.9004  , 0.8936  , 0.884   ,\n",
       "            0.8823  , 0.8696  , 0.869   , 0.868   , 0.867   , 0.8643  ,\n",
       "            0.8594  , 0.859   , 0.858   , 0.8564  , 0.855   , 0.8496  ,\n",
       "            0.8457  , 0.843   , 0.8413  , 0.8364  , 0.835   , 0.8306  ,\n",
       "            0.8237  , 0.8003  , 0.7993  , 0.798   , 0.7974  , 0.7944  ,\n",
       "            0.793   , 0.791   , 0.789   , 0.788   , 0.7866  , 0.786   ,\n",
       "            0.781   , 0.7803  , 0.7783  , 0.771   , 0.759   , 0.75    ,\n",
       "            0.7495  , 0.7485  , 0.7393  , 0.7383  , 0.738   , 0.7363  ,\n",
       "            0.736   , 0.7354  , 0.7324  , 0.7285  , 0.7266  , 0.724   ,\n",
       "            0.7207  , 0.7183  , 0.7144  , 0.6997  , 0.6934  , 0.6885  ,\n",
       "            0.6865  , 0.6855  , 0.6846  , 0.6787  , 0.678   , 0.6763  ,\n",
       "            0.6733  , 0.673   , 0.6665  , 0.666   , 0.6606  , 0.657   ,\n",
       "            0.654   , 0.6475  , 0.647   , 0.6436  , 0.6406  , 0.639   ,\n",
       "            0.6357  , 0.6333  , 0.6265  , 0.6255  , 0.615   , 0.61    ,\n",
       "            0.606   , 0.593   , 0.592   , 0.585   , 0.58    , 0.576   ,\n",
       "            0.563   , 0.562   , 0.559   , 0.5493  , 0.547   , 0.5312  ,\n",
       "            0.529   , 0.527   , 0.5254  , 0.5234  , 0.4944  , 0.4814  ,\n",
       "            0.4744  , 0.4573  , 0.4375  , 0.426   , 0.4226  , 0.4163  ,\n",
       "            0.3743  , 0.3613  , 0.3389  , 0.3296  , 0.3225  , 0.3147  ,\n",
       "            0.313   , 0.3003  , 0.2996  , 0.27    , 0.2698  , 0.269   ,\n",
       "            0.261   , 0.213   , 0.1953  , 0.1931  , 0.1844  , 0.1626  ,\n",
       "            0.1327  , 0.1213  , 0.11066 , 0.1067  , 0.1063  , 0.08374 ,\n",
       "            0.0831  , 0.0806  , 0.0778  , 0.0741  , 0.06696 , 0.04895 ,\n",
       "            0.04178 , 0.04147 , 0.04047 , 0.03934 , 0.03488 , 0.03192 ,\n",
       "            0.02611 , 0.02232 , 0.01816 , 0.01628 , 0.01267 , 0.004738],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6268657, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.36567163, 0.38059703,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.06034483, 0.06896552, 0.0775862 , 0.0862069 , 0.09482758,\n",
       "            0.12931034, 0.14655173, 0.15517241, 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.23275863,\n",
       "            0.2413793 , 0.25862068, 0.2672414 , 0.29310346, 0.31034482,\n",
       "            0.3275862 , 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43965518, 0.44827586, 0.4827586 , 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.80172414, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.      , 0.994   , 0.9927  , 0.9917  , 0.991   , 0.9907  ,\n",
       "            0.9897  , 0.989   , 0.9883  , 0.988   , 0.9873  , 0.987   ,\n",
       "            0.9863  , 0.986   , 0.9854  , 0.9844  , 0.984   , 0.9834  ,\n",
       "            0.983   , 0.982   , 0.979   , 0.978   , 0.9775  , 0.977   ,\n",
       "            0.9766  , 0.976   , 0.9756  , 0.9746  , 0.974   , 0.9736  ,\n",
       "            0.9727  , 0.972   , 0.971   , 0.9707  , 0.97    , 0.9697  ,\n",
       "            0.9688  , 0.9673  , 0.967   , 0.966   , 0.965   , 0.9644  ,\n",
       "            0.964   , 0.963   , 0.9624  , 0.961   , 0.9604  , 0.9595  ,\n",
       "            0.9575  , 0.957   , 0.9565  , 0.9556  , 0.955   , 0.954   ,\n",
       "            0.9526  , 0.952   , 0.949   , 0.9487  , 0.948   , 0.9453  ,\n",
       "            0.944   , 0.943   , 0.9355  , 0.934   , 0.9336  , 0.9326  ,\n",
       "            0.931   , 0.93    , 0.929   , 0.928   , 0.927   , 0.9263  ,\n",
       "            0.9243  , 0.924   , 0.9233  , 0.919   , 0.9175  , 0.913   ,\n",
       "            0.9043  , 0.904   , 0.9     , 0.8906  , 0.8877  , 0.886   ,\n",
       "            0.8857  , 0.8853  , 0.883   , 0.882   , 0.8774  , 0.8735  ,\n",
       "            0.8657  , 0.865   , 0.8643  , 0.863   , 0.8564  , 0.8516  ,\n",
       "            0.8506  , 0.8345  , 0.8325  , 0.8315  , 0.831   , 0.8296  ,\n",
       "            0.8276  , 0.826   , 0.8203  , 0.82    , 0.8154  , 0.8125  ,\n",
       "            0.811   , 0.8037  , 0.8003  , 0.796   , 0.7925  , 0.7896  ,\n",
       "            0.7847  , 0.78    , 0.7793  , 0.779   , 0.777   , 0.776   ,\n",
       "            0.773   , 0.7686  , 0.7676  , 0.764   , 0.761   , 0.7603  ,\n",
       "            0.76    , 0.7583  , 0.743   , 0.7407  , 0.735   , 0.73    ,\n",
       "            0.728   , 0.7275  , 0.7256  , 0.7246  , 0.7197  , 0.7173  ,\n",
       "            0.716   , 0.713   , 0.705   , 0.702   , 0.699   , 0.698   ,\n",
       "            0.6924  , 0.69    , 0.6895  , 0.6855  , 0.6846  , 0.682   ,\n",
       "            0.68    , 0.6655  , 0.6562  , 0.6523  , 0.6514  , 0.64    ,\n",
       "            0.618   , 0.6113  , 0.605   , 0.6045  , 0.5986  , 0.598   ,\n",
       "            0.59    , 0.5835  , 0.5825  , 0.5796  , 0.5776  , 0.552   ,\n",
       "            0.5493  , 0.5156  , 0.4988  , 0.4915  , 0.4773  , 0.4548  ,\n",
       "            0.4414  , 0.4407  , 0.432   , 0.3877  , 0.3716  , 0.3523  ,\n",
       "            0.3423  , 0.3354  , 0.3254  , 0.3228  , 0.3103  , 0.3079  ,\n",
       "            0.2803  , 0.2798  , 0.2795  , 0.268   , 0.2186  , 0.2001  ,\n",
       "            0.1978  , 0.1891  , 0.1658  , 0.1335  , 0.12274 , 0.1216  ,\n",
       "            0.11066 , 0.1067  , 0.10614 , 0.0827  , 0.0805  , 0.0764  ,\n",
       "            0.07263 , 0.06635 , 0.04742 , 0.04025 , 0.0401  , 0.03934 ,\n",
       "            0.0377  , 0.0334  , 0.03079 , 0.02475 , 0.02101 , 0.01718 ,\n",
       "            0.01525 , 0.01178 , 0.004265], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6492537, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.06034483, 0.06896552, 0.0775862 , 0.0862069 , 0.11206897,\n",
       "            0.13793103, 0.15517241, 0.1724138 , 0.18965517, 0.19827586,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25862068,\n",
       "            0.28448275, 0.3275862 , 0.33620688, 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.38793105, 0.41379312, 0.4224138 , 0.43965518,\n",
       "            0.45689654, 0.47413793, 0.5       , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.8103448 , 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9956  , 0.9946  , 0.994   , 0.9937  , 0.993   ,\n",
       "            0.992   , 0.9917  , 0.991   , 0.9907  , 0.99    , 0.9897  ,\n",
       "            0.9893  , 0.9883  , 0.988   , 0.987   , 0.9863  , 0.9854  ,\n",
       "            0.9834  , 0.983   , 0.9824  , 0.982   , 0.9814  , 0.981   ,\n",
       "            0.9805  , 0.9795  , 0.978   , 0.977   , 0.976   , 0.975   ,\n",
       "            0.9746  , 0.9736  , 0.9727  , 0.972   , 0.9717  , 0.9707  ,\n",
       "            0.9697  , 0.969   , 0.9683  , 0.967   , 0.9663  , 0.9653  ,\n",
       "            0.965   , 0.9634  , 0.962   , 0.9614  , 0.961   , 0.959   ,\n",
       "            0.9585  , 0.958   , 0.9575  , 0.956   , 0.955   , 0.9478  ,\n",
       "            0.9473  , 0.947   , 0.9443  , 0.944   , 0.9434  , 0.9424  ,\n",
       "            0.94    , 0.9395  , 0.9385  , 0.935   , 0.9326  , 0.93    ,\n",
       "            0.924   , 0.923   , 0.914   , 0.911   , 0.9106  , 0.907   ,\n",
       "            0.9067  , 0.9043  , 0.904   , 0.9023  , 0.9014  , 0.8984  ,\n",
       "            0.8975  , 0.897   , 0.8955  , 0.895   , 0.886   , 0.8833  ,\n",
       "            0.882   , 0.8784  , 0.8755  , 0.8706  , 0.8696  , 0.868   ,\n",
       "            0.8643  , 0.8604  , 0.859   , 0.8545  , 0.853   , 0.841   ,\n",
       "            0.8384  , 0.8354  , 0.8345  , 0.8286  , 0.8257  , 0.8223  ,\n",
       "            0.8213  , 0.8184  , 0.818   , 0.815   , 0.812   , 0.809   ,\n",
       "            0.806   , 0.8057  , 0.8047  , 0.804   , 0.8027  , 0.7974  ,\n",
       "            0.7856  , 0.785   , 0.7817  , 0.778   , 0.774   , 0.773   ,\n",
       "            0.7725  , 0.7686  , 0.7666  , 0.766   , 0.7603  , 0.7593  ,\n",
       "            0.758   , 0.757   , 0.752   , 0.747   , 0.746   , 0.744   ,\n",
       "            0.7437  , 0.741   , 0.7407  , 0.74    , 0.7383  , 0.7363  ,\n",
       "            0.728   , 0.7173  , 0.706   , 0.7046  , 0.693   , 0.6797  ,\n",
       "            0.669   , 0.6636  , 0.658   , 0.6543  , 0.6465  , 0.646   ,\n",
       "            0.6426  , 0.641   , 0.6333  , 0.631   , 0.625   , 0.61    ,\n",
       "            0.6094  , 0.583   , 0.5786  , 0.5444  , 0.523   , 0.5156  ,\n",
       "            0.505   , 0.4795  , 0.4705  , 0.4636  , 0.4539  , 0.408   ,\n",
       "            0.3906  , 0.3728  , 0.362   , 0.3564  , 0.3457  , 0.3396  ,\n",
       "            0.3281  , 0.3235  , 0.3     , 0.2993  , 0.2974  , 0.2827  ,\n",
       "            0.2307  , 0.2109  , 0.2085  , 0.2021  , 0.1746  , 0.1392  ,\n",
       "            0.1305  , 0.1266  , 0.115   , 0.112   , 0.1101  , 0.0862  ,\n",
       "            0.0854  , 0.0848  , 0.07825 , 0.07434 , 0.0693  , 0.0483  ,\n",
       "            0.04092 , 0.04068 , 0.04037 , 0.0384  , 0.03384 , 0.03143 ,\n",
       "            0.02493 , 0.02109 , 0.01724 , 0.015305, 0.01169 , 0.00415 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6641791, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05223881, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08208955, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.31343284, 0.32089552, 0.3283582 , 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.03448276, 0.05172414,\n",
       "            0.06034483, 0.0775862 , 0.0862069 , 0.11206897, 0.13793103,\n",
       "            0.1724138 , 0.18965517, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.29310346, 0.31896552, 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.4051724 , 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.45689654, 0.5       , 0.5086207 ,\n",
       "            0.5344828 , 0.54310346, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.80172414, 0.8103448 , 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.      , 0.9966  , 0.996   , 0.9956  , 0.995   , 0.9946  ,\n",
       "            0.994   , 0.9937  , 0.993   , 0.9927  , 0.992   , 0.991   ,\n",
       "            0.9907  , 0.9897  , 0.9893  , 0.989   , 0.987   , 0.9863  ,\n",
       "            0.986   , 0.985   , 0.9844  , 0.9834  , 0.983   , 0.9824  ,\n",
       "            0.982   , 0.9814  , 0.981   , 0.98    , 0.979   , 0.9785  ,\n",
       "            0.978   , 0.9775  , 0.9756  , 0.975   , 0.9746  , 0.973   ,\n",
       "            0.9727  , 0.972   , 0.971   , 0.9707  , 0.9697  , 0.969   ,\n",
       "            0.9683  , 0.9673  , 0.967   , 0.966   , 0.9653  , 0.9604  ,\n",
       "            0.959   , 0.9585  , 0.9575  , 0.9565  , 0.9556  , 0.955   ,\n",
       "            0.9546  , 0.9526  , 0.952   , 0.95    , 0.949   , 0.947   ,\n",
       "            0.946   , 0.941   , 0.9404  , 0.9336  , 0.9297  , 0.9287  ,\n",
       "            0.928   , 0.926   , 0.9243  , 0.923   , 0.9194  , 0.919   ,\n",
       "            0.918   , 0.9155  , 0.914   , 0.912   , 0.906   , 0.9053  ,\n",
       "            0.905   , 0.9014  , 0.9004  , 0.897   , 0.895   , 0.8945  ,\n",
       "            0.89    , 0.8887  , 0.886   , 0.8784  , 0.87    , 0.8677  ,\n",
       "            0.864   , 0.8613  , 0.86    , 0.8574  , 0.8555  , 0.8545  ,\n",
       "            0.8516  , 0.8496  , 0.849   , 0.8477  , 0.8467  , 0.846   ,\n",
       "            0.8457  , 0.845   , 0.8413  , 0.8374  , 0.835   , 0.8335  ,\n",
       "            0.8276  , 0.8247  , 0.823   , 0.8223  , 0.815   , 0.813   ,\n",
       "            0.812   , 0.811   , 0.8086  , 0.8057  , 0.8027  , 0.8013  ,\n",
       "            0.7993  , 0.797   , 0.796   , 0.7954  , 0.791   , 0.7905  ,\n",
       "            0.79    , 0.7886  , 0.7803  , 0.775   , 0.771   , 0.762   ,\n",
       "            0.7617  , 0.7524  , 0.7354  , 0.732   , 0.728   , 0.7275  ,\n",
       "            0.7197  , 0.716   , 0.7144  , 0.714   , 0.68    , 0.6675  ,\n",
       "            0.6655  , 0.6587  , 0.644   , 0.6196  , 0.6147  , 0.5806  ,\n",
       "            0.558   , 0.551   , 0.5405  , 0.513   , 0.5063  , 0.498   ,\n",
       "            0.4863  , 0.4377  , 0.4216  , 0.4026  , 0.3916  , 0.3855  ,\n",
       "            0.3745  , 0.3674  , 0.3552  , 0.35    , 0.327   , 0.3262  ,\n",
       "            0.3232  , 0.3066  , 0.251   , 0.2294  , 0.2266  , 0.2203  ,\n",
       "            0.1893  , 0.1505  , 0.1423  , 0.1364  , 0.1238  , 0.1213  ,\n",
       "            0.1184  , 0.09283 , 0.09204 , 0.09186 , 0.08344 , 0.07904 ,\n",
       "            0.0749  , 0.05154 , 0.04346 , 0.0432  , 0.04312 , 0.04132 ,\n",
       "            0.03583 , 0.03333 , 0.02626 , 0.0222  , 0.01805 , 0.01596 ,\n",
       "            0.0121  , 0.004215], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6791045, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.07462686, 0.08208955,\n",
       "            0.08208955, 0.08955224, 0.08955224, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.25373134, 0.26119402,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.3283582 , 0.33582088, 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.05172414, 0.06896552,\n",
       "            0.10344828, 0.12068965, 0.1637931 , 0.1724138 , 0.19827586,\n",
       "            0.20689656, 0.22413793, 0.23275863, 0.2672414 , 0.31896552,\n",
       "            0.3275862 , 0.36206895, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.47413793, 0.5       ,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.5862069 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.6465517 , 0.6551724 , 0.67241377, 0.6896552 , 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.7586207 , 0.76724136,\n",
       "            0.79310346, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8534483 , 0.87068963, 0.87068963, 0.87931037, 0.87931037,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.997  , 0.9966 , 0.996  , 0.9956 , 0.9946 , 0.994  ,\n",
       "            0.9937 , 0.993  , 0.9927 , 0.992  , 0.9907 , 0.99   , 0.9893 ,\n",
       "            0.989  , 0.9883 , 0.988  , 0.9863 , 0.986  , 0.9854 , 0.985  ,\n",
       "            0.984  , 0.9834 , 0.9824 , 0.982  , 0.9814 , 0.981  , 0.9805 ,\n",
       "            0.9795 , 0.979  , 0.9785 , 0.9775 , 0.976  , 0.9756 , 0.9746 ,\n",
       "            0.974  , 0.973  , 0.9727 , 0.9707 , 0.9697 , 0.968  , 0.965  ,\n",
       "            0.9634 , 0.9624 , 0.962  , 0.96   , 0.957  , 0.956  , 0.955  ,\n",
       "            0.9546 , 0.954  , 0.9507 , 0.9473 , 0.943  , 0.94   , 0.9385 ,\n",
       "            0.935  , 0.934  , 0.9326 , 0.9307 , 0.928  , 0.927  , 0.9263 ,\n",
       "            0.925  , 0.9233 , 0.9224 , 0.921  , 0.918  , 0.9165 , 0.9146 ,\n",
       "            0.9116 , 0.91   , 0.9097 , 0.909  , 0.9077 , 0.9067 , 0.9043 ,\n",
       "            0.9004 , 0.893  , 0.8926 , 0.888  , 0.8877 , 0.884  , 0.881  ,\n",
       "            0.878  , 0.8774 , 0.874  , 0.873  , 0.871  , 0.8706 , 0.867  ,\n",
       "            0.8657 , 0.865  , 0.8623 , 0.8604 , 0.8594 , 0.8584 , 0.857  ,\n",
       "            0.856  , 0.854  , 0.851  , 0.849  , 0.8486 , 0.8467 , 0.843  ,\n",
       "            0.842  , 0.8384 , 0.8374 , 0.836  , 0.835  , 0.832  , 0.83   ,\n",
       "            0.828  , 0.8237 , 0.8228 , 0.818  , 0.8164 , 0.8105 , 0.8047 ,\n",
       "            0.8037 , 0.798  , 0.7896 , 0.7876 , 0.787  , 0.7847 , 0.7837 ,\n",
       "            0.783  , 0.7764 , 0.776  , 0.774  , 0.7344 , 0.7    , 0.6875 ,\n",
       "            0.685  , 0.678  , 0.6646 , 0.6636 , 0.638  , 0.635  , 0.6006 ,\n",
       "            0.5786 , 0.571  , 0.5605 , 0.534  , 0.525  , 0.5176 , 0.507  ,\n",
       "            0.4573 , 0.4402 , 0.4211 , 0.4097 , 0.403  , 0.392  , 0.3845 ,\n",
       "            0.3726 , 0.3667 , 0.3416 , 0.341  , 0.3386 , 0.3215 , 0.2637 ,\n",
       "            0.2413 , 0.2383 , 0.2302 , 0.199  , 0.1583 , 0.1487 , 0.143  ,\n",
       "            0.1298 , 0.1268 , 0.1241 , 0.09705, 0.0964 , 0.0959 , 0.0871 ,\n",
       "            0.0825 , 0.07806, 0.0537 , 0.0452 , 0.04492, 0.04477, 0.0432 ,\n",
       "            0.0372 , 0.03455, 0.02722, 0.02307, 0.01859, 0.01646, 0.01243,\n",
       "            0.0043 ], dtype=float16)}}]],\n",
       " 'roc_results': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.00333333, 0.00333333, 0.00333333, 0.00666667,\n",
       "         0.01      , 0.01333333, 0.01333333, 0.01333333, 0.01666667,\n",
       "         0.02      , 0.02666667, 0.03333334, 0.04      , 0.05      ,\n",
       "         0.06      , 0.06333333, 0.08      , 0.08666667, 0.09666666,\n",
       "         0.09666666, 0.1       , 0.11333334, 0.12333333, 0.13333334,\n",
       "         0.13666667, 0.15      , 0.17333333, 0.18333334, 0.20333333,\n",
       "         0.22666667, 0.23      , 0.24666667, 0.25666666, 0.27666667,\n",
       "         0.3       , 0.31666666, 0.32666665, 0.34      , 0.35666665,\n",
       "         0.36333334, 0.36666667, 0.37333333, 0.37666667, 0.38      ,\n",
       "         0.38      , 0.38333333, 0.38333333, 0.38666666, 0.39      ,\n",
       "         0.39666668, 0.39666668, 0.40333334, 0.40666667, 0.40666667,\n",
       "         0.40666667, 0.40666667, 0.40666667, 0.41333333, 0.41666666,\n",
       "         0.42      , 0.43      , 0.43333334, 0.43333334, 0.43333334,\n",
       "         0.43333334, 0.43333334, 0.43666667, 0.44      , 0.44333333,\n",
       "         0.44333333, 0.44666666, 0.45666668, 0.45666668, 0.46      ,\n",
       "         0.46333334, 0.46333334, 0.46333334, 0.46333334, 0.47      ,\n",
       "         0.47333333, 0.47333333, 0.47333333, 0.47666666, 0.48      ,\n",
       "         0.48333332, 0.48333332, 0.48666668, 0.48666668, 0.48666668,\n",
       "         0.48666668, 0.49      , 0.5       , 0.5       , 0.5       ,\n",
       "         0.50666666, 0.50666666, 0.50666666, 0.50666666, 0.50666666,\n",
       "         0.5133333 , 0.5133333 , 0.52      , 0.5233333 , 0.53      ,\n",
       "         0.53333336, 0.54      , 0.54333335, 0.55333334, 0.55333334,\n",
       "         0.5566667 , 0.56      , 0.57      , 0.58      , 0.59      ,\n",
       "         0.5933333 , 0.5933333 , 0.61      , 0.61333334, 0.61333334,\n",
       "         0.6166667 , 0.62666667, 0.62666667, 0.63666666, 0.64666665,\n",
       "         0.6533333 , 0.66      , 0.6666667 , 0.6766667 , 0.68333334,\n",
       "         0.68333334, 0.68666667, 0.6933333 , 0.69666666, 0.69666666,\n",
       "         0.7       , 0.7033333 , 0.71      , 0.71666664, 0.72333336,\n",
       "         0.7266667 , 0.73333335, 0.7366667 , 0.7366667 , 0.74333334,\n",
       "         0.74666667, 0.75      , 0.75666666, 0.76      , 0.7633333 ,\n",
       "         0.76666665, 0.76666665, 0.7733333 , 0.78      , 0.78333336,\n",
       "         0.79      , 0.79333335, 0.79333335, 0.8       , 0.8066667 ,\n",
       "         0.81333333, 0.81666666, 0.82666665, 0.83      , 0.84      ,\n",
       "         0.8466667 , 0.85      , 0.8566667 , 0.86333334, 0.8666667 ,\n",
       "         0.8666667 , 0.87      , 0.87333333, 0.88      , 0.88666666,\n",
       "         0.89      , 0.89      , 0.8933333 , 0.89666665, 0.9       ,\n",
       "         0.9033333 , 0.9066667 , 0.9066667 , 0.9066667 , 0.9066667 ,\n",
       "         0.9066667 , 0.9066667 , 0.91      , 0.91      , 0.91333336,\n",
       "         0.9166667 , 0.92      , 0.92333335, 0.9266667 , 0.93      ,\n",
       "         0.93      , 0.93333334, 0.93333334, 0.93666667, 0.94      ,\n",
       "         0.9433333 , 0.94666666, 0.94666666, 0.94666666, 0.95      ,\n",
       "         0.95      , 0.95      , 0.9533333 , 0.9533333 , 0.9533333 ,\n",
       "         0.95666665, 0.96      , 0.96      , 0.96      , 0.96666664,\n",
       "         0.96666664, 0.96666664, 0.97      , 0.97      , 0.97333336,\n",
       "         0.97333336, 0.97333336, 0.97333336, 0.97333336, 0.9766667 ,\n",
       "         0.98      , 0.98      , 0.98      , 0.98333335, 0.9866667 ,\n",
       "         0.9866667 , 0.9866667 , 0.99      , 0.99      , 0.99      ,\n",
       "         0.99      , 0.99      , 0.99      , 0.99      , 0.99      ,\n",
       "         0.99      , 0.99      , 0.99      , 0.99      , 0.99      ,\n",
       "         0.99      , 0.99      , 0.99      , 0.99      , 0.99      ,\n",
       "         0.99      , 0.99      , 0.99333334, 0.99333334, 0.99333334,\n",
       "         0.99666667, 0.99666667, 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "        dtype=float32),\n",
       "  'tpr': array([0.        , 0.00333333, 0.00666667, 0.01333333, 0.02      ,\n",
       "         0.02333333, 0.03666667, 0.04      , 0.04666667, 0.05      ,\n",
       "         0.05333333, 0.07      , 0.08666667, 0.09      , 0.1       ,\n",
       "         0.10333333, 0.11333334, 0.11666667, 0.12333333, 0.12666667,\n",
       "         0.14      , 0.14666666, 0.15333334, 0.16333333, 0.17      ,\n",
       "         0.17      , 0.17666666, 0.18      , 0.18      , 0.18      ,\n",
       "         0.18666667, 0.18666667, 0.19      , 0.19666667, 0.2       ,\n",
       "         0.20333333, 0.21333334, 0.21333334, 0.21666667, 0.21666667,\n",
       "         0.22666667, 0.23333333, 0.24      , 0.25      , 0.26      ,\n",
       "         0.27666667, 0.28333333, 0.28333333, 0.29      , 0.3       ,\n",
       "         0.3       , 0.30666667, 0.31      , 0.31      , 0.31      ,\n",
       "         0.31333333, 0.31333333, 0.32      , 0.32333332, 0.32333332,\n",
       "         0.32333332, 0.33333334, 0.33666667, 0.34666666, 0.35      ,\n",
       "         0.35333332, 0.35666665, 0.36      , 0.36333334, 0.37333333,\n",
       "         0.38      , 0.38      , 0.38333333, 0.39      , 0.39333335,\n",
       "         0.39666668, 0.4       , 0.40333334, 0.40333334, 0.40333334,\n",
       "         0.40666667, 0.40666667, 0.41      , 0.41666666, 0.42      ,\n",
       "         0.42      , 0.42666668, 0.43      , 0.43333334, 0.43666667,\n",
       "         0.43666667, 0.44      , 0.44666666, 0.45333335, 0.45333335,\n",
       "         0.46      , 0.46333334, 0.46666667, 0.47      , 0.47333333,\n",
       "         0.47666666, 0.48      , 0.48333332, 0.49      , 0.49333334,\n",
       "         0.49666667, 0.50333333, 0.50666666, 0.51      , 0.51666665,\n",
       "         0.51666665, 0.52      , 0.52      , 0.52      , 0.52      ,\n",
       "         0.52      , 0.5233333 , 0.53      , 0.5366667 , 0.54      ,\n",
       "         0.54333335, 0.5466667 , 0.5466667 , 0.5466667 , 0.5466667 ,\n",
       "         0.5466667 , 0.55      , 0.55      , 0.55      , 0.55333334,\n",
       "         0.56666666, 0.57      , 0.57666665, 0.57666665, 0.58      ,\n",
       "         0.58      , 0.5833333 , 0.59      , 0.59      , 0.5933333 ,\n",
       "         0.5966667 , 0.5966667 , 0.5966667 , 0.5966667 , 0.60333335,\n",
       "         0.60333335, 0.60333335, 0.61      , 0.61      , 0.61      ,\n",
       "         0.61      , 0.61      , 0.61333334, 0.62      , 0.62      ,\n",
       "         0.62      , 0.62      , 0.62      , 0.62      , 0.62      ,\n",
       "         0.62      , 0.62333333, 0.6333333 , 0.6333333 , 0.6333333 ,\n",
       "         0.6333333 , 0.6333333 , 0.63666666, 0.64      , 0.64      ,\n",
       "         0.64      , 0.6433333 , 0.65      , 0.65      , 0.6533333 ,\n",
       "         0.6566667 , 0.6566667 , 0.6566667 , 0.6566667 , 0.6566667 ,\n",
       "         0.66333336, 0.6666667 , 0.67      , 0.67      , 0.67      ,\n",
       "         0.67      , 0.67333335, 0.67333335, 0.68      , 0.68      ,\n",
       "         0.68      , 0.68      , 0.68333334, 0.68666667, 0.69      ,\n",
       "         0.6933333 , 0.69666666, 0.69666666, 0.7       , 0.7       ,\n",
       "         0.7       , 0.7       , 0.7       , 0.7       , 0.7       ,\n",
       "         0.71      , 0.7133333 , 0.72      , 0.72333336, 0.72333336,\n",
       "         0.7266667 , 0.7266667 , 0.73      , 0.73333335, 0.73333335,\n",
       "         0.7366667 , 0.74666667, 0.74666667, 0.75      , 0.75333333,\n",
       "         0.75333333, 0.75333333, 0.75666666, 0.76      , 0.76      ,\n",
       "         0.7633333 , 0.77      , 0.77      , 0.7733333 , 0.7733333 ,\n",
       "         0.77666664, 0.78      , 0.78333336, 0.7866667 , 0.7866667 ,\n",
       "         0.79      , 0.79333335, 0.7966667 , 0.7966667 , 0.7966667 ,\n",
       "         0.8       , 0.80333334, 0.80333334, 0.8066667 , 0.81      ,\n",
       "         0.81333333, 0.81666666, 0.82      , 0.8233333 , 0.82666665,\n",
       "         0.83      , 0.8333333 , 0.83666664, 0.8433333 , 0.8466667 ,\n",
       "         0.85      , 0.85333335, 0.8566667 , 0.86      , 0.86333334,\n",
       "         0.8666667 , 0.87      , 0.87      , 0.87333333, 0.87666667,\n",
       "         0.87666667, 0.8833333 , 0.8833333 , 0.88666666, 0.8933333 ,\n",
       "         0.89666665, 0.9       , 0.9033333 , 0.9066667 , 0.91      ,\n",
       "         0.91333336, 0.9166667 , 0.92      , 0.92333335, 0.9266667 ,\n",
       "         0.93      , 0.93333334, 0.93666667, 0.94      , 0.9433333 ,\n",
       "         0.94666666, 0.9533333 , 0.95666665, 0.96      , 0.9633333 ,\n",
       "         0.96666664, 0.97      , 0.97333336, 0.9766667 , 0.98333335,\n",
       "         0.9866667 , 0.99      , 0.99333334, 0.99666667, 1.        ],\n",
       "        dtype=float32),\n",
       "  'thresholds': array([1.    , 0.5254, 0.5244, 0.524 , 0.5234, 0.523 , 0.5225, 0.522 ,\n",
       "         0.5215, 0.521 , 0.5205, 0.52  , 0.5195, 0.519 , 0.5186, 0.518 ,\n",
       "         0.5176, 0.517 , 0.5166, 0.516 , 0.5156, 0.515 , 0.5146, 0.514 ,\n",
       "         0.5137, 0.513 , 0.5127, 0.512 , 0.5117, 0.511 , 0.5107, 0.5103,\n",
       "         0.51  , 0.5093, 0.509 , 0.5083, 0.508 , 0.5073, 0.507 , 0.5063,\n",
       "         0.506 , 0.5054, 0.505 , 0.5044, 0.5034, 0.503 , 0.5024, 0.502 ,\n",
       "         0.5015, 0.501 , 0.5005, 0.5   , 0.4998, 0.4995, 0.4993, 0.499 ,\n",
       "         0.4985, 0.4978, 0.4976, 0.4973, 0.497 , 0.4968, 0.4966, 0.4963,\n",
       "         0.496 , 0.4958, 0.4956, 0.4954, 0.495 , 0.4949, 0.4946, 0.4944,\n",
       "         0.4941, 0.494 , 0.4937, 0.4934, 0.4932, 0.493 , 0.4924, 0.4922,\n",
       "         0.4915, 0.4912, 0.4905, 0.4902, 0.49  , 0.4897, 0.4895, 0.4893,\n",
       "         0.4888, 0.4883, 0.4878, 0.4873, 0.487 , 0.4868, 0.4866, 0.4863,\n",
       "         0.486 , 0.4858, 0.4856, 0.4854, 0.4849, 0.4844, 0.4841, 0.4834,\n",
       "         0.4824, 0.4822, 0.482 , 0.4817, 0.4814, 0.4812, 0.4807, 0.4805,\n",
       "         0.48  , 0.4797, 0.4795, 0.4792, 0.479 , 0.4788, 0.4783, 0.478 ,\n",
       "         0.4778, 0.4775, 0.4773, 0.4768, 0.4766, 0.4758, 0.4756, 0.4753,\n",
       "         0.475 , 0.4749, 0.4746, 0.4744, 0.474 , 0.4739, 0.4736, 0.4734,\n",
       "         0.4731, 0.4727, 0.4724, 0.4722, 0.472 , 0.4717, 0.4714, 0.471 ,\n",
       "         0.4707, 0.4705, 0.4702, 0.47  , 0.4697, 0.4688, 0.4685, 0.4683,\n",
       "         0.468 , 0.4678, 0.467 , 0.4668, 0.4666, 0.466 , 0.4656, 0.4648,\n",
       "         0.4646, 0.4644, 0.464 , 0.4639, 0.4636, 0.4634, 0.463 , 0.4626,\n",
       "         0.4622, 0.462 , 0.4617, 0.4614, 0.4612, 0.461 , 0.4607, 0.4604,\n",
       "         0.46  , 0.4595, 0.4592, 0.4585, 0.458 , 0.4578, 0.4573, 0.4568,\n",
       "         0.4565, 0.4563, 0.456 , 0.4558, 0.4556, 0.4553, 0.455 , 0.4548,\n",
       "         0.4546, 0.4543, 0.454 , 0.4539, 0.4531, 0.453 , 0.4526, 0.4524,\n",
       "         0.4521, 0.452 , 0.4517, 0.4514, 0.4512, 0.451 , 0.4507, 0.4504,\n",
       "         0.4502, 0.45  , 0.449 , 0.4485, 0.4482, 0.448 , 0.4478, 0.4475,\n",
       "         0.4473, 0.447 , 0.446 , 0.4456, 0.4448, 0.4446, 0.4436, 0.4434,\n",
       "         0.443 , 0.4424, 0.4414, 0.441 , 0.4404, 0.44  , 0.4382, 0.438 ,\n",
       "         0.4375, 0.4368, 0.4355, 0.4343, 0.4338, 0.4333, 0.433 , 0.432 ,\n",
       "         0.4312, 0.4304, 0.43  , 0.4294, 0.428 , 0.4277, 0.4275, 0.4272,\n",
       "         0.4268, 0.4265, 0.4263, 0.426 , 0.4253, 0.424 , 0.4238, 0.4233,\n",
       "         0.423 , 0.422 , 0.4219, 0.4216, 0.4211, 0.4202, 0.4194, 0.4187,\n",
       "         0.4185, 0.4182, 0.4177, 0.417 , 0.4163, 0.4146, 0.4114, 0.4106,\n",
       "         0.4102, 0.4087, 0.4084, 0.4026, 0.4019, 0.4016, 0.4004, 0.4001,\n",
       "         0.4   , 0.3977, 0.3975, 0.3962, 0.3953, 0.3918, 0.3916, 0.3914,\n",
       "         0.391 , 0.3901, 0.3894, 0.3867, 0.3835, 0.3826, 0.379 , 0.3772,\n",
       "         0.3735, 0.3728, 0.3706, 0.3572], dtype=float16),\n",
       "  'name': 'Original NN data1',\n",
       "  'auc': array(0.44575554, dtype=float32),\n",
       "  'model': LitClassifier(\n",
       "    (model): SimpleClassifier(\n",
       "      (layer_stack): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): BCEWithLogitsLoss()\n",
       "    (train_accuracy): BinaryAccuracy()\n",
       "    (test_accuracy): BinaryAccuracy()\n",
       "    (test_auc): BinaryAUROC()\n",
       "  )},\n",
       " 'test_loader': <torch.utils.data.dataloader.DataLoader at 0x735411b5cfb0>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle, load_from_pickle\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison\n",
    "from predict_ensemble_and_evaluate import make_curve_monotonic\n",
    "\n",
    "# Save the data\n",
    "save_to_pickle(list_folds_best_models, list_folds_weighted_clfs, results_original_roc, test_loader, filename='pickle/NN_data1_weighted.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3aba17",
   "metadata": {},
   "source": [
    "# Load pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "256006b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle, load_from_pickle\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison\n",
    "from predict_ensemble_and_evaluate import make_curve_monotonic\n",
    "\n",
    "# Load the data\n",
    "list_folds_best_models, list_folds_weighted_clfs, results_original_roc, test_loader = load_from_pickle(filename='pickle/NN_data1_weighted.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5d9c39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the best classifiers of all folds\n",
    "results_lists = []\n",
    "results_lists.extend(list_folds_best_models)\n",
    "results_lists.extend(list_folds_weighted_clfs)\n",
    "plot_roc_comparison(\n",
    "    results_lists=results_lists,\n",
    "    names=[\"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Weighted1\", \"Weighted2\", \"Weighted3\", \"Weighted4\"],\n",
    "    results_original_roc=results_original_roc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275941a6",
   "metadata": {},
   "source": [
    "### Ensemble prediction using voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "586c430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a single ensemble from 50 models across all folds.\n",
      "Extracting full dataset...\n",
      "Getting predictions from all models...\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Loop through all the FPR values to generate the ensemble ROC curve ---\n",
    "\n",
    "\n",
    "\n",
    "results_tuple = predict_ensemble_and_evaluate(list_folds_best_models=list_folds_best_models,\n",
    "    test_loader=test_loader)\n",
    "\n",
    "ensemble_results_soft = results_tuple['soft_voting']\n",
    "ensemble_results_hard = results_tuple['hard_voting']\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bae1a225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Plotting all ROC curves for comparison ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the best classifiers of all folds\n",
    "results_lists = []\n",
    "results_lists.extend(list_folds_best_models)\n",
    "results_lists.extend(list_folds_weighted_clfs)\n",
    "results_lists.append(ensemble_results_soft)\n",
    "results_lists.append(ensemble_results_hard)\n",
    "\n",
    "\n",
    "# --- Plot the final comparison ---\n",
    "print(\"\\n--- Plotting all ROC curves for comparison ---\")\n",
    "plot_roc_comparison(\n",
    "    results_lists=results_lists,\n",
    "    names=[\"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Weighted1\", \"Weighted2\", \"Weighted3\", \"Weighted4\", \"Ensemble_voting_soft\", \"Ensemble_voting_hard\"],\n",
    "    results_original_roc=results_original_roc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd54a198",
   "metadata": {},
   "source": [
    "## Check performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667ba0e7",
   "metadata": {},
   "source": [
    "## Check performance on test1 and test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f504bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_performance_tester(classifier_list, test_loader):\n",
    "\n",
    "    list_weighted_clfs = []  # Reset the list for final testing\n",
    "    for i, model_info in enumerate(classifier_list):\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator='gpu',\n",
    "            devices=1,\n",
    "            #strategy='ddp_notebook',\n",
    "            max_epochs=NUM_EPOCHS, # Number of epochs for THIS stage\n",
    "            callbacks=[checkpoint_callback, progress_bar],\n",
    "            logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=f\"stage_{i+1}\"),\n",
    "            precision='16-mixed'\n",
    "            )\n",
    "\n",
    "        model = model_info[\"model\"]\n",
    "        raw_threshold = model_info[\"threshold\"]\n",
    "\n",
    "\n",
    "        # CORRECTED: Use isinstance() to check if model is a string\n",
    "        if isinstance(model, str):\n",
    "            print(f\"Skipping model {i+1} as it is a string placeholder: '{model}'\")\n",
    "            continue\n",
    "\n",
    "        # Check if the stored threshold is a NumPy number or a PyTorch Tensor\n",
    "        if isinstance(raw_threshold, (np.number, torch.Tensor)):\n",
    "            # If it is, we can safely call .item() to extract the Python float\n",
    "            threshold = raw_threshold.item()\n",
    "        else:\n",
    "            # Otherwise, it's already a float or something that can be cast to one\n",
    "            threshold = float(raw_threshold)\n",
    "        model.current_test_threshold = threshold  # Set the threshold for this model\n",
    "\n",
    "        # This code will now only run if 'model' is a PyTorch Lightning module\n",
    "        # and not a string.\n",
    "        print(f\"--- Testing model {i+1} ---\")\n",
    "\n",
    "        trainer.test(model, dataloaders=test_loader, ckpt_path=None)\n",
    "        \n",
    "        results_classifier = model.last_test_results.copy()\n",
    "        current_model = {\n",
    "            \"model\": model,\n",
    "            \"fpr\": results_classifier[\"fpr\"],\n",
    "            \"tpr\": results_classifier[\"tpr\"],\n",
    "            \"threshold\": results_classifier[\"threshold\"],\n",
    "            \"full_roc\": results_classifier[\"full_roc\"]\n",
    "        }\n",
    "        list_weighted_clfs.append(current_model)\n",
    "\n",
    "    # Ensure the curve starts at (0, 0)\n",
    "    if not list_weighted_clfs or list_weighted_clfs[0]['fpr'] > 0.0:\n",
    "        list_weighted_clfs.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if list_weighted_clfs[-1]['fpr'] < 1.0 or list_weighted_clfs[-1]['tpr'] < 1.0:\n",
    "        list_weighted_clfs.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    return list_weighted_clfs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLlabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
